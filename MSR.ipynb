{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/PoPCites2.csv')\n",
    "#data = pd.read_csv('data/PoPCites2.csv',usecols = '')\n",
    "\n",
    "# RQ1: Which technologies have been investigated in the last decade?\n",
    "\n",
    "# RQ2: In which phase of the technology life cycle path are the technologies?\n",
    "# - Interest in topic: #Papers on a topic over time\n",
    "# - Parallel dazu: Interest in topic: Number of citations to papers on a topic over time\n",
    "#- Publikationstyp: Workshop -> Conference -> Journal \n",
    "\n",
    "# RQ3: How stable is the community working on the topics (new authors emerging, authors staying on for the whole time,\n",
    "# or authors “leaving” the area)?\n",
    "\n",
    "#data.info()\n",
    "#data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktionen\n",
    "def Count(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountCites(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountWords(data,count):\n",
    "    cnt = Counter()\n",
    "    #Pandas.Series durchlaufen um die Title zu bekommen\n",
    "    for index, value in data.items():\n",
    "        words = value.lower().split(' ')\n",
    "        #Title in Wörter teilen\n",
    "        for word in words:\n",
    "            #Aussortieren der Stopwords\n",
    "            if not word in stopwords:\n",
    "                #Für bestimmte Begriffe\n",
    "                #for word in wordlist:\n",
    "                cnt[word] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountToTfidf(counts):\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    \n",
    "    #Gewichtet die CountMatrix\n",
    "    tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "    #Gibt Array zurück\n",
    "    return tfidf.toarray()\n",
    "\n",
    "def ListToDataFrame(l):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:'data'})\n",
    "    ld = ld.set_index('word')\n",
    "    return ld\n",
    "\n",
    "\n",
    "def ListToDataArray(l,year):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:year})\n",
    "    ld = ld.set_index('word')\n",
    "    #Gibt Pandas.DataFrame zurück\n",
    "    return ld\n",
    "\n",
    "\n",
    "def TfidfVector(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(X.toarray())\n",
    "    \n",
    "def CountVector(data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    return X.toarray()\n",
    "\n",
    "def FilteredByYear(data,year):\n",
    "    databyyear = data.loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "    \n",
    "def TitleFilteredByYear(data,year):\n",
    "    databyyear = data['Title'].loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "\n",
    "def CountWordsByYear(data,year):\n",
    "    #d = Pandas.Series\n",
    "    d = FilteredByYear(data,year)\n",
    "    l = CountWords(d['Title'],30)\n",
    "    #Gibt List zurück\n",
    "    return l\n",
    "\n",
    "def CountWordsInAbstractByYear(data,year):\n",
    "    d = FilteredByYear(data,year)\n",
    "    l = CountWords(d['Abstract'],30)\n",
    "    return l\n",
    "    \n",
    "def MergeDataFrames(data,anzahlJahre):\n",
    "    year = datetime.datetime.now()\n",
    "    year = year.year\n",
    "    da = pd.DataFrame()\n",
    "    for y in range(year - anzahlJahre, year):\n",
    "        l = CountWordsByYear(data,y)\n",
    "        p = ListToDataArray(l,y)\n",
    "        if(da.empty):\n",
    "            da = p\n",
    "        else:\n",
    "            da = da.merge(p, on= 'word' ,how='inner')\n",
    "    return da       \n",
    "    \n",
    "def CosineSimilarity(data):\n",
    "    return cosine_similarity(data,data)\n",
    "\n",
    "def CreateDocTermMatrix(data):\n",
    "    documents = []\n",
    "\n",
    "    for text in data:\n",
    "        documents.append(text)\n",
    "\n",
    "\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    #count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "    print(sparse_matrix)\n",
    "\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    return pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variablen erstellen\n",
    "title = data['Title']\n",
    "publisher = data['Publisher']\n",
    "year = data['Year']\n",
    "\n",
    "wordlist = [\n",
    "    'DevOps',\n",
    "    'engineering',\n",
    "    'Software',\n",
    "    'Engineering',\n",
    "    'software'\n",
    "    \n",
    "]\n",
    "stopwords =[\n",
    "    'this',\n",
    "    'is',\n",
    "    'none',\n",
    "    'in',\n",
    "    'of',\n",
    "    'A',\n",
    "    'a',\n",
    "    'and',\n",
    "    'for',\n",
    "    'with',\n",
    "    'on',\n",
    "    'the',\n",
    "    'to',\n",
    "    'an',\n",
    "    'be',\n",
    "    'as',\n",
    "    'has',\n",
    "    'are',\n",
    "    'we',\n",
    "    'been',\n",
    "    'by',\n",
    "    'many',\n",
    "    'that',\n",
    "    'at',\n",
    "    '...',\n",
    "    'more',\n",
    "    'them',\n",
    "    'have',\n",
    "    'such'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1 = CountWordsByYear(data,2017)\n",
    "#l2 = CountWordsByYear(data,2018)\n",
    "#l3 = CountWordsByYear(data,2019)\n",
    "#l4 = CountWordsByYear(data,2020)\n",
    "#l4 = ListToDataArray(l4,2020)\n",
    "l = CountWordsInAbstractByYear(data,2019)\n",
    "#d = CalculateSimilarity(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = CountWordsInAbstractByYear(data,2019)\n",
    "df = ListToDataFrame(l)\n",
    "#df\n",
    "#df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "strip arg must be None or str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7a132ae9eb8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Hier arbeiten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mabstract\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCreateDocTermMatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Abstract'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCosineSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabstract\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-96f9ea3295aa>\u001b[0m in \u001b[0;36mCreateDocTermMatrix\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[0mdocuments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: strip arg must be None or str"
     ]
    }
   ],
   "source": [
    "#Hier arbeiten\n",
    "\n",
    "abstract = CreateDocTermMatrix(data['Abstract'])\n",
    "print(abstract)\n",
    "print(CosineSimilarity(abstract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = CreateDocTermMatrix(data['Title'])\n",
    "title.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "#doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "#print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "#print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "#for entity in doc.ents:\n",
    "##print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dokumentenähnlichkeit x Graphanalyse\n",
    "\n",
    "#Wachstum darstellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018 = TitleFilteredByYear(data,2018)\n",
    "#data['Cites'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVector(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
