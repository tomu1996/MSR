{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Cites           200 non-null    int64  \n",
      " 1   Authors         200 non-null    object \n",
      " 2   Title           200 non-null    object \n",
      " 3   Year            200 non-null    int64  \n",
      " 4   Source          183 non-null    object \n",
      " 5   Publisher       200 non-null    object \n",
      " 6   ArticleURL      200 non-null    object \n",
      " 7   CitesURL        200 non-null    object \n",
      " 8   GSRank          200 non-null    int64  \n",
      " 9   QueryDate       200 non-null    object \n",
      " 10  Type            37 non-null     object \n",
      " 11  DOI             0 non-null      float64\n",
      " 12  ISSN            0 non-null      float64\n",
      " 13  CitationURL     0 non-null      float64\n",
      " 14  Volume          0 non-null      float64\n",
      " 15  Issue           0 non-null      float64\n",
      " 16  StartPage       0 non-null      float64\n",
      " 17  EndPage         0 non-null      float64\n",
      " 18  ECC             200 non-null    int64  \n",
      " 19  CitesPerYear    200 non-null    float64\n",
      " 20  CitesPerAuthor  200 non-null    int64  \n",
      " 21  AuthorCount     200 non-null    int64  \n",
      " 22  Age             200 non-null    int64  \n",
      " 23  Abstract        200 non-null    object \n",
      "dtypes: float64(8), int64(7), object(9)\n",
      "memory usage: 37.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/PoPCites2.csv')\n",
    "#data = pd.read_csv('data/PoPCites2.csv',usecols = '')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktionen\n",
    "def Count(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountCites(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountWords(data,count):\n",
    "    cnt = Counter()\n",
    "    #Pandas.Series durchlaufen um die Title zu bekommen\n",
    "    for index, value in data.items():\n",
    "        words = value.lower().split(' ')\n",
    "        #Title in Wörter teilen\n",
    "        for word in words:\n",
    "            #Aussortieren der Stopwords\n",
    "            if not word in stopwords:\n",
    "                #Für bestimmte Begriffe\n",
    "                #for word in wordlist:\n",
    "                cnt[word] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountToTfidf(counts):\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    \n",
    "    #Gewichtet die CountMatrix\n",
    "    tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "    #Gibt Array zurück\n",
    "    return tfidf.toarray()\n",
    "\n",
    "\n",
    "def ListToDataArray(l,year):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:year})\n",
    "    ld = ld.set_index('word')\n",
    "    #Gibt Pandas.DataFrame zurück\n",
    "    return ld\n",
    "\n",
    "\n",
    "def TfidfVector(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(X.toarray())\n",
    "    \n",
    "def CountVector(data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    return X.toarray()\n",
    "    \n",
    "def TitleFilteredByYear(data,year):\n",
    "    databyyear = data['Title'].loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "\n",
    "def CountWordsByYear(data,year):\n",
    "    #d = Pandas.Series\n",
    "    d = TitleFilteredByYear(data,year)\n",
    "    l = CountWords(d,30)\n",
    "    #Gibt List zurück\n",
    "    return l\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-4-be28766c5aaa>, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-be28766c5aaa>\"\u001b[1;36m, line \u001b[1;32m7\u001b[0m\n\u001b[1;33m    'DevOps',<<\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Variablen erstellen\n",
    "title = data['Title']\n",
    "publisher = data['Publisher']\n",
    "year = data['Year']\n",
    "\n",
    "wordlist = [\n",
    "    'DevOps',<<\n",
    "    'engineering',\n",
    "    'Software',\n",
    "    'Engineering',\n",
    "    'software'\n",
    "    \n",
    "]\n",
    "stopwords =[\n",
    "    'this',\n",
    "    'is ',\n",
    "    'none',\n",
    "    'in',\n",
    "    'of',\n",
    "    'A',\n",
    "    'a',\n",
    "    'and',\n",
    "    'for',\n",
    "    'with',\n",
    "    'on',\n",
    "    'the',\n",
    "    'to',\n",
    "    'an'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zählen der Publisher\n",
    "lst = Count(publisher,10)\n",
    "#lst\n",
    "\n",
    "#for x in data:\n",
    " #   print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = CountWordsByYear(data,2017)\n",
    "a = []for letter, count in l1:\n",
    "    a.append(count)\n",
    "print(a)\n",
    "l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = CountWordsByYear(data,2018)\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = CountWordsByYear(data,2019)\n",
    "l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l4 = CountWordsByYear(data,2020)\n",
    "l4 = ListToDataArray(l4,2020)\n",
    "l4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "#doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "#print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "#print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "#for entity in doc.ents:\n",
    "##print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dokumentenähnlichkeit x Graphanalyse\n",
    "\n",
    "#Wachstum darstellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018 = TitleFilteredByYear(data,2018)\n",
    "#data['Cites'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVector(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
