{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/PoPCites2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktionen\n",
    "def Count(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountCites(data,count):\n",
    "    \n",
    "    i = 0\n",
    "    cnt = Counter()\n",
    "    for item in data['Cites']: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountWords(data,count):\n",
    "    cnt = Counter()\n",
    "    #Pandas.Series durchlaufen um die Title zu bekommen\n",
    "    for index, value in data.items():\n",
    "        words = value.lower().split(' ')\n",
    "        #Title in Wörter teilen\n",
    "        for word in words:\n",
    "            #Aussortieren der Stopwords\n",
    "            if not word in stopwords:\n",
    "                #Für bestimmte Begriffe\n",
    "                #for word in wordlist:\n",
    "                cnt[word] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountToTfidf(counts):\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    \n",
    "    #Gewichtet die CountMatrix\n",
    "    tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "    #Gibt Array zurück\n",
    "    return tfidf.toarray()\n",
    "\n",
    "def ListToDataFrame(l):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:'data'})\n",
    "    ld = ld.set_index('word')\n",
    "    return ld\n",
    "\n",
    "\n",
    "def ListToDataArray(l,year):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:year})\n",
    "    ld = ld.set_index('word')\n",
    "    #Gibt Pandas.DataFrame zurück\n",
    "    return ld\n",
    "\n",
    "\n",
    "def TfidfVector(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(X.toarray())\n",
    "    \n",
    "def CountVector(data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    return X.toarray()\n",
    "\n",
    "def FilteredbyPublisher(data,publisher):\n",
    "    databypublisher = data.loc[data['Publisher'] == publisher]\n",
    "    return databypublisher\n",
    "\n",
    "def FilteredByYear(data,year):\n",
    "    databyyear = data.loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "    \n",
    "def TitleFilteredByYear(data,year):\n",
    "    databyyear = data['Title'].loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "\n",
    "def CountWordsByYear(data,year):\n",
    "    #d = Pandas.Series\n",
    "    d = FilteredByYear(data,year)\n",
    "    l = CountWords(d['Title'],30)\n",
    "    #Gibt List zurück\n",
    "    return l\n",
    "\n",
    "def CountWordsInAbstractByYear(data,year):\n",
    "    d = FilteredByYear(data,year)\n",
    "    l = CountWords(d['Abstract'],30)\n",
    "    return l\n",
    "    \n",
    "def MergeDataFrames(data,anzahlJahre):\n",
    "    year = datetime.datetime.now()\n",
    "    year = year.year\n",
    "    da = pd.DataFrame()\n",
    "    for y in range(year - anzahlJahre, year):\n",
    "        l = CountWordsByYear(data,y)\n",
    "        p = ListToDataArray(l,y)\n",
    "        if(da.empty):\n",
    "            da = p\n",
    "        else:\n",
    "            da = da.merge(p, on= 'word' ,how='inner')\n",
    "    return da       \n",
    "    \n",
    "def CosineSimilarity(data):\n",
    "    return cosine_similarity(data,data)\n",
    "\n",
    "def CreateTermDocMatrix(data):\n",
    "    documents = []\n",
    "\n",
    "    for text in data['Abstract']:\n",
    "        documents.append(text)\n",
    "\n",
    "\n",
    "    count_vectorizer = CountVectorizer(stop_words='english')\n",
    "    #count_vectorizer = CountVectorizer()\n",
    "    sparse_matrix = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names())\n",
    "    df['PublishingYear'] = data['Year']\n",
    "    returndf = df.groupby('PublishingYear').sum()\n",
    "    return returndf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variablen erstellen\n",
    "title = data['Title']\n",
    "publisher = data['Publisher']\n",
    "year = data['Year']\n",
    "\n",
    "wordlist = [\n",
    "    'DevOps',\n",
    "    'engineering',\n",
    "    'Software',\n",
    "    'Engineering',\n",
    "    'software'\n",
    "    \n",
    "]\n",
    "stopwords =[\n",
    "    'this',\n",
    "    'is',\n",
    "    'none',\n",
    "    'in',\n",
    "    'of',\n",
    "    'A',\n",
    "    'a',\n",
    "    'and',\n",
    "    'for',\n",
    "    'with',\n",
    "    'on',\n",
    "    'the',\n",
    "    'to',\n",
    "    'an',\n",
    "    'be',\n",
    "    'as',\n",
    "    'has',\n",
    "    'are',\n",
    "    'we',\n",
    "    'been',\n",
    "    'by',\n",
    "    'many',\n",
    "    'that',\n",
    "    'at',\n",
    "    '...',\n",
    "    'more',\n",
    "    'them',\n",
    "    'have',\n",
    "    'such'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.21710791, 0.03618465, ..., 0.12021658, 0.15456232,\n",
       "        0.12255111],\n",
       "       [0.21710791, 1.        , 0.12307692, ..., 0.10222489, 0.11500161,\n",
       "        0.08684168],\n",
       "       [0.03618465, 0.12307692, 1.        , ..., 0.01703748, 0.0328576 ,\n",
       "        0.01736834],\n",
       "       ...,\n",
       "       [0.12021658, 0.10222489, 0.01703748, ..., 1.        , 0.12735696,\n",
       "        0.13464028],\n",
       "       [0.15456232, 0.11500161, 0.0328576 , ..., 0.12735696, 1.        ,\n",
       "        0.07418865],\n",
       "       [0.12255111, 0.08684168, 0.01736834, ..., 0.13464028, 0.07418865,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract = CreateDocTermMatrix(data['Abstract'])\n",
    "l = CosineSimilarity(abstract)\n",
    "l\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "databyyear = data.groupby(['Year','Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hier arbeiten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = CreateDocTermMatrix(data['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6667456\n"
     ]
    }
   ],
   "source": [
    "#data.info()\n",
    "\n",
    "import en_core_web_md\n",
    "nlp = en_core_web_md.load()\n",
    "#nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "doc = nlp(\"Tim and Tom\")\n",
    "token1, token2 = doc[0], doc[2]\n",
    "\n",
    "# Berechne die Ähnlichkeit der Tokens \"TV\" und \"books\"\n",
    "similarity = token1.similarity(token2)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "#doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "#print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "#print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "#for entity in doc.ents:\n",
    "##print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "token_text = [token.text for token in doc]\n",
    ">>> print(token_text)\n",
    ">>> token = [token for token in doc]\n",
    ">>> print(token)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018 = TitleFilteredByYear(data,2018)\n",
    "#data['Cites'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVector(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
