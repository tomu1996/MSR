{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/PoPCites2.csv')\n",
    "#data = pd.read_csv('data/PoPCites2.csv',usecols = '')\n",
    "\n",
    "# RQ1: Which technologies have been investigated in the last decade?\n",
    "\n",
    "# RQ2: In which phase of the technology life cycle path are the technologies?\n",
    "# - Interest in topic: #Papers on a topic over time\n",
    "# - Parallel dazu: Interest in topic: Number of citations to papers on a topic over time\n",
    "#- Publikationstyp: Workshop -> Conference -> Journal \n",
    "\n",
    "# RQ3: How stable is the community working on the topics (new authors emerging, authors staying on for the whole time,\n",
    "# or authors “leaving” the area)?\n",
    "\n",
    "#data.info()\n",
    "#data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktionen\n",
    "def Count(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountCites(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountWords(data,count):\n",
    "    cnt = Counter()\n",
    "    #Pandas.Series durchlaufen um die Title zu bekommen\n",
    "    for index, value in data.items():\n",
    "        words = value.lower().split(' ')\n",
    "        #Title in Wörter teilen\n",
    "        for word in words:\n",
    "            #Aussortieren der Stopwords\n",
    "            if not word in stopwords:\n",
    "                #Für bestimmte Begriffe\n",
    "                #for word in wordlist:\n",
    "                cnt[word] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountToTfidf(counts):\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    \n",
    "    #Gewichtet die CountMatrix\n",
    "    tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "    #Gibt Array zurück\n",
    "    return tfidf.toarray()\n",
    "\n",
    "def ListToDataFrame(l):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:'data'})\n",
    "    ld = ld.set_index('word')\n",
    "    return ld\n",
    "\n",
    "\n",
    "def ListToDataArray(l,year):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:year})\n",
    "    ld = ld.set_index('word')\n",
    "    #Gibt Pandas.DataFrame zurück\n",
    "    return ld\n",
    "\n",
    "\n",
    "def TfidfVector(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(X.toarray())\n",
    "    \n",
    "def CountVector(data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    return X.toarray()\n",
    "\n",
    "def FilteredByYear(data,year):\n",
    "    databyyear = data.loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "    \n",
    "def TitleFilteredByYear(data,year):\n",
    "    databyyear = data['Title'].loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "\n",
    "def CountWordsByYear(data,year):\n",
    "    #d = Pandas.Series\n",
    "    d = TitleFilteredByYear(data,year)\n",
    "    l = CountWords(d,30)\n",
    "    #Gibt List zurück\n",
    "    return l\n",
    "\n",
    "def CountWordsInAbstractByYear(data,year):\n",
    "    d = FilteredByYear(data,2018)\n",
    "    l = CountWords(d['Abstract'],30)\n",
    "    return l\n",
    "    \n",
    "def MergeDataFrames(data,anzahlJahre):\n",
    "    year = datetime.datetime.now()\n",
    "    year = year.year\n",
    "    da = pd.DataFrame()\n",
    "    for y in range(year - anzahlJahre, year):\n",
    "        l = CountWordsByYear(data,y)\n",
    "        p = ListToDataArray(l,y)\n",
    "        if(da.empty):\n",
    "            da = p\n",
    "        else:\n",
    "            da = da.merge(p, on= 'word' ,how='inner')\n",
    "    return da       \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variablen erstellen\n",
    "title = data['Title']\n",
    "publisher = data['Publisher']\n",
    "year = data['Year']\n",
    "\n",
    "wordlist = [\n",
    "    'DevOps',\n",
    "    'engineering',\n",
    "    'Software',\n",
    "    'Engineering',\n",
    "    'software'\n",
    "    \n",
    "]\n",
    "stopwords =[\n",
    "    'this',\n",
    "    'is',\n",
    "    'none',\n",
    "    'in',\n",
    "    'of',\n",
    "    'A',\n",
    "    'a',\n",
    "    'and',\n",
    "    'for',\n",
    "    'with',\n",
    "    'on',\n",
    "    'the',\n",
    "    'to',\n",
    "    'an',\n",
    "    'be',\n",
    "    'as',\n",
    "    'has',\n",
    "    'are',\n",
    "    'we',\n",
    "    'been',\n",
    "    'by',\n",
    "    'many',\n",
    "    'that',\n",
    "    'at'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l1 = CountWordsByYear(data,2017)\n",
    "#l2 = CountWordsByYear(data,2018)\n",
    "#l3 = CountWordsByYear(data,2019)\n",
    "#l4 = CountWordsByYear(data,2020)\n",
    "#l4 = ListToDataArray(l4,2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = CountWordsInAbstractByYear(data,2019)\n",
    "df = ListToDataFrame(l)\n",
    "#df.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hier arbeiten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "#doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "#print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "#print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "#for entity in doc.ents:\n",
    "##print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dokumentenähnlichkeit x Graphanalyse\n",
    "\n",
    "#Wachstum darstellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018 = TitleFilteredByYear(data,2018)\n",
    "#data['Cites'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVector(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
