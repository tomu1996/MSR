{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import datetime\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 24 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Cites           200 non-null    int64  \n",
      " 1   Authors         200 non-null    object \n",
      " 2   Title           200 non-null    object \n",
      " 3   Year            200 non-null    int64  \n",
      " 4   Source          183 non-null    object \n",
      " 5   Publisher       200 non-null    object \n",
      " 6   ArticleURL      200 non-null    object \n",
      " 7   CitesURL        200 non-null    object \n",
      " 8   GSRank          200 non-null    int64  \n",
      " 9   QueryDate       200 non-null    object \n",
      " 10  Type            37 non-null     object \n",
      " 11  DOI             0 non-null      float64\n",
      " 12  ISSN            0 non-null      float64\n",
      " 13  CitationURL     0 non-null      float64\n",
      " 14  Volume          0 non-null      float64\n",
      " 15  Issue           0 non-null      float64\n",
      " 16  StartPage       0 non-null      float64\n",
      " 17  EndPage         0 non-null      float64\n",
      " 18  ECC             200 non-null    int64  \n",
      " 19  CitesPerYear    200 non-null    float64\n",
      " 20  CitesPerAuthor  200 non-null    int64  \n",
      " 21  AuthorCount     200 non-null    int64  \n",
      " 22  Age             200 non-null    int64  \n",
      " 23  Abstract        200 non-null    object \n",
      "dtypes: float64(8), int64(7), object(9)\n",
      "memory usage: 37.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('./data/PoPCites2.csv')\n",
    "#data = pd.read_csv('data/PoPCites2.csv',usecols = '')\n",
    "\n",
    "# RQ1: Which technologies have been investigated in the last decade?\n",
    "\n",
    "# RQ2: In which phase of the technology life cycle path are the technologies?\n",
    "# - Interest in topic: #Papers on a topic over time\n",
    "# - Parallel dazu: Interest in topic: Number of citations to papers on a topic over time\n",
    "#- Publikationstyp: Workshop -> Conference -> Journal \n",
    "\n",
    "# RQ3: How stable is the community working on the topics (new authors emerging, authors staying on for the whole time,\n",
    "# or authors “leaving” the area)?\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funktionen\n",
    "def Count(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountCites(data,count):\n",
    "    cnt = Counter()\n",
    "    for item in data: \n",
    "        cnt[item] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountWords(data,count):\n",
    "    cnt = Counter()\n",
    "    #Pandas.Series durchlaufen um die Title zu bekommen\n",
    "    for index, value in data.items():\n",
    "        words = value.lower().split(' ')\n",
    "        #Title in Wörter teilen\n",
    "        for word in words:\n",
    "            #Aussortieren der Stopwords\n",
    "            if not word in stopwords:\n",
    "                #Für bestimmte Begriffe\n",
    "                #for word in wordlist:\n",
    "                cnt[word] += 1\n",
    "    return cnt.most_common(count)\n",
    "\n",
    "def CountToTfidf(counts):\n",
    "    transformer = TfidfTransformer(smooth_idf=False)\n",
    "    \n",
    "    #Gewichtet die CountMatrix\n",
    "    tfidf = transformer.fit_transform(counts)\n",
    "\n",
    "    #Gibt Array zurück\n",
    "    return tfidf.toarray()\n",
    "\n",
    "\n",
    "def ListToDataArray(l,year):\n",
    "    ld = pd.DataFrame.from_dict(l)\n",
    "    ld = ld.rename(columns={ 0:'word',1:year})\n",
    "    ld = ld.set_index('word')\n",
    "    #Gibt Pandas.DataFrame zurück\n",
    "    return ld\n",
    "\n",
    "\n",
    "def TfidfVector(data):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    print(X.toarray())\n",
    "    \n",
    "def CountVector(data):\n",
    "    vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    print(vectorizer.get_feature_names())\n",
    "    return X.toarray()\n",
    "    \n",
    "def TitleFilteredByYear(data,year):\n",
    "    databyyear = data['Title'].loc[data['Year'] == year]\n",
    "    return databyyear\n",
    "\n",
    "def CountWordsByYear(data,year):\n",
    "    #d = Pandas.Series\n",
    "    d = TitleFilteredByYear(data,year)\n",
    "    l = CountWords(d,30)\n",
    "    print(type(l))\n",
    "   # r = []\n",
    "    #for x in word,count:\n",
    "     #   if(type(x) != NoneType):\n",
    "      #      r.append(x)\n",
    "    #Gibt List zurück\n",
    "    return l\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variablen erstellen\n",
    "title = data['Title']\n",
    "publisher = data['Publisher']\n",
    "year = data['Year']\n",
    "\n",
    "wordlist = [\n",
    "    'DevOps',\n",
    "    'engineering',\n",
    "    'Software',\n",
    "    'Engineering',\n",
    "    'software'\n",
    "    \n",
    "]\n",
    "stopwords =[\n",
    "    'this',\n",
    "    'is ',\n",
    "    'none',\n",
    "    'in',\n",
    "    'of',\n",
    "    'A',\n",
    "    'a',\n",
    "    'and',\n",
    "    'for',\n",
    "    'with',\n",
    "    'on',\n",
    "    'the',\n",
    "    'to',\n",
    "    'an'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MergeDataFrames(data,anzahlJahre):\n",
    "    year = datetime.datetime.now()\n",
    "    year = year.year\n",
    "    da = pd.DataFrame()\n",
    "    for y in range(year - anzahlJahre, year):\n",
    "        l = CountWordsByYear(data,y)  \n",
    "        p = ListToDataArray(l,y)\n",
    "        if(da.empty):\n",
    "            da = p\n",
    "        else:\n",
    "            da = da.merge(p, on= 'word' ,how='inner')\n",
    "    return da        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('software', 65),\n",
       " ('engineering', 56),\n",
       " ('engineering:', 7),\n",
       " ('teaching', 6),\n",
       " ('analysis', 6),\n",
       " ('systematic', 6),\n",
       " ('research', 5),\n",
       " ('course', 5),\n",
       " ('from', 4),\n",
       " ('study', 4),\n",
       " ('data', 4),\n",
       " ('methods', 3),\n",
       " ('empirical', 3),\n",
       " ('challenges', 3),\n",
       " ('industry', 3),\n",
       " ('experience', 3),\n",
       " ('applying', 3),\n",
       " ('using', 3),\n",
       " ('education', 3),\n",
       " ('mapping', 3),\n",
       " ('agile', 3),\n",
       " ('perspective', 3),\n",
       " ('guidelines', 3),\n",
       " ('de', 3),\n",
       " ('based', 3),\n",
       " ('model-driven', 2),\n",
       " ('use', 2),\n",
       " ('crowdsourcing', 2),\n",
       " ('continuous', 2),\n",
       " ('directions', 2)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = CountWordsByYear(data,2017)\n",
    "\n",
    "l1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('software', 79),\n",
       " ('engineering', 61),\n",
       " ('research', 10),\n",
       " ('engineering:', 10),\n",
       " ('learning', 6),\n",
       " ('using', 6),\n",
       " ('systematic', 5),\n",
       " ('study', 5),\n",
       " ('search-based', 5),\n",
       " ('from', 5),\n",
       " ('data', 5),\n",
       " ('continuous', 5),\n",
       " ('empirical', 4),\n",
       " ('based', 4),\n",
       " ('mapping', 4),\n",
       " ('knowledge', 4),\n",
       " ('project', 4),\n",
       " ('tools', 3),\n",
       " ('education', 3),\n",
       " ('measuring', 3),\n",
       " ('experience', 3),\n",
       " ('approaches', 3),\n",
       " ('towards', 3),\n",
       " ('model', 3),\n",
       " ('practice', 3),\n",
       " ('students', 3),\n",
       " ('what', 3),\n",
       " ('role', 3),\n",
       " ('value', 3),\n",
       " ('systems', 3)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = CountWordsByYear(data,2018)\n",
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('software', 48),\n",
       " ('engineering', 38),\n",
       " ('study', 11),\n",
       " ('systematic', 9),\n",
       " ('mapping', 7),\n",
       " ('engineering:', 5),\n",
       " ('literature', 4),\n",
       " ('design', 4),\n",
       " ('case', 3),\n",
       " ('analysis', 3),\n",
       " ('systems', 3),\n",
       " ('studies', 3),\n",
       " ('education', 3),\n",
       " ('practices', 3),\n",
       " ('empirical', 3),\n",
       " ('from', 3),\n",
       " ('end-user', 3),\n",
       " ('machine', 2),\n",
       " ('industrial', 2),\n",
       " ('sethesaurus:', 2),\n",
       " ('wordnet', 2),\n",
       " ('progression', 2),\n",
       " ('model', 2),\n",
       " ('goals,', 2),\n",
       " ('challenges,', 2),\n",
       " ('start-ups', 2),\n",
       " ('reviews', 2),\n",
       " ('cerse-catalog', 2),\n",
       " ('research', 2),\n",
       " ('safety', 2)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l3 = CountWordsByYear(data,2019)\n",
    "l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>79</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engineering</th>\n",
       "      <td>61</td>\n",
       "      <td>38</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>systematic</th>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             2018  2019  2020\n",
       "word                         \n",
       "software       79    48    17\n",
       "engineering    61    38    15\n",
       "research       10     2     2\n",
       "systematic      5     9     3"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MergeDataFrames(data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process whole documents\n",
    "#doc = nlp(text)\n",
    "\n",
    "# Analyze syntax\n",
    "#print(\"Noun phrases:\", [chunk.text for chunk in doc.noun_chunks])\n",
    "#print(\"Verbs:\", [token.lemma_ for token in doc if token.pos_ == \"VERB\"])\n",
    "\n",
    "# Find named entities, phrases and concepts\n",
    "#for entity in doc.ents:\n",
    "##print(entity.text, entity.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Dokumentenähnlichkeit x Graphanalyse\n",
    "\n",
    "#Wachstum darstellen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018 = TitleFilteredByYear(data,2018)\n",
    "#data['Cites'].plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfVector(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data2018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
