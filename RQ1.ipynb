{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1: Which technologies have been investigated in the last decade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.symbols import NOUN\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen\n",
    "In diesem Block werden die Daten in eine Pandas DataFrame geladen. Anschließend werden die Spalten zur besseren Übersichtlichkeit umbenannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is an Athletic Approach the Future of Software...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Traditional software engineering education app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What Do We Know about Knowledge Management? Pr...</td>\n",
       "      <td>2009</td>\n",
       "      <td>There have been many claims about knowledge ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Global Software Engineering: An Industry Persp...</td>\n",
       "      <td>2016</td>\n",
       "      <td>Professional software products and IT systems ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advancing Software Engineering Professional Ed...</td>\n",
       "      <td>2011</td>\n",
       "      <td>The paper mentions that a reference curriculum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Improving the State of Automotive Software Eng...</td>\n",
       "      <td>2017</td>\n",
       "      <td>The automotive industry is fundamentally chang...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  year  \\\n",
       "index                                                            \n",
       "0      Is an Athletic Approach the Future of Software...  2016   \n",
       "1      What Do We Know about Knowledge Management? Pr...  2009   \n",
       "2      Global Software Engineering: An Industry Persp...  2016   \n",
       "3      Advancing Software Engineering Professional Ed...  2011   \n",
       "4      Improving the State of Automotive Software Eng...  2017   \n",
       "\n",
       "                                                abstract  \n",
       "index                                                     \n",
       "0      Traditional software engineering education app...  \n",
       "1      There have been many claims about knowledge ma...  \n",
       "2      Professional software products and IT systems ...  \n",
       "3      The paper mentions that a reference curriculum...  \n",
       "4      The automotive industry is fundamentally chang...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datene einlesen\n",
    "data = pd.read_csv('./data/data.csv',usecols = ['Unnamed: 0','Document Title','Abstract','Publication Year'])\n",
    "data.columns = ['index','title','year','abstract']\n",
    "data.index = data['index']\n",
    "\n",
    "data.drop([\"index\"], axis = 1, inplace = True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion für die TermDokumentenMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTermDocMatrix(column):\n",
    "        \n",
    "    count_vectorizer = CountVectorizer(stop_words='english',ngram_range = (1,2),dtype=np.int32)\n",
    "    sparse_matrix = count_vectorizer.fit_transform(data[column].values.astype('U'))\n",
    "\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names(), dtype=np.int32)\n",
    "    df['year'] = data['year']\n",
    "    returndf = df.groupby('year').sum().transpose().astype('int32')\n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowWord(data,word):\n",
    "    d = data.loc[word]\n",
    "    d.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpaltenEntf(data):\n",
    "    y = []\n",
    "    for item in data.columns:\n",
    "        y = data.columns\n",
    "\n",
    "\n",
    "    for index in range(len(y)):\n",
    "        x = y[index]\n",
    "        if x in stopwords or x.isnumeric():\n",
    "            del data[y[index]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen der TermDokumentenmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retokenize(text):\n",
    "    # Verarbeite den Text\n",
    "    if type(text) is str:\n",
    "        doc = nlp(text)\n",
    "\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    sp  = [doc[match[1]:match[2]] for match in matches] \n",
    "\n",
    "    filtered = filter_spans(sp)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for s in filtered:\n",
    "            retokenizer.merge(s, attrs = {\"POS\": \"NOUN\"})\n",
    "    [(token.pos_, token.text) for token in doc]\n",
    "        \n",
    "    #Returns spacy doc\n",
    "    return doc\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "years = []\n",
    "\n",
    "#Balkendiagramm\n",
    "#plt.bar(range(len(years)),anzah)\n",
    "\n",
    "#Titel\n",
    "#plt.title(\"Toller Plot\")\n",
    "#plt.ylabel(\"# of awards\")\n",
    "\n",
    "#plt.xticks(range(len(years)),years)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Model laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter und Matcher initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "words = Counter()\n",
    "words_chunk = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern festlegen und dem Matcher hinzufügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_test = [{'POS': 'NOUN'},\n",
    "                {'POS': 'NOUN'}]\n",
    "\n",
    "pattern_exmaple = [{'POS': 'ADJ', 'OP': '?'},\n",
    "                   {'OP': '+', 'POS': 'NOUN'},\n",
    "                   {'POS': 'NOUN', 'OP': '?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"match_test\", [pattern_test])\n",
    "matcher.add(\"match_example\", [pattern_exmaple])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in data.itertuples():\n",
    "    text = columns[3] #1 = title 2 = year 3 = abstract\n",
    "    # Verarbeite den Text\n",
    "    if type(text) is str:\n",
    "            doc = nlp(text)\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    sp  = [doc[match[1]:match[2]] for match in matches]\n",
    "    filtered = filter_spans(sp)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for s in filtered:\n",
    "            retokenizer.merge(s, attrs = {\"POS\": \"NOUN\"})\n",
    "    [(token.pos_, token.text) for token in doc]\n",
    "\n",
    "    for token in doc:\n",
    "        # Greife auf den Text, die Wortart und die Dependenzrelation des Tokens zu\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        token_dep = token.dep_\n",
    "        token_ent = token.ent_type_\n",
    "\n",
    "        if token.pos == NOUN:\n",
    "            if not token.is_stop:\n",
    "                words[token_text] += 1\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wörter darstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paper', 712),\n",
       " ('approach', 634),\n",
       " ('developers', 580),\n",
       " ('results', 458),\n",
       " ('software', 365),\n",
       " ('code', 317),\n",
       " ('article', 314),\n",
       " ('percent', 279),\n",
       " ('system', 267),\n",
       " ('model', 266),\n",
       " ('time', 259),\n",
       " ('%', 256),\n",
       " ('techniques', 241),\n",
       " ('data', 235),\n",
       " ('systems', 234),\n",
       " ('state', 208),\n",
       " ('set', 207),\n",
       " ('software engineering', 198),\n",
       " ('number', 193),\n",
       " ('performance', 192),\n",
       " ('study', 188),\n",
       " ('analysis', 185),\n",
       " ('tools', 185),\n",
       " ('work', 181),\n",
       " ('problem', 177),\n",
       " ('effectiveness', 171),\n",
       " ('framework', 171),\n",
       " ('models', 171),\n",
       " ('development', 169),\n",
       " ('terms', 169),\n",
       " ('method', 167),\n",
       " ('researchers', 163),\n",
       " ('approaches', 162),\n",
       " ('projects', 161),\n",
       " ('users', 160),\n",
       " ('use', 158),\n",
       " ('quality', 153),\n",
       " ('process', 152),\n",
       " ('practitioners', 151),\n",
       " ('application', 149),\n",
       " ('applications', 148),\n",
       " ('technique', 148),\n",
       " ('tool', 147),\n",
       " ('context', 144),\n",
       " ('research', 143),\n",
       " ('challenges', 138),\n",
       " ('requirements', 138),\n",
       " ('methods', 132),\n",
       " ('order', 130),\n",
       " ('issue', 129),\n",
       " ('programs', 128),\n",
       " ('testing', 127),\n",
       " ('knowledge', 126),\n",
       " ('findings', 126),\n",
       " ('information', 125),\n",
       " ('changes', 124),\n",
       " ('design', 123),\n",
       " ('practice', 119),\n",
       " ('experiments', 118),\n",
       " ('software development', 118),\n",
       " ('bugs', 118),\n",
       " ('source code', 117),\n",
       " ('impact', 116),\n",
       " ('project', 115),\n",
       " ('test cases', 113),\n",
       " ('evaluation', 109),\n",
       " ('apps', 108),\n",
       " ('cost', 106),\n",
       " ('program', 106),\n",
       " ('software systems', 105),\n",
       " ('test', 105),\n",
       " ('Web', 102),\n",
       " ('architecture', 100),\n",
       " ('problems', 97),\n",
       " ('features', 96),\n",
       " ('faults', 92),\n",
       " ('benefits', 90),\n",
       " ('need', 90),\n",
       " ('end', 87),\n",
       " ('years', 87),\n",
       " ('example', 87),\n",
       " ('service', 87),\n",
       " ('complexity', 86),\n",
       " ('addition', 85),\n",
       " ('practices', 84),\n",
       " ('way', 84),\n",
       " ('defects', 84),\n",
       " ('column', 83),\n",
       " ('literature', 83),\n",
       " ('algorithms', 83),\n",
       " ('implementation', 83),\n",
       " ('case study', 83),\n",
       " ('level', 83),\n",
       " ('companies', 81),\n",
       " ('authors', 80),\n",
       " ('metrics', 80),\n",
       " ('components', 79),\n",
       " ('algorithm', 79),\n",
       " ('patterns', 79),\n",
       " ('tests', 79)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(words.most_common(20))\n",
    "wordlist = []\n",
    "for x in l:\n",
    "    wordlist.append(x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(wordlist,dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = CreateTermDocMatrix('abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = abstract[abstract.index.isin(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [words, data]\n",
       "Index: []"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "a = pd.DataFrame(b[2020])\n",
    "a\n",
    "#alt.Chart(b[2020]).mark_bar().encode(\n",
    "#    x='index',\n",
    "#    y=''\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.97389904 0.97221548 0.97023292 0.96346638 0.96519768\n",
      "  0.94210367 0.97379072 0.92684277 0.94478534 0.91039197 0.85843915\n",
      "  0.84997698]\n",
      " [0.97389904 1.         0.97676008 0.97738856 0.97988756 0.9758839\n",
      "  0.94435718 0.96494792 0.93025759 0.93098487 0.93398509 0.89794393\n",
      "  0.8777266 ]\n",
      " [0.97221548 0.97676008 1.         0.97435146 0.97061242 0.97862669\n",
      "  0.94651967 0.95604291 0.93873491 0.92426527 0.92370842 0.88846634\n",
      "  0.8843884 ]\n",
      " [0.97023292 0.97738856 0.97435146 1.         0.98803874 0.98384753\n",
      "  0.97727071 0.97752894 0.96392018 0.9598203  0.95932958 0.9311224\n",
      "  0.90985011]\n",
      " [0.96346638 0.97988756 0.97061242 0.98803874 1.         0.98387122\n",
      "  0.96903109 0.98397662 0.9637556  0.94902511 0.95555378 0.9239563\n",
      "  0.89980402]\n",
      " [0.96519768 0.9758839  0.97862669 0.98384753 0.98387122 1.\n",
      "  0.9838939  0.97854185 0.98178064 0.95816456 0.96705906 0.9444172\n",
      "  0.92765589]\n",
      " [0.94210367 0.94435718 0.94651967 0.97727071 0.96903109 0.9838939\n",
      "  1.         0.9758572  0.98464707 0.97597487 0.97986137 0.96224132\n",
      "  0.94247283]\n",
      " [0.97379072 0.96494792 0.95604291 0.97752894 0.98397662 0.97854185\n",
      "  0.9758572  1.         0.96910722 0.97593816 0.95396859 0.91354887\n",
      "  0.89552166]\n",
      " [0.92684277 0.93025759 0.93873491 0.96392018 0.9637556  0.98178064\n",
      "  0.98464707 0.96910722 1.         0.96536362 0.97600332 0.96406349\n",
      "  0.95065073]\n",
      " [0.94478534 0.93098487 0.92426527 0.9598203  0.94902511 0.95816456\n",
      "  0.97597487 0.97593816 0.96536362 1.         0.94992094 0.91508069\n",
      "  0.90169862]\n",
      " [0.91039197 0.93398509 0.92370842 0.95932958 0.95555378 0.96705906\n",
      "  0.97986137 0.95396859 0.97600332 0.94992094 1.         0.98735917\n",
      "  0.97970354]\n",
      " [0.85843915 0.89794393 0.88846634 0.9311224  0.9239563  0.9444172\n",
      "  0.96224132 0.91354887 0.96406349 0.91508069 0.98735917 1.\n",
      "  0.98514761]\n",
      " [0.84997698 0.8777266  0.8843884  0.90985011 0.89980402 0.92765589\n",
      "  0.94247283 0.89552166 0.95065073 0.90169862 0.97970354 0.98514761\n",
      "  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(cosine_similarity(b.transpose()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
