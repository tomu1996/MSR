{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RQ1: Which technologies have been investigated in the last decade?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module importieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spacy.symbols import NOUN\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.util import filter_spans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten einlesen\n",
    "In diesem Block werden die Daten in eine Pandas DataFrame geladen. Anschließend werden die Spalten zur besseren Übersichtlichkeit umbenannt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datene einlesen\n",
    "data = pd.read_csv('./data/data.csv',usecols = ['Unnamed: 0','Document Title','Abstract','Publication Year'])\n",
    "data.columns = ['index','title','year','abstract']\n",
    "data.index = data['index']\n",
    "\n",
    "data.drop([\"index\"], axis = 1, inplace = True)\n",
    "\n",
    "data.head()\n",
    "\n",
    "data.groupby('year').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktion für die TermDokumentenMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTermDocMatrix(column):\n",
    "        \n",
    "    count_vectorizer = CountVectorizer(stop_words='english',ngram_range = (1,2),dtype=np.int32)\n",
    "    sparse_matrix = count_vectorizer.fit_transform(data[column].values.astype('U'))\n",
    "\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names(), dtype=np.int32)\n",
    "    df['year'] = data['year']\n",
    "    returndf = df.groupby('year').sum().transpose().astype('int32')\n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowWord(data,word):\n",
    "    d = data.loc[word]\n",
    "    d.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpaltenEntf(data):\n",
    "    y = []\n",
    "    for item in data.columns:\n",
    "        y = data.columns\n",
    "\n",
    "\n",
    "    for index in range(len(y)):\n",
    "        x = y[index]\n",
    "        if x in stopwords or x.isnumeric():\n",
    "            del data[y[index]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen der TermDokumentenmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Retokenize(text):\n",
    "    # Verarbeite den Text\n",
    "    if type(text) is str:\n",
    "        doc = nlp(text)\n",
    "\n",
    "\n",
    "    matches = matcher(doc)\n",
    "    sp  = [doc[match[1]:match[2]] for match in matches] \n",
    "\n",
    "    filtered = filter_spans(sp)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for s in filtered:\n",
    "            retokenizer.merge(s, attrs = {\"POS\": \"NOUN\"})\n",
    "    [(token.pos_, token.text) for token in doc]\n",
    "        \n",
    "    #Returns spacy doc\n",
    "    return doc\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "years = []\n",
    "\n",
    "#Balkendiagramm\n",
    "#plt.bar(range(len(years)),anzah)\n",
    "\n",
    "#Titel\n",
    "#plt.title(\"Toller Plot\")\n",
    "#plt.ylabel(\"# of awards\")\n",
    "\n",
    "#plt.xticks(range(len(years)),years)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Model laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counter und Matcher initialisieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "words = Counter()\n",
    "words_chunk = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern festlegen und dem Matcher hinzufügen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_test = [{'POS': 'NOUN'},\n",
    "                {'POS': 'NOUN'}]\n",
    "\n",
    "pattern_exmaple = [{'POS': 'ADJ', 'OP': '?'},\n",
    "                   {'OP': '+', 'POS': 'NOUN'},\n",
    "                   {'POS': 'NOUN', 'OP': '?'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher.add(\"match_test\", [pattern_test])\n",
    "matcher.add(\"match_example\", [pattern_exmaple])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columns in data.itertuples():\n",
    "    text = columns[3] #1 = title 2 = year 3 = abstract\n",
    "    # Verarbeite den Text\n",
    "    if type(text) is str:\n",
    "            doc = nlp(text)\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    sp  = [doc[match[1]:match[2]] for match in matches]\n",
    "    filtered = filter_spans(sp)\n",
    "    with doc.retokenize() as retokenizer:\n",
    "        for s in filtered:\n",
    "            retokenizer.merge(s, attrs = {\"POS\": \"NOUN\"})\n",
    "    [(token.pos_, token.text) for token in doc]\n",
    "\n",
    "    for token in doc:\n",
    "        # Greife auf den Text, die Wortart und die Dependenzrelation des Tokens zu\n",
    "        token_text = token.text\n",
    "        token_pos = token.pos_\n",
    "        token_dep = token.dep_\n",
    "        token_ent = token.ent_type_\n",
    "\n",
    "        if token.pos == NOUN:\n",
    "            if not token.is_stop:\n",
    "                words[token_text] += 1\n",
    "                                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wörter darstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liste erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(words.most_common(30))\n",
    "wordlist = []\n",
    "for x in l:\n",
    "    wordlist.append(x[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.Series(wordlist,dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = CreateTermDocMatrix('abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = abstract[abstract.index.isin(words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balkendiagramm erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "\n",
    "source = pd.DataFrame({'Technologies': b.index,\n",
    "                       'Anzahl': b[2020]})\n",
    "\n",
    "\n",
    "\n",
    "alt.Chart(source).mark_bar().encode(\n",
    "    x='Technologies',\n",
    "    y='Anzahl'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarity(b.transpose()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
