{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RQ1: Which technologies have been investigated in the last decade?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document Title</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What Do We Know about Knowledge Management? Pr...</td>\n",
       "      <td>2009</td>\n",
       "      <td>There have been many claims about knowledge ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Research on National and International Softwar...</td>\n",
       "      <td>2009</td>\n",
       "      <td>The article analyzed the basic life cycle mode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advancing Software Engineering Professional Ed...</td>\n",
       "      <td>2011</td>\n",
       "      <td>The paper mentions that a reference curriculum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Putting Human Aspects of Software Engineering ...</td>\n",
       "      <td>2010</td>\n",
       "      <td>Although people-related issues are central fac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where's the Theory for Software Engineering?</td>\n",
       "      <td>2012</td>\n",
       "      <td>Darwin's theory of natural selection, Maxwell'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Document Title  Publication Year  \\\n",
       "0  What Do We Know about Knowledge Management? Pr...              2009   \n",
       "1  Research on National and International Softwar...              2009   \n",
       "2  Advancing Software Engineering Professional Ed...              2011   \n",
       "3  Putting Human Aspects of Software Engineering ...              2010   \n",
       "4       Where's the Theory for Software Engineering?              2012   \n",
       "\n",
       "                                            Abstract  \n",
       "0  There have been many claims about knowledge ma...  \n",
       "1  The article analyzed the basic life cycle mode...  \n",
       "2  The paper mentions that a reference curriculum...  \n",
       "3  Although people-related issues are central fac...  \n",
       "4  Darwin's theory of natural selection, Maxwell'...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Datene einlesen\n",
    "#data = pd.read_csv('./data/data.csv')\n",
    "#data.drop([\"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "\n",
    "data = pd.read_csv('./data/export1.csv',dtype={'Abstract': str}, usecols = ['Document Title','Abstract','Publication Year'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Document Title', 'Publication Year', 'Abstract'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document Title      1946\n",
       "Publication Year    1946\n",
       "Abstract            1933\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTermDocMatrix(column):\n",
    "        \n",
    "    count_vectorizer = CountVectorizer(stop_words='english',ngram_range = (1,2),dtype=np.int32)\n",
    "    sparse_matrix = count_vectorizer.fit_transform(data[column].values.astype('U'))\n",
    "\n",
    "    doc_term_matrix = sparse_matrix.todense()\n",
    "    df = pd.DataFrame(doc_term_matrix, columns=count_vectorizer.get_feature_names(), dtype=np.int32)\n",
    "    df['PublishingYear'] = data['Publication Year']\n",
    "    returndf = df.groupby('PublishingYear').sum().transpose().astype('int32')\n",
    "    return returndf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ShowWord(data,word):\n",
    "    d = data.loc[word]\n",
    "    d.plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpaltenEntf(data):\n",
    "    y = []\n",
    "    for item in data.columns:\n",
    "        y = data.columns\n",
    "\n",
    "\n",
    "    for index in range(len(y)):\n",
    "        x = y[index]\n",
    "        if x in stopwords or x.isnumeric():\n",
    "            del data[y[index]]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Untersuchung Abstract\n",
    "#abstract = CreateTermDocMatrix('Abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b = abstract.loc[abstract[2011] > 20] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#b.plot.bar()\n",
    "#print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#cnt = Counter()\n",
    "\n",
    "#for abstract in data['Abstract']:\n",
    "#    if type(abstract) is str:\n",
    "#        wordlist = abstract.split(' ')\n",
    "#        for word in wordlist:\n",
    "#            cnt[word] += 1\n",
    "        \n",
    "#cnt.most_common(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for abstract in data.itertuples():\n",
    "#    print(abstract[1])\n",
    "#    print(abstract[2])\n",
    "#    print(abstract[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data.csv',usecols = ['Document Title','Abstract','Publication Year'], nrows =1000)\n",
    "data.columns = ['title','abstract','year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Untersuchung Title\n",
    "#title = CreateTermDocMatrix('title')\n",
    "\n",
    "#print(title)\n",
    "#title = SpaltenEntf(title)\n",
    "#print(title)\n",
    "\n",
    "#b = title.loc[title[2017] > 5] \n",
    "\n",
    "#b.plot.bar()\n",
    "#print(b)\n",
    "#b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy\n",
    "#from spacy.symbols import NOUN\n",
    "#from collections import Counter\n",
    "\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#cnt = Counter()\n",
    "#tokenlist = []\n",
    "#i = 1\n",
    "\n",
    "#for columns in data.itertuples():\n",
    "\n",
    "#    text = columns[1] #1 = title 2 = year 3 = abstract\n",
    "    #print(type(abstract))\n",
    "    # Verarbeite den Text\n",
    "#    if type(text) is str:\n",
    "#        doc = nlp(text)\n",
    "\n",
    "#        for noun_phrase in list(doc.noun_chunks):\n",
    "#             noun_phrase.merge(noun_phrase.root.tag_, noun_phrase.root.lemma_, noun_phrase.root.ent_type_)\n",
    "\n",
    "#        [(token.text,token.pos_) for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "years = []\n",
    "\n",
    "#Balkendiagramm\n",
    "#plt.bar(range(len(years)),anzah)\n",
    "\n",
    "#Titel\n",
    "#plt.title(\"Toller Plot\")\n",
    "#plt.ylabel(\"# of awards\")\n",
    "\n",
    "#plt.xticks(range(len(years)),years)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = [{'POS': 'ADJ', 'OP': '?'},\n",
    " #          {'OP': '+', 'POS': 'NOUN'},\n",
    "  #         {'POS': 'NOUN', 'OP': '?'}]\n",
    "\n",
    "#doc = nlp(\"I work on artificial intelligence topics.\")\n",
    "\n",
    "#matcher.add(\"match_nouns\", [pattern])\n",
    "#matches = matcher(doc)\n",
    "#sp  = [doc[match[1]:match[2]] for match in matches] \n",
    "\n",
    "#filtered = filter_spans(sp)\n",
    "#with doc.retokenize() as retokenizer:\n",
    "#    for s in filtered:\n",
    "#        retokenizer.merge(s, attrs = {\"POS\": \"NOUN\"})\n",
    "#[(token.pos_, token.text) for token in doc]\n",
    "\n",
    "#doc[3].vector == (nlp.vocab[\"artificial\"].vector + \n",
    "#                  nlp.vocab[\"intelligence\"].vector + \n",
    "#                  nlp.vocab[\"topics\"].vector)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.symbols import NOUN\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "words = Counter()\n",
    "words_chunk = Counter()\n",
    "tokenlist = []\n",
    "chunklist = []\n",
    "i = 1\n",
    "\n",
    "for columns in data.itertuples():\n",
    "\n",
    "    text = columns[3] #1 = title 2 = year 3 = abstract\n",
    "    #print(type(abstract))\n",
    "    # Verarbeite den Text\n",
    "    if type(text) is str:\n",
    "        doc = nlp(text)\n",
    "        #list(dosc.noun_chunks)\n",
    "        #print(i)\n",
    "        i+= 1\n",
    "        \n",
    "\n",
    "        \n",
    "        for token in doc:\n",
    "            # Greife auf den Text, die Wortart und die Dependenzrelation des Tokens zu\n",
    "            token_text = token.text\n",
    "            token_pos = token.pos_\n",
    "            token_dep = token.dep_\n",
    "            token_ent = token.ent_type_\n",
    "            \n",
    "            if token.pos == NOUN:\n",
    "                if not token.is_stop:\n",
    "                    #print(f\"{token_text}: {token_ent}\")\n",
    "                    #print(token.tag_)\n",
    "                    words[token_text] += 1\n",
    "                    #tokenlist.append([token_text,columns[2],token_ent])\n",
    "                    \n",
    "        for chunk in doc.noun_chunks:\n",
    "            words_chunk[chunk.text] += 1\n",
    "\n",
    "\n",
    "#tokenlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paper', 741),\n",
       " ('model', 635),\n",
       " ('system', 618),\n",
       " ('method', 600),\n",
       " ('software', 554),\n",
       " ('algorithm', 478),\n",
       " ('data', 381),\n",
       " ('results', 369),\n",
       " ('time', 281),\n",
       " ('process', 263),\n",
       " ('network', 260),\n",
       " ('information', 258),\n",
       " ('analysis', 237),\n",
       " ('problem', 234),\n",
       " ('development', 232),\n",
       " ('performance', 203),\n",
       " ('approach', 197),\n",
       " ('design', 184),\n",
       " ('engineering', 179),\n",
       " ('methods', 179),\n",
       " ('systems', 175),\n",
       " ('application', 171),\n",
       " ('quality', 170),\n",
       " ('image', 152),\n",
       " ('simulation', 147),\n",
       " ('technology', 145),\n",
       " ('control', 143),\n",
       " ('order', 143),\n",
       " ('research', 138),\n",
       " ('service', 130),\n",
       " ('knowledge', 128),\n",
       " ('test', 128),\n",
       " ('structure', 127),\n",
       " ('study', 123),\n",
       " ('management', 118),\n",
       " ('optimization', 110),\n",
       " ('testing', 107),\n",
       " ('experiment', 107),\n",
       " ('models', 105),\n",
       " ('function', 105),\n",
       " ('Web', 101),\n",
       " ('theory', 99),\n",
       " ('teaching', 99),\n",
       " ('evaluation', 99),\n",
       " ('state', 98),\n",
       " ('problems', 96),\n",
       " ('parameters', 96),\n",
       " ('framework', 95),\n",
       " ('set', 94),\n",
       " ('number', 92),\n",
       " ('detection', 91),\n",
       " ('level', 90),\n",
       " ('learning', 89),\n",
       " ('environment', 89),\n",
       " ('platform', 89),\n",
       " ('applications', 85),\n",
       " ('distribution', 85),\n",
       " ('project', 84),\n",
       " ('-', 83),\n",
       " ('way', 82),\n",
       " ('students', 82),\n",
       " ('case', 80),\n",
       " ('result', 80),\n",
       " ('factors', 79),\n",
       " ('computer', 79),\n",
       " ('field', 78),\n",
       " ('article', 78),\n",
       " ('feature', 78),\n",
       " ('program', 77),\n",
       " ('efficiency', 77),\n",
       " ('architecture', 76),\n",
       " ('code', 76),\n",
       " ('search', 76),\n",
       " ('value', 76),\n",
       " ('strategy', 76),\n",
       " ('resources', 76),\n",
       " ('features', 76),\n",
       " ('technique', 75),\n",
       " ('networks', 75),\n",
       " ('decision', 74),\n",
       " ('requirements', 74),\n",
       " ('accuracy', 73),\n",
       " ('example', 72),\n",
       " ('prediction', 72),\n",
       " ('space', 72),\n",
       " ('experiments', 71),\n",
       " ('rate', 71),\n",
       " ('algorithms', 68),\n",
       " ('effect', 68),\n",
       " ('mining', 68),\n",
       " ('characteristics', 67),\n",
       " ('component', 67),\n",
       " ('techniques', 66),\n",
       " ('support', 66),\n",
       " ('cost', 64),\n",
       " ('services', 64),\n",
       " ('flow', 64),\n",
       " ('users', 63),\n",
       " ('implementation', 63),\n",
       " ('education', 62)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 430),\n",
       " ('this paper', 379),\n",
       " ('it', 319),\n",
       " ('This paper', 219),\n",
       " ('We', 211),\n",
       " ('It', 179),\n",
       " ('order', 116),\n",
       " ('they', 80),\n",
       " ('the system', 60),\n",
       " ('them', 57),\n",
       " ('-', 55),\n",
       " ('the paper', 55),\n",
       " ('the model', 54),\n",
       " ('algorithm', 54),\n",
       " ('The results', 53),\n",
       " ('the method', 47),\n",
       " ('The paper', 43),\n",
       " ('data', 43),\n",
       " ('the performance', 41),\n",
       " ('This article', 40),\n",
       " ('students', 39),\n",
       " ('the process', 39),\n",
       " ('the problem', 39),\n",
       " ('this method', 37),\n",
       " ('software engineering', 36),\n",
       " ('users', 34),\n",
       " ('the effectiveness', 34),\n",
       " ('the algorithm', 33),\n",
       " ('Experimental results', 33),\n",
       " ('the application', 32),\n",
       " ('the results', 31),\n",
       " ('developers', 31),\n",
       " ('the efficiency', 31),\n",
       " ('software', 30),\n",
       " ('terms', 29),\n",
       " ('this problem', 29),\n",
       " ('analysis', 29),\n",
       " ('China', 28),\n",
       " ('the basis', 28),\n",
       " ('the quality', 28),\n",
       " ('a set', 26),\n",
       " ('The experimental results', 26),\n",
       " ('the design', 26),\n",
       " ('what', 25),\n",
       " ('the same time', 25),\n",
       " ('development', 24),\n",
       " ('practice', 24),\n",
       " ('time', 24),\n",
       " ('the analysis', 24),\n",
       " ('information', 23),\n",
       " ('The method', 23),\n",
       " ('the number', 23),\n",
       " ('our approach', 22),\n",
       " ('resources', 22),\n",
       " ('the proposed method', 22),\n",
       " ('the publisher', 22),\n",
       " ('us', 21),\n",
       " ('software development', 21),\n",
       " ('models', 21),\n",
       " ('the development', 21),\n",
       " ('The result', 21),\n",
       " ('method', 20),\n",
       " ('application', 20),\n",
       " ('this model', 20),\n",
       " ('addition', 20),\n",
       " ('this article', 20),\n",
       " ('knowledge', 19),\n",
       " ('research', 19),\n",
       " ('the data', 19),\n",
       " ('This method', 19),\n",
       " ('design', 19),\n",
       " ('an example', 19),\n",
       " ('the field', 18),\n",
       " ('methods', 18),\n",
       " ('detail', 18),\n",
       " ('the relationship', 18),\n",
       " ('this approach', 18),\n",
       " ('the characteristics', 18),\n",
       " ('Experiments', 18),\n",
       " ('this algorithm', 18),\n",
       " ('the approach', 17),\n",
       " ('simulation', 17),\n",
       " ('experiments', 17),\n",
       " ('accuracy', 17),\n",
       " ('the use', 17),\n",
       " ('the feasibility', 17),\n",
       " ('a method', 17),\n",
       " ('prediction', 17),\n",
       " ('management', 16),\n",
       " ('systems', 16),\n",
       " ('an approach', 16),\n",
       " ('performance', 16),\n",
       " ('The system', 16),\n",
       " ('parameters', 16),\n",
       " ('use', 16),\n",
       " ('the research', 15),\n",
       " ('requirements', 15),\n",
       " ('model', 15),\n",
       " ('this study', 15),\n",
       " ('education', 15)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_chunk.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
