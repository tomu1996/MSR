,index,Document Title,Authors,Author Affiliations,Publication Title,Date Added To Xplore,Publication Year,Volume,Issue,Start Page,End Page,Abstract,ISSN,ISBNs,DOI,Funding Information,PDF Link,Author Keywords,IEEE Terms,INSPEC Controlled Terms,INSPEC Non-Controlled Terms,Mesh_Terms,Article Citation Count,Patent Citation Count,Reference Count,License,Online Date,Issue Date,Meeting Date,Publisher,Document Identifier
0,0,Is an Athletic Approach the Future of Software Engineering Education?,E. Hill; P. M. Johnson; D. Port,Drew University; University of Hawaii at Manoa; University of Hawaii at Manoa,IEEE Software,29 Dec 2015,2016,33,1,97,100,"Traditional software engineering education approaches--in-class lectures, unsupervised homework assignments, and occasional projects--create many opportunities for distraction. To address this problem, the authors have employed an approach that treats software engineering education more like athletic training.",1937-4194,,10.1109/MS.2016.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367991,software engineering education;athletic software engineering;education;software development;unit testing;software engineering,Software engineering;Programming profession;Training;Computer science education;Software development,computer science education;educational institutions;software engineering;training,software engineering education;in-class lectures;unsupervised homework assignments;occasional projects;athletic training,,5.0,,1.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1,1,What Do We Know about Knowledge Management? Practical Implications for Software Engineering,T. Dingsøyr; F. O. Bjørnson; F. Shull,SINTEF Information and Communication Technology; SINTEF Fisheries and Aquaculture; Fraunhofer Center for Experimental Software Engineering,IEEE Software,17 Apr 2009,2009,26,3,100,103,"There have been many claims about knowledge management's benefits in software engineering, such as decreased time and cost for development, increased quality, and better decision-making abilities. Although we can find some success stories illustrating these claims, particularly on aspects related to the systems and engineering schools, more research is necessary to explore the intersection between each school and the software engineering field. Researchers should continue to emphasize the need for a broad focus across multiple KM schools to suceed in improving KM's practical application in software engineering.",1937-4194,,10.1109/MS.2009.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814968,software engineering;knowledge management;learning software organization;software process improvement;systematic review,Knowledge management;Software engineering;Educational institutions;Systems engineering and theory;Knowledge engineering;Guidelines;Software development management;Programming;Social network services;Space technology,knowledge management;software engineering,knowledge management;software engineering;decision making;software development,,28.0,,7.0,,17 Apr 2009,,,IEEE,IEEE Magazines
2,2,Global Software Engineering: An Industry Perspective,C. Ebert; M. Kuhrmann; R. Prikladnicki,Vector Consulting Services; University of Southern Denmark; Pontifícia Universidade Católica do Rio Grande do Sul (PUCRS),IEEE Software,29 Dec 2015,2016,33,1,105,108,"Professional software products and IT systems and services today are developed mostly by globally distributed teams, projects, and companies. This issue's column summarizes experiences and guidance from industry to facilitate knowledge and technology transfer. It's based on industry feedback from the annual IEEE International Conference on Global Software Engineering.",1937-4194,,10.1109/MS.2016.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367984,global software engineering;agile software development;agile;outsourcing;IEEE International Conference on Global Software Engineering;ICGSE;software engineering;software development,Software engineering;Industries;Globalization;Outsourcing;Software development,software engineering;software houses;technology transfer,global software engineering;industry perspective;professional software products;IT systems;IT services;globally distributed teams;technology transfer,,11.0,,7.0,,29 Dec 2015,,,IEEE,IEEE Magazines
3,3,Advancing Software Engineering Professional Education,M. Ardis; P. Bourque; T. Hilburn; K. Lasfer; S. Lucero; J. McDonald; A. Pyster; M. Shaw,Stevens Institute of Technology; École de Technologie Supérieure; Embry-Riddle Aeronautical University; Stevens Institute of Technology; US Department of Defense; Monmouth University; Stevens Institute of Technology; Carnegie Mellon University,IEEE Software,23 Jun 2011,2011,28,4,58,63,"The paper mentions that a reference curriculum for master's programs helps ensure software engineers possess the appropriate skills, knowledge, and experience to develop, maintain, and acquire complex systems.",1937-4194,,10.1109/MS.2010.133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5590235,software engineering;computer and information science education;graduate programs;curriculum architecture;core body of knowledge;SWEBOK,Software engineering;Computer science education;Engineering education;Engineering profession;Career development,computer science education;software engineering,software engineering professional education;masters program;software engineering skill;software engineering knowledge;software engineering experience;complex systems development;complex systems maintenance;complex systems acquisition,,11.0,,15.0,,30 Sep 2010,,,IEEE,IEEE Magazines
4,4,Improving the State of Automotive Software Engineering,A. Haghighatkhah; M. Oivo; A. Banijamali; P. Kuvaja,University of Oulu; University of Oulu; University of Oulu; University of Oulu,IEEE Software,26 Sep 2017,2017,34,5,82,86,"The automotive industry is fundamentally changing by becoming software intensive, rather than mechanically intensive. To stay ahead of the game, automakers must continuously improve their software engineering. For this article, the authors studied the existing literature on the subject and made practitioner-oriented recommendations.",1937-4194,,10.1109/MS.2017.3571571,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8050198,automotive software engineering;ASE;AUTOSAR;standards;testing;search-based testing;requirements engineering;model-based development;agile development;system integration;continuous integration;regression testing;software reliability growth models;SRGM;variability;software engineering;software development,Software;Automotive engineering;Industries;Testing;Tools;Software engineering;Biological system modeling,production engineering computing;software engineering,automotive software engineering;automotive industry;practitioner-oriented recommendations,,4.0,,18.0,,26 Sep 2017,,,IEEE,IEEE Magazines
5,5,Putting Human Aspects of Software Engineering in University Curricula,O. Hazzan,Technion–Israel Institute of Technology,IEEE Software,14 Jun 2010,2010,27,4,90,91,"Although people-related issues are central factors in determining the success of software projects, they do not receive sufficient attention in the software industry to improve project results. This essay describes two barriers to their getting more attention: barriers that originate in the academic status and positioning of software engineering. The essay also proposes several suggestions regarding the professional development of software practitioners.",1937-4194,,10.1109/MS.2010.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484115,human aspects of software engineering;software engineering education;computer science education;software projects;software industry;professional development of software engineers,Humans;Software engineering;Computer industry,computer science education;DP industry;software engineering,software engineering;university curricula;software projects;software industry,,3.0,,7.0,,14 Jun 2010,,,IEEE,IEEE Magazines
6,6,Where's the Theory for Software Engineering?,P. Johnson; M. Ekstedt; I. Jacobson,KTH Royal Institute of Technology; KTH Royal Institute of Technology; Peking University,IEEE Software,21 Aug 2012,2012,29,5,96,96,"Darwin's theory of natural selection, Maxwell's equations, the theory of demand and supply; almost all established academic disciplines place great emphasis on what their core theory is. This is not, however, the case in software engineering. What is the reason behind the software engineering community's apparent indifference to a concept that is so important to so many others?",1937-4194,,10.1109/MS.2012.127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6276302,software engineering theory;theory;explanation;prediction;science;engineering,Software engineering;Predictive models,software engineering,software engineering theory;software engineering community,,17.0,,,,21 Aug 2012,,,IEEE,IEEE Magazines
7,7,Software Engineering for Spreadsheets,M. Erwig,Oregon State University,IEEE Software,25 Aug 2009,2009,26,5,25,30,The idiosyncratic structure of spreadsheets allows the adaptation of proven software engineering principles to an end-user domain and thus makes software engineering accessible to many users.,1937-4194,,10.1109/MS.2009.140,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222790,spreadsheets;software engineering;type checking;debugging;spatial analysis,Software engineering;Labeling;Embedded software;Software tools;Embedded computing;Application software;Runtime,software engineering;spreadsheet programs,software engineering;spreadsheets;idiosyncratic structure;end-user domain,,20.0,,15.0,,25 Aug 2009,,,IEEE,IEEE Magazines
8,8,Regress or Progress? Seeing Good Software Engineering Ideas Through,H. Erdogmus,Kalemun Research,IEEE Software,25 Feb 2010,2010,27,2,4,7,"In the last edition of From the Editor (""Deja Vu: The Life of Software Engineering Ideas,"" January/February 2010), I wrote about how modern software engineering ideas evolve. I represented an idea's maturation life cycle from conception to streaming in terms of nine states, interactions with the life cycle of other related ideas, and regressive loops that preempt an idea's normal progression and revert it to a previous state. In this edition, I discuss the levers that help prevent reversion, or at least premature reversion, and push a worthwhile idea forward toward the streamed state. These levers work only for good ideas, or those that have genuine merit, and before the idea reaches the streamed state. Once an idea reaches that point, we don't have much control; short attention spans are inevitably diverted elsewhere.",1937-4194,,10.1109/MS.2010.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420787,software engineering innovation;diffusion of software innovations;adoptability of software innovations,Software engineering,software engineering,software engineering;maturation software life cycle,,,,,,25 Feb 2010,,,IEEE,IEEE Magazines
9,9,Collaboration Tools for Global Software Engineering,F. Lanubile; C. Ebert; R. Prikladnicki; A. Vizcaíno,University of Bari; Vector Consulting Services; Pontifícia Universidade do Rio Grande do Sul; University of Castilla-La Mancha,IEEE Software,25 Feb 2010,2010,27,2,52,55,"Software engineering involves people collaborating to develop better software. Collaboration is challenging, especially across time zones and without face-to-face meetings. We therefore use collaboration tools all along the product life cycle to let us work together, stay together, and achieve results together. This article summarizes experiences and trends chosen from recent IEEE International Conference on Global Software Engineering (IGSCE) conferences.",1937-4194,,10.1109/MS.2010.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420797,software engineering;collaboration;global software development,Collaborative tools;Collaborative software;International collaboration;Software engineering;Collaborative work;Meetings,groupware;product life cycle management;software engineering,collaboration tools;global software engineering;product life cycle;IEEE international conference,,101.0,3.0,10.0,,25 Feb 2010,,,IEEE,IEEE Magazines
10,10,A Whisper of Evidence in Global Software Engineering,D. Èmite; C. Wohlin,NA; NA,IEEE Software,23 Jun 2011,2011,28,4,15,18,"A systematic review of global software engineering (GSE) literature from 2000 to 2007 shows the field to be immature. Studies report many challenges but little evidence regarding specific GSE practices directly related to project success or failure. There is evidence that distance matters and, furthermore, that GSE--although driven by cost-reduction goals--seldom brings immediate cost savings.",1937-4194,,10.1109/MS.2011.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929523,software engineering;systematic literature review,Software engineering;Globalization;Cost benefit analysis;Research initiatives,cost reduction;software engineering,global software engineering;GSE practices;cost-reduction goals;cost savings,,23.0,,10.0,,23 Jun 2011,,,IEEE,IEEE Magazines
11,11,Maturing Software Engineering Knowledge through Classifications: A Case Study on Unit Testing Techniques,S. Vegas; N. Juristo; V. R. Basili,"Universidad Politecnica de Madrid, Madrid; Universidad Politecnica de Madrid, Madrid; University of Maryland, College Park and Fraunhofer Center for Experimental Software Engineering, Maryland",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,551,565,"Classification makes a significant contribution to advancing knowledge in both science and engineering. It is a way of investigating the relationships between the objects to be classified and identifies gaps in knowledge. Classification in engineering also has a practical application; it supports object selection. They can help mature software engineering knowledge, as classifications constitute an organized structure of knowledge items. Till date, there have been few attempts at classifying in software engineering. In this research, we examine how useful classifications in software engineering are for advancing knowledge by trying to classify testing techniques. The paper presents a preliminary classification of a set of unit testing techniques. To obtain this classification, we enacted a generic process for developing useful software engineering classifications. The proposed classification has been proven useful for maturing knowledge about testing techniques, and therefore, SE, as it helps to: 1) provide a systematic description of the techniques, 2) understand testing techniques by studying the relationships among techniques (measured in terms of differences and similarities), 3) identify potentially useful techniques that do not yet exist by analyzing gaps in the classification, and 4) support practitioners in testing technique selection by matching technique characteristics to project characteristics.",1939-3520,,10.1109/TSE.2009.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4775907,Classification;software engineering;software testing;test design techniques;testing techniques;unit testing techniques.,Software engineering;Software testing;Diseases;Knowledge engineering;System testing;Chemical elements;Application software;Software design;Chemistry;Civil engineering,program testing;software engineering,software engineering knowledge;unit testing techniques;engineering classification;matching technique characteristic;project characteristic;software testing,,29.0,,31.0,,6 Feb 2009,,,IEEE,IEEE Journals
12,12,Toward Evidence-Based Software Engineering: Lessons Learned in Healthcare Application Development,A. Nowak; H. J. Schünemann,Evidence Prime; McMaster University,IEEE Software,22 Sep 2017,2017,34,5,67,71,"The authors look back at their journey of implementing, rolling out, and evolving a collaboration tool to support evidence-based healthcare and reflect on how software engineers could benefit from similar methods.",1937-4194,,10.1109/MS.2017.3571572,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048641,architectural decisions;evidence;guidelines;healthcare;web application development;GRADEpro Guideline Development Tool;GRADEpro GDT;software development;software engineering,Medical services;Software engineering;Decision making;Guidelines;Stakeholders;Collaboration,health care;software engineering,software engineering;healthcare application development,,,,15.0,,22 Sep 2017,,,IEEE,IEEE Magazines
13,13,Investigating Country Differences in Mobile App User Behavior and Challenges for Software Engineering,S. L. Lim; P. J. Bentley; N. Kanakam; F. Ishikawa; S. Honiden,"Department of Computer Science, University College, London; Department of Computer Science, University College London; Department of Clinical, Education and Health Psychology, University College, London; Digital Content and Media Sciences Research Division, National Institute of Informatics, Japan; National Institute of Informatics, Japan",IEEE Transactions on Software Engineering,7 Jan 2015,2015,41,1,40,64,"Mobile applications (apps) are software developed for use on mobile devices and made available through app stores. App stores are highly competitive markets where developers need to cater to a large number of users spanning multiple countries. This work hypothesizes that there exist country differences in mobile app user behavior and conducts one of the largest surveys to date of app users across the world, in order to identify the precise nature of those differences. The survey investigated user adoption of the app store concept, app needs, and rationale for selecting or abandoning an app. We collected data from more than 15 countries, including USA, China, Japan, Germany, France, Brazil, United Kingdom, Italy, Russia, India, Canada, Spain, Australia, Mexico, and South Korea. Analysis of data provided by 4,824 participants showed significant differences in app user behaviors across countries, for example users from USA are more likely to download medical apps, users from the United Kingdom and Canada are more likely to be influenced by price, users from Japan and Australia are less likely to rate apps. Analysis of the results revealed new challenges to market-driven software engineering related to packaging requirements, feature space, quality expectations, app store dependency, price sensitivity, and ecosystem effect.",1939-3520,,10.1109/TSE.2014.2360674,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913003,Requirements/specifications;market-driven software engineering;mobile application development;user requirements;survey research;app user behavior;software product lines;software ecosystems;Requirements/specifications;market-driven software engineering;mobile application development;user requirements;survey research;app user behavior;software product lines;software ecosystems,Mobile communication;Software;Smart phones;Software engineering;Data mining;Educational institutions,consumer behaviour;mobile computing;smart phones;software engineering,market-driven software engineering;medical applications;data analysis;South Korea;South;Mexico;Australia;Spain;Canada;India;Russia;Italy;United Kingdom;Brazil;France;Germany;Japan;China;USA;applications stores;mobile devices;user behavior;mobile application,,79.0,,65.0,,29 Sep 2014,,,IEEE,IEEE Journals
14,14,Master's Degrees in Software Engineering: An Analysis of 28 University Programs,A. Pyster; R. Turner; D. Henry; K. Lasfer; L. Bernstein,Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology,IEEE Software,25 Aug 2009,2009,26,5,94,101,"The software engineering institute published the last reference curriculum for a master's in software engineering in 1991. In 2007, a coalition from academia, industry, and government began creating a new reference curriculum. An early step was to establish a baseline of graduate education by surveying 28 master's programs in software engineering. The survey was largely limited to US schools. Key findings showed that the universities viewed software engineering largely as a specialization of computer science, that faculty size is generally small with few dedicated professors, and that new master's programs continue to start despite the decrease in computer science majors over the past few years. We used the IEEE Computer Society's Software Engineering Body of Knowledge (SWEBOK) to structure our analysis of the 28 curricula, focusing primarily on courses and topics required or semirequired of all students. (A course is semirequired if there is at least a 50 percent chance a student must take it.) Major findings show wide variation in the depth and breadth of SWEBOK coverage in required and semirequired courses, less than 40 percent of all programs requiring an introductory course on software engineering, and many universities having required and semirequired courses that are peripheral to SWEBOK.",1937-4194,,10.1109/MS.2009.133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222804,software engineering;curriculum;Software Engineering Body of Knowledge;SWEBOK;computer science education,Software engineering;Taxonomy;Computer science;Aerospace engineering;Automotive engineering;Systems engineering and theory;Educational institutions;Educational programs;Radio access networks;Collaboration,computer science education;educational courses;software engineering,master degree;software engineering;university program;graduate education;computer science specialization;educational course,,11.0,,8.0,,25 Aug 2009,,,IEEE,IEEE Magazines
15,15,Cost Savings in Global Software Engineering: Where's the Evidence?,D. Smite; F. Calefato; C. Wohlin,Blekinge Institute of Technology; University of Bari; Blekinge Institute of Technology,IEEE Software,30 Jun 2015,2015,32,4,26,32,Researchers examined published studies of global software engineering to determine whether offshoring actually yielded cost savings. Not enough evidence existed to reach the verdict that offshoring reduced costs.,1937-4194,,10.1109/MS.2015.102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140692,global software engineering;software engineering;offshoring;outsourcing;evidence profile,Software engineering;Outsourcing;Globalization;Economics;Employment,outsourcing;software cost estimation,global software engineering;software offshoring;cost saving;cost reduction,,9.0,,19.0,,30 Jun 2015,,,IEEE,IEEE Magazines
16,16,Group Awareness in Global Software Engineering,F. Lanubile; F. Calefato; C. Ebert,University of Bari; University of Bari; Vector Consulting Services,IEEE Software,25 Feb 2013,2013,30,2,18,23,"Insufficient team collaboration often challenges global software engineering projects. Group awareness can improve teams' trust, relationships, and efficiency. This article surveys the key technologies and tools that support group awareness and collaboration. The insights on technologies derive from discussions and presentations at related conferences, including the IEEE-sponsored International Conference on Global Software Engineering (ICGSE).",1937-4194,,10.1109/MS.2013.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6470588,global software;group awareness;software engineering;collaboration;teams,Software engineering;Globalization;Visualization;Licenses;Collaboration;Ports (Computers);Software development,project management;software management;team working,group awareness;global software engineering projects;insufficient team collaboration;group collaboration;IEEE-sponsored International Conference on Global Software Engineering;ICGSE,,14.0,,5.0,,25 Feb 2013,,,IEEE,IEEE Magazines
17,17,To Game or Not to Game?,C. G. von Wangenheim; F. Shull,"Universidade do Vale do Itajaí; Fraunhofer Center for Experimental Software Engineering, Maryland",IEEE Software,24 Feb 2009,2009,26,2,92,94,"One challenge in software engineering education is to give students sufficient hands-on experience in actually building software. This is necessary so that students can understand which practices and techniques are useful in various situations. Some researchers have advocated alternative teaching methods to help in this regard. If successful, such methods could give students some experience with different approaches' effects in a shorter, more constrained time period. We examine one such approach, game-based learning, here.",1937-4194,,10.1109/MS.2009.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786960,Software engineering education;game-based learning;software management;software simulation,Project management;Computational modeling;Computer simulation;Engineering education;Software engineering;Computer science education;Software libraries;Databases;Search methods;World Wide Web,computer aided instruction;computer games;software engineering;teaching,software engineering education;hands-on experience;alternative teaching methods;game-based learning,,52.0,,7.0,,24 Feb 2009,,,IEEE,IEEE Magazines
18,18,The Role of Ethnographic Studies in Empirical Software Engineering,H. Sharp; Y. Dittrich; C. R. B. de Souza,"Open University, Walton Hall, Milton Keynes, UK; Software and Systems Section, IT University of Copenhagen, Rued Langgaards Vej 7, Copenhagen S, Denmark; Vale Institute of Technology and the Federal University of Pará, Tv. Boaventura da Silva, 955, Belém, PA, Brazil",IEEE Transactions on Software Engineering,11 Aug 2016,2016,42,8,786,804,"Ethnography is a qualitative research method used to study people and cultures. It is largely adopted in disciplines outside software engineering, including different areas of computer science. Ethnography can provide an in-depth understanding of the socio-technological realities surrounding everyday software development practice, i.e., it can help to uncover not only what practitioners do, but also why they do it. Despite its potential, ethnography has not been widely adopted by empirical software engineering researchers, and receives little attention in the related literature. The main goal of this paper is to explain how empirical software engineering researchers would benefit from adopting ethnography. This is achieved by explicating four roles that ethnography can play in furthering the goals of empirical software engineering: to strengthen investigations into the social and human aspects of software engineering; to inform the design of software engineering tools; to improve method and process development; and to inform research programmes. This article introduces ethnography, explains its origin, context, strengths and weaknesses, and presents a set of dimensions that position ethnography as a useful and usable approach to empirical software engineering research. Throughout the paper, relevant examples of ethnographic studies of software practice are used to illustrate the points being made.",1939-3520,,10.1109/TSE.2016.2519887,CNPq; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7387744,Design tools and techniques;human factors in software design;software engineering process;computer-supported collaborative work,Software engineering;Software;Context;Sociology;Electronic mail;Computer science;Guidelines,cultural aspects;human factors;software process improvement,sociotechnological realities;software development practice;ethnography;empirical software engineering;human aspects;social aspects;software process development;software engineering tools,,30.0,,135.0,,20 Jan 2016,,,IEEE,IEEE Journals
19,19,Is the New Software Engineering Curriculum Agile?,A. Fox; D. Patterson,"University of California, Berkeley; University of California, Berkeley",IEEE Software,3 Sep 2013,2013,30,5,88,88,"As the last standardization effort was done in 2004, the software engineering curriculum is currently being revised. Haven't we reached the point where agile development should be part of all software engineering curricula? And if so, shouldn't new curriculum standards ensure that it is? Thus, the answer to the question in the title of this article can be affirmative even if the computer science standards committee is absent-minded. Instructors can follow the initial call of the standard for projects by student teams while using an agile process, which is the most natural match. As long as you review both plan-and-document and agile processes in lecture, students can become familiar with both sets of terms and concepts. The more demanding outcomes can be met by the project as well, provided you look to the deeper meaning behind the plan-and-document terms to see where agile can fit.",1937-4194,,10.1109/MS.2013.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6588520,agile;curriculum;ACM-IEEE Computer Society;software engineering,Computer science education;Software engineering;Education courses;Software systems,computer science education;educational courses;software prototyping,software engineering curriculum;standardization;agile development;curriculum standards;computer science standards committee;student teams;agile process;plan-and-document process,,1.0,,11.0,,3 Sep 2013,,,IEEE,IEEE Magazines
20,20,Practices and Technologies in Computer Game Software Engineering,W. Scacchi,"University of California, Irvine",IEEE Software,16 Jan 2017,2017,34,1,110,116,"Computer games are rich, complex, and often large-scale software applications. They're a significant, interesting, and often compelling domain for innovative research in software engineering techniques and technologies. Computer games are progressively changing the everyday world in many positive ways. Game developers, whether focusing on entertainment market opportunities or game-based applications in nonentertainment domains such as education, healthcare, defense, or scientific research (that is, serious games), thus share a common interest in how best to engineer game software. This article examines techniques and technologies that inform contemporary computer game software engineering.",1937-4194,,10.1109/MS.2017.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819395,computer games;software engineering;software development;software engineering education;game development;game platforms;game engines;software architecture;gameplay;playtesting;software reuse;requirements engineering;runtime services;scalability,Games;Software development;Software engineering;Engines;Computer architecture;Runtime;Requirements engineering,computer games;software engineering,large-scale software applications;entertainment market opportunities;game-based applications;nonentertainment domains;computer game SE;serious games;computer game software engineering,,5.0,,7.0,,16 Jan 2017,,,IEEE,IEEE Magazines
21,21,Crossover Designs in Software Engineering Experiments: Benefits and Perils,S. Vegas; C. Apa; N. Juristo,"Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Madrid, Spain; Instituto de Computación, Facultad de Ingeniería, Montevideo, Uruguay; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Madrid, Spain",IEEE Transactions on Software Engineering,11 Feb 2016,2016,42,2,120,135,"In experiments with crossover design subjects apply more than one treatment. Crossover designs are widespread in software engineering experimentation: they require fewer subjects and control the variability among subjects. However, some researchers disapprove of crossover designs. The main criticisms are: the carryover threat and its troublesome analysis. Carryover is the persistence of the effect of one treatment when another treatment is applied later. It may invalidate the results of an experiment. Additionally, crossover designs are often not properly designed and/or analysed, limiting the validity of the results. In this paper, we aim to make SE researchers aware of the perils of crossover experiments and provide risk avoidance good practices. We study how another discipline (medicine) runs crossover experiments. We review the SE literature and discuss which good practices tend not to be adhered to, giving advice on how they should be applied in SE experiments. We illustrate the concepts discussed analysing a crossover experiment that we have run. We conclude that crossover experiments can yield valid results, provided they are properly designed and analysed, and that, if correctly addressed, carryover is no worse than other validity threats.",1939-3520,,10.1109/TSE.2015.2467378,Spanish Ministry of Economy and Competitiveness research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192651,Data analysis;crossover designs;carryover;Experimental software engineering;controlled experiment;data analysis;crossover design;carryover,Software engineering;Animals;Atmospheric measurements;Particle measurements;Psychology;US Government agencies;Information processing,software engineering,crossover design;software engineering experiments;SE research;crossover experiment,,29.0,,38.0,,12 Aug 2015,,,IEEE,IEEE Journals
22,22,Preparing Tomorrow's Software Engineers for Work in a Global Environment,S. Beecham; T. Clear; J. Barr; M. Daniels; M. Oudshoorn; J. Noll,Lero; Auckland University of Technology; Ithaca College; Uppsala University; Northwest Missouri State University; University of East London,IEEE Software,16 Jan 2017,2017,34,1,9,12,Global software engineering (GSE) is becoming common. It's thus important to educate university software engineering students in GSE. The authors discuss challenges to and recommendations for implementing such instruction.,1937-4194,,10.1109/MS.2017.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819397,global software engineering;GSE;distributed projects;global distance;Valentine's taxonomy;software engineering;software development,Education courses;Software engineering;Teamwork;Cultural differences;Computer science education;Professional development;Globalization,computer science education;educational institutions;software engineering,global software engineering;university software engineering students;GSE,,17.0,,5.0,,16 Jan 2017,,,IEEE,IEEE Magazines
23,23,GALE: Geometric Active Learning for Search-Based Software Engineering,J. Krall; T. Menzies; M. Davies,"LoadIQ, NV; Computer ScienceNorth Carolina State University; Intelligent Systems Division, NASA Ames Research Center, CA",IEEE Transactions on Software Engineering,13 Oct 2015,2015,41,10,1001,1018,"Multi-objective evolutionary algorithms (MOEAs) help software engineers find novel solutions to complex problems. When automatic tools explore too many options, they are slow to use and hard to comprehend. GALE is a near-linear time MOEA that builds a piecewise approximation to the surface of best solutions along the Pareto frontier. For each piece, GALE mutates solutions towards the better end. In numerous case studies, GALE finds comparable solutions to standard methods (NSGA-II, SPEA2) using far fewer evaluations (e.g. 20 evaluations, not 1,000). GALE is recommended when a model is expensive to evaluate, or when some audience needs to browse and understand how an MOEA has made its conclusions.",1939-3520,,10.1109/TSE.2015.2432024,US National Science Foundation (NSF); Qatar/West Virginia University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105950,Multi-objective optimization;search based software engineering;active learning;Multi-objective optimization;search based software engineering;active learning,Optimization;Software;Computational modeling;Approximation methods;Standards;Biological system modeling;Sociology,approximation theory;computational complexity;evolutionary computation;learning (artificial intelligence);Pareto optimisation;software engineering,GALE;geometric active learning;search-based software engineering;multiobjective evolutionary algorithm;near-linear time MOEA;piecewise approximation;Pareto frontier,,23.0,,64.0,,12 May 2015,,,IEEE,IEEE Journals
24,24,Supporting Reflective Practice in Software Engineering Education through a Studio-Based Approach,C. N. Bull; J. Whittle,Lancaster University; Lancaster University,IEEE Software,13 Jun 2014,2014,31,4,44,50,"Learning is a lifelong process, especially in the fast-paced software industry. In addition to formal training courses, good software developers continually learn by reflecting on what they've done in the past. However, reflective practice is rarely taught explicitly in university software engineering education. One way to teach reflective techniques from the start is through studio-based learning.",1937-4194,,10.1109/MS.2014.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774769,software studio;studio;atelier;software engineering education;collaboration;collocation;reflective practice;software engineering;pervasive computing;project management,Learning;Software engineering;Computer science education;Reflection;Computer architecture,computer science education;DP industry;educational courses;educational institutions;further education;software engineering,university software engineering education;studio-based learning;software industry;reflective practice,,20.0,,10.0,,18 Mar 2014,,,IEEE,IEEE Magazines
25,25,Model-Based Software Engineering to Tame the IoT Jungle,B. Morin; N. Harrand; F. Fleurey,SINTEF Information and Communication Technology; SINTEF Information and Communication Technology; SINTEF Information and Communication Technology,IEEE Software,16 Jan 2017,2017,34,1,30,36,"The Internet of Things (IoT) is a challenging combination of distribution and heterogeneity. A number of software engineering solutions address those challenges in isolation, but few solutions tackle them in combination, which poses a set of concrete challenges. The ThingML (Internet of Things Modeling Language) approach attempts to address those challenges. This model-driven, generative approach, which was inspired by UML, integrates concepts targeted at the IoT. Over the past six years, it has been continuously evolved and applied to cases in different domains, including a commercial e-health solution.",1937-4194,,10.1109/MS.2017.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819419,model-driven software engineering;Internet of Things;IoT;e-health;eHealth;ThingML;Tellu;software engineering;software development,Internet of things;Software engineering;Modeling;Computer languages,Internet of Things;software engineering;Unified Modeling Language,model-based software engineering;IoT;ThingML;UML;model-driven generative approach;e-health solution;Internet of Things Modeling Language,,28.0,,11.0,,16 Jan 2017,,,IEEE,IEEE Magazines
26,26,Technologies to Support Collaboration across Time Zones,R. Prikladnicki; S. Marczak; E. Carmel; C. Ebert,Pontifícia Universidade do Rio Grande do Sul; Pontifícia Universidade Católica do Rio Grande do Sul; American University; Vector Consulting Services,IEEE Software,20 Apr 2012,2012,29,3,10,13,"Time zone differences are a challenge to global software engineering. This column surveys the key technologies and tools that support collaboration across time zones. The insights on technologies derive from a meta- analysis of the 2010 and 2011 IEEE International Conference on Global Software Engineering (ICGSE), among others.",1937-4194,,10.1109/MS.2012.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188595,software;technology;global;time zones;distributed software development;global software engineering;international conference on global software engineering;icgse,Collaboration;Synchronization;Software;Software engineering;Programming;Conferences;Educational institutions,software engineering,time zone differences;software engineering;meta analysis,,7.0,,4.0,,20 Apr 2012,,,IEEE,IEEE Magazines
27,27,Variability in Software Systems—A Systematic Literature Review,M. Galster; D. Weyns; D. Tofan; B. Michalik; P. Avgeriou,"Department of Computer Science and Software Engineering, University of Canterbury, Private Bag 4800, Christchurch, New Zealand; Department of Computer Science, Linnaeus University, Växjö, Sweden; Department of Mathematics and Computing Science, University of Groningen, Groningen 9700 AK, The Netherlands; Amartus, Poland; Department of Mathematics and Computing Science, University of Groningen, Groningen 9700 AK, The Netherlands",IEEE Transactions on Software Engineering,31 Mar 2014,2014,40,3,282,306,"Context: Variability (i.e., the ability of software systems or artifacts to be adjusted for different contexts) became a key property of many systems. Objective: We analyze existing research on variability in software systems. We investigate variability handling in major software engineering phases (e.g., requirements engineering, architecting). Method: We performed a systematic literature review. A manual search covered 13 premium software engineering journals and 18 premium conferences, resulting in 15,430 papers searched and 196 papers considered for analysis. To improve reliability and to increase reproducibility, we complemented the manual search with a targeted automated search. Results: Software quality attributes have not received much attention in the context of variability. Variability is studied in all software engineering phases, but testing is underrepresented. Data to motivate the applicability of current approaches are often insufficient; research designs are vaguely described. Conclusions: Based on our findings we propose dimensions of variability in software engineering. This empirically grounded classification provides a step towards a unifying, integrated perspective of variability in software systems, spanning across disparate or loosely coupled research themes in the software engineering community. Finally, we provide recommendations to bridge the gap between research and practice and point to opportunities for future research.",1939-3520,,10.1109/TSE.2013.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682901,Variability;systematic review;software engineering,Decision support systems;Software systems;Systematics;Software engineering;Context;Manuals;Data collection,program testing;software product lines;software reliability;software reviews,software systems;variability handling;systematic literature review;manual search;software engineering journals;software reliability;reproducibility;targeted automated search;software engineering phase;software testing;software engineering community,,99.0,,60.0,,12 Dec 2013,,,IEEE,IEEE Journals
28,28,Software Components beyond Programming: From Routines to Services,I. Crnkovic; J. Stafford; C. Szyperski,Mälardalen University; Tufts University; Microsoft,IEEE Software,25 Apr 2011,2011,28,3,22,26,"Software engineering (SE) conference in 1968, Doug Mc Ilroy introduced the concept of software components during his keynote speech, ""Mass-Produced Software Components."" That components hold such an esteemed place in SE history should come as no surprise: componentization is a fundamental engineering principle. Top-down approaches decompose large systems into smaller parts-components and bottom-up approaches compose smaller parts components into larger systems. Since 1968, components have played a role in both SE research and practice. For example, components have been an immanent part of software architecture from its early days.2 In 1998, the In ternational Conference on Software Engineering introduced component based software engineering (CBSE) as a specific area within SE at the first workshop on CBSE.",1937-4194,,10.1109/MS.2011.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756294,software component;component-based software;engineering,Software architecture;Object oriented modeling;Unified modeling language;Software engineering,object-oriented programming;software engineering,software engineering;mass produced software components;SE;top-down approaches;bottom-up approaches;software architecture;component based software engineering;CBSE,,35.0,,2.0,,25 Apr 2011,,,IEEE,IEEE Magazines
29,29,Katie Malone on Machine Learning,E. Salinas,Microsoft Research,IEEE Software,11 Jul 2017,2017,34,4,92,96,Host Edaena Salinas talks with Civis Analytics' Katie Malone about the basics of machine learning and why we'll be seeing it much more frequently. The Web extra at http://www.se-radio.net/2017/03/se-radio-episode-286-katie-malone-intro-to-machine-learning/ is an audio recording of this episode of Software Engineering Radio.,1937-4194,,10.1109/MS.2017.96,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974684,Katie Malone;software engineering;machine learning;supervised machine learning;unsupervised machine learning;data analysis;SE Radio;Software Engineering Radio;software development,Motion pictures;Machine learning;Software engineering;Measurement;Artificial intelligence;Classification algorithms,learning (artificial intelligence);software engineering,machine learning;software engineering radio,,,,,,11 Jul 2017,,,IEEE,IEEE Magazines
30,30,Trends in the Quality of Human-Centric Software Engineering Experiments--A Quasi-Experiment,B. Kitchenham; D. I. K. Sjøberg; T. Dybå; O. P. Brereton; D. Budgen; M. Höst; P. Runeson,"Keele University, Keele; University of Oslo, Oslo; University of Oslo, Oslo and SINTEF, Trondheim; Keele University, Keele; Durham University, Durham; Lund University, Lund; Lund University, Lund",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,1002,1017,"Context: Several text books and papers published between 2000 and 2002 have attempted to introduce experimental design and statistical methods to software engineers undertaking empirical studies. Objective: This paper investigates whether there has been an increase in the quality of human-centric experimental and quasi-experimental journal papers over the time period 1993 to 2010. Method: Seventy experimental and quasi-experimental papers published in four general software engineering journals in the years 1992-2002 and 2006-2010 were each assessed for quality by three empirical software engineering researchers using two quality assessment methods (a questionnaire-based method and a subjective overall assessment). Regression analysis was used to assess the relationship between paper quality and the year of publication, publication date group (before 2003 and after 2005), source journal, average coauthor experience, citation of statistical text books and papers, and paper length. The results were validated both by removing papers for which the quality score appeared unreliable and using an alternative quality measure. Results: Paper quality was significantly associated with year, citing general statistical texts, and paper length (p <; 0.05). Paper length did not reach significance when quality was measured using an overall subjective assessment. Conclusions: The quality of experimental and quasi-experimental software engineering papers appears to have improved gradually since 1993.",1939-3520,,10.1109/TSE.2012.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374196,Quality evaluation;empirical studies;human-centric experiments;experimentation;software engineering,Software engineering;Guidelines;Correlation;Manuals;Educational institutions;Humans;Materials,citation analysis;design of experiments;publishing;regression analysis;software quality;text analysis,human-centric software engineering experiments;experimental design;statistical methods;human-centric experimental journal papers;quasi-experimental journal papers;quality assessment methods;questionnaire-based method;subjective overall assessment;regression analysis;paper quality;publication year;publication date group;source journal;average coauthor experience;statistical text books citation;statistical papers citation;paper length,,10.0,,28.0,,4 Dec 2012,,,IEEE,IEEE Journals
31,31,iTree: Efficiently Discovering High-Coverage Configurations Using Interaction Trees,C. Song; A. Porter; J. S. Foster,"Fraunhofer USA Center for Experimental Software Engineering, 5825 University Research Court, Suite 1300, College Park; Department of Computer Science, University of Maryland, A.V. Williams Building, College Park; Department of Computer Science, University of Maryland, A.V. Williams Building, College Park",IEEE Transactions on Software Engineering,31 Mar 2014,2014,40,3,251,265,"Modern software systems are increasingly configurable. While this has many benefits, it also makes some software engineering tasks,such as software testing, much harder. This is because, in theory,unique errors could be hiding in any configuration, and, therefore,every configuration may need to undergo expensive testing. As this is generally infeasible, developers need cost-effective technique for selecting which specific configurations they will test. One popular selection approach is combinatorial interaction testing (CIT), where the developer selects a strength t and then computes a covering array (a set of configurations) in which all t-way combinations of configuration option settings appear at least once. In prior work, we demonstrated several limitations of the CIT approach. In particular, we found that a given system's effective configuration space - the minimal set of configurations needed to achieve a specific goal - could comprise only a tiny subset of the system's full configuration space. We also found that effective configuration space may not be well approximated by t-way covering arrays. Based on these insights we have developed an algorithm called interaction tree discovery (iTree). iTree is an iterative learning algorithm that efficiently searches for a small set of configurations that closely approximates a system's effective configuration space. On each iteration iTree tests the system on a small sample of carefully chosen configurations, monitors the system's behaviors, and then applies machine learning techniques to discover which combinations of option settings are potentially responsible for any newly observed behaviors. This information is used in the next iteration to pick a new sample of configurations that are likely to reveal further new behaviors. In prior work, we presented an initial version of iTree and performed an initial evaluation with promising results. This paper presents an improved iTree algorithm in greater detail. The key improvements are based on our use of composite proto-interactions - a construct that improves iTree's ability to correctly learn key configuration option combinations, which in turn significantly improves iTree's running time, without sacrificing effectiveness. Finally, the paper presents a detailed evaluation of the improved iTree algorithm by comparing the coverage it achieves versus that of covering arrays and randomly generated configuration sets, including a significantly expanded scalability evaluation with the ~ 1M-LOC MySQL. Our results strongly suggest that the improved iTree algorithm is highly scalable and can identify a high-coverage test set of configurations more effectively than existing methods.",1939-3520,,10.1109/TSE.2013.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6671585,Empirical software engineering;software configurations;software testing and analysis,Testing;Arrays;Software algorithms;Software engineering;Machine learning algorithms;Software systems;Algorithm design and analysis,iterative methods;learning (artificial intelligence);program testing;software engineering,iTree;efficiently discovering high-coverage configurations;interaction trees;software systems;software engineering;software testing;cost-effective technique;combinatorial interaction testing;CIT;interaction tree discovery;iterative learning algorithm;machine learning techniques;iTree algorithm,,11.0,,39.0,,20 Nov 2013,,,IEEE,IEEE Journals
32,32,"Speed, Data, and Ecosystems: The Future of Software Engineering",J. Bosch,Chalmers University of Technology,IEEE Software,29 Dec 2015,2016,33,1,82,88,"An evaluation of recent industrial and societal trends revealed three key factors driving software engineering's future: speed, data, and ecosystems. These factors' implications have led to guidelines for companies to evolve their software engineering practices. This article is part of a special issue on the Future of Software Engineering.",1937-4194,,10.1109/MS.2016.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368022,software;software development;software engineering,Software engineering;Market research;Ecosystems;Business;Technological innovation,software engineering,software engineering,,49.0,,15.0,,29 Dec 2015,,,IEEE,IEEE Magazines
33,33,Reducing Friction in Software Development,P. Avgeriou; P. Kruchten; R. L. Nord; I. Ozkaya; C. Seaman,"University of Groningen; University of British Columbia; Software Engineering Institute; Software Engineering Institute; University of Maryland, Baltimore County",IEEE Software,29 Dec 2015,2016,33,1,66,73,"Software is being produced so fast that its growth hinders its sustainability. Technical debt, which encompasses internal software quality, evolution and maintenance, reengineering, and economics, is growing such that its management is becoming the dominant driver of software engineering progress. It spans the software engineering life cycle, and its management capitalizes on recent advances in fields such as source code analysis, quality measurement, and project management. Managing technical debt will become an investment activity applying economic theories. It will effectively address the architecture level and will offer specific processes and tools employing data science and analytics to support decision making. It will also be an essential part of the software engineering curriculum. Getting ahead of the software quality and innovation curve will inevitably involve establishing technical-debt management as a core software engineering practice. This article is part of a special issue on the Future of Software Engineering.",1937-4194,,10.1109/MS.2016.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367977,technical debt;software management;software economics;software quality;software engineering;software development;software architecture;maintenance and evolution;sustainability;education,Software development;Economics;Software engineering;Stakeholders;Sustainability;Maintenance engineering,data analysis;decision making;software maintenance;software quality,software reengineering;software maintenance;software evolution;innovation curve;decision making;data analysis;data science;economic theory;investment activity;software engineering life cycle;software engineering progress;internal software quality;software development,,20.0,,13.0,,29 Dec 2015,,,IEEE,IEEE Magazines
34,34,Key Abstractions for IoT-Oriented Software Engineering,F. Zambonelli,University of Modena and Reggio Emilia,IEEE Software,16 Jan 2017,2017,34,1,38,45,"Despite the progress in Internet of Things (IoT) research, a general software engineering approach for systematic development of IoT systems and applications is still missing. A synthesis of the state of the art in the area can help frame the key abstractions related to such development. Such a framework could be the basis for guidelines for IoT-oriented software engineering.",1937-4194,,10.1109/MS.2017.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819396,software engineering;Internet of Things;IoT;software development,Software engineering;Internet of things;Research and development;Software development,Internet of Things;software engineering,IoT-oriented software engineering;key abstractions;Internet of Things;IoT systems,,25.0,,15.0,,16 Jan 2017,,,IEEE,IEEE Magazines
35,35,The “Physics” of Notations: Toward a Scientific Basis for Constructing Visual Notations in Software Engineering,D. Moody,"University of Twente , Enschede",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,756,779,"Visual notations form an integral part of the language of software engineering (SE). Yet historically, SE researchers and notation designers have ignored or undervalued issues of visual representation. In evaluating and comparing notations, details of visual syntax are rarely discussed. In designing notations, the majority of effort is spent on semantics, with graphical conventions largely an afterthought. Typically, no design rationale, scientific or otherwise, is provided for visual representation choices. While SE has developed mature methods for evaluating and designing semantics, it lacks equivalent methods for visual syntax. This paper defines a set of principles for designing cognitively effective visual notations: ones that are optimized for human communication and problem solving. Together these form a design theory, called the Physics of Notations as it focuses on the physical (perceptual) properties of notations rather than their logical (semantic) properties. The principles were synthesized from theory and empirical evidence from a wide range of fields and rest on an explicit theory of how visual notations communicate. They can be used to evaluate, compare, and improve existing visual notations as well as to construct new ones. The paper identifies serious design flaws in some of the leading SE notations, together with practical suggestions for improving them. It also showcases some examples of visual notation design excellence from SE and other fields.",1939-3520,,10.1109/TSE.2009.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5353439,Modeling;analysis;diagrams;communication;visualization;visual syntax;concrete syntax.,Software engineering;Humans;Visualization;Design optimization;Problem-solving;Physics;Concrete;Flowcharts;Unified modeling language;Computer industry,software engineering,visual notations;software engineering;visual representation;physics of notations;design flaws,,596.0,1.0,152.0,,15 Dec 2009,,,IEEE,IEEE Journals
36,36,The Ethical Software Engineer,D. Hall,University of Manchester,IEEE Software,19 Jun 2009,2009,26,4,9,10,Compliance to a professional society's code of ethics carries obligations beyond minimum standards of behavior. Members of software engineering professional societies should also serve the public interest and promote the common good.,1937-4194,,10.1109/MS.2009.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076450,professional ethics;codes of ethics;codes of good practice;professional licensing;software engineering practice,Ethics;Software engineering;Software standards;Standards development;Programming;ISO;Knowledge engineering;Software development management;IEC standards;Career development,ethical aspects;software engineering,ethics;software engineering professional societies;ethical software engineer,,5.0,,4.0,,19 Jun 2009,,,IEEE,IEEE Magazines
37,37,Exploring the Relationship between Software Process Adaptive Capability and Organisational Performance,P. Clarke; R. V. O’Connor; B. Leavy; M. Yilmaz,"School of Computing, Dublin City University, Ireland, and Lero—The Irish Software Research Centre; School of Computing, Dublin City University, Ireland, and Lero—The Irish Software Research Centre; Dublin City University Business School, Ireland; Çanyaka University, Ankara, Turkey",IEEE Transactions on Software Engineering,8 Dec 2015,2015,41,12,1169,1183,"Software development is a complex socio-technical activity, with the result that software development organisations need to establish and maintain robust software development processes. While much debate exists regarding the effectiveness of various software development approaches, no single approach is perfectly suited to all settings and no setting is unchanging. The capability to adapt the software process is therefore essential to sustaining an optimal software process. We designed an exploratory study to concurrently examine software process adaptive capability and organisational performance in 15 software development organisations, finding that companies with greater software process adaptive capability are shown to also experience greater business success. While our exploratory study of the complex relationship between these phenomena is limited in some respects, the findings indicate that software process adaptive capability may be worthy of further integration into software process engineering techniques. Software process adaptive capability may be an important organisational strength when deriving competitive advantage, and those responsible for the creation and evolution of software process models and methodologies may want to focus some of their future efforts in this area.",1939-3520,,10.1109/TSE.2015.2467388,Science Foundation Ireland; Irish Software Engineering Research Centre; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214314,Software engineering;Software engineering process;Software development;Software management;Software engineering;software engineering process;software development;software management,Software engineering;Software development;ISO Standards;IEC Standards;Software management,software process improvement,software process adaptive capability;organisational performance;socio-technical activity;software development organisation;robust software development process;software development approach;optimal software process;software process engineering technique;organisational strength,,29.0,,97.0,,20 Aug 2015,,,IEEE,IEEE Journals
38,38,A Cooperative Parallel Search-Based Software Engineering Approach for Code-Smells Detection,W. Kessentini; M. Kessentini; H. Sahraoui; S. Bechikh; A. Ouni,"Department of Computer Science, University of Montreal, Montreal, Quebec, Canada; Department of Computer Science, University of Michigan, Dearborn, MI; Department of Computer Science, University of Montreal, Montreal, Quebec, Canada; Department of Computer Science, University of Michigan, Dearborn, MI; Department of Computer Science, University of Michigan, Dearborn, MI",IEEE Transactions on Software Engineering,4 Sep 2014,2014,40,9,841,861,"We propose in this paper to consider code-smells detection as a distributed optimization problem. The idea is that different methods are combined in parallel during the optimization process to find a consensus regarding the detection of code-smells. To this end, we used Parallel Evolutionary algorithms (P-EA) where many evolutionary algorithms with different adaptations (fitness functions, solution representations, and change operators) are executed, in a parallel cooperative manner, to solve a common goal which is the detection of code-smells. An empirical evaluation to compare the implementation of our cooperative P-EA approach with random search, two single population-based approaches and two code-smells detection techniques that are not based on meta-heuristics search. The statistical analysis of the obtained results provides evidence to support the claim that cooperative P-EA is more efficient and effective than state of the art detection approaches based on a benchmark of nine large open source systems where more than 85 percent of precision and recall scores are obtained on a variety of eight different types of code-smells.",1939-3520,,10.1109/TSE.2014.2331057,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835187,Search-based software engineering;code-smells;software quality;distributed evolutionary algorithms,Measurement;Sociology;Statistics;Evolutionary computation;Detectors;Optimization;Computational modeling,evolutionary computation;public domain software;search problems;software engineering;statistical analysis,cooperative parallel search-based software engineering approach;code-smells detection;distributed optimization problem;optimization process;parallel evolutionary algorithms;P-EA approach;random search;single population-based approaches;statistical analysis;open source systems,,51.0,,57.0,,16 Jun 2014,,,IEEE,IEEE Journals
39,39,Evaluating Legal Implementation Readiness Decision-Making,A. K. Massey; P. N. Otto; A. I. Antón,"Postdoctoral Fellow at the School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA; Association of Computing Machinery, District of Columbia, 555 13th St. NW, Washington; Professor and Chair of the School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA",IEEE Transactions on Software Engineering,10 Jun 2015,2015,41,6,545,564,"Software systems are increasingly regulated. Software engineers therefore must determine which requirements have met or exceeded their legal obligations and which requirements have not. Requirements that have met or exceeded their legal obligations are legally implementation ready, whereas requirements that have not met or exceeded their legal obligations need further refinement. In this paper, we examine how software engineers make these determinations using a multi-case study with three cases. Each case involves assessment of requirements for an electronic health record system that must comply with the US Health Insurance Portability and Accountability Act (HIPAA) and is measured against the evaluations of HIPAA compliance subject matter experts. Our first case examines how individual graduate-level software engineering students assess whether the requirements met or exceeded their HIPAA obligations. Our second case replicates the findings from our first case using a different set of participants. Our third case examines how graduate-level software engineering students assess requirements using the Wideband Delphi approach to deriving consensus in groups. Our findings suggest that the average graduate-level software engineering student is ill-prepared to write legally compliant software with any confidence and that domain experts are an absolute necessity.",1939-3520,,10.1109/TSE.2014.2383374,NSF ITR; NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991569,Legal Implementation Readiness;Regulatory Compliance Software Engineering;Legal Requirements;Requirements Engineering;Legal implementation readiness;regulatory compliance software engineering;legal requirements;requirements engineering,Law;Software;Software engineering;Atmospheric measurements;Particle measurements;Decision making,electronic health records;law;software engineering,legal implementation readiness decision-making;software systems;legal obligations;electronic health record system;US Health Insurance Portability and Accountability Act;HIPAA obligations;requirement assessment;wideband Delphi approach;legally compliant software,,7.0,,41.0,,18 Dec 2014,,,IEEE,IEEE Journals
40,40,How Reliable Are Systematic Reviews in Empirical Software Engineering?,S. MacDonell; M. Shepperd; B. Kitchenham; E. Mendes,"Auckland University of Technology, Auckland; Brunel University, West London; Keele University, Keele; The University of Auckland, Auckland",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,676,687,"BACKGROUND-The systematic review is becoming a more commonly employed research instrument in empirical software engineering. Before undue reliance is placed on the outcomes of such reviews it would seem useful to consider the robustness of the approach in this particular research context. OBJECTIVE-The aim of this study is to assess the reliability of systematic reviews as a research instrument. In particular, we wish to investigate the consistency of process and the stability of outcomes. METHOD-We compare the results of two independent reviews undertaken with a common research question. RESULTS-The two reviews find similar answers to the research question, although the means of arriving at those answers vary. CONCLUSIONS-In addressing a well-bounded research question, groups of researchers with similar domain experience can arrive at the same review outcomes, even though they may do so in different ways. This provides evidence that, in this context at least, the systematic review is a robust research method.",1939-3520,,10.1109/TSE.2010.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416726,Empirical software engineering;meta-analysis;systematic review;cost estimation.,Software engineering;Instruments;Robustness;Best practices;Stability;Costs;Mathematics;Computer science,software cost estimation;software reviews,systematic review reliability;empirical software engineering;research instrument;software cost estimation,,46.0,,26.0,,18 Feb 2010,,,IEEE,IEEE Journals
41,41,Variability and Reproducibility in Software Engineering: A Study of Four Companies that Developed the Same System,B. C. D. Anda; D. I. K. Sjøberg; A. Mockus,"University of Oslo, Oslo; Simula Research Laboratory, Lysaker; Avaya Labs Research, Basking Ridge",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,407,429,"The scientific study of a phenomenon requires it to be reproducible. Mature engineering industries are recognized by projects and products that are, to some extent, reproducible. Yet, reproducibility in software engineering (SE) has not been investigated thoroughly, despite the fact that lack of reproducibility has both practical and scientific consequences. We report a longitudinal multiple-case study of variations and reproducibility in software development, from bidding to deployment, on the basis of the same requirement specification. In a call for tender to 81 companies, 35 responded. Four of them developed the system independently. The firm price, planned schedule, and planned development process, had, respectively, ldquolow,rdquo ldquolow,rdquo and ldquomediumrdquo reproducibilities. The contractor's costs, actual lead time, and schedule overrun of the projects had, respectively, ldquomedium,rdquo ldquohigh,rdquo and ldquolowrdquo reproducibilities. The quality dimensions of the delivered products, reliability, usability, and maintainability had, respectively, ldquolow,rdquo ""high,rdquo and ldquolowrdquo reproducibilities. Moreover, variability for predictable reasons is also included in the notion of reproducibility. We found that the observed outcome of the four development projects matched our expectations, which were formulated partially on the basis of SE folklore. Nevertheless, achieving more reproducibility in SE remains a great challenge for SE research, education, and industry.",1939-3520,,10.1109/TSE.2008.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4693714,Software engineering life cycle;software quality;software project success;software process;multiple-case study.;General;Life cycle;Software Quality/SQA;Multiple-case study,Reproducibility of results;Software engineering;Programming;Job shop scheduling;Software quality;Computer industry;Costs;Software measurement;Systems engineering and theory;Usability,software quality,software engineering;mature engineering industries;software development;software quality;software process,,44.0,,94.0,,2 Dec 2008,,,IEEE,IEEE Journals
42,42,Software Engineering: An Idea Whose Time Has Come and Gone?,T. DeMarco,Atlantic Systems Guild,IEEE Software,19 Jun 2009,2009,26,4,96,96,Certain principles long considered fundamental to software engineering are examined and found wanting.,1937-4194,,10.1109/MS.2009.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076468,software engineering;metrics;control;project management;budget and schedule,Software engineering;Birds;Educational institutions;Documentation;Ethics;Pressure measurement;Feedback;Project management;Financial management;Packaging,,,,8.0,,,,19 Jun 2009,,,IEEE,IEEE Magazines
43,43,"Crowdsourcing in Software Engineering: Models, Motivations, and Challenges",T. D. LaToza; A. van der Hoek,"George Mason University; University of California, Irvine",IEEE Software,29 Dec 2015,2016,33,1,74,80,"Almost surreptitiously, crowdsourcing has entered software engineering practice. In-house development, contracting, and outsourcing still dominate, but many development projects use crowdsourcing-for example, to squash bugs, test software, or gather alternative UI designs. Although the overall impact has been mundane so far, crowdsourcing could lead to fundamental, disruptive changes in how software is developed. Various crowdsourcing models have been applied to software development. Such changes offer exciting opportunities, but several challenges must be met for crowdsourcing software development to reach its potential.",1937-4194,,10.1109/MS.2016.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367992,programming teams;staffing;software management;software development;software engineering;crowdsourcing;open innovation;peer production;software development competitions;microtasking,Crowdsourcing;Software develoment;Production facilities;Software engineering;Companies;Testing,outsourcing;software engineering,crowdsourcing;software engineering;software development projects;bug squashing;software testing;UI design,,81.0,,16.0,,29 Dec 2015,,,IEEE,IEEE Magazines
44,44,A Survey of App Store Analysis for Software Engineering,W. Martin; F. Sarro; Y. Jia; Y. Zhang; M. Harman,"Department of Computer Science, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom",IEEE Transactions on Software Engineering,15 Sep 2017,2017,43,9,817,847,"App Store Analysis studies information about applications obtained from app stores. App stores provide a wealth of information derived from users that would not exist had the applications been distributed via previous software deployment methods. App Store Analysis combines this non-technical information with technical information to learn trends and behaviours within these forms of software repositories. Findings from App Store Analysis have a direct and actionable impact on the software teams that develop software for app stores, and have led to techniques for requirements engineering, release planning, software design, security and testing. This survey describes and compares the areas of research that have been explored thus far, drawing out common aspects, trends and directions future research should take to address open problems and challenges.",1939-3520,,10.1109/TSE.2016.2630689,EPRSC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7765038,App store;analysis;mining;API;feature;release planning;requirements engineering;reviews;security;ecosystem,Software;Security;Software engineering;Market research;Ecosystems;Mobile communication;Google,program testing;software engineering,app store analysis;software engineering;software deployment;software repositories;software development;requirements engineering;release planning;software design;software security;software testing,,48.0,,262.0,CCBY,2 Dec 2016,,,IEEE,IEEE Journals
45,45,ASCENT: An Algorithmic Technique for Designing Hardware and Software in Tandem,J. White; B. Doughtery; D. C. Schmidt,"Virginia Tech, Blacksburg; Vanderbilt University, Nashville; Vanderbilt University, Nashville",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,838,851,"Search-based software engineering is an emerging paradigm that uses automated search algorithms to help designers iteratively find solutions to complicated design problems. For example, when designing a climate monitoring satellite, designers may want to use the minimal amount of computing hardware to reduce weight and cost while supporting the image processing algorithms running onboard. A key problem in these situations is that the hardware and software designs are locked in a tightly coupled cost-constrained producer/consumer relationship that makes it hard to find a good hardware/software design configuration. Search-based software engineering can be used to apply algorithmic techniques to automate the search for hardware/software designs that maximize the image processing accuracy while respecting cost constraints. This paper provides the following contributions to research on search-based software engineering: 1) We show how a cost-constrained producer/consumer problem can be modeled as a set of two multidimensional multiple-choice knapsack problems (MMKPs), 2) we present a polynomial-time search-based software engineering technique, called the Allocation-baSed Configuration Exploration Technique (ASCENT), for finding near optimal hardware/software codesign solutions, and 3) we present empirical results showing that ASCENT's solutions average over 95 percent of the optimal solution's value.",1939-3520,,10.1109/TSE.2010.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5539763,Algorithms;computer aided software engineering;optimization methods;distributed computing.,Software algorithms;Software design;Algorithm design and analysis;Hardware;Software engineering;Iterative algorithms;Costs;Image processing;Monitoring;Satellites,hardware-software codesign;knapsack problems;software engineering,ASCENT;hardware-software codesign;automated search algorithm;climate monitoring satellite;computing hardware;image processing algorithm;hardware/software design configuration;cost-constrained producer/consumer problem;multidimensional multiple choice knapsack problem;polynomial time search-based software engineering;allocation-based configuration exploration technique,,8.0,,34.0,,5 Aug 2010,,,IEEE,IEEE Journals
46,46,An Improved SDA Based Defect Prediction Framework for Both Within-Project and Cross-Project Class-Imbalance Problems,X. Jing; F. Wu; X. Dong; B. Xu,"State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, China; Department of Computer Science and Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,14 Apr 2017,2017,43,4,321,339,"Background. Solving the class-imbalance problem of within-project software defect prediction (SDP) is an important research topic. Although some class-imbalance learning methods have been presented, there exists room for improvement. For cross-project SDP, we found that the class-imbalanced source usually leads to misclassification of defective instances. However, only one work has paid attention to this cross-project class-imbalance problem. Objective. We aim to provide effective solutions for both within-project and cross-project class-imbalance problems. Method. Subclass discriminant analysis (SDA), an effective feature learning method, is introduced to solve the problems. It can learn features with more powerful classification ability from original metrics. For within-project prediction, we improve SDA for achieving balanced subclasses and propose the improved SDA (ISDA) approach. For cross-project prediction, we employ the semi-supervised transfer component analysis (SSTCA) method to make the distributions of source and target data consistent, and propose the SSTCA+ISDA prediction approach. Results. Extensive experiments on four widely used datasets indicate that: 1) ISDA-based solution performs better than other state-of-the-art methods for within-project class-imbalance problem; 2) SSTCA+ISDA proposed for cross-project class-imbalance problem significantly outperforms related methods. Conclusion. Within-project and cross-project class-imbalance problems greatly affect prediction performance, and we provide a unified and effective prediction framework for both problems.",1939-3520,,10.1109/TSE.2016.2597849,National Natural Science Foundation of China; The Chinese 973 Program; Research Project of NJUPT; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7530877,Software defect prediction (SDP);within-project class-imbalance;cross-project class-imbalance;improved subclass discriminant analysis (ISDA);ISDA based defect prediction framework,Support vector machines;Learning systems;Predictive models;Software;Software engineering;Measurement,learning (artificial intelligence);software engineering,SDA based defect prediction;within-project class-imbalance problem;cross-project class-imbalance problem;software defect prediction;SDP;class-imbalance learning;subclass discriminant analysis;semisupervised transfer component analysis;SSTCA,,69.0,,78.0,,3 Aug 2016,,,IEEE,IEEE Journals
47,47,Imprecise Matching of Requirements Specifications for Software Services Using Fuzzy Logic,M. C. Platenius; A. Shaker; M. Becker; E. Hüllermeier; W. Schäfer,"Software Engineering Group, Heinz Nixdorf Institute, Paderborn University, Germany; Intelligent Systems Group, Department of Computer Science, Paderborn University, Germany; Software Engineering Group, Fraunhofer IEM, Paderborn, Germany; Intelligent Systems Group, Department of Computer Science, Paderborn University, Germany; Software Engineering Group, Heinz Nixdorf Institute, Paderborn University, Germany",IEEE Transactions on Software Engineering,11 Aug 2017,2017,43,8,739,759,"Today, software components are provided by global markets in the form of services. In order to optimally satisfy service requesters and service providers, adequate techniques for automatic service matching are needed. However, a requester's requirements may be vague and the information available about a provided service may be incomplete. As a consequence, fuzziness is induced into the matching procedure. The contribution of this paper is the development of a systematic matching procedure that leverages concepts and techniques from fuzzy logic and possibility theory based on our formal distinction between different sources and types of fuzziness in the context of service matching. In contrast to existing methods, our approach is able to deal with imprecision and incompleteness in service specifications and to inform users about the extent of induced fuzziness in order to improve the user's decision-making. We demonstrate our approach on the example of specifications for service reputation based on ratings given by previous users. Our evaluation based on real service ratings shows the utility and applicability of our approach.",1939-3520,,10.1109/TSE.2016.2632115,German Research Foundation (DFG); Collaborative Research Center “On-The-Fly Computing”; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7755807,Service selection;service matching;requirements specifications;non-functional properties;fuzzy logic;uncertainty;decision making,Uncertainty;Fuzzy logic;Context;Security;Software;Software engineering;Decision making,decision making;fuzzy logic;fuzzy set theory;pattern matching;software engineering,software components;requirement specification imprecise matching;software services;fuzzy logic;automatic service matching;possibility theory;user decision-making,,,,93.0,,23 Nov 2016,,,IEEE,IEEE Journals
48,48,Targeted Scrum: Applying Mission Command to Agile Software Development,D. P. Harvie; A. Agah,"Department of Electrical Engineering and Computer Science, University of Kansas, Lawrence, KS; Department of Electrical Engineering and Computer Science, University of Kansas, Lawrence, KS",IEEE Transactions on Software Engineering,12 May 2016,2016,42,5,476,489,"Software engineering and mission command are two separate but similar fields, as both are instances of complex problem solving in environments with ever changing requirements. Our research hypothesis is that modifications to agile software development based on inspirations from mission command can improve the software engineering process in terms of planning, prioritizing, and communication of software requirements and progress, as well as improving the overall software product. Targeted Scrum is a modification of Traditional Scrum based on three inspirations from Mission Command: End State, Line of Effort, and Targeting. These inspirations have led to the introduction of the Product Design Meeting and modifications of some current Scrum meetings and artifacts. We tested our research hypothesis using a semester-long undergraduate level software engineering class. Students developed two software projects, one using Traditional Scrum and the other using Targeted Scrum. We then assessed how well both methodologies assisted the software development teams in planning and developing the software architecture, prioritizing requirements, and communicating progress. We also evaluated the software product produced by both methodologies. We found that Targeted Scrum did better in assisting the software development teams in the planning and prioritization of the requirements. However, Targeted Scrum had a negligible effect on improving the software development teams external and internal communications. Finally, Targeted Scrum did not have an impact on the product quality by the top performing and worst performing teams. Targeted Scrum did assist the product quality of the teams in the middle of the performance spectrum.",1939-3520,,10.1109/TSE.2015.2489654,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296686,"Scrum, Mission Command;Line of Effort;Product Design Meeting;Agile;Empirical Software Engineering;Scrum;mission command;line of effort;product design meeting;agile;empirical software engineering",Software;Planning;Scrum (Software development);Product design;Software engineering;Force,software architecture;software prototyping,targeted Scrum;mission command;agile software development;software engineering;software requirements;software product improvement;end state;line of effort;targeting;product design meeting;software projects;traditional Scrum;software architecture;product quality;performance spectrum,,8.0,,34.0,,12 Oct 2015,,,IEEE,IEEE Journals
49,49,ERP Customization as Software Engineering: Knowledge Sharing and Cooperation,Y. Dittrich; S. Vaucouleur; S. Giff,IT University of Copenhagen; IT University of Copenhagen; Microsoft Visual Studio,IEEE Software,16 Oct 2009,2009,26,6,41,47,"Enterprise resource planning (ERP) vendors provide multiple configuration possibilities ranging from module selection to master data provision to steer access rights for different users. These configuration possibilities cover anticipated variability. If the customer requires adaptation beyond what's anticipated, the source code of the product must be adapted. Customizations in this article's context are source code based adaptations of software products. The size and complexity of customizations range from simple report generation to developing independent add-ons that support specific businesses, for example, solutions for flight carriers. The size and lead time of such projects can compare to a full-size software development project. Enterprise resource planning (ERP) systems must be configured and customized to fit a specific company. The authors discuss cooperation with regard to ERP systems customization.",1937-4194,,10.1109/MS.2009.173,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287008,D.2 Software Engineering;D Software/Software Engineering;D.2.14 Human Factors in Software Design;J Computer Applications;J.1 Administrative Data Processing;J.1.a Business,Enterprise resource planning;Software engineering;Permission;Programming;Companies,cooperative systems;enterprise resource planning;software development management,ERP customization;software engineering;knowledge sharing;enterprise resource planning vendor;multiple configuration possibility;module selection;master data provision;product source code;source code based adaptation;software product;customization complexity;independent add-on;report generation;business support;software development project;cooperation,,39.0,2.0,14.0,,16 Oct 2009,,,IEEE,IEEE Magazines
50,50,Software Development in Startup Companies: The Greenfield Startup Model,C. Giardino; N. Paternoster; M. Unterkalmsteiner; T. Gorschek; P. Abrahamsson,"Faculty of Computer Science, Free University of Bolzano/Bozen, Dominikanerplatz 3, Italy; Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Campus Gräsvik, 371 79 Karlskrona, Sweden; Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Campus Gräsvik, 371 79 Karlskrona, Sweden; Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Campus Gräsvik, 371 79 Karlskrona, Sweden; Department of Computer and Information Science, Norwegian University of Science and Technology NTNU, Sem Saelandsvei 7-9, Trondheim, Norway",IEEE Transactions on Software Engineering,10 Jun 2016,2016,42,6,585,604,"Software startups are newly created companies with no operating history and oriented towards producing cutting-edge products. However, despite the increasing importance of startups in the economy, few scientific studies attempt to address software engineering issues, especially for early-stage startups. If anything, startups need engineering practices of the same level or better than those of larger companies, as their time and resources are more scarce, and one failed project can put them out of business. In this study we aim to improve understanding of the software development strategies employed by startups. We performed this state-of-practice investigation using a grounded theory approach. We packaged the results in the Greenfield Startup Model (GSM), which explains the priority of startups to release the product as quickly as possible. This strategy allows startups to verify product and market fit, and to adjust the product trajectory according to early collected user feedback. The need to shorten time-to-market, by speeding up the development through low-precision engineering activities, is counterbalanced by the need to restructure the product before targeting further growth. The resulting implications of the GSM outline challenges and gaps, pointing out opportunities for future research to develop and validate engineering practices in the startup context.",1939-3520,,10.1109/TSE.2015.2509970,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360225,Software Development;Startups;Grounded Theory;Software development;startups;grounded theory,Software;Companies;GSM;Context;Software engineering;History,software development management,Greenfield startup model;software startups;software engineering issues;engineering practices;software development strategies;state-of-practice investigation;grounded theory approach;GSM;user feedback;time-to-market,,55.0,,119.0,,17 Dec 2015,,,IEEE,IEEE Journals
51,51,MADMatch: Many-to-Many Approximate Diagram Matching for Design Comparison,S. Kpodjedo; F. Ricca; P. Galinier; G. Antoniol; Y. Guéhéneuc,"Ecole Polytechnique de Montreal, Montreal; Università di Genova, Genova; Ecole Polytechnique de Montreal, Montreal; Ecole Polytechnique de Montreal, Montreal; Ecole Polytechnique de Montreal, Montreal",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1090,1111,"Matching algorithms play a fundamental role in many important but difficult software engineering activities, especially design evolution analysis and model comparison. We present MADMatch, a fast and scalable many-to-many approximate diagram matching approach based on an error-tolerant graph matching (ETGM) formulation. Diagrams are represented as graphs, costs are assigned to possible differences between two given graphs, and the goal is to retrieve the cheapest matching. We address the resulting optimization problem with a tabu search enhanced by the novel use of lexical and structural information. Through several case studies with different types of diagrams and tasks, we show that our generic approach obtains better results than dedicated state-of-the-art algorithms, such as AURA, PLTSDiff, or UMLDiff, on the exact same datasets used to introduce (and evaluate) these algorithms.",1939-3520,,10.1109/TSE.2013.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6464271,Diagram differencing;search-based software engineering;approximate graph matching;identifier splitting,Unified modeling language;Algorithm design and analysis;Software;Scalability;Software algorithms;Software engineering;Optimization,graph theory;optimisation;search problems;software engineering,MADMatch approach;many-to-many approximate diagram matching approach;error-tolerant graph matching;ETGM;software engineering;design evolution analysis;model comparison;design comparison;optimization problem;tabu search;lexical information;structural information;AURA algorithm;PLTSDiff algorithm;UMLDiff algorithm,,9.0,,32.0,,18 Feb 2013,,,IEEE,IEEE Journals
52,52,Bayesian Networks For Evidence-Based Decision-Making in Software Engineering,A. T. Misirli; A. B. Bener,"Department of Information Processing Science, University of Oulu, Finland; Mechanical and Industrial Engineering Department, Ryerson University, Toronto, CA",IEEE Transactions on Software Engineering,16 Jun 2014,2014,40,6,533,554,"Recommendation systems in software engineering (SE) should be designed to integrate evidence into practitioners experience. Bayesian networks (BNs) provide a natural statistical framework for evidence-based decision-making by incorporating an integrated summary of the available evidence and associated uncertainty (of consequences). In this study, we follow the lead of computational biology and healthcare decision-making, and investigate the applications of BNs in SE in terms of 1) main software engineering challenges addressed, 2) techniques used to learn causal relationships among variables, 3) techniques used to infer the parameters, and 4) variable types used as BN nodes. We conduct a systematic mapping study to investigate each of these four facets and compare the current usage of BNs in SE with these two domains. Subsequently, we highlight the main limitations of the usage of BNs in SE and propose a Hybrid BN to improve evidence-based decision-making in SE. In two industrial cases, we build sample hybrid BNs and evaluate their performance. The results of our empirical analyses show that hybrid BNs are powerful frameworks that combine expert knowledge with quantitative data. As researchers in SE become more aware of the underlying dynamics of BNs, the proposed models will also advance and naturally contribute to evidence based-decision-making.",1939-3520,,10.1109/TSE.2014.2321179,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6808495,Evidence-based decision-making;Bayesian networks;Bayesian statistics;software reliability;software metrics;post-release defects,Software engineering;Decision making;Bayes methods;Software;Medical services;Systematics;Buildings,belief networks;decision making;software metrics;software reliability,Bayesian networks;evidence-based decision-making;software engineering;recommendation systems;SE;natural statistical framework;associated uncertainty;computational biology;health care decision-making;systematic mapping study;hybrid BN node;software reliability;software metrics,,32.0,1.0,81.0,,30 Apr 2014,,,IEEE,IEEE Journals
53,53,Alloy Meets the Algebra of Programming: A Case Study,J. N. Oliveira; M. A. Ferreira,"University of Minho, Braga; Software Improvement Group, Amsterdam",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,305,326,"Relational algebra offers to software engineering the same degree of conciseness and calculational power as linear algebra in other engineering disciplines. Binary relations play the role of matrices with similar emphasis on multiplication and transposition. This matches with Alloy's lemma “everything is a relation” and with the relational basis of the Algebra of Programming (AoP). Altogether, it provides a simple and coherent approach to checking and calculating programs from abstract models. In this paper, we put Alloy and the Algebra of Programming together in a case study originating from the Verifiable File System mini-challenge put forward by Joshi and Holzmann: verifying the refinement of an abstract file store model into a journaled (Flash) data model catering to wear leveling and recovery from power loss. Our approach relies on diagrams to graphically express typed assertions. It interweaves model checking (in Alloy) with calculational proofs in a way which offers the best of both worlds. This provides ample evidence of the positive impact in software verification of Alloy's focus on relations, complemented by induction-free proofs about data structures such as stores and lists.",1939-3520,,10.1109/TSE.2012.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155724,Model checking;algebra of programming;software verification;grand challenges in computing,Metals;Software;Programming;Matrices;Calculus;Cognition,formal verification;mathematics computing;relational algebra;software engineering,relational algebra;software engineering;linear algebra;Alloys lemma;relational basis;algebra of programming;AoP;calculating programs;verifiable file system;model checking;software verification;data structures,,5.0,,53.0,,21 Feb 2012,,,IEEE,IEEE Journals
54,54,Supporting Change Impact Analysis Using a Recommendation System: An Industrial Case Study in a Safety-Critical Context,M. Borg; K. Wnuk; B. Regnell; P. Runeson,"SICS Swedish ICT AB, Ideon Science Park, Building Beta 2, Scheelevägen 17, Lund, Sweden; Blekinge Institute of Technology, Karlskrona, Sweden; Lund University, Lund, Sweden; Lund University, Lund, Sweden",IEEE Transactions on Software Engineering,14 Jul 2017,2017,43,7,675,700,"Change Impact Analysis (CIA) during software evolution of safety-critical systems is a labor-intensive task. Several authors have proposed tool support for CIA, but very few tools were evaluated in industry. We present a case study on ImpRec, a recommendation System for Software Engineering (RSSE), tailored for CIA at a process automation company. ImpRec builds on assisted tracing, using information retrieval solutions and mining software repositories to recommend development artifacts, potentially impacted when resolving incoming issue reports. In contrast to the majority of tools for automated CIA, ImpRec explicitly targets development artifacts that are not source code. We evaluate ImpRec in a two-phase study. First, we measure the correctness of ImpRec's recommendations by a simulation based on 12 years' worth of issue reports in the company. Second, we assess the utility of working with ImpRec by deploying the RSSE in two development teams on different continents. The results suggest that ImpRec presents about 40 percent of the true impact among the top-10 recommendations. Furthermore, user log analysis indicates that ImpRec can support CIA in industry, and developers acknowledge the value of ImpRec in interviews. In conclusion, our findings show the potential of reusing traceability associated with developers' past activities in an RSSE.",1939-3520,,10.1109/TSE.2016.2620458,Embedded Applications Software Engineering; ORION; Knowledge Foundation; Lund University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7637029,Case;maintenance management;software and system safety;tracing,Context;Industries;Software engineering;Unified modeling language;Automation;Software systems,program diagnostics;recommender systems;safety-critical software;software engineering,change impact analysis;safety-critical context;CIA;software evolution;safety-critical system;recommendation system for software engineering;RSSE;ImpRec;information retrieval solution;software repository mining,,6.0,,120.0,,24 Oct 2016,,,IEEE,IEEE Journals
55,55,How Software Development Group Leaders Influence Team Members' Innovative Behavior,F. Q. B. da Silva; C. V. F. Monteiro; I. E. dos Santos; L. F. Capretz,"Universidade Federal de Pernambuco; Universidade Federal Rural de Pernambuco; Avanade; Western University, Canada",IEEE Software,24 Aug 2016,2016,33,5,106,109,"Innovation is important to a company's success, and a team leader's behavior is a major factor affecting group members' innovative activity. This article examines how software development team leaders influence innovative activity.",1937-4194,,10.1109/MS.2016.120,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548896,innovation;creativity;software development;transformational leadership;transactional leadership;ambidextrous leadership;exploitative innovation;exploratory innovation;software engineering,Technological innovation;Innovation management;Creativity;Software engineering;Software engineering;Management,behavioural sciences computing;human resource management;innovation management;software engineering,software development;innovation;company success;team leader behavior,,,,7.0,,24 Aug 2016,,,IEEE,IEEE Magazines
56,56,Automated Fixing of Programs with Contracts,Y. Pei; C. A. Furia; M. Nordio; Y. Wei; B. Meyer; A. Zeller,"Chair of Software Engineering, Department of Computer Science, ETH Zürich, Switzerland; Chair of Software Engineering, Department of Computer Science, ETH Zürich, Switzerland; Chair of Software Engineering, Department of Computer Science, ETH Zürich, Switzerland; Constraint Reasoning Group, Microsoft Research Cambridge, United Kingdom; Chair of Software Engineering, Department of Computer Science, ETH Zürich, Switzerland; Software Engineering Chair, Saarland University, Germany",IEEE Transactions on Software Engineering,14 May 2014,2014,40,5,427,449,"This paper describes AutoFix, an automatic debugging technique that can fix faults in general-purpose software. To provide high-quality fix suggestions and to enable automation of the whole debugging process, AutoFix relies on the presence of simple specification elements in the form of contracts (such as pre- and postconditions). Using contracts enhances the precision of dynamic analysis techniques for fault detection and localization, and for validating fixes. The only required user input to the AutoFix supporting tool is then a faulty program annotated with contracts; the tool produces a collection of validated fixes for the fault ranked according to an estimate of their suitability. In an extensive experimental evaluation, we applied AutoFix to over 200 faults in four code bases of different maturity and quality (of implementation and of contracts). AutoFix successfully fixed 42 percent of the faults, producing, in the majority of cases, corrections of quality comparable to those competent programmers would write; the used computational resources were modest, with an average time per fix below 20 minutes on commodity hardware. These figures compare favorably to the state of the art in automated program fixing, and demonstrate that the AutoFix approach is successfully applicable to reduce the debugging burden in real-world scenarios.",1939-3520,,10.1109/TSE.2014.2312918,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6776507,Automatic program repair;contracts;dynamic analysis,Indexes;Contracts;Debugging;Libraries;Software engineering;Software;Automation,contracts;fault diagnosis;program debugging;program diagnostics;software tools,automated program fixing;contracts;automatic debugging technique;general-purpose software fault fixing;high-quality fix suggestions;debugging process;dynamic analysis techniques;fault localization;fault detection;AutoFix supporting tool;computational resources;commodity hardware;AutoFix approach,,53.0,,68.0,,20 Mar 2014,,,IEEE,IEEE Journals
57,57,"Supporting Scope Tracking and Visualization for Very Large-Scale Requirements Engineering-Utilizing FSC+, Decision Patterns, and Atomic Decision Visualizations",K. Wnuk; T. Gorschek; D. Callele; E. Karlsson; E. Åhlin; B. Regnell,"Software Engineering Research Lab (SERL), Department of Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; Software Engineering Research Lab (SERL), Department of Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Computer Science, University of Saskatchewan, Saskatoon, Canada; Add a Lot, Sweden; Sony Mobile Communications, Lund, Sweden; Department of Computer Science, Lund University, Lund, Sweden",IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,47,74,"Deciding the optimal project scope that fulfills the needs of the most important stakeholders is challenging due to a plethora of aspects that may impact decisions. Large companies that operate in rapidly changing environments experience frequently changing customer needs which force decision makers to continuously adjust the scope of their projects. Change intensity is further fueled by fierce market competition and hard time-to-market deadlines. Staying in control of the changes in thousands of features becomes a major issue as information overload hinders decision makers from rapidly extracting relevant information. This paper presents a visual technique, called Feature Survival Charts+ (FSC+), designed to give a quick and effective overview of the requirements scoping process for Very Large-Scale Requirements Engineering (VLSRE). FSC+ were applied at a large company with thousands of features in the database and supported the transition from plan-driven to a more dynamic and change-tolerant release scope management process. FSC+ provides multiple views, filtering, zooming, state-change intensity views, and support for variable time spans. Moreover, this paper introduces five decision archetypes deduced from the dataset and subsequently analyzed and the atomic decision visualization that shows the frequency of various decisions in the process. The capabilities and usefulness of FSC+, decision patterns (state changes that features undergo) and atomic decision visualizations are evaluated through interviews with practitioners who found utility in all techniques and indicated that their inherent flexibility was necessary to meet the varying needs of the stakeholders.",1939-3520,,10.1109/TSE.2015.2445347,IKNOWDM project; Knowledge Foundation in Sweden; SCALARE ITEA2 project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7123669,- D.2.1Requirements/Specifications D.2.9.d Initiation and scope definition D.2.9 Management;Requirements/specifications;initiation and scope definition;management,Power capacitors;Companies;Planning;Visualization;Software;Software engineering;Electronic mail,data visualisation;formal specification,scope tracking;very large-scale requirements engineering visualization;FSC+;decision patterns;atomic decision visualizations;Feature Survival Charts+;requirements scoping process;very large-scale requirements engineering;VLSRE;change-tolerant release scope management process,,12.0,,108.0,,15 Jun 2015,,,IEEE,IEEE Journals
58,58,Tracking Developers' Eyes in the IDE,B. Sharif; T. Shaffer; J. Wise; J. I. Maletic,Youngstown State University; University of Notre Dame; Youngstown State University; Kent State University,IEEE Software,25 Apr 2016,2016,33,3,105,108,"With recorded eye gaze sessions, researchers will be able to determine all the locations that developers examine in software development artifacts. This will pave the way to further improve IDEs to support developers in various software engineering tasks. Toward that goal, researchers developed iTrace, software that interfaces with an eye tracker and IDE to capture eye gaze on software artifacts and map them to their semantic meaning.",1937-4194,,10.1109/MS.2016.84,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458758,iTrace;eye tracking;IDE;integrated development environment;software engineering;software development,Software development;Tracking;Gaze tracking;Visualization;Software engineering;Unified modeling language;Integrated development environment,ergonomics;software engineering,IDE;eye gaze sessions;software development artifacts;integrated development environment,,7.0,,7.0,,25 Apr 2016,,,IEEE,IEEE Magazines
59,59,Recommendation Systems for Software Engineering,M. Robillard; R. Walker; T. Zimmermann,"McGill University, Montreal; University of Calgary, Calgary; Microsoft Corportation, Redmond",IEEE Software,14 Jun 2010,2010,27,4,80,86,"Software development can be challenging because of the large information spaces that developers must navigate. Without assistance, developers can become bogged down and spend a disproportionate amount of their time seeking information at the expense of other value-producing tasks. Recommendation systems for software engineering (RSSEs) are software tools that can assist developers with a wide range of activities, from reusing code to writing effective bug reports. The authors provide an overview of recommendation systems for software engineering: what they are, what they can do for developers, and what they might do in the future.",1937-4194,,10.1109/MS.2009.161,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5235134,software engineering;development tools;programming environments;software construction tools;coding tools and techniques;design tools and techniques,Software engineering;Programming;Navigation;Software tools;Writing,recommender systems;software tools,recommendation system;software engineering;software development;information space;time seeking information;value-producing task;software tool;bug reports,,143.0,16.0,17.0,,11 Sep 2009,,,IEEE,IEEE Magazines
60,60,Continuing Prospects for an Engineering Discipline of Software,M. Shaw,Carnegie Mellon University,IEEE Software,16 Oct 2009,2009,26,6,64,67,"In her 1990 IEEE Software article ""Prospects for an Engineering Discipline of Software"" (Nov./Dec, pp. 15-24), Mary Shaw identified the key areas that the software development profession must address to become a true engineering discipline. That classic article made the magazine's 25th anniversary top picks list (Jan./Feb. 2009, pp. 9-11). Here, Mary reflects on the evolution of her thinking since the publication of ""Prospects"". The paper dealt with the topics of: programming progress; beyond programming; management of the software production; and progress toward an engineering discipline.",1937-4194,,10.1109/MS.2009.172,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287012,software engineering;commercial practice;critical applications;development techniques;economic force;engineering discipline;expertise;information processing;professional specializations;routine practice;science;scientific basis;software engineering;software technology,Programming profession;Engineering management;Production,social aspects of automation;software engineering,IEEE software article;software engineering discipline;software development profession;prospects publication;programming progress;software production management,,11.0,,10.0,,16 Oct 2009,,,IEEE,IEEE Magazines
61,61,Process Improvement from an Academic Perspective: How Could Software Engineering Education Contribute to CMMI Practices?,A. M. Moreno; M. Sánchez-Segura; F. Medina-Dominguez; G. Cuevas,Universidad Politécnica de Madrid; Universidad Carlos III de Madrid; Universidad Carlos III de Madrid; Universidad Politécnica de Madrid,IEEE Software,13 Jun 2014,2014,31,4,91,97,"Educating software engineers is a longstanding challenge, but the results of examining the overlap between software engineering educational standards (SE 2004 and GSwE 2009) and one of the most well-known software process improvement models (CMMI-DEV) could prove useful to both industry and academia.",1937-4194,,10.1109/MS.2013.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6509869,software engineering education;software process improvement;education;software engineering,Process control;Software development;Process management;Project management;Monitoring,computer science education;software process improvement;software standards,academic perspective;CMMI practices;software engineering educational standards;SE 2004;GSwE 2009;software process improvement models;CMMI-DEV,,1.0,,13.0,,29 Apr 2013,,,IEEE,IEEE Magazines
62,62,Contextualizing empirical evidence,T. Dybå,SINTEF,IEEE Software,3 Jan 2013,2013,30,1,81,83,"What works for whom, where, when, and why is the ultimate question of evidence-based software engineering. Still, the empirical research seems mostly concerned with identifying universal relationships that are independent of how work settings and other contexts interact with the processes important to software practice. Questions of “What is best?” seem to prevail. For example, “Which is better: pair or solo programming? test-first or test-last?” However, just as the question of whether a helicopter is better than a bicycle is meaningless, so are these questions because the answers depend on the settings and goals of the projects studied. Practice settings are rarely, if ever, the same. For example, the environments of software organizations differ, as do their sizes, customer types, countries or geography, and history. All these factors influence engineering practices in unique ways. Additionally, the human factors underlying the organizational culture differ from one organization to the next and also influence the way software is developed. We know these issues and the ways they interrelate are important for the successful uptake of research into practice. However, the nature of these relationships is poorly understood. Consequently, we can't a priori assume that the results of a particular study apply outside the specific context in which it was run. Here, I offer an overview of how context affects empirical research and how to better contextualize empirical evidence so that others can better understand what works for whom, where, when, and why.",1937-4194,,10.1109/MS.2013.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401115,software engineering;empirical software engineering,Software engineering;Context awareness;Information processing;Content management,organisational aspects;software development management,empirical evidence contextualization;evidence-based software engineering;software practice;pair programming;solo programming;test-first;test-last;practice settings;software organization environments;organizational culture,,21.0,,10.0,,3 Jan 2013,,,IEEE,IEEE Magazines
63,63,A Scalable Approach to Exact Model and Commonality Counting for Extended Feature Models,D. Fernandez-Amoros; R. Heradio; J. A. Cerrada; C. Cerrada,"Department of Languages and Computer Systems, Spanish Open University (UNED), Madrid, Spain; Department of Software Engineering and Computer Systems, Spanish Open University (UNED), Madrid, Spain; Department of Software Engineering and Computer Systems, Spanish Open University (UNED), Madrid, Spain; Department of Software Engineering and Computer Systems, Spanish Open University (UNED), Madrid, Spain",IEEE Transactions on Software Engineering,4 Sep 2014,2014,40,9,895,910,"A software product line is an engineering approach to efficient development of software product portfolios. Key to the success of the approach is to identify the common and variable features of the products and the interdependencies between them, which are usually modeled using feature models. Implicitly, such models also include valuable information that can be used by economic models to estimate the payoffs of a product line. Unfortunately, as product lines grow, analyzing large feature models manually becomes impracticable. This paper proposes an algorithm to compute the total number of products that a feature model represents and, for each feature, the number of products that implement it. The inference of both parameters is helpful to describe the standardization/parameterization balance of a product line, detect scope flaws, assess the product line incremental development, and improve the accuracy of economic models. The paper reports experimental evidence that our algorithm has better runtime performance than existing alternative approaches.",1939-3520,,10.1109/TSE.2014.2331073,Spanish Government; Comunidad de Madrid; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6835200,Feature models;formal methods;economic models;software product lines,Frequency modulation;Computational modeling;Analytical models;Software;Economics;Headphones;Portfolios,software engineering;software product lines,product line incremental development;software product portfolio development;software product line;commonality counting;extended feature models,,7.0,,56.0,,16 Jun 2014,,,IEEE,IEEE Journals
64,64,"Distribution, Data, Deployment: Software Architecture Convergence in Big Data Systems",I. Gorton; J. Klein,Software Engineering Institute; Software Engineering Institute,IEEE Software,23 Apr 2015,2015,32,3,78,85,"Big data applications are pushing the limits of software engineering on multiple horizons. Successful solutions span the design of the data, distribution, and deployment architectures. The body of software architecture knowledge must evolve to capture this advanced design knowledge for big data systems. This article is a first step on this path. Our research is proceeding in two complementary directions. First, we're expanding our collection of architecture tactics and encoding them in an environment that supports navigation between quality attributes and tactics, making crosscutting concerns for design choices explicit. Second, we're linking tactics to design solutions based on specific big data technologies, enabling architects to rapidly relate a particular technology's capabilities to a specific set of tactics.",1937-4194,,10.1109/MS.2014.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774768,software architecture;big data;distributed systems;data management;NoSQL;software engineering,Big data;Distributed databases;Computer architecture;Software engineering;Software architecture;Data management;Data models,Big Data;knowledge engineering;software architecture,big data system;software architecture convergence;software engineering;software architecture knowledge;architecture tactics,,44.0,,15.0,,18 Mar 2014,,,IEEE,IEEE Magazines
65,65,Research 2.0?,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,22 Oct 2012,2012,29,6,4,8,"IEEE Software Editor in Chief Forrest Shull discuss the state of research in software engineering, focusing on empirical software engineering (ESE) and the expanded goal—question—metric strategies (GQM+Strategies) to tie specific measurements to the technical goals that they address. He also welcomes Girish Suryanarayana as the magazine's newest member of its Industry Advisory Board.",1937-4194,,10.1109/MS.2012.164,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6336718,empirical software engineering;research;software;metrics;systems;test-driven development;tdd;goal-question-metric;gqm,Software engineering;Software testing;Software measurements;Testing,,,,3.0,,2.0,,22 Oct 2012,,,IEEE,IEEE Magazines
66,66,Exploiting Big Data's Benefits,J. Heidrich; A. Trendowicz; C. Ebert,Fraunhofer Institute for Experimental Software Engineering; Fraunhofer Institute for Experimental Software Engineering; Vector Consulting Services,IEEE Software,23 Jun 2016,2016,33,4,111,116,Knowing about big data's potential for exploiting new business ideas is a key capability for staying successful in the market. Potential analysis provides a systematic way to identify and close the gap between big data's possible benefits and the ability to turn that data into business value.,1937-4194,,10.1109/MS.2016.99,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498546,big data;lambda architecture;smart ecosystems;potential analysis;benefit analysis;readiness analysis;PRO-OPT;IWSM Mensura;software engineering;software development,Big data;Ecosystems;Smart devices;Software engineering;Computer architecture,Big Data;business data processing,big data benefits;business ideas;potential analysis;business value,,7.0,,4.0,,23 Jun 2016,,,IEEE,IEEE Magazines
67,67,Creating Software Process Capability/Maturity Models,C. G. von Wangenheim; J. C. R. Hauck; A. Zoucas; C. F. Salviano; F. McCaffery; F. Shull,"Federal University of Santa Catarina; Dundalk Institute of Technology; University of the Valley of Itajaí; CTI (Centro de Tecnologia da Informação) Renato Archer; Dundalk Institute of Technology (DkIT); Fraunhofer Center for Experimental Software Engineering, Maryland",IEEE Software,14 Jun 2010,2010,27,4,92,94,"A seeming multitude of software process capability/maturity models (SPCMMs) have emerged, and many software engineers have had to worry about compliance with them at one time or another. Although using SPCMMs is a well-established practice, the ways they're used can vary widely. At best, they can pull together vast bodies of knowledge about good software practices-the hard-won expertise of many engineers-into a form that's easier to work with. At worst, they're misused as ""processes for process' sake,"" in which conforming to the model stifles opportunities for innovation and tailoring. If software engineers had better knowledge about how SPCMMs are developed and the basis of their recommendations, they might be able to interpret and use them to optimize their benefits. We therefore studied these issues in a systematic literature review and follow-on questionnaire.",1937-4194,,10.1109/MS.2010.96,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484116,software engineering;Process Capability/Maturity Models;CMMI;ISO/IEC 15504,Knowledge engineering;Technological innovation,Capability Maturity Model;software engineering,software process capability;software process maturity models;SPCMM;software engineers;systematic literature;follow on questionnaire,,49.0,,15.0,,14 Jun 2010,,,IEEE,IEEE Magazines
68,68,StakeRare: Using Social Networks and Collaborative Filtering for Large-Scale Requirements Elicitation,S. L. Lim; A. Finkelstein,"University College London, London; University College London, London",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,707,735,"Requirements elicitation is the software engineering activity in which stakeholder needs are understood. It involves identifying and prioritizing requirements-a process difficult to scale to large software projects with many stakeholders. This paper proposes StakeRare, a novel method that uses social networks and collaborative filtering to identify and prioritize requirements in large software projects. StakeRare identifies stakeholders and asks them to recommend other stakeholders and stakeholder roles, builds a social network with stakeholders as nodes and their recommendations as links, and prioritizes stakeholders using a variety of social network measures to determine their project influence. It then asks the stakeholders to rate an initial list of requirements, recommends other relevant requirements to them using collaborative filtering, and prioritizes their requirements using their ratings weighted by their project influence. StakeRare was evaluated by applying it to a software project for a 30,000-user system, and a substantial empirical study of requirements elicitation was conducted. Using the data collected from surveying and interviewing 87 stakeholders, the study demonstrated that StakeRare predicts stakeholder needs accurately and arrives at a more complete and accurately prioritized list of requirements compared to the existing method used in the project, taking only a fraction of the time.",1939-3520,,10.1109/TSE.2011.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740931,Requirements/specifications;elicitation methods;requirements prioritization;experimentation;human factors;recommender systems;social network analysis;stakeholder analysis.,Social network services;Collaboration;Filtering;Software;Size measurement;Software engineering;Business,collaborative filtering;data acquisition;project management;recommender systems;social networking (online);software management,social network;collaborative filtering;requirement elicitation;software engineering;stakeholder;StakeRare;recommender system;software project;data collection,,85.0,,113.0,,5 Apr 2011,,,IEEE,IEEE Journals
69,69,Impact of Budget and Schedule Pressure on Software Development Cycle Time and Effort,N. Nan; D. E. Harter,"University of Oklahoma, Norman; Syracuse University, Syracuse",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,624,637,"As excessive budget and schedule compression becomes the norm in today's software industry, an understanding of its impact on software development performance is crucial for effective management strategies. Previous software engineering research has implied a nonlinear impact of schedule pressure on software development outcomes. Borrowing insights from organizational studies, we formalize the effects of budget and schedule pressure on software cycle time and effort as U-shaped functions. The research models were empirically tested with data from a 25 billion/year international technology firm, where estimation bias is consciously minimized and potential confounding variables are properly tracked. We found that controlling for software process, size, complexity, and conformance quality, budget pressure, a less researched construct, has significant U-shaped relationships with development cycle time and development effort. On the other hand, contrary to our prediction, schedule pressure did not display significant nonlinear impact on development outcomes. A further exploration of the sampled projects revealed that the involvement of clients in the software development might have ldquoerodedrdquo the potential benefits of schedule pressure. This study indicates the importance of budget pressure in software development. Meanwhile, it implies that achieving the potential positive effect of schedule pressure requires cooperation between clients and software development teams.",1939-3520,,10.1109/TSE.2009.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815275,Cost estimation;time estimation;schedule and organizational issues;systems development.,Programming;Job shop scheduling;Software performance;Computer industry;Financial management;Software development management;Software engineering;Testing;Pressure control;Size control,budgeting;DP industry;project management;sampling methods;scheduling;software cost estimation;software development management;software metrics;software quality;statistical testing,budget pressure;schedule pressure;software development cycle time estimation;software development effort estimation;software industry;software development performance;software engineering research;nonlinear impact;organizational study;U-shaped function;empirical testing;international technology firm;potential confounding variable;software process control;software size control;software complexity control;software conformance quality control;sampled project management;potential positive effect;software development team management strategy;software cost estimation,,46.0,,74.0,,17 Apr 2009,,,IEEE,IEEE Journals
70,70,"Semi-Proving: An Integrated Method for Program Proving, Testing, and Debugging",T. Y. Chen; T. H. Tse; Z. Q. Zhou,"Centre for Software Analysis and Testing, Swinburne University of Technology, Hawthorn, Victoria 3122, Australia; Department of Computer Science, The University of Hong Kong, Pokfulam, Hong Kong; School of Computer Science and Software Engineering, University of Wollongong, Wollongong, NSW 2522, Australia",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,109,125,"We present an integrated method for program proving, testing, and debugging. Using the concept of metamorphic relations, we select necessary properties for target programs. For programs where global symbolic evaluation can be conducted and the constraint expressions involved can be solved, we can either prove that these necessary conditions for program correctness are satisfied or identify all inputs that violate the conditions. For other programs, our method can be converted into a symbolic-testing approach. Our method extrapolates from the correctness of a program for tested inputs to the correctness of the program for related untested inputs. The method supports automatic debugging through the identification of constraint expressions that reveal failures.",1939-3520,,10.1109/TSE.2010.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406529,Software/program verification;symbolic execution;testing and debugging.,Software testing;Automatic testing;Computer science;Built-in self-test;Software debugging;Costs;Automation;Australia Council;Communications technology;Software engineering,formal verification;program debugging;program testing,semiproving;program proving;program testing;program debugging;integrated method;metamorphic relation;symbolic evaluation;constraint expression;symbolic testing;automatic debugging;program verification,,45.0,,60.0,,5 Feb 2010,,,IEEE,IEEE Journals
71,71,Strategies for Early-Stage Collaborative Design,A. Dilmaghani; J. Dibble,Oracle; Cooper,IEEE Software,22 Dec 2011,2012,29,1,39,45,"Collaboration can enhance the output of early-stage design. When software designers or architects work together to define a problem and explore potential solutions, they find and address design problems earlier and arrive at more innovative and effective solutions than when they work alone. Nonetheless, collaboration can fail without proper planning. This set of 10 design session ground rules can significantly enhance the process and output of early-stage design.",1937-4194,,10.1109/MS.2011.124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035660,analysis;requirements;specifications;software engineering;software;elicitation methods;process;design concepts;human factors;software design,Collaboration;Software design;Product development;Software engineering;Unified modeling language;Software architecture,software engineering,early-stage collaborative design;software designer;software architect,,1.0,,1.0,,6 Oct 2011,,,IEEE,IEEE Magazines
72,72,Steering Software Development Workflow: Lessons from the Internet,M. Cantor; B. MacIsaac; R. Mannan,Cutter Consortium; IBM; IBM,IEEE Software,24 Aug 2016,2016,33,5,96,102,"There's a body of literature on the software factory that might lead readers to believe that software development is analogous to manufacturing: requirements enter one end of a pipeline; tested code exits the other. In The Principles of Product Development Flow, Donald Reinertsen challenged this paradigm, proposing that a flow-based model is more applicable. Reinertsen's principles apply to both communication networks and software development workflows, and network optimization approaches are applicable to software development workflows.",1937-4194,,10.1109/MS.2016.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548902,agile methods;agile software development;lean software development;Scrum;process improvement;queuing;Donald Reinertsen;communication networks;product development flow;WSJF;weighted shortest job first;software engineering,Software engineering;Agile software development;Economics;Job shop scheduling;Internet;Queueing analysis,Internet;software engineering,network optimization;communication networks;Reinertsen principle;flow-based model;product development flow principles;software factory;Internet;software development workflow,,,,10.0,,24 Aug 2016,,,IEEE,IEEE Magazines
73,73,The Value of a Single Solution for End-to-End ALM Tool Support,M. Gatrell,Neilson Financial Services,IEEE Software,24 Aug 2016,2016,33,5,103,105,"A single solution for application lifecycle management (ALM) support lets stakeholders see their requirements throughout the ALM process. This ranges from idea origination through to seeing when, and to which environments, an application was released and the changes it has undergone. Such a solution provides metrics that natively cover the ALM process and provide new insights. Finally, it provides a collaboration platform that brings all stakeholders together with a single view over a single source of truth throughout ALM.",1937-4194,,10.1109/MS.2016.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548904,application lifecycle management;ALM;user experience;DevOps;software engineering;software development,Stakeholders;Software engineering;Collaboration;Product life cycle management;Documentation;Ecosystems;Software metrics,groupware;product life cycle management;software engineering,end-to-end ALM tool support;application lifecycle management;collaboration platform,,4.0,,,,24 Aug 2016,,,IEEE,IEEE Magazines
74,74,Privacy Requirements in an Age of Increased Sharing,T. Breaux,,IEEE Software,15 Sep 2014,2014,31,5,24,27,"Privacy is a critical design principle that must be balanced with how we utilize personal data in software. This article examines the increasing importance of privacy in emerging software ecosystems, legal and standards compliance, and software design practice. The Web extra at http://youtu.be/E9kbrOE8dFA is an audio podcast in which author Travis Breaux provides an audio recording of the Requirements column about the increasing importance of privacy in emerging software ecosystems, legal and standards compliance, and software design practice.",1937-4194,,10.1109/MS.2014.118,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898709,privacy;requirements;design;software engineering,Privacy;Software engineering;Law;Business;Standards,data privacy;law;software engineering;software standards,privacy requirements;data sharing;personal data;software ecosystems;legal compliance;standards compliance;software design practice,,6.0,,3.0,,15 Sep 2014,,,IEEE,IEEE Magazines
75,75,Technical Debt: Challenges and Perspectives,B. Stopford; K. Wallace; J. Allspaw,Confluent; NA; Etsy,IEEE Software,11 Jul 2017,2017,34,4,79,81,Three IT managers from different domains present their views on the challenges of tackling technical debt.,1937-4194,,10.1109/MS.2017.99,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974723,technical debt;software development;software engineering;Ben Stopford;Ken Wallace;John Allspaw,Information technology;Computer architecture;Software engineering;Parallel processing;Best practices;Software measurement,software engineering,software development,,1.0,,,,11 Jul 2017,,,IEEE,IEEE Magazines
76,76,Design Strategy and Software Design Effectiveness,A. Tang; H. van Vliet,Swinburne University of Technology; VU University Amsterdam,IEEE Software,22 Dec 2011,2012,29,1,51,55,"Software design is about a sequence of steps taken to achieve a goal. Designers must plan their approach to carrying out these steps. In studying designers at work, the authors observed breadth- versus depth-first approaches to design-space exploration and problem- versus solution-driven approaches during the actual design. Which approaches and when to use them are important to effective design. The authors suggest four archetypical strategies that designers can choose under different circumstances, thus making design strategy one of the early design decisions.",1937-4194,,10.1109/MS.2011.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051414,design concepts;software engineering;design tools and techniques,Software design;Product development;Complexity theory;Planning;Software engineering,software engineering,design strategy;software design effectiveness;breadth-first approach;depth-first approach;design-space exploration;problem-driven approach;solution-driven approach,,9.0,,4.0,,18 Oct 2011,,,IEEE,IEEE Magazines
77,77,The Software behind the Higgs Boson Discovery,D. Rousseau,Orsay Université Paris-Sud,IEEE Software,21 Aug 2012,2012,29,5,11,15,"In this column, David Rousseau describes the enormous software development effort associated with teasing out evidence for the elusive Higgs boson, a cornerstone of the Standard Model. In keeping with previous Impact columns, everything about this is huge but the application is unique.",1937-4194,,10.1109/MS.2012.123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6276293,impact;Higgs boson;physics;CERN;nuclear research;Atlas;decay;software engineering;software development,Software development;Physcis;Nuclear physics;Software engineering;Particle collisions,Higgs bosons;physics computing;software engineering,Higgs boson discovery;software development;standard model,,7.0,,2.0,,21 Aug 2012,,,IEEE,IEEE Magazines
78,78,Requirements Tracery,O. Gotel; S. Morris,independent researcher; City University London,IEEE Software,18 Aug 2011,2011,28,5,92,94,"This paper presents traceability of software. Traceability expresses the potential to create and follow links between pairs of development artifacts to support analytical or development tasks. While a traceability information model or some similar specification of permissible links between artifact types can predefine the intended types of trace to establish and use, the overall tracery obtained in practice is rarely designed or scrutinized. The sum total of the actual traces created within a project provides the scaffolding for supporting many diverse engineering activities. They deserve far more attention.",1937-4194,,10.1109/MS.2011.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984800,software engineering;requirements;techniques;agile;creativity;meaning carriers,Software engineering;Software reliability,formal verification;program diagnostics;software engineering,software traceability;software development;diverse engineering activities;requirements tracery,,1.0,,2.0,,18 Aug 2011,,,IEEE,IEEE Magazines
79,79,A Follow-Up Reflection on Software Process Improvement ROI,R. van Solingen,Delft University of Technology,IEEE Software,25 Aug 2009,2009,26,5,77,79,"Our discipline must shift toward value-based software engineering, because we're obliged to prove our contributions to the financial bottom line. In the May/June 2004 IEEE Software special issue on return on investment (ROI), the author presented measurement results for the ROI of software process improvement (SPI). This article made three main contributions. First, provided a detailed overview of publications containing real-life measurement results from practical applications of SPI, in which the author measured the ROI. My study included 20 cases, with an average ROI of 7 and a median of 6.6. This indicates that SPI's net profit seems to be approximately US$7 for every dollar invested. However, I found no published cases in which SPI investments resulted in a measurable loss; furthermore, the ROI bandwidth was large (between 1.5 and 19). This indicates that the actual ROI of an SPI investment seems hard to really guarantee up front. Second, I showed that benefits are just as easy to quantify as costs. Cost measurements are always based on an agreement about how to measure and quantify costs. Such an agreement can also serve as the basis for measuring benefits. My article contained data from two real-life projects that had made such cost and benefit measurements and calculated ROI. Finally, I concluded that expressing ""value"" is crucial. Software engineering and its improvement are often major investments for organizations. Investments must be profitable. Because different people in different roles share one generic term for value-money, I recommended expressing any software engineering effort and its benefits in financial terms.",1937-4194,,10.1109/MS.2009.120,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222799,software process improvement;return on investment;value-based software engineering;Six Sigma;management commitment;benefit measurement,Reflection;Financial management;Investments;Software engineering;Software measurement;Computer science;Computer industry;Data analysis;Data engineering;Economic indicators,software cost estimation;software metrics;software process improvement,follow-up reflection;ROI software process improvement;value-based software engineering;SPI investment;cost measurement;software organization,,3.0,,9.0,,25 Aug 2009,,,IEEE,IEEE Magazines
80,80,Assessing the Effectiveness of Sequence Diagrams in the Comprehension of Functional Requirements: Results from a Family of Five Experiments,S. Abrahão; C. Gravino; E. Insfran; G. Scanniello; G. Tortora,"Universitat Politècnica de València, València; University of Salerno via Ponte Don Melillo, Salerno; Universitat Politècnica de València, València; University of Basilicata Viale DellAteneo, Macchia Romana, Potenza; University of Salerno via Ponte Don Melillo, Salerno",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,327,342,Modeling is a fundamental activity within the requirements engineering process and concerns the construction of abstract descriptions of requirements that are amenable to interpretation and validation. The choice of a modeling technique is critical whenever it is necessary to discuss the interpretation and validation of requirements. This is particularly true in the case of functional requirements and stakeholders with divergent goals and different backgrounds and experience. This paper presents the results of a family of experiments conducted with students and professionals to investigate whether the comprehension of functional requirements is influenced by the use of dynamic models that are represented by means of the UML sequence diagrams. The family contains five experiments performed in different locations and with 112 participants of different abilities and levels of experience with UML. The results show that sequence diagrams improve the comprehension of the modeled functional requirements in the case of high ability and more experienced participants.,1939-3520,,10.1109/TSE.2012.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6193111,Documentation;software engineering;requirements specifications,Unified modeling language;Object oriented modeling;Analytical models;Computational modeling;Software systems;Materials,formal specification;Unified Modeling Language,effectiveness assessment;UML sequence diagrams;functional requirements;family-of-five experiments;requirements engineering process;abstract descriptions;requirement interpretation;requirement validation;functional stakeholders;software engineering;requirements specifications;unified modeling language,,38.0,,55.0,,1 May 2012,,,IEEE,IEEE Journals
81,81,Automated Abstractions for Contract Validation,G. de Caso; V. Braberman; D. Garbervetsky; S. Uchitel,"FCEyN, Universidad de Buenos Aires, Buenos Aires; FCEyN, Universidad de Buenos Aires, Buenos Aires; FCEyN, Universidad de Buenos Aires, Buenos Aires; FCEyN, Universidad de Buenos Aires, Buenos Aires and Imperial College, London",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,141,162,"Pre/postcondition-based specifications are commonplace in a variety of software engineering activities that range from requirements through to design and implementation. The fragmented nature of these specifications can hinder validation as it is difficult to understand if the specifications for the various operations fit together well. In this paper, we propose a novel technique for automatically constructing abstractions in the form of behavior models from pre/postcondition-based specifications. Abstraction techniques have been used successfully for addressing the complexity of formal artifacts in software engineering; however, the focus has been, up to now, on abstractions for verification. Our aim is abstraction for validation and hence, different and novel trade-offs between precision and tractability are required. More specifically, in this paper, we define and study enabledness-preserving abstractions, that is, models in which concrete states are grouped according to the set of operations that they enable. The abstraction results in a finite model that is intuitive to validate and which facilitates tracing back to the specification for debugging. The paper also reports on the application of the approach to two industrial strength protocol specifications in which concerns were identified.",1939-3520,,10.1109/TSE.2010.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5639021,Requirements/specifications;validation;automated abstraction.,Validation;Software engineering;Object oriented modeling;Protocols;Buffer storage,formal specification;software engineering,automated abstractions;contract validation;software engineering;behavior models;postcondition based specifications;precondition based specifications;formal artifacts;industrial strength,,22.0,,38.0,,18 Nov 2010,,,IEEE,IEEE Journals
82,82,A Taxonomy and Mapping of Computer-Based Critiquing Tools,N. M. Ali; J. Hosking; J. Grundy,"Universiti Putra Malaysia, Selangor; Australian National University, Canberra; Swinburne University, Melbourne",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1494,1520,"Critics have emerged in recent times as a specific tool feature to support users in computer-mediated tasks. These computer-supported critics provide proactive guidelines or suggestions for improvement to designs, code, and other digital artifacts. The concept of a critic has been adopted in various domains, including medical, programming, software engineering, design sketching, and others. Critics have been shown to be an effective mechanism for providing feedback to users. We propose a new critic taxonomy based on extensive review of the critic literature. The groups and elements of our critic taxonomy are presented and explained collectively with examples, including the mapping of 13 existing critic tools, predominantly for software engineering and programming education tasks to the taxonomy. We believe this critic taxonomy will assist others in identifying, categorizing, developing, and deploying computer-supported critics in a range of domains.",1939-3520,,10.1109/TSE.2013.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6570472,Design critics;critiquing systems;critic taxonomy;software tool support;survey,Taxonomy;Software;Recommender systems;Programming;Software engineering;Unified modeling language;Java,computer science education;programming;software engineering,computer-based critiquing tool taxonomy;computer-based critiquing tool mapping;computer-mediated tasks;computer-supported critics;digital artifacts;critic taxonomy;software engineering;programming education tasks,,8.0,,68.0,,26 Jul 2013,,,IEEE,IEEE Journals
83,83,Naïveté Squared: In Search of Two Taxonomies and a Mapping between Them,R. L. Glass; I. Vessey,"Griffith Univ., Brisbane, QLD, Australia; Univ. of Queensland, Brisbane, QLD, Australia",IEEE Software,18 Aug 2011,2011,28,5,14,15,"The authors describe an issue that they think is extremely important: the relationship between applications and solutions in the software engineering and information systems fields. In particular, they believe the fields desperately need a taxonomy of application domains, a taxonomy of solution approaches, and a mapping between the two. This article has a Web extra that offers an interview with one of the article's authors, Robert L. Glass, about the ""dark side"" of this topic.",1937-4194,,10.1109/MS.2011.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984790,taxonomy;application domains;software solutions,Software development;Taxonomy;Information systems;Information services;Software engineering;Information retrieval;Industry applications;Computer applications,information systems;software engineering,taxonomies;software engineering;information systems fields,,,2.0,,,18 Aug 2011,,,IEEE,IEEE Magazines
84,84,Practicing What We Preach,S. Ghaisas,Tata Consultancy Services,IEEE Software,28 Feb 2014,2014,31,1,88,92,"The rhetorical question ""do we practice what we preach?"" still seems to be relevant, even a decade after it appeared on the requirements engineering research landscape. New perspectives from various seasoned professionals from India address the question yet again. The Web extra at http://youtu.be/QtJcaibyetw is an audio podcast of Requirements column editor Jane Cleland-Huang speaking with Tony Gorschek, a professor of software engineering at the Blekinge Institute of Technology with more than 10 years of experience as a CTO, senior executive consultant, engineer, chief architect, and product manager, about technology transfer in the requirements engineering field.",1937-4194,,10.1109/MS.2014.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6750452,requirements;requirements engineering;fieldwork;requirements practitioners;India,Requirements engineering;Strategic planning;Software engineering;Companies,software engineering;systems analysis,requirements engineering;software engineering;RE community,,3.0,,8.0,,28 Feb 2014,,,IEEE,IEEE Magazines
85,85,Adaptive Multi-Objective Evolutionary Algorithms for Overtime Planning in Software Projects,F. Sarro; F. Ferrucci; M. Harman; A. Manna; J. Ren,"University College London, CREST Centre, London, United Kingdom; University of Salerno, Fisciano, SA, Italy; University College London, CREST Centre, London, United Kingdom; University of Salerno, Fisciano, SA, Italy; Beihang University, Beijing, China",IEEE Transactions on Software Engineering,13 Oct 2017,2017,43,10,898,917,"Software engineering and development is well-known to suffer from unplanned overtime, which causes stress and illness in engineers and can lead to poor quality software with higher defects. Recently, we introduced a multi-objective decision support approach to help balance project risks and duration against overtime, so that software engineers can better plan overtime. This approach was empirically evaluated on six real world software projects and compared against state-of-the-art evolutionary approaches and currently used overtime strategies. The results showed that our proposal comfortably outperformed all the benchmarks considered. This paper extends our previous work by investigating adaptive multi-objective approaches to meta-heuristic operator selection, thereby extending and (as the results show) improving algorithmic performance. We also extended our empirical study to include two new real world software projects, thereby enhancing the scientific evidence for the technical performance claims made in the paper. Our new results, over all eight projects studied, showed that our adaptive algorithm outperforms the considered state of the art multi-objective approaches in 93 percent of the experiments (with large effect size). The results also confirm that our approach significantly outperforms current overtime planning practices in 100 percent of the experiments (with large effect size).",1939-3520,,10.1109/TSE.2017.2650914,EPSRC; Microsoft Azure Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7814340,Software engineering;management;planning;search-based software engineering;project scheduling;overtime;hyperheuristic;multi-objective evolutionary algorithms;NSGAII,Software;Planning;Software engineering;Search problems;Adaptive algorithms;Project management;Standards,decision support systems;DP management;evolutionary computation;project management;software development management;software quality,adaptive multiobjective evolutionary algorithms;multiobjective decision support approach;project risks;software engineers;evolutionary approaches;overtime strategies;adaptive multiobjective approaches;meta-heuristic operator selection;software projects;overtime planning practices,,7.0,,96.0,CCBY,11 Jan 2017,,,IEEE,IEEE Journals
86,86,The Birth of Refactoring: A Retrospective on the Nature of High-Impact Software Engineering Research,W. G. Griswold; W. F. Opdyke,"University of California, San Diego; JPMorgan Chase",IEEE Software,28 Oct 2015,2015,32,6,30,38,"Software refactoring was independently invented in the late '80s by two students in two research groups: Ralph Johnson's group at the University of Illinois and David Notkin's group at the University of Washington. This article provides a retrospective of the birth of refactoring, reflecting on how the ideas came about and were developed in those two students' doctoral dissertations. The analysis provides useful insights for both researchers and practitioners seeking high impact in their work. This article is part of a special issue on Refactoring.",1937-4194,,10.1109/MS.2015.107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7274256,refactoring;program restructuring;integrated development environment;history;software development;software engineering;Ralph Johnson;David Notkin;Bill Griswold;Bill Opdyke,Code refractoring;Data structures;Programming;Software engineering;Technological innovation;Semantics;Software development,software maintenance,high-impact software engineering research;software refactoring,,11.0,,22.0,,23 Sep 2015,,,IEEE,IEEE Magazines
87,87,Point/Counterpoint,J. Singer; M. Vigder; J. Segal; S. Clarke,National Research Council Canada; National Research Council Canada; Open University; Microsoft,IEEE Software,25 Aug 2009,2009,26,5,54,57,"Tools help end users develop software, but they're effective only when combined with a basic understanding of software engineering. Given this proliferation of new and old capabilities, how will end users exploit the programming possibilities available to them? Will tools to support end users be enough - or should everyone be taught some form of software engineering literacy? We believe we need a new literacy: not just reading, writing, and arithmetic, but the 3 Rs + SE. With such an education, end users will have greater success customizing environments and manipulating digital information correctly and thoughtfully.",1937-4194,,10.1109/MS.2009.135,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222795,end-user programming;software engineering;version control;configuration management;software testing;debugging;software maintenance,Software engineering;Programming profession;Collaborative work;Collaborative tools;Application software;Collaborative software;Control systems;Engineering management;Software tools;Cellular phones,computer science education;programming;reverse engineering;software tools;teaching,end-user programming teaching;software engineering literacy;software tools;software development;software understanding;SE education;software environment customization;digital information manipulation;reading-writing-and-arithmetic;3 Rs,,,,,,25 Aug 2009,,,IEEE,IEEE Magazines
88,88,Empirical Principles and an Industrial Case Study in Retrieving Equivalent Requirements via Natural Language Processing Techniques,D. Falessi; G. Cantone; G. Canfora,"Simula Research Laboratory, Lysaker and University of Rome ""TorVergata"", Rome; University of Rome ""TorVergata"", Rome; University of Sannio, Benevento",IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,18,44,"Though very important in software engineering, linking artifacts of the same type (clone detection) or different types (traceability recovery) is extremely tedious, error-prone, and effort-intensive. Past research focused on supporting analysts with techniques based on Natural Language Processing (NLP) to identify candidate links. Because many NLP techniques exist and their performance varies according to context, it is crucial to define and use reliable evaluation procedures. The aim of this paper is to propose a set of seven principles for evaluating the performance of NLP techniques in identifying equivalent requirements. In this paper, we conjecture, and verify, that NLP techniques perform on a given dataset according to both ability and the odds of identifying equivalent requirements correctly. For instance, when the odds of identifying equivalent requirements are very high, then it is reasonable to expect that NLP techniques will result in good performance. Our key idea is to measure this random factor of the specific dataset(s) in use and then adjust the observed performance accordingly. To support the application of the principles we report their practical application to a case study that evaluates the performance of a large number of NLP techniques for identifying equivalent requirements in the context of an Italian company in the defense and aerospace domain. The current application context is the evaluation of NLP techniques to identify equivalent requirements. However, most of the proposed principles seem applicable to evaluating any estimation technique aimed at supporting a binary decision (e.g., equivalent/nonequivalent), with the estimate in the range [0,1] (e.g., the similarity provided by the NLP), when the dataset(s) is used as a benchmark (i.e., testbed), independently of the type of estimator (i.e., requirements text) and of the estimation method (e.g., NLP).",1939-3520,,10.1109/TSE.2011.122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112783,Empirical software engineering;traceability recovery;natural language processing;equivalent requirements;metrics and measurement,Natural language processing;Context;Semantics;Measurement;Matrix decomposition;Monitoring;Thesauri,information retrieval;natural language processing;program diagnostics;software engineering,industrial case study;equivalent requirement retrieval;natural language processing techniques;software engineering;traceability recovery;clone detection;NLP techniques;reliable evaluation procedures;Italian company;aerospace domain;defense domain;estimation technique;binary decision,,55.0,,116.0,,27 Dec 2011,,,IEEE,IEEE Journals
89,89,Dynamic QoS Management and Optimization in Service-Based Systems,R. Calinescu; L. Grunske; M. Kwiatkowska; R. Mirandola; G. Tamburrelli,"Aston University, Birmingham; Swinburne University of Technology, Swinburne; Oxford University Computing Laboratories, Oxford; Politecnico di Milano, Milano; Politecnico di Milano, Milano",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,387,409,"Service-based systems that are dynamically composed at runtime to provide complex, adaptive functionality are currently one of the main development paradigms in software engineering. However, the Quality of Service (QoS) delivered by these systems remains an important concern, and needs to be managed in an equally adaptive and predictable way. To address this need, we introduce a novel, tool-supported framework for the development of adaptive service-based systems called QoSMOS (QoS Management and Optimization of Service-based systems). QoSMOS can be used to develop service-based systems that achieve their QoS requirements through dynamically adapting to changes in the system state, environment, and workload. QoSMOS service-based systems translate high-level QoS requirements specified by their administrators into probabilistic temporal logic formulae, which are then formally and automatically analyzed to identify and enforce optimal system configurations. The QoSMOS self-adaptation mechanism can handle reliability and performance-related QoS requirements, and can be integrated into newly developed solutions or legacy systems. The effectiveness and scalability of the approach are validated using simulations and a set of experiments based on an implementation of an adaptive service-based system for remote medical assistance.",1939-3520,,10.1109/TSE.2010.92,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611553,Service-oriented software engineering;QoS management;QoS optimization;adaptive systems.,Quality of service;Markov processes;Probabilistic logic;Unified modeling language;Analytical models;Optimization;Scattering,health care;medical computing;optimisation;quality of service;software engineering,QoS management;optimization;service-based systems;software engineering;QoSMOS;remote medical assistance;health care,,185.0,1.0,102.0,,28 Oct 2010,,,IEEE,IEEE Journals
90,90,Assessing the Refactorability of Software Clones,N. Tsantalis; D. Mazinanian; G. P. Krishnan,"Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada",IEEE Transactions on Software Engineering,10 Nov 2015,2015,41,11,1055,1090,"The presence of duplicated code in software systems is significant and several studies have shown that clones can be potentially harmful with respect to the maintainability and evolution of the source code. Despite the significance of the problem, there is still limited support for eliminating software clones through refactoring, because the unification and merging of duplicated code is a very challenging problem, especially when software clones have gone through several modifications after their initial introduction. In this work, we propose an approach for automatically assessing whether a pair of clones can be safely refactored without changing the behavior of the program. In particular, our approach examines if the differences present between the clones can be safely parameterized without causing any side-effects. The evaluation results have shown that the clones assessed as refactorable by our approach can be indeed refactored without causing any compile errors or test failures. Additionally, the computational cost of the proposed approach is negligible (less than a second) in the vast majority of the examined cases. Finally, we perform a large-scale empirical study on over a million clone pairs detected by four different clone detection tools in nine open-source projects to investigate how refactorability is affected by different clone properties and tool configuration options. Among the highlights of our conclusions, we found that (a) clones in production code tend to be more refactorable than clones in test code, (b) clones with a close relative location (i.e., same method, type, or file) tend to be more refactorable than clones in distant locations (i.e., same hierarchy, or unrelated types), (c) Type-1 clones tend to be more refactorable than the other clone types, and (d) clones with a small size tend to be more refactorable than clones with a larger size.",1939-3520,,10.1109/TSE.2015.2448531,European Union (European Social Fund—ESF); Greek national funds through the Operational Program; National Strategic Reference Framework (NSRF); Thalis—Athens University of Economics; Business—Software Engineering Research Platform; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7130676,Code duplication;Software clone management;Clone refactoring;Refactorability assessment;Empirical study;Code duplication;software clone management;clone refactoring;refactorability assessment;empirical study,Cloning;Arrays;Java;Software systems;Production;Space exploration,software maintenance;software management;source code (software),software clone refactorability assessment;duplicated code;software systems;source code evolution;source code maintainability;duplicated code merging;duplicated code unification;compile errors;test failures;computational cost;large-scale empirical;clone pairs;clone detection tools;open-source projects;clone properties;tool configuration;test code;relative location;distant locations;type-1 clones,,31.0,,63.0,,22 Jun 2015,,,IEEE,IEEE Journals
91,91,Evaluating the Effects of Architectural Documentation: A Case Study of a Large Scale Open Source Project,R. Kazman; D. Goldenson; I. Monarch; W. Nichols; G. Valetto,"Software Engineering Institute, Pittsburgh, PA; Software Engineering Institute, Pittsburgh, PA; NA; Software Engineering Institute, Pittsburgh, PA; Distributed Adaptive Systems research unit at Fondazione Bruno Kessler, Italy",IEEE Transactions on Software Engineering,11 Mar 2016,2016,42,3,220,260,"Sustaining large open source development efforts requires recruiting new participants; however, a lack of architectural documentation might inhibit new participants since large amounts of project knowledge are unavailable to newcomers. We present the results of a multitrait, multimethod analysis of the effects of introducing architectural documentation into a substantial open source project-the Hadoop Distributed File System (HDFS). HDFS had only minimal architectural documentation, and we wanted to discover whether the putative benefits of architectural documentation could be observed over time. To do this, we created and publicized an architecture document and then monitored its usage and effects on the project. The results were somewhat ambiguous: by some measures the architecture documentation appeared to effect the project but not by others. Perhaps of equal importance is our discovery that the project maintained, in its Web-accessible JIRA archive of software issues and fixes, enough architectural discussion to support architectural thinking and reasoning. This “emergent” architecture documentation served an important purpose in recording core project members' architectural concerns and resolutions. However, this emergent architecture documentation did not serve all project members equally well; it appears that those on the periphery of the project-newcomers and adopters-still require explicit architecture documentation, as we will show.",1939-3520,,10.1109/TSE.2015.2465387,Department of Defense; Carnegie Mellon University; Software Engineering Institute; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7230299,"software architecture,;open source software,;documentation;Software architecture;open source software;documentation",Documentation;Computer architecture;Social network services;Electronic mail;Measurement;Open source software,distributed databases;public domain software;software architecture,large-scale substantial open source project;architectural documentation;project knowledge;multitrait-multimethod analysis;Hadoop distributed file system;HDFS;Web-accessible JIRA archive;architectural thinking;architectural reasoning;project members,,13.0,,77.0,,31 Aug 2015,,,IEEE,IEEE Journals
92,92,Generating Complete Controllable Test Suites for Distributed Testing,R. M. Hierons,"Department of Computer Science, Brunel University, United Kingdom",IEEE Transactions on Software Engineering,11 Mar 2015,2015,41,3,279,293,"A test suite is m-complete for finite state machine (FSM) M if it distinguishes between M and all faulty FSMs with m states or fewer. While there are several algorithms that generate m-complete test suites, they cannot be directly used in distributed testing since there can be additional controllability and observability problems. Indeed, previous results show that there is no general method for generating an m-complete test suite for distributed testing and so the focus has been on conditions under which this is possible. This paper takes a different approach, which is to generate what we call cm-complete test suites: controllable test suites that distinguish an FSM N with no more than m states from M if this is possible in controllable testing. Thus, under the hypothesis that the system under test has no more than m states, a cm-complete test suite achieves as much as is possible given the restriction that testing should be controllable. We show how the problem of generating a cm-complete test suite can be mapped to the problem of generating an m-complete test suite for a partial FSM. Thus, standard test suite generation methods can be adapted for use in distributed testing.",1939-3520,,10.1109/TSE.2014.2364035,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6930767,Software engineering/software/program verification;software engineering/testing and debugging;systems and software;distributed testing;test suite generation;checking experiment;Software engineering/software/program verification;software engineering/testing and debugging;systems and software;distributed testing;test suite generation;checking experiment,Testing;Controllability;Ports (Computers);Protocols;Automata;Computer architecture;Observability,distributed processing;finite state machines;program debugging;program testing,complete controllable test suite generation;distributed testing;m-complete test suite;finite state machine;faulty FSM;controllability problem;observability problem;cm-complete test suites;controllable testing;system under test;partial-FSM;standard test suite generation methods,,10.0,,49.0,,20 Oct 2014,,,IEEE,IEEE Journals
93,93,The Value of Doubt,G. J. Holzmann,Jet Propulsion Laboratory,IEEE Software,16 Jan 2017,2017,34,1,106,109,"Doubt is key to becoming a good programmer. If you don't doubt the correctness of your work, you have no incentive to look for the hidden spoilers that are always there.",1937-4194,,10.1109/MS.2017.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819389,debugging;software bugs;Morris worm;secure software;software development;software engineering,Computer bugs;Debugging;Software reliability;Computer security;Software testing,software engineering,doubt value;software engineering,,2.0,,3.0,,16 Jan 2017,,,IEEE,IEEE Magazines
94,94,Point/Counterpoint,D. L. Parnas; B. Curtis,Middle Road Software; Cast Software,IEEE Software,16 Oct 2009,2009,26,6,56,59,"The need for empirical research into the practicality and efficacy of software development methods is obvious but most published papers have inadequate experimental design. The assumption that what programmers do is ""natural,"" and somehow right or practical, needs to be questioned seriously. Human beings haven't evolved by natural selection to be good programmers. There are people alive today who worked on the first electronic computers. Further, almost all of today's programmers learned from earlier programmers; either they were explicitly taught or they observed how the programmers that preceded them had done their work. If those pioneers were wrong, the methods that we now perceive as natural or intuitive will also be wrong. We can't simply conclude that what we observe in projects today is the best way to do something.",1937-4194,,10.1109/MS.2009.184,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287010,empirical research;software engineering;analysis;independent variables;controlled experiments;exploratory observational studies,Programming profession;Design for experiments;Humans,software engineering,software engineering;software development;experimental design;natural selection;electronic computer,,6.0,,6.0,,16 Oct 2009,,,IEEE,IEEE Magazines
95,95,Vulnerability Discovery with Attack Injection,J. Antunes; N. Neves; M. Correia; P. Verissimo; R. Neves,"University of Lisboa, Lisboa; University of Lisboa, Lisboa; University of Lisboa, Lisboa; University of Lisboa, Lisboa; Technical University of Lisbon, Lisboa",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,357,370,"The increasing reliance put on networked computer systems demands higher levels of dependability. This is even more relevant as new threats and forms of attack are constantly being revealed, compromising the security of systems. This paper addresses this problem by presenting an attack injection methodology for the automatic discovery of vulnerabilities in software components. The proposed methodology, implemented in AJECT, follows an approach similar to hackers and security analysts to discover vulnerabilities in network-connected servers. AJECT uses a specification of the server's communication protocol and predefined test case generation algorithms to automatically create a large number of attacks. Then, while it injects these attacks through the network, it monitors the execution of the server in the target system and the responses returned to the clients. The observation of an unexpected behavior suggests the presence of a vulnerability that was triggered by some particular attack (or group of attacks). This attack can then be used to reproduce the anomaly and to assist the removal of the error. To assess the usefulness of this approach, several attack injection campaigns were performed with 16 publicly available POP and IMAP servers. The results show that AJECT could effectively be used to locate vulnerabilities, even on well-known servers tested throughout the years.",1939-3520,,10.1109/TSE.2009.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374427,Testing and debugging;software engineering;test design;testing tools;experimental evaluation;fault injection;attack injection.,Network servers;Software testing;Protocols;Debugging;Application software;Computer networks;Computer hacking;Communication system security;Automatic testing;Software engineering,computer crime;software engineering,vulnerability discovery;attack injection;networked computer systems;software components;security analysts;hackers analysts;AJECT;IMAP servers;POP servers,,24.0,1.0,33.0,,8 Jan 2010,,,IEEE,IEEE Journals
96,96,Introducing the Pragmatic Architect,F. Buschmann,Siemens Corporate Technology,IEEE Software,25 Aug 2009,2009,26,5,10,11,"This paper present the software architecture, design, and development-but through the eyes of a practicing software architect. From such a perspective, software engineering can appear surprisingly different. This is what's new about this column and what you'll hopefully enjoy-a fresh, new light on the practices and state-of-the-art of the profession.",1937-4194,,10.1109/MS.2009.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222785,software architect;software architecture;software engineering,Computer architecture;Software architecture;Software engineering;Books;Business communication;Design methodology;Publishing;Large-scale systems;Computer industry;Manufacturing automation,software architecture,pragmatic architect;software architecture;software development;software engineering;software architect,,5.0,,5.0,,25 Aug 2009,,,IEEE,IEEE Magazines
97,97,Voice Of Evidence: A look back,F. Shull; T. Dybå; H. Sharp; R. Prikladnicki,"Carnegie Mellon University's Software Engineering Institute; SINTEF Digital; The Open University, Milton Keynes; Pontifícia Universidade Católica do Rio Grande do Sul",IEEE Software,11 Jul 2017,2017,34,4,23,25,"To celebrate the 200th issue of IEEE Software, Voice of Evidence uses data to examine whether it has helped bridge the gap between research and practice by extracting actionable lessons from the body of research.",1937-4194,,10.1109/MS.2017.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974677,Voice of Evidence;software development;software engineering,Research and development;Software engineering;Bibliometrics,,,,1.0,,,,11 Jul 2017,,,IEEE,IEEE Magazines
98,98,Toward Agile Architecture: Insights from 15 Years of ATAM Data,S. Bellomo; I. Gorton; R. Kazman,Software Engineering Institute; Software Engineering Institute; Software Engineering Institute,IEEE Software,21 Aug 2015,2015,32,5,38,45,"Agile teams strive to balance short-term feature development with longer-term quality concerns. These evolutionary approaches often hit a ""complexity wall""' from the cumulative effects of unplanned changes, resulting in unreliable, poorly performing software. So, the agile community is refocusing on approaches to address architectural concerns. Researchers analyzed quality attribute concerns from 15 years of Architecture Trade-Off Analysis Method data, gathered from 31 projects. Modifiability was the dominant concern across all project types; performance, availability, and interoperability also received considerable attention. For IT projects, a relatively new quality-deployability-emerged as a key concern. The study results provide insights for agile teams allocating architecture-related tasks to iterations. For example, teams can use these results to create checklists for release planning or retrospectives to help assess whether to address a given quality to support future needs. This article is part of a special issue on Software Architecture.",1937-4194,,10.1109/MS.2015.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7024074,architecture evaluation;agile;technical debt;incremental development;modifiability;availability;interoperability;deployability;software development;software engineering,Computer architecture;Software architecture;Software development;Complexity theory;Interoperability;Software engineering;Encoding,open systems;software architecture;software performance evaluation;software prototyping;software reliability,agile architecture;ATAM data;agile teams;short-term feature development;longer-term quality concerns;complexity wall;agile community;architecture trade-off analysis method data;interoperability;availability;IT projects;architecture-related task allocation;software architecture,,20.0,,11.0,,27 Jan 2015,,,IEEE,IEEE Magazines
99,99,Building Pipelines for Heterogeneous Execution Environments for Big Data Processing,D. Wu; L. Zhu; X. Xu; S. Sakr; D. Sun; Q. Lu,NICTA; NICTA; NICTA; NICTA; NICTA; NICTA,IEEE Software,26 Feb 2016,2016,33,2,60,67,"Many real-world data analysis scenarios require pipelining and integration of multiple (big) data-processing and data-analytics jobs, which often execute in heterogeneous environments, such as MapReduce; Spark; or R, Python, or Bash scripts. Such a pipeline requires much glue code to get data across environments. Maintaining and evolving these pipelines are difficult. Pipeline frameworks that try to solve such problems are usually built on top of a single environment. They might require rewriting the original job to take into account a new API or paradigm. The Pipeline61 framework supports the building of data pipelines involving heterogeneous execution environments. It reuses the existing code of the deployed jobs in different environments and provides version control and dependency management that deals with typical software engineering issues. A real-world case study shows its effectiveness. This article is part of a special issue on Software Engineering for Big Data Systems.",1937-4194,,10.1109/MS.2016.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420521,big data;pipeline;Spark;MapReduce;software engineering;software development;Pipeline61,Big data;Pipeline processing;Software engineering;Context modeling;Data analysis;Programming;Software development,application program interfaces;Big Data;data analysis;pipeline processing;software engineering,software engineering;data pipeline;API;glue code;data-analytics;multiple Big data-processing;real-world data analysis;heterogeneous execution environment,,21.0,,1.0,,26 Feb 2016,,,IEEE,IEEE Magazines
100,100,Evaluation of Accuracy in Design Pattern Occurrence Detection,N. Pettersson; W. Löwe; J. Nivre,"Växjö University, Växjö; Växjö University, Växjö; Växjö University, Växjö",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,575,590,"Detection of design pattern occurrences is part of several solutions to software engineering problems, and high accuracy of detection is important to help solve the actual problems. The improvement in accuracy of design pattern occurrence detection requires some way of evaluating various approaches. Currently, there are several different methods used in the community to evaluate accuracy. We show that these differences may greatly influence the accuracy results, which makes it nearly impossible to compare the quality of different techniques. We propose a benchmark suite to improve the situation and a community effort to contribute to, and evolve, the benchmark suite. Also, we propose fine-grained metrics assessing the accuracy of various approaches in the benchmark suite. This allows comparing the detection techniques and helps improve the accuracy of detecting design pattern occurrences.",1939-3520,,10.1109/TSE.2009.92,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374428,Patterns;object-oriented design methods;measurement techniques;evaluation;reverse engineering;reengineering;restructuring.,Design methodology;Software systems;Computer science;Natural languages;Software engineering;Measurement techniques;Reverse engineering;Software tools;Application software;Software quality,object-oriented methods;software engineering;software metrics;software performance evaluation,design pattern occurrence detection;software engineering problem;fine grained metric;benchmark suite,,39.0,,47.0,,8 Jan 2010,,,IEEE,IEEE Journals
101,101,"Assessing, Comparing, and Combining State Machine-Based Testing and Structural Testing: A Series of Experiments",S. Mouchawrab; L. C. Briand; Y. Labiche; M. Di Penta,"Carleton University, Ottawa, Canada; Simula Research Laboratory, Lysaker, Norway; Carleton University, Ottawa, Canada; University of Sannio, Benevento, Italy",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,161,187,"A large number of research works have addressed the importance of models in software engineering. However, the adoption of model-based techniques in software organizations is limited since these models are perceived to be expensive and not necessarily cost-effective. Focusing on model-based testing, this paper reports on a series of controlled experiments. It investigates the impact of state machine testing on fault detection in class clusters and its cost when compared with structural testing. Based on previous work showing this is a good compromise in terms of cost and effectiveness, this paper focuses on a specific state-based technique: the round-trip paths coverage criterion. Round-trip paths testing is compared to structural testing, and it is investigated whether they are complementary. Results show that even when a state machine models the behavior of the cluster under test as accurately as possible, no significant difference between the fault detection effectiveness of the two test strategies is observed, while the two test strategies are significantly more effective when combined by augmenting state machine testing with structural testing. A qualitative analysis also investigates the reasons why test techniques do not detect certain faults and how the cost of state machine testing can be brought down.",1939-3520,,10.1109/TSE.2010.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416729,State-based software testing;structural testing;controlled experiments;state machines.,Object oriented modeling;Costs;Fault detection;Unified modeling language;System testing;Software testing;Automatic testing;Software engineering;Software design;Logic testing,fault tolerant computing;finite state machines;program testing;software engineering,state machine based testing;software engineering;model based techniques;software organizations;fault detection;round trip paths testing;structural testing,,46.0,,69.0,,18 Feb 2010,,,IEEE,IEEE Journals
102,102,Dealing with Traceability in the MDDof Model Transformations,J. M. Vara; V. A. Bollati; Á. Jiménez; E. Marcos,"Computing Languages and Systems - II, University Rey Juan Carlos, Mostoles, Madrid, Spain; Computing Languages and Systems - II, University Rey Juan Carlos, Mostoles, Madrid, Spain; Computing Languages and Systems - II, University Rey Juan Carlos, Mostoles, Madrid, Spain; Computing Languages and Systems - II, University Rey Juan Carlos, Mostoles, Madrid, Spain",IEEE Transactions on Software Engineering,17 Jun 2014,2014,40,6,555,583,"Traceability has always been acknowledged as a relevant topic in Software Engineering. However, keeping track of the relationships between the different assets involved in a development process is a complex and tedious task. The fact that the main assets handled in any model-driven engineering project are models and model transformations eases the task. In order to take advantage of this scenario, which has not been appropriately capitalized on by the most widely adopted model transformation languages before, this work presents MeTAGeM-Trace, a methodological and technical proposal with which to support the model-driven development of model transformations that include trace generation. The underlying idea is to start from a high-level specification of the transformation which is subsequently refined into lower-level transformation models in terms of a set of DSLs until the source code that implements the transformation can be generated. Running this transformation produces not only the corresponding target models, but also a trace model between the elements of the source and target models. As part of the proposal, an EMF-based toolkit has been developed to support the development of ATL and ETL model transformations. This toolkit has been empirically validated by conducting a set of case studies following a systematic research methodology.",1939-3520,,10.1109/TSE.2014.2316132,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784505,Model-driven engineering;model transformations;traceability,Proposals;Object oriented modeling;Software;DSL;Complexity theory;Data models;Software engineering,research and development;software engineering;source code (software),MDD;traceability;software engineering;model-driven engineering project;model transformation languages;MeTAGeM-Trace;trace generation;lower-level transformation models;DSL;source code;EMF-based toolkit;ATL model transformations;ETL model transformations;systematic research methodology,,13.0,,79.0,,8 Apr 2014,,,IEEE,IEEE Journals
103,103,"Interactive, Evolutionary Search in Upstream Object-Oriented Class Design",C. L. Simons; I. C. Parmee; R. Gwynllyw,"University of the West of England, Frenchay; University of the West of England, Frenchay; University of the West of England, Frenchay",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,798,816,"Although much evidence exists to suggest that early life cycle software engineering design is a difficult task for software engineers to perform, current computational tool support for software engineers is limited. To address this limitation, interactive search-based approaches using evolutionary computation and software agents are investigated in experimental upstream design episodes for two example design domains. Results show that interactive evolutionary search, supported by software agents, appears highly promising. As an open system, search is steered jointly by designer preferences and software agents. Directly traceable to the design problem domain, a mass of useful and interesting class designs is arrived at which may be visualized by the designer with quantitative measures of structural integrity, such as design coupling and class cohesion. The class designs are found to be of equivalent or better coupling and cohesion when compared to a manual class design for the example design domains, and by exploiting concurrent execution, the runtime performance of the software agents is highly favorable.",1939-3520,,10.1109/TSE.2010.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432223,Software design;evolutionary computation;interactive search.,Software agents;Software design;Software performance;Software tools;Design engineering;Software engineering;Evolutionary computation;Open systems;Visualization;Runtime,evolutionary computation;interactive systems;object-oriented methods;open systems;search problems;software agents;software engineering,upstream object oriented class design;life cycle software engineering design;software agent;interactive evolutionary search;open system;design problem domain;structural integrity;concurrent execution;runtime performance,,50.0,2.0,66.0,,18 Mar 2010,,,IEEE,IEEE Journals
104,104,Extending the UML Statecharts Notation to Model Security Aspects,M. El-Attar; H. Luqman; P. Kárpáti; G. Sindre; A. L. Opdahl,"Information and Computer Science Department, King Fahd University of Petroleum and Minerals, Dhahran, Kingdom of Saudi Arabia; Information and Computer Science Department, King Fahd University of Petroleum and Minerals, Dhahran, Kingdom of Saudi Arabia; Institute for Energy Technology, Halden, Norway; Department of Computer and Information Science, Norwegian University of Science and Technology, Trondheim, Norway; Department of Information Science and Media, University of Bergen, Bergen, Norway",IEEE Transactions on Software Engineering,14 Jul 2015,2015,41,7,661,690,"Model driven security has become an active area of research during the past decade. While many research works have contributed significantly to this objective by extending popular modeling notations to model security aspects, there has been little modeling support for state-based views of security issues. This paper undertakes a scientific approach to propose a new notational set that extends the UML (Unified Modeling Language) statecharts notation. An online industrial survey was conducted to measure the perceptions of the new notation with respect to its semantic transparency as well as its coverage of modeling state based security aspects. The survey results indicate that the new notation encompasses the set of semantics required in a state based security modeling language and was largely intuitive to use and understand provided very little training. A subject-based empirical evaluation using software engineering professionals was also conducted to evaluate the cognitive effectiveness of the proposed notation. The main finding was that the new notation is cognitively more effective than the original notational set of UML statecharts as it allowed the subjects to read models created using the new notation much quicker.",1939-3520,,10.1109/TSE.2015.2396526,Deanship of Scientific Research; King Fahd University of Petroleum and Minerals; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7042284,Statecharts;Security Modeling;Extended Notation;Industrial Survey;Subject-Based Experiment;Statecharts;security modeling;extended notation;industrial survey;subject-based experiment,Unified modeling language;Security;Software engineering;Object oriented modeling;Semantics;Proposals;Educational institutions,security of data;software engineering;Unified Modeling Language,UML statecharts notation;model driven security;scientific approach;Unified Modeling Language statecharts notation;semantic transparency;modeling state based security aspect coverage;state based security modeling language;subject-based empirical evaluation;software engineering professionals;notation cognitive effectiveness,,13.0,,80.0,,13 Feb 2015,,,IEEE,IEEE Journals
105,105,Patterns in Effective Distributed Software Development,R. Prikladnicki; J. L. N. Audy; F. Shull,"Pontifícia Universidade do Rio Grande do Sul; Pontifícia Universidade do Rio Grande do Sul; Fraunhofer Center for Experimental Software Engineering, Maryland",IEEE Software,25 Feb 2010,2010,27,2,12,15,"As with many other industries today, software development must increasingly adapt to teams whose members work together but are geographically distributed. Many factors have contributed to this rise in distributed software development (DSD), including companies' desires to leverage skilled resources wherever they can be found and to reduce costs by working in different labor markets. Its increasing popularity has led to diverse industrial experience, which has in turn led to some best practices and an initial body of knowledge.",1937-4194,,10.1109/MS.2010.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420790,software development;offshoring,Programming;Computer industry;Costs;Best practices,software engineering,distributed software development;organizations;software engineering;software patterns;geographically distributed team members;labor markets,,19.0,,19.0,,25 Feb 2010,,,IEEE,IEEE Magazines
106,106,Self-Supervising BPEL Processes,L. Baresi; S. Guinea,"Politecnico di Milano, Milano, Italy; Politecnico di Milano, Milano, Italy",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,247,263,"Service compositions suffer changes in their partner services. Even if the composition does not change, its behavior may evolve over time and become incorrect. Such changes cannot be fully foreseen through prerelease validation, but impose a shift in the quality assessment activities. Provided functionality and quality of service must be continuously probed while the application executes, and the application itself must be able to take corrective actions to preserve its dependability and robustness. We propose the idea of self-supervising BPEL processes, that is, special-purpose compositions that assess their behavior and react through user-defined rules. Supervision consists of monitoring and recovery. The former checks the system's execution to see whether everything is proceeding as planned, while the latter attempts to fix any anomalies. The paper introduces two languages for defining monitoring and recovery and explains how to use them to enrich BPEL processes with self-supervision capabilities. Supervision is treated as a cross-cutting concern that is only blended at runtime, allowing different stakeholders to adopt different strategies with no impact on the actual business logic. The paper also presents a supervision-aware runtime framework for executing the enriched processes, and briefly discusses the results of in-lab experiments and of a first evaluation with industrial partners.",1939-3520,,10.1109/TSE.2010.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432226,Software engineering;software/program verification;assertion checkers;assertion languages;performance;design tools and techniques;distributed/Internet-based software engineering tools and techniques.,Runtime;Monitoring;Robustness;Software engineering;Application software;Quality assessment;Quality of service;Logic;Software performance;Software tools,business process re-engineering;program verification;service-oriented architecture;Web services,self supervising BPEL process;quality assessment;stakeholder;business logic;supervision aware runtime framework;industrial partner;business process execution language,,73.0,,41.0,,18 Mar 2010,,,IEEE,IEEE Journals
107,107,Learning Communicating Automata from MSCs,B. Bollig; J. Katoen; C. Kern; M. Leucker,"ENS Cachan and CNRS, Cachan; RWTH Aachen University, Aachen; RWTH Aachen University, Aachen; Technical University Munich, Munich",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,390,408,"This paper is concerned with bridging the gap between requirements and distributed systems. Requirements are defined as basic message sequence charts (MSCs) specifying positive and negative scenarios. Communicating finite-state machines (CFMs), i.e., finite automata that communicate via FIFO buffers, act as system realizations. The key contribution is a generalization of Angluin's learning algorithm for synthesizing CFMs from MSCs. This approach is exact-the resulting CFM precisely accepts the set of positive scenarios and rejects all negative ones-and yields fully asynchronous implementations. The paper investigates for which classes of MSC languages CFMs can be learned, presents an optimization technique for learning partial orders, and provides substantial empirical evidence indicating the practical feasibility of the approach.",1939-3520,,10.1109/TSE.2009.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374425,Software engineering/requirements/specifications/elicitation methods;software engineering/design/design concepts;computing methodologies/artificial intelligence/learning/induction;theory of computation/computation by abstract devices/models of computation/automata.,Learning automata;Software engineering;Software design;Unified modeling language;Communication channels;System recovery;Computer Society;Design engineering;Design methodology;Artificial intelligence,distributed processing;finite state machines;learning (artificial intelligence),communicating automata;MSC;message sequence charts;distributed systems;communicating finite-state machines;finite automata;FIFO buffers;Angluin learning algorithm;optimization technique,,13.0,,41.0,,8 Jan 2010,,,IEEE,IEEE Journals
108,108,How Developers' Experience and Ability Influence Web Application Comprehension Tasks Supported by UML Stereotypes: A Series of Four Experiments,F. Ricca; M. Di Penta; M. Torchiano; P. Tonella; M. Ceccato,"University of Genova, Italy; University of Sannio, Benevento; Politecnico di Torino, Torino; Fondazione Bruno Kessler, Trento; Fondazione Bruno Kessler, Trento",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,96,118,"In recent years, several design notations have been proposed to model domain-specific applications or reference architectures. In particular, Conallen has proposed the UML Web Application Extension (WAE): a UML extension to model Web applications. The aim of our empirical investigation is to test whether the usage of the Conallen notation supports comprehension and maintenance activities with significant benefits, and whether such benefits depend on developers ability and experience. This paper reports and discusses the results of a series of four experiments performed in different locations and with subjects possessing different experience-namely, undergraduate students, graduate students, and research associates-and different ability levels. The experiments aim at comparing performances of subjects in comprehension tasks where they have the source code complemented either by standard UML diagrams or by diagrams stereotyped using the Conallen notation. Results indicate that, although, in general, it is not possible to observe any significant benefit associated with the usage of stereotyped diagrams, the availability of stereotypes reduces the gap between subjects with low skill or experience and highly skilled or experienced subjects. Results suggest that organizations employing developers with low experience can achieve a significant performance improvement by adopting stereotyped UML diagrams for Web applications.",1939-3520,,10.1109/TSE.2009.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332231,Documentation;maintenance;and enhancement;software engineering;software/software engineering.,Unified modeling language;Application software;Object oriented modeling;Software maintenance;Web pages;Software engineering;Computer Society;Computer architecture;Service oriented architecture;Testing,Internet;Unified Modeling Language,Web application comprehension tasks;UML stereotypes;source code;stereotyped diagrams,,52.0,,34.0,,13 Nov 2009,,,IEEE,IEEE Journals
109,109,Oracles for Distributed Testing,R. M. Hierons,"Brunel University, Middlesex",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,629,641,"The problem of deciding whether an observed behavior is acceptable is the oracle problem. When testing from a finite state machine (FSM), it is easy to solve the oracle problem and so it has received relatively little attention for FSMs. However, if the system under test has physically distributed interfaces, called ports, then in distributed testing, we observe a local trace at each port and we compare the set of local traces with the set of allowed behaviors (global traces). This paper investigates the oracle problem for deterministic and nondeterministic FSMs and for two alternative definitions of conformance for distributed testing. We show that the oracle problem can be solved in polynomial time for the weaker notion of conformance (⊆w) but is NP-hard for the stronger notion of conformance (⊆), even if the FSM is deterministic. However, when testing from a deterministic FSM with controllable input sequences, the oracle problem can be solved in polynomial time and similar results hold for nondeterministic FSMs. Thus, in some cases, the oracle problem can be efficiently solved when using ⊆s and where this is not the case, we can use the decision procedure for ⊆w as a sound approximation.",1939-3520,,10.1109/TSE.2011.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750006,Software engineering/software/program verification;software engineering/testing and debugging;systems and software;distributed systems;finite state machine;nondeterminism;test oracle;controllability;local observability.,Testing;Controllability;Observability;Polynomials;Software;Software engineering,distributed processing;finite state machines;polynomials;program testing,distributed testing;oracle problem;finite state machine;FSM;physically distributed interfaces;polynomial time;weaker notion;NP-hard problem;sound approximation;decision procedure,,24.0,,37.0,,15 Apr 2011,,,IEEE,IEEE Journals
110,110,Frameworks Generate Domain-Specific Languages: A Case Study in the Multimedia Domain,X. Amatriain; P. Arumi,"Telefonica Research, Barcelona, Spain; Universitat Pompeu Fabra, Barcelona, Spain",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,544,558,"We present an approach to software framework development that includes the generation of domain-specific languages (DSLs) and pattern languages as goals for the process. Our model is made of three workflows-framework, metamodel, and patterns-and three phases-inception, construction, and formalization. The main conclusion is that when developing a framework, we can produce with minimal overhead-almost as a side effect-a metamodel with an associated DSL and a pattern language. Both outputs will not only help the framework evolve in the right direction, but will also be valuable in themselves. In order to illustrate these ideas, we present a case study in the multimedia domain. For several years, we have been developing a multimedia framework. The process has produced a full-fledged domain-specific metamodel for the multimedia domain, with an associated DSL and a pattern language.",1939-3520,,10.1109/TSE.2010.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5441292,Domain-specific architectures;visual programming;life cycle;CASE.,Domain specific languages;DSL;Unified modeling language;Vocabulary;Concrete;Software engineering;Computer aided software engineering;Natural languages;Metamodeling;Best practices,multimedia computing;software engineering;specification languages;visual programming,domain-specific languages;multimedia domain;pattern languages;domain-specific metamodel;associated DSL;visual programming;software framework development,,8.0,,37.0,,1 Apr 2010,,,IEEE,IEEE Journals
111,111,Self-Organizing Roles on Agile Software Development Teams,R. Hoda; J. Noble; S. Marshall,"The University of Auckland, Auckland; Victoria University of Wellington, Wellington; Victoria University of Wellington, Wellington",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,422,444,"Self-organizing teams have been recognized and studied in various forms-as autonomous groups in socio-technical systems, enablers of organizational theories, agents of knowledge management, and as examples of complex-adaptive systems. Over the last decade, self-organizing teams have taken center stage in software engineering when they were incorporated as a hallmark of Agile methods. Despite the long and rich history of self-organizing teams and their recent popularity with Agile methods, there has been little research on the topic within software wngineering. Particularly, there is a dearth of research on how Agile teams organize themselves in practice. Through a Grounded Theory research involving 58 Agile practitioners from 23 software organizations in New Zealand and India over a period of four years, we identified informal, implicit, transient, and spontaneous roles that make Agile teams self-organizing. These roles-Mentor, Coordinator, Translator, Champion, Promoter, and Terminator-are focused toward providing initial guidance and encouraging continued adherence to Agile methods, effectively managing customer expectations and coordinating customer collaboration, securing and sustaining senior management support, and identifying and removing team members threatening the self-organizing ability of the team. Understanding these roles will help software development teams and their managers better comprehend and execute their roles and responsibilities as a self-organizing team.",1939-3520,,10.1109/TSE.2012.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197202,Self-organizing;team roles;software engineering;Agile software development;grounded theory,Programming;Organizations;Collaboration;Software;Organizing;Software engineering,knowledge management;software management;software prototyping;team working,self-organizing roles;agile software development teams;self-organizing teams;autonomous groups;socio-technical systems;organizational theories enablers;knowledge management agents;complex-adaptive system examples;software engineering;grounded theory research;New Zealand;India;mentor role;coordinator role;translator role;champion role;promoter role;terminator role;customer expectation management;customer collaboration coordination;senior management support security;senior management support sustainability,,92.0,,115.0,,8 May 2012,,,IEEE,IEEE Journals
112,112,What Do We Know about the Effectiveness of Software Design Patterns?,C. Zhang; D. Budgen,"Durham University, Durham; Durham University, Durham",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1213,1231,"Context. Although research in software engineering largely seeks to improve the practices and products of software development, many practices are based upon codification of expert knowledge, often with little or no underpinning from objective empirical evidence. Software design patterns seek to codify expert knowledge to share experience about successful design structures. Objectives. To investigate how extensively the use of software design patterns has been subjected to empirical study and what evidence is available about how and when their use can provide an effective mechanism for knowledge transfer about design. Method. We conducted a systematic literature review in the form of a mapping study, searching the literature up to the end of 2009 to identify relevant primary studies about the use of the 23 patterns catalogued in the widely referenced book by the “Gang of Four.” These studies were then categorized according to the forms of study employed, the patterns that were studied, as well as the context within which the study took place. Results. Our searches identified 611 candidate papers. Applying our inclusion/exclusion criteria resulted in a final set of 10 papers that described 11 instances of “formal” experimental studies of object-oriented design patterns. We augmented our analysis by including seven “experience” reports that described application of patterns using less rigorous observational forms. We report and review the profiles of the empirical evidence for those patterns for which multiple studies exist. Conclusions. We could not identify firm support for any of the claims made for patterns in general, although there was some support for the usefulness of patterns in providing a framework for maintenance, and some qualitative indication that they do not help novices learn about design. For future studies we recommend that researchers use case studies that focus upon some key patterns, and seek to identify the impact that their use can have upon maintenance.",1939-3520,,10.1109/TSE.2011.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975176,Design patterns;systematic literature review;empirical software engineering,Software engineering;Software design;Systematics;Search engines;Terminology;Maintenance engineering,object-oriented programming;software maintenance,software design patterns;software engineering;software development;design structures;knowledge transfer;Gang-of-Four;object-oriented design patterns,,46.0,,66.0,,4 Aug 2011,,,IEEE,IEEE Journals
113,113,Technology Transfer: A Software Security Marketplace Case Study,G. McGraw,Cigital,IEEE Software,18 Aug 2011,2011,28,5,9,11,"This paper presents the software security (application security) solutions. It is an idea of engineering software so that it continues to function correctly under malicious attack. Although as a discipline software security is relatively young, much progress has been made on ways to integrate security best practices into the software development life cycle. Microsoft, for example, has helped spearhead soft ware security through its Trustworthy Computing Initiative and the resulting Security Development Lifecycle (SDL). Cigital has also been instrumental in bringing software security to the wider market through its professional services.",1937-4194,,10.1109/MS.2011.110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984788,code review;technology transfer;software security,Computer security;Technology transfer;Software engineering;Best practices,security of data;software engineering;technology transfer,software security;computer security;software engineering;malicious attack;software development life cycle;Microsoft;trustworthy computing initiative;Cigital;technology transfer,,1.0,,2.0,,18 Aug 2011,,,IEEE,IEEE Magazines
114,114,Facilitating Coordination between Software Developers: A Study and Techniques for Timely and Efficient Recommendations,K. Blincoe; G. Valetto; D. Damian,"Software Engineering Global Interaction Lab, Victoria, BC, Canada; Fondazione Bruno Kessler, Trento, Italy; Software Engineering Global Interaction Lab, Victoria, BC, Canada",IEEE Transactions on Software Engineering,13 Oct 2015,2015,41,10,969,985,"When software developers fail to coordinate, build failures, duplication of work, schedule slips and software defects can result. However, developers are often unaware of when they need to coordinate, and existing methods and tools that help make developers aware of their coordination needs do not provide timely or efficient recommendations. We describe our techniques to identify timely and efficient coordination recommendations, which we developed and evaluated in a study of coordination needs in the Mylyn software project. We describe how data obtained from tools that capture developer actions within their Integrated Development Environment (IDE) as they occur can be used to timely identify coordination needs; we also describe how properties of tasks coupled with machine learning can focus coordination recommendations to those that are more critical to the developers to reduce information overload and provide more efficient recommendations. We motivate our techniques through developer interviews and report on our quantitative analysis of coordination needs in the Mylyn project. Our results suggest that by leveraging IDE logging facilities, properties of tasks and machine learning techniques awareness tools could make developers aware of critical coordination needs in a timely way. We conclude by discussing implications for software engineering research and tool design.",1939-3520,,10.1109/TSE.2015.2431680,US National Science Foundation (NSF); NECSIS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105409,Human Factors in Software Design;Management;Metrics/Measurement;Productivity;Programming Teams;Computer-supported cooperative work;human factors in software design;management;metrics/measurement;productivity;programming teams,Software;Encoding;Interviews;Statistical analysis;Manuals;Accuracy;Correlation,groupware;learning (artificial intelligence);programming environments;project management;software tools,software developers;coordination recommendation;Mylyn software project;integrated development environment;coordination needs quantitative analysis;IDE logging facilities;task properties;machine learning technique awareness tools;software engineering research;tool design,,10.0,,70.0,,11 May 2015,,,IEEE,IEEE Journals
115,115,Test-Driven Development for Spreadsheet Risk Management,K. McDaid; A. Rust,"Dundalk Institute of Technology, Ireland; Dundalk Institute of Technology, Ireland",IEEE Software,25 Aug 2009,2009,26,5,31,36,"Spreadsheet technology is central to the functioning of the financial sector, but the spreadsheets themselves can have a high level of error that requires innovative supporting processes and tools. Several large-scale international studies conducted in response to the Enron-inspired Sarbanes-Oxley Act confirm the importance and complexity of spreadsheet systems in financial reporting, with some companies using 200+ spreadsheets in manually controlled interconnected ""webs."" Unfortunately, spreadsheets frequently have an unacceptably high number of faults. Early research indicated that between 2 and 5 percent of cell formulas can be incorrect, but a more recent study found that of 50 real-world operational spreadsheets audited, 94 percent contained errors with almost 1 percent of formula cells found to be incorrect. Spreadsheet developers don't appreciate this high risk and thus use little or no formal software development processes.",1937-4194,,10.1109/MS.2009.143,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222791,end-user software engineering;spreadsheets;office automation;information technology and systems applications;IT and systems;testing and debugging;software engineering,Risk management;Inventory management;Environmental management;Financial management;Project management;Protection;Control systems;Software testing;Software engineering;Counting circuits,company reports;financial data processing;legislation;program testing;risk management;software engineering;spreadsheet programs,test-driven development;spreadsheet system risk management technology;financial reporting sector;innovative tool;large-scale international study;Enron-inspired Sarbanes-Oxley Act;cell formula error;formal software development process;spreadsheet fault,,2.0,,15.0,,25 Aug 2009,,,IEEE,IEEE Magazines
116,116,Software Analytics in Practice,D. Zhang; S. Han; Y. Dang; J. Lou; H. Zhang; T. Xie,Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; Microsoft Research Asia; University of Illinois at Urbana-Champaign,IEEE Software,3 Sep 2013,2013,30,5,30,37,"With software analytics, software practitioners explore and analyze data to obtain insightful, actionable information for tasks regarding software development, systems, and users. The StackMine project produced a software analytics system for Microsoft product teams. The project provided lessons on applying software analytics technologies to positively impact software development practice. The lessons include focusing on problems that practitioners care about, using domain knowledge for correct data understanding and problem modeling, building prototypes early to get practitioners' feedback, taking into account scalability and customizability, and evaluating analysis results using criteria related to real tasks.",1937-4194,,10.1109/MS.2013.94,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6559957,Algorithm design and analysis;Software systems;Data mining;Performance analysis;Debugging;Software analytics;Software engineering;software engineering;software analytics;mining software repositories;technology transfer;StackMine;data exploration;software artifacts;insightful information;actionable information,Algorithm design and analysis;Software systems;Data mining;Performance analysis;Debugging;Software analytics;Software engineering,data analysis;software engineering,software analytics technology;data exploration;data analysis;StackMine project;Microsoft product team;software development practice;domain knowledge;data understanding;problem modeling;data scalability;data customizability,,47.0,,13.0,,16 Jul 2013,,,IEEE,IEEE Magazines
117,117,Model-Based Self-Aware Performance and Resource Management Using the Descartes Modeling Language,N. Huber; F. Brosig; S. Spinner; S. Kounev; M. Bähr,"Department of Computer Science, Chair of Software Engineering, University of Würzburg, Würzburg, Germany; Department of Computer Science, Chair of Software Engineering, University of Würzburg, Würzburg, Germany; Department of Computer Science, Chair of Software Engineering, University of Würzburg, Würzburg, Germany; Department of Computer Science, Chair of Software Engineering, University of Würzburg, Würzburg, Germany; Blue Yonder GmbH & Co. KG., Karlsruhe, Germany",IEEE Transactions on Software Engineering,12 May 2017,2017,43,5,432,452,"Modern IT systems have increasingly distributed and dynamic architectures providing flexibility to adapt to changes in the environment and thus enabling higher resource efficiency. However, these benefits come at the cost of higher system complexity and dynamics. Thus, engineering systems that manage their end-to-end application performance and resource efficiency in an autonomic manner is a challenge. In this article, we present a holistic model-based approach for self-aware performance and resource management leveraging the Descartes Modeling Language (DML), an architecture-level modeling language for online performance and resource management. We propose a novel online performance prediction process that dynamically tailors the model solving depending on the requirements regarding accuracy and overhead. Using these prediction capabilities, we implement a generic model-based control loop for proactive system adaptation. We evaluate our model-based approach in the context of two representative case studies showing that with the proposed methods, significant resource efficiency gains can be achieved while maintaining performance requirements. These results represent the first end-to-end validation of our approach, demonstrating its potential for self-aware performance and resource management in the context of modern IT systems and infrastructures.",1939-3520,,10.1109/TSE.2016.2613863,Deutsche Forschungsgemeinschaft (DFG); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577879,Autonomic;self-aware;adaptation;model-based;modeling language;performance;efficiency,Adaptation models;Resource management;Computer architecture;Predictive models;Unified modeling language;Software;Dynamic scheduling,software architecture;software performance evaluation,model-based self-aware performance;resource management;Descartes modeling language;IT systems;dynamic architectures;distributed architectures;system complexity;engineering systems;end-to-end application performance;resource efficiency;holistic model-based approach;DML;architecture-level modeling language;online performance prediction process;generic model-based control loop;proactive system adaptation;resource efficiency gains,,23.0,,64.0,,27 Sep 2016,,,IEEE,IEEE Journals
118,118,The Crowd in Requirements Engineering: The Landscape and Challenges,E. C. Groen; N. Seyff; R. Ali; F. Dalpiaz; J. Doerr; E. Guzman; M. Hosseini; J. Marco; M. Oriol; A. Perini; M. Stade,Fraunhofer Institute for Experimental Software Engineering; University of Applied Sciences and Arts Northwestern Switzerland; Bournemouth University; Utrecht University; Fraunhofer Institute for Experimental Software Engineering; University of Zurich; Bournemouth University; Polytechnic University of Catalonia; Polytechnic University of Catalonia; FBK Center for Information and Communication Technology; University of Applied Sciences and Arts Northwestern Switzerland,IEEE Software,28 Mar 2017,2017,34,2,44,52,"Crowd-based requirements engineering (CrowdRE) could significantly change RE. Performing RE activities such as elicitation with the crowd of stakeholders turns RE into a participatory effort, leads to more accurate requirements, and ultimately boosts software quality. Although any stakeholder in the crowd can contribute, CrowdRE emphasizes one stakeholder group whose role is often trivialized: users. CrowdRE empowers the management of requirements, such as their prioritization and segmentation, in a dynamic, evolved style through collecting and harnessing a continuous flow of user feedback and monitoring data on the usage context. To analyze the large amount of data obtained from the crowd, automated approaches are key. This article presents current research topics in CrowdRE; discusses the benefits, challenges, and lessons learned from projects and experiments; and assesses how to apply the methods and tools in industrial contexts. This article is part of a special issue on Crowdsourcing for Software Engineering.",1937-4194,,10.1109/MS.2017.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888433,crowd-based requirements engineering;CrowdRE;user feedback;requirements engineering;software requirements;crowdsourcing;software development;software engineering,Software development;Context awareness;Monitoring;Context modeling;Stakeholders;Crowdsourcing;Software engineering,crowdsourcing;data analysis;formal specification;formal verification;software quality,crowd-based requirements engineering;RE activities;software quality;CrowdRE;user feedback;data monitoring;usage context;data analysis;industrial contexts;crowdsourcing,,72.0,,25.0,,28 Mar 2017,,,IEEE,IEEE Magazines
119,119,Rapid Releases and Patch Backouts: A Software Analytics Approach,R. Souza; C. Chavez; R. A. Bittencourt,Federal University of Bahia; Federal University of Bahia; State University of Feira de Santana,IEEE Software,10 Mar 2015,2015,32,2,89,96,"Release engineering deals with decisions that impact the daily lives of developers, testers, and users and thus contribute to a product's success. Although gut feeling is important in such decisions, it's increasingly important to leverage existing data, such as bug reports, source code changes, code reviews, and test results, both to support decisions and to help evaluate current practices. The exploration of software engineering data to obtain insightful information is called software analytics.",1937-4194,,10.1109/MS.2015.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006390,release engineering;rapid releases;software analytics;bug reopening;software engineering;software development;Mozilla;Firefox;Web browsers,Computer bugs;Linux;Continuous production;Marketing and sales;Browsers;Market research;Software analytics;Software engineering;Software development,data analysis;software engineering,software analytics approach;Mozilla;rapid releases;patch backouts;software engineering data,,13.0,,5.0,,12 Jan 2015,,,IEEE,IEEE Magazines
120,120,Multitier Diversification in Web-Based Software Applications,S. Allier; O. Barais; B. Baudry; J. Bourcier; E. Daubert; F. Fleurey; M. Monperrus; H. Song; M. Tricoire,INRIA; University of Rennes 1; INRIA; University of Rennes 1; INRIA; SINTEF Information and Communication Technology; University of Lille; SINTEF Information and Communication Technology; INRIA,IEEE Software,4 Feb 2015,2015,32,1,83,90,"Web application development benefits massively from modular architectures and reuse. This excellent software engineering practice is also the source of a new form of monoculture in application-level co de, which creates a potential risk for dependability. Researchers propose using software diversification in multiple components of Web applications to reconcile the tension between reuse and dependability. This article identifies key enablers for the effective diversification of software, especially at the application-code level. It's possible to combine different software diversification strategies, from deploying different vendor solutions to fine-grained code transformations, to provide different forms of protection.",1937-4194,,10.1109/MS.2014.150,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6957484,software diversity;software monoculture;Web applications;security;dependability;software engineering,Internet;Servers;Operating systems;Computer architecture;Diversity reception;Web services;Software engineering,Internet;software engineering,multitier diversification;Web-based software applications;modular architectures;modular reuse;software engineering practice;application-level code;software diversification;vendor solutions;fine-grained code transformations,,16.0,,11.0,,14 Nov 2014,,,IEEE,IEEE Magazines
121,121,Barriers Faced by Newcomers to Software-Crowdsourcing Projects,A. L. Zanatta; I. Steinmacher; L. S. Machado; C. R. B. de Souza; R. Prikladnicki,Pontifical Catholic University of Rio Grande do Sul; Federal University of Technology-Paraná and Northern Arizona University; Pontifical Catholic University of Rio Grande do Sul; Instituto Tecnológico Vale and Federal University of Pará; Pontifical Catholic University of Rio Grande do Sul,IEEE Software,28 Mar 2017,2017,34,2,37,43,"Crowdsourcing distributes a task to a large network of people-the crowd-through an open call. Newcomers (those attempting to make their first successful contribution) are especially important because they are a source of new ideas and promote a sustainable number of developers. So, newcomers should be encouraged to be active participants in software crowdsourcing. However, newcomers can have difficulty winning algorithm competitions. In addition, six types of barriers can hinder them: lack of documentation, poor task management, problems understanding code structure or architecture, information overload, poor platform usability, and the language barrier. Fortunately, ways exist to minimize the barriers, including consistent documentation, well-structured source code, recommending tasks that are appropriate for newcomers, and assigning tasks to newcomers that let them derive more benefits for themselves. This article is part of a special issue on Crowdsourcing for Software Engineering.",1937-4194,,10.1109/MS.2017.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888391,software crowdsourcing;crowdsourcing;software engineering;software development;Topcoder,Crowdsourcing;Documentation;Usability;Software engineering;Open source software;Software testing;Software development,crowdsourcing;project management;software engineering;software management,software crowdsourcing projects;newcomers;winning algorithm;poor task management;code structure;platform usability;language barriers;consistent documentation;well-structured source code;software engineering,,14.0,,18.0,,28 Mar 2017,,,IEEE,IEEE Magazines
122,122,Preventing Defects: The Impact of Requirements Traceability Completeness on Software Quality,P. Rempel; P. Mäder,"Software Engineering for Safety-Critical Systems Group, Technische Universität Ilmenau, Ilmenau, Germany; Software Engineering for Safety-Critical Systems Group, Technische Universität Ilmenau, Ilmenau, Germany",IEEE Transactions on Software Engineering,11 Aug 2017,2017,43,8,777,797,"Requirements traceability has long been recognized as an important quality of a well-engineered system. Among stakeholders, traceability is often unpopular due to the unclear benefits. In fact, little evidence exists regarding the expected traceability benefits. There is a need for empirical work that studies the effect of traceability. In this paper, we focus on the four main requirements implementation supporting activities that utilize traceability. For each activity, we propose generalized traceability completeness measures. In a defined process, we selected 24 medium to large-scale open-source projects. For each software project, we quantified the degree to which a studied development activity was enabled by existing traceability with the proposed measures. We analyzed that data in a multi-level Poisson regression analysis. We found that the degree of traceability completeness for three of the studied activities significantly affects software quality, which we quantified as defect rate. Our results provide for the first time empirical evidence that more complete traceability decreases the expected defect rate in the developed software. The strong impact of traceability completeness on the defect rate suggests that traceability is of great practical value for any kind of software development project, even if traceability is not mandated by a standard or regulation.",1939-3520,,10.1109/TSE.2016.2622264,German Ministry of Education and Research (BMBF); Thüringer Aufbaubank (TAB); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7723818,Requirements traceability;traceability completeness;traceability metrics;change impact analysis;requirements satisfaction analysis;source code justification analysis;software quality;error proneness;defects;bugs;empirical validation;regression analysis,Software quality;Software systems;Context;Software engineering;Stakeholders;Standards,public domain software;regression analysis;software quality;stochastic processes,software development project;multilevel Poisson regression analysis;software project;large-scale open-source projects;generalized traceability completeness measurement;requirement traceability completeness impact;software quality,,13.0,,131.0,,27 Oct 2016,,,IEEE,IEEE Journals
123,123,Collaboration Spaces for Virtual Software Teams,K. Dullemond; B. van Gameren; R. van Solingen,Delft University of Technology; Delft University of Technology; Delft University of Technology,IEEE Software,7 Nov 2014,2014,31,6,47,53,"Software engineering is a field in which distributed development through virtual teams is a fact of life. The authors claim that environments for supporting virtual software teams should place collaboration in the forefront. Here, they present a set of eight core requirements for support environments for virtual software teams. These requirements have been derived from, and validated in, industrial settings, and address how to provide virtual software teams with a sufficient level of awareness for their work activities.",1937-4194,,10.1109/MS.2014.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6879053,virtual teams;virtual software teams;global software engineering;collaboration support environments;interrupts;attention and interruption;mood indicators;awareness;computer-supported cooperative work;software environments;software engineering,Collaboration;Software engineering;Research and development;Teamwork;Virtual groups;Computer languages;Programming,groupware;programming environments;software development management;team working,collaboration spaces;virtual software teams;software engineering;distributed development,,7.0,,15.0,,15 Aug 2014,,,IEEE,IEEE Magazines
124,124,"Software Development Tooling: Information, Opinion, Guidelines, and Tools",D. Spinellis; S. Androutsellis-Theotokis,Athens University of Economics and Business; NA,IEEE Software,7 Nov 2014,2014,31,6,21,23,"The article depicts in two infographics a summary of what has been presented in the Tools of the Trade column over the past 10 years. The first figure categorizes the major points of each column into information, opinion, and prescriptive guidelines. The second figure associates with each broad theme specific indicative tools.",1937-4194,,10.1109/MS.2014.146,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949502,software engineering tools;Tools of the Trade;infographics;software engineering,Software development;Guidelines;Software engineering;Debugging,,,,,,,,7 Nov 2014,,,IEEE,IEEE Magazines
125,125,Parallel Algorithms for Testing Finite State Machines:Generating UIO Sequences,R. M. Hierons; U. C. Türker,"Department of Computer Science, Brunel University London, United Kingdom; Department of Computer Science, Brunel University London, United Kingdom",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,1077,1091,This paper describes an efficient parallel algorithm that uses many-core GPUs for automatically deriving Unique Input Output sequences (UIOs) from Finite State Machines. The proposed algorithm uses the global scope of the GPU's global memory through coalesced memory access and minimises the transfer between CPU and GPU memory. The results of experiments indicate that the proposed method yields considerably better results compared to a single core UIO construction algorithm. Our algorithm is scalable and when multiple GPUs are added into the system the approach can handle FSMs whose size is larger than the memory available on a single GPU.,1939-3520,,10.1109/TSE.2016.2539964,Scientific and Technological Research Council of Turkey; NVIDIA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7429774,Software engineering/software/program verification;software engineering/testing and debugging;software engineering/test design;finite state machine;unique input output sequence generation;general purpose graphics processing units,Graphics processing units;Testing;Automata;Algorithm design and analysis;Software algorithms;Automation,finite state machines;graphics processing units;input-output programs;multiprocessing systems;parallel algorithms;program testing,parallel algorithms;finite state machine testing;UIO sequence generation;unique input output sequences;many-core GPU;graphics processing unit;coalesced memory access;memory transfer;single core UIO construction algorithm,,11.0,,46.0,,9 Mar 2016,,,IEEE,IEEE Journals
126,126,End Users at the Bazaar: Designing Next-Generation Enterprise Resource Planning Systems,C. Dorner; S. Draxler; V. Pipek; V. Wulf,University of Siegen; University of Siegen; University of Siegen; University of Siegen,IEEE Software,25 Aug 2009,2009,26,5,45,51,"Studying changing software architectures from an end-user development perspective inspires an enterprise resource planning architecture that lets end users create their own solutions.The ""bazaar,"" a notion Eric Raymond coined, is a well-known metaphor for a software engineering model that developers often use in open source projects. In this model, software development is in view of the public, which means that anyone has access to the source code and can change, improve, test, and use it. Open source projects such as Firefox or the ADempiere ERP Business Suite have produced high-quality results, indicating that bazaar-like software engineering models are effective.",1937-4194,,10.1109/MS.2009.127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222793,visual programming;domain-specific architectures;graphical user interfaces;workflow management;business;software engineering,Enterprise resource planning;Service oriented architecture;Software tools;Application software;Software engineering;Impedance;Product design;Manufacturing;Meeting planning;Materials requirements planning,program testing;public domain software;software architecture;software quality,next-generation enterprise resource planning system;software architectures;software engineering model;open source project;software development;bazaar-like software engineering model;Firefox;ADempiere ERP Business Suite,,15.0,,19.0,,25 Aug 2009,,,IEEE,IEEE Magazines
127,127,Piloting a Mobile-App Ecosystem for Smart Farming,S. Braun; R. Carbon; M. Naab,Fraunhofer Institute for Experimental Software Engineering; John Deere; Fraunhofer Institute for Experimental Software Engineering,IEEE Software,23 Jun 2016,2016,33,4,9,14,"Mobile apps increasingly constitute complete ecosystems to support businesses such as farming. Software architects and engineers from John Deere and the Fraunhofer Institute for Experimental Software Engineering recently piloted a mobile-app ecosystem for farmers, focusing on data's role in architecting. Having the right data at the right time at the right place is crucial for high user productivity and a good user experience. In particular, offline capability is important but difficult. The authors describe a custom solution for offline capability and share lessons learned regarding data-related architecture decisions.",1937-4194,,10.1109/MS.2016.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498540,software architecture;mobile-app ecosystem;data;offline capability;synchronization;smart farming;software development;software engineering,Synchronization;Mobile communication;Meteorology;Food production;Computer architecture;Agricultural products;Ecosystems,farming;mobile computing,mobile-app ecosystem;smart farming;data-related architecture decision,,4.0,,6.0,,23 Jun 2016,,,IEEE,IEEE Magazines
128,128,Inner Source--Adopting Open Source Development Practices in Organizations: A Tutorial,K. Stol; B. Fitzgerald,Lero--The Irish Software Engineering Research Centre; Lero--The Irish Software Engineering Research Centre,IEEE Software,30 Jun 2015,2015,32,4,60,67,"Inner source, the adoption and tailoring of open source development practices in organizations, is receiving increased interest. However, although it offers numerous benefits, many practitioners are unclear about what it is and how to adopt it. When adopting inner source, organizations should consider nine factors pertaining to product, process, and organization. A description of three inner-source initiatives illustrates these nine factors.",1937-4194,,10.1109/MS.2014.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6809709,open source development;inner source;software engineering;software development;open source,Open source software;Software development;Software engineering;Standards organizations,public domain software;software houses,inner source adoption;open source development practices;software organization;software industry,,26.0,,16.0,,2 May 2014,,,IEEE,IEEE Magazines
129,129,Reflecting on Evidence-Based Timelines,E. Bjarnason; A. Hess; R. Berntsson Svensson; B. Regnell; J. Doerr,"Lund University; Fraunhofer Institute for Experimental Software Engineering; Chalmers, University of Gothenburg; Lund University; Fraunhofer Institute for Experimental Software Engineering",IEEE Software,13 Jun 2014,2014,31,4,37,43,"Project retrospectives can be powerful tools for project teams to collectively identify communication gaps and practices to improve for future projects. However, even if project members take the time for a retrospective, it can be hard to correctly remember and jointly discuss past events in a constructive way. Fact-based timelines that visualize a project's events offer a possible solution.",1937-4194,,10.1109/MS.2014.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834711,project retrospective;timeline;software process improvement;software engineering;pervasive computing;project management,Software development;Software engineering;Project management;Strategic planning,,,,6.0,,8.0,,13 Jun 2014,,,IEEE,IEEE Magazines
130,130,Why and How Should Open Source Projects Adopt Time-Based Releases?,M. Michlmayr; B. Fitzgerald; K. Stol,Hewlett-Packard; Lero--The Irish Software Engineering Research Centre; Lero--The Irish Software Engineering Research Centre,IEEE Software,10 Mar 2015,2015,32,2,55,63,"Traditional release strategies have problems that can be overcome by time-based release management. Interviews with key members of seven prominent volunteer-based open source projects reveal time-based release's advantages. The authors discuss release planning's importance, the numerous challenges that can result from a lack of such planning, and time-based releases' benefits. They also discuss how to adopt time-based release. An online supplement provides additional information on the projects and interview guide discussed in the article.",1937-4194,,10.1109/MS.2015.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057555,release management;time-based releases;release strategies;open source projects;software development;software engineering;open source software,Schedules;Continuous production;Software development;Project management;Software engineering;Computer bugs;Open source software,public domain software;software development management,traditional release strategies;time-based release management;volunteer-based open source projects;release planning;online supplement;interview guide,,26.0,,17.0,,10 Mar 2015,,,IEEE,IEEE Magazines
131,131,A Systematic Literature Review on Fault Prediction Performance in Software Engineering,T. Hall; S. Beecham; D. Bowes; D. Gray; S. Counsell,"Brunel University, Uxbridge; University of Limerick, Limerick; University of Hertfordshire, Hatfield; University of Hertfordshire, Hatfield; Brunel University, Uxbridge",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1276,1304,"Background: The accurate prediction of where faults are likely to occur in code can help direct test effort, reduce costs, and improve the quality of software. Objective: We investigate how the context of models, the independent variables used, and the modeling techniques applied influence the performance of fault prediction models. Method: We used a systematic literature review to identify 208 fault prediction studies published from January 2000 to December 2010. We synthesize the quantitative and qualitative results of 36 studies which report sufficient contextual and methodological information according to the criteria we develop and apply. Results: The models that perform well tend to be based on simple modeling techniques such as Naive Bayes or Logistic Regression. Combinations of independent variables have been used by models that perform well. Feature selection has been applied to these combinations when models are performing particularly well. Conclusion: The methodology used to build models seems to be influential to predictive performance. Although there are a set of fault prediction studies in which confidence is possible, more studies are needed that use a reliable methodology and which report their context, methodology, and performance comprehensively.",1939-3520,,10.1109/TSE.2011.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035727,Systematic literature review;software fault prediction,Predictive models;Context modeling;Software testing;Data models;Systematics;Analytical models;Fault diagnosis,Bayes methods;regression analysis;software fault tolerance;software quality,systematic literature review;fault prediction performance;software engineering;cost reduction;software quality;independent variables;fault prediction models;contextual information;methodological information;simple modeling techniques;naive Bayes;logistic regression;feature selection;predictive performance;fault prediction study;reliable methodology,,462.0,,241.0,,6 Oct 2011,,,IEEE,IEEE Journals
132,132,FAML: A Generic Metamodel for MAS Development,G. Beydoun; G. Low; B. Henderson-Sellers; H. Mouratidis; J. J. Gomez-Sanz; J. Pavon; C. Gonzalez-Perez,"University of Wollongong, Wollongong; The University of New South Wales, Sydney; University of Technology, Sydney; University of East London, London; Universidad Complutense de Madrid, Madrid; Universidad Complutense de Madrid, Madrid; Instituto de Estudios Gallegos Padre Sarmiento (CSIC), Santiago de Compostela",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,841,863,"In some areas of software engineering research, there are several metamodels claiming to capture the main issues. Though it is profitable to have variety at the beginning of a research field, after some time, the diversity of metamodels becomes an obstacle, for instance to the sharing of results between research groups. To reach consensus and unification of existing metamodels, metamodel-driven software language engineering can be applied. This paper illustrates an application of software language engineering in the agent-oriented software engineering research domain. Here, we introduce a relatively generic agent-oriented metamodel whose suitability for supporting modeling language development is demonstrated by evaluating it with respect to several existing methodology-specific metamodels. First, the metamodel is constructed by a combination of bottom-up and top-down analysis and best practice. The concepts thus obtained and their relationships are then evaluated by mapping to two agent-oriented metamodels: TAO and Islander. We then refine the metamodel by extending the comparisons with the metamodels implicit or explicit within five more extant agent-oriented approaches: Adelfe, PASSI, Gaia, INGENIAS, and Tropos. The resultant FAML metamodel is a potential candidate for future standardization as an important component for engineering an agent modeling language.",1939-3520,,10.1109/TSE.2009.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967615,Modeling;metamodel;multiagent systems.,Software engineering;Australia;Application software;Multiagent systems;Management information systems;Best practices;Standardization;Software architecture;Natural languages,languages;multi-agent systems;software engineering,MAS development;metamodel;software language engineering;multiagent systems;FAML,,93.0,,72.0,,26 May 2009,,,IEEE,IEEE Journals
133,133,CrowdSummarizer: Automated Generation of Code Summaries for Java Programs through Crowdsourcing,S. Badihi; A. Heydarnoori,Sharif University of Technology; Sharif University of Technology,IEEE Software,28 Mar 2017,2017,34,2,71,80,"To perform software maintenance, developers must have a relatively good understanding of the program's source code, which is often written by other developers. Code summaries, which describe a program's entities (for example, its methods), help developers better comprehend code more quickly. However, generating code summaries can be challenging. To mitigate this problem, CrowdSummarizer exploits crowdsourcing, gamification, and natural-language processing to automatically generate high-level summaries of Java program methods. Researchers have implemented it as an Eclipse plug-in together with a Web-based code summarization game that can be played by the crowd. Two empirical studies determined that CrowdSummarizer generates quality results. This article is part of a special issue on Crowdsourcing for Software Engineering.",1937-4194,,10.1109/MS.2017.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888409,CrowdSummarizer;crowdsourcing;program comprehension;source code summarization;gamification;software engineering;software development,Software reliability;Crowdsourcing;Java;Software maintenance;Software engineering;Software engineering;Software measurement,computer games;crowdsourcing;Java;natural language processing;software maintenance;source code (software),Eclipse plug-in;software engineering;Web-based code summarization game;high-level summaries;Java program;gamification;natural-language processing;program source code;software maintenance;code summary automated generation;CrowdSummarizer,,6.0,,14.0,,28 Mar 2017,,,IEEE,IEEE Magazines
134,134,Yakov Fain on Angular,M. Farwell,Nexthink,IEEE Software,13 Nov 2017,2017,34,6,109,112,Yakov Fain talks with Software Engineering Radio host Matthew Farwell about the popular Angular web development framework.,1937-4194,,10.1109/MS.2017.4121218,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106872,Yakov Fain;Angular;web development frameworks;software engineering;software development;Software Engineering Radio.,Software engineering;Visualization;Programming;Navigation,,,,,,,,13 Nov 2017,,,IEEE,IEEE Magazines
135,135,Integrate End to End Early and Often,F. H. Bachmann; L. Carballo; J. McHale; R. L. Nord,Software Engineering Institute; Bursatec; Software Engineering Institute; Software Engineering Institute,IEEE Software,26 Jun 2013,2013,30,4,9,14,"This column is all about stories, and this one is as exciting as a paperback whodunit. The details are all included, and I hate to spoil it, but there's a happy ending. The story is about something old--designing and implementing a new system when the old one was really old (two decades!) and something new--using outside research consultants to save the day with a secret sauce. Enjoy!",1937-4194,,10.1109/MS.2013.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547611,software architecture;software process;incremental iterative development;integration;architecture-centric engineering;team software process,Computer architecture;Software development;Aging;Software engineering;Prototypes;Software testing;Software quality,software architecture,end-to-end software integration;software development project;software architecture,,3.0,,5.0,,26 Jun 2013,,,IEEE,IEEE Magazines
136,136,Instance Generator and Problem Representation to Improve Object Oriented Code Coverage,A. Sakti; G. Pesant; Y. Guéhéneuc,"Department of Computer and Software Engineering, École Polytechnique de Montral, Montral, QC, Canada; Department of Computer and Software Engineering, École Polytechnique de Montral, Montral, QC, Canada; Department of Computer and Software Engineering, École Polytechnique de Montral, Montral, QC, Canada",IEEE Transactions on Software Engineering,11 Mar 2015,2015,41,3,294,313,"Search-based approaches have been extensively applied to solve the problem of software test-data generation. Yet, test-data generation for object-oriented programming (OOP) is challenging due to the features of OOP, e.g., abstraction, encapsulation, and visibility that prevent direct access to some parts of the source code. To address this problem we present a new automated search-based software test-data generation approach that achieves high code coverage for unit-class testing. We first describe how we structure the test-data generation problem for unit-class testing to generate relevant sequences of method calls. Through a static analysis, we consider only methods or constructors changing the state of the class-under-test or that may reach a test target. Then we introduce a generator of instances of classes that is based on a family of means-of-instantiation including subclasses and external factory methods. It also uses a seeding strategy and a diversification strategy to increase the likelihood to reach a test target. Using a search heuristic to reach all test targets at the same time, we implement our approach in a tool, JTExpert, that we evaluate on more than a hundred Java classes from different open-source libraries. JTExpert gives better results in terms of search time and code coverage than the state of the art, EvoSuite, which uses traditional techniques.",1939-3520,,10.1109/TSE.2014.2363479,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926828,Automatic Test Data Generation;Search Based Software Testing;Unit Class Testing;Seeding Strategy;Diversification Strategy;Java Testing;Automatic test data generation;search based software testing;unit class testing;seeding strategy;diversification strategy;Java testing,Testing;Complexity theory;Generators;Search problems;Java;Production facilities;Libraries,Java;object-oriented programming;program diagnostics;program testing;public domain software,instance generator;problem representation;object oriented code coverage;search-based approach;object-oriented programming;OOP;abstraction;encapsulation;visibility;source code;automated search-based software test-data generation approach;unit-class testing;method call sequences;static analysis;class-under-test;means-of-instantiation;seeding strategy;diversification strategy;search heuristic;JTExpert;Java class evaluation;open-source libraries;search time;EvoSuite,,39.0,,53.0,,16 Oct 2014,,,IEEE,IEEE Journals
137,137,Using Natural Language Processing to Automatically Detect Self-Admitted Technical Debt,E. d. S. Maldonado; E. Shihab; N. Tsantalis,"Department of Computer Science and Software Engineering, Data-Driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Data-Driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1044,1062,"The metaphor of technical debt was introduced to express the trade off between productivity and quality, i.e., when developers take shortcuts or perform quick hacks. More recently, our work has shown that it is possible to detect technical debt using source code comments (i.e., self-admitted technical debt), and that the most common types of self-admitted technical debt are design and requirement debt. However, all approaches thus far heavily depend on the manual classification of source code comments. In this paper, we present an approach to automatically identify design and requirement self-admitted technical debt using Natural Language Processing (NLP). We study 10 open source projects: Ant, ArgoUML, Columba, EMF, Hibernate, JEdit, JFreeChart, JMeter, JRuby and SQuirrel SQL and find that 1) we are able to accurately identify self-admitted technical debt, significantly outperforming the current state-of-the-art based on fixed keywords and phrases; 2) words related to sloppy code or mediocre source code quality are the best indicators of design debt, whereas words related to the need to complete a partially implemented requirement in the future are the best indicators of requirement debt; and 3) we can achieve 90 percent of the best classification performance, using as little as 23 percent of the comments for both design and requirement self-admitted technical debt, and 80 percent of the best performance, using as little as 9 and 5 percent of the comments for design and requirement self-admitted technical debt, respectively. The last finding shows that the proposed approach can achieve a good accuracy even with a relatively small training dataset.",1939-3520,,10.1109/TSE.2017.2654244,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820211,Technical debt;source code comments;natural language processing;empirical study,Software;Natural language processing;Manuals;Entropy;Unified modeling language;Java;Structured Query Language,computer crime;Java;natural language processing;project management;public domain software;software maintenance;software management;software quality;SQL,Natural Language Processing;requirement debt;self-admitted technical debt detection;open source projects;source code quality;source code comment classification;NLP;design debt,,29.0,,58.0,Traditional,17 Jan 2017,,,IEEE,IEEE Journals
138,138,A Learning-Based Framework for Engineering Feature-Oriented Self-Adaptive Software Systems,N. Esfahani; A. Elkhodary; S. Malek,"George Mason University, Fairfax; George Mason University, Fairfax; George Mason University, Fairfax",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1467,1493,"Self-adaptive software systems are capable of adjusting their behavior at runtime to achieve certain functional or quality-of-service goals. Often a representation that reflects the internal structure of the managed system is used to reason about its characteristics and make the appropriate adaptation decisions. However, runtime conditions can radically change the internal structure in ways that were not accounted for during their design. As a result, unanticipated changes at runtime that violate the assumptions made about the internal structure of the system could degrade the accuracy of the adaptation decisions. We present an approach for engineering self-adaptive software systems that brings about two innovations: 1) a feature-oriented approach for representing engineers' knowledge of adaptation choices that are deemed practical, and 2) an online learning-based approach for assessing and reasoning about adaptation decisions that does not require an explicit representation of the internal structure of the managed software system. Engineers' knowledge, represented in feature-models, adds structure to learning, which in turn makes online learning feasible. We present an empirical evaluation of the framework using a real-world self-adaptive software system. Results demonstrate the framework's ability to accurately learn the changing dynamics of the system while achieving efficient analysis and adaptation.",1939-3520,,10.1109/TSE.2013.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574860,Self-adaptive software;autonomic computing;feature-orientation;machine learning,Software systems;Runtime;Adaptation models;Quality of service;Authentication;Measurement,inference mechanisms;learning (artificial intelligence);quality of service;software engineering,feature-models;adaptation decision reasoning;adaptation decision assessment;online learning-based approach;runtime conditions;quality-of-service goals;engineering feature-oriented self-adaptive software systems;learning-based framework,,53.0,1.0,67.0,,5 Aug 2013,,,IEEE,IEEE Journals
139,139,Conservation of Information: Software’sHidden Clockwork?,L. Hatton,"Faculty of Science, Engineering and Computing, Kingston University, United Kingdom",IEEE Transactions on Software Engineering,14 May 2014,2014,40,5,450,460,"In this paper it is proposed that the Conservation of Hartley-Shannon Information (hereafter contracted to H-S Information) plays the same role in discrete systems as the Conservation of Energy does in physical systems. In particular, using a variational approach, it is shown that the symmetry of scale-invariance, power-laws and the Conservation of H-S Information are intimately related and lead to the prediction that the component sizes of any software system assembled from components made from discrete tokens always asymptote to a scale-free power-law distribution in the unique alphabet of tokens used to construct each component. This is then validated to a very high degree of significance on some 100 million lines of software in seven different programming languages independently of how the software was produced, what it does, who produced it or what stage of maturity it has reached. A further implication of the theory presented here is that the average size of components depends only on their unique alphabet, independently of the package they appear in. This too is demonstrated on the main data set and also on 24 additional Fortran 90 packages.",1939-3520,,10.1109/TSE.2014.2316158,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6784340,Information conservation;component size distribution;power-law;software systems,Software systems;Computer languages;Genomics;Bioinformatics;Genetic communication,information theory;programming languages;software engineering,software hidden clockwork;Hartley-Shannon information conservation;physical systems;discrete systems;energy conservation;variational approach;scale-invariance symmetry;H-S information conservation;software system;scale-free power-law distribution;discrete tokens;Fortran,,3.0,,30.0,,8 Apr 2014,,,IEEE,IEEE Journals
140,140,Reporting Usability Defects: A Systematic Literature Review,N. S. M. Yusop; J. Grundy; R. Vasa,"Faculty of Computer and Mathematical Science, Universiti Teknologi MARA, Malaysia; Faculty of Science, Engineering and Built Environment, Deakin University, AUD, Australia; Faculty of Science, Engineering and Built Environment, Deakin University, AUD, Australia",IEEE Transactions on Software Engineering,15 Sep 2017,2017,43,9,848,867,"Usability defects can be found either by formal usability evaluation methods or indirectly during system testing or usage. No matter how they are discovered, these defects must be tracked and reported. However, empirical studies indicate that usability defects are often not clearly and fully described. This study aims to identify the state of the art in reporting of usability defects in the software engineering and usability engineering literature. We conducted a systematic literature review of usability defect reporting drawing from both the usability and software engineering literature from January 2000 until March 2016. As a result, a total of 57 studies were identified, in which we classified the studies into three categories: reporting usability defect information, analysing usability defect data and key challenges. Out of these, 20 were software engineering studies and 37 were usability studies. The results of this systematic literature review show that usability defect reporting processes suffer from a number of limitations, including: mixed data, inconsistency of terms and values of usability defect data, and insufficient attributes to classify usability defects. We make a number of recommendations to improve usability defect reporting and management in software engineering.",1939-3520,,10.1109/TSE.2016.2638427,"Ministry of Higher Education Malaysia, Universiti Teknologi MARA (UiTM); ARC Discovery projects scheme, the Deakin Software Technology Innovation Lab; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7779159,Systematic review;test management;user interface;usability testing;usability defect reporting,Usability;Systematics;Software engineering;Testing;Human computer interaction;Bibliographies,formal verification;pattern classification;product design;program testing,formal usability evaluation;system testing;software engineering;usability defect reporting processes;mixed data;usability defect data;usability defect classification,,5.0,,87.0,Traditional,9 Dec 2016,,,IEEE,IEEE Journals
141,141,"How Programmers Debug, Revisited: An Information Foraging Theory Perspective",J. Lawrance; C. Bogart; M. Burnett; R. Bellamy; K. Rector; S. D. Fleming,"Wentworth Institute of Technology, Boston; Oregon State University, Corvallis; Oregon State University, Corvallis; IBM TJ Watson Research Center, Hawthorne; Oregon State University, Corvallis; Oregon State University, Corvallis",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,197,215,"Many theories of human debugging rely on complex mental constructs that offer little practical advice to builders of software engineering tools. Although hypotheses are important in debugging, a theory of navigation adds more practical value to our understanding of how programmers debug. Therefore, in this paper, we reconsider how people go about debugging in large collections of source code using a modern programming environment. We present an information foraging theory of debugging that treats programmer navigation during debugging as being analogous to a predator following scent to find prey in the wild. The theory proposes that constructs of scent and topology provide enough information to describe and predict programmer navigation during debugging, without reference to mental states such as hypotheses. We investigate the scope of our theory through an empirical study of 10 professional programmers debugging a real-world open source program. We found that the programmers' verbalizations far more often concerned scent-following than hypotheses. To evaluate the predictiveness of our theory, we created an executable model that predicted programmer navigation behavior more accurately than comparable models that did not consider information scent. Finally, we discuss the implications of our results for enhancing software engineering tools.",1939-3520,,10.1109/TSE.2010.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5674060,Information foraging theory;debugging;software maintenance;programmer navigation;information scent;empirical software engineering,Debugging;Navigation;Topology;Programming environments;Predictive models;Approximation methods,cognition;program debugging;public domain software;software maintenance;topology,information foraging theory;human debugging theories;complex mental constructs;navigation theory;programming environment;topology constructs;information scent constructs;open source code program debugging;programmer verbalizations;programmer navigation behavior prediction;software engineering tool enhancement,,59.0,,54.0,,23 Dec 2010,,,IEEE,IEEE Journals
142,142,Managing Variability in Software Product Lines,M. A. Babar; L. Chen; F. Shull,"IT University of Copenhagen; Lero, University of Limerick; Fraunhofer Center for Experimental Software Engineering, Maryland",IEEE Software,19 Apr 2010,2010,27,3,89,"91, 94","A software product line (SPL) is a set of software-intensive systems that share a common set of features for satisfying a particular market segment needs. SPLs can reduce development costs, shorten time-to-market, and improve product quality by reusing core assets for project-specific customizations. To enable reuse on a large scale, SPL engineering (SPLE) identifies and manages commonalities and variations across a set of system artifacts such as requirements, architectures, code components, and test cases.Variability management (VM) is a fundamental SPLE activity that explicitly represents software artifact variations for managing dependencies among variants and supporting their instantiations throughout the SPL life cycle. Managing variability involves extremely complex and challenging tasks, which must be supported by effective methods, techniques, and tools.",1937-4194,,10.1109/MS.2010.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452151,software engineering;evidence-based software engineering;software product lines,Engineering management;Costs;Time to market;Large-scale systems;Computer architecture;Life testing;Software testing;System testing;Virtual manufacturing,product development;software quality;software reusability,variability management;software product lines;software-intensive systems;product quality improvement;project-specific customizations;development costs reduction,,36.0,,23.0,,19 Apr 2010,,,IEEE,IEEE Magazines
143,143,Trends in Embedded Software Engineering,P. Liggesmeyer; M. Trapp,University of Kaiserslautern; Fraunhofer Institute for Experimental Software Engineering,IEEE Software,17 Apr 2009,2009,26,3,19,25,"Software's importance in the development of embedded systems has been growing rapidly over the last 20 years. Because of current embedded systems' complexity, they require sophisticated engineering methods for systematically developing high-quality software. Embedded software development differs from IT system development in several ways. For example, IT systems developers can use standard hardware and software platforms and don't face the resource requirements that embedded systems developers must take into account. To meet embedded software's extrafunctional requirements, embedded systems development is shifting from programming to model-driven development. Another important trend is the emphasis on the quality assurance of safety-related systems.",1937-4194,,10.1109/MS.2009.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814954,embedded systems development;model-driven development;embedded software;quality assurance;safety-critical systems,Embedded software;Object oriented modeling;Mathematical model;Embedded system;Hardware;IEC standards;Costs;Automotive engineering;Computer languages;Operating systems,embedded systems;software quality,embedded software engineering;embedded systems;embedded software development;IT system development;safety-related systems;quality assurance,,53.0,,14.0,,17 Apr 2009,,,IEEE,IEEE Magazines
144,144,Leveraging Transparency,L. Dabbish; C. Stuart; J. Tsay; J. Herbsleb,Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,IEEE Software,3 Jan 2013,2013,30,1,37,43,"A new generation of development environments takes a radical approach to communication and coordination by fusing social networking functionality with flexible, distributed version control. Through these transparent work environments, people, repositories, development activities, and their histories are immediately and easily visible to all users. Developers quickly acquire the skill to interpret this rich information to find useful resources, connect with people, solve technical problems, and enhance their learning opportunities. This article presents the results of a qualitative study of users of one such environment, GitHub. It describes how transparency helps developers on GitHub manage their projects, handle dependencies more effectively, reduce communication needs, and figure out what requires their attention. Although transparency is not a silver bullet, the approach shows great promise for enhancing collaboration and coordination. The Web extra at http://www.youtube.com/watch?v=LpGA2fmAHvM is a video of Joel Spolsky discussing the structure, software, technology, and culture of Stack Exchange.",1937-4194,,10.1109/MS.2012.172,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6357175,Social network services;Software engineering;Collaboration;Organizational aspects;User interfaces;Information technology;Software management;information technology and systems;software engineering tools and techniques;software engineering;organizational management;coordination;group interfaces;organization interfaces;information interfaces and representation;HCI,Social network services;Software engineering;Collaboration;Organizational aspects;User interfaces;Information technology;Software management,Internet;project management;security of data;social networking (online),transparency leverage;development environments;social networking functionality;distributed version control;learning opportunities;GitHub;project management,,30.0,,9.0,,20 Nov 2012,,,IEEE,IEEE Magazines
145,145,Whole Test Suite Generation,G. Fraser; A. Arcuri,"Saarland University, Saarbrücken; Simula Research Laboratory, Lysaker",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,276,291,"Not all bugs lead to program crashes, and not always is there a formal specification to check the correctness of a software test's outcome. A common scenario in software testing is therefore that test data are generated, and a tester manually adds test oracles. As this is a difficult task, it is important to produce small yet representative test sets, and this representativeness is typically measured using code coverage. There is, however, a fundamental problem with the common approach of targeting one coverage goal at a time: Coverage goals are not independent, not equally difficult, and sometimes infeasible-the result of test generation is therefore dependent on the order of coverage goals and how many of them are feasible. To overcome this problem, we propose a novel paradigm in which whole test suites are evolved with the aim of covering all coverage goals at the same time while keeping the total size as small as possible. This approach has several advantages, as for example, its effectiveness is not affected by the number of infeasible targets in the code. We have implemented this novel approach in the EvoSuite tool, and compared it to the common approach of addressing one goal at a time. Evaluated on open source libraries and an industrial case study for a total of 1,741 classes, we show that EvoSuite achieved up to 188 times the branch coverage of a traditional approach targeting single branches, with up to 62 percent smaller test suites.",1939-3520,,10.1109/TSE.2012.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152257,Search-based software engineering;length;branch coverage;genetic algorithm;infeasible goal;collateral coverage,Software;Genetic algorithms;Search problems;Arrays;Genetic programming;Software testing,formal specification;program debugging;program testing,whole test suite generation;program crashes;formal specification;software testing;code coverage;EvoSuite tool;program debugging,,243.0,2.0,52.0,,16 Feb 2012,,,IEEE,IEEE Journals
146,146,From UML to Petri Nets: The PCM-Based Methodology,S. Distefano; M. Scarpa; A. Puliafito,"University of Messina, Sicily; University of Messina, Sicily; University of Messina, Sicily",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,65,79,"In this paper, we present an evaluation methodology to validate the performance of a UML model, representing a software architecture. The proposed approach is based on open and well-known standards: UML for software modeling and the OMG Profile for Schedulability, Performance, and Time Specification for the performance annotations into UML models. Such specifications are collected in an intermediate model, called the Performance Context Model (PCM). The intermediate model is translated into a performance model which is subsequently evaluated. The paper is focused on the mapping from the PCM to the performance domain. More specifically, we adopt Petri nets as the performance domain, specifying a mapping process based on a compositional approach we have entirely implemented in the ArgoPerformance tool. All of the rules to derive a Petri net from a PCM and the performance measures assessable from the former are carefully detailed. To validate the proposed technique, we provide an in-depth analysis of a web application for music streaming.",1939-3520,,10.1109/TSE.2010.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5396344,Software engineering;performances evaluation;Petri nets;UML;software performance engineering.,Unified modeling language;Petri nets;Phase change materials;Software architecture;Software performance;Context modeling;Application software;Design engineering;Performance analysis;Stochastic processes,media streaming;Petri nets;software architecture;software metrics;software performance evaluation;Unified Modeling Language;Web services,UML;Petri nets;PCM;software architecture;software modeling;OMG profile;schedulability;time specification;performance context model;mapping process;ArgoPerformance tool;music streaming;Web application,,34.0,,31.0,,22 Jan 2010,,,IEEE,IEEE Journals
147,147,Approaches to Co-Evolution of Metamodels and Models: A Survey,R. Hebig; D. E. Khelladi; R. Bendraou,"Computer Science and Engineering Göteborg, Chalmers University of Technology, Göteborg, Sweden; Sorbonne Universités, UPMC Univ Paris 06, UMR 7606, LIP6, Paris, France; Sorbonne Universités, UPMC Univ Paris 06, UMR 7606, LIP6, Paris, France",IEEE Transactions on Software Engineering,12 May 2017,2017,43,5,396,414,"Modeling languages, just as all software artifacts, evolve. This poses the risk that legacy models of a company get lost, when they become incompatible with the new language version. To address this risk, a multitude of approaches for metamodel-model co-evolution were proposed in the last 10 years. However, the high number of solutions makes it difficult for practitioners to choose an appropriate approach. In this paper, we present a survey on 31 approaches to support metamodel-model co-evolution. We introduce a taxonomy of solution techniques and classify the existing approaches. To support researchers, we discuss the state of the art, in order to better identify open issues. Furthermore, we use the results to provide a decision support for practitioners, who aim to adopt solutions from research.",1939-3520,,10.1109/TSE.2016.2610424,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7569018,Survey;software engineering;metamodels;models;design notations and documentation,Unified modeling language;Companies;Taxonomy;Biological system modeling;Atmospheric modeling;Libraries;Productivity,software engineering,coevolution approaches;metamodel-model coevolution;solution technique taxonomy;decision support,,15.0,,84.0,,15 Sep 2016,,,IEEE,IEEE Journals
148,148,A Study of Variability Models and Languages in the Systems Software Domain,T. Berger; S. She; R. Lotufo; A. Wasowski; K. Czarnecki,"IT University of Copenhagen, Copenhagen; University of Waterloo, Waterloo; University of Waterloo, Waterloo; IT University of Copenhagen, Copenhagen; University of Waterloo, Waterloo",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1611,1640,"Variability models represent the common and variable features of products in a product line. Since the introduction of FODA in 1990, several variability modeling languages have been proposed in academia and industry, followed by hundreds of research papers on variability models and modeling. However, little is known about the practical use of such languages. We study the constructs, semantics, usage, and associated tools of two variability modeling languages, Kconfig and CDL, which are independently developed outside academia and used in large and significant software projects. We analyze 128 variability models found in 12 open--source projects using these languages. Our study 1) supports variability modeling research with empirical data on the real-world use of its flagship concepts. However, we 2) also provide requirements for concepts and mechanisms that are not commonly considered in academic techniques, and 3) challenge assumptions about size and complexity of variability models made in academic papers. These results are of interest to researchers working on variability modeling and analysis techniques and to designers of tools, such as feature dependency checkers and interactive product configurators.",1939-3520,,10.1109/TSE.2013.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6572787,Empirical software engineering;software product lines;variability modeling;feature modeling;configuration;open source,Biological system modeling;Software products;Product line;Analytical models;Computational modeling;Semantics;Computer architecture,public domain software;simulation languages;software engineering,interactive product configurators;feature dependency checkers;variability analysis techniques;open-source projects;software projects;associated language tools;language usage;language semantics;language constructs;CDL language;Kconfig language;variability modeling languages;FODA;systems software domain;variability models,,59.0,,88.0,,31 Jul 2013,,,IEEE,IEEE Journals
149,149,A UML/MARTE Model Analysis Method for Uncovering Scenarios Leading to Starvation and Deadlocks in Concurrent Systems,M. Shousha; L. Briand; Y. Labiche,"Carleton University, Ottawa; Simula Research Laboratory, Lysaker and University of Oslo, Norway; Carleton University, Ottawa",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,354,374,"Concurrency problems such as starvation and deadlocks should be identified early in the design process. As larger, more complex concurrent systems are being developed, this is made increasingly difficult. We propose here a general approach based on the analysis of specialized design models expressed in the Unified Modeling Language (UML) that uses a specifically designed genetic algorithm to detect concurrency problems. Though the current paper addresses deadlocks and starvation, we will show how the approach can be easily tailored to other concurrency issues. Our main motivations are 1) to devise solutions that are applicable in the context of the UML design of concurrent systems without requiring additional modeling and 2) to use a search technique to achieve scalable automation in terms of concurrency problem detection. To achieve the first objective, we show how all relevant concurrency information is extracted from systems' UML models that comply with the UML Modeling and Analysis of Real-Time and Embedded Systems (MARTE) profile. For the second objective, a tailored genetic algorithm is used to search for execution sequences exhibiting deadlock or starvation problems. Scalability in terms of problem detection is achieved by showing that the detection rates of our approach are, in general, high and are not strongly affected by large increases in the size of complex search spaces.",1939-3520,,10.1109/TSE.2010.107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661791,Search-based software engineering;MDD;deadlock;starvation;model analysis;concurrent systems;UML;MARTE;genetic algorithms.,Unified modeling language;Concurrent computing;System recovery;Analytical models;Real time systems;Computational modeling;Data mining,concurrency control;embedded systems;genetic algorithms;search problems;software engineering;Unified Modeling Language,UML-MARTE model analysis method;starvation;deadlocks;concurrency problems;design process;complex concurrent systems;specialized design models;Unified Modeling Language;genetic algorithm;UML design;search technique;scalable automation;concurrency problem detection;concurrency information;UML models;UML modeling and analysis;real-time systems;embedded systems;MARTE profile;execution sequences;complex search spaces,,14.0,,46.0,,10 Dec 2010,,,IEEE,IEEE Journals
150,150,Automatic Summarization of Bug Reports,S. Rastkar; G. C. Murphy; G. Murray,"Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver, Canada; Department of Computer Science, University of British Columbia, 2366 Main Mall, Vancouver, Canada; Computer Information Systems Department, University of the Fraser Valley, 33844 King Road, Abbotsford, Canada",IEEE Transactions on Software Engineering,2 May 2014,2014,40,4,366,380,"Software developers access bug reports in a project's bug repository to help with a number of different tasks, including understanding how previous changes have been made and understanding multiple aspects of particular defects. A developer's interaction with existing bug reports often requires perusing a substantial amount of text. In this article, we investigate whether it is possible to summarize bug reports automatically so that developers can perform their tasks by consulting shorter summaries instead of entire bug reports. We investigated whether existing conversation-based automated summarizers are applicable to bug reports and found that the quality of generated summaries is similar to summaries produced for e-mail threads and other conversations. We also trained a summarizer on a bug report corpus. This summarizer produces summaries that are statistically better than summaries produced by existing conversation-based generators. To determine if automatically produced bug report summaries can help a developer with their work, we conducted a task-based evaluation that considered the use of summaries for bug report duplicate detection tasks. We found that summaries helped the study participants save time, that there was no evidence that accuracy degraded when summaries were used and that most participants preferred working with summaries to working with original bug reports.",1939-3520,,10.1109/TSE.2013.2297712,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6704866,Empirical software engineering;summarization of software artifacts;bug report duplicate detection,Software;Electronic mail;Computer bugs;Natural languages;Feature extraction;Detectors,electronic mail;program debugging;software engineering,automatic summarization;bug reports;software developers;bug repository;conversation-based automated summarizers;e-mail threads;bug report corpus;conversation-based generators;bug report summaries;task-based evaluation;bug report duplicate detection tasks,,79.0,,41.0,,9 Jan 2014,,,IEEE,IEEE Journals
151,151,Parallelizing Bzip2: A Case Study in Multicore Software Engineering,V. Pankratius; A. Jannesari; W. F. Tichy,University of Karlsruhe; University of Karlsruhe; University of Karlsruhe,IEEE Software,16 Oct 2009,2009,26,6,70,77,"We conducted a case study of parallelizing a real program for multicore computers using currently available libraries and tools. We selected the sequential Bzip2 compression program for the study because it's a computing-intensive, widely used, and relevant application in everyday life. Its source code is available, and its algorithm is well documented. In addition, the algorithm is non-trivial, but, with 8,000 LOC, the application is small enough to manage in a course.",1937-4194,,10.1109/MS.2009.183,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287014,Programming techniques;concurrent programming;parallel programming;multicore systems;bzip;concurrency;synchronization;patterns;OpenMP;Posix,Multicore processing;Software engineering;Concurrent computing;Software libraries;Application software;Lab-on-a-chip,data compression;parallel programming;software libraries;software tools,multicore software engineering;parallel programming;multicore computers;libraries;tools;sequential Bzip2 compression program,,21.0,,18.0,,16 Oct 2009,,,IEEE,IEEE Magazines
152,152,Embedded-Software Architects: It's Not Only about the Software,P. O. Antonino; A. Morgenstern; T. Kuhn,Fraunhofer Institute for Experimental Software Engineering; Fraunhofer Institute for Experimental Software Engineering; Fraunhofer Institute for Experimental Software Engineering,IEEE Software,28 Oct 2016,2016,33,6,56,62,"Owing to the increasing amount of computation in electromechanical devices, the role of software architect is often found in embedded-systems development. However, because computer scientists usually have limited knowledge of embedded-systems concepts such as controllers, actuators, and buses, embedded-software architects are often engineers with no education in software architecture basics, which is normally a topic in computer science courses. In these environments, serious architectural problems can occur, such as contradictory architecture decisions and inconsistencies between the architecture design and the architecture drivers. This article discusses the current profile of embedded-software architects, characteristics of embedded architectures designed by architects with no computer science background, and the shortcomings of architects whose knowledge is limited to information systems. The authors also discuss how to overcome these challenges.",1937-4194,,10.1109/MS.2016.142,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725234,system architecture;integration and modeling;software architecture;real-time and embedded systems;domain-specific architectures;software development;software engineering;software architect,Computer architecture;Software architecture;Electromechanical devices;Computational modeling,embedded systems;personnel;software architecture;software development management,embedded software architects;electromechanical devices;embedded systems development;software architecture,,11.0,,14.0,,28 Oct 2016,,,IEEE,IEEE Magazines
153,153,"Continuous Delivery: Huge Benefits, but Challenges Too",L. Chen,Paddy Power,IEEE Software,10 Mar 2015,2015,32,2,50,54,"Continuous delivery (CD) has emerged as an auspicious alternative to traditional release engineering, promising to provide the capability to release valuable software continuously to customers. Paddy Power has been implementing CD for the past two years. This article explains why Paddy Power decided to adopt CD, describes the resulting CD capability, and reports the huge benefits and challenges involved. These experiences can provide fellow practitioners with insights for their adoption of CD, and the identified challenges can provide researchers valuable input for developing their research agendas.",1937-4194,,10.1109/MS.2015.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006384,continuous delivery;release engineering;software deployment;DevOps;continuous software engineering;software engineering,Pipelines;Software development;Continuous production;Software engineering;Testing;Companies;Context modeling,research and development;software development management,continuous delivery;release engineering;valuable software;Paddy Power;CD capability;research agendas,,82.0,,5.0,,12 Jan 2015,,,IEEE,IEEE Magazines
154,154,Insights from the Past: The IEEE Software History Experiment,Z. Obrenovic,Software Improvement Group,IEEE Software,11 Jul 2017,2017,34,4,71,78,A look at the IEEE Software history website illustrates the practical value of historical data and offers a glimpse into the magazine's future.,1937-4194,,10.1109/MS.2017.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974718,IEEE Software;software engineering;software development;history;history of software engineering,History;Unified modeling language;Analytical models;Data models;Software engineering;Market research;IEEE publishing,,,,2.0,,12.0,,11 Jul 2017,,,IEEE,IEEE Magazines
155,155,Francois Raynaud on DevSecOps,K. Carter,BinaryMist,IEEE Software,22 Sep 2017,2017,34,5,93,96,"Host Kim Carter talks with Francois Raynaud about how to easily apply DevOps principles to security, and how this helps improve the relationship between security and development teams and ultimately the success of a product or business. The full podcast of this interview is at www.se-radio.net/2017/04/se-radio-episode-288-devsecops.",1937-4194,,10.1109/MS.2017.3571578,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048652,Francois Raynaud;software engineering;DevSecOps;DevOps;security;software development;software security;SE Radio;Software Engineering Radio,Security;Companies;Software engineering;Computer bugs;Software development,,,,4.0,,,,22 Sep 2017,,,IEEE,IEEE Magazines
156,156,Amorphous Slicing of Extended Finite State Machines,K. Androutsopoulos; D. Clark; M. Harman; R. M. Hierons; Z. Li; L. Tratt,"University College London, London; University College London, London; University College London, London; Brunel University, Uxbridge, Middlesex; Beijing University of Chemical Technology, Beijing; King's Colledge London, London",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,892,909,"Slicing is useful for many software engineering applications and has been widely studied for three decades, but there has been comparatively little work on slicing extended finite state machines (EFSMs). This paper introduces a set of dependence-based EFSM slicing algorithms and an accompanying tool. We demonstrate that our algorithms are suitable for dependence-based slicing. We use our tool to conduct experiments on 10 EFSMs, including benchmarks and industrial EFSMs. Ours is the first empirical study of dependence-based program slicing for EFSMs. Compared to the only previously published dependence-based algorithm, our average slice is smaller 40 percent of the time and larger only 10 percent of the time, with an average slice size of 35 percent for termination insensitive slicing.",1939-3520,,10.1109/TSE.2012.72,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374192,Slicing;extended finite state machines,Automata;Algorithm design and analysis;Approximation algorithms;Software algorithms;Unified modeling language;Educational institutions;Electronic mail,finite state machines;program slicing;software engineering,software engineering application;extended finite state machine slicing;dependence-based EFSM slicing algorithm;benchmarks EFSM;industrial EFSM;dependence-based program slicing;termination insensitive slicing;amorphous slicing,,12.0,,62.0,,4 Dec 2012,,,IEEE,IEEE Journals
157,157,The Role of the Tester's Knowledge in Exploratory Software Testing,J. Itkonen; M. V. Mäntylä; C. Lassenius,"Aalto University School of Science, Espoo; Aalto University School of Science, Espoo; Aalto University School of Science, Espoo",IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,707,724,"We present a field study on how testers use knowledge while performing exploratory software testing (ET) in industrial settings. We video recorded 12 testing sessions in four industrial organizations, having our subjects think aloud while performing their usual functional testing work. Using applied grounded theory, we analyzed how the subjects performed tests and what type of knowledge they utilized. We discuss how testers recognize failures based on their personal knowledge without detailed test case descriptions. The knowledge is classified under the categories of domain knowledge, system knowledge, and general software engineering knowledge. We found that testers applied their knowledge either as a test oracle to determine whether a result was correct or not, or for test design, to guide them in selecting objects for test and designing tests. Interestingly, a large number of failures, windfall failures, were found outside the actual focus areas of testing as a result of exploratory investigation. We conclude that the way exploratory testers apply their knowledge for test design and failure recognition differs clearly from the test-case-based paradigm and is one of the explanatory factors of the effectiveness of the exploratory testing approach.",1939-3520,,10.1109/TSE.2012.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298893,Software testing;exploratory testing;validation;test execution;test design;human factors;methods for SQA;and V&V,Software testing;Context;Software;Knowledge engineering;Observers;Organizations,program testing;software engineering,tester knowledge;exploratory software testing;ET;functional testing;grounded theory;personal knowledge;domain knowledge;system knowledge;general software engineering knowledge;test oracle;windfall failures;test design;failure recognition;test-case-based paradigm,,40.0,,76.0,,11 Sep 2012,,,IEEE,IEEE Journals
158,158,Interaction Models and Automated Control under Partial Observable Environments,D. Ciolek; V. Braberman; N. D’Ippolito; N. Piterman; S. Uchitel,"Departamento de Computación, Universidad de Buenos Aires, Argentina; Departamento de Computación, Universidad de Buenos Aires, Argentina; Department of Computing, Imperial College, London, United Kingdom; Department of Computer Science, University of Leicester, Leicester, United Kingdom; Department of Computing, Imperial College, London, United Kingdom",IEEE Transactions on Software Engineering,9 Jan 2017,2017,43,1,19,33,"The problem of automatically constructing a software component such that when executed in a given environment satisfies a goal, is recurrent in software engineering. Controller synthesis is a field which fits into this vision. In this paper we study controller synthesis for partially observable LTS models. We exploit the link between partially observable control and non-determinism and show that, unlike fully observable LTS or Kripke structure control problems, in this setting the existence of a solution depends on the interaction model between the controller-to-be and its environment. We identify two interaction models, namely Interface Automata and Weak Interface Automata, define appropriate control problems and describe synthesis algorithms for each of them.",1939-3520,,10.1109/TSE.2016.2564959,ERC; PBM-FIMBSE; ANPCYT PICT; ANPCYT PICT; ANPCYT PICT; UBACYT; UBACYT; CONICET PIP; MEALS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7466810,LTS;controller synthesis;imperfect-information games,Servers;Maintenance engineering;Automata;Context;Observability;Uncertainty,automata theory;software engineering,interaction models;automated control;software engineering;controller synthesis;partially observable LTS models;partially observable control;weak interface automata;labelled transition systems,,8.0,,35.0,,9 May 2016,,,IEEE,IEEE Journals
159,159,Genetic Algorithms for Randomized Unit Testing,J. H. Andrews; T. Menzies; F. C. H. Li,"University of Western Ontario, London, Ont., Canada; West Virginia University, Morgantown, WV, USA; University of Western Ontario, London, Ont., Canada",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,80,94,"Randomized testing is an effective method for testing software units. The thoroughness of randomized unit testing varies widely according to the settings of certain parameters, such as the relative frequencies with which methods are called. In this paper, we describe Nighthawk, a system which uses a genetic algorithm (GA) to find parameters for randomized unit testing that optimize test coverage. Designing GAs is somewhat of a black art. We therefore use a feature subset selection (FSS) tool to assess the size and content of the representations within the GA. Using that tool, we can reduce the size of the representation substantially while still achieving most of the coverage found using the full representation. Our reduced GA achieves almost the same results as the full system, but in only 10 percent of the time. These results suggest that FSS could significantly optimize metaheuristic search-based software engineering tools.",1939-3520,,10.1109/TSE.2010.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704237,Software testing;randomized testing;genetic algorithms;feature subset selection;search-based optimization;testing tools.,Testing;Biological cells;Gallium;Receivers;Software;Java;Optimization,feature extraction;genetic algorithms;program testing;randomised algorithms;search problems;software engineering,genetic algorithm;randomized unit testing;relative frequency;Nighthawk;optimized test coverage;feature subset selection tool;metaheuristic search;software engineering tool;software testing,,46.0,,49.0,,28 Jan 2011,,,IEEE,IEEE Journals
160,160,Safer User Interfaces: A Case Study in Improving Number Entry,H. Thimbleby,"Department of Computer Science, Swansea University, Swansea SA2 0SF, Wales, United Kingdom",IEEE Transactions on Software Engineering,14 Jul 2015,2015,41,7,711,729,"Numbers are used in critical applications, including finance, healthcare, aviation, and of course in every aspect of computing. User interfaces for number entry in many devices (calculators, spreadsheets, infusion pumps, mobile phones, etc.) have bugs and design defects that induce unnecessary use errors that compromise their dependability. Focusing on Arabic key interfaces, which use digit keys 0-9-· usually augmented with correction keys, this paper introduces a method for formalising and managing design problems. Since number entry and devices such as calculators have been the subject of extensive user interface research since at least the 1980s, the diverse design defects uncovered imply that user evaluation methodologies are insufficient for critical applications. Likewise, formal methods are not being applied effectively. User interfaces are not trivial and more attention should be paid to their correct design and implementation. The paper includes many recommendations for designing safer number entry user interfaces.",1939-3520,,10.1109/TSE.2014.2383396,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991548,Error processing;Software/Software Engineering;User interfaces;Human Factors in Software Design;User Interfaces;Information Interfaces;Representation (HCI);Error processing;software/software engineering;user interfaces;human factors in software design;user interfaces;information interfaces and representation (HCI),User interfaces;Calculators;Computer bugs;Safety;Pressing;Software;Debugging,user interfaces,safer user interfaces;number entry;Arabic key interfaces;correction keys;design problem formalization;design problem management,,15.0,,47.0,,18 Dec 2014,,,IEEE,IEEE Journals
161,161,Testing from Partial Finite State Machines without Harmonised Traces,R. M. Hierons,"Department of Computer Science, Brunel University London, Uxbridge, United Kingdom",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1033,1043,"This paper concerns the problem of testing from a partial, possibly non-deterministic, finite state machine (FSM) S. Two notions of correctness (quasi-reduction and quasi-equivalence) have previously been defined for partial FSMs but these, and the corresponding test generation techniques, only apply to FSMs that have harmonised traces. We show how quasi-reduction and quasi-equivalence can be generalised to all partial FSMs. We also consider the problem of generating an m-complete test suite from a partial FSM S: a test suite that is guaranteed to determine correctness as long as the system under test has no more than m states. We prove that we can complete S to form a completely-specified non-deterministic FSM S' such that any m-complete test suite generated from S' can be converted into an m-complete test suite for S. We also show that there is a correspondence between test suites that are reduced for S and S' and also that are minimal for S and S'.",1939-3520,,10.1109/TSE.2017.2652457,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7815407,Software engineering/software/program verification;software engineering/testing and debugging;systems and software;checking experiment;partial finite state machine,Testing;Fault detection;Redundancy;Automata;Indexes;Software;Debugging,finite state machines;formal specification;program testing,finite state machine;test generation techniques;nondeterministic FSM;partial finite state machines;m-complete test suite;harmonised traces;partial FSMs,,,,30.0,Traditional,16 Jan 2017,,,IEEE,IEEE Journals
162,162,An Investigation into the Functional Form of the Size-Defect Relationship for Software Modules,A. G. Koru; D. Zhang; K. El Emam; H. Liu,"University of Maryland Baltimore County, Baltimore; University of Maryland Baltimore County, Baltimore; University of Ottawa, Ottawa; Georgetown University, Washington",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,293,304,"The importance of the relationship between size and defect proneness of software modules is well recognized. Understanding the nature of that relationship can facilitate various development decisions related to prioritization of quality assurance activities. Overall, the previous research only drew a general conclusion that there was a monotonically increasing relationship between module size and defect proneness. In this study, we analyzed class-level size and defect data in order to increase our understanding of this crucial relationship. In order to obtain validated and more generalizable results, we studied four large-scale object-oriented products, Mozilla, Cn3d, JBoss, and Eclipse. Our results consistently revealed a significant effect of size on defect proneness; however, contrary to common intuition, the size-defect relationship took a logarithmic form, indicating that smaller classes were proportionally more problematic than larger classes. Therefore, practitioners should consider giving higher priority to smaller modules when planning focused quality assurance activities with limited resources. For example, in Mozilla and Eclipse, an inspection strategy investing 80% of available resources on 100-LOC classes and the rest on 1,000-LOC classes would be more than twice as cost effective as the opposite strategy. These results should be immediately useful to guide focused quality assurance activities in large-scale software projects.",1939-3520,,10.1109/TSE.2008.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4693715,Software science;Product metrics;Planning for SQA and Measurement applied to SQA and Software Quality/SQA;Software Engineering;Software/Software Engin;Open-source software;Software science;Product metrics;Planning for SQA and Measurement applied to SQA and Software Quality/SQA;Software Engineering;Software/Software Engin;Open-source software,Open source software;Software quality;Size measurement;Inspection;Object oriented modeling;Predictive models;Quality assurance;Large-scale systems;Software measurement;Density measurement,object-oriented methods;project management;software management;software metrics;software quality,software modules;size-defect relationship;quality assurance activities;object-oriented products;Mozilla;Cn3d;JBoss;Eclipse;software projects;product metrics,,82.0,,60.0,,2 Dec 2008,,,IEEE,IEEE Journals
163,163,State-Density Functions over DBM Domains in the Analysis of Non-Markovian Models,L. Carnevali; L. Grassi; E. Vicario,"Università di Firenze, Firenze; Università di Firenze, Firenze; Università di Firenze, Firenze",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,178,194,"Quantitative evaluation of models with generally-distributed transitions requires analysis of non-Markovian processes that may be not isomorphic to their underlying untimed models and may include any number of concurrent non-exponential timers. The analysis of stochastic Time Petri Nets copes with the problem by covering the state space with stochastic-classes, which extend Difference Bounds Matrices (DBM) with a state probability density function. We show that the state-density function accepts a continuous piecewise representation over a partition in DBM-shaped sub-domains. We then develop a closed-form symbolic calculus of state-density functions assuming that model transitions have expolynomial distributions. The calculus shows that within each sub-domain the state-density function is a multivariate expolynomial function and makes explicit how this form evolves through subsequent transitions. This enables an efficient implementation of the analysis process and provides the formal basis that supports introduction of an approximate analysis based on Bernstein Polynomials. The approximation attacks practical and theoretical limits in the applicability of stochastic state-classes, and devises a new approach to the analysis of non Markovian models, relying on approximations in the state space rather than in the structure of the model.",1939-3520,,10.1109/TSE.2008.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711059,Software Engineering;Tools;Validation;Software and System Safety;Software/Program Verification;Formal methods;Reliability;Automata;Parallelism and concurrency;Approximation;Markov processes;Renewal theory;Stochastic processes;Software Engineering;Tools;Validation;Software and System Safety;Software/Program Verification;Formal methods;Reliability;Automata;Parallelism and concurrency;Approximation;Markov processes;Renewal theory;Stochastic processes,Stochastic processes;Function approximation;State-space methods;Petri nets;Density functional theory;Calculus;Polynomials;Software safety;Timing;Encoding,calculus;concurrency control;Petri nets;polynomial approximation;polynomial matrices;program verification;state-space methods;statistical distributions;stochastic processes,difference bound matrix domain;nonMarkovian model analysis;concurrent nonexponential timer;stochastic time Petri net;state space;state probability density function;continuous piecewise representation;closed-form symbolic calculus;expolynomial distribution;multivariate expolynomial function;approximate analysis;Bernstein polynomial;quantitative evaluation;untimed model;timed software verification,,25.0,,39.0,,12 Dec 2008,,,IEEE,IEEE Journals
164,164,Automatic Extraction of Heap Reference Properties in Object-Oriented Programs,B. Demsky; M. Rinard,"University of California, Irvine, Irvine; Massachusetts Institute of Technology, Cambridge",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,305,324,"We present a new technique for helping developers understand heap referencing properties of object-oriented programs and how the actions of the program affect these properties. Our dynamic analysis uses the aliasing properties of objects to synthesize a set of roles; each role represents an abstract object state intended to be of interest to the developer. We allow the developer to customize the analysis to explore the object states and behavior of the program at multiple different and potentially complementary levels of abstraction. The analysis uses roles as the basis for three abstractions: role transition diagrams, which present the observed transitions between roles and the methods responsible for the transitions; role relationship diagrams, which present the observed referencing relationships between objects playing different roles; and enhanced method interfaces, which present the observed roles of method parameters. Together, these abstractions provide useful information about important object and data structure properties and how the actions of the program affect these properties. We have implemented the role analysis and have used this implementation to explore the behavior of several Java programs. Our experience indicates that, when combined with a powerful graphical user interface, roles are a useful abstraction for helping developers explore and understand the behavior of object-oriented programs.",1939-3520,,10.1109/TSE.2008.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4693716,Program understanding;roles;design recovery.;Requirements/Specifications;Design Tools and Techniques;Software Engineering;Software/Software Engineering;Testing and Debugging,Data structures;Computer Society;Java;Graphical user interfaces;Information analysis;Data mining,data structures;diagrams;graphical user interfaces;Java;object-oriented programming;reverse engineering,automatic extraction;heap reference property;object-oriented program;role transition diagram;enhanced method interface;data structure;Java program;graphical user interface;program understanding;role relationship diagram,,3.0,1.0,30.0,,2 Dec 2008,,,IEEE,IEEE Journals
165,165,Ant Colony Optimization for Software Project Scheduling and Staffing with an Event-Based Scheduler,W. Chen; J. Zhang,"Sun Yat-sen University, Guangzhou; Sun Yat-sen University, Guangzhou",IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,1,17,"Research into developing effective computer aided techniques for planning software projects is important and challenging for software engineering. Different from projects in other fields, software projects are people-intensive activities and their related resources are mainly human resources. Thus, an adequate model for software project planning has to deal with not only the problem of project task scheduling but also the problem of human resource allocation. But as both of these two problems are difficult, existing models either suffer from a very large search space or have to restrict the flexibility of human resource allocation to simplify the model. To develop a flexible and effective model for software project planning, this paper develops a novel approach with an event-based scheduler (EBS) and an ant colony optimization (ACO) algorithm. The proposed approach represents a plan by a task list and a planned employee allocation matrix. In this way, both the issues of task scheduling and employee allocation can be taken into account. In the EBS, the beginning time of the project, the time when resources are released from finished tasks, and the time when employees join or leave the project are regarded as events. The basic idea of the EBS is to adjust the allocation of employees at events and keep the allocation unchanged at nonevents. With this strategy, the proposed method enables the modeling of resource conflict and task preemption and preserves the flexibility in human resource allocation. To solve the planning problem, an ACO algorithm is further designed. Experimental results on 83 instances demonstrate that the proposed method is very promising.",1939-3520,,10.1109/TSE.2012.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165315,Software project planning;project scheduling;resource allocation;workload assignment;ant colony optimization (ACO),Software;Resource management;Planning;Humans;Project management;Job shop scheduling;Search problems,ant colony optimisation;human resource management;planning (artificial intelligence);project management;scheduling;software management,ant colony optimization algorithm;software project scheduling;software project staffing;event-based scheduler;computer aided techniques;software project planning;software engineering;project task scheduling problem;human resource allocation problem;EBS;ACO;task list;planned employee allocation matrix;resource conflict modeling;task preemption modeling,,94.0,,51.0,,6 Mar 2012,,,IEEE,IEEE Journals
166,166,MOSES: A Framework for QoS Driven Runtime Adaptation of Service-Oriented Systems,V. Cardellini; E. Casalicchio; V. Grassi; S. Iannucci; F. L. Presti; R. Mirandola,"University of Roma ""Tor Vergata"", Roma; University of Roma ""Tor Vergata"", Roma; University of Roma ""Tor Vergata"", Roma; University of Roma ""Tor Vergata"", Roma; University of Roma ""Tor Vergata"", Roma; Politecnico di Milano, Milano",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1138,1159,"Architecting software systems according to the service-oriented paradigm and designing runtime self-adaptable systems are two relevant research areas in today's software engineering. In this paper, we address issues that lie at the intersection of these two important fields. First, we present a characterization of the problem space of self-adaptation for service-oriented systems, thus providing a frame of reference where our and other approaches can be classified. Then, we present MOSES, a methodology and a software tool implementing it to support QoS-driven adaptation of a service-oriented system. It works in a specific region of the identified problem space, corresponding to the scenario where a service-oriented system architected as a composite service needs to sustain a traffic of requests generated by several users. MOSES integrates within a unified framework different adaptation mechanisms. In this way it achieves greater flexibility in facing various operating environments and the possibly conflicting QoS requirements of several concurrent users. Experimental results obtained with a prototype implementation of MOSES show the effectiveness of the proposed approach.",1939-3520,,10.1109/TSE.2011.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963694,Service-oriented architecture;runtime adaptation;quality of service,Service oriented architecture;Quality of service;Runtime;Concrete;Semiconductor optical amplifiers;Adaptation models;Software systems,service-oriented architecture,MOSES;QoS driven runtime adaptation;service oriented system;software system architecture;service oriented paradigm;runtime self adaptable system;software engineering;self adaptation;QoS-driven adaptation;service-oriented system,,91.0,,62.0,,28 Jul 2011,,,IEEE,IEEE Journals
167,167,Combining Perceptions and Prescriptions in Requirements Engineering Process Assessment: An Industrial Case Study,N. P. Napier; L. Mathiassen; R. D. Johnson,"Georgia Gwinnett College, Lawrenceville; Georgia State University, Atlanta; University of Pretoria, Pretoria",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,593,606,"Requirements engineering (RE) is a key discipline in software development and several methods are available to help assess and improve RE processes. However, these methods rely on prescriptive models of RE; they do not, like other disciplines within software engineering, draw directly on stakeholder perceptions and subjective judgments. Given this backdrop, we present an empirical study in RE process assessment. Our aim was to investigate how stakeholder perceptions and process prescriptions can be combined during assessments to effectively inform RE process improvement. We first describe existing methods for RE process assessment and the role played by stakeholder perceptions and subjective judgments in the software engineering and management literature. We then present a method that combines perceptions and prescriptions in RE assessments together with an industrial case study in which the method was applied and evaluated over a three-year period at TelSoft. The data suggest that the combined method led to a comprehensive and rich assessment and it helped TelSoft consider RE as an important and integral part of the broader engineering context. This, in turn, led to improvements that combined plan-driven and adaptive principles for RE. Overall, the combined method helped TelSoft move from Level 1 to Level 2 in RE maturity, and the employees perceived the resulting engineering practices to be improved. Based on these results, we suggest that software managers and researchers combine stakeholder perceptions and process prescriptions as one way to effectively balance the specificity, comparability, and accuracy of software process assessments.",1939-3520,,10.1109/TSE.2009.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967614,Process implementation and change;qualitative process analysis;requirements engineering process;software management;software process.,Software engineering;Computer industry;Programming;Engineering management;Software quality;Project management;Risk management;Educational institutions;Data engineering;Quality management,formal specification;formal verification;project management;software development management;software maintenance;software process improvement;software quality;statistical analysis;systems analysis,requirements engineering process assessment;industrial case study;software development;RE prescription model;software engineering;stakeholder perception;subjective judgment;empirical study;software RE process improvement;software project management;TelSoft;plan-driven principle;adaptive principle;software process change;qualitative process analysis,,22.0,,56.0,,26 May 2009,,,IEEE,IEEE Journals
168,168,A Framework for Evaluating the Results of the SZZ Approach for Identifying Bug-Introducing Changes,D. A. da Costa; S. McIntosh; W. Shang; U. Kulesza; R. Coelho; A. E. Hassan,"Department of Informatics and Applied Mathematics (DIMAp), Federal University of Rio Grande do Norte, Natal-RN, Brazil; Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Informatics and Applied Mathematics (DIMAp), Federal University of Rio Grande do Norte, Natal-RN, Brazil; Department of Informatics and Applied Mathematics (DIMAp), Federal University of Rio Grande do Norte, Natal-RN, Brazil; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen’s University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,14 Jul 2017,2017,43,7,641,657,"The approach proposed by Silwerski, Zimmermann, and Zeller (SZZ) for identifying bug-introducing changes is at the foundation of several research areas within the software engineering discipline. Despite the foundational role of SZZ, little effort has been made to evaluate its results. Such an evaluation is a challenging task because the ground truth is not readily available. By acknowledging such challenges, we propose a framework to evaluate the results of alternative SZZ implementations. The framework evaluates the following criteria: (1) the earliest bug appearance, (2) the future impact of changes, and (3) the realism of bug introduction. We use the proposed framework to evaluate five SZZ implementations using data from ten open source projects. We find that previously proposed improvements to SZZ tend to inflate the number of incorrectly identified bug-introducing changes. We also find that a single bug-introducing change may be blamed for introducing hundreds of future bugs. Furthermore, we find that SZZ implementations report that at least 46 percent of the bugs are caused by bug-introducing changes that are years apart from one another. Such results suggest that current SZZ implementations still lack mechanisms to accurately identify bug-introducing changes. Our proposed framework provides a systematic mean for evaluating the data that is generated by a given SZZ implementation.",1939-3520,,10.1109/TSE.2016.2616306,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7588121,SZZ;evaluation framework;bug detection;software repository mining,Computer bugs;Software engineering;Electronic mail;Software;Manuals;History;Systematics,program debugging,SZZ approach;bug-introducing change identification;Silwerski-Zimmermann-Zeller approach;ground truth;open source projects;data evaluation,,18.0,,54.0,,11 Oct 2016,,,IEEE,IEEE Journals
169,169,Managing Software Complexity and Variability in Coupled Climate Models,S. Rugaber; R. Dunlap; l. mark; S. Ansari,Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology; Georgia Institute of Technology,IEEE Software,20 Oct 2011,2011,28,6,43,48,"Coupled climate models exhibit scientific, numerical, and architectural variability. This variability introduces requirements that give rise to complexity. However, techniques exist that can tame this complexity; one such technique is feature analysis. As climate model fidelity and complexity increase, the climate-modeling community should adopt a systematic way to deal with software variability.",1937-4194,,10.1109/MS.2011.114,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999646,climate modeling;earth and atmospheric sciences;automatic programming;domain engineering;reusable software;software engineering,Meteorology;Atmospheric modeling;Global warming;Software development;Atmospheric measurements;Analytical models;Data models,computational complexity;software engineering,software complexity;software variability;coupled climate models;architectural variability;numerical variability;scientific variability;feature analysis;climate modeling community,,3.0,,13.0,,25 Aug 2011,,,IEEE,IEEE Magazines
170,170,On the Impact of Being Open,R. Schuwer; M. van Genuchten; L. Hatton,Fontys University of Applied Sciences; VitalHealth; Kingston University,IEEE Software,21 Aug 2015,2015,32,5,81,83,"There's much discussion about being open, with topics such as open source software, open innovation, open research, and open education. Will the whole world be open, and, if so, what was all closed in the past? The authors analyze the similarities and differences between the open movements they've been part of and come up with expectations for software's future.",1937-4194,,10.1109/MS.2015.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217776,open source;open source software;open education;open research;Creative Commons;open educational resources;OER;massive open online courses;MOOC;software development;software engineering,Companies;Open Access;Education;Open source software;Linux;Licenses,public domain software;software engineering,open source software;open education;open research;open innovation,,7.0,,14.0,,21 Aug 2015,,,IEEE,IEEE Magazines
171,171,"Agile Documentation, Anyone?",B. Selic,Malina Software Corp.,IEEE Software,16 Oct 2009,2009,26,6,11,12,"Software developers are notorious for skimping on design documentation, often eschewing it altogether. This trend has led to claims that it is merely an impediment in the fast-paced and highly pliable world of software development-a useless vestige of old-style engineering that should be eliminated altogether. While recognizing the unique nature of software, the author argues that, because of the complexity of modern software systems and the cryptic nature of current programming languages, good design documentation is not only useful but vital. However, we must seek ways of adapting it to suit the medium as well as the exceptionally dynamic development process.",1937-4194,,10.1109/MS.2009.167,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287001,Documentation;Software engineering;Software maintenance,Documentation;Impedance;Software systems;Computer languages,software engineering;system documentation,agile documentation;software development;old-style engineering;modern software system complexity;programming languages;dynamic development process,,30.0,,2.0,,16 Oct 2009,,,IEEE,IEEE Magazines
172,172,Drawing Conclusions from Linked Data on the Web: The EYE Reasoner,R. Verborgh; J. De Roo,Multimedia Lab; Agfa Healthcare,IEEE Software,23 Apr 2015,2015,32,3,23,27,Linked data represents each piece of data as a link between two things. It lets software reasoners arrive at conclusions in a human-like way. This column discusses how the EYE reasoner exploits linked data and how industry is employing EYE.,1937-4194,,10.1109/MS.2015.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093047,EYE;Semantic Web;software engineering;software development;reasoning;linked data,Software;Cognition;Resource description framework;Engines;Uniform resource locators;Hardware,Internet;software engineering,linked data;eye reasoner;software reasoners,,20.0,,2.0,,23 Apr 2015,,,IEEE,IEEE Magazines
173,173,Frequently Unanswered Questions,G. J. Holzmann,Jet Propulsion Laboratory,IEEE Software,25 Apr 2016,2016,33,3,10,12,"We often think of software development as an ideally streamlined process consisting of three phases: design, build, and test. If we want our code to be useful to anyone, though, we'll reluctantly have to acknowledge that we also need a documentation phase, which typically comes at the very end. Generally, there will be some iterations across these phases before we get everything right. In large software development projects, the design phase should result in a list of requirements the final code must satisfy. There's no reason why you couldn't develop the test suite at that point, which should eventually be able to show that each requirement was met. Documenting the requirements and tests up front will force you to be clear about the intended performance envelope of an application. That in turn can let you make an informed assessment of the risk that the application will find itself outside that performance envelope when conditions aren't favorable.",1937-4194,,10.1109/MS.2016.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458766,software documentation;software design;programming;test-driven development;model-driven design;software engineering;software development,Documentation;Software;Manuals;Reliability;Force;Games,program testing;software engineering,software development;software design phase;software build phase;software test phase,,,,4.0,,25 Apr 2016,,,IEEE,IEEE Magazines
174,174,Work Substitution: A Neo-Luddite Look at Software Growth,A. Rutkowski,Tilburg University,IEEE Software,25 Apr 2016,2016,33,3,101,104,"With the big data trend, automated algorithmic decision making will open the door to countless more lines of code. Too many people already worship and revere software as a solution to human needs. And, in a continuous spiral, more data collection accelerates the need for more technology and more automated decision support systems. On a neo-Luddite view, the author is concerned about how such systems will impact our safety, sense of privacy, and psychological well-being, and in the long run replace the best of our humanity-our gut feelings. The author proposes to switch your empathetic button on and consider some of the consequence of building too much software, particularly if you're building automated decision support systems.",1937-4194,,10.1109/MS.2016.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458772,neo-Luddite;software growth;automated systems;self-driving cars;software automation;aviation software;healthcare software;software engineering;software development,Software development;Decision making;Self-driving automobiles;Medical services;Physiology;Automation;Aircraft,decision support systems;software engineering,neo-Luddite view;software growth;Big Data;data collection;decision support systems,,4.0,,17.0,,25 Apr 2016,,,IEEE,IEEE Magazines
175,175,Multimedia Software for Mobile Phones,L. Bouchard,RealNetworks,IEEE Software,19 Apr 2010,2010,27,3,8,10,"The amount of software in mobile phones has increased dramatically over recent years-up to 20 million LOC in some cases-resulting in a magnitude of new features from apps to multimedia. To keep up with the rapidly expanding market, software developers for mobile phones must be innovative and astute.",1937-4194,,10.1109/MS.2010.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452142,software engineering;standards;RealNetworks;Helix;best practices;mobile phones,Mobile handsets;Lab-on-a-chip,mobile computing;mobile handsets;multimedia communication;software engineering,multimedia software;mobile phones;software developer,,10.0,,,,19 Apr 2010,,,IEEE,IEEE Magazines
176,176,Out of Bounds,G. J. Holzmann,Jet Propulsion Laboratory,IEEE Software,28 Oct 2015,2015,32,6,24,26,"Writing reliable code means understanding bounds. Only a finite amount of memory is available for computation, only a finite amount of time exists to do it, and every object we store and modify must be finite. Resources are similarly bounded. Stacks are bounded, queues are bounded, file system capacity is bounded, and even numbers are bounded. This makes the world of computer science very different from the world of mathematics, but too few people take this into account when they write code.",1937-4194,,10.1109/MS.2015.147,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310984,reliable code;counter overflow;Deep Impact;Boeing 787;Dreamliner;generator control unit;GCU;LightSail;Curiosity;Mars rover;EPOXI;software engineering;software development,Radiation detectors;Space vehicles;Flash memories;File systems;Random access memory,software engineering,code writing;similarly bounded Resources;bounded stacks;bounded queues;bounded file system capacity;bounded numbers;computer science,,1.0,,2.0,,28 Oct 2015,,,IEEE,IEEE Magazines
177,177,The Role of Design Spaces,M. Shaw,Carnegie-Mellon University,IEEE Software,22 Dec 2011,2012,29,1,46,50,"A central task in design is deciding what artifact will best satisfy the client's needs, whether that requires creating an artifact or choosing from existing alternatives. A design space identifies and organizes the decisions that must be made, together with the alternatives for those decisions, thereby providing guidance for creating artifacts or a framework for comparing them. The Studying Professional Software Design workshop studied three pairs of professional software designers sketching designs for a traffic signal simulator. A discussion of the design space for the simulation task shows how this design space enables comparison of the designs. It also illustrates the benefits of explicitly considering the design space during design and the risks of failing to do so.",1937-4194,,10.1109/MS.2011.121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030869,software engineering;design;software design;design space,Software design;Software architecture;Software design;Product development;Object oriented modeling,software engineering,design space;Studying Professional Software Design workshop;traffic signal simulator,,11.0,,11.0,,29 Sep 2011,,,IEEE,IEEE Magazines
178,178,In the Pursuit of Hygge Software,H. D. Vianna; J. L. V. Victória Barbosa; F. Pittoli,University of Vale do Rio dos Sinos; University of Vale do Rio dos Sinos; University of Vale do Rio dos Sinos,IEEE Software,13 Nov 2017,2017,34,6,48,52,Hygge is a Danish and Norwegian word for well-being related to conviviality. Two healthcare scenarios show ways to achieve hygge by integrating software and distributed technologies.,1937-4194,,10.1109/MS.2017.4121208,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106876,distributed applications;ubiquitous computing;real-time systems;embedded systems;pervasive computing;hygge;U’Ductor;ChronicDuctor;ChronicPrediction;healthcare;software development;software engineering;context-aware and smart healthcare,Middleware;Medical services;Real-time systems;Embedded systems;Privacy;Access control;Context awareness,distributed processing;health care;software engineering,distributed technologies;healthcare;Hygge software,,,,7.0,,13 Nov 2017,,,IEEE,IEEE Magazines
179,179,Monitoring Requirements in Systems of Systems,M. Vierhauser; R. Rabiser; P. Grünbacher,Johannes Kepler University Linz; Johannes Kepler University Linz; Johannes Kepler University Linz,IEEE Software,24 Aug 2016,2016,33,5,22,24,"Developers of systems of systems (SoSs) face challenges such as heterogeneous, inconsistent, and changing elements; continuous evolution and deployment; decentralized control; and inherently conflicting and often unknowable requirements. In response to these challenges, researchers are developing the ReMinds tool. Engineers can use it to instrument systems in an SoS to extract events and data at runtime and to define requirements as constraints to check expected behavior and properties. ReMinds can also visualize and explain requirements violations to facilitate diagnosis.",1937-4194,,10.1109/MS.2016.112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548894,systems of systems;SoS;ReMinds;software requirements;software development;software engineering,Monitoring;Heterogeneous networks;Runtime;Decentralized control;Software systems;Data mining;Data visualization;Runtime,software engineering,SoS requirements monitoring;system-of-systems;ReMinds tool,,,,6.0,,24 Aug 2016,,,IEEE,IEEE Magazines
180,180,Job Security,D. Spinellis,Athens University of Economics and Business,IEEE Software,25 Aug 2009,2009,26,5,14,15,"In this paper, job security in code design is discussed. Techniques on how to make codes unreadable is mentioned. Like when naming variables, methods, fields, and classes, the readers can use some languages such as Java that is well-established naming conventions regarding capitalization and the joining of words. The author also suggest that the reader can make use of many IDEs that insert boilerplate comments at the beginning of each method and class. This column also suggest that the more unreadable the code the more indispensable a programmer with his job.",1937-4194,,10.1109/MS.2009.131,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222787,job security;maintainability;analyzability;coupling;stability;testability;design;software engineering,Testing;Data security;Job design;Packaging;Information services;Web sites;Internet;Programming profession;Debugging;Protocols,design engineering;DP industry;software engineering;unemployment,job security;Java;code design;programmer,,,,,,25 Aug 2009,,,IEEE,IEEE Magazines
181,181,Gamification,D. Basten,University of Cologne,IEEE Software,22 Sep 2017,2017,34,5,76,81,Games can help motivate people in otherwise nongame scenarios and engage users in high interaction. This article explores gamification applications and underlying technologies.,1937-4194,,10.1109/MS.2017.3571581,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048643,Badgeville Enterprise Plus;CROWN SharePoint Learning Management System;customer relationship management;Ford p2p Cup;Ford Professional Performance Program Cup;gamification;Jive Advanced Gamification Module;Nitro;SAP Cloud Platform Gamification;software development;software engineering;Zoho CRM;Zurmo,Customer relationship management;Software testing;Games;Companies;Training;Mobile communication,computer games;human computer interaction;software engineering;user interfaces,gamification;users interaction;software technologies,,6.0,,10.0,,22 Sep 2017,,,IEEE,IEEE Magazines
182,182,Conway's Law Revisited: The Evidence for a Task-Based Perspective,I. Kwan; M. Cataldo; D. Damian,Oregon State University; Robert Bosch; University of Victoria,IEEE Software,22 Dec 2011,2012,29,1,90,93,"Conway's law, also called the mirroring hypothesis, predicts that a development organization will inevitably design systems that mirror its organizational communication structure. The alignment between architecture and communication applies to physical systems, but not necessarily to software systems. In this article, the authors present evidence that a task-level view of Conway's law can realize the benefits of alignment in software systems.",1937-4194,,10.1109/MS.2012.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111370,software design;software architecture;organizations;evidence-based software engineering;engineering management,Software design;Product development;Prediction theory;Software deveopment,law;software engineering,Conway law;task-based perspective;mirroring hypothesis law;organizational communication structure;software system alignment,,18.0,,18.0,,22 Dec 2011,,,IEEE,IEEE Magazines
183,183,Software Module Clustering as a Multi-Objective Search Problem,K. Praditwong; M. Harman; X. Yao,"The University of Birmingham, Birmingham; University College London, London; The University of Birmingham, Birmingham",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,264,282,"Software module clustering is the problem of automatically organizing software units into modules to improve program structure. There has been a great deal of recent interest in search-based formulations of this problem in which module boundaries are identified by automated search, guided by a fitness function that captures the twin objectives of high cohesion and low coupling in a single-objective fitness function. This paper introduces two novel multi-objective formulations of the software module clustering problem, in which several different objectives (including cohesion and coupling) are represented separately. In order to evaluate the effectiveness of the multi-objective approach, a set of experiments was performed on 17 real-world module clustering problems. The results of this empirical study provide strong evidence to support the claim that the multi-objective approach produces significantly better solutions than the existing single-objective approach.",1939-3520,,10.1109/TSE.2010.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406532,SBSE;module clustering;multi-objective optimization;evolutionary computation.,Search problems;Computer science;Performance evaluation;Software engineering;Clustering algorithms;Computational intelligence;Testing;Educational institutions;Computer applications;Application software,optimisation;pattern clustering;search problems;software engineering,software module clustering;multi-objective search problem;program structure,,210.0,1.0,32.0,,5 Feb 2010,,,IEEE,IEEE Journals
184,184,Mining Sequences of Developer Interactions in Visual Studio for Usage Smells,K. Damevski; D. C. Shepherd; J. Schneider; L. Pollock,"Department of Computer Science, Virginia Commonwealth University, Richmond, VA; ABB Corporate Research, Raleigh, NC; ABB Corporate Research, Baden-Dättwill, Switzerland; Department of Computer and Information Sciences, University of Delaware, Newark, DE",IEEE Transactions on Software Engineering,14 Apr 2017,2017,43,4,359,371,"In this paper, we present a semi-automatic approach for mining a large-scale dataset of IDE interactions to extract usage smells, i.e., inefficient IDE usage patterns exhibited by developers in the field. The approach outlined in this paper first mines frequent IDE usage patterns, filtered via a set of thresholds and by the authors, that are subsequently supported (or disputed) using a developer survey, in order to form usage smells. In contrast with conventional mining of IDE usage data, our approach identifies time-ordered sequences of developer actions that are exhibited by many developers in the field. This pattern mining workflow is resilient to the ample noise present in IDE datasets due to the mix of actions and events that these datasets typically contain. We identify usage patterns and smells that contribute to the understanding of the usability of Visual Studio for debugging, code search, and active file navigation, and, more broadly, to the understanding of developer behavior during these software development activities. Among our findings is the discovery that developers are reluctant to use conditional breakpoints when debugging, due to perceived IDE performance problems as well as due to the lack of error checking in specifying the conditional.",1939-3520,,10.1109/TSE.2016.2592905,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516714,IDE usage data;data mining;pattern mining;usability analysis,Data mining;Visualization;Usability;Data analysis;Debugging;Software engineering;Navigation,data mining;program debugging;software engineering,developer interactions sequences mining;visual studio;usage smells extraction;large-scale dataset mining;IDE interactions;frequent IDE usage pattern mining;time-ordered sequences identifies;active file navigation;code search;software development activities,,20.0,,26.0,,19 Jul 2016,,,IEEE,IEEE Journals
185,185,Keeping the Development Environment Up to Date—A Study of the Situated Practices of Appropriating the Eclipse IDE,S. Draxler; G. Stevens; A. Boden,"Department for Information Systems and New Media, University of Siegen, Siegen, Germany; Department for Information Systems and New Media, University of Siegen, Siegen, Germany; Usability and User Experience Design Competence Center, Fraunhofer Institute for Applied Information Technology FIT, Sankt Augustin, Germany",IEEE Transactions on Software Engineering,10 Nov 2014,2014,40,11,1061,1074,"Software engineers and developers are surrounded by highly complex software systems. What does it take to cope with these? We introduce a field study that explores the maintenance of the Eclipse Integrated Development Environment by software developers as part of their daily work. The study focuses on appropriation of the Eclipse IDE. We present an empirical view on appropriation as a means to maintain the collective ability to work. We visited seven different organizations and observed and interviewed their members. Each organization was chosen to provide an overall picture of Eclipse use throughout the industry. The results decompose the appropriation of Eclipse by software developers in organizations into four categories: learning, tailoring and discovering, as well as the cross-cutting category: collaboration. The categories are grounded in situations that provoked a need to change as well as in policies adopted for coping with this need. By discussing these categories against the background of Eclipse and its ecosystem, we want to illustrate in what ways appropriation of component- or plugin- based software is nowadays a common and highly complex challenge for Eclipse users, and how the related appropriation practices can be supported by IT systems.",1939-3520,,10.1109/TSE.2014.2354047,German Federal Ministry for Education and Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898825,Programmer workbench;human factors in software design;deployment;usage experience,Software;Organizations;Computer aided software engineering;Interviews;Context;Employment;Ecosystems,object-oriented languages;object-oriented programming;software engineering,development environment;Eclipse IDE;software engineers;software developers;highly complex software systems;Eclipse Integrated Development Environment;component-based software;plugin-based software;IT systems,,2.0,,60.0,,15 Sep 2014,,,IEEE,IEEE Journals
186,186,Effect of Domain Knowledge on Elicitation Effectiveness: An Internally Replicated Controlled Experiment,A. M. Aranda; O. Dieste; N. Juristo,"Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Campus de Montegancedo, Boadilla del Monte, Spain",IEEE Transactions on Software Engineering,12 May 2016,2016,42,5,427,451,"Context. Requirements elicitation is a highly communicative activity in which human interactions play a critical role. A number of analyst characteristics or skills may influence elicitation process effectiveness. Aim. Study the influence of analyst problem domain knowledge on elicitation effectiveness. Method. We executed a controlled experiment with post-graduate students. The experimental task was to elicit requirements using open interview and consolidate the elicited information immediately afterwards. We used four different problem domains about which students had different levels of knowledge. Two tasks were used in the experiment, whereas the other two were used in an internal replication of the experiment; that is, we repeated the experiment with the same subjects but with different domains. Results. Analyst problem domain knowledge has a small but statistically significant effect on the effectiveness of the requirements elicitation activity. The interviewee has a big positive and significant influence, as does general training in requirements activities and interview experience. Conclusion. During early contacts with the customer, a key factor is the interviewee; however, training in tasks related to requirements elicitation and knowledge of the problem domain helps requirements analysts to be more effective.",1939-3520,,10.1109/TSE.2015.2494588,Spanish Ministry of Ministry of Economy and Competitiveness; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7307191,Controlled experiment;domain knowledge;requirements elicitation;internal replication;Controlled experiment;domain knowledge;requirements elicitation;internal replication,Interviews;Knowledge engineering;Computer science;Software engineering;Requirements engineering;Training,software engineering,requirements elicitation;elicitation effectiveness;internally replicated controlled experiment;problem domain knowledge,,15.0,,56.0,,26 Oct 2015,,,IEEE,IEEE Journals
187,187,The Impact of Lessons-Learned Sessions on Effort Estimation and Uncertainty Assessments,M. Jørgensen; T. M. Gruschke,"Simula Research Laboratory and University of Oslo, Norway; KnowIT Objectnet, Oslo",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,368,383,"Inaccurate estimates of software development effort is a frequently reported cause of IT-project failures. We report results from a study that investigated the effect of introducing lessons-learned sessions on estimation accuracy and the assessment of uncertainty. Twenty software professionals were randomly allocated to a Learning group or a Control group and instructed to estimate and complete the same five development tasks. Those in the Learning group but not those in the Control group were instructed to spend at least 30 minutes on identifying, analyzing, and summarizing their effort estimation and uncertainty assessment experience after completing each task. We found that the estimation accuracy and the realism of the uncertainty assessment were not better in the Learning group than in the Control group. A follow-up study with 83 software professionals was completed to better understand this lack of improvement from lessons-learned sessions. The follow-up study found that receiving feedback about other software professionals' estimation performance led to more realistic uncertainty assessments than receiving the same feedback of one's own estimates. Lessons-learned sessions, not only in estimation contexts, have to be carefully designed to avoid wasting resources on learning processes that stimulate rather than reduce learning biases.",1939-3520,,10.1109/TSE.2009.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4752843,Cost estimation;process implementation and change;review and evaluation;software psychology.,Uncertainty;Yield estimation;Feedback;Programming;Software performance;Psychology;Software engineering;Computer industry;Acoustic reflection;Databases,feedback;learning systems;software engineering,lessons-learned sessions;effort estimation;uncertainty assessments;software development;IT-project failures;feedback;learning process,,41.0,,42.0,,19 Jan 2009,,,IEEE,IEEE Journals
188,188,A Model-Based Approach to Families of Embedded Domain-Specific Languages,J. Sanchez Cuadrado; J. G. Molina,"University of Murcia, Murcia; University of Murcia, Murcia",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,825,840,"With the emergence of model-driven engineering (MDE), the creation of domain-specific languages (DSLs) is becoming a fundamental part of language engineering. The development cost of a DSL should be modest compared to the cost of developing a general-purpose programming language. Reducing the implementation effort and providing reuse techniques are key aspects for DSL approaches to be really effective. In this paper, we present an approach to build embedded domain-specific languages applying the principles of model-driven engineering. On the basis of this approach, we will tackle reuse of DSLs by defining families of DSLs, addressing reuse both from the DSL developer and user point of views. A family of DSLs will be built up by composing several DSLs, so we will propose composition mechanisms for the abstract syntax, concrete syntax, and model transformation levels of a DSL's definition. Finally, we contribute a software framework to support our approach, and we illustrate the paper with a case study to demonstrate its practical applicability.",1939-3520,,10.1109/TSE.2009.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4782971,Domain-specific languages;model-driven development;families of DSLs;DSL composition.,Domain specific languages;DSL;Model driven engineering;Object oriented modeling;Costs;Computer languages;Concrete;Metamodeling;Proposals;Software engineering,computational linguistics;programming languages;software engineering,embedded domain-specific languages;model-driven engineering;programming language;abstract syntax;concrete syntax;model transformation levels,,25.0,,38.0,,13 Feb 2009,,,IEEE,IEEE Journals
189,189,Data Quality: Some Comments on the NASA Software Defect Datasets,M. Shepperd; Q. Song; Z. Sun; C. Mair,"Brunel University, Uxbridge; Xi'an Jiaotong University, Xi'an; Xi'an Jiaotong University, Xi'an; Southampton Solent University, Southampton",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1208,1215,"Background--Self-evidently empirical analyses rely upon the quality of their data. Likewise, replications rely upon accurate reporting and using the same rather than similar versions of datasets. In recent years, there has been much interest in using machine learners to classify software modules into defect-prone and not defect-prone categories. The publicly available NASA datasets have been extensively used as part of this research. Objective--This short note investigates the extent to which published analyses based on the NASA defect datasets are meaningful and comparable. Method--We analyze the five studies published in the IEEE Transactions on Software Engineering since 2007 that have utilized these datasets and compare the two versions of the datasets currently in use. Results--We find important differences between the two versions of the datasets, implausible values in one dataset and generally insufficient detail documented on dataset preprocessing. Conclusions--It is recommended that researchers 1) indicate the provenance of the datasets they use, 2) report any preprocessing in sufficient detail to enable meaningful replication, and 3) invest effort in understanding the data prior to applying machine learners.",1939-3520,,10.1109/TSE.2013.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6464273,Empirical software engineering;data quality;machine learning;defect prediction,NASA;Software;PROM;Educational institutions;Sun;Communities;Abstracts,data analysis;learning (artificial intelligence);pattern classification;software reliability,data quality;NASA software defect dataset;National Aeronautics and Space Administration;data replication;machine learning;software module classification;defect-prone classification;not-defect-prone classification;IEEE Transactions on Software Engineering;data preprocessing;dataset provenance,,197.0,,21.0,,18 Feb 2013,,,IEEE,IEEE Journals
190,190,Measuring Code Quality to Improve Specification Mining,C. Le Goues; W. Weimer,"University of Virginia, Charlottesville; University of Virginia, Charlottesville",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,175,190,"Formal specifications can help with program testing, optimization, refactoring, documentation, and, most importantly, debugging and repair. However, they are difficult to write manually, and automatic mining techniques suffer from 90-99 percent false positive rates. To address this problem, we propose to augment a temporal-property miner by incorporating code quality metrics. We measure code quality by extracting additional information from the software engineering process and using information from code that is more likely to be correct, as well as code that is less likely to be correct. When used as a preprocessing step for an existing specification miner, our technique identifies which input is most indicative of correct program behavior, which allows off-the-shelf techniques to learn the same number of specifications using only 45 percent of their original input. As a novel inference technique, our approach has few false positives in practice (63 percent when balancing precision and recall, 3 percent when focused on precision), while still finding useful specifications (e.g., those that find many bugs) on over 1.5 million lines of code.",1939-3520,,10.1109/TSE.2011.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680914,Specification mining;machine learning;software engineering;code metrics;program understanding.,Software measurement;Refactoring;Data mining;Maintenance engineering;Cloning;Optimization,data mining;formal specification;program debugging;program testing;software quality,specification mining;formal specifications;program testing;optimization;refactoring;documentation;debugging;repair;automatic mining techniques;temporal-property miner;code quality metrics;software engineering process,,20.0,,61.0,,6 Jan 2011,,,IEEE,IEEE Journals
191,191,"Identification, Impact, and Refactoring of Smells in Pipe-Like Web Mashups",K. T. Stolee; S. Elbaum,"Iowa State University, Ames; University of Nebraska-Lincoln, Lincoln",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1654,1679,"With the emergence of tools to support visual mashup creation, tens of thousands of users have started to access, manipulate, and compose data from web sources. We have observed, however, that mashups created by these users tend to suffer from deficiencies that propagate as mashups are reused, which happens frequently. To address these deficiencies, we would like to bring some of the benefits of software engineering techniques to the end users creating these programs. In this work, we focus on identifying code smells indicative of the deficiencies we observed in web mashups programmed in the popular Yahoo! Pipes environment. Through an empirical study, we explore the impact of those smells on the preferences of 61 users, and observe that a significant majority of users prefer mashups without smells. We then introduce refactorings targeting those smells. These refactorings reduce the complexity of the mashup programs, increase their abstraction, update broken data sources and dated components, and standardize their structures to fit the community development patterns. Our assessment of a sample of over 8,000 mashups shows that smells are present in 81 percent of them and that the proposed refactorings can reduce the number of smelly mashups to 16 percent, illustrating the potential of refactoring to support the thousands of end-users programming mashups. Further, we explore how the smells and refactorings can apply to other end-user programming domains to show the generalizability of our approach.",1939-3520,,10.1109/TSE.2013.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6589568,End-user software engineering;end-user programming;web mashups;refactoring;code smells;empirical studies,Mashups;Visualization;Factoring;Generators;Programming,Internet;software maintenance,smell identification;smell impact;smell refactoring;pipe-like Web mashups;visual mashup creation;Web sources;software engineering techniques;Yahoo! Pipes environment;end-users programming mashups,,12.0,,56.0,,6 Sep 2013,,,IEEE,IEEE Journals
192,192,Uncovering Latent Social Communities in Software Development,D. A. Tamburri; P. Lago; H. van Vliet,VU University Amsterdam; VU University Amsterdam; VU University Amsterdam,IEEE Software,3 Jan 2013,2013,30,1,29,36,"Software development is increasingly carried out by developer communities in a global setting. One way to prepare for development success is to uncover and harmonize these communities to exploit their collective, collaborative potential. A proposed decision tree can help practitioners do this.",1937-4194,,10.1109/MS.2012.170,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6336697,Communities;Social network services;Problem-solving;Organizational aspects;Software development;Globalization;Decision making;Decision trees;software engineering organizations;global software engineering;social communities;development communities;community detection,Communities;Social network services;Problem-solving;Organizational aspects;Software development;Globalization;Decision making;Decision trees,decision trees;social networking (online);software engineering,latent social communities;software development;decision tree;developer communities;collaborative potential,,21.0,,9.0,,22 Oct 2012,,,IEEE,IEEE Magazines
193,193,A Tale of Two Conferences,H. Erdogmus,National Research Council Canada,IEEE Software,22 Dec 2008,2009,26,1,4,7,"For the 2008 ICSE and Agile conferences, The magazine's editor in chief prepared a flash poll to gauge key perceptions regarding the separation between software engineering research and software development practice. The results for each conference were interesting, but the differences between the two groups were especially revealing.",1937-4194,,10.1109/MS.2009.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721171,software engineering research;software development practice;collaboration,Software engineering;Coatings;Cultural differences;Circuit testing;Software testing;Project management;Software development management;Programming;Personal communication networks;Sampling methods,,,,,,,,22 Dec 2008,,,IEEE,IEEE Magazines
194,194,"Safety, Security, Now Sustainability: The Nonfunctional Requirement for the 21st Century",B. Penzenstadler; A. Raturi; D. Richardson; B. Tomlinson,"University of California, Irvine; University of California, Irvine; University of California, Irvine; University of California, Irvine",IEEE Software,21 Apr 2014,2014,31,3,40,47,"Many software systems today control large-scale sociotechnical systems. These systems aren't just entangled with the environment but also with our dwindling resources and mostly unsustainable way of living, while the planet's population continues to grow. Dealing with sustainability requirements and systematically supporting their elicitation, analysis, and realization is a problem that has yet to be solved. Decades ago, the discipline of software engineering dealt with similar shortcomings in its processes by including safety and security as new system qualities. In light of the increasing consequences of inadequately addressing sustainability in developing software systems, software engineers must apply the lessons learned from these prior research efforts and identify the necessary research agenda. Considering sustainability in software engineering means more than energy efficiency and green IT, which are concerned with the first-order impacts of software systems. Software engineers must also take into account the second- and third-order impacts in the system context, even if they're hard to assess. By doing so, engineers have the potential to considerably improve civilization's sustainability. The Web extra at http://youtu.be/VC07j6a1XUw is a video in which author Birgit Penzenstadler talks about how software engineers can considerably improve civilization's sustainability by taking into account not just the first-order impacts of software systems but also their second- and third-order impacts.",1937-4194,,10.1109/MS.2014.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728940,requirements engineering;sustainability;green software;software;security;nonfunctional requirements,Security;Safety;Software systems;Green products;Software engineering;Standards,safety;security of data;software engineering,nonfunctional requirement;software systems;large-scale sociotechnical systems;software engineering;civilization sustainability;energy efficiency;green IT;software security;software safety;sustainability requirements,,43.0,,24.0,,30 Jan 2014,,,IEEE,IEEE Magazines
195,195,Clarifications on the Construction and Use of the ManyBugs Benchmark,C. Le Goues; Y. Brun; S. Forrest; W. Weimer,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; College of Information and Computer Science, University of Massachusetts at Amherst, Amherst, MA; Department of Computer Science, University of New Mexico, Albuquerque, NM; Computer Science and Engineering, University of Michigan, Ann Arbor, MI",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1089,1090,"Automated repair techniques produce variant php interpreters, which should naturally serve as the tested interpreters. However, the answer to the question of what should serve as the testing interpreter is less obvious. php's default test harness configuration uses the same version of the interpreter for both the tested and testing interpreter. However, php may be configured via a command-line argument to use a different interpreter, such as the unmodified defective version, or a separate, manually-repaired version.",1939-3520,,10.1109/TSE.2017.2755651,US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048536,,Maintenance engineering;Benchmark testing;Computer science;Electronic mail;Software engineering;Software,program debugging,ManyBugs benchmark;automated repair techniques;test harness configuration;testing interpreter,,1.0,,7.0,Traditional,22 Sep 2017,,,IEEE,IEEE Journals
196,196,Mutation Operators for Spreadsheets,R. Abraham; M. Erwig,"Oregon State University, Corvallis; Oregon State University, Corvallis",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,94,108,"Based on 1) research into mutation testing for general-purpose programming languages and 2) spreadsheet errors that have been reported in the literature, we have developed a suite of mutation operators for spreadsheets. We present an evaluation of the mutation adequacy of definition-use adequate test suites generated by a constraint-based automatic test-case generation system we have developed in previous work. The results of the evaluation suggest additional constraints that can be incorporated into the system to target mutation adequacy. In addition to being useful in mutation testing of spreadsheets, the operators can be used in the evaluation of error-detection tools and also for seeding spreadsheets with errors for empirical studies. We describe two case studies where the suite of mutation operators helped us carry out such empirical evaluations. The main contribution of this paper is a suite of mutation operators for spreadsheets that can be used for performing empirical evaluations of spreadsheet tools to indicate ways in which the tools can be improved.",1939-3520,,10.1109/TSE.2008.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4609389,Test coverage of code;Test design;Spreadsheets;Test coverage of code;Test design;Spreadsheets,Genetic mutations;System testing;Software testing;Computer languages;Automatic testing;Software engineering;Costs;Performance evaluation;Spreadsheet programs;Collaboration,program testing;spreadsheet programs,spreadsheet mutation operator;constraint-based automatic test-case generation system;error-detection tool;general purpose programming language;mutation testing,,38.0,1.0,86.0,,29 Aug 2008,,,IEEE,IEEE Journals
197,197,Performance Analysis for Object-Oriented Software: A Systematic Mapping,D. Maplesden; E. Tempero; J. Hosking; J. C. Grundy,"Department of Computer Science, University of Auckland, Private Bag 92019, Auckland 1142, New Zealand; Department of Computer Science, University of Auckland, Private Bag 92019, Auckland 1142, New Zealand; Faculty of Science, University of Auckland, Private Bag 92019, Auckland 1142, New Zealand; Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn, Vic. 3122, Australia",IEEE Transactions on Software Engineering,14 Jul 2015,2015,41,7,691,710,"Performance is a crucial attribute for most software, making performance analysis an important software engineering task. The difficulty is that modern applications are challenging to analyse for performance. Many profiling techniques used in real-world software development struggle to provide useful results when applied to large-scale object-oriented applications. There is a substantial body of research into software performance generally but currently there exists no survey of this research that would help identify approaches useful for object-oriented software. To provide such a review we performed a systematic mapping study of empirical performance analysis approaches that are applicable to object-oriented software. Using keyword searches against leading software engineering research databases and manual searches of relevant venues we identified over 5,000 related articles published since January 2000. From these we systematically selected 253 applicable articles and categorised them according to ten facets that capture the intent, implementation and evaluation of the approaches. Our mapping study results allow us to highlight the main contributions of the existing literature and identify areas where there are interesting opportunities. We also find that, despite the research including approaches specifically aimed at object-oriented software, there are significant challenges in providing actionable feedback on the performance of large-scale object-oriented applications.",1939-3520,,10.1109/TSE.2015.2396514,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7024167,Systematic review;survey;performance;object-oriented;Systematic review;survey;performance;object-oriented,Performance analysis;Systematics;Software performance;Databases;Mathematical model;Runtime,database management systems;object-oriented methods;program diagnostics;software performance evaluation,performance analysis;object-oriented software;systematic mapping;software engineering task;profiling techniques;software engineering research database,,9.0,,17.0,,27 Jan 2015,,,IEEE,IEEE Journals
198,198,The Value of Exact Analysis in Requirements Selection,L. Li; M. Harman; F. Wu; Y. Zhang,"Department of Computer Science, CREST, University College London, Gower Street, London, United Kingdom; Department of Computer Science, CREST, University College London, Gower Street, London, United Kingdom; Department of Computer Science, CREST, University College London, Gower Street, London, United Kingdom; Department of Computer Science, CREST, University College London, Gower Street, London, United Kingdom",IEEE Transactions on Software Engineering,12 Jun 2017,2017,43,6,580,596,"Uncertainty is characterised by incomplete understanding. It is inevitable in the early phase of requirements engineering, and can lead to unsound requirement decisions. Inappropriate requirement choices may result in products that fail to satisfy stakeholders' needs, and might cause loss of revenue. To overcome uncertainty, requirements engineering decision support needs uncertainty management. In this research, we develop a decision support framework METRO for the Next Release Problem (NRP) to manage algorithmic uncertainty and requirements uncertainty. An exact NRP solver (NSGDP) lies at the heart of METRO. NSGDP's exactness eliminates interference caused by approximate existing NRP solvers. We apply NSGDP to three NRP instances, derived from a real world NRP instance, RALIC, and compare with NSGA-II, a widely-used approximate (inexact) technique. We find the randomness of NSGA-II results in decision makers missing up to 99.95 percent of the optimal solutions and obtaining up to 36.48 percent inexact requirement selection decisions. The chance of getting an inexact decision using existing approximate approaches is negatively correlated with the implementation cost of a requirement (Spearman r up to -0.72). Compared to the inexact existing approach, NSGDP saves 15.21 percent lost revenue, on average, for the RALIC dataset.",1939-3520,,10.1109/TSE.2016.2615100,China Scholarship Council (CSC); EPSRC; DAASE; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7582553,Software engineering;exact multi-objective optimisation;simulation optimisation;next release problem,Uncertainty;Stakeholders;Robustness;Optimization;Software;Software engineering;Software algorithms,decision support systems;formal specification,requirements engineering decision support;METRO;next-release problem;algorithmic uncertainty management;requirements uncertainty management;exact NRP solver;NSGDP;NRP solvers;optimal solutions;inexact requirement selection decisions;RALIC dataset,,9.0,,62.0,CCBY,4 Oct 2016,,,IEEE,IEEE Journals
199,199,Improved Evolutionary Algorithm Design for the Project Scheduling Problem Based on Runtime Analysis,L. L. Minku; D. Sudholt; X. Yao,"CERCIA, School of Computer Science , The University of Birmingham, Birmingham B15 2TT, United Kingdom; Department of Computer Science , University of Sheffield, Sheffield S1 4DP, United Kingdom; CERCIA, School of Computer Science , The University of Birmingham, Birmingham B15 2TT, United Kingdom",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,1,83,102,"Several variants of evolutionary algorithms (EAs) have been applied to solve the project scheduling problem (PSP), yet their performance highly depends on design choices for the EA. It is still unclear how and why different EAs perform differently. We present the first runtime analysis for the PSP, gaining insights into the performance of EAs on the PSP in general, and on specific instance classes that are easy or hard. Our theoretical analysis has practical implications-based on it, we derive an improved EA design. This includes normalizing employees' dedication for different tasks to ensure they are not working overtime; a fitness function that requires fewer pre-defined parameters and provides a clear gradient towards feasible solutions; and an improved representation and mutation operator. Both our theoretical and empirical results show that our design is very effective. Combining the use of normalization to a population gave the best results in our experiments, and normalization was a key component for the practical effectiveness of the new design. Not only does our paper offer a new and effective algorithm for the PSP, it also provides a rigorous theoretical analysis to explain the efficiency of the algorithm, especially for increasingly large projects.",1939-3520,,10.1109/TSE.2013.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648326,Schedule and organizational issues;evolutionary algorithms;software project scheduling;software project management;search-based software engineering;runtime analysis,Software;Schedules;Scheduling;Algorithm design and analysis;Software algorithms;Resource management;Software engineering,evolutionary computation;project management;scheduling;software development management,improved evolutionary algorithm;project scheduling problem;runtime analysis;PSP;improved EA design;employee dedication;fitness function;representation operator;mutation operator;population normalization;software project scheduling,,20.0,,45.0,CCBY,25 Oct 2013,,,IEEE,IEEE Journals
200,200,Learning Project Management Decisions: A Case Study with Case-Based Reasoning versus Data Farming,T. Menzies; A. Brady; J. Keung; J. Hihn; S. Williams; O. El-Rawas; P. Green; B. Boehm,"West Virginia University, Morgantown; West Virginia University, Morgantown; The City University of Hong Kong, Hong Kong; California Institute of Technology, Pasadena; Indiana University, Bloomington; West Virginia University, Morgantown; West Virginia University, Morgantown; University of Southern California, Los Angeles",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1698,1713,"Background: Given information on just a few prior projects, how do we learn the best and fewest changes for current projects? Aim: To conduct a case study comparing two ways to recommend project changes. 1) Data farmers use Monte Carlo sampling to survey and summarize the space of possible outcomes. 2) Case-based reasoners (CBR) explore the neighborhood around test instances. Method: We applied a state-of-the data farmer (SEESAW) and a CBR tool ()'V2) to software project data. Results: CBR with )'V2 was more effective than SEESAW's data farming for learning best and recommended project changes, effectively reducing runtime, effort, and defects. Further, CBR with )'V2 was comparably easier to build, maintain, and apply in novel domains, especially on noisy data sets. Conclusion: Use CBR tools like )'V2 when data are scarce or noisy or when project data cannot be expressed in the required form of a data farmer. Future Work: This study applied our own CBR tool to several small data sets. Future work could apply other CBR tools and data farmers to other data (perhaps to explore other goals such as, say, minimizing maintenance effort).",1939-3520,,10.1109/TSE.2013.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6600685,Search-based software engineering;case-based reasoning;data farming;COCOMO,Data models;Project management;Search methods;Monte Carlo methods;Mathematical model;Software engineering,case-based reasoning;data handling;learning (artificial intelligence);Monte Carlo methods;project management;sampling methods;software management,project management decision learning;case-based reasoning;data farming;Monte Carlo sampling;CBR;SEESAW;software project data,,8.0,,101.0,,16 Sep 2013,,,IEEE,IEEE Journals
201,201,Does Socio-Technical Congruence Have an Effect on Software Build Success? A Study of Coordination in a Software Project,I. Kwan; A. Schroter; D. Damian,"University of Victoria, Victoria; University of Victoria, Victoria; University of Victoria, Victoria",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,307,324,"Socio-technical congruence is an approach that measures coordination by examining the alignment between the technical dependencies and the social coordination in the project. We conduct a case study of coordination in the IBM Rational Team Concert project, which consists of 151 developers over seven geographically distributed sites, and expect that high congruence leads to a high probability of successful builds. We examine this relationship by applying two congruence measurements: an unweighted congruence measure from previous literature, and a weighted measure that overcomes limitations of the existing measure. We discover that there is a relationship between socio-technical congruence and build success probability, but only for certain build types, and observe that in some situations, higher congruence actually leads to lower build success rates. We also observe that a large proportion of zero-congruence builds are successful, and that socio-technical gaps in successful builds are larger than gaps in failed builds. Analysis of the social and technical aspects in IBM Rational Team Concert allows us to discuss the effects of congruence on build success. Our findings provide implications with respect to the limits of applicability of socio-technical congruence and suggest further improvements of socio-technical congruence to study coordination.",1939-3520,,10.1109/TSE.2011.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740929,Empirical software engineering;socio-technical congruence;coordination;awareness;software quality;integration.,Software;Weight measurement;Programming;Software measurement;Collaboration;Software engineering;Context,social aspects of automation;software development management,socio-technical congruence;software build success;software project;social coordination;congruence measurements;unweighted congruence measure;weighted measure,,67.0,1.0,54.0,,5 Apr 2011,,,IEEE,IEEE Journals
202,202,"A Theoretical and Empirical Study of Search-Based Testing: Local, Global, and Hybrid Search",M. Harman; P. McMinn,"King's College London, London; University of Sheffield, Sheffield",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,226,247,"Search-based optimization techniques have been applied to structural software test data generation since 1992, with a recent upsurge in interest and activity within this area. However, despite the large number of recent studies on the applicability of different search-based optimization approaches, there has been very little theoretical analysis of the types of testing problem for which these techniques are well suited. There are also few empirical studies that present results for larger programs. This paper presents a theoretical exploration of the most widely studied approach, the global search technique embodied by Genetic Algorithms. It also presents results from a large empirical study that compares the behavior of both global and local search-based optimization on real-world programs. The results of this study reveal that cases exist of test data generation problem that suit each algorithm, thereby suggesting that a hybrid global-local search (a Memetic Algorithm) may be appropriate. The paper presents a Memetic Algorithm along with further empirical results studying its performance.",1939-3520,,10.1109/TSE.2009.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5342440,Automated test data generation;search-based testing;search-based software engineering;Evolutionary Testing;Genetic Algorithms;Hill Climbing;schema theory;Royal Road;testing and debugging;testing tools;artificial intelligence;problem solving;control methods;and search;heuristic methods;algorithms;experimentation;measurement;performance;theory.,Software testing;Automatic testing;Genetic algorithms;Costs;Hybrid power systems;Software engineering;Automation;Stress;Debugging;Artificial intelligence,automatic test software;genetic algorithms;program testing;search problems,search based testing;search based optimization techniques;structural software test data generation;genetic algorithms;hybrid global-local search problem;memetic algorithm;real-world programs,,213.0,,61.0,,1 Dec 2009,,,IEEE,IEEE Journals
203,203,UML Everywhere,D. Spinellis,Athens University of Economics and Business,IEEE Software,19 Aug 2010,2010,27,5,90,91,"A standardized and widely used diagramming notation is a sign of a profession's maturity. It simplifies the life of the diverse group of people who read the drawings, it improves the quality of the drawings, and it benefits the profession through network effects. In the field of software engineering we've got a long way to travel. Every one of us should make a concerted effort to use the same graphic notation for drawing all our diagrams. We should adopt the graphic notation techniques of Unified Modeling Language (UML).",1937-4194,,10.1109/MS.2010.131,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551018,Unified modeling language;UML;diagram;notation,Unified modeling language;Programming;Economics,software engineering;Unified Modeling Language,UML;unified modeling language;diagramming notation;software engineering;graphic notation,,,,,,19 Aug 2010,,,IEEE,IEEE Magazines
204,204,Estimation Tools and Techniques,L. Buglione; C. Ebert,Engineering.IT SpA; Vector Consulting Services,IEEE Software,25 Apr 2011,2011,28,3,91,94,"Estimating size or resources is one of the most important topics in software engineering and IT. You won't deliver according to expectations if you don't plan, and you can't plan if you don't know the underlying dependencies and estimates. This column is an overview of estimation. It covers estimation methods and provides an overview and evaluation of popular estimation tools.",1937-4194,,10.1109/MS.2011.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756296,estimation;software tools;benchmarking,Estimation;Software measurement;Databases,software engineering,estimation tools;estimation techniques;software engineering;IT,,8.0,,7.0,,25 Apr 2011,,,IEEE,IEEE Magazines
205,205,Next-Generation Architects for a Harsh Business World,W. A. Risi,KPMG Argentina,IEEE Software,20 Feb 2012,2012,29,2,9,12,"Walter Ariel Risi proposes some patterns for hiring productive people that remind me of research done in the early days of patterns by Jim Coplien, who found that hyperproductive teams included, in many cases, musicians! In the old days, companies often hired smart people from other disciplines because software engineering or computer science hadn't joined the academic production of certified, degreed contributors. With the current focus now on degrees, I wonder if we've lost something important.",1937-4194,,10.1109/MS.2012.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155136,personnel;HR;architects;traditional;nontraditional,Career development;Personnel;Engineering profession;Computer science education;Research and development,personnel;recruitment;software engineering,next generation architects;harsh business world;productive people hiring;hyperproductive team;musicians;smart people hiring;software engineering;computer science;academic production;degreed contributor,,1.0,,,,20 Feb 2012,,,IEEE,IEEE Magazines
206,206,Keyword Search for Building Service-Based Systems,Q. He; R. Zhou; X. Zhang; Y. Wang; D. Ye; F. Chen; J. C. Grundy; Y. Yang,"State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; Centre for Applied Informatics, Victoria University, Melbourne, Australia; University of Auckland, Auckland, New Zealand; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia; School of Engineering and Information Technology, Federation University Australia, Melbourne, Australia; School of Information Technology, Deakin University, Geelong, Victoria, Australia; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia",IEEE Transactions on Software Engineering,14 Jul 2017,2017,43,7,658,674,"With the fast growth of applications of service-oriented architecture (SOA) in software engineering, there has been a rapid increase in demand for building service-based systems (SBSs) by composing existing Web services. Finding appropriate component services to compose is a key step in the SBS engineering process. Existing approaches require that system engineers have detailed knowledge of SOA techniques which is often too demanding. To address this issue, we propose Keyword Search for Service-based Systems (KS3), a novel approach that integrates and automates the system planning, service discovery and service selection operations for building SBSs based on keyword search. KS3 assists system engineers without detailed knowledge of SOA techniques in searching for component services to build SBSs by typing a few keywords that represent the tasks of the SBSs with quality constraints and optimisation goals for system quality, e.g., reliability, throughput and cost. KS3 offers a new paradigm for SBS engineering that can significantly save the time and effort during the system engineering process. We conducted large-scale experiments using two real-world Web service datasets to demonstrate the practicality, effectiveness and efficiency of KS3.",1939-3520,,10.1109/TSE.2016.2624293,Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7731135,Service-based system;keyword search;service composition;web service;quality of service;cloud computing,Service-oriented architecture;Data models;Keyword search;Buildings;Planning;Libraries,service-oriented architecture;Web services,keyword search;service-based system building;service-oriented architecture;software engineering;Web services;SBS engineering process;SOA techniques;KS3,,6.0,,51.0,,2 Nov 2016,,,IEEE,IEEE Journals
207,207,App Store 2.0: From Crowdsourced Information to Actionable Feedback in Mobile Ecosystems,M. Gómez; B. Adams; W. Maalej; M. Monperrus; R. Rouvoy,Inria Lille; Polytechnique Montréal; University of Hamburg; University of Lille; University of Lille,IEEE Software,28 Mar 2017,2017,34,2,81,89,"Given the increasing competition in mobile-app ecosystems, improving the user experience has become a major goal for app vendors. App Store 2.0 will exploit crowdsourced information about apps, devices, and users to increase the overall quality of the delivered mobile apps. App Store 2.0 generates different kinds of actionable feedback from the crowd information. This feedback helps developers deal with potential errors that could affect their apps before publication or even when the apps are in the users' hands. The App Store 2.0 vision has been transformed into a concrete implementation for Android devices. This article is part of a special issue on Crowdsourcing for Software Engineering.",1937-4194,,10.1109/MS.2017.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888388,Android;app store;App Store 2.0;crowdsourcing;user feedback;mobile apps;software engineering;data-driven software development;software development,Computer crashes;Monitoring;Context modeling;Mobile communication;Ecosystems;Performance evaluation;Androids;Mobile computing;Computer applications,Android (operating system);crowdsourcing;mobile computing;smart phones;software engineering,App Store 2.0;crowdsourced information;actionable feedback;mobile ecosystems;mobile-app ecosystems;user experience;app vendors;mobile apps;Android devices;crowdsourcing;software engineering,,11.0,2.0,22.0,,28 Mar 2017,,,IEEE,IEEE Magazines
208,208,Comprehensive Multiplatform Dynamic Program Analysis for Java and Android,Y. Zheng; S. Kell; L. Bulej; H. Sun; W. Binder,Università della Svizzera italiana; University of Cambridge; Università della Svizzera italiana; Università della Svizzera italiana; Università della Svizzera italiana,IEEE Software,23 Jun 2016,2016,33,4,55,63,"Dynamic program analysis, such as with profiling, tracing, and bug-finding tools, is essential for software engineering. Unfortunately, implementing dynamic analysis for managed languages such as Java is unduly difficult and error prone because the runtime environments provide only complex low-level mechanisms. Programmers writing custom tooling must expend great effort in tool development and maintenance, while still suffering substantial limitations such as incomplete code coverage or lack of portability. Ideally, programmers should have a framework that lets them express dynamic-analysis tools at a high level, robustly, with high coverage and supporting alternative runtimes such as Android. To satisfy these requirements, ShadowVM, an all-in-one dynamic-program-analysis framework, uses a combination of techniques.",1937-4194,,10.1109/MS.2015.151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7330309,dynamic program analysis;Java;Android;software engineering;software development;ShadowVM;virtual machines,Dynamic programming;Java;Performance analysis;Software development;Androids;Humanoid robots;Virtual machining,Android (operating system);Java;program debugging;program diagnostics;software engineering,multiplatform dynamic program analysis;Java;Android;program profiling;program tracing;bug-finding tool;software engineering;ShadowVM,,6.0,,12.0,,18 Nov 2015,,,IEEE,IEEE Magazines
209,209,A Distributed Access Control Architecture for Cloud Computing,A. Almutairi; M. Sarfraz; S. Basalamah; W. Aref; A. Ghafoor,Purdue University; Purdue University; Umm Al-Qura University; Purdue University; Purdue University,IEEE Software,20 Feb 2012,2012,29,2,36,44,"The large-scale, dynamic, and heterogeneous nature of cloud computing poses numerous security challenges. But the cloud's main challenge is to provide a robust authorization mechanism that incorporates multitenancy and virtualization aspects of resources. The authors present a distributed architecture that incorporates principles from security management and software engineering and propose key requirements and a design model for the architecture.",1937-4194,,10.1109/MS.2011.153,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095492,software engineering;distributed access control;cloud computing;multitenancy;resource virtualization,Collaboration;Cloud computing;Authorization;Computer architecture;Resource management;Computer security,authorisation;cloud computing;software engineering;virtualisation,distributed access control architecture;cloud computing;authorization mechanism;multitenancy aspect;virtualization aspect;security management;software engineering,,77.0,2.0,10.0,,6 Dec 2011,,,IEEE,IEEE Magazines
210,210,Learning from Quality Issues of BPMN Models from Industry,H. Leopold; J. Mendling; O. Günther,Vrije Universiteit Amsterdam; Wirtschaftsuniversität Wien; Universität Potsdam,IEEE Software,23 Jun 2016,2016,33,4,26,33,"Many organizations use business process models to document business operations and formalize business requirements in software-engineering projects. The Business Process Model and Notation (BPMN), a specification by the Object Management Group, has evolved into the leading standard for process modeling. One challenge is BPMN's complexity: it offers a huge variety of elements and often several representational choices for the same semantics. This raises the question of how well modelers can deal with these choices. Empirical insights into BPMN use from the practitioners' perspective are still missing. To close this gap, researchers analyzed 585 BPMN 2.0 process models from six companies. They found that split and join representations, message flow, the lack of proper model decomposition, and labeling related to quality issues. They give five specific recommendations on how to avoid these issues.",1937-4194,,10.1109/MS.2015.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106381,process model quality;modeling guidelines;Business Process Model and Notation;BPMN;industry study;software engineering;software development,Data models;Business processes;Documentation;Logic gates,business data processing;organisational aspects;software engineering,quality issues;organizations;business operations;business requirements;software-engineering projects;business process model and notation;object management group;BPMN 2.0 process models;split representations;message flow;join representations,,26.0,,13.0,,13 May 2015,,,IEEE,IEEE Magazines
211,211,On Event-Based Middleware for Location-Aware Mobile Applications,R. Meier; V. Cahill,"Trinity College Dublin, Dublin and Lero—The Irish Software Engineering Research Centre; Trinity College Dublin, Dublin and Lero—The Irish Software Engineering Research Centre",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,409,430,"As mobile applications become more widespread, programming paradigms and middleware architectures designed to support their development are becoming increasingly important. The event-based programming paradigm is a strong candidate for the development of mobile applications due to its inherent support for the loose coupling between components required by mobile applications. However, existing middleware that supports the event-based programming paradigm is not well suited to supporting location-aware mobile applications in which highly mobile components come together dynamically to collaborate at some location. This paper presents a number of techniques including location-independent announcement and subscription coupled with location-dependent filtering and event delivery that can be used by event-based middleware to support such collaboration. We describe how these techniques have been implemented in STEAM, an event-based middleware with a fully decentralized architecture, which is particularly well suited to deployment in ad hoc network environments. The cost of such location-based event dissemination and the benefits of distributed event filtering are evaluated.",1939-3520,,10.1109/TSE.2009.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374426,Distributed systems;middleware;publish subscribe;event-based communication;mobile computing;collaborative and location-aware applications;wireless ad hoc networks.,Middleware;Collaboration;Mobile computing;Application software;Mobile communication;Unmanned aerial vehicles;Pervasive computing;Computer architecture;Filtering;Ad hoc networks,information dissemination;middleware;mobile computing;software architecture,event-based middleware;location-aware mobile applications;event-based programming paradigm;location-independent announcement;location-dependent filtering;STEAM;decentralized architecture;ad hoc network environments;location-based event dissemination;distributed event filtering,,21.0,2.0,56.0,,8 Jan 2010,,,IEEE,IEEE Journals
212,212,Impact of Introducing Domain-Specific Modelling in Software Maintenance: An Industrial Case Study,N. Mellegård; A. Ferwerda; K. Lind; R. Heldal; M. R. V. Chaudron,"Electromobility Group at the Research Institute Viktoria Swedish ICT, Gothenburg, Sweden; Centric, Gouda, The Netherlands; Electromobility Group at the Research Institute Viktoria Swedish ICT, Gothenburg, Sweden; Software Engineering Division at the joint Department of Computer Science and Engineering, Chalmers and Gothenborg University, Gothenburg, Sweden; Software Engineering Division at the joint Department of Computer Science and Engineering, Chalmers and Gothenborg University, Gothenburg, Sweden",IEEE Transactions on Software Engineering,11 Mar 2016,2016,42,3,245,260,"Domain-specific modelling (DSM) is a modern software development technology that aims at enhancing productivity. One of the claimed advantages of DSM is increased maintainability of software. However, current empirical evidence supporting this claim is lacking. In this paper, we contribute evidence from a case study conducted at a software development company. We study how the introduction of DSM affected the maintenance of a legacy system. We collected data about the maintenance phase of a system that was initially developed using manual programming, but which was gradually replaced by DSM development. We performed statistical analyses of the relation between the use of DSM and the time needed to resolve defects, the defect density, and the phase in which defects were detected. The results show that after introducing DSM the defect density is lower, that defects are found earlier, but resolving defects takes longer. Other observed benefits are that the number of developers and the number of person-hours needed for maintaining the system decreased, and the portability to new platforms increased. Our findings are useful for organizations that consider introducing DSM and would like to know which benefits can be realized in software maintenance.",1939-3520,,10.1109/TSE.2015.2479221,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270333,Empirical investigation;software maintenance;maintenance measurement;process measurement;productivity;Empirical investigation;software maintenance;maintenance measurement;process measurement;productivity,DSL;Maintenance engineering;Unified modeling language;Business;Software maintenance;Productivity,software maintenance;statistical analysis,domain-specific modelling;software maintenance;DSM;software development technology;software maintainability;software development company;legacy system;manual programming;statistical analysis,,10.0,,42.0,,16 Sep 2015,,,IEEE,IEEE Journals
213,213,"Resource Management for Complex, Dynamic Environments",M. S. Raunak; L. J. Osterweil,"Loyola University MD, Baltimore; University of Massachusetts Amherst, Amherst",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,384,402,"This paper describes an approach to the specification and management of the agents and resources that are required to support the execution of complex systems and processes. The paper suggests that a resource should be viewed as a provider of a set of capabilities that are needed by a system or process, where that set may vary dynamically over time and with circumstances. This view of resources is defined and then made the basis for the framework of an approach to specifying, managing, and allocating resources in the presence of real-world complexity and dynamism. The ROMEO prototype resource management system is presented as an example of how this framework can be instantiated. Some case studies of the use of ROMEO to support system execution are presented and used to evaluate the framework, the ROMEO prototype, and our view of the nature of resources.",1939-3520,,10.1109/TSE.2012.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197203,Resources management;process modeling;discrete event simulation;healthcare processes,Resource management;Hospitals;Surgery;Software;Context;Databases,formal specification;software agents;software engineering,resource management;dynamic environments;complex environments;complex systems;complex processes;ROMEO prototype resource management system;software engineering,,20.0,,40.0,,8 May 2012,,,IEEE,IEEE Journals
214,214,Sustainable Embedded Software Life-Cycle Planning,D. Lee; H. P. In; K. Lee; S. Park; M. Hinchey,"Korea University; Korea University; Samsung Electronics; Sogang University; Lero--The Irish Software Engineering Research Centre, University of Limerick",IEEE Software,26 Jun 2013,2013,30,4,72,80,"Time to market is a crucial factor in increasing market share in consumer electronics. Furthermore, fierce market competition tends to sharply lower the prices of new consumer electronics products as soon as they're released. Researchers have studied software-intensive embedded system design methods, such as hardware/software co-design, with the goal of reducing development lead time by designing hardware and software simultaneously. However, most studies concentrate on static design methods, in which a design remains unchanged once it's determined. To survive the market competition in consumer electronics requires a dynamic design strategy that takes various market conditions into account for software-intensive embedded systems. This article proposes a sustainable embedded software life-cycle planning (SeSLP) process based on the evolution of embedded software. The SeSLP process provides a dynamic method for both selecting product life-cycle design alternatives and generating a profit-maximizing transition plan that covers the entire product life cycle.",1937-4194,,10.1109/MS.2012.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226340,software engineering;product life cycle;embedded systems;embedded software evolution,Market research;Analytical models;Software development;Consumer electronics;Product design;Competitive intelligence;Marketing and sales,consumer electronics;electronics industry;embedded systems;hardware-software codesign;planning;production engineering computing;software engineering;sustainable development,sustainable embedded software;software life-cycle planning;consumer electronics;market competition;software-intensive embedded system;embedded system design method;hardware-software codesign;static design method;dynamic design strategy;SeSLP process;embedded software evolution;product life-cycle design alternative;profit-maximizing transition plan;time-to-market factor,,2.0,,6.0,,26 Jun 2012,,,IEEE,IEEE Magazines
215,215,Requirements: The Key to Sustainability,C. Becker; S. Betz; R. Chitchyan; L. Duboc; S. M. Easterbrook; B. Penzenstadler; N. Seyff; C. C. Venters,"University of Toronto; Karlsruhe Institute of Technology; University of Leicester; State University of Rio de Janeiro; University of Toronto; California State University, Long Beach; University of Applied Sciences and Arts Northwestern Switzerland; University of Huddersfield",IEEE Software,29 Dec 2015,2016,33,1,56,65,Software's critical role in society demands a paradigm shift in the software engineering mind-set. This shift's focus begins in requirements engineering. This article is part of a special issue on the Future of Software Engineering.,1937-4194,,10.1109/MS.2015.158,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325195,software engineering;requirements;sustainability;sustainability design;software development,Stakeholders;Economics;Procurement;Software systems;Software engineering;Requirements engineering;Sustainability,formal specification,software engineering;requirements engineering,,44.0,,11.0,,11 Nov 2015,,,IEEE,IEEE Magazines
216,216,Using Genetic Search for Reverse Engineering of Parametric Behavior Models for Performance Prediction,K. Krogmann; M. Kuperberg; R. Reussner,"Karlsruhe Institute of Technology (KIT), Karlsruhe; Karlsruhe Institute of Technology (KIT), Karlsruhe; Karlsruhe Institute of Technology (KIT), Karlsruhe",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,865,877,"In component-based software engineering, existing components are often reused in new applications. Correspondingly, the response time of an entire component-based application can be predicted from the execution durations of individual component services. These execution durations depend on the runtime behavior of a component which itself is influenced by three factors: the execution platform, the usage profile, and the component wiring. To cover all relevant combinations of these influencing factors, conventional prediction of response times requires repeated deployment and measurements of component services for all such combinations, incurring a substantial effort. This paper presents a novel comprehensive approach for reverse engineering and performance prediction of components. In it, genetic programming is utilized for reconstructing a behavior model from monitoring data, runtime bytecode counts, and static bytecode analysis. The resulting behavior model is parameterized over all three performance-influencing factors, which are specified separately. This results in significantly fewer measurements: The behavior model is reconstructed only once per component service, and one application-independent bytecode benchmark run is sufficient to characterize an execution platform. To predict the execution durations for a concrete platform, our approach combines the behavior model with platform-specific benchmarking results. We validate our approach by predicting the performance of a file sharing application.",1939-3520,,10.1109/TSE.2010.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5530323,Genetic search;genetic programming;reverse engineering;performance prediction;bytecode benchmarking.,Reverse engineering;Predictive models;Application software;Delay;Runtime;Software engineering;Wiring;Genetic programming;Monitoring;Concrete,genetic algorithms;object-oriented programming;reverse engineering;search problems;software performance evaluation,genetic search;reverse engineering;parametric behavior model;component based software engineering;genetic programming;runtime bytecode count;static bytecode analysis;application independent bytecode benchmark,,34.0,2.0,38.0,,29 Jul 2010,,,IEEE,IEEE Journals
217,217,A Second Replicated Quantitative Analysis of Fault Distributions in Complex Software Systems,T. Galinac Grbac; P. Runeson; D. Huljenić,"Univesity of Rijeka, Rijeka; Lund University, Lund; Ericsson Nikola Tesla, Zagreb",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,462,476,"Background: Software engineering is searching for general principles that apply across contexts, for example, to help guide software quality assurance. Fenton and Ohlsson presented such observations on fault distributions, which have been replicated once. Objectives: We aimed to replicate their study again to assess the robustness of the findings in a new environment, five years later. Method: We conducted a literal replication, collecting defect data from five consecutive releases of a large software system in the telecommunications domain, and conducted the same analysis as in the original study. Results: The replication confirms results on unevenly distributed faults over modules, and that fault proneness distributions persist over test phases. Size measures are not useful as predictors of fault proneness, while fault densities are of the same order of magnitude across releases and contexts. Conclusions: This replication confirms that the uneven distribution of defects motivates uneven distribution of quality assurance efforts, although predictors for such distribution of efforts are not sufficiently precise.",1939-3520,,10.1109/TSE.2012.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6235962,Software fault distributions;software metrics;empirical research;replication,Testing;Measurement;Context;Software;Software engineering;Complexity theory;Telecommunications,software fault tolerance;software quality,second replicated quantitative analysis;fault distribution;complex software system;software engineering;literal replication;telecommunications domain;data analysis;data collection;fault proneness distribution;size measure;fault density;quality assurance effort,,21.0,,43.0,,10 Jul 2012,,,IEEE,IEEE Journals
218,218,How Software Developers Use Tagging to Support Reminding and Refinding,M. Storey; J. Ryall; J. Singer; D. Myers; L. Cheng; M. Muller,"University of Victoria, Victoria; University of Victoria, Victoria; National Research Council Canada, Ottawa; University of Victoria, Victoria; IBM Research, Cambridge; IBM Research, Cambridge",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,470,483,"Developers frequently add annotations to source code to help them remember pertinent information and mark locations of interest for future investigation. Finding and refinding these notes is a form of navigation that is integral to software maintenance. Although there is some tool support in modern development environments for authoring and navigating these comments, we have observed that these annotations often fail to remind and are sometimes difficult to find by the programmer. To address these shortcomings, we have designed a new approach for software navigation called tags for software engineering activities (TagSEA). TagSEA combines the notion of waypointing (a mechanism for marking locations in spatial navigation) with social tagging to support programmers in defining semantically rich annotations to source code comments. The tool provides support for creating, editing, navigating, and managing these annotations. We present the results from two empirical studies, where we observed and then analyzed how professional programmers used source code annotations to support their development activities over 24 months. Our findings indicate that the addition of semantic information to annotations can improve their value. We also provide suggestions on how annotation tools in general may be improved.",1939-3520,,10.1109/TSE.2009.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4782972,Annotations;software navigation;software tagging;tags;software development tools.,Tagging;Navigation;Programming profession;Software maintenance;Software tools;Software engineering;Filters;Software development management;Maintenance engineering;Computer science,authoring systems;software maintenance,source code annotations;software maintenance;modern development environments;software navigation;software engineering activities;waypointing;social tagging;software development tools,,35.0,1.0,34.0,,13 Feb 2009,,,IEEE,IEEE Journals
219,219,Stressing Search with Scenarios for Flexible Solutions to Real-Time Task Allocation Problems,P. Emberson; I. Bate,"University of York, York; University of York, York",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,704,718,"One of the most important properties of a good software engineering process and of the design of the software it produces is robustness to changing requirements. Scenario-based analysis is a popular method for improving the flexibility of software architectures. This paper demonstrates a search-based technique for automating scenario-based analysis in the software architecture deployment view. Specifically, a novel parallel simulated annealing search algorithm is applied to the real-time task allocation problem to find baseline solutions which require a minimal number of changes in order to meet the requirements of potential upgrade scenarios. Another simulated annealing-based search is used for finding a solution that is similar to an existing baseline when new requirements arise. Solutions generated using a variety of scenarios are judged by how well they respond to different system requirements changes. The evaluation is performed on a set of problems with a controlled set of different characteristics.",1939-3520,,10.1109/TSE.2009.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5262947,Maintainability;extensibility;heuristics;search;scheduling;scenarios.,Software architecture;Computer architecture;Hardware;Real time systems;Software engineering;Software design;Simulated annealing;System testing;Robustness;Performance evaluation,parallel algorithms;real-time systems;search problems;simulated annealing;software architecture;task analysis,real-time task allocation problem;search stress;software engineering process;software design;scenario-based analysis;software architectures;search-based technique;parallel simulated annealing search algorithm,,16.0,,37.0,,25 Sep 2009,,,IEEE,IEEE Journals
220,220,Engineering a Sound Assertion Semantics for the Verifying Compiler,P. Chalin,"Dependable Software Research Group, Concordia University, Montreal",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,275,287,"The Verifying Compiler (VC) project is a core component of the Dependable Systems Evolution Grand Challenge. The VC offers the promise of automatically proving that a program or component is correct, where correctness is defined by program assertions. While several VC prototypes exist, all adopt a semantics for assertions that is unsound. This paper presents a consolidation of VC requirements analysis (RA) activities that, in particular, brought us to ask targeted VC customers what kind of semantics they wanted. Taking into account both practitioners' needs and current technological factors, we offer recovery of soundness through an adjusted definition of assertion validity that matches user expectations and can be implemented practically using current prover technology. For decades, there have been debates concerning the most appropriate semantics for program assertions. Our contribution here is unique in that we have applied fundamental software engineering techniques by asking primary stakeholders what they want and, based on this, proposed a means of efficiently realizing the semantics stakeholders want using standard tools and techniques. We describe how support for the new semantics has been added to ESC/Java2, one of the most fully developed VC prototypes. Case studies demonstrate the effectiveness of the new semantics at uncovering previously indiscernible specification errors.",1939-3520,,10.1109/TSE.2009.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5262949,Software verification;assertions;programming by contract;logics of programs;requirements engineering.,Acoustical engineering;Virtual colonoscopy;Prototypes;Software prototyping;Java;Logic programming;Runtime;Software engineering;Software standards;Contracts,program compilers;program verification;systems analysis,verifying compiler project;Dependable Systems Evolution Grand Challenge;sound assertion semantics engineering;program correctness proving;VC requirements analysis;software engineering techniques;program assertions;ESC/Java2,,5.0,,70.0,,25 Sep 2009,,,IEEE,IEEE Journals
221,221,What Types of Defects Are Really Discovered in Code Reviews?,M. V. Mäntylä; C. Lassenius,"Helsinki University of Technology, TKK; Helsinki University of Technology, TKK",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,430,448,"Research on code reviews has often focused on defect counts instead of defect types, which offers an imperfect view of code review benefits. In this paper, we classified the defects of nine industrial (C/C++) and 23 student (Java) code reviews, detecting 388 and 371 defects, respectively. First, we discovered that 75 percent of defects found during the review do not affect the visible functionality of the software. Instead, these defects improved software evolvability by making it easier to understand and modify. Second, we created a defect classification consisting of functional and evolvability defects. The evolvability defect classification is based on the defect types found in this study, but, for the functional defects, we studied and compared existing functional defect classifications. The classification can be useful for assigning code review roles, creating checklists, assessing software evolvability, and building software engineering tools. We conclude that, in addition to functional defects, code reviews find many evolvability defects and, thus, offer additional benefits over execution-based quality assurance methods that cannot detect evolvability defects. We suggest that code reviews may be most valuable for software products with long life cycles as the value of discovering evolvability defects in them is greater than for short life cycle systems.",1939-3520,,10.1109/TSE.2008.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4604671,Code inspections and walkthroughs;enhancement;extensibility;maintainability;restructuring.;Source code organization;Code documentation;Construction QA;Methods for SQA and V&V;Measurement applied to SQA and V&V;Code inspections and walkthroughs;Maintainability,Quality assurance;Inspection;Runtime;Java;Software tools;Software engineering;Software measurement;Software quality;Guidelines;Timing,pattern classification;software maintenance;software reviews,software functionality;software evolvability;defect classification;software engineering tools;execution-based quality assurance methods;software products,,76.0,,73.0,,22 Aug 2008,,,IEEE,IEEE Journals
222,222,GEA: A Goal-Driven Approach toDiscovering Early Aspects,J. Lee; K. Hsu,"Department of Computer Science and Information Engineering, National Taiwan University, Taipei, Taiwan; Department of Computer Science, National Taichung University of Education, Taichung, Taiwan",IEEE Transactions on Software Engineering,16 Jun 2014,2014,40,6,584,602,"Aspect-oriented software development has become an important development and maintenance approach to software engineering across requirements, design and implementation phases. However, discovering early aspects from requirements for a better integration of crosscutting concerns into a target system is still not well addressed in the existing works. In this paper, we propose a Goal-driven Early Aspect approach (called GEA) to discovering early aspects by means of a clustering algorithm in which relationships among goals and use cases are utilized to explore similarity degrees of clustering goals, and total interaction degrees are devised to check the validity of the formation of each cluster. Introducing early aspects not only enhances the goal-driven requirements modeling to manage crosscutting concerns, but also provides modularity insights into the analysis and design of software development. Moreover, relationships among goals represented numerically are more informative to discover early aspects and more easily to be processed computationally than qualitative terms. The proposed approach is illustrated by using two problem domains: a meeting scheduler system and a course enrollment system. An experiment is also conducted to evaluate the benefits of the proposed approach with Mann-Whitney U-test to show that the difference between with GEA and without GEA is statistically significant.",1939-3520,,10.1109/TSE.2014.2322368,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6822606,Early aspects;goals;goals interaction;fuzzy logic;use cases;goal cluster,Software;Clustering algorithms;Educational institutions;Analytical models;Computer science;Software engineering;Documentation,aspect-oriented programming;pattern clustering;software maintenance,GEA;early aspect discovery;aspect-oriented software development;maintenance approach;software engineering;goal-driven early aspect approach;clustering algorithm;goal-driven requirements;crosscutting concerns;meeting scheduler system;course enrollment system;Mann-Whitney U-test,,3.0,,51.0,,29 May 2014,,,IEEE,IEEE Journals
223,223,Dynamic Software Project Scheduling through a Proactive-Rescheduling Method,X. Shen; L. L. Minku; R. Bahsoon; X. Yao,"B-DAT & CICAEET, School of Information and Control, Nanjing University of Information Science and Technology, No.219, Ning-Liu Road, Pu-Kou District, Nanjing, P.R. China; Department of Computer Science, University of Leicester, University Road, Leicester, United Kingdom; CERCIA, University of Birmingham, Edgbaston, Birmingham, United Kingdom; CERCIA, University of Birmingham, Edgbaston, Birmingham, United Kingdom",IEEE Transactions on Software Engineering,14 Jul 2016,2016,42,7,658,686,"Software project scheduling in dynamic and uncertain environments is of significant importance to real-world software development. Yet most studies schedule software projects by considering static and deterministic scenarios only, which may cause performance deterioration or even infeasibility when facing disruptions. In order to capture more dynamic features of software project scheduling than the previous work, this paper formulates the project scheduling problem by considering uncertainties and dynamic events that often occur during software project development, and constructs a mathematical model for the resulting multi-objective dynamic project scheduling problem (MODPSP), where the four objectives of project cost, duration, robustness and stability are considered simultaneously under a variety of practical constraints. In order to solve MODPSP appropriately, a multi-objective evolutionary algorithm based proactive-rescheduling method is proposed, which generates a robust schedule predictively and adapts the previous schedule in response to critical dynamic events during the project execution. Extensive experimental results on 21 problem instances, including three instances derived from real-world software projects, show that our novel method is very effective. By introducing the robustness and stability objectives, and incorporating the dynamic optimization strategies specifically designed for MODPSP, our proactive-rescheduling method achieves a very good overall performance in a dynamic environment.",1939-3520,,10.1109/TSE.2015.2512266,"National Natural Science Foundation of China (NSFC); Natural Science Foundation of Jiangsu Province of China; EPSRC; DAASE: Dynamic Adaptive Automated Software Engineering; EPSRC; Evolutionary Computation for Dynamic Optimization in Network Environments; CERCIA; School of Computer Science, University of Birmingham, United Kingdom; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7365465,Schedule and organizational issues;dynamic software project scheduling;search-based software engineering;multi-objective evolutionary algorithms;mathematical modeling,Dynamic scheduling;Software;Schedules;Uncertainty;Robustness;Job shop scheduling,evolutionary computation;project management;scheduling;software development management,uncertain environments;dynamic environments;dynamic features;software project development;multiobjective dynamic software project scheduling problem;MODPSP;project cost;project duration;project robustness;project stability;multiobjective evolutionary algorithm based proactive-rescheduling method;critical dynamic events;project execution;dynamic optimization strategies,,23.0,,49.0,CCBY,24 Dec 2015,,,IEEE,IEEE Journals
224,224,Self-Adaptive and Online QoS Modeling for Cloud-Based Software Services,T. Chen; R. Bahsoon,"CERCIA, School of Computer Science, University of Birmingham, Birmingham, United Kingdom; CERCIA, School of Computer Science, University of Birmingham, Birmingham, United Kingdom",IEEE Transactions on Software Engineering,12 May 2017,2017,43,5,453,475,"In the presence of scale, dynamism, uncertainty and elasticity, cloud software engineers faces several challenges when modeling Quality of Service (QoS) for cloud-based software services. These challenges can be best managed through self-adaptivity because engineers' intervention is difficult, if not impossible, given the dynamic and uncertain QoS sensitivity to the environment and control knobs in the cloud. This is especially true for the shared infrastructure of cloud, where unexpected interference can be caused by co-located software services running on the same virtual machine; and co-hosted virtual machines within the same physical machine. In this paper, we describe the related challenges and present a fully dynamic, self-adaptive and online QoS modeling approach, which grounds on sound information theory and machine learning algorithms, to create QoS model that is capable to predict the QoS value as output over time by using the information on environmental conditions, control knobs and interference as inputs. In particular, we report on in-depth analysis on the correlations of selected inputs to the accuracy of QoS model in cloud. To dynamically selects inputs to the models at runtime and tune accuracy, we design self-adaptive hybrid dual-learners that partition the possible inputs space into two sub-spaces, each of which applies different symmetric uncertainty based selection techniques; the results of sub-spaces are then combined. Subsequently, we propose the use of adaptive multi-learners for building the model. These learners simultaneously allow several learning algorithms to model the QoS function, permitting the capability for dynamically selecting the best model for prediction on the fly. We experimentally evaluate our models in the cloud environment using RUBiS benchmark and realistic FIFA 98 workload. The results show that our approach is more accurate and effective than state-of-the-art modelings.",1939-3520,,10.1109/TSE.2016.2608826,EPSRC Grant; DAASE: Dynamic Adaptive Automated Software Engineering; The PhD scholarship from the School of Computer Science; University of Birmingham; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7572219,Software quality;search-based software engineering;self-adaptive systems;machine learning;cloud computing;performance modeling,Quality of service;Cloud computing;Interference;Adaptation models;Sensitivity;Uncertainty,cloud computing;learning (artificial intelligence);quality of service;virtual machines,cloud-based software services;quality of service;self-adaptivity;uncertain QoS sensitivity;cloud infrastructure;colocated software service;virtual machine;fully dynamic self-adaptive online QoS modeling;information theory;machine learning algorithm;environmental conditions;control knobs;self-adaptive hybrid dual-learners;input space partitioning;symmetric uncertainty based selection technique;QoS function;cloud environment;RUBiS benchmark;FIFA 98 workload,,25.0,,54.0,CCBY,20 Sep 2016,,,IEEE,IEEE Journals
225,225,A Probabilistic Analysis of the Efficiency of Automated Software Testing,M. Böhme; S. Paul,"Software Engineering Chair, Germany; School of Computing, National University of Singapore, Singapore",IEEE Transactions on Software Engineering,14 Apr 2016,2016,42,4,345,360,"We study the relative efficiencies of the random and systematic approaches to automated software testing. Using a simple but realistic set of assumptions, we propose a general model for software testing and define sampling strategies for random (R) and systematic (S0) testing, where each sampling is associated with a sampling cost: 1 and c units of time, respectively. The two most important goals of software testing are: (i) achieving in minimal time a given degree of confidence x in a program's correctness and (ii) discovering a maximal number of errors within a given time bound n̂. For both (i) and (ii), we show that there exists a bound on c beyond which R performs better than S0 on the average. Moreover for (i), this bound depends asymptotically only on x. We also show that the efficiency of R can be fitted to the exponential curve. Using these results we design a hybrid strategy H that starts with R and switches to S0 when S0 is expected to discover more errors per unit time. In our experiments we find that H performs similarly or better than the most efficient of both and that S0 may need to be significantly faster than our bounds suggest to retain efficiency over R.",1939-3520,,10.1109/TSE.2015.2487274,Singapore's Ministry of Education; ERC; SPECMATE; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7289448,Partition Testing;Random Testing;Error-based Partitioning;Efficient Testing;Testing Theory;Partition testing;random testing;error-based partitioning;efficient testing;testing theory,Systematics;Software testing;Software engineering;Input variables;Random variables;Color,probability;program testing,probabilistic analysis;automated software testing;sampling strategies;random testing;systematic testing;exponential curve;hybrid strategy,,23.0,,37.0,,5 Oct 2015,,,IEEE,IEEE Journals
226,226,The Role of Method Chains and Comments in Software Readability and Comprehension—An Experiment,J. Börstler; B. Paech,"Department of Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Computer Science, Heidelberg University, Heidelberg, Germany",IEEE Transactions on Software Engineering,15 Sep 2016,2016,42,9,886,898,"Software readability and comprehension are important factors in software maintenance. There is a large body of research on software measurement, but the actual factors that make software easier to read or easier to comprehend are not well understood. In the present study, we investigate the role of method chains and code comments in software readability and comprehension. Our analysis comprises data from 104 students with varying programming experience. Readability and comprehension were measured by perceived readability, reading time and performance on a simple cloze test. Regarding perceived readability, our results show statistically significant differences between comment variants, but not between method chain variants. Regarding comprehension, there are no significant differences between method chain or comment variants. Student groups with low and high experience, respectively, show significant differences in perceived readability and performance on the cloze tests. Our results do not show any significant relationships between perceived readability and the other measures taken in the present study. Perceived readability might therefore be insufficient as the sole measure of software readability or comprehension. We also did not find any statistically significant relationships between size and perceived readability, reading time and comprehension.",1939-3520,,10.1109/TSE.2016.2527791,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7404062,Software readability;software comprehension;software measurement;comments;method chains;experiment,Software;Guidelines;Software measurement;Software engineering;Programming;Complexity theory;Object oriented modeling,software maintenance;software metrics,software readability;software comprehension;software maintenance;software measurement;method chains;code comments;cloze tests,,9.0,,57.0,,11 Feb 2016,,,IEEE,IEEE Journals
227,227,Mining Workflow Models from Web Applications,M. Schur; A. Roth; A. Zeller,"SAP SE; SAP SE, Germany; Saarland University–Chair for Software Engineering, Germany",IEEE Transactions on Software Engineering,8 Dec 2015,2015,41,12,1184,1201,"Modern business applications predominantly rely on web technology, enabling software vendors to efficiently provide them as a service, removing some of the complexity of the traditional release and update process. While this facilitates shorter, more efficient and frequent release cycles, it requires continuous testing. Having insight into application behavior through explicit models can largely support development, testing and maintenance. Model-based testing allows efficient test creation based on a description of the states the application can be in and the transitions between these states. As specifying behavior models that are precise enough to be executable by a test automation tool is a hard task, an alternative is to extract them from running applications. However, mining such models is a challenge, in particular because one needs to know when two states are equivalent, as well as how to reach that state. We present Process Crawler (ProCrawl), a tool to mine behavior models from web applications that support multi-user workflows. ProCrawl incrementally learns a model by generating program runs and observing the application behavior through the user interface. In our evaluation on several real-world web applications, ProCrawl extracted models that concisely describe the implemented workflows and can be directly used for model-based testing.",1939-3520,,10.1109/TSE.2015.2461542,German Federal Ministry of Education and Research (BMBF); European Research Council (ERC); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7169616,Specification mining;dynamic analysis;model-based testing;web system testing;Specification mining;dynamic analysis;model-based testing;web system testing,Web services;Software engineering;Data models;Data mining;Automation;Browsers,data mining;Internet;program testing;system monitoring;user interfaces,user interface;multiuser workflow;ProCrawl;Process Crawler;test automation tool;behavior model;test creation;model-based testing;continuous testing;software vendor;Web technology;Web applications;mining workflow model,,7.0,,47.0,,28 Jul 2015,,,IEEE,IEEE Journals
228,228,A Survey on Software Fault Localization,W. E. Wong; R. Gao; Y. Li; R. Abreu; F. Wotawa,"State Key Laboratory of Software Engineering, Wuhan University, Department of Computer Science, University of Texas at Dallas, Richardson, TX; Department of Computer Science, University of Texas at Dallas, Richardson, TX; Department of Computer Science, University of Texas at Dallas, Richardson, TX; Department of Informatics Engineering, University of Porto, Palo Alto Research Center (PARC), Palo Alto, CA; Institute for Software Technology, Graz University of Technology, Austria",IEEE Transactions on Software Engineering,11 Aug 2016,2016,42,8,707,740,"Software fault localization, the act of identifying the locations of faults in a program, is widely recognized to be one of the most tedious, time consuming, and expensive - yet equally critical - activities in program debugging. Due to the increasing scale and complexity of software today, manually locating faults when failures occur is rapidly becoming infeasible, and consequently, there is a strong demand for techniques that can guide software developers to the locations of faults in a program with minimal human intervention. This demand in turn has fueled the proposal and development of a broad spectrum of fault localization techniques, each of which aims to streamline the fault localization process and make it more effective by attacking the problem in a unique way. In this article, we catalog and provide a comprehensive overview of such techniques and discuss key issues and concerns that are pertinent to software fault localization as a whole.",1939-3520,,10.1109/TSE.2016.2521368,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7390282,Software fault localization;program debugging;software testing;execution trace;suspicious code;survey,Debugging;Software engineering;Computer bugs;Software debugging;Fault diagnosis;Complexity theory,program debugging;software reliability,software fault localization;program debugging;software developers;program fault locations;human intervention,,264.0,,427.0,,25 Jan 2016,,,IEEE,IEEE Journals
229,229,Intelligently Transparent Software Ecosystems,J. Herbsleb; C. Kästner; C. Bogart,Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,IEEE Software,29 Dec 2015,2016,33,1,89,96,"Today's social-coding tools foreshadow a transformation of the software industry, as it relies increasingly on open libraries, frameworks, and code fragments. Our vision calls for new intelligently transparent services that support rapid development of innovative products while helping developers manage risk and issuing them early warnings of looming failures. Intelligent transparency is enabled by an infrastructure that applies analytics to data from all phases of the life cycle of open source projects, from development to deployment. Such an infrastructure brings stakeholders the information they need when they need it.",1937-4194,,10.1109/MS.2015.156,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325197,programming environments;metrics;software management;software development;software engineering;intelligent software assurance and monitoring;intelligent transparency;ISAM,Software engineering;Stability analysis;Business;Software assurance;Ecosystems;Software management;Programming,innovation management;public domain software;risk management;software engineering;software houses,intelligently transparent software ecosystems;risk management;data analytics;open source projects;innovative products;social-coding tools;software industry;open libraries,,1.0,,15.0,,11 Nov 2015,,,IEEE,IEEE Magazines
230,230,What are Hackathons for?,M. Komssi; D. Pichlis; M. Raatikainen; K. Kindström; J. Järvinen,F-Secure; Aalto University; Aalto University; F-Secure; F-Secure,IEEE Software,21 Aug 2015,2015,32,5,60,67,"A swift execution from idea to market has become a key competitive advantage for software companies to enable them to survive and grow in turbulent business environments. To combat this challenge, companies are using hackathons. A hackathon is a highly engaging, continuous event in which people in small groups produce working software prototypes in a limited amount of time. F-Secure, a software product company, views hackathons as a possible solution to the fundamental business problem of how to make revenue from an idea, spanning the phases from creating the idea to producing a software prototype. However, hackathons pose the challenge of how to transform those promising prototypes into finalized products that create revenue and real business value.",1937-4194,,10.1109/MS.2014.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6809711,rapid prototyping;design;software engineering;process implementation and change;requirements and specifications;initiation and scope definition;organizational management and coordination;hackathon,Requirements engineering;Software engineering;Market research;Business;Prototypes;Software development,software engineering,hackathons;f-secure;software product company;business problem,,46.0,,8.0,,2 May 2014,,,IEEE,IEEE Magazines
231,231,Metadesign: Guidelines for Supporting Domain Experts in Software Development,G. Fischer; K. Nakakoji; Y. Ye,University of Colorado at Boulder; University of Tokyo; Software Research Associates,IEEE Software,25 Aug 2009,2009,26,5,37,44,"Our collaborative research activities in software development (at the University of Colorado's Center for Lifelong Learning and Design, the University of Tokyo, and Software Research Associates) have focused on understanding the implications of the quickly disappearing distinction between users and developers. We've also concentrated on establishing new software development methodologies by viewing software systems as continuously evolving sociotechnical systems driven by design activities of both professional software engineers and users. We believe that domain experts, as the owners of problems, need to be in charge of developing the software they require. Toward that end, we've created the metadesign framework, which reformulates software development activities as a continuum of different degrees of design and use. In addition, on the basis of our research and our findings in the research literature, we've developed a set of guidelines for supporting domain experts in software development.",1937-4194,,10.1109/MS.2009.134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222792,software developers;domain experts;end-user development;end-user software engineering;domain-specific software development;domain-oriented design environments;seeding;evolutionary growth;reseeding;metadesign;mash-ups;open source;ecologies of participation;software development,Guidelines;Software systems;Application software;Software engineering;Instruments;Biological system modeling;Environmental factors;Data analysis;Programming profession;Productivity,software engineering,metadesign;domain experts;software development;sociotechnical systems;professional software engineers;software users,,27.0,,17.0,,25 Aug 2009,,,IEEE,IEEE Magazines
232,232,Programming with Implicit Flows,G. Salvaneschi; P. Eugster; M. Mezini,"Technical University of Darmstadt, Darmstadt; Purdue University, West Lafayette; Darmstadt University of Technology, Darmstadt",IEEE Software,15 Sep 2014,2014,31,5,52,59,"Modern software differs significantly from traditional computer applications that mostly process reasonably small amounts of static input data-sets in batch mode. Modern software increasingly processes massive amounts of data, whereby it is also often the case that new input data is produced and/or existing data is modified on the fly. Consequently, programming models that facilitate the development of such software are emerging. What characterizes them is that data, respectively changes thereof, implicitly flow through computation modules. The software engineer declaratively defines computations as compositions of other computations without explicitly modeling how data should flow along dependency relations between data producer and data consumer modules, letting the runtime to automatically manage and optimize data flows.",1937-4194,,10.1109/MS.2014.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6840828,reactive programming;event;stream;big data;data-flow;programming languages;software engineering,Programming;Big data;Computational modeling;Runtime;Software engineering;Data models;Market research,software engineering,implicit flows programming;static input data-sets;programming models;software development;computation modules;data producer module;data consumer module;data flow management;data flow optimization,,6.0,,13.0,,20 Jun 2014,,,IEEE,IEEE Magazines
233,233,Modeling Test Cases in BPMN for Behavior-Driven Development,D. Lübke; T. van Lessen,innoQ; innoQ,IEEE Software,24 Aug 2016,2016,33,5,15,21,"Testing large-scale process integration solutions is complex and cumbersome. To tackle this problem, researchers employed behavior-driven development. They used the Business Process Model and Notation language to model domain-specific test cases. These test cases can be understood by both developers and business stakeholders and can be executed automatically.",1937-4194,,10.1109/MS.2016.117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548916,business processes;Business Process Model and Notation;BPMN;behavior-driven development;BDD;test-driven development;TDD;software testing;software development;software engineering,Simple object access protocol;Business process management;Modeling;Testing;Software engineering;Behaviorial sciences,business data processing;program testing;software engineering,test case modelling;Business Process Model and Notation;BPMN;behavior-driven development,,8.0,,10.0,,24 Aug 2016,,,IEEE,IEEE Magazines
234,234,How Expertise Affects a Digital-Rights-Management-Sharing Application's Usability,U. Lah; J. R. Lewis,EMO-Orodjarna; IBM,IEEE Software,25 Apr 2016,2016,33,3,76,82,"Researchers performed a usability study of a digital-rights-management sharing (DRMS) application with which users protect and share digital files. Besides the standard goal of identifying usability problems, the study investigated how expertise affects objective and perceived usability, the correlations among the usability metrics, and how the usability outcomes compared with emerging norms. The researchers divided the 18 study participants into two groups of nine according to skill level. The participants performed seven DRMS tasks. The groups differed significantly in objective usability (successful task completions, errors, and completion times) and perceived usability (ratings of a variant of the System Usability Scale [SUS]). Two correlations were statistically significant (success with the SUS and success with errors); all six possible correlations were in the expected direction. On the basis of the published norms, the overall success rate was below average; the SUS's overall mean was average. The main takeaways for practitioners are two practical examples. The first involved using independently derived benchmarks to assess the perceived usability and effectiveness; the second involved testing different skill groups.",1937-4194,,10.1109/MS.2015.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7281117,digital rights management;DRM;digital-rights-management sharing;DRMS;usability study;perceived usability;System Usability Scale;SUS;success rates;usability metrics;usability norms;software engineering;software development,Digital rights management;Copyright protection;Software development;Correlation;Software engineering;Portable computers,digital rights management;software engineering,digital-rights-management sharing application;DRMS application;digital files protection;digital files sharing;objective usability;perceived usability;usability metrics;usability outcomes;system usability scale,,8.0,,15.0,,29 Sep 2015,,,IEEE,IEEE Magazines
235,235,DevOps: Making It Easy to Do the Right Thing,M. Callanan; A. Spillane,Wotif; Wotif,IEEE Software,25 Apr 2016,2016,33,3,53,59,"Wotif Group used DevOps principles to recover from the downward spiral of manual release activity that many IT departments face. Its approach involved the idea of ""making it easy to do the right thing."" By defining the right thing (deployment standards) for development and operations teams and making it easy to adopt, Wotif drastically improved the average release cycle time. This article is part of a theme issue on DevOps.",1937-4194,,10.1109/MS.2016.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436644,software release;software delivery;software release management and delivery;Internet;e-commerce;DevOps;continuous delivery;continuous deployment;Wotif Group;software development;software engineering,Software development;Testing;Software delivery;Production processes;Software development;Software engineering;Automation,software engineering,DevOps principles;software development;software deployment standards;release cycle time;Wotif Group,,26.0,,11.0,,18 Mar 2016,,,IEEE,IEEE Magazines
236,236,Model-Driven Engineering for Mission-Critical IoT Systems,F. Ciccozzi; I. Crnkovic; D. Di Ruscio; I. Malavolta; P. Pelliccione; R. Spalazzese,Mälardalen University; Chalmers University of Technology and University of Gothenburg; University of L'Aquila; Vrije Universiteit Amsterdam; Chalmers University of Technology and University of Gothenburg; Malmö University,IEEE Software,16 Jan 2017,2017,34,1,46,53,"Mission-critical Internet of Things (MC-IoT) systems involve heterogeneous things from both the digital and physical worlds. They run applications whose failure might cause significant and possibly dramatic consequences, such as interruption of public services, significant business losses, and deterioration of enterprise operations. These applications require not only high availability, reliability, safety, and security but also regulatory compliance, scalability, and serviceability. At the same time, they're exposed to various facets of uncertainty, spanning from software and hardware variability to mission planning and execution in possibly unforeseeable environments. Model-driven engineering can potentially meet these challenges and better enable the adoption of MC-IoT systems.",1937-4194,,10.1109/MS.2017.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819388,software engineering;Internet of Things;IoT;model-driven engineering;mission-critical systems;software development,Internet of things;Mission critical systems;Software engineering;Software development,Internet of Things;software engineering,model-driven engineering;IoT systems;mission-critical Internet of Things;software variability;hardware variability;MC-IoT systems,,37.0,,23.0,,16 Jan 2017,,,IEEE,IEEE Magazines
237,237,Deep Learning in Automotive Software,F. Falcini; G. Lami; A. M. Costanza,Information Science and Technologies Institute of the National Research Council of Italy; Information Science and Technologies Institute of the National Research Council of Italy; Fiat Chrysler Automobiles,IEEE Software,15 May 2017,2017,34,3,56,63,"Deep-learning-based systems are becoming pervasive in automotive software. So, in the automotive software engineering community, the awareness of the need to integrate deep-learning-based development with traditional development approaches is growing, at the technical, methodological, and cultural levels. In particular, data-intensive deep neural network (DNN) training, using ad hoc training data, is pivotal in the development of software for vehicle functions that rely on deep learning. Researchers have devised a development lifecycle for deep-learning-based development and are participating in an initiative, based on Automotive SPICE (Software Process Improvement and Capability Determination), that's promoting the effective adoption of DNN in automotive software.",1937-4194,,10.1109/MS.2017.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927925,artificial neural networks;neural networks;deep neural networks;ANNs;W model;V model;Automotive SPICE;ISO 26262;ISO/AWI PAS 21448;software engineering process;software engineering;vision and scene understanding;computer vision;artificial intelligence;computing methodologies;standards;software development,Deep leanring;Machine learning;Software development;Biological neural networks;Artificial neural networks;Automotive electronics,automotive engineering;intelligent transportation systems;learning (artificial intelligence);neural nets;software process improvement,Software Process Improvement and Capability Determination;automotive software engineering;automotive SPICE;development lifecycle;software development;ad hoc training data;DNN training;data-intensive deep neural network training;deep learning,,44.0,,14.0,,15 May 2017,,,IEEE,IEEE Magazines
238,238,Palantir: Early Detection of Development Conflicts Arising from Parallel Code Changes,A. Sarma; D. F. Redmiles; A. van der Hoek,"University of Nebraska- Lincoln, Lincoln; University of California, Irvine, Irvine; University of California, Irvine, Irvine",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,889,908,"The earlier a conflict is detected, the easier it is to resolve-this is the main precept of workspace awareness. Workspace awareness seeks to provide users with information of relevant ongoing parallel changes occurring in private workspaces, thereby enabling the early detection and resolution of potential conflicts. The key approach is to unobtrusively inform developers of potential conflicts arising because of concurrent changes to the same file and dependency violations in ongoing parallel work. This paper describes our research goals, approach, and implementation of workspace awareness through Palantír and includes a comprehensive evaluation involving two laboratory experiments. We present both quantitative and qualitative results from the experiments, which demonstrate that the use of Palantír, as compared to not using Palantír 1) leads to both earlier detection and earlier resolution of a larger number of conflicts, 2) leaves fewer conflicts unresolved in the code base that was ultimately checked in, and 3) involves reasonable overhead. Furthermore, we report on interesting changes in users' behavior, especially how conflict resolution strategies changed among Palantír users.",1939-3520,,10.1109/TSE.2011.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928359,Software engineering;computer-supported collaborative work;programmer workbench;configuration management,Monitoring;Measurement;Instant messaging;Computer architecture;Databases;Context;Laboratories,configuration management;groupware;parallel processing;software management,Palantír;development conflict early detection;parallel code changes;workspace awareness;dependency violations;laboratory experiments;conflict resolution strategies;software configuration management system;computer-supported collaborative work;software engineering,,38.0,1.0,55.0,,23 Jun 2011,,,IEEE,IEEE Journals
239,239,Roundtable: What's Next in Software Analytics,A. E. Hassan; A. Hindle; P. Runeson; M. Shepperd; P. Devanbu; S. Kim,"Queen's University, Canada; University of Alberta; Lund University; Brunel University; University of California, Davis; Hong Kong University of Science and Technology",IEEE Software,26 Jun 2013,2013,30,4,53,56,"For this special issue, the guest editors asked a panel of six established experts in software analytics to highlight what they thought were the most important, or overlooked, aspect of this field. They all pleaded for a much broader view of analytics than seen in current practice: software analytics should go beyond developers (Ahmed Hassan) and numbers (Per Runeson). Analytics should also prove its relevance to practitioners (Abram Hindle, Martin Shepperd). There are now opportunities for ""natural"" software analytics based on statistical natural language processing (Prem Devanbu). Lastly, software analytics needs information analysts and field agents like Chloe O'Brian and Jack Bauer in the TV show 24 (Sung Kim).",1937-4194,,10.1109/MS.2013.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547637,software/program verification;statistical methods;testing and debugging;metrics;management;information search and retrieval;decision support,Software development;Data mining;Software engineering;Analytical models;Natural language processing;Analytical models,natural language processing;software engineering;statistical analysis,natural software analytics;statistical natural language processing,,13.0,,7.0,,26 Jun 2013,,,IEEE,IEEE Magazines
240,240,What Do Programmers Know about Software Energy Consumption?,C. Pang; A. Hindle; B. Adams; A. E. Hassan,University of Alberta; University of Alberta; Polytechnique Montréal; Queen's University,IEEE Software,25 Apr 2016,2016,33,3,83,89,"Traditionally, programmers received a range of training on programming languages and methodologies, but they rarely receive training on software energy consumption. Yet, the popularity of mobile devices and cloud computing requires increased awareness of software energy consumption. On mobile devices, battery life often limits computation. Under the demands of cloud computing, datacenters struggle to reduce energy consumption through virtualization and datacenter-infrastructure-management systems. Efficient software energy consumption is increasingly becoming an important nonfunctional requirement for programmers. However, are programmers knowledgeable enough about software energy consumption? Do they base their implementation decision on popular beliefs? Researchers surveyed more than 100 programmers regarding their knowledge of software energy consumption. They found that the programmers had limited knowledge of energy efficiency, lacked knowledge of the best practices to reduce software energy consumption, and were often unsure about how software consumes energy. These results highlight the need for better training and education on energy consumption and efficiency.",1937-4194,,10.1109/MS.2015.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155416,software energy consumption;energy efficiency;software power consumption;power usage,Software engineering;Energy consumption;Power demand;Energy measurement;Software measurement;Mobile handsets;Battery charge measurement,energy consumption;green computing;software engineering,programmers;programming languages;programming methodologies;software energy consumption;mobile devices;cloud computing;virtualization;data center-infrastructure-management systems;best practices;energy efficiency,,50.0,,10.0,,13 Jul 2015,,,IEEE,IEEE Magazines
241,241,Coupled Evolution in Model-Driven Engineering,D. Di Ruscio; L. Iovino; A. Pierantonio,Università degli Studi dell'Aquila; Università degli Studi dell'Aquila; Università degli Studi dell'Aquila,IEEE Software,22 Oct 2012,2012,29,6,78,84,"Model-driven engineering bases a wide range of artifacts on metamodels. When such metamodels evolve, such as a new version of Unified Modeling Language or Business Process Execution Notation or a company-specific metamodel, underlying artifacts often become invalid. In this article, the authors provide an overview of coupled evolution methods and tools to handle such dependencies. I look forward to hearing from both readers and prospective authors about this column and the technologies you want to know more about.",1937-4194,,10.1109/MS.2012.153,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6336727,software technology;coupled evolution;model-driven engineering;Unified Modeling Language,Software engineering;Software development;Modeling;Unified modeling language,software engineering,coupled evolution;model-driven engineering;metamodel,,24.0,,5.0,,22 Oct 2012,,,IEEE,IEEE Magazines
242,242,Social Psychology and Software Teams: Establishing Task-Effective Group Norms,A. Teh; E. Baniassad; D. van Rooy; C. Boughton,Australian National University; Australian National University; Australian National University; Australian National University,IEEE Software,10 Aug 2012,2012,29,4,53,58,"It's a common belief that groups that possess appropriate expertise and work well together will be more likely to successfully complete a project. However, social psychological research shows that getting the right mix of people doesn't guarantee a successful outcome. Group success also relies on group norms, which are derived as much from the group's context as from the people in it. A small, preliminary study illustrates how norm manipulation affected how well groups performed requirements elicitation. Results show that groups performed better on this task when norms emphasized creativity rather than agreeability. Norm manipulation might be a practical way to enhance group performance in software engineering tasks. There is an erratum in this article: in Figure 1, the description in the “Constructive norm condition” box should have read “Priming: list what they had learned in their requirements-analysis course.” The description in the “Critical norm condition” box should have read “Priming: debate and reach consensus on the statement‘Requirements specifications should always reflect design constraints.’”",1937-4194,,10.1109/MS.2011.157,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095494,group norms;sociology;teamwork;software engineering,Psychology;Memory management;Software engineering;Sociology;Collaboration;Software engineering;Design methodology;Teamwork,,,,16.0,,15.0,,6 Dec 2011,,,IEEE,IEEE Magazines
243,243,Architectural Mismatch: Why Reuse Is Still So Hard,D. Garlan; R. Allen; J. Ockerbloom,Carnegie Mellon University; IBM; University of Pennsylvania,IEEE Software,19 Jun 2009,2009,26,4,66,69,"In this article, David Garlan, Robert Allen, and John Ockerbloom reflect on the state of architectural mismatch, a term they coined in their 1995 IEEE Software article, ""Architectural Mismatch: Why Reuse Is So Hard."" Although the nature of software systems has changed dramatically since the earlier article was published, the challenge of architectural mismatch remains an important concern for the software engineering field.",1937-4194,,10.1109/MS.2009.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076461,architecture mismatch;software architecture;component-based systems;software engineering,Software systems;Filters;Connectors;Software tools;Communication standards;Software standards;Open source software;Software libraries;Programming;User interfaces,software architecture;software reusability,architectural mismatch;software systems;software engineering field,,39.0,,6.0,,19 Jun 2009,,,IEEE,IEEE Magazines
244,244,Doubt and Software Standards,R. L. Glass,Griffith University,IEEE Software,25 Aug 2009,2009,26,5,104,104,"Software standards. Now there's a subject that brooks no ""loyal opposition,"" right? Standards are material provided by some software god, biblically significant, subject to no doubt? In recent years I've come to question all that.In 2006, my colleague Johann Rost wrote a guest Loyal Opposition column on the standard for requirements documents. He explained that at the conceptual level he understood the standard quite well, but at the implementation level he found it impossible to follow. I offered him sympathy, hosted his column here, and sort of forgot about it. Time passed. Another colleague, Barbara Kitchenham, was beginning to struggle with certain software standards. One standard gave ""inappropriate advice for measuring software engineering processes."" Another standard was ""not suitable for measuring the design quality of a software product."" Echoing Johann's concerns, Barbara commented that ""experienced designers will be able to construct a number of different interpretations of the standard, implying that [it] is not a standard at all."" Barbara pointed me at yet another critic of software standards, Magne Jorgensen. He noted that one standard for software quality ""requires quality measurement and at the same time admits that there are no (universally) accepted quality measures"".",1937-4194,,10.1109/MS.2009.126,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222806,software engineering;software standards,Software standards;Environmental economics;Project management;Subscriptions;Industrial economics;Radio access networks;ISO standards;IEC standards;Software systems,software quality;software standards,software standard;requirements documents;software engineering process;design quality;software product;software quality;quality measurement,,,,7.0,,25 Aug 2009,,,IEEE,IEEE Magazines
245,245,How Software Architects Drive Connected Vehicles,S. Frey; L. Charissis; J. Nahm,Daimler TSS; Daimler TSS; Daimler TSS,IEEE Software,28 Oct 2016,2016,33,6,41,47,"For many years, software engineering researchers and practitioners have tried to determine, define, and redefine the role of software architects. But we still haven't reached a real consensus. The popularity of agile methods such as Scrum and Kanban, with their clear focus on team collaboration, threatens many roles traditionally assigned to individual experts. Some organizations are even challenging the raison d'être of the software architect role. However, researchers' experiences developing connected-vehicle software revealed two reasons why successful projects still often assign architecture-related responsibilities to individual experts acting as software architects. First, the experts help effectively manage complexity; second, they act as knowledge multipliers when development must scale up.",1937-4194,,10.1109/MS.2016.145,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725231,software architectures;software engineering;staffing;project and people management;management of computing and information systems;real-time and embedded systems;special-purpose and application-based systems;computer systems organization;software development;software architects,Software development;Context modeling;Complexity theory;Scrum (Software development);Software architecture;Software architecture,personnel;software development management,software architect role;software engineering;agile methods;Scrum method;Kanban method;team collaboration;connected-vehicle software;complexity management,,4.0,,12.0,,28 Oct 2016,,,IEEE,IEEE Magazines
246,246,Four Trends Leading to Java Runtime Bloat,N. Mitchell; E. Schonberg; G. Sevitsky,IBM Research; IBM Research; IBM Research,IEEE Software,31 Dec 2009,2010,27,1,56,63,"Today, programmers work in an environment of rapid global development of large-scale applications that have become increasingly interconnected. These drivers are the backdrop for four important software engineering trends: the wide adoption of object-oriented principles, the pervasive use of abstractions, system and data integration, and the increasing need for software flexibility. Programmers no longer write monolithic applications; they assemble code from a sea of reuseable libraries and frameworks. Many programmers believe that improved productivity always outweighs any resulting loss in performance, but experience with large Java applications doesn't support this belief.",1937-4194,,10.1109/MS.2010.7,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370764,software construction;data storage representations;metrics;measurements;language constructs and features,Java;Runtime;Programming profession;Application software;Large-scale systems;Software engineering;Assembly;Software libraries;Productivity;Performance loss,Java;software engineering,Java runtime;software engineering trend;abstractions application;data integration;system integration;software flexibility;reuseable library;object-oriented principles,,30.0,1.0,15.0,,31 Dec 2009,,,IEEE,IEEE Magazines
247,248,What Makes an Architect Successful?,J. Klein,Software Engineering Institute,IEEE Software,29 Dec 2015,2016,33,1,20,22,"An architect whose skills and capabilities match a project's needs will more likely be successful. Moreover, each software life-cycle phase requires different skills. A proposed model identifies the skills needed at each phase and helps explain common failure patterns.",1937-4194,,10.1109/MS.2016.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367982,agile teams;software architect;software architecture;software design;software development;software engineering,Software development;Computer architecture;Software architecture;Pragmatics;Performance evaluation;Business,professional aspects;software architecture;software reliability,software life-cycle phase;failure patterns;user skills,,4.0,,5.0,,29 Dec 2015,,,IEEE,IEEE Magazines
248,249,Measuring Developers: Aligning Perspectives and Other Best Practices,M. Umarji; F. Shull,"University of Maryland Baltimore County; Fraunhofer Center for Experimental Software Engineering, Maryland",IEEE Software,16 Oct 2009,2009,26,6,92,94,"The paper discusses the software metrics programs. Software metrics programs might rank among the all-time touchiest subjects in software development. Done well, a measurement program can prove an effective tool for keeping on top of development effort-especially for large, distributed projects. It can help developers feel that they have a fair and objective way of communicating their progress and getting resources allocated where they're needed most. An effective metrics program must address both products and processes. Product-related metrics can be tied to customer satisfaction. They often represent objectively verifiable properties such as the number of bugs or defects found in a product. Process metrics, include measures of effort and effectiveness and can give quick feedback about the status of defect containment, productivity, and other desirable properties at many points during development. However, instituting these metrics poses different challenges that the authors discussed and developed some best practice solutions. These include design measures with multiple stakeholders, build on measures that come naturally out of existing processes, and transparency.",1937-4194,,10.1109/MS.2009.180,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287018,Software engineering;software metrics,Best practices;Software metrics;Programming;Resource management;Customer satisfaction;Computer bugs;Feedback;Productivity,software metrics,software metrics programs;software development;product-related metrics;process metrics;stakeholder design solutions;measure building solutions;transparency solutions,,1.0,,11.0,,16 Oct 2009,,,IEEE,IEEE Magazines
249,250,ICSE Highlights,J. C. Carver; A. Serebrenik,University of Alabama; Eindhoven University of Technology,IEEE Software,13 Nov 2017,2017,34,6,18,20,"This issue’s column reports on papers from the 2017 International Conference on Software Engineering. Topics include context-based analytics, defect prediction, software development and energy consumption, continuous delivery, and continuous deployment.",1937-4194,,10.1109/MS.2017.4121213,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106866,context-based analytics;defect prediction;summation;energy consumption;continuous delivery;continuous deployment;feature freeze;ICSE;International Conference on Software Engineering;software engineering;software development;Practitioners’ Digest,,,,,,,,,13 Nov 2017,,,IEEE,IEEE Magazines
250,251,Quantifying the Effect of Using Kanban versus Scrum: A Case Study,D. I. K. Sjøberg; A. Johnsen; J. Solberg,University of Oslo; Software Innovation; Software Innovation,IEEE Software,21 Aug 2012,2012,29,5,47,53,"Proponents of various processes and methods in the agile and lean communities have made many bold claims about usefulness, but those claims are rarely supported by empirical investigations. Data gathered from more than 12,000 work items collected over two years sheds light on Kanban versus Scrum.To acquire more knowledge about the performance of different agile or lean methods, scholars should conduct similar studies in different organizations in different application domains and with people of different cultures and competences.",1937-4194,,10.1109/MS.2012.110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6231615,lean;software process models;software engineering process;software engineering;process metrics;measurement;productivity;management,Computer bugs;Product life cycle management;Agile manufacturing;Productivity;Software engineering;Software management;Software measurement,kanban;lean production;software development management;software prototyping,agile communities;lean communities;Kanban;Scrum,,32.0,,8.0,,3 Jul 2012,,,IEEE,IEEE Magazines
251,252,Five Years of Software Architecture Checking: A Case Study of Eclipse,J. Brunet; G. C. Murphy; D. Serey; J. Figueiredo,Federal University of Campina Grande; University of British Columbia; Federal University of Campina Grande; Federal University of Campina Grande,IEEE Software,21 Aug 2015,2015,32,5,30,36,"Over time, source code tends to drift from the intended software architecture, often resulting in the loss of desired software qualities. To help keep code aligned with the intended architecture, the developers of core parts of the open source Eclipse platform introduced API Tools to express and check architectural rules. Researchers analyzed five years of Eclipse architecture-checking reports that API Tools produced. They investigated what kinds of rules the developers found helpful to check, how code diverged from the intended architecture, and how the developers dealt with architectural violations over time. This article is part of a special issue on Software Architecture.",1937-4194,,10.1109/MS.2014.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6879058,architecture checking;empirical software engineering;Eclipse;software development;software engineering,Computer architecture;Software architecture;Software engineering;Documentation;Software maintenance;Computer science,application program interfaces;program verification;software architecture,software architecture checking;source code;software qualities;open source Eclipse platform;API tools;architectural rules;Eclipse architecture-checking;architectural violations,,7.0,,9.0,,15 Aug 2014,,,IEEE,IEEE Magazines
252,253,Microblogging in Open Source Software Development: The Case of Drupal and Twitter,X. Wang; I. Kuzmickaja; K. Stol; P. Abrahamsson; B. Fitzgerald,Free University of Bozen-Bolzano; Free University of Bozen-Bolzano; Lero--The Irish Software Engineering Research Centre; Free University of Bozen-Bolzano; Lero--The Irish Software Engineering Research Centre,IEEE Software,13 Jun 2014,2014,31,4,72,80,"Microblogging is a popular form of social media that has quickly permeated both enterprise and open source software development communities. However, how exactly open source communities can leverage microblogging isn't yet well understood.",1937-4194,,10.1109/MS.2013.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6576114,Twitter;microblogging;social media;open source software development;Drupal;communication;crowdsourcing;software engineering;pervasive computing,Open source software;Social network services;Media;Blogs;Twitter,public domain software;social networking (online),microblogging;drupal;twitter;social media;enterprise;open source software development community;open source community,,14.0,,16.0,,7 Aug 2013,,,IEEE,IEEE Magazines
253,254,Strategic Prototyping for Developing Big Data Systems,H. Chen; R. Kazman; S. Haziyev,University of Hawaii at Manoa; University of Hawaii at Manoa; SoftServe,IEEE Software,26 Feb 2016,2016,33,2,36,43,"Conventional horizontal evolutionary prototyping for small-data system development is inadequate and too expensive for identifying, analyzing, and mitigating risks in big data system development. RASP (Risk-Based, Architecture-Centric Strategic Prototyping) is a model for cost-effective, systematic risk management in agile big data system development. It uses prototyping strategically and only in areas that architecture analysis can't sufficiently address. Developers use less costly vertical evolutionary prototypes instead of blindly building full-scale prototypes. An embedded multiple-case study of nine big data projects at a global outsourcing firm validated RASP. A decision flowchart and guidelines distilled from lessons learned can help architects decide whether, when, and how to do strategic prototyping. This article is part of a special issue on Software Engineering for Big Data Systems.",1937-4194,,10.1109/MS.2016.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420518,big data;RASP;risk management;rapid prototyping;evolutionary prototyping;throwaway prototyping;software architecture;software development;software engineering,Big data;Risk management;Rapid prototyping;Data models;Data structures;Boolean functions;Software architecture;Software engineering,Big Data;outsourcing;risk management;software prototyping,evolutionary prototyping;small-data system development;Big data systems;RASP;risk-based architecture-centric strategic prototyping;cost-effective systematic risk management;agile big data system development;big data projects;global outsourcing firm;decision flowchart;software engineering,,20.0,,16.0,,26 Feb 2016,,,IEEE,IEEE Magazines
254,255,Operational-Log Analysis for Big Data Systems: Challenges and Solutions,A. Miranskyy; A. Hamou-Lhadj; E. Cialini; A. Larsson,"Ryerson University; Concordia University, Montreal; IBM; Ericsson",IEEE Software,26 Feb 2016,2016,33,2,52,59,"Big data systems (BDSs) are complex, consisting of multiple interacting hardware and software components, such as distributed computing nodes, databases, and middleware. Any of these components can fail. Finding the failures' root causes is extremely laborious. Analysis of BDS-generated logs can speed up this process. The logs can also help improve testing processes, detect security breaches, customize operational profiles, and aid with any other tasks requiring runtime-data analysis. However, practical challenges hamper log analysis tools' adoption. The logs emitted by a BDS can be thought of as big data themselves. When working with large logs, practitioners face seven main issues: scarce storage, unscalable log analysis, inaccurate capture and replay of logs, inadequate log-processing tools, incorrect log classification, a variety of log formats, and inadequate privacy of sensitive data. Some practical solutions exist, but serious challenges remain. This article is part of a special issue on Software Engineering for Big Data Systems.",1937-4194,,10.1109/MS.2016.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412635,big data;software tracing and logging;software engineering;software development,Big data;Computer security;Software engineering;Distributed databases;Tracking;Software development,Big Data;middleware;security of data,operational-log analysis;Big Data systems;hardware components;software components;distributed computing nodes;database management;middleware;BDS-generated log analysis;testing process improvement;security breach detection;operational profile customization;runtime-data analysis;software engineering,,22.0,,14.0,,18 Feb 2016,,,IEEE,IEEE Magazines
255,256,Mining for Computing Jobs,A. Aken; C. Litecky; A. Ahmad; J. Nelson,"Southern Illinois University, Carbondale; Southern Illinois University, Carbondale; Southern Illinois University, Carbondale; Southern Illinois University, Carbondale",IEEE Software,31 Dec 2009,2010,27,1,78,85,"A Web content mining approach identified 20 job categories and the associated skills needs prevalent in the computing professions. Using a Web content data mining application, we extracted almost a quarter million unique IT job descriptions from various job search engines and distilled each to its required skill sets. We statistically examined these, revealing 20 clusters of similar skill sets that map to specific job definitions. The results allow software engineering professionals to tune their skills portfolio to match those in demand from real computing jobs across the US to attain more lucrative salaries and more mobility in a chaotic environment.",1937-4194,,10.1109/MS.2009.150,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232798,clustering;web mining;data mining;computer and information science education;employment;occupations;software;software engineering,Data mining;Application software;Search engines;Software engineering;Portfolios;Remuneration;Chaos,data mining;information filtering;Internet;search engines;statistical analysis,Web content data mining application;IT job description extraction;job search engines;statistical analysis;software engineering professionals;chaotic environment,,34.0,,32.0,,4 Sep 2009,,,IEEE,IEEE Magazines
256,257,A Deep-Intelligence Framework for Online Video Processing,W. Zhang; L. Xu; Z. Li; Q. Lu; Y. Liu,"China University of Petroleum; China University of Petroleum; China University of Petroleum; China University of Petroleum; Concordia University, Montreal",IEEE Software,26 Feb 2016,2016,33,2,44,51,"Video data has become the largest source of big data. Owing to video data's complexities, velocity, and volume, public security and other surveillance applications require efficient, intelligent runtime video processing. To address these challenges, a proposed framework combines two cloud-computing technologies: Storm stream processing and Hadoop batch processing. It uses deep learning to realize deep intelligence that can help reveal knowledge hidden in video data. An implementation of this framework combines five architecture styles: service-oriented architecture, publish-subscribe, the Shared Data pattern, MapReduce, and a layered architecture. Evaluations of performance, scalability, and fault tolerance showed the framework's effectiveness. This article is part of a special issue on Software Engineering for Big Data Systems.",1937-4194,,10.1109/MS.2016.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412619,big data;cloud computing;deep learning;fault tolerance;video processing;MapReduce;Storm;Hadoop;software engineering;software development,Streaming media;Computer architecture;Real-time systems;Big data;Machine learning;Scalability;Software engineering;Cloud computing;Fault tolerance;Software development;Deep learning,Big Data;cloud computing;data handling;learning (artificial intelligence);service-oriented architecture;software fault tolerance;video signal processing,deep-intelligence framework;online video processing;cloud-computing technologies;storm stream processing;Hadoop batch processing;deep learning;service-oriented architecture;publish-subscribe style;shared data pattern;MapReduce;layered architecture;fault tolerance;software engineering;big data systems,,34.0,,6.0,,18 Feb 2016,,,IEEE,IEEE Magazines
257,258,Why Software Is Like Baseball,R. Valerdi,University of Arizona,IEEE Software,22 Sep 2017,2017,34,5,7,9,"In baseball, the practice of sabermetrics uses data to make objective decisions about which players to draft, which players to play, how much to pay players, and which personnel trades between teams make the most sense. Applying such thinking to software projects might help software teams find hidden value and operate more efficiently and effectively.",1937-4194,,10.1109/MS.2017.3571583,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048622,baseball;Moneyball;sabermetrics;software development;COCOMO II;software engineering,Decision making;Software development;Software measurement;Software engineering;Games,decision making;project management;software management,decisions making;software projects;software teams,,,,4.0,,22 Sep 2017,,,IEEE,IEEE Magazines
258,259,How Do I Know Whether to Trust a Research Result?,M. Shepperd,Brunel University London,IEEE Software,4 Feb 2015,2015,32,1,106,109,"A meta-analysis indicated that some areas of computer science research are subject to researcher bias. However, rather than mistrust all scientific research, researchers should examine research to determine its validity.",1937-4194,,10.1109/MS.2015.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030205,meta-analysis;software engineering;research results;statistical significance;software defect prediction;Matthews correlation coefficient;researcher bias;scientific research,Research and development;Systematics;Software engineering;Statistical analysis;Internet,computer science;trusted computing,trust;scientific research result;meta-analysis;computer science research;researcher bias,,3.0,,6.0,,4 Feb 2015,,,IEEE,IEEE Magazines
259,260,Service-Oriented Architecture and Legacy Systems,N. Serrano; J. Hernantes; G. Gallardo,NA; NA; NA,IEEE Software,15 Sep 2014,2014,31,5,15,19,"Enterprise systems are quickly evolving from monolithic silos to distributed applications with service-oriented flexible usage schemes. To keep up, IT organizations must adapt their legacy systems to meet changing business challenges almost in real time, with no second chances. Service-oriented architectures (SOAs) have evolved to flexibly operate and federate business processes and underlying systems. Authors Nicolas Serrano, Josune Hernantes, and Gorka Gallardo provide an overview of current SOA technologies and how to evolve in legacy environments.",1937-4194,,10.1109/MS.2014.125,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898686,software engineering;SOA;service-oriented architecture;cloud computing;Web services;APIs;legacy systems;systems integration;HTTP;SOAP;REST,Service-oriented architecture;Simple object access protocol;Software engineering;Legacy systems,service-oriented architecture;software maintenance,service-oriented architecture;legacy systems;enterprise systems;service-oriented flexible usage schemes;IT organizations;information technology;SOA;legacy environment,,17.0,,5.0,,15 Sep 2014,,,IEEE,IEEE Magazines
260,261,Release Stabilization on Linux and Chrome,M. T. Rahman; P. C. Rigby,Concordia University; Concordia University,IEEE Software,10 Mar 2015,2015,32,2,81,88,"An empirical study of the time and effort for release stabilization on Linux and Chrome found that small teams controlled the stabilization effort, few changes were reverted, and the original developer didn't do much of the rework. Despite regular rapid release cycles, a rush period occurred before release stabilization, and stabilization periods could vary up to 10 days.",1937-4194,,10.1109/MS.2015.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006343,software engineering;software release management and delivery;configuration management,Continuous production;Software development;Schedules;Software engineering;Software measurement;Standards;Configuration management,Linux;online front-ends;software development management,Linux;Chrome;release stabilization;stabilization effort;regular rapid release cycles;rush period,,14.0,,12.0,,12 Jan 2015,,,IEEE,IEEE Magazines
261,262,Breezing My Way as a Solution Architect: A Retrospective on Skill Development and Use,R. Krishnamurthy,Cognizant Technology Solutions,IEEE Software,15 May 2017,2017,34,3,9,13,"Solution architecture is a team effort balancing various forces. Solution architects must consciously cultivate skills cutting across technical, social, and behavioral domains. In this article, Raghuraman Krishnamurthy discusses eight such skills that will likely be helpful.",1937-4194,,10.1109/MS.2017.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927930,software architecture;software systems;knowledge management;software engineering;software development,Software architecture;Databases;Stakeholders;Strategic planning;Software engineering;Software development,software architecture;team working,skill development;solution architecture;team effort;skills cultivation;technical domains;social domains;behavioral domains;Raghuraman Krishnamurthy,,3.0,,14.0,,15 May 2017,,,IEEE,IEEE Magazines
262,263,Just Enough Anticipation: Architect Your Time Dimension,E. Poort; C. Pautasso; O. Zimmermann,CGI; University of Lugano; University of Applied Sciences of Eastern Switzerland,IEEE Software,28 Oct 2016,2016,33,6,11,15,"Documenting the time dimension part of your architecture might look like extra work. However, anticipation should be a large part of your job as an architect, anyway. If you communicate your anticipation as an evolution viewpoint or architecture roadmap, your architecture description will stay valid longer. And, you'll have a ready answer when stakeholders ask how you've addressed their change and planning concerns.",1937-4194,,10.1109/MS.2016.134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725228,software architecture;architecture roadmapping;software evolution;software development;software engineering;technical debt;RCDA;risk- and cost-driven architecture;agile development,Software architecture;Software development;Documentation;Service-oriented architecture;Software engineering,software architecture,evolution viewpoint;architecture roadmap;architecture description;time dimension part,,5.0,,8.0,,28 Oct 2016,,,IEEE,IEEE Magazines
263,264,Data Center Energy Demand: What Got Us Here Won't Get Us There,R. Bashroush; E. Woods; A. Noureddine,University of East London; Endava; University of East London,IEEE Software,26 Feb 2016,2016,33,2,18,21,"Given environmentalism's rising tide and increasing energy prices and IT workloads, architects must determine whether they can continue designing systems without considering energy and power efficiency.",1937-4194,,10.1109/MS.2016.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420488,energy efficiency;green computing;software architect;software architecture;software design;software development;software engineering,Energy efficiency;Software engineering;Software architecture;Computer architecture;Software design;Green computing;Environmental factors,computer centres;energy conservation;energy consumption;power aware computing,energy prices;IT workloads;energy efficiency;power efficiency;data center energy demand,,4.0,,6.0,,26 Feb 2016,,,IEEE,IEEE Magazines
264,265,Cyclomatic Complexity,C. Ebert; J. Cain; G. Antoniol; S. Counsell; P. Laplante,University of Stuttgart; Brunel University; Polytechnique Montréal; Pennsylvania State University; Brunel University,IEEE Software,28 Oct 2016,2016,33,6,27,29,"The cyclomatic complexity (CC) metric measures the number of linearly independent paths through a piece of code. Although Thomas McCabe developed CC for procedural languages, its popularity has endured throughout the object-oriented era. That said, CC is one of the most controversial metrics, shunned for the most part by academia for certain theoretical weaknesses and the belief that it's no more useful than a simple “lines of code” metric. However, most metrics collection tools support its collection, and, paradoxically, industry uses it extensively. So, why is this the case? This question also leads to fundamental perennial questions about industry's exposure to academic opinion and whether academic research fails to take account of software development's daily practicalities. Maybe industry is simply looking for straightforward, widely understood metrics?",1937-4194,,10.1109/MS.2016.147,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725232,cyclomatic complexity;software industry;software engineering;software development,Software measurement;Software engineering;Software development;Complexity theory;Software testing;Blogs,software metrics,cyclomatic complexity metric;CC metric;procedural languages;object-oriented language;software development,,13.0,,1.0,,28 Oct 2016,,,IEEE,IEEE Magazines
265,266,Evaluating Lehman's Laws of Software Evolution for Software Product Lines,R. P. de Oliveira; E. S. de Almeida,Federal Institute of Sergipe; Federal University of Bahia,IEEE Software,25 Apr 2016,2016,33,3,90,93,"The evolution of software to maintain its performance and usefulness over time occurs in successful software development processes. To address this, Meir Lehman formulated his well-known software-evolution laws. This article evaluates Lehman's laws in the context of two companies' real-world software-product-line projects to gain useful insights about the evolution process.",1937-4194,,10.1109/MS.2016.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458762,software;software evolution;Lehman's laws;Meir Lehman;software product lines;SPL;software development;software engineering,Software development;Product lines;Complexity theory;Software engineering;Software product lines;Stability analysis,software product lines,Lehman software evolution laws;software product lines;software development process;software evolution process,,2.0,,7.0,,25 Apr 2016,,,IEEE,IEEE Magazines
266,267,Driving Agile Architecting with Cost and Risk,E. R. Poort,,IEEE Software,15 Sep 2014,2014,31,5,20,23,"Five pieces of advice can help architects become more effective in an agile world without having to implement new methods or frameworks. They describe changes in attitude or behavior rather than complete practices or principles so they're easy to digest and apply. The ideas are based on a solution architecting approach called Risk- and Cost-Driven Architecture. Core to the approach is the use of risk and cost to determine the architectural significance of concerns. Agility is achieved by keeping the architecture lightweight, addressing only those concerns that are especially risky or costly. A risk- and cost-driven backlog of architectural concerns balances the generally value-driven product backlog to achieve “just enough anticipation” in the evolution of software solutions.",1937-4194,,10.1109/MS.2014.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898730,software engineering;project management;agile;architecture,Computer architecture;Agile manufacturing;Software engineering;Pragmatics;Project management,costing;risk management;software architecture;software prototyping,agile architecture;solution architecting approach;risk-driven architecture;cost-driven architecture;software agility;risk-driven backlog;cost-driven backlog;value-driven product backlog;software solutions,,10.0,,4.0,,15 Sep 2014,,,IEEE,IEEE Magazines
267,268,Architectural Principles for Energy-Aware Internet-Scale Applications,R. Bashroush; E. Woods,University of East London; Endava,IEEE Software,15 May 2017,2017,34,3,14,17,"Optimizing the energy consumption of today's Internet-scale systems will require a radical approach that considers the whole system. To address system-level energy efficiency, software architects can follow three simple design principles. A case study illustrates the possible savings.",1937-4194,,10.1109/MS.2017.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927928,software architect;green computing;energy;energy efficiency;datacenters;software engineering;Internet;cloud;eBay;software development,Software engineering;Redundancy;Internet;Energy consumption;Optimization,Internet;power aware computing;software architecture,architectural principles;energy-aware Internet-scale applications;energy consumption;Internet-scale systems;system-level energy efficiency;software architects,,3.0,,8.0,,15 May 2017,,,IEEE,IEEE Magazines
268,269,From Raw Project Data to Business Intelligence,P. Mäder; J. Cleland-Huang,Technische Universität Ilmenau; DePaul University,IEEE Software,30 Jun 2015,2015,32,4,22,25,"VTML (Visual Trace Modeling Language) empowers project stakeholders to issue useful queries. The Web extra at https://youtu.be/RH4rvFgj8lQ is an audio podcast in which author Jane Cleland-Huang provides an audio recording of the Requirements column, in which she discusses how VTML (Visual Trace Modeling Language) empowers project stakeholders to issue useful queries.",1937-4194,,10.1109/MS.2015.92,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140680,TIM;Traceability Information Mode;VTML;Visual Trace Modeling Language;SQL queries;trace links;software engineering;software development,Unified modeling language;Visualization;Data models;Software development;Software engineering;Visual analytics;Query processing,competitive intelligence;project management;visual languages,business intelligence;raw project data;visual trace modeling language;VTML;project stakeholders,,1.0,,2.0,,30 Jun 2015,,,IEEE,IEEE Magazines
269,270,Mobile Money's Impact on Tanzanian Agriculture,B. Seetharam; D. Johnson,Vodafone Solutions; TechnoServe,IEEE Software,4 Feb 2015,2015,32,1,29,34,Software has enabled the use of mobile money by farmers and significantly benefited Tanzanian agriculture.,1937-4194,,10.1109/MS.2015.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030183,Tanzania;mobile money;cell phones;mobile networks;agriculture;M-Pesa;Multiflower;software engineering,Mobile communication;Servers;Mobile handsets;Finance;Mobile computing;Software engineering;Logic gates,agriculture;electronic money;mobile computing,mobile money impact;Tanzanian agriculture;farmers,,1.0,,8.0,,4 Feb 2015,,,IEEE,IEEE Magazines
270,271,"Caring: An Undiscovered ""Super -ility"" of Smart Healthcare",N. Laplante; P. A. Laplante; J. Voas,Widener University; Pennsylvania State University; US National Institute of Standards and Technology,IEEE Software,28 Oct 2016,2016,33,6,16,19,"As new and exciting healthcare applications arise that use smart technologies, the Internet of Things, data analytics, and other technologies, a critical problem is emerging: the potential loss of caring. Although these exciting technologies have improved patient care by allowing for better assessment, surveillance, and treatment, their use can disassociate the caregiver from the patient, essentially removing the ""care"" from healthcare. So, you can view caring as an undiscovered -ility that ranks at least as important as other well-known -ilities in healthcare systems. The Web Extra at https://youtu.be/bDyZ2geRyJE is an audio podcast of author Phil Laplante reading this article.",1937-4194,,10.1109/MS.2016.136,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725236,smart healthcare systems;Internet of Things;requirements;-ilities;software engineering;software development;healthcare;caring;nursing,Medical services;Software engineering;Internet of things;Smart devices,data analysis;health care;Internet of Things,smart healthcare;smart technologies;Internet of Things;data analytics;patient care,,6.0,,5.0,,28 Oct 2016,,,IEEE,IEEE Magazines
271,272,Collaboration in Formative Design: Working Together at a Whiteboard,J. Rooksby; N. Ikeya,University of St Andrews; Keio University,IEEE Software,22 Dec 2011,2012,29,1,56,60,"To successfully collaborate in a creative design session, software developers must achieve and maintain a shared focus, encourage and challenge each other, and manage their working relations, even in stressful situations. This article describes six key ways professional software developers do this using examples from a video study of professional developers designing at a whiteboard.",1937-4194,,10.1109/MS.2011.123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035658,programming teams;software engineering process;qualitative process analysis;management,Collaboration;Software design;Software engineering;Product development;Software development management,software development management;team working,formative design collaboration;creative design session;professional software developer;whiteboard,,5.0,,7.0,,6 Oct 2011,,,IEEE,IEEE Magazines
272,273,Guest Editors' Introduction: Parallelism on the Desktop,V. Pankratius; W. Schulte; K. Keutzer,"Karlsruhe Institute of Technology; Microsoft; University of California, Berkeley",IEEE Software,20 Dec 2010,2011,28,1,14,16,"The computer industry is experiencing a major shift: improved single processor performance via higher clock rates has reached its technical limits due to overheating. Fortunately, Moore's law still holds, so chip makers use transistors to boost performance through parallelism in multicore and manycore processors. However, exploiting the full potential of these processors requires parallel programming. Thus, a large number of developers need to parallelize desktop applications, including browsers, business applications, media processing, and other domain-specific applications. This is likely to result in the largest rewrite of software in the history of the desktop. To be successful, systematic engineering principles must be applied to parallelize performance-critical applications and environments. In light of these developments, we're pleased to present this special issue on programming methods, tools, and libraries for parallelizing desktop applications.",1937-4194,,10.1109/MS.2011.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672515,Multicore;Manycore;parallel programming;multicore software engineering,Special issues and sections;Parallel processing;Instruction sets;Software engineering;Multicore processing,,,,,,,,20 Dec 2010,,,IEEE,IEEE Magazines
273,274,It Is Cold. And Lonely.,G. Booch,,IEEE Software,25 Apr 2016,2016,33,3,7,9,"The next generation of software-intensive systems will be taught instead of programmed. This poses considerable pragmatic challenges in how we develop, deliver, and evolve them. The Web extra at https://youtu.be/_tAxyi5Cma0 is an audio podcast of author Grady Booch reading his column.",1937-4194,,10.1109/MS.2016.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458768,software engineering;deep learning;development tools;ethics;software development,Neural networks;Ehtics;Complexity theory;Software engineering;Artificial intelligence;Deep learning;Robots;Software development,learning (artificial intelligence),machine learning;software-intensive system;IBM Watson;AlphaGo;arificial intelligence,,,,6.0,,25 Apr 2016,,,IEEE,IEEE Magazines
274,275,Software Mythbusters Explore Formal Methods,C. Jaspan; M. Keeling; L. Maccherone; G. L. Zenarosa; M. Shaw,Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University; University of Pittsburgh; Carnegie Mellon University,IEEE Software,16 Oct 2009,2009,26,6,60,63,"In 1990, Anthony Hall identified and challenged seven common myths about formal methods in the IEEE Software article ""Seven Myths of Formal Methods."" This update re-examines those myths, reflecting both on the authors' experience with formal methods in practice and on their persistent mythic status",1937-4194,,10.1109/MS.2009.188,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287011,formal methods;formal specification;specifications;education;software engineering education;development process;mathematics;specification tool,Application software;Unified modeling language;Computer industry;Defense industry;Springs;Seminars;Software engineering;Programming;Real time systems;Biomedical informatics,,,,4.0,,1.0,,16 Oct 2009,,,IEEE,IEEE Magazines
275,276,Architecture Haiku: A Case Study in Lean Documentation [The Pragmatic Architect],M. Keeling,IBM,IEEE Software,23 Apr 2015,2015,32,3,35,39,"An architecture haiku aims to capture software system architecture's most important details on a single piece of paper. An architecture haiku helps development teams focus on the most essential information relevant to the architecture, provides clear guidance for construction, and encourages collaboration.",1937-4194,,10.1109/MS.2015.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093016,architecture haiku;software architecture;software documentation;software engineering;software development,Computer architecture;Software engineering;Documentation;Pragmatics;Software development;Context modeling,software architecture,software system architecture;Haiku;lean documentation,,1.0,,4.0,,23 Apr 2015,,,IEEE,IEEE Magazines
276,277,Requirements and Architectures for Secure Vehicles,M. W. Whalen; D. Cofer; A. Gacek,University of Minnesota; Rockwell Collins Advanced Technology Center; Rockwell Collins Advanced Technology Center,IEEE Software,23 Jun 2016,2016,33,4,22,25,"In the High-Assurance Cyber Military Systems project, researchers are investigating how to construct complex networked-vehicle software securely. Experiments demonstrated that careful attention to requirements and system architecture, along with formally verified approaches that remove known security weaknesses, can lead to vehicles that can withstand attacks from even sophisticated attackers with access to vehicle design data. The Web extra at https://youtu.be/EvG7fjdvyro is an audio podcast of author Michael W. Whalen reading the column that he cowrote with Darren Cofer and Andrew Gacek.",1937-4194,,10.1109/MS.2016.94,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498541,software requirements;vehicle security;HACMS;High-Assurance Cyber Military Systems;UAVs;unmanned aerial vehicles;software development;software engineering,Software engineering;Computer architecture;Encryption;Computer crime;Unmanned aerial vehicles;Military communication,military computing;military vehicles,secure vehicles;high-assurance cyber military systems project;networked-vehicle software;system architecture;security weaknesses;sophisticated attackers;vehicle design data,,9.0,,5.0,,23 Jun 2016,,,IEEE,IEEE Magazines
277,278,Web App Security: A Comparison and Categorization of Testing Frameworks,S. M. Srinivasan; R. S. Sangwan,Penn State University; Penn State University,IEEE Software,16 Jan 2017,2017,34,1,99,102,"Web app developers often face challenges in using the many available security-testing frameworks, owing to those frameworks' inherent complexity and the lack of proper documentation. No up-to-date criteria exist that can help practitioners and organizations select an appropriate framework. Consequently, numerous vulnerabilities go undetected in the final product, creating a potential for major attacks. To help practitioners select the right framework, researchers classified 26 frameworks, using 27 criteria.",1937-4194,,10.1109/MS.2017.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819409,Web apps;security testing;software security;software development;software engineering,Computer applications;Authentication;Authorization;Software engineering;Forgery;High performance computing;Computer security;Software testing,Internet;program testing;safety-critical software,documentation;security-testing frameworks;Web application security,,6.0,,4.0,,16 Jan 2017,,,IEEE,IEEE Magazines
278,279,Disrupting the Disrupters,G. Booch,,IEEE Software,23 Jun 2016,2016,33,4,6,8,"How do you disrupt an industry? Question the fundamental, sacred assumptions on which that industry is founded, then journey along the path of the possible. The Web extra at https://youtu.be/bDVbj5XO2bU is an audio podcast of author Grady Booch reading his column.",1937-4194,,10.1109/MS.2016.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498539,software engineering;disruption;human experience;computing;software development,Software engineering;Behavioral science;Human factors;Technological innovation;Software development,software prototyping,computing disruption;pair programming;development process,,,,3.0,,23 Jun 2016,,,IEEE,IEEE Magazines
279,280,Obstanovka: Exploring Nearby Space,J. Nagy; K. Balajthy; S. Szalai; B. Sódor; I. Horváth; C. Lipusz,Wigner Research Centre for Physics; Wigner Research Centre for Physics; SGF Ltd.; Wigner Research Centre for Physics; Wigner Research Centre for Physics; Ericsson,IEEE Software,23 Jun 2016,2016,33,4,101,105,"The exploration and examination of near-Earth space helps us better understand our solar system and deeply affects our everyday life in areas such as telecommunications, Earth observation, and weather forecasting. Toward that end, scientists developed the onboard data acquisition and control system of the Obstanovka (Russian for environment) experiment in the Russian segment of the International Space Station. Obstanovka, developed by nine teams from different countries, employs 11 sensors to study how the Sun, magnetosphere, and ionosphere influence Earth's weather.",1937-4194,,10.1109/MS.2016.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498543,Obstanovka;space exploration;magnetosphere;ionosphere;International Space Station;software development;software engineering,Space research;Sensors;Space stations;Software engineering;Real-time systems;Linux;Telemetry,aerospace engineering;control engineering computing;control systems;data acquisition;solar system;weather forecasting,Obstanovka;near-Earth space;solar system;Earth observation;weather forecasting;onboard data acquisition;control system;International Space Station,,1.0,,1.0,,23 Jun 2016,,,IEEE,IEEE Magazines
280,281,Requirements in a Global World,J. Cleland-Huang; P. Laurent,DePaul University; Blue Cross Blue Shield,IEEE Software,7 Nov 2014,2014,31,6,34,37,"The challenges of eliciting requirements in global projects can be addressed through deliberate up-front planning processes that take into consideration, people, technology, meeting locations, communication, workflow processes, and documentation needs. The authors present a practical approach to support this planning process. The Web extra at http://youtu.be/eLk66zSFS6c is an audio podcast in which author Jane Cleland-Huang provides an audio recording of the Requirements column, coauthored with Paula Laurent, in which she discusses how the challenges of eliciting requirements in global projects can be addressed through deliberate upfront planning processes that take into consideration people, technology, meeting locations, communication, workflow processes, and documentation needs.",1937-4194,,10.1109/MS.2014.144,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949515,global projects;requirements elicitation;collaboration;project planning;software engineering,Globalization;Software engineering;Planning;Software development;Collaboration,planning;software development management,requirements elicitation;planning process,,,,4.0,,7 Nov 2014,,,IEEE,IEEE Magazines
281,282,Automating the Web with CoScripter: An Interview with Tessa Lau,A. J. Ko,University of Washington,IEEE Software,25 Aug 2009,2009,26,5,52,53,"The future of computer use is undeniably on the Web. People bank, store documents, do research, and even make and maintain friendships online. With this explosion of Web-based content and applications has come a proliferation of tools to streamline and automate people's interactions on the Web, leading many users to write Web scripts to simplify their work. With CoScripter, users can automate Web activities through scripting and share scripts with others.",1937-4194,,10.1109/MS.2009.122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222794,Web;automation;scripting;software engineering,Interviews;Debugging;Computer bugs;Collaboration;Advertising;Web pages;Software engineering;Tagging;Web page design;Automatic control,social networking (online),Web activity automation;computer use;Tessa Lau;Web script sharing;social sharing;social networking;online friendship;people bank;document storage,,,,,,25 Aug 2009,,,IEEE,IEEE Magazines
282,283,Scaling Agile,C. Ebert; M. Paasivaara,Vector Consulting Services; IT University of Copenhagen,IEEE Software,13 Nov 2017,2017,34,6,98,103,"Agile software development has become mainstream. Industry-scale agility for distributed teams, large projects, or critical systems requires scaling agile practices, which agile scaling frameworks attempt to provide. Here, Maria Paasivaara and I explore frameworks such as the Scaled Agile Framework (SAFe) and show best practices from two industry case studies. I look forward to hearing from both readers and prospective column authors about this column and the technologies you want to know more about.",1937-4194,,10.1109/MS.2017.4121226,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106870,agile development;Scaled Agile Framework;SAFe;Large-Scale Scrum;LeSS;Disciplined Agile Delivery;DAD;Scrum of Scrums;SoS;Lean Scalable Agility for Engineering;LeanSAFE;software engineering;software development;Software Technology,Agile development;Software engineering;Scrum (Software development);Modeling,software prototyping,agile software development;industry-scale agility;agile scaling frameworks;scaled agile framework;SAFe,,9.0,,6.0,,13 Nov 2017,,,IEEE,IEEE Magazines
283,284,"Software Developers, Moods, Emotions, and Performance",D. Graziotin; X. Wang; P. Abrahamsson,Free University of Bozen-Bolzano; Free University of Bozen-Bolzano; Free University of Bozen-Bolzano,IEEE Software,13 Jun 2014,2014,31,4,24,27,Studies show that software developers' happiness pays off when it comes to productivity.,1937-4194,,10.1109/MS.2014.94,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834716,software engineering;performance;development;human factors,Software development;Mood;Software engineering;Productivity,,,,30.0,,14.0,,13 Jun 2014,,,IEEE,IEEE Magazines
284,285,Agile Compass: A Tool for Identifying Maturity in Agile Software-Development Teams,R. M. Fontana; S. Reinehr; A. Malucelli,Pontifical Catholic University of Paraná; Pontifical Catholic University of Paraná; Pontifical Catholic University of Paraná,IEEE Software,28 Oct 2015,2015,32,6,20,23,"Researchers investigated how agile software development teams evolve. They analyzed nine teams' evolution of practices and found that the process was idiosyncratic. Each team adopted practices on the basis of its circumstances and improved the practices on the basis of the challenges it faced. Using this research, the researchers designed the Agile Compass, a questionnaire based on a set of guidelines for agile-development improvement, supported by real teams' values and principles. The article has three Web extras. The first shows the Agile Compass questionnaire (https://s3.amazonaws.com/ieeecs.cdn.csdl.public/mags/so/2015/06/extras/mso201506_AnAgile_s1.pdf), which can help development teams identify which outcomes they have accomplished. The second describes the Agile Compass research approach (https://s3.amazonaws.com/ieeecs.cdn.csdl.public/mags/so/2015/06/extras/mso201506_AnAgile_s2.png). The third is the Map of Evidence (https://s3.amazonaws.com/ieeecs.cdn.csdl.public/mags/so/2015/06/extras/mso201506_AnAgile_s3.png), showing the information supporting each type of project outcome that the authors gathered during interviews with development teams.",1937-4194,,10.1109/MS.2015.135,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7311000,Agile Compass;agile software development;software process maturity;software development;software engineering,Agile software;Software development;Programming;Encoding;Software engineering;Context modeling,software development management;software prototyping,maturity identification;agile software-development teams;agile-development improvement;team values;team principles;Agile Compass research approach;map-of-evidence approach,,10.0,,4.0,,28 Oct 2015,,,IEEE,IEEE Magazines
285,286,Conflict-Centric Software Architectural Views: Exposing Trade-Offs in Quality Requirements,J. Savolainen; T. Mannisto,"Nokia Research Center, Finland; Aalto University",IEEE Software,14 Oct 2010,2010,27,6,33,37,"Architectural documentation improves the overall understanding of a proposed software system's design, but its true value comes from facilitating the process of satisfying architecturally significant requirements (ASRs). Architectural views are a tool for documenting ASRs in the context of particular quality attributes. Views offer a convenient way to capture architectural decisions, rationales, and alternatives considered. However, when multiple stakeholders have conflicting quality requirements, traditional architectural views tend to scatter their resolutions throughout the documentation.",1937-4194,,10.1109/MS.2010.139,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604360,software architecture;software engineering,Software architecture;Software engineering ;Quality;Investments,formal specification;formal verification;software architecture;software quality;system documentation,software architecture;software system;architecturally significant requirement;software quality;architectural decision;documentation,,5.0,,9.0,,14 Oct 2010,,,IEEE,IEEE Magazines
286,287,Creating the Virtual Universe,S. P. Zwart; J. Bedorf,Leiden Observatory; Leiden Observatory,IEEE Software,24 Aug 2016,2016,33,5,25,29,"Simulation software is important to our understanding of the universe. The intrinsic multiphysics aspects are spiced with a range of temporal scales and spatial scales, both of which cover more digits than are available in the standard hardware. This, together with the intrinsic chaotic nature of many physical processes, poses quite a challenge. To meet this challenge, researchers developed the Astronomical Multipurpose Environment (AMUSE). Instead of writing a suite of multiphysics solvers from scratch, AMUSE's developers coupled existing solvers for each physical ingredient. The result is a highly inhomogeneous collection of dedicated solvers with a homogeneous protocol that scales to supercomputers.",1937-4194,,10.1109/MS.2016.113,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548908,simulation software;Astronomical Multipurpose Environment;AMUSE;astrophysics;astrophysics simulations;software development;software engineering,Graphics processing units;Computational modeling;Software development;Astrophysics;Software engineering;Astronomy,astronomy computing;digital simulation,virtual universe;simulation software;astronomical multipurpose environment;AMUSE;multiphysics solver,,3.0,,9.0,,24 Aug 2016,,,IEEE,IEEE Magazines
287,288,Anarchy and Order [On Computing],G. Booch,IBM,IEEE Software,23 Apr 2015,2015,32,3,20,22,"Computing amplifies governments' actions but can also temper their behavior by enabling mechanisms for private communication and for open, transparent communication by a nation's people. Similarly, governments can help focus the artifacts of computing on their citizens' health and happiness, and temper it as well. The Web extra at http://youtu.be/GuFNqmvbkrE is an audio podcast of Grady Booch's On Computing column, in which he discusses how computing amplifies the actions of governments, but can also temper its behavior by enabling mechanisms for private communication as well as for open and transparent communication by the people of a nation. Similarly, governments can help focus the artifacts of computing to the health and happiness of its citizens, but temper it as well.",1937-4194,,10.1109/MS.2015.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093028,software engineering;computing;government;privacy;security,Software engineering;Network security;Government policies;Privacy;Digital audio broadcasting,government data processing;Web sites,government actions;private communication;open transparent communication;citizen happiness;citizen health;Web extra;audio podcast;government behavior,,,,,,23 Apr 2015,,,IEEE,IEEE Magazines
288,289,Toward Learning Teams,R. Hoda; J. Babb; J. Nørbjerg,University of Auckland; West Texas A&M University; Copenhagen Business School,IEEE Software,26 Jun 2013,2013,30,4,95,98,"Today's software development challenges require learning teams that can continuously apply new engineering and management practices, new and complex technical skills, cross-functional skills, and experiential lessons learned. The pressure of delivering working software often forces software teams to sacrifice learning-focused practices. Effective learning under pressure involves conscious efforts to implement original agile practices such as retrospectives and adapted strategies such as learning spikes. Teams, their management, and customers must all recognize the importance of creating learning teams as the key to braving the erratic climates and uncharted territories of future software development.",1937-4194,,10.1109/MS.2013.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547633,programming teams;software engineering process;agile processes;learning teams,Software development;Information systems;Software engineering;Training,learning (artificial intelligence);software prototyping;team working,learning teams;software development;engineering practice;management practice;complex technical skills;cross-functional skills;experiential lessons;software teams;learning-focused practice;agile practice;adapted strategy,,3.0,,9.0,,26 Jun 2013,,,IEEE,IEEE Magazines
289,290,What Do We Know about Test-Driven Development?,F. Shull; G. Melnik; B. Turhan; L. Layman; M. Diep; H. Erdogmus,University of Maryland; Microsoft; University of Oulu; University of Maryland; University of Nebraska-Lincoln; Kalemun Research,IEEE Software,14 Oct 2010,2010,27,6,16,19,"What if someone argued that one of your basic conceptions about how to develop software was misguided? What would it take to change your mind? That's essentially the dilemma faced by advocates of test-driven development (TDD). The TDD paradigm argues that the basic cycle of developing code and then testing it to make sure it does what it's supposed to do-something drilled into most of us from the time we began learning software development- isn't the most effective approach. TDD replaces the traditional ""code then test"" cycle. First, you develop test cases for a small increment of functionality; then you write code that makes those tests run correctly. After each increment, you refactor the code to maintain code quality.",1937-4194,,10.1109/MS.2010.152,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604358,software engineering,Software engineering;Testing,program testing;software maintenance;software quality,test driven development;code development;software development;code refactoring;code quality,,38.0,,3.0,,14 Oct 2010,,,IEEE,IEEE Magazines
290,291,Critical Decisions in Software Development: Updating the State of the Practice,M. A. Cusumano; A. MacCormack; C. F. Kemerer; W. Crandall,Massachusetts Institute of Technology; Massachusetts Institute of Technology; University of Pittsburgh; Hewlett-Packard,IEEE Software,25 Aug 2009,2009,26,5,84,87,"This article focuses on how to choose the ""right"" software development process, how to structure global software design chains, how to manage the interaction of project structure and software design, and how to balance innovation and efficiency in a software business.",1937-4194,,10.1109/MS.2009.124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222801,software development process;project management;software design;software business;software engineering,Uncertainty;Europe;Software prototyping;Software development management;Productivity;Radio access networks;Testing;Programming profession;Software engineering;Process design,software development management,critical decision;software development;global software design;software business,,15.0,,9.0,,25 Aug 2009,,,IEEE,IEEE Magazines
291,292,ADAPT: A Framework for Agile Distributed Software Development,R. Vallon; S. Strobl; M. Bernhart; R. Prikladnicki; T. Grechenig,TU Wien; TU Wien; TU Wien; Pontifical Catholic University of Rio Grande do Sul; TU Wien,IEEE Software,28 Oct 2016,2016,33,6,106,111,A growing number of developers are using agile practices in distributed software projects. Researchers have created the ADAPT (Agile Distributed Adaptable Process Toolkit) framework to guide the implementation of agile practices in distributed environments. The Web Extras detail the research methods the authors employed.,1937-4194,,10.1109/MS.2016.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725219,agile software development;distributed software development;ADAPT;Agile Distributed Adaptable Process Toolkit;software engineering;software development,Guidelines;Software development;Industries;Agile manufacturing;Outsourcing;Software engineering,software prototyping,ADAPT framework;agile distributed adaptable process toolkit;agile distributed software development;distributed environment;distributed software projects;agile practices,,1.0,,5.0,,28 Oct 2016,,,IEEE,IEEE Magazines
292,293,Software Crowdsourcing Platforms,A. L. Zanatta; L. S. Machado; G. B. Pereira; R. Prikladnicki; E. Carmel,"Pontifical Catholic University of Rio Grande do Sul; Pontifical Catholic University of Rio Grande do Sul; PROCERGS; Pontifical Catholic University of Rio Grande do Sul; American University, Washington, DC",IEEE Software,28 Oct 2016,2016,33,6,112,116,"Software crowdsourcing is mediated by platforms that connect requesters (buyers) with online workers--the crowd. Thus, these platforms have emerged as an important stakeholder in software development. This article introduces them and groups them by development phase.",1937-4194,,10.1109/MS.2016.151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725223,crowdsourcing;software development;software engineering;outsourcing;software development phases;Crowdtest,Software;Crowdsourcing;Testing;Computer bugs;Recruitment;Software engineering,,,,7.0,,5.0,,28 Oct 2016,,,IEEE,IEEE Magazines
293,294,"Listen, Then Use EARS",A. Mavin,Rolls-Royce,IEEE Software,20 Feb 2012,2012,29,2,17,18,"Applying the Easy Approach to Requirements Syntax (EARS) template can result in a simple, clear requirement. However, to be able to write a simple statement, you must first understand what you want the system to do, which might be difficult. The simplicity of the EARS templates prevents engineers from hiding behind ambiguous statements of what the system must do.",1937-4194,,10.1109/MS.2012.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155138,easy approach to requirements syntax;ears;template;requirements;software engineering;developers;development;notation;natural language,Software engineering;Software development;Natural language processing,computational linguistics;formal specification,EARS template;Easy Approach to Requirements Syntax;event-driven requirement,,13.0,,2.0,,20 Feb 2012,,,IEEE,IEEE Magazines
294,295,Architectural Refactoring: A Task-Centric View on Software Evolution,O. Zimmermann,"Institute for Software at the University of Applied Sciences of Eastern Switzerland, Rapperswil",IEEE Software,10 Mar 2015,2015,32,2,26,29,"A refactoring aims to improve a certain quality while preserving others. For example, code refactoring restructures code to make it more maintainable without changing its observable behavior. Given the success of code refactoring, it's surprising that architectural refactoring (AR) hasn't taken off yet. This article examines AR from a new angle: as an evolution technique that revisits architectural decisions and identifies related design, implementation, and documentation tasks.",1937-4194,,10.1109/MS.2015.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057560,refactoring;software evolution;software development;software engineering,Software development;Computer architecture;Context modeling;Software engineering;Catalogs;Pragmatics;Software architecture,program compilers;software architecture;software maintenance,architectural refactoring;task centric view;software evolution;code refactoring restructures code;observable behavior;code refactoring;AR;evolution technique,,15.0,,5.0,,10 Mar 2015,,,IEEE,IEEE Magazines
295,296,Aligning Architecture Work with Agile Teams,E. Woods,Endava,IEEE Software,21 Aug 2015,2015,32,5,24,26,"Difficulties frequently arise when agile development teams and software architects work together. By adopting practices aligned with the ""agile manifesto,"" software architects can work constructively with agile teams and significantly contribute to a project's success.",1937-4194,,10.1109/MS.2015.119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217769,software architecture;software engineering;software development;software design;agile teams,Tutorials;Computer architecture;Pragmatics;Agile software development;Software architecture;Documentation;Software engineering;Agile development;Software development,software architecture;software prototyping,agile development teams;software architects,,10.0,,5.0,,21 Aug 2015,,,IEEE,IEEE Magazines
296,297,Start-Ups Must Be Ready to Pivot,S. S. Bajwa; X. Wang; A. N. Duc; R. M. Chanin; R. Prikladnicki; L. B. Pompermaier; P. Abrahamsson,Free University of Bozen-Bolzano; Free University of Bozen-Bolzano; Norwegian University of Science and Technology; Pontifical Catholic University of Rio Grande do Sul; Pontifical Catholic University of Rio Grande do Sul; Pontifical Catholic University of Rio Grande do Sul; Norwegian University of Science and Technology,IEEE Software,15 May 2017,2017,34,3,18,22,"As prominent examples such as Twitter have demonstrated, software start-ups frequently find that their initial product ideas don't pan out commercially. So, they must be prepared to change direction in one or more ways, a process called pivoting.",1937-4194,,10.1109/MS.2017.84,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927923,start-up;software;pivot;pivot triggers;pivot types;Tecnopuc;software engineering;software development,Software engineering;Social network services;Twitter;Market opportunities,DP industry;innovation management;software houses,Twitter;software start-ups;initial product ideas;pivoting,,9.0,,7.0,,15 May 2017,,,IEEE,IEEE Magazines
297,298,Replicating Rare Software Failures with Exploratory Visual GUI Testing,E. Alégroth; J. Gustafsson; H. Ivarsson; R. Feldt,Chalmers University of Technology; Saab AB; Saab AB; Blekinge Institute of Technology,IEEE Software,22 Sep 2017,2017,34,5,53,59,"Saab AB developed software that had a defect that manifested itself only after months of continuous system use. After years of customer failure reports, the defect still persisted, until Saab developed failure replication based on visual GUI testing.",1937-4194,,10.1109/MS.2017.3571568,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048660,visual GUI testing;failure replication;industrial success story;semiautomated testing;industry–academia collaboration;software engineering;software development;software testing;Saab AB,Graphical user interfaces;Failure analysis;Companies;Software engineering;Visualization;Memory management,graphical user interfaces;program testing;software fault tolerance,software failure replication;visual GUI testing;Saab AB developed software,,,,14.0,,22 Sep 2017,,,IEEE,IEEE Magazines
298,299,Beyond Data Mining,T. Menzies,West Virginia University,IEEE Software,18 Apr 2013,2013,30,3,92,92,"Last century, it wasn't known if data miners could find structure within software projects. This century, we know better: data mining has been successfully applied to many different artifacts from software projects. So it's time to move on to ""What's next?"" In the author's view, ""discussion mining"" is the next great challenge for the predictive modeling community. These discussion miners know that while predictions and decisions are important, so too are the questions and insights generated on the way to those conclusions.",1937-4194,,10.1109/MS.2013.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6504887,data mining;software engineering;predictive modeling,Data mining;Software engineering;Predictive modeling,,,,2.0,,5.0,,18 Apr 2013,,,IEEE,IEEE Magazines
299,300,Naming the Pain in Requirements Engineering: Comparing Practices in Brazil and Germany,D. M. Fernández; S. Wagner; M. Kalinowski; A. Schekelmann; A. Tuzcu; T. Conte; R. Spinola; R. Prikladnicki,Technische Universität München; University of Stuttgart; Fluminense Federal University; Niederrhein University of Applied Sciences; zeb.rolfes.schierenbeck.associates; Federal University of Amazonas; Federal University of Bahia; Pontifical Catholic University of Rio Grande of the South,IEEE Software,21 Aug 2015,2015,32,5,16,23,"As part of the Naming the Pain in Requirements Engineering (NaPiRE) initiative, researchers compared problems that companies in Brazil and Germany encountered during requirements engineering (RE). The key takeaway was that in RE, human interaction is necessary for eliciting and specifying high-quality requirements, regardless of country, project type, or company size.",1937-4194,,10.1109/MS.2015.122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217775,requirements engineering;NaPiRE;software development;software engineering;cause and effect analysis,Requirements engineering;Software engineering;Product development;Collaboration,formal verification,Brazil;Germany;naming the pain in requirements engineering;NaPiRE;human interaction,,20.0,,7.0,,21 Aug 2015,,,IEEE,IEEE Magazines
300,301,"First, Do No Harm",D. Spinellis,Athens University of Economics and Business,IEEE Software,15 Sep 2014,2014,31,5,12,14,"When we maintain existing code, we must be very careful to avoid breaking or degrading the system we're working on. During development, we can minimize problems through reviews, adherence to style rules, defensive programming, maintenance of backward compatibility, and the preservation of architectural properties. Thorough testing at all levels can catch many issues before they reach the deployment stage. Finally, during deployment, a phased rollout, a back-off plan, and careful planning can minimize the occurrence of catastrophic failures. The Web extra at http://youtu.be/pifgzfFXanE is an audio podcast of the Tools of the Trade column in which author Diomidis Spinellis discusses how we must be very careful to avoid breaking or degrading the system while working to maintain existing code.",1937-4194,,10.1109/MS.2014.112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898723,maintenance;defensive programming;testing;deployment;operations;reviews;software engineering,Software engineering;Software testing;Codes;Computer applicaitons;Programming,software architecture;software maintenance,code maintenance;code development;defensive programming;backward compatibility;code architectural properties,,,,,,15 Sep 2014,,,IEEE,IEEE Magazines
301,302,Assertive Testing [Reliable Code],G. J. Holzmann,NASA/JPL,IEEE Software,23 Apr 2015,2015,32,3,12,15,"Standard software testing might not catch important defects, and formal methods can be difficult to use. But, there's a middle ground between the two. This middle ground involves adding five steps to standard testing and employing test randomization, model-based testing, and a more aggressive use of assertions (also called self-tests).",1937-4194,,10.1109/MS.2015.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093042,software testing;model-based testing;software defects;software reliability;software failures;assertion density;software engineering;software development,Failure analysis;Software reliability;Software testing;Software engineering;Software measurement;Software development,program testing,assertive testing;standard software testing;formal methods;test randomization;model-based testing,,1.0,,5.0,,23 Apr 2015,,,IEEE,IEEE Magazines
302,303,What Do We Know about Software Development in Startups?,C. Giardino; M. Unterkalmsteiner; N. Paternoster; T. Gorschek; P. Abrahamsson,NA; NA; NA; NA; NA,IEEE Software,15 Sep 2014,2014,31,5,28,32,"An impressive number of new startups are launched every day as a result of growing new markets, accessible technologies, and venture capital. New ventures such as Facebook, Supercell, Linkedin, Spotify, WhatsApp, and Dropbox, to name a few, are good examples of startups that evolved into successful businesses. However, despite many successful stories, the great majority of them fail prematurely. Operating in a chaotic and rapidly evolving domain conveys new uncharted challenges for startuppers. In this study, the authors characterize their context and identify common software development startup practices.",1937-4194,,10.1109/MS.2014.129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898758,startups;software development;systematic mapping study;software engineering,Software development;Companies;Software engineering;Market research;Commercialization,software development management,Facebook;Supercell;Linkedin;Spotify;WhatsApp;Dropbox;software development startup practices,,47.0,,15.0,,15 Sep 2014,,,IEEE,IEEE Magazines
303,304,To Pay or Not to Pay Technical Debt,F. Buschmann,,IEEE Software,20 Oct 2011,2011,28,6,29,31,"Ward Cunningham coined the term technical debt as a metaphor for the trade-off between writing clean code at higher cost and delayed de livery, and writing messy code cheap and fast at the cost of higher maintenance efforts once it's shipped. Joshua Kerievsky extended the metaphor to architecture and design. Technical debt is similar to financial debt: it supports quick development at the cost of compound interest to be paid later. The longer we wait to garden our design and code, the larger the amount of interest. Discussions of the metaphor have distinguished different types of technical debt and how and when to best pay them off. Most agree that, sooner or later, technical debt will come due. But is this assumption universally true? If it's better to pay interest, what factors influence the decision to service the debt? And if we decide to retire it, what approach should we take?",1937-4194,,10.1109/MS.2011.150,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6055661,technical debt;software;software engineering;architecture,Software engineering;Software architecture;System analysis and design;Encoding;Business,program compilers;software development management;software maintenance,technical debt;clean code;messy code;maintenance efforts,,18.0,,9.0,,20 Oct 2011,,,IEEE,IEEE Magazines
304,305,Fifteen Years of Service-Oriented Architecture at Credit Suisse,S. Murer; C. Hagen,NA; NA,IEEE Software,7 Nov 2014,2014,31,6,9,15,"Credit Suisse has been an adopter of service oriented architecture (SOA) principles and patterns since the beginnings of this architectural style, even before the term appeared. The authors reflect on the financial institution's journey from using tightly integrated mainframe programs to open SOA services, emphasizing the importance of interface contracts and service governance in corporate IT.",1937-4194,,10.1109/MS.2013.137,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654116,service-oriented architecture;SOA;Credit Suisse;software engineering;interface contracts;service governance;corporate IT,Computer architecture;Service-oriented architecture;Banks;Documentation;Quality assurance;Software engineering;Business;Information technology,service-oriented architecture,service-oriented architecture;Credit Suisse;SOA principles;SOA patterns;SOA services;service governance;interface contracts;corporate IT;information technology,,7.0,,6.0,,4 Nov 2013,,,IEEE,IEEE Magazines
305,306,What Type of People Are Software Architects?,M. Erder; P. Pureur,NA; NA,IEEE Software,11 Jul 2017,2017,34,4,20,22,"Psychometrics measures mental traits, abilities, and processes. This article presents popular industry approaches to psychometric testing and how to apply them to the role of the software architect.",1937-4194,,10.1109/MS.2017.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974721,psychometrics;personality testing;software architect;Myers-Briggs Type Indicator;MBTI;Herrmann Brain Dominance Instrument;HBDI;Belbin Team Roles;software architecture;software engineering;software development,Computer architecture;Software engineering;Sociology;Statistics;Pragmatics;Psychology;Monitoring,psychometric testing;software architecture,software architect;psychometric testing,,1.0,,7.0,,11 Jul 2017,,,IEEE,IEEE Magazines
306,307,Injecting Value-Thinking into Prioritization Decisions,J. Cleland-Huang,DePaul University,IEEE Software,10 Mar 2015,2015,32,2,14,18,"A proposed approach injects value-thinking into feature prioritization, using story mapping. The Web extra at http://youtu.be/Xm5VqODvVZE is an audio podcast in which author Jane Cleland-Huang provides an audio recording of the Requirements column, in which she discusses an approach that injects value-thinking into feature prioritization by using story mapping.",1937-4194,,10.1109/MS.2015.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057568,value-thinking;feature prioritization;story mapping;release planning;minimum marketable features;minimum viable product;incremental funding;return on investment;ROI;software engineering,Software engineering;Planning;Investments;Marketing and sales;Funding;Schedules,decision making;formal specification;formal verification,value-thinking injection;prioritization decision;feature prioritization;story mapping;requirements column,,3.0,,3.0,,10 Mar 2015,,,IEEE,IEEE Magazines
307,308,Industry Trends 2017,C. Ebert; K. Shankar,Vector Consulting Services; Microsoft,IEEE Software,28 Mar 2017,2017,34,2,112,116,"A survey of software industry professionals revealed trends involving efficiency and cost, security and safety, innovation, the digital transformation, connectivity, and governance and compliance. On the basis of the survey and personal experience in the industry, researchers have developed recommendations on how software development organizations can deal with these trends.",1937-4194,,10.1109/MS.2017.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888415,software industry;efficiency;cost;security;privacy;innovation;connectivity;governance;compliance;quality;software development;software engineering,Software development;Technological innovation;Performance evaluation;Market research;Computer security;Safety;Software engineering,,,,7.0,,2.0,,28 Mar 2017,,,IEEE,IEEE Magazines
308,309,The Inhibited Analyst,N. Maiden,,IEEE Software,20 Oct 2011,2011,28,6,100,102,Requirements analysts need to ask the right questions repeatedly. They need to be more inquisitive and know why people want things as well as what happens beforehand. This requires them to become less inhibited and keep asking questions until they and their stakeholders are satisfied with the answers.,1937-4194,,10.1109/MS.2011.149,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6055667,software;software engineering;requirements;engineer;analysis;analyst;stakeholders;social modeling;modelling;questions,Information analysis;Knowledge acquisition;Software engineering;Modeling;Social factors;Query processing,,,,1.0,,2.0,,20 Oct 2011,,,IEEE,IEEE Magazines
309,310,Managing Technical Debt: Insights from Recent Empirical Evidence,N. Ramasubbu; C. F. Kemerer; C. J. Woodard,University of Pittsburgh; University of Pittsburgh; Singapore Management University,IEEE Software,10 Mar 2015,2015,32,2,22,25,"Technical debt refers to maintenance obligations that software teams accumulate as a result of their actions. Empirical research has led researchers to suggest three dimensions along which software development teams should map their technical-debt metrics: customer satisfaction needs, reliability needs, and the probability of technology disruption.",1937-4194,,10.1109/MS.2015.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057576,technical debt;software development;software maintenance;disruptive technology;reliability;customer satisfaction;software engineering,Software development;Software reliability;Software engineering;Customer satisfaction;Software measurement,customer satisfaction;software development management;software metrics;software reliability,empirical evidence;maintenance obligations;software development teams;technical-debt metrics;customer satisfaction needs;reliability needs;technology disruption,,6.0,,5.0,,10 Mar 2015,,,IEEE,IEEE Magazines
310,311,The Risk of Overly Strict Requirements,R. Lutz; J. Cleland-Huang,Iowa State University; University of Notre Dame,IEEE Software,28 Mar 2017,2017,34,2,26,29,"Overly strict requirements can lead to more work, more dependencies, and more code, all of which place extra pressure on software development project schedules and budgets. Identifying such requirements and considering viable alternatives can reduce needless design complexity and project risk. The Web Extra https://youtu.be/SMdU78gPP1Q is an audio podcast of the Requirements article ""The Risk of Overly Strict Requirements"".",1937-4194,,10.1109/MS.2017.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888423,software requirements;fit criteria;GRAIL;software engineering;software development,Space vehicles;Software development;NASA;Complexity theory;Stakeholders;Safety;Software engineering,formal specification;formal verification;project management;software development management,overly strict requirements risk;software development project schedules;software development project budgets;design complexity;project risk,,1.0,,9.0,,28 Mar 2017,,,IEEE,IEEE Magazines
311,312,A Tail-Tolerant Cloud API Wrapper,Q. Lu; X. Xu; L. Bass; L. Zhu; W. Zhang,"China University of Petroleum, Qingdao, China; NICTA; NICTA; NICTA; China University of Petroleum, Qingdao, China",IEEE Software,4 Feb 2015,2015,32,1,76,82,"System operations (such as deployment, upgrade, and reconfiguration) for cloud applications are failure prone. These failures occur because these operations are performed through cloud APIs provided by cloud providers and because cloud APIs, in turn, are failure prone. Researchers have explored the characteristics of cloud APIs using Amazon EC2 (Elastic Compute Cloud) as a testbed and have devised mechanisms to improve cloud API performance. Specifically, mining the Amazon EC2 discussion forum revealed that 45 percent of complaints referred to cloud API timing failures. A series of experiments on cloud API timing behavior showed that cloud APIs have a long-tail distribution. A proposed cloud API wrapper implements mechanisms to avoid long tails. In experiments, this wrapper largely removed long tails, compared with the unwrapped APIs.",1937-4194,,10.1109/MS.2015.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030263,cloud computing;API;fault tolerance;long tail;dependability;software engineering,Fault tolerance;Cloud computing;Software engineering;Systems engineering and theory,application program interfaces;cloud computing;data mining,tail-tolerant cloud API wrapper;system operations;cloud applications;Amazon EC2;Elastic Compute Cloud;Amazon EC2 discussion forum mining;cloud API timing failures;cloud API timing behavior;long-tail distribution,,1.0,,9.0,,4 Feb 2015,,,IEEE,IEEE Magazines
312,313,Supporting the Management of Reusable Automotive Software,X. Larrucea; A. Walker; R. Colomo-Palacios,Tecnalia; Lorit Consultancy; Østfold University College,IEEE Software,15 May 2017,2017,34,3,40,47,"Improvements in the automotive industry are introducing challenges related to management, software development, and safety requirements. The safety requirements involve both products and processes, the latter requirements stemming from regulations and standards such as ISO 26262. The OpenCert toolkit helps engineers define safety cases, manage evidence, and comply with ISO 26262. The development of a Safety Element out of Context (SEooC) based on a Hall-effect sensor illustrates this tool's use. SEooCs are reusable and are particularly demanding regarding process requirements and the associated information. This article is part of a theme issue on Automotive Software.",1937-4194,,10.1109/MS.2017.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927906,ISO 26262;compliance;OpenCert;Hall-effect sensors;Hall sensors;Safety Element out of Context;SEooC;automotive software;safety-critical software;software engineering;software development,ISO Standards;Safety;Software engineering;Automotive engineering;Context modeling;Magnetic domains,automobile industry;automotive engineering;Hall effect transducers;ISO standards;software management;software reusability,reusable automotive software management;automotive industry;safety requirements;software development;ISO 26262 standard;OpenCert toolkit;safety element out-of-context;SEooC;Hall-effect sensor,,13.0,,14.0,,15 May 2017,,,IEEE,IEEE Magazines
313,314,Brace Yourself,G. J. Holzmann,Jet Propulsion Laboratory,IEEE Software,24 Aug 2016,2016,33,5,34,37,"The author states that to reduce the risk of hard-to-spot coding mistakes, you can do one simple thing: correctly use parentheses.",1937-4194,,10.1109/MS.2016.123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548903,C code;C operators;software verification;precedence rules;operator precedence;programming;software development;software engineering,Software reliability;Software algorithms;Software engineering;Encoding;Software verification;Operator precendence,programming,programming;coding mistakes,,2.0,,4.0,,24 Aug 2016,,,IEEE,IEEE Magazines
314,315,Dataflow Modeling with Crosscutting Concerns and a Concept Lattice,Y. Chernak,Valley Forge Consulting,IEEE Software,7 Nov 2014,2014,31,6,70,78,Applying the concept of crosscutting concerns to dataflow modeling can help software practitioners better deal with the complexity of business applications and produce more complete and compact dataflow diagrams in the form of a concept lattice.,1937-4194,,10.1109/MS.2014.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728935,aspect-oriented analysis;crosscutting concerns;data flow;requirements composition table;change impact analysis;ripple effect;formal concept analysis;concept lattice;software engineering,Data models;Software development;Software engineering;Formal concept analysis,data flow analysis,dataflow modeling;crosscutting concerns;concept lattice;business applications;dataflow diagrams,,,,13.0,,30 Jan 2014,,,IEEE,IEEE Magazines
315,316,Machine Learning,P. Louridas; C. Ebert,Athens University of Economics and Business; Vector Consulting Services,IEEE Software,24 Aug 2016,2016,33,5,110,115,"In machine learning, a computer first learns to perform a task by studying a training set of examples. The computer then performs the same task with data it hasn't encountered before. This article presents a brief overview of machine-learning technologies, with a concrete case study from code analysis.",1937-4194,,10.1109/MS.2016.114,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548905,machine learning;supervised learning;unsupervised learning;classification;regression;clustering;dimensionality reduction;R;Python;Hadoop;Spark;H2O;Julia;Matlab;SAS;TensorFlow;artificial neural networks;ANNs;deep learning;software development;software engineering;software technology,Machine learning;Software engineering;Classification;Complexity theory;Neural networks;Artificial neural networks;Clustering;Supervised learning,learning (artificial intelligence),machine learning;code analysis,,73.0,1.0,4.0,,24 Aug 2016,,,IEEE,IEEE Magazines
316,317,Evaluating Software Project Managers: A Multidimensional Perspective,L. Peters; A. M. Moreno,Universidad Politécnica de Madrid; Universidad Politécnica de Madrid,IEEE Software,13 Nov 2017,2017,34,6,104,108,"Qualified, motivated project managers are key contributors to software organizations. Experts have identified a capable project manager as the most important factor in a software project's success. Project managers' value to software projects, software engineers, and their companies is unquestionable. Thus, getting the most out of those managers is critical. The literature about knowledge workers' psychological profiles show that the best motivator is feedback about how well they've done. This is consistent with our experience in software project management and consulting. Frequent, detailed feedback can also be a positive learning experience and an opportunity to improve skills. Feedback and recognition require the evaluation of professionals, who must accept responsibility for their work if they're going to consider assessments as an opportunity instead of a burden. However, the criteria needed to evaluate professionals aren't obvious. Unfortunately, the literature provides little empirical data about evaluating software project managers. At best, the literature refers to assessing managers in terms of whether a project meets or exceeds its time and cost requirements. Our combined 50 years' experience in software project management (see the “Our Experience in Software Project Management” sidebar) has revealed some best practices for evaluating software project managers.",1937-4194,,10.1109/MS.2017.4121223,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106867,software project managers;evaluations;multidimensional;senior managers;software engineers;clients;balanced scorecard;software engineering;software development;Voice of Evidence,Software engineering;Project management;Stakeholders;Appraisal,DP industry;human factors;project management;software development management,software project manager evaluation;software organizations;software engineers;software project management;software project consulting;best practices;knowledge workers psychological profiles,,2.0,,12.0,,13 Nov 2017,,,IEEE,IEEE Magazines
317,318,Adaptable Blockchain-Based Systems: A Case Study for Product Traceability,Q. Lu; X. Xu,China University of Petroleum; Commonwealth Scientific and Industrial Research Organisation (CSIRO),IEEE Software,13 Nov 2017,2017,34,6,21,27,"Tracing the origin of products across complex supply chains requires a transparent, tamper-proof metadata infrastructure that's not only trusted by all the involved parties but also adaptable to changing environments and regulations. Can such advanced infrastructure be implemented in a decentralized way? Qinghua Lu and Xiwei Xu share their story of developing the originChain system, which leverages emerging blockchain technology to do so.",1937-4194,,10.1109/MS.2017.4121227,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106871,blockchain;traceability;supply chain;originChain;software development;software engineering;Insights,Tracking;Production facilities;Supply chains;Databases;Software engineering;Memory management,meta data;supply chains,complex supply chains;advanced infrastructure;blockchain technology;originChain system;transparent infrastructure;tamper-proof metadata infrastructure;product traceability;adaptable blockchain-based systems,,58.0,,9.0,,13 Nov 2017,,,IEEE,IEEE Magazines
318,319,What's the Evidence for Lean?,T. Dybå; H. Sharp,SINTEF; Open University,IEEE Software,21 Aug 2012,2012,29,5,19,21,A close look at the evidence underpinning the original concept of lean production and its popular interpretation reveals the inherent challenges of measuring and interpreting evidence for performance differences.,1937-4194,,10.1109/MS.2012.126,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6276295,software engineering methodologies,Software engineering;Performance evaluation,lean production;production engineering computing;software performance evaluation,lean production;performance differences;evidence interpretation,,3.0,,5.0,,21 Aug 2012,,,IEEE,IEEE Magazines
319,320,Unintentional and Unbalanced Transparency,G. Booch,IBM,IEEE Software,18 Aug 2011,2011,28,5,12,13,"Security and privacy are interdependent concepts. Each impacts the other, but to say that they are alternatives is a false dichotomy. Both are issues of human concern; their policies and their risks may be made manifest in software-intensive systems. Architecting a system that attends to the needs of security and privacy is possible and desirable, yet there are often unintended and unexpected consequences in so doing.",1937-4194,,10.1109/MS.2011.112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984789,architecture;software-intensive system;security;privacy;software engineering;standards and best practices,Privacy;Computer security;Computer architecture;Best practices;Surveillance;Software engineering,data privacy;security of data;software architecture,software-intensive systems;data security;data privacy,,1.0,,,,18 Aug 2011,,,IEEE,IEEE Magazines
320,321,Software Project Management: Learning from Our Mistakes [Voice of Evidence],P. Silva; A. M. Moreno; L. Peters,Universidad Politécnica de Madrid; Universidad Politécnica de Madrid; Universidad Politécnica de Madrid,IEEE Software,23 Apr 2015,2015,32,3,40,43,Software project management antipatterns can help practitioners identify and avoid practices that will hinder success. This article provides a consolidated list of such antipatterns and discusses their implications.,1937-4194,,10.1109/MS.2015.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093031,software project management;antipatterns;software development;software engineering,Software development;Project management;pattern recognition;Process control;Software engineering,project management;software management,software project management antipatterns;consolidated list,,7.0,,12.0,,23 Apr 2015,,,IEEE,IEEE Magazines
321,322,Reference Architectures for the Internet of Things,M. Weyrich; C. Ebert,University of Stuttgart; Vector Consulting Services,IEEE Software,29 Dec 2015,2016,33,1,112,116,The Internet of Things (IoT) is about innovative functionality and better productivity by seamlessly connecting devices. But a major threat is the lack of architecture standards for the industrial Internet and connectivity in the IoT. This article reviews recent IoT architecture evolution and what it means for industry projects.,1937-4194,,10.1109/MS.2016.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367994,Internet of Things;IoT;Internet of Things--Architecture;IoT-A;Industrial Internet Reference Architecture;IIRA;reference architecture;software engineering;software development,Computer architecture;Software engineering;Industries;Internet of things;Standards;Protocols,Internet;Internet of Things,reference architectures;Internet of Things;architecture standards;industrial Internet;IoT connectivity;IoT architecture evolution,,179.0,,4.0,,29 Dec 2015,,,IEEE,IEEE Magazines
322,323,To Code Is Human,G. J. Holzmann,NASA/JPL,IEEE Software,4 Feb 2015,2015,32,1,14,17,"Programmers have found creative ways around programming rules. However, such tactics have a cost.",1937-4194,,10.1109/MS.2015.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030198,computer programming;programming errors;compilers;software engineering,Encoding;Software reliability;Computer programs;Software engineering;Reliability engineering;program processors,programming,programmer;programming rules,,,,4.0,,4 Feb 2015,,,IEEE,IEEE Magazines
323,324,"What's the Architect's Role in an Agile, Cloud-Centric World?",M. Erder; P. Pureur,NA; NA,IEEE Software,24 Aug 2016,2016,33,5,30,33,"The software architecture pendulum is swinging away from traditional practices and toward agile and continuous practices. To be successful in this new world, architects should emphasize products over projects, drive architectural decisions, understand code, and communicate and collaborate effectively with delivery teams.",1937-4194,,10.1109/MS.2016.119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548909,software architect;agile;cloud;software engineering;software development,Computer architecture;Software engineering;Microarchitecture;Pragmatics;Stakeholders,software architecture;software prototyping,agile cloud-centric world;software architecture;agile architecture;architectural decisions;continuous architecture,,7.0,,4.0,,24 Aug 2016,,,IEEE,IEEE Magazines
324,325,Techniques and Tools for Parallelizing Software,H. Vandierendonck; T. Mens,"Research Foundation Flanders; University of Mons, Belgium",IEEE Software,20 Feb 2012,2012,29,2,22,25,"With the emergence of multicore and manycore processors, engineers must design and develop software in drastically new ways to benefit from the computational power of all cores. However, developing parallel software is much harder than sequential software because parallelism can't be abstracted away easily. Authors Hans Vandierendonck and Tom Mens provide an overview of technologies and tools to support developers in this complex and error-prone task.",1937-4194,,10.1109/MS.2012.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155141,multicore;manycore;parallelization;parallelism;debugging;programming;software engineering;software;hardware,Multicore processing;Software engineering;Software development,multiprocessing systems;parallel programming;software tools,parallelizing software;multicore processors;manycore processors;core computational power;sequential software;support tools,,4.0,,8.0,,20 Feb 2012,,,IEEE,IEEE Magazines
325,326,Managing Software's Impact,M. van Genuchten; L. Hatton,VitalHealth Software; Oakwood Computing Associates,IEEE Software,30 Jun 2015,2015,32,4,15,17,"As a review of past articles in IEEE Software's Impact department shows, software economics largely determines a software product's success, and volume plays a key role.",1937-4194,,10.1109/MS.2015.99,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140700,software development;software engineering;software economics;software size;software mileage,Software maintenance;Economics;Software development;Software quality;Software engineering,,,,,,15.0,,30 Jun 2015,,,IEEE,IEEE Magazines
326,327,Fault Intolerance [Reliable Code],G. J. Holzmann,NASA/JPL,IEEE Software,7 Nov 2014,2014,31,6,16,20,"The author considers what it takes to develop truly reliable software systems, and what the role is of program verification in all this. One problem he focuses on is the difficulty of writing good specifications, particularly in making sure that those specifications are complete. Reality can be surprisingly good in showing that our painfully constructed software design requirements are incomplete or even incorrect.",1937-4194,,10.1109/MS.2014.136,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949563,software verification;reliable software systems;software specification;requirements;software engineering,Software engineering;Documentation;Software reliability;Fault tolerance;Encoding;Programming;Software reliability,formal specification;program verification;software fault tolerance;software reliability,fault intolerance;reliable software systems;program verification;software design requirements;specifications,,3.0,,3.0,,7 Nov 2014,,,IEEE,IEEE Magazines
327,328,Peter Hilton on Naming,F. Hermans,Delft University of Technology,IEEE Software,15 May 2017,2017,34,3,117,120,"Host Felienne Hermans talks with Peter Hilton about why naming is much harder than we think, why it matters in programming and program comprehension, and how to improve your naming skills.",1937-4194,,10.1109/MS.2017.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927922,Peter Hilton;software engineering;naming;software naming;SE Radio;software development;coding,Software engineering;Programming;Computer bugs;Software testing,,,,,,,,15 May 2017,,,IEEE,IEEE Magazines
328,329,Service Orientation and Systems of Systems,G. Lewis; E. Morris; S. Simanta; D. Smith,Software Engineering Institute; Software Engineering Institute; Software Engineering Institute; Software Engineering Institute,IEEE Software,20 Dec 2010,2011,28,1,58,63,"Interconnected systems of systems provide capabilities that aren't available in any single system. Fundamental service-oriented principles can help in engineering them, regardless of the implementation technologies used.",1937-4194,,10.1109/MS.2011.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672519,SOA;service-oriented architecture;service orientation;systems of systems;SoS;SoS engineering,Service oriented architecture;Interconnected systems;Couplings;Runtime;Systems engineering and theory;Standards,interconnected systems;service-oriented architecture,service orientation;interconnected systems of systems;service-oriented principles;service- oriented architecture;SOA,,20.0,,11.0,,20 Dec 2010,,,IEEE,IEEE Magazines
329,330,Design Patterns: Magic or Myth?,D. Budgen,Durham University,IEEE Software,25 Feb 2013,2013,30,2,87,90,"A mapping study of design pattern literature combined with two follow-on surveys shows only limited empirical evidence that the ""Gang of Four"" patterns provide a useful way of transferring design knowledge or that their use will lead to better designs.",1937-4194,,10.1109/MS.2013.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6470594,software design;software design patterns;research,Software design;Production facilities;Maintenance engineering;Design methodology;Pattern recognition;Research and development,software engineering,magic;myth;mapping study;design pattern literature;gang of four patterns;transferring design knowledge;software engineering,,2.0,,8.0,,25 Feb 2013,,,IEEE,IEEE Magazines
330,331,The highways and country roads to continuous deployment,M. Leppänen; S. Mäkinen; M. Pagels; V. Eloranta; J. Itkonen; M. V. Mäntylä; T. Männistö,Tampere University of Technology; University of Helsinki; University of Helsinki; Tampere University of Technology; Aalto University; Aalto University; University of Helsinki,IEEE Software,10 Mar 2015,2015,32,2,64,72,"As part of a Finnish research program, researchers interviewed 15 information and communications technology companies to determine the extent to which the companies adopted continuous deployment. They also aimed to find out why continuous deployment is considered beneficial and what the obstacles are to its full adoption. The benefits mentioned the most often were the ability to get faster feedback, the ability to deploy more often to keep customers satisfied, and improved quality and productivity. Despite understanding the benefits, none of the companies adopted a fully automatic deployment pipeline. The companies also had higher continuous-deployment capability than what they practiced. In many cases, they consciously chose to not aim for full continuous deployment. Obstacles to full adoption included domain-imposed restrictions, resistance to change, customer desires, and developers' skill and confidence.",1937-4194,,10.1109/MS.2015.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057604,continuous deployment;software development;software engineering;thematic analysis;continuous delivery;continuous integration,Continuous production;Software engineering;Production;Software development;Software engineering;Testing,customer satisfaction;management of change;software development management,Finnish research program;information and communications technology companies;customer satisfaction;fully automatic deployment pipeline;continuous-deployment capability;domain-imposed restrictions;customer desires;developers skill;developers confidence;change resistance,,47.0,,9.0,,10 Mar 2015,,,IEEE,IEEE Magazines
331,332,To Boldly Go Where No One Has Gone Before,F. Buschmann,Siemens Corporate Technology,IEEE Software,22 Dec 2011,2012,29,1,23,25,"Architecture mastery is more than professional expertise in modern software engineering methods and techniques. It is mainly in how architects approach design. Particularly, the ""things between things"" require the architect's full attention: domain concepts hidden between the lines of code; interactions and interfaces residing between components; and even choices between design options. This is the architect's territory, and successful architecture uncovers the things ""in-between"" as early as possible, make them explicit, and decide about them!",1937-4194,,10.1109/MS.2012.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111363,architecture;domain-driven design;interface design;interaction design;integration design,Software architecture;Software design;Software engineering;Product development,software architecture,software architecture;software engineering method,,2.0,,10.0,,22 Dec 2011,,,IEEE,IEEE Magazines
332,333,The Human Factor,J. C. Carver; B. Penzenstadler; A. Serebrenik; A. Yamashita,"University of Alabama; California State University, Long Beach; Eindhoven University of Technology; Oslo and Akershus University",IEEE Software,22 Sep 2017,2017,34,5,90,92,"This installment reports on five papers from the 39th International Conference on Software Engineering and its collocated events. These papers focus on human factors in software engineering, with the last three dealing with open source software.",1937-4194,,10.1109/MS.2017.3571580,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048655,brainstorming;inclusiveness;privacy;privacy requirements;code review;open source licenses;Docker;GitHub;39th International Conference on Software Engineering;ICSE;software development;software engineering,,,,,,,,,22 Sep 2017,,,IEEE,IEEE Magazines
333,334,Adaptation of Service Protocols Using Process Algebra and On-the-Fly Reduction Techniques,R. Mateescu; P. Poizat; G. Salaün,"Inria Grenoble-Rhône-Alpes/CONVECS, Montbonnot Saint-Martin; Université d'Evry Val d'Essonne, Paris and LRI UMR CNRS, Université Paris Sud, Orsay; Grenoble INP and Inria Grenoble-Rhône-Alpes/CONVECS, Montbonnot Saint-Martin",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,755,777,"Reuse and composition are increasingly advocated and put into practice in modern software engineering. However, the software entities that are to be reused to build an application, e.g., services, have seldom been developed to integrate and to cope with the application requirements. As a consequence, they present mismatch, which directly hampers their reusability and the possibility of composing them. Software Adaptation has become a hot topic as a nonintrusive solution to work mismatch out using corrective pieces named adaptors. However, adaptation is a complex issue, especially when behavioral interfaces, or conversations, are taken into account. In this paper, we present state-of-the-art techniques to generate adaptors given the description of reused entities' conversations and an abstract specification of the way mismatch can be solved. We use a process algebra to encode the adaptation problem, and propose on-the-fly exploration and reduction techniques to compute adaptor protocols. Our approach follows the model-driven engineering paradigm, applied to service-oriented computing as a representative field of composition-based software engineering. We take service description languages as inputs of the adaptation process and we implement adaptors as centralized service compositions, i.e., orchestrations. Our approach is completely tool supported.",1939-3520,,10.1109/TSE.2011.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928357,Service composition;software adaptation;interfaces;protocols;mismatch;adaptation contracts;process algebra;on--the-fly generation;verification;tools,Adaptation model;Protocols;Contracts;Algebra;Semantics;Encoding;Computational modeling,formal specification;process algebra;protocols;service-oriented architecture;software reusability;specification languages,service protocol adaptation;process algebra;on-the-fly reduction techniques;composition;software entities;reusability;software adaptation;adaptors;reused entity conversations;abstract specification;on-the-fly exploration;model-driven engineering paradigm;service-oriented computing;composition-based software engineering;service description languages;centralized service compositions,,35.0,,65.0,,23 Jun 2011,,,IEEE,IEEE Journals
334,335,Leveraging the Power of the Crowd for Software Testing,N. Leicht; I. Blohm; J. M. Leimeister,University of St. Gallen; University of St. Gallen; University of St. Gallen,IEEE Software,28 Mar 2017,2017,34,2,62,69,"The rapid development of new IT-enabled business models, a fast-growing hardware market, and that market's segmentation are making software testing more complex. So, manual testing is becoming less applicable--economically and practicably. One approach to overcome these issues is crowdtesting--using crowdsourcing to perform testing. To profit from crowdtesting, companies can use three approaches: engage an external crowd of Internet users, engage their employees, or engage their customers. Three case studies illustrate these approaches' differences, benefits, and challenges, and the potential solutions to those challenges. Researchers' experiences with these approaches have led to guidelines that can help software development executives establish crowdtesting in their organizations. The Web Extra at extras.computer.org/extra/mso2017020062s1.pdf describes the procedure for the case studies. This article is part of a special issue on Crowdsourcing for Software Engineering.",1937-4194,,10.1109/MS.2017.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888424,software engineering;software testing;crowdsourcing;debugging;testing strategies;distributed testing;crowdtesting;software development,Companies;Information technology;Computer bugs;Software testing;Crowdsourcing;Hardware,crowdsourcing;Internet;personnel;program testing;software engineering,software testing;IT-enabled business models;manual testing;crowdtesting;crowdsourcing;Internet users;employees;software development executives,,14.0,,16.0,,28 Mar 2017,,,IEEE,IEEE Magazines
335,336,Understanding Exception Handling: Viewpoints of Novices and Experts,H. Shah; C. Gorg; M. J. Harrold,"Georgia Institute of Technology, Atlanta; Georgia Institute of Technology, Atlanta; Georgia Institute of Technology, Atlanta",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,150,161,"Several recent studies indicate that many industrial applications exhibit poor quality in the design of exception-handling. To improve the quality of error-handling, we need to understand the problems and obstacles that developers face when designing and implementing exception-handling. In this paper, we present our research on understanding the viewpoint of developers-novices and experts-toward exception-handling. First, we conducted a study with novice developers in industry. The study results reveal that novices tend to ignore exceptions because of the complex nature of exception-handling. Then, we conducted a second study with experts in industry to understand their perspective on exception-handling. The study results show that, for experts, exception-handling is a crucial part in the development process. Experts also confirm the novices' approach of ignoring exception-handling and provide insights as to why novices do so. After analyzing the study data, we identified factors that influence experts' strategy selection process for handling exceptions and then built a model that represents a strategy selection process experts use to handle exceptions. Our model is based on interacting modules and fault scope. We conclude with some recommendations to help novices improve their understanding of exception-handling.",1939-3520,,10.1109/TSE.2010.7,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383375,Exception handling;user study;software developers.,Software performance;Application software;Debugging;Data analysis;Software tools;Functional programming;Programming profession;Performance evaluation;Visualization,error handling;software engineering,exception handling design;error handling quality;software development process;expert strategy selection process,,30.0,,15.0,,15 Jan 2010,,,IEEE,IEEE Journals
336,337,How Software Designers Interact with Sketches at the Whiteboard,N. Mangano; T. D. LaToza; M. Petre; A. van der Hoek,"Molimur, Mission Viejo, CA; Department of Informatics, Donald Bren School Information and Computer Sciences, University of California, Irvine, CA; Faculty of Mathematics and Computing, The Open University, Milton Keynes, United Kingdom; Department of Informatics, Donald Bren School Information and Computer Sciences, University of California, Irvine, CA",IEEE Transactions on Software Engineering,10 Feb 2015,2015,41,2,135,156,"Whiteboard sketches play a crucial role in software development, helping to support groups of designers in reasoning about a software design problem at hand. However, little is known about these sketches and how they support design `in the moment', particularly in terms of the relationships among sketches, visual syntactic elements within sketches, and reasoning activities. To address this gap, we analyzed 14 hours of design activity by eight pairs of professional software designers, manually coding over 4000 events capturing the introduction of visual syntactic elements into sketches, focus transitions between sketches, and reasoning activities. Our findings indicate that sketches serve as a rich medium for supporting design conversations. Designers often use general-purpose notations. Designers introduce new syntactic elements to record aspects of the design, or re-purpose sketches as the design develops. Designers constantly shift focus between sketches, using groups of sketches together that contain complementary information. Finally, sketches play an important role in supporting several types of reasoning activities (mental simulation, review of progress, consideration of alternatives). But these activities often leave no trace and rarely lead to sketch creation. We discuss the implications of these and other findings for the practice of software design at the whiteboard and for the creation of new electronic software design sketching tools.",1939-3520,,10.1109/TSE.2014.2362924,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6922572,Interaction styles;systems analysis and design;user-centered design;Interaction styles;systems analysis and design;user-centered design,Encoding;Cognition;Software design;Visualization;Syntactics;Videos,software engineering,software design;whiteboard sketch;software development;visual syntactic elements;reasoning activity,,9.0,,60.0,,14 Oct 2014,,,IEEE,IEEE Journals
337,338,Process Aspects and Social Dynamics of Contemporary Code Review: Insights from Open Source Development and Industrial Practice at Microsoft,A. Bosu; J. C. Carver; C. Bird; J. Orbeck; C. Chockley,"Department of Computer Science, Southern Illinois University, Carbondale, IL; Department of Computer Science, University of Alabama, Tuscaloosa, AL; Microsoft Research, Microsoft Corportation, Redmond, WA; Department of Computer Science, University of Alabama, Tuscaloosa, AL; Department of Computer Science, University of Alabama, Tuscaloosa, AL",IEEE Transactions on Software Engineering,9 Jan 2017,2017,43,1,56,75,"Many open source and commercial developers practice contemporary code review, a lightweight, informal, tool-based code review process. To better understand this process and its benefits, we gathered information about code review practices via surveys of open source software developers and developers from Microsoft. The results of our analysis suggest that developers spend approximately 10-15 percent of their time in code reviews, with the amount of effort increasing with experience. Developers consider code review important, stating that in addition to finding defects, code reviews offer other benefits, including knowledge sharing, community building, and maintaining code quality. The quality of the code submitted for review helps reviewers form impressions about their teammates, which can influence future collaborations. We found a large amount of similarity between the Microsoft and OSS respondents. One interesting difference is that while OSS respondents view code review as an important method of impression formation, Microsoft respondents found knowledge dissemination to be more important. Finally, we found little difference between distributed and co-located Microsoft teams. Our findings identify the following key areas that warrant focused research: 1) exploring the non-technical benefits of code reviews, 2) helping developers in articulating review comments, and 3) assisting reviewers' program comprehension during code reviews.",1939-3520,,10.1109/TSE.2016.2576451,US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7484733,Code review;open source;OSS;survey;peer impressions;commercial projects,Inspection;Organizations;Collaboration;Context;Instruments;Measurement;Human factors,public domain software;software engineering;software management;software reviews;team working,contemporary code review;open source software developers;code quality;OSS;knowledge dissemination;Microsoft teams,,32.0,,58.0,,7 Jun 2016,,,IEEE,IEEE Journals
338,339,Early Detection of Collaboration Conflicts and Risks,Y. Brun; R. Holmes; M. D. Ernst; D. Notkin,"University of Massachusetts, Amherst; University of Waterloo, Waterloo; University of Washington, Seattle; University of Washington, Seattle",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1358,1375,"Conflicts among developers' inconsistent copies of a shared project arise in collaborative development and can slow progress and decrease quality. Identifying and resolving such conflicts early can help. Identifying situations which may lead to conflicts can prevent some conflicts altogether. By studying nine open-source systems totaling 3.4 million lines of code, we establish that conflicts are frequent, persistent, and appear not only as overlapping textual edits but also as subsequent build and test failures. Motivated by this finding, we develop a speculative analysis technique that uses previously unexploited information from version control operations to precisely diagnose important classes of conflicts. Then, we design and implement Crystal, a publicly available tool that helps developers identify, manage, and prevent conflicts. Crystal uses speculative analysis to make concrete advice unobtrusively available to developers.",1939-3520,,10.1109/TSE.2013.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6520859,Collaborative development;collaboration conflicts;developer awareness;speculative analysis;version control;Crystal,Crystals;Collaboration;History;Open source software;Control systems;Terminology;Computer science,configuration management;groupware;program diagnostics;public domain software;software engineering,collaboration conflicts;collaborative development;open-source systems;overlapping textual edits;subsequent build-and-test failures;speculative analysis technique;version control operations;Crystal;publicly available tool;source code,,32.0,,48.0,,27 May 2013,,,IEEE,IEEE Journals
339,340,A Comparison of Six UML-Based Languages for Software Process Modeling,R. Bendraou; J. Jézéquel; M. Gervais; X. Blanc,"University of Pierre and Marie Curie (UPMC), Paris; IRISA, INRIA-Rennes Bretagne Atlantique, Rennes; University of Paris Ouest Nanterre La Défense, Paris; University of Pierre and Marie Curie (UPMC), Paris",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,662,675,"Describing and managing activities, resources, and constraints of software development processes is a challenging goal for many organizations. A first generation of Software Process Modeling Languages (SPMLs) appeared in the 1990s but failed to gain broad industrial support. Recently, however, a second generation of SPMLs has appeared, leveraging the strong industrial interest for modeling languages such as UML. In this paper, we propose a comparison of these UML-based SPMLs. While not exhaustive, this comparison concentrates on SPMLs most representative of the various alternative approaches, ranging from UML-based framework specializations to full-blown executable metamodeling approaches. To support the comparison of these various approaches, we propose a frame gathering a set of requirements for process modeling, such as semantic richness, modularity, executability, conformity to the UML standard, and formality. Beyond discussing the relative merits of these approaches, we also evaluate the overall suitability of these UML-based SPMLs for software process modeling. Finally, we discuss the impact of these approaches on the current state of the practice, and conclude with lessons we have learned in doing this comparison.",1939-3520,,10.1109/TSE.2009.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593045,Metamodeling;process modeling and execution;software process modeling languages;UML.,Unified modeling language;Software;Object oriented modeling;Analytical models;Semantics;Programming;Computational modeling,software engineering;Unified Modeling Language,UML based language;software development process;software process modeling language;UML based SPML;metamodeling approach,,48.0,,78.0,,30 Sep 2010,,,IEEE,IEEE Journals
340,341,"The Work Life of Developers: Activities, Switches and Perceived Productivity",A. N. Meyer; L. E. Barton; G. C. Murphy; T. Zimmermann; T. Fritz,"University of Zurich, Zürich, Switzerland; University of British Columbia, Vancouver, BC, Canada; University of British Columbia, Vancouver, BC, Canada; Microsoft Research, Redmond, WA; University of Zurich, Zürich, Switzerland",IEEE Transactions on Software Engineering,8 Dec 2017,2017,43,12,1178,1193,"Many software development organizations strive to enhance the productivity of their developers. All too often, efforts aimed at improving developer productivity are undertaken without knowledge about how developers spend their time at work and how it influences their own perception of productivity. To fill in this gap, we deployed a monitoring application at 20 computers of professional software developers from four companies for an average of 11 full work day in situ. Corroborating earlier findings, we found that developers spend their time on a wide variety of activities and switch regularly between them, resulting in highly fragmented work. Our findings extend beyond existing research in that we correlate developers' work habits with perceived productivity and also show productivity is a personal matter. Although productivity is personal, developers can be roughly grouped into morning, low-at-lunch and afternoon people. A stepwise linear regression per participant revealed that more user input is most often associated with a positive, and emails, planned meetings and work unrelated websites with a negative perception of productivity. We discuss opportunities of our findings, the potential to predict high and low productivity and suggest design approaches to create better tool support for planning developers' work day and improving their personal productivity.",1939-3520,,10.1109/TSE.2017.2656886,ABB; SNF; NSERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7829407,Productivity;developer activity;work fragmentation;interruptions;human factors;user studies,Productivity;Software development;Encoding;Human factors;Monitoring,regression analysis;software development management;software engineering,developer productivity;software development organizations;personal productivity;work unrelated websites;perceived productivity;highly fragmented work;professional software developers,,24.0,,64.0,Traditional,23 Jan 2017,,,IEEE,IEEE Journals
341,342,A Dissection of the Test-Driven Development Process: Does It Really Matter to Test-First or to Test-Last?,D. Fucci; H. Erdogmus; B. Turhan; M. Oivo; N. Juristo,"Department of Information Processing Science, University of Oulu, Oulu, Finland; Silicon Valley Campus, Carnegie Mellon University, Pittsburgh, PA; Department of Information Processing Science, University of Oulu, Oulu, Finland; Department of Information Processing Science, University of Oulu, Oulu, Finland; Department of Information Processing Science, University of Oulu, Oulu, Finland",IEEE Transactions on Software Engineering,14 Jul 2017,2017,43,7,597,614,"Background: Test-driven development (TDD) is a technique that repeats short coding cycles interleaved with testing. The developer first writes a unit test for the desired functionality, followed by the necessary production code, and refactors the code. Many empirical studies neglect unique process characteristics related to TDD iterative nature. Aim: We formulate four process characteristic: sequencing, granularity, uniformity, and refactoring effort. We investigate how these characteristics impact quality and productivity in TDD and related variations. Method: We analyzed 82 data points collected from 39 professionals, each capturing the process used while performing a specific development task. We built regression models to assess the impact of process characteristics on quality and productivity. Quality was measured by functional correctness. Result: Quality and productivity improvements were primarily positively associated with the granularity and uniformity. Sequencing, the order in which test and production code are written, had no important influence. Refactoring effort was negatively associated with both outcomes. We explain the unexpected negative correlation with quality by possible prevalence of mixed refactoring. Conclusion: The claimed benefits of TDD may not be due to its distinctive test-first dynamic, but rather due to the fact that TDD-like processes encourage fine-grained, steady steps that improve focus and flow.",1939-3520,,10.1109/TSE.2016.2616877,Academy of Finland; TEKES; FiDiPro; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7592412,Test-driven development;empirical investigation;process dimensions;external quality;productivity,Testing;Productivity;Context;Companies;Sequential analysis;Conferences,program testing;regression analysis;software engineering,test-driven development process;TDD technique;TDD iterative nature;sequencing characteristic;granularity characteristic;uniformity characteristic;refactoring effort characteristic;regression model,,9.0,,46.0,,18 Oct 2016,,,IEEE,IEEE Journals
342,343,A Model-Driven Methodology for Developing Secure Data-Management Applications,D. Basin; M. Clavel; M. Egea; M. A. G. de Dios; C. Dania,"ETH Zürich, Zürich, Switzerland; IMDEA Software, Campus de Montegancedo, s/n, Pozuelo de Alarcon, Madrid, Spain; ATOS Research & Innovation, Madrid, Spain; IMDEA Software, Campus de Montegancedo, s/n, Pozuelo de Alarcon, Madrid, Spain; IMDEA Software, Campus de Montegancedo, s/n, Pozuelo de Alarcon, Madrid, Spain",IEEE Transactions on Software Engineering,2 May 2014,2014,40,4,324,337,"We present a novel model-driven methodology for developing secure data-management applications. System developers proceed by modeling three different views of the desired application: its data model, security model, and GUI model. These models formalize respectively the application's data domain, authorization policy, and its graphical interface together with the application's behavior. Afterwards a model-transformation function lifts the policy specified by the security model to the GUI model. This allows a separation of concerns where behavior and security are specified separately, and subsequently combined to generate a security-aware GUI model. Finally, a code generator generates a multi-tier application, along with all support for access control, from the security-aware GUI model. We report on applications built using our approach and the associated tool.",1939-3520,,10.1109/TSE.2013.2297116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698396,Model-driven development;model-driven security;access control;GUI models;model transformation,Data models;Graphical user interfaces;Unified modeling language;Authorization;Syntactics,authorisation;graphical user interfaces;software engineering,model-driven methodology;secure data-management applications;data model;security model;graphical user intefaces;authorization policy;model-transformation function;security-aware GUI model;code generator;multitier application;access control,,14.0,,30.0,,2 Jan 2014,,,IEEE,IEEE Journals
343,344,Program Characterization Using Runtime Values and Its Application to Software Plagiarism Detection,Y. Jhi; X. Jia; X. Wang; S. Zhu; P. Liu; D. Wu,"Samsung SDS R&D Center, Seoul, Korea; State Key Laboratory of Information Security, Institute of Information Engineering, Beijing, Haidian District, China; Shape Security, Mountain View, CA; Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA",IEEE Transactions on Software Engineering,15 Sep 2015,2015,41,9,925,943,"Illegal code reuse has become a serious threat to the software community. Identifying similar or identical code fragments becomes much more challenging in code theft cases where plagiarizers can use various automated code transformation or obfuscation techniques to hide stolen code from being detected. Previous works in this field are largely limited in that (i) most of them cannot handle advanced obfuscation techniques, and (ii) the methods based on source code analysis are not practical since the source code of suspicious programs typically cannot be obtained until strong evidences have been collected. Based on the observation that some critical runtime values of a program are hard to be replaced or eliminated by semantics-preserving transformation techniques, we introduce a novel approach to dynamic characterization of executable programs. Leveraging such invariant values, our technique is resilient to various control and data obfuscation techniques. We show how the values can be extracted and refined to expose the critical values and how we can apply this runtime property to help solve problems in software plagiarism detection. We have implemented a prototype with a dynamic taint analyzer atop a generic processor emulator. Our value-based plagiarism detection method (VaPD) uses the longest common subsequence based similarity measuring algorithms to check whether two code fragments belong to the same lineage. We evaluate our proposed method through a set of real-world automated obfuscators. Our experimental results show that the value-based method successfully discriminates 34 plagiarisms obfuscated by SandMark, plagiarisms heavily obfuscated by KlassMaster, programs obfuscated by Thicket, and executables obfuscated by Loco/Diablo.",1939-3520,,10.1109/TSE.2015.2418777,US National Science Foundation (NSF); AFRL; National Natural Science Foundation of China (NSFC); National High-tech R&D Program of China; Strategic Priority Research Program of the Chinese Academy of Sciences; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7076635,Software plagiarism detection;dynamic code identification.;Software plagiarism detection;dynamic code identification,Plagiarism;Runtime;Optimization;Program processors;Semantics;Java,security of data;software engineering;source code (software),program characterization;runtime values;software plagiarism detection;illegal code reuse;software community;identical code fragments;obfuscation techniques;source code;semantics-preserving transformation techniques;generic processor emulator;value-based plagiarism detection method;VaPD;SandMark;Thicket;Loco/Diablo,,18.0,1.0,59.0,,1 Apr 2015,,,IEEE,IEEE Journals
344,345,FlowTalk: Language Support for Long-Latency Operations in Embedded Devices,A. Bergel; W. Harrison; V. Cahill; S. Clarke,"University of Chile, Santiago; Software Structure Group; Lero and Trinity College Dublin, Ireland; Lero and Trinity College Dublin, Ireland",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,526,543,"Wireless sensor networks necessitate a programming model different from those used to develop desktop applications. Typically, resources in terms of power and memory are constrained. C is the most common programming language used to develop applications on very small embedded sensor devices. We claim that C does not provide efficient mechanisms to address the implicit asynchronous nature of sensor sampling. C applications for these devices suffer from a disruption in their control flow. In this paper, we present FlowTalk, a new object-oriented programming language aimed at making software development for wireless embedded sensor devices easier. FlowTalk is an object-oriented programming language in which dynamicity (e.g., object creation) has been traded for a reduction in memory consumption. The event model that traditionally comes from using sensors is adapted in FlowTalk with controlled disruption, a light-weight continuation mechanism. The essence of our model is to turn asynchronous long-latency operations into synchronous and blocking method calls. FlowTalk is built for TinyOS and can be used to develop applications that can fit in 4 KB of memory for a large number of wireless sensor devices.",1939-3520,,10.1109/TSE.2010.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492692,Embedded systems;object-based programming.,Sampling methods;Object oriented modeling;Wireless sensor networks;Application software;Computer languages;Object oriented programming;Java;Biosensors;Automotive engineering;Embedded software,C language;embedded systems;intelligent sensors;object-oriented languages;object-oriented programming;software engineering;wireless sensor networks,FlowTalk;language support;wireless sensor networks;programming language;C language;embedded sensor devices;sensor sampling;object-oriented programming language;memory consumption;light-weight continuation mechanism;asynchronous long-latency operations;TinyOS;memory size 4 KByte,,1.0,,44.0,,28 Jun 2010,,,IEEE,IEEE Journals
345,346,Engineering of Framework-Specific Modeling Languages,M. Antkiewicz; K. Czarnecki; M. Stephan,"University of Waterloo, Waterloo; University of Waterloo, Waterloo; University of Waterloo, Waterloo",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,795,824,"Framework-specific modeling languages (FSMLs) help developers build applications based on object-oriented frameworks. FSMLs model abstractions and rules of application programming interfaces (APIs) exposed by frameworks and can express models of how applications use APIs. Such models aid developers in understanding, creating, and evolving application code. We present four exemplar FSMLs and a method for engineering new FSMLs. The method was created postmortem by generalizing the experience of building the exemplars and by specializing existing approaches to domain analysis, software development, and quality evaluation of models and languages. The method is driven by the use cases that the FSML under development should support and the evaluation of the constructed FSML is guided by two existing quality frameworks. The method description provides concrete examples for the engineering steps, outcomes, and challenges. It also provides strategies for making engineering decisions. Our work offers a concrete example of software language engineering and its benefits. FSMLs capture existing domain knowledge in language form and support application code understanding through reverse engineering, application code creation through forward engineering, and application code evolution through round-trip engineering.",1939-3520,,10.1109/TSE.2009.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4907004,Framework-specific modeling language;domain-specific language;object-oriented framework;application programming interface (API);feature model;framework-specific model;forward engineering;reverse engineering;round-trip engineering;evolution;code pattern;mapping.,Object oriented modeling;Application software;Documentation;Writing;Concrete;Reverse engineering;Knowledge engineering;Java;Scattering;Buildings,application program interfaces;object-oriented programming;software engineering,framework-specific modeling languages;object-oriented frameworks;application programming interfaces;software development;software language engineering;reverse engineering;application code creation through forward engineering;application code evolution through round-trip engineering,,34.0,,102.0,,2 May 2009,,,IEEE,IEEE Journals
346,347,Extracting Development Tasks to Navigate Software Documentation,C. Treude; M. P. Robillard; B. Dagenais,"Departamento de Informática e Matemática Aplicada, Universidade Federal do Rio Grande do Norte, Natal, RN, Brazil; School of Computer Science, McGill University, Montréal, QC, Canada; Resulto, Montréal, QC, Canada",IEEE Transactions on Software Engineering,10 Jun 2015,2015,41,6,565,581,"Knowledge management plays a central role in many software development organizations. While much of the important technical knowledge can be captured in documentation, there often exists a gap between the information needs of software developers and the documentation structure. To help developers navigate documentation, we developed a technique for automatically extracting tasks from software documentation by conceptualizing tasks as specific programming actions that have been described in the documentation. More than 70 percent of the tasks we extracted from the documentation of two projects were judged meaningful by at least one of two developers. We present TaskNavigator, a user interface for search queries that suggests tasks extracted with our technique in an auto-complete list along with concepts, code elements, and section headers. We conducted a field study in which six professional developers used TaskNavigator for two weeks as part of their ongoing work. We found search results identified through extracted tasks to be more helpful to developers than those found through concepts, code elements, and section headers. The results indicate that task descriptions can be effectively extracted from software documentation, and that they help bridge the gap between documentation structure and the information needs of software developers.",1939-3520,,10.1109/TSE.2014.2387172,NSERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7000568,Software Documentation;Development Tasks;Navigation;Auto-Complete;Natural Language Processing;Software documentation;development tasks;navigation;auto-complete;natural language processing,Documentation;Software;Navigation;Data mining;Programming;Natural language processing;Subscriptions,knowledge management;software engineering;user interfaces,software documentation navigation;knowledge management;software developers;information needs;programming action;TaskNavigator user interface;documentation structure,,35.0,,59.0,,31 Dec 2014,,,IEEE,IEEE Journals
347,348,Supporting Domain Analysis through Mining and Recommending Features from Online Product Listings,N. Hariri; C. Castro-Herrera; M. Mirakhorli; J. Cleland-Huang; B. Mobasher,"DePaul University, Chicago; Google Inc.; DePaul University, Chicago; DePaul University, Chicago; DePaul University, Chicago",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1736,1752,"Domain analysis is a labor-intensive task in which related software systems are analyzed to discover their common and variable parts. Many software projects include extensive domain analysis activities, intended to jumpstart the requirements process through identifying potential features. In this paper, we present a recommender system that is designed to reduce the human effort of performing domain analysis. Our approach relies on data mining techniques to discover common features across products as well as relationships among those features. We use a novel incremental diffusive algorithm to extract features from online product descriptions, and then employ association rule mining and the (k)-nearest neighbor machine learning method to make feature recommendations during the domain analysis process. Our feature mining and feature recommendation algorithms are quantitatively evaluated and the results are presented. Also, the performance of the recommender system is illustrated and evaluated within the context of a case study for an enterprise-level collaborative software suite. The results clearly highlight the benefits and limitations of our approach, as well as the necessary preconditions for its success.",1939-3520,,10.1109/TSE.2013.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6582404,Domain analysis;recommender systems;clustering;association rule mining;k-nearest neighbor,Feature extraction;Recommender systems;Clustering algorithms;Domain analysis;Data mining;Algorithm design and analysis;Electronic mail;Nearest neighbor search;Clustering,data mining;groupware;Internet;learning (artificial intelligence);pattern classification;recommender systems;software engineering,enterprise-level collaborative software suite;feature recommendation algorithms;feature mining;k-nearest neighbor machine learning method;association rule mining;online product descriptions;feature extraction;incremental diffusive algorithm;data mining techniques;recommender system;domain analysis activity;software projects;software systems;labor-intensive task;online product listings,,56.0,,52.0,,16 Aug 2013,,,IEEE,IEEE Journals
348,349,Visualizing Co-Change Information with the Evolution Radar,M. D'Ambros; M. Lanza; M. Lungu,"University of Lugano, Lugano; University of Lugano, Lugano; University of Lugano, Lugano",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,720,735,"Software evolution analysis provides a valuable source of information that can be used both to understand a system's design and predict its future development. While for many program comprehension purposes, it is sufficient to model a single version of a system, there are types of information that can only be recovered when the history of a system is taken into account. Logical coupling, the implicit dependency between software artifacts that have been changed together, is an example of such information. Previous research has dealt with low-level couplings between files, leading to an explosion of the data to be analyzed, or has abstracted the logical couplings to the level of modules, leading to a loss of detailed information. In this paper, we present a visualization-based approach that integrates logical coupling information at different levels of abstraction. This facilitates an in-depth analysis of the logical couplings, and at the same time, leads to a characterization of a system's modules in terms of their logical coupling. The presented approach supports the retrospective analysis of a software system and maintenance activities such as restructuring and redocumentation. We illustrate retrospective analysis on two large open-source software systems.",1939-3520,,10.1109/TSE.2009.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815274,Software evolution;software visualization;logical coupling.,Radar;Information analysis;Software systems;Information resources;System analysis and design;History;Explosions;Data analysis;Data visualization;Software maintenance,data visualisation;software engineering;systems re-engineering,evolution radar;software evolution analysis;software artifacts;visualization;logical coupling information;abstraction;system module;open source software system analysis,,54.0,,38.0,,17 Apr 2009,,,IEEE,IEEE Journals
349,350,Automatic Detection and Resolution of Lexical Ambiguity in Process Models,F. Pittke; H. Leopold; J. Mendling,"Institute for Information Business, Vienna, WU, Austria; Department of Computer Science, VU University Amsterdam, The Netherlands; Institute for Information Business, Vienna, WU, Austria",IEEE Transactions on Software Engineering,10 Jun 2015,2015,41,6,526,544,"System-related engineering tasks are often conducted using process models. In this context, it is essential that these models do not contain structural or terminological inconsistencies. To this end, several automatic analysis techniques have been proposed to support quality assurance. While formal properties of control flow can be checked in an automated fashion, there is a lack of techniques addressing textual quality. More specifically, there is currently no technique available for handling the issue of lexical ambiguity caused by homonyms and synonyms. In this paper, we address this research gap and propose a technique that detects and resolves lexical ambiguities in process models. We evaluate the technique using three process model collections from practice varying in size, domain, and degree of standardization. The evaluation demonstrates that the technique significantly reduces the level of lexical ambiguity and that meaningful candidates are proposed for resolving ambiguity.",1939-3520,,10.1109/TSE.2015.2396895,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7027184,Identification of Lexical Ambiguity;Resolution of Lexical Ambiguity;Business Process Models;Identification of lexical ambiguity;resolution of lexical ambiguity;business process models,Unified modeling language;Object oriented modeling;Context;Business;Natural languages;Manuals;Vectors,computational linguistics;grammars;natural language processing;software engineering,automatic detection;automatic resolution;lexical ambiguity;system-related engineering task;structural inconsistency;terminological inconsistency;automatic analysis technique;quality assurance;control flow;automated fashion;textual quality;homonyms;synonyms;process model collection,,32.0,,106.0,,29 Jan 2015,,,IEEE,IEEE Journals
350,351,Time and Probability-Based Information Flow Analysis,R. Lanotte; A. Maggiolo-Schettini; A. Troina,"Università dell'Insubria, Como; Università di Pisa, Pisa; Università di Torino, Torino",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,719,734,"In multilevel systems, it is important to avoid unwanted indirect information flow from higher levels to lower levels, namely, the so-called covert channels. Initial studies of information flow analysis were performed by abstracting away from time and probability. It is already known that systems that are proven to be secure in a possibilistic framework may turn out to be insecure when time or probability is considered. Recently, work has been done in order to consider also aspects either of time or of probability, but not both. In this paper, we propose a general framework based on Probabilistic Timed Automata, where both probabilistic and timing covert channels can be studied. We define a Noninterference security property and a Nondeducibility on Composition security property, which allow expressing information flow in a timed and probabilistic setting. We then compare these properties with analogous ones defined in contexts where either time or probability or neither of them are taken into account. This permits a classification of the properties depending on their discerning power. As an application, we study a system with covert channels that we are able to discover by applying our techniques.",1939-3520,,10.1109/TSE.2010.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383372,Probabilistic timed automata;multilevel security;information flow analysis;weak bisimulation.,Information analysis;Information security;Automata;Clocks;Multilevel systems;Timing;Communication system control;Performance analysis;Power system security;Control systems,data flow analysis;probabilistic automata;probability;security of data;software agents;software engineering,probability based information flow analysis;multilevel system;indirect unwanted information flow;covert channel;probabilistic timed automata;probabilistic covert channel;timing covert channel;noninterference security property;nondeducibility;composition security property,,9.0,,45.0,,15 Jan 2010,,,IEEE,IEEE Journals
351,352,Range Fixes: Interactive Error Resolution for Software Configuration,Y. Xiong; H. Zhang; A. Hubaux; S. She; J. Wang; K. Czarnecki,"School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; ASML, Eindhoven, the Netherlands; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Canada",IEEE Transactions on Software Engineering,10 Jun 2015,2015,41,6,603,619,"To prevent ill-formed configurations, highly configurable software often allows defining constraints over the available options. As these constraints can be complex, fixing a configuration that violates one or more constraints can be challenging. Although several fix-generation approaches exist, their applicability is limited because (1) they typically generate only one fix or a very long fix list, difficult for the user to identify the desirable fix; and (2) they do not fully support non-Boolean constraints, which contain arithmetic, inequality, and string operators. This paper proposes a novel concept, range fix, for software configuration. A range fix specifies the options to change and the ranges of values for these options. We also design an algorithm that automatically generates range fixes for a violated constraint. We have evaluated our approach with three different strategies for handling constraint interactions, on data from nine open source projects over two configuration platforms. The evaluation shows that our notion of range fix leads to mostly simple yet complete sets of fixes, and our algorithm is able to generate fixes within one second for configuration systems with a few thousands options and constraints.",1939-3520,,10.1109/TSE.2014.2383381,National Basic Research Program of China; High-Tech Research and Development Program of China; National Natural Science Foundation of China; NSERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6991616,Consistency Management;Error Resolution;Range Fix;Software Configuration;Consistency management;error resolution;range fix;software configuration,Concrete;Linux;Biological system modeling;Reactive power;Kernel;Navigation,constraint handling;software engineering,range fixes;interactive error resolution;software configuration;fix-generation approaches;constraint interaction handling;open source projects,,13.0,,46.0,,18 Dec 2014,,,IEEE,IEEE Journals
352,353,The Design Space of Bug Fixes and How Developers Navigate It,E. Murphy-Hill; T. Zimmermann; C. Bird; N. Nagappan,"Department of Computer Science, North Carolina State University, Raleigh, NC; Microsoft Research, Redmond, WA; Microsoft Research, Redmond, WA; Microsoft Research, Redmond, WA",IEEE Transactions on Software Engineering,7 Jan 2015,2015,41,1,65,81,"When software engineers fix bugs, they may have several options as to how to fix those bugs. Which fix they choose has many implications, both for practitioners and researchers: What is the risk of introducing other bugs during the fix? Is the bug fix in the same code that caused the bug? Is the change fixing the cause or just covering a symptom? In this paper, we investigate alternative fixes to bugs and present an empirical study of how engineers make design choices about how to fix bugs. We start with a motivating case study of the Pex4Fun environment. Then, based on qualitative interviews with 40 engineers working on a variety of products, data from six bug triage meetings, and a survey filled out by 326 Microsoft engineers and 37 developers from other companies, we found a number of factors, many of them non-technical, that influence how bugs are fixed, such as how close to release the software is. We also discuss implications for research and practice, including how to make bug prediction and localization more accurate.",1939-3520,,10.1109/TSE.2014.2357438,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6901259,Design concepts;human factors in software design;maintainability,Interviews;Computer bugs;Software;Encoding;Navigation;Protocols;Buildings,program debugging;software engineering,bug fix design space;software engineers;design choices;Pex4Fun environment;qualitative interviews;bug triage meetings;Microsoft engineers;bug prediction;bug localization,,24.0,,36.0,,17 Sep 2014,,,IEEE,IEEE Journals
353,354,Automatically Recommending Peer Reviewers in Modern Code Review,M. B. Zanjani; H. Kagdi; C. Bird,"Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, Kansas; Department of Electrical Engineering and Computer Science, Wichita State University, Wichita, Kansas; Microsoft Research, Redmond, WA",IEEE Transactions on Software Engineering,10 Jun 2016,2016,42,6,530,543,"Code review is an important part of the software development process. Recently, many open source projects have begun practicing code review through “modern” tools such as GitHub pull-requests and Gerrit. Many commercial software companies use similar tools for code review internally. These tools enable the owner of a source code change to request individuals to participate in the review, i.e., reviewers. However, this task comes with a challenge. Prior work has shown that the benefits of code review are dependent upon the expertise of the reviewers involved. Thus, a common problem faced by authors of source code changes is that of identifying the best reviewers for their source code change. To address this problem, we present an approach, namely cHRev, to automatically recommend reviewers who are best suited to participate in a given review, based on their historical contributions as demonstrated in their prior reviews. We evaluate the effectiveness of cHRev on three open source systems as well as a commercial codebase at Microsoft and compare it to the state of the art in reviewer recommendation. We show that by leveraging the specific information in previously completed reviews (i.e.,quantification of review comments and their recency), we are able to improve dramatically on the performance of prior approaches, which (limitedly) operate on generic review information (i.e., reviewers of similar source code file and path names) or source coderepository data. We also present the insights into why our approach cHRev outperforms the existing approaches.",1939-3520,,10.1109/TSE.2015.2500238,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7328331,Modern code review;reviewer recommendation;code change;Gerrit;Modern code review;reviewer recommendation;code change;Gerrit,History;Electronic mail;Birds;Inspection;Androids;Humanoid robots;Software,software engineering;software reviews,peer reviewer recommendation;code review;software development process;open source projects;GitHub pull-requests tool;Gerrit tool;source code change;cHRev approach;commercial codebase,,46.0,,55.0,,12 Nov 2015,,,IEEE,IEEE Journals
354,355,Exploring Mobile End User Development: Existing Use and Design Factors,A. Namoun; A. Daskalopoulou; N. Mehandjiev; Z. Xun,"Islamic University of Madinah, Medina, Saudi Arabia; University of Manchester, Booth Street West, Manchester, United Kingdom; University of Manchester, Booth Street West, Manchester, United Kingdom; University of Manchester, Booth Street West, Manchester, United Kingdom",IEEE Transactions on Software Engineering,13 Oct 2016,2016,42,10,960,976,"Mobile devices are everywhere, and the scope of their use is growing from simple calling and texting through Internet browsing to more technical activities such as creating message processing filters and connecting different apps. However, building tools which provide effective support for such advanced technical use of mobile devices by non-programmers (mobile end user development or mEUD) requires thorough understanding of user needs and motivations, including factors which can impact user intentions regarding mEUD activities. We propose a model linking these mEUD factors with mobile users' attitudes towards, and intent of doing mEUD, and discuss a number of implications for supporting mEUD. Our research process is user-centered, and we formulate a number of hypotheses by fusing results from an exploratory survey which gathers facts about mEUD motivations and activities, and from a focus group study, which delivers deeper understanding of particular mEUD practices and issues. We then test the hypothesized relationships through a follow-up enquiry mixing quantitative and qualitative techniques, leading to the creation of a preliminary mEUD model. Altogether we have involved 275 mobile users in our research. Our contribution links seven mEUD factors with mEUD intentions and attitudes, and highlights a number of implications for mEUD support.",1939-3520,,10.1109/TSE.2016.2532873,Manchester Business School; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416245,Human factors in software design;mobile environments;models and principles;requirements/specifications,Mobile communication;Mobile handsets;Mashups;Games;Context;Electronic mail,human factors;mobile computing;software engineering;user centred design,mobile end user development;mEUD;user attitude;user-centered design;mobile device;software development,,9.0,,50.0,,23 Feb 2016,,,IEEE,IEEE Journals
355,356,Optimized Resource Allocation for Software Release Planning,A. Ngo-The; G. Ruhe,"Expert Decisions Inc., Calgary; University of Calgary, Calgary",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,109,123,"Release planning for incremental software development assigns features to releases such that technical, resource, risk and budget constraints are met. Planning of software releases and allocation of resources cannot be handled in isolation. A feature can be offered as part of a release only if all its necessary tasks are done before the given release date. We assume a given pool of human resources with different degrees of productivity to perform different types of tasks. To address the inherent difficulty of this process, we propose a two-phased optimization approach that combines the strength of two existing solution methods. The industrial applicability of the approach is primarily directed towards mature organizations having systematic development and measurement processes in place. The expected practical benefit of the planning method is to provide release plan solutions that achieve a better overall business value (e.g., expressed by the degree of stakeholder satisfaction) by better allocation of resources. Without ignoring the importance of the human expert in this process, the contributions of the paper are seen in making the overall process more objective and the resulting decisions more transparent.",1939-3520,,10.1109/TSE.2008.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4641940,Planning;Management;Planning;Management,Resource management;Humans;Productivity;Optimization methods;Constraint optimization;Integer linear programming;Genetic programming;Project management;Feedback;Companies,project management;resource allocation;software engineering;software management,optimized resource allocation;software release planning;incremental software development;software project management,,54.0,3.0,41.0,,10 Oct 2008,,,IEEE,IEEE Journals
356,357,Systematic review and aggregation of empirical studies on elicitation techniques,O. Dieste; N. Juristo,"Universidad Politécnica de Madrid, Boadilla del Monte; Universidad Politécnica de Madrid, Boadilla del Monte",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,283,304,"We have located the results of empirical studies on elicitation techniques and aggregated these results to gather empirically grounded evidence. Our chosen surveying methodology was systematic review, whereas we used an adaptation of comparative analysis for aggregation because meta-analysis techniques could not be applied. The review identified 564 publications from the SCOPUS, IEEEXPLORE, and ACM DL databases, as well as Google. We selected and extracted data from 26 of those publications. The selected publications contain 30 empirical studies. These studies were designed to test 43 elicitation techniques and 50 different response variables. We got 100 separate results from the experiments. The aggregation generated 17 pieces of knowledge about the interviewing, laddering, sorting, and protocol analysis elicitation techniques. We provide a set of guidelines based on the gathered pieces of knowledge.",1939-3520,,10.1109/TSE.2010.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416730,Elicitation methods;performance measures;experimentation;systematic literature review.,Protocols;Information analysis;Sensitivity analysis;Databases;Data mining;Sorting;Software measurement,knowledge acquisition;software engineering,empirically grounded evidence;elicitation techniques;surveying methodology;systematic review;SCOPUS;IEEEXPLORE;ACM DL databases;Google,,72.0,,102.0,,18 Feb 2010,,,IEEE,IEEE Journals
357,358,CACheck: Detecting and Repairing Cell Arrays in Spreadsheets,W. Dou; C. Xu; S. C. Cheung; J. Wei,"State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,14 Mar 2017,2017,43,3,226,251,"Spreadsheets are widely used by end users for numerical computation in their business. Spreadsheet cells whose computation is subject to the same semantics are often clustered in a row or column as a cell array. When a spreadsheet evolves, the cells in a cell array can degenerate due to ad hoc modifications. Such degenerated cell arrays no longer keep cells prescribing the same computational semantics, and are said to exhibit ambiguous computation smells. We propose CACheck, a novel technique that automatically detects and repairs smelly cell arrays by recovering their intended computational semantics. Our empirical study on the EUSES and Enron corpora finds that such smelly cell arrays are common. Our study also suggests that CACheck is useful for detecting and repairing real spreadsheet problems caused by smelly cell arrays. Compared with our previous work AmCheck, CACheck detects smelly cell arrays with higher precision and recall rate.",1939-3520,,10.1109/TSE.2016.2584059,Beijing Natural Science Foundation; National Key Research and Development Plan; Research Grants Council; General Research Fund; National Natural Science Foundation; Collaborative Innovation Center of Novel Software Technology and Industrialization of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498607,Spreadsheet;cell array;ambiguous computation smell,Semantics;Maintenance engineering;Software;Computer science;Nonhomogeneous media;Electronic mail;Business,software engineering;spreadsheet programs,spreadsheets;CACheck;numerical computation;ad hoc modifications;EUSES corpora;Enron corpora;smelly cell arrays,,16.0,,63.0,,23 Jun 2016,,,IEEE,IEEE Journals
358,359,Scalable Differential Analysis of Process Algebra Models,M. Tribastone; S. Gilmore; J. Hillston,"The University of Edinburgh, Edinburgh; The University of Edinburgh, Edinburgh; The University of Edinburgh, Edinburgh",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,205,219,"The exact performance analysis of large-scale software systems with discrete-state approaches is difficult because of the well-known problem of state-space explosion. This paper considers this problem with regard to the stochastic process algebra PEPA, presenting a deterministic approximation to the underlying Markov chain model based on ordinary differential equations. The accuracy of the approximation is assessed by means of a substantial case study of a distributed multithreaded application.",1939-3520,,10.1109/TSE.2010.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5567115,Modeling and prediction;ordinary differential equations;Markov processes.,Mathematical model;Semantics;Computational modeling;Approximation methods;Numerical models;Stochastic processes;Markov methods,differential equations;Markov processes;multi-threading;process algebra;software engineering,scalable differential analysis;large-scale software systems;discrete-state approach;stochastic process algebra;PEPA;Markov chain model;ordinary differential equations;distributed multithreaded application,,65.0,,26.0,,9 Sep 2010,,,IEEE,IEEE Journals
359,360,Power-Law Distributions of Component Size in General Software Systems,L. Hatton,"CISM, University, United Kingdom",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,566,572,"This paper begins by modeling general software systems using concepts from statistical mechanics which provide a framework for linking microscopic and macroscopic features of any complex system. This analysis provides a way of linking two features of particular interest in software systems: first the microscopic distribution of defects within components and second the macroscopic distribution of component sizes in a typical system. The former has been studied extensively, but the latter much less so. This paper shows that subject to an external constraint that the total number of defects is fixed in an equilibrium system, commonly used defect models for individual components directly imply that the distribution of component sizes in such a system will obey a power-law Pareto distribution. The paper continues by analyzing a large number of mature systems of different total sizes, different implementation languages, and very different application areas, and demonstrates that the component sizes do indeed appear to obey the predicted power-law distribution. Some possible implications of this are explored.",1939-3520,,10.1109/TSE.2008.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711063,Defects;macroscopic system behavior;component size distribution;Pareto.;General systems theory;Software science;Design concepts;Reliability;availability;and serviceability,Software systems;Power system modeling;Joining processes;Microscopy;Thermodynamics;Temperature distribution;Predictive models;Assembly systems;Software standards;Equations,Pareto distribution;software engineering;statistical mechanics,general software systems modeling;statistical mechanics;complex system;defects distribution;component sizes distribution;power-law Pareto distribution,,20.0,,15.0,,12 Dec 2008,,,IEEE,IEEE Journals
360,361,Semantics-Based Obfuscation-Resilient Binary Code Similarity Comparison with Applications to Software and Algorithm Plagiarism Detection,L. Luo; J. Ming; D. Wu; P. Liu; S. Zhu,"College of Information Sciences and Technology, Pennsylvania State University, University Park, PA; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, TX; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA; College of Information Sciences and Technology, Pennsylvania State University, University Park, PA; Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA",IEEE Transactions on Software Engineering,8 Dec 2017,2017,43,12,1157,1177,"Existing code similarity comparison methods, whether source or binary code based, are mostly not resilient to obfuscations. Identifying similar or identical code fragments among programs is very important in some applications. For example, one application is to detect illegal code reuse. In the code theft cases, emerging obfuscation techniques have made automated detection increasingly difficult. Another application is to identify cryptographic algorithms which are widely employed by modern malware to circumvent detection, hide network communications, and protect payloads among other purposes. Due to diverse coding styles and high programming flexibility, different implementation of the same algorithm may appear very distinct, causing automatic detection to be very hard, let alone code obfuscations are sometimes applied. In this paper, we propose a binary-oriented, obfuscation-resilient binary code similarity comparison method based on a new concept, longest common subsequence of semantically equivalent basic blocks , which combines rigorous program semantics with longest common subsequence based fuzzy matching. We model the semantics of a basic block by a set of symbolic formulas representing the input-output relations of the block. This way, the semantic equivalence (and similarity) of two blocks can be checked by a theorem prover. We then model the semantic similarity of two paths using the longest common subsequence with basic blocks as elements. This novel combination has resulted in strong resiliency to code obfuscation. We have developed a prototype. The experimental results show that our method can be applied to software plagiarism and algorithm detection, and is effective and practical to analyze real-world software.",1939-3520,,10.1109/TSE.2017.2655046,US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823022,Software plagiarism detection;algorithm detection;binary code similarity comparison;obfuscation;symbolic execution;constraint solving,Semantics;Software development;Plagiarism;Binary codes;Software algorithms;Syntactics;Computational modeling,fuzzy set theory;invasive software;program diagnostics;software engineering;theorem proving,code similarity comparison methods;identical code fragments;illegal code reuse;code theft cases;obfuscation techniques;cryptographic algorithms;diverse coding styles;automatic detection;code obfuscations;obfuscation-resilient binary code similarity comparison method;longest common subsequence;semantically equivalent basic blocks;rigorous program semantics;semantic similarity,,14.0,,81.0,Traditional,18 Jan 2017,,,IEEE,IEEE Journals
361,362,Schedule of Bad Smell Detection and Resolution: A New Way to Save Effort,H. Liu; Z. Ma; W. Shao; Z. Niu,"Beijing Institute of Technology and Ministry of Education, Beijing; Ministry of Education, Beijing; Ministry of Education, Beijing; Beijing Institute of Technology, Beijing",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,220,235,"Bad smells are signs of potential problems in code. Detecting and resolving bad smells, however, remain time-consuming for software engineers despite proposals on bad smell detection and refactoring tools. Numerous bad smells have been recognized, yet the sequences in which the detection and resolution of different kinds of bad smells are performed are rarely discussed because software engineers do not know how to optimize sequences or determine the benefits of an optimal sequence. To this end, we propose a detection and resolution sequence for different kinds of bad smells to simplify their detection and resolution. We highlight the necessity of managing bad smell resolution sequences with a motivating example, and recommend a suitable sequence for commonly occurring bad smells. We evaluate this recommendation on two nontrivial open source applications, and the evaluation results suggest that a significant reduction in effort ranging from 17.64 to 20 percent can be achieved when bad smells are detected and resolved using the proposed sequence.",1939-3520,,10.1109/TSE.2011.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680918,Scheme;bad smell;software refactoring;effort;detection;schedule.,Refactoring;Feature extraction;Distance measurement;Scheduling,scheduling;software engineering,bad smell detection;bad smell resolution;software engineers;optimal sequence;resolution sequence;detection sequence;open source applications,,55.0,,54.0,,6 Jan 2011,,,IEEE,IEEE Journals
362,363,Identifying and Summarizing Systematic Code Changes via Rule Inference,M. Kim; D. Notkin; D. Grossman; G. Wilson,"The University of Texas at Austin, Austin; University of Washington, Seattle; University of Washington, Seattle; The University of Texas at Austin, Austin",IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,45,62,"Programmers often need to reason about how a program evolved between two or more program versions. Reasoning about program changes is challenging as there is a significant gap between how programmers think about changes and how existing program differencing tools represent such changes. For example, even though modification of a locking protocol is conceptually simple and systematic at a code level, diff extracts scattered text additions and deletions per file. To enable programmers to reason about program differences at a high level, this paper proposes a rule-based program differencing approach that automatically discovers and represents systematic changes as logic rules. To demonstrate the viability of this approach, we instantiated this approach at two different abstraction levels in Java: first at the level of application programming interface (API) names and signatures, and second at the level of code elements (e.g., types, methods, and fields) and structural dependences (e.g., method-calls, field-accesses, and subtyping relationships). The benefit of this approach is demonstrated through its application to several open source projects as well as a focus group study with professional software engineers from a large e-commerce company.",1939-3520,,10.1109/TSE.2012.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165314,Software evolution;program differencing;rule learning;logic-based program representation,Systematics;Syntactics;Inference algorithms;Cloning;Software;Semantics;Libraries,application program interfaces;electronic commerce;inference mechanisms;Java;reasoning about programs;software engineering,systematic code;rule inference;reasoning about program;locking protocol;scattered text additions;rule-based program differencing approach;Java;application programming interface;API;professional software engineers;large e-commerce company;structural dependences,,28.0,,50.0,,6 Mar 2012,,,IEEE,IEEE Journals
363,364,ARENA: An Approach for the Automated Generation of Release Notes,L. Moreno; G. Bavota; M. D. Penta; R. Oliveto; A. Marcus; G. Canfora,"University of Texas at Dallas, Richardson, TX; University of Lugano, Lugano, Switzerland; University of Sannio, Benevento, Italy; University of Molise, Pesche, IS, Italy; University of Texas at Dallas, Richardson, TX; University of Sannio, Benevento, Italy",IEEE Transactions on Software Engineering,13 Feb 2017,2017,43,2,106,127,"Release notes document corrections, enhancements, and, in general, changes that were implemented in a new release of a software project. They are usually created manually and may include hundreds of different items, such as descriptions of new features, bug fixes, structural changes, new or deprecated APIs, and changes to software licenses. Thus, producing them can be a time-consuming and daunting task. This paper describes ARENA (Automatic RElease Notes generAtor), an approach for the automatic generation of release notes. ARENA extracts changes from the source code, summarizes them, and integrates them with information from versioning systems and issue trackers. ARENA was designed based on the manual analysis of 990 existing release notes. In order to evaluate the quality of the release notes automatically generated by ARENA, we performed four empirical studies involving a total of 56 participants (48 professional developers and eight students). The obtained results indicate that the generated release notes are very good approximations of the ones manually produced by developers and often include important information that is missing in the manually created release notes.",1939-3520,,10.1109/TSE.2016.2591536,National Science Foundation; Markos project; European Commission; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7513412,Release notes;software documentation;software evolution,Libraries;Licenses;Feature extraction;Documentation;Computer bugs;Open source software,application program interfaces;program debugging;software engineering;source code (software);system documentation,ARENA;automated release note generation;release note document corrections;release note document enhancements;software project;bug fixes;new features;structural changes;API;software licenses;source code change extraction;source code change summarization,,26.0,,40.0,,14 Jul 2016,,,IEEE,IEEE Journals
364,365,Cina: Suppressing the Detection of Unstable Context Inconsistency,C. Xu; W. Xi; S. C. Cheung; X. Ma; C. Cao; J. Lu,"State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China",IEEE Transactions on Software Engineering,15 Sep 2015,2015,41,9,842,865,"Context-aware applications adapt their behavior based on contexts. Contexts can, however, be incorrect. A popular means to build dependable applications is to augment them with a set of constraints to govern the consistency of context values. These constraints are evaluated upon context changes to detect inconsistencies so that they can be timely handled. However, we observe that many context inconsistencies are unstable. They vanish by themselves and do not require handling. Such inconsistencies are detected due to misaligned sensor sampling or improper inconsistency detection scheduling. We call them unstable context inconsistencies (or STINs). STINs should be avoided to prevent unnecessary inconsistency handling and unstable behavioral adaptation to applications. In this article, we study STINs systematically, from examples to theoretical analysis, and present algorithms to suppress their detection. Our key insight is that only certain patterns of context changes can make a consistency constraint subject to the detection of STINs. We derive such patterns and proactively use them to suppress the detection of STINs. We implemented our idea and applied it to real-world applications. Experimental results confirmed its effectiveness in suppressing the detection of numerous STINs with negligible overhead, while preserving the detection of stable context inconsistencies that require inconsistency handling.",1939-3520,,10.1109/TSE.2015.2418760,National Basic Research 973 Program; National Natural Science Foundation; Research Grants Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7078871,Constraint;context inconsistency;impact propagation;instability analysis;pervasive computing;Constraint;context inconsistency;impact propagation;instability analysis;pervasive computing,Context;Schedules;Delays;Sensors;Middleware;Finite element analysis,software engineering;ubiquitous computing,CINA;unstable context inconsistency detection;context-aware applications;STIN,,7.0,,65.0,,2 Apr 2015,,,IEEE,IEEE Journals
365,366,Locating Need-to-Externalize Constant Strings for Software Internationalization with Generalized String-Taint Analysis,X. Wang; L. Zhang; T. Xie; H. Mei; J. Sun,"Peking University, Beijing; Peking University, Beijing; North Carolina State University, Raleigh; Peking University, Beijing; Peking University, Beijing",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,516,536,"Nowadays, a software product usually faces a global market. To meet the requirements of different local users, the software product must be internationalized. In an internationalized software product, user-visible hard-coded constant strings are externalized to resource files so that local versions can be generated by translating the resource files. In many cases, a software product is not internationalized at the beginning of the software development process. To internationalize an existing product, the developers must locate the user-visible constant strings that should be externalized. This locating process is tedious and error-prone due to 1) the large number of both user-visible and non-user-visible constant strings and 2) the complex data flows from constant strings to the Graphical User Interface (GUI). In this paper, we propose an automatic approach to locating need-to-externalize constant strings in the source code of a software product. Given a list of precollected API methods that output values of their string argument variables to the GUI and the source code of the software product under analysis, our approach traces from the invocation sites (within the source code) of these methods back to the need-to-externalize constant strings using generalized string-taint analysis. In our empirical evaluation, we used our approach to locate need-to-externalize constant strings in the uninternationalized versions of seven real-world open source software products. The results of our evaluation demonstrate that our approach is able to effectively locate need-to-externalize constant strings in uninternationalized software products. Furthermore, to help developers understand why a constant string requires translation and properly translate the need-to-externalize strings, we provide visual representation of the string dependencies related to the need-to-externalize strings.",1939-3520,,10.1109/TSE.2012.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216383,Software internationalization;need-to-externalize constant strings;string-taint analysis,Software;Graphical user interfaces;Prototypes;Java;Libraries;Production;Globalization,globalisation;graphical user interfaces;public domain software;software engineering,need-to-externalize constant string location;software internationalization;generalized string-taint analysis;user requirement;internationalized software product;user-visible hard-coded constant string;software development process;graphical user interface;GUI;data flow;API method;application program interface;string argument variable;open source software product;string dependency,,6.0,,31.0,,12 Jun 2012,,,IEEE,IEEE Journals
366,367,Improving Source Code Lexicon via Traceability and Information Retrieval,A. De Lucia; M. Di Penta; R. Oliveto,"University of Salerno, Fisciano; University of Sannio, Benevento; University of Molise, Pesche",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,205,227,"The paper presents an approach helping developers to maintain source code identifiers and comments consistent with high-level artifacts. Specifically, the approach computes and shows the textual similarity between source code and related high-level artifacts. Our conjecture is that developers are induced to improve the source code lexicon, i.e., terms used in identifiers or comments, if the software development environment provides information about the textual similarity between the source code under development and the related high-level artifacts. The proposed approach also recommends candidate identifiers built from high-level artifacts related to the source code under development and has been implemented as an Eclipse plug-in, called COde Comprehension Nurturant Using Traceability (COCONUT). The paper also reports on two controlled experiments performed with master's and bachelor's students. The goal of the experiments is to evaluate the quality of identifiers and comments (in terms of their consistency with high-level artifacts) in the source code produced when using or not using COCONUT. The achieved results confirm our conjecture that providing the developers with similarity between code and high-level artifacts helps to improve the quality of source code lexicon. This indicates the potential usefulness of COCONUT as a feature for software development environments.",1939-3520,,10.1109/TSE.2010.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5601742,Software traceability;source code comprehensibility;source code identifier quality;information retrieval;software development environments;empirical software engineering.,Documentation;Programming;Large scale integration;Semantics;Software quality;Couplings,information retrieval;program diagnostics;software quality,source code lexicon;information retrieval;textual similarity;high level artifact;software development;candidate identifier;code comprehension nurturant using traceability;COCONUT;bachelor student;master student,,40.0,2.0,72.0,,14 Oct 2010,,,IEEE,IEEE Journals
367,368,Reasoning About Identifier Spaces: How to Make Chord Correct,P. Zave,"AT&T Laboratories—Research, Bedminster, NJ",IEEE Transactions on Software Engineering,8 Dec 2017,2017,43,12,1144,1156,"The Chord distributed hash table (DHT) is well-known and often used to implement peer-to-peer systems. Chord peers find other peers, and access their data, through a ring-shaped pointer structure in a large identifier space. Despite claims of proven correctness, i.e., eventual reachability, previous work has shown that the Chord ring-maintenance protocol is not correct under its original operating assumptions. Previous work has not, however, discovered whether Chord could be made correct under the same assumptions. The contribution of this paper is to provide the first specification of correct operations and initialization for Chord, an inductive invariant that is necessary and sufficient to support a proof of correctness, and two independent proofs of correctness. One proof is informal and intuitive, and applies to networks of any size. The other proof is based on a formal model in Alloy, and uses fully automated analysis to prove the assertions for networks of bounded size. The two proofs complement each other in several important ways.",1939-3520,,10.1109/TSE.2017.2655056,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7823003,Computers and information processing;distributed computing;peer-to-peer computing;software engineering;formal verification,Peer-to-peer computing;Formal verification;Information processing;Analytical models;Structural rings;Distributed processing,peer-to-peer computing;protocols;telecommunication network topology,hash table;peer-to-peer systems;Chord peers;ring-shaped pointer structure;identifier space;Chord ring-maintenance protocol,,4.0,,33.0,Traditional,18 Jan 2017,,,IEEE,IEEE Journals
368,369,Modeling Human-in-the-Loop Security Analysis and Decision-Making Processes,M. A. Schumann; D. Drusinsky; J. B. Michael; D. Wijesekera,"KEYW Corporation, 7740 Milestone Pkwy, Suite 400, Hanover; Department of Computer Science , Naval Postgraduate School, Monterey; Departments of Computer Science and Electrical & Computer Engineering, Naval Postgraduate School, 900 N Glebe Road, Arlington; Department of Computer Science , George Mason University, Fairfax",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,2,154,166,"This paper presents a novel application of computer-assisted formal methods for systematically specifying, documenting, statically and dynamically checking, and maintaining human-centered workflow processes. This approach provides for end-to-end verification and validation of process workflows, which is needed for process workflows that are intended for use in developing and maintaining high-integrity systems. We demonstrate the technical feasibility of our approach by applying it on the development of the US government's process workflow for implementing, certifying, and accrediting cross-domain computer security solutions. Our approach involves identifying human-in-the-loop decision points in the process activities and then modeling these via statechart assertions. We developed techniques to specify and enforce workflow hierarchies, which was a challenge due to the existence of concurrent activities within complex workflow processes. Some of the key advantages of our approach are: it results in development of a model that is executable, supporting both upfront and runtime checking of process-workflow requirements; aids comprehension and communication among stakeholders and process engineers; and provides for incorporating accountability and risk management into the engineering of process workflows.",1939-3520,,10.1109/TSE.2014.2302433,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6727512,Formal methods;information assurance;process modeling;software engineering;statechart assertions;verification and validation,Unified modeling language;Object oriented modeling;Software;Runtime;Formal specifications;Analytical models;Business,decision making;formal specification;formal verification;government data processing;security of data;workflow management software,human-in-the-loop security analysis;decision-making process;computer-assisted formal methods;human-centered workflow process;process specification;process documentation;process statically checking;process dynamically checking;process maintenance;end-to-end verification;end-to-end validation;high-integrity systems;US government process workflow;United States;cross-domain computer security solutions;human-in-the-loop decision points;process activities;statechart assertions;workflow hierarchies;accountability;risk management;process workflows engineering,,5.0,,44.0,,28 Jan 2014,,,IEEE,IEEE Journals
369,370,Effects of Developer Experience on Learning and Applying Unit Test-Driven Development,R. Latorre,"Universidad Autónoma de Madrid, Madrid, Spain",IEEE Transactions on Software Engineering,2 May 2014,2014,40,4,381,395,"Unit test-driven development (UTDD) is a software development practice where unit test cases are specified iteratively and incrementally before production code. In the last years, researchers have conducted several studies within academia and industry on the effectiveness of this software development practice. They have investigated its utility as compared to other development techniques, focusing mainly on code quality and productivity. This quasi-experiment analyzes the influence of the developers' experience level on the ability to learn and apply UTDD. The ability to apply UTDD is measured in terms of process conformance and development time. From the research point of view, our goal is to evaluate how difficult is learning UTDD by professionals without any prior experience in this technique. From the industrial point of view, the goal is to evaluate the possibility of using this software development practice as an effective solution to take into account in real projects. Our results suggest that skilled developers are able to quickly learn the UTDD concepts and, after practicing them for a short while, become as effective in performing small programming tasks as compared to more traditional test-last development techniques. Junior programmers differ only in their ability to discover the best design, and this translates into a performance penalty since they need to revise their design choices more frequently than senior programmers.",1939-3520,,10.1109/TSE.2013.2295827,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6690135,Test-driven development;test-first design;software engineering process;software quality/SQA;software construction;process conformance;programmer productivity,Software;Testing;Training;Programming profession;Context;Production,learning (artificial intelligence);program testing;software quality,learning;unit test-driven development;UTDD;software development;code quality;productivity,,12.0,,44.0,,20 Dec 2013,,,IEEE,IEEE Journals
370,371,Software Development Estimation Biases: The Role of Interdependence,M. Jorgensen; S. Grimstad,"University of Oslo, Lysaker; University of Oslo, Lysaker",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,677,693,"Software development effort estimates are frequently too low, which may lead to poor project plans and project failures. One reason for this bias seems to be that the effort estimates produced by software developers are affected by information that has no relevance for the actual use of effort. We attempted to acquire a better understanding of the underlying mechanisms and the robustness of this type of estimation bias. For this purpose, we hired 374 software developers working in outsourcing companies to participate in a set of three experiments. The experiments examined the connection between estimation bias and developer dimensions: self-construal (how one sees oneself), thinking style, nationality, experience, skill, education, sex, and organizational role. We found that estimation bias was present along most of the studied dimensions. The most interesting finding may be that the estimation bias increased significantly with higher levels of interdependence, i.e., with stronger emphasis on connectedness, social context, and relationships. We propose that this connection may be enabled by an activation of one's self-construal when engaging in effort estimation, and a connection between a more interdependent self-construal and increased search for indirect messages, lower ability to ignore irrelevant context, and a stronger emphasis on socially desirable responses.",1939-3520,,10.1109/TSE.2011.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6193066,Effort estimation;estimation bias;cultural differences;software engineering.,Estimation;Software;Companies;Context;Programming;Outsourcing;Instruments,estimation theory;software management,software development estimation;interdependence role;project failures;project plans;outsourcing companies,,13.0,,48.0,,1 May 2012,,,IEEE,IEEE Journals
371,372,Requirements Elicitation and Specification Using the Agent Paradigm: The Case Study of an Aircraft Turnaround Simulator,T. Miller; B. Lu; L. Sterling; G. Beydoun; K. Taveter,"Department of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria, Autralia; Department of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria, Autralia; Faculty of ICT, Swinburne University of Technology, Melbourne, Victoria, Autralia; Faculty of Informatics, University of Wollongong, Wollongong, NSW 2522, Australia; Institute of Informatics, Tallinn University of Technology, Tallinn, EU, Estonia",IEEE Transactions on Software Engineering,9 Oct 2014,2014,40,10,1007,1024,"In this paper, we describe research results arising from a technology transfer exercise on agent-oriented requirements engineering with an industry partner. We introduce two improvements to the state-of-the-art in agent-oriented requirements engineering, designed to mitigate two problems experienced by ourselves and our industry partner: (1) the lack of systematic methods for agent-oriented requirements elicitation and modelling; and (2) the lack of prescribed deliverables in agent-oriented requirements engineering. We discuss the application of our new approach to an aircraft turnaround simulator built in conjunction with our industry partner, and show how agent-oriented models can be derived and used to construct a complete requirements package. We evaluate this by having three independent people design and implement prototypes of the aircraft turnaround simulator, and comparing the three prototypes. Our evaluation indicates that our approach is effective at delivering correct, complete, and consistent requirements that satisfy the stakeholders, and can be used in a repeatable manner to produce designs and implementations. We discuss lessons learnt from applying this approach.",1939-3520,,10.1109/TSE.2014.2339827,Australian Research Council Linkage; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6860260,Agent-oriented software engineering;agent-oriented modelling;technology transfer,Object oriented modeling;Aircraft;Atmospheric modeling;Software;Industries;Analytical models;Educational institutions,aerospace computing;aircraft;formal specification;multi-agent systems;object-oriented programming;software agents,requirements elicitation;requirements specification;agent paradigm;aircraft turnaround simulator;agent oriented requirements engineering;industry partner;systematic methods;agent-oriented requirements elicitation;agent-oriented requirement modelling;independent people design,,23.0,,46.0,,18 Jul 2014,,,IEEE,IEEE Journals
372,373,Coping with Existing Systems in Information Systems Development,F. Zickert; R. Beck,"Goethe University Frankfurt, Frankfurt; Goethe University Frankfurt, Frankfurt",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1027,1039,"Determining how to cope with existing systems is an important issue for information systems development (ISD). In this paper, we investigate how well different ISD patterns are suited for coping with existing systems. Empirical results, gathered from three software development projects undertaken by a financial institution, suggest propositions regarding how ISD patterns and existing systems affect the characteristics of objective ISD complexity, which in turn determine overall experienced complexity. Existing systems increase complexity due to conflicting interdependencies, but ISD patterns that reduce this complexity, such as those that employ bottom-up or concurrent consideration patterns, are best suited for coping with existing systems. In contrast, top-down and iterative focusing patterns, as classically used in new development, increase the complexity associated with conflicting interdependency, which makes them particularly unsuited for coping with existing systems in ISD.",1939-3520,,10.1109/TSE.2011.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999674,Complexity measures;improvements;software maintenance;software engineering process,Complexity theory;Information systems;Maintenance engineering;Software maintenance;File systems;Programming;Servers,financial data processing;information systems;investment;project management;software maintenance;software metrics,information systems development;ISD patterns;software development projects;financial institution;complexity reduction;bottom-up patterns;concurrent consideration patterns;top-down focusing patterns;iterative focusing patterns;information systems portfolio;complexity measures;software maintenance,,,,73.0,,25 Aug 2011,,,IEEE,IEEE Journals
373,374,A Theoretical and Empirical Analysis of the Role of Test Sequence Length in Software Testing for Structural Coverage,A. Arcuri,"Simula Research Laboratory, Lysaker",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,497,519,"In the presence of an internal state, often a sequence of function calls is required to test software. In fact, to cover a particular branch of the code, a sequence of previous function calls might be required to put the internal state in the appropriate configuration. Internal states are not only present in object-oriented software, but also in procedural software (e.g., static variables in C programs). In the literature, there are many techniques to test this type of software. However, to the best of our knowledge, the properties related to the choice of the length of these sequences have received only a little attention in the literature. In this paper, we analyze the role that the length plays in software testing, in particular branch coverage. We show that, on “difficult” software testing benchmarks, longer test sequences make their testing trivial. Hence, we argue that the choice of the length of the test sequences is very important in software testing. Theoretical analyses and empirical studies on widely used benchmarks and on an industrial software are carried out to support our claims.",1939-3520,,10.1109/TSE.2011.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750005,Evolutionary testing;object-oriented software;state problem;search-based software engineering;software testing;length;test sequence.,Software;Containers;Software testing;Algorithm design and analysis;Search problems;Software algorithms,C language;object-oriented programming;program testing,empirical analysis;theoretical analysis;test sequence length;software testing;structural coverage;internal state;function calls;object-oriented software;procedural software;C programs;static variables;test sequences,,19.0,,40.0,,15 Apr 2011,,,IEEE,IEEE Journals
374,375,Supporting the Combined Selection of Model-Based Testing Techniques,A. C. Dias-Neto; G. H. Travassos,"Institute of Computing, Federal University of Amazonas, Manaus, Brazil; Systems Engineering and Computer Science Programme at COPPE, Federal University of Rio de Janeiro, Rio de Janeiro , Brazil",IEEE Transactions on Software Engineering,9 Oct 2014,2014,40,10,1025,1041,"The technical literature on model-based testing (MBT) offers us several techniques with different characteristics and goals. Contemporary software projects usually need to make use of different software testing techniques. However, a lack of empirical information regarding their scalability and effectiveness is observed. It makes their application difficult in real projects, increasing the technical difficulties to combine two or more MBT techniques for the same software project. In addition, current software testing selection approaches offer limited support for the combined selection of techniques. Therefore, this paper describes the conception and evaluation of an approach aimed at supporting the combined selection of MBT techniques for software projects. It consists of an evidence-based body of knowledge with 219 MBT techniques and their corresponding characteristics and a selection process that provides indicators on the level of adequacy (impact indicator) amongst MBT techniques and software projects characteristics. Results from the data analysis indicate it contributes to improve the effectiveness and efficiency of the selection process when compared to another selection approach available in the technical literature. Aiming at facilitating its use, a computerized infrastructure, evaluated into an industrial context and evolved to implement all the facilities needed to support such selection approach, is presented.",1939-3520,,10.1109/TSE.2014.2312915,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6776497,Software testing;model-based testing;software technology selection;recommendation system;experimental software engineering,Software testing;Context;Computational modeling;Organizations;Software quality,program testing;project management;software development management,model-based testing techniques;technical literature;software projects;software testing techniques;MBT techniques;software testing selection;impact indicator;software project characteristics;data analysis;computerized infrastructure,,10.0,,39.0,,20 Mar 2014,,,IEEE,IEEE Journals
375,376,Generating Test Data from OCL Constraints with Search Techniques,S. Ali; M. Zohaib Iqbal; A. Arcuri; L. C. Briand,"Simula Research Lab, Norway; National University of Computer and Emerging Sciences, Islamabad and University of Luxembourg, Luxembourg; Simula Research Lab, Norway; University of Luxembourg, Luxembourg",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1376,1402,"Model-based testing (MBT) aims at automated, scalable, and systematic testing solutions for complex industrial software systems. To increase chances of adoption in industrial contexts, software systems can be modeled using well-established standards such as the Unified Modeling Language (UML) and the Object Constraint Language (OCL). Given that test data generation is one of the major challenges to automate MBT, we focus on test data generation from OCL constraints in this paper. This endeavor is all the more challenging given the numerous OCL constructs and operations that are designed to facilitate the definition of constraints. Though search-based software testing has been applied to test data generation for white-box testing (e.g., branch coverage), its application to the MBT of industrial software systems has been limited. In this paper, we propose a set of search heuristics targeted to OCL constraints to guide test data generation and automate MBT in industrial applications. We evaluate these heuristics for three search algorithms: Genetic Algorithm, (1+1) Evolutionary Algorithm, and Alternating Variable Method. We empirically evaluate our heuristics using complex artificial problems, followed by empirical analyses of the feasibility of our approach on one industrial system in the context of robustness testing. Our approach is also compared with the most widely referenced OCL solver (UMLtoCSP) in the literature and shows to be significantly more efficient.",1939-3520,,10.1109/TSE.2013.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6491405,OCL;search-based testing;test data generation;empirical evaluation;search-based software engineering;model-based testing,Unified modeling language;Search problems;Software algorithms;Genetic algorithms;Standards;Software testing,genetic algorithms;program testing;specification languages,test data generation;OCL constraints;search techniques;model-based testing;MBT;industrial software systems;object constraint language;unified modeling language;UML;OCL constructs;OCL operations;search-based software testing;white-box testing;genetic algorithm;one-plus-one evolutionary algorithm;alternating variable method;empirical analysis;robustness testing context;UMLtoCSP OCL solver,,71.0,,75.0,,1 Apr 2013,,,IEEE,IEEE Journals
376,377,Incremental Test Generation for Software Product Lines,E. Uzuncaova; S. Khurshid; D. Batory,"Microsoft, Redmond; University of Texas at Austin, Austin; University of Texas at Austin, Austin",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,309,322,"Recent advances in mechanical techniques for systematic testing have increased our ability to automatically find subtle bugs, and hence, to deploy more dependable software. This paper builds on one such systematic technique, scope-bounded testing, to develop a novel specification-based approach for efficiently generating tests for products in a software product line. Given properties of features as first-order logic formulas in Alloy, our approach uses SAT-based analysis to automatically generate test inputs for each product in a product line. To ensure soundness of generation, we introduce an automatic technique for mapping a formula that specifies a feature into a transformation that defines incremental refinement of test suites. Our experimental results using different data structure product lines show that an incremental approach can provide an order of magnitude speedup over conventional techniques. We also present a further optimization using dedicated integer constraint solvers for feature properties that introduce integer constraints, and show how to use a combination of solvers in tandem for solving Alloy formulas.",1939-3520,,10.1109/TSE.2010.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5456077,Software/program verification;testing and debugging;software engineering.,Software testing;Automatic testing;System testing;Computer bugs;Logic testing;Data structures;Software quality;Automatic logic units;Acoustic testing;Constraint optimization,computability;data structures;program testing;program verification,incremental test generation;software product lines;mechanical techniques;systematic testing;scope-bounded testing;specification-based approach;first-order logic formulas;SAT-based analysis;data structure product lines;dedicated integer constraint solvers;Alloy formulas;program verification,,49.0,,60.0,,29 Apr 2010,,,IEEE,IEEE Journals
377,378,SMT-Based Bounded Model Checking for Embedded ANSI-C Software,L. Cordeiro; B. Fischer; J. Marques-Silva,"Federal University of Amazonas, Brazil; University of Southampton, Southampton; University College Dublin, Dublin",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,957,974,"Propositional bounded model checking has been applied successfully to verify embedded software, but remains limited by increasing propositional formula sizes and the loss of high-level information during the translation preventing potential optimizations to reduce the state space to be explored. These limitations can be overcome by encoding high-level information in theories richer than propositional logic and using SMT solvers for the generated verification conditions. Here, we propose the application of different background theories and SMT solvers to the verification of embedded software written in ANSI-C in order to improve scalability and precision in a completely automatic way. We have modified and extended the encodings from previous SMT-based bounded model checkers to provide more accurate support for variables of finite bit width, bit-vector operations, arrays, structures, unions, and pointers. We have integrated the CVC3, Boolector, and Z3 solvers with the CBMC front-end and evaluated them using both standard software model checking benchmarks and typical embedded software applications from telecommunications, control systems, and medical devices. The experiments show that our ESBMC model checker can analyze larger problems than existing tools and substantially reduce the verification time.",1939-3520,,10.1109/TSE.2011.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928354,Software engineering;formal methods;verification;model checking,Encoding;Embedded software;Safety;Space exploration;Optimization;Electronic mail,embedded systems;formal verification,SMT based bounded model checking;embedded ANSI-C software;embedded software verification;SMT solvers;model checkers;software model checking benchmarks,,74.0,1.0,64.0,,23 Jun 2011,,,IEEE,IEEE Journals
378,379,How Social and Communication Channels Shape and Challenge a Participatory Culture in Software Development,M. Storey; A. Zagalsky; F. F. Filho; L. Singer; D. M. German,"University of Victoria, Victoria, BC, Canada; University of Victoria, Victoria, BC, Canada; Universidade Federal do Rio Grande do Norte, Natal, Brazil; University of Victoria, Victoria, BC, Canada; University of Victoria, Victoria, BC, Canada",IEEE Transactions on Software Engineering,13 Feb 2017,2017,43,2,185,204,"Software developers use many different communication tools and channels in their work. The diversity of these tools has dramatically increased over the past decade and developers now have access to a wide range of socially enabled communication channels and social media to support their activities. The availability of such social tools is leading to a participatory culture of software development, where developers want to engage with, learn from, and co-create software with other developers. However, the interplay of these social channels, as well as the opportunities and challenges they may create when used together within this participatory development culture are not yet well understood. In this paper, we report on a large-scale survey conducted with 1,449 GitHub users. We discuss the channels these developers find essential to their work and gain an understanding of the challenges they face using them. Our findings lay the empirical foundation for providing recommendations to developers and tool designers on how to use and improve tools for software developers.",1939-3520,,10.1109/TSE.2016.2584053,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498605,Participatory culture;communication;social media;CSCW;software engineering,Software;Communication channels;Media;Collaboration;Electronic mail;Face;Knowledge engineering,cultural aspects;professional communication;social networking (online);software development management;team working,social channels;software development;participatory culture;communication tools;socially enabled communication channels;social media;social tools;GitHub users;software developers,,53.0,,41.0,,23 Jun 2016,,,IEEE,IEEE Journals
379,380,Using Dependency Structures for Prioritization of Functional Test Suites,S. Haidry; T. Miller,"University of Melbourne, Parkville; University of Melbourne, Parkville",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,258,275,"Test case prioritization is the process of ordering the execution of test cases to achieve a certain goal, such as increasing the rate of fault detection. Increasing the rate of fault detection can provide earlier feedback to system developers, improving fault fixing activity and, ultimately, software delivery. Many existing test case prioritization techniques consider that tests can be run in any order. However, due to functional dependencies that may exist between some test cases-that is, one test case must be executed before another-this is often not the case. In this paper, we present a family of test case prioritization techniques that use the dependency information from a test suite to prioritize that test suite. The nature of the techniques preserves the dependencies in the test ordering. The hypothesis of this work is that dependencies between tests are representative of interactions in the system under test, and executing complex interactions earlier is likely to increase the fault detection rate, compared to arbitrary test orderings. Empirical evaluations on six systems built toward industry use demonstrate that these techniques increase the rate of fault detection compared to the rates achieved by the untreated order, random orders, and test suites ordered using existing ""coarse-grained” techniques based on function coverage.",1939-3520,,10.1109/TSE.2012.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6189361,Software engineering;testing and debugging;test execution,Fault detection;Digital signal processing;Schedules;Software;Complexity theory;Testing;Weight measurement,program debugging;program testing;software fault tolerance;software process improvement,dependency structures;functional test suite prioritization;test case execution ordering;fault detection rate;system developers;fault fixing improvement;software delivery;functional dependencies;test case prioritization technique;dependency information;system under test;software debugging,,29.0,,31.0,,24 Apr 2012,,,IEEE,IEEE Journals
380,381,Governing Software Process Improvementsin Globally Distributed Product Development,N. Ramasubbu,"Joseph M. Katz Graduate School of Business, University of Pittsburgh, 354 Mervis Hall, Pittsburgh",IEEE Transactions on Software Engineering,31 Mar 2014,2014,40,3,235,250,"Continuous software process improvement (SPI) practices have been extensively prescribed to improve performance of software projects. However, SPI implementation mechanisms have received little scholarly attention, especially in the context of distributed software product development. We took an action research approach to study the SPI journey of a large multinational enterprise that adopted a distributed product development strategy. We describe the interventions and action research cycles enacted over a period of five years in collaboration with the firm, which resulted in a custom SPI framework that catered to both the social and technical needs of the firm's distributed teams. Institutionalizing the process maturity framework got stalled initially because the SPI initiatives were perceived by product line managers as a mechanism for exercising wider controls by the firm's top management. The implementation mechanism was subsequently altered to co-opt product line managers, which contributed to a wider adoption of the SPI framework. Insights that emerge from our analysis of the firm's SPI journey pertain to the integration of the technical and social views of software development, preserving process diversity through the use of a multi-tiered, non-blueprint approach to SPI, the linkage between key process areas and project control modes, and the role of SPI in aiding organizational learning.",1939-3520,,10.1109/TSE.2013.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682900,Software process improvement (SPI);distributed teams;software engineering;process control;action research,Software;Product development;Process control;Benchmark testing;ISO standards;Resource management;Quality management,software management;software process improvement;software product lines,software process improvements;globally distributed software product development strategy;software project performance;large multinational enterprise;custom SPI framework;process maturity framework;product line managers;firm top management;multitiered nonblueprint approach;project control modes;organizational learning;action research approach,,42.0,,93.0,,12 Dec 2013,,,IEEE,IEEE Journals
381,382,Swarm Verification Techniques,G. J. Holzmann; R. Joshi; A. Groce,"California Institute of Technology, Pasadena; California Institute of Technology, Pasadena; Oregon State University, Corvallis",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,845,857,"The range of verification problems that can be solved with logic model checking tools has increased significantly in the last few decades. This increase in capability is based on algorithmic advances and new theoretical insights, but it has also benefitted from the steady increase in processing speeds and main memory sizes on standard computers. The steady increase in processing speeds, though, ended when chip-makers started redirecting their efforts to the development of multicore systems. For the near-term future, we can anticipate the appearance of systems with large numbers of CPU cores, but without matching increases in clock-speeds. We will describe a model checking strategy that can allow us to leverage this trend and that allows us to tackle significantly larger problem sizes than before.",1939-3520,,10.1109/TSE.2010.110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661793,Software engineering tools and techniques;logic model checking;distributed algorithms;software verification.,Memory management;Formal verification;Search problems;Computational modeling;Multicore processing;Data models;Parallel processing,formal verification;multiprocessing systems,swarm verification techniques;logic model checking tools;multicore system development;CPU cores,,49.0,,22.0,,10 Dec 2010,,,IEEE,IEEE Journals
382,383,Verifying Protocol Conformance Using Software Model Checking for the Model-Driven Development of Embedded Systems,Y. Moffett; J. Dingel; A. Beaulieu,"CF 18 Avionics System Engineering, Ottawa; Queens University, Kingston; Royal Military College, Kingston",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1307,13256,"To facilitate modular development, the use of state machines has been proposed to specify the protocol (i.e., the sequence of messages) that each port of a component can engage in. The protocol conformance checking problem consists of determining whether the actual behavior of a component conforms to the protocol specifications on its ports. In this paper, we consider this problem in the context of the model-driven development (MDD) of embedded systems based on UML 2, in which UML 2 state machines are used to specify component behavior. We provide a definition of conformance which slightly extends those found in the literature and reduce the conformance check to a state space exploration. We describe a tool implementing the approach using the Java PathFinder software model checker and the MDD tool IBM Rational RoseRT, discuss its application to three case studies, and show how the tool repeatedly allowed us to find unexpected conformance errors with encouraging performance. We conclude that the approach is promising for supporting the modular development of embedded components in the context of industrial applications of MDD.",1939-3520,,10.1109/TSE.2013.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6482140,Component-based software engineering;behavioral interface specifications;software modeling;model-driven development;formal specification and verification;software model checking,Unified modeling language;Protocols;Ports (Computers);Software;Safety;Context;Java,embedded systems;formal verification;object-oriented programming;Unified Modeling Language,protocol conformance verification;software model checking;model-driven development;embedded system;protocol conformance checking problem;UML 2 state machines;Unified Modeling Language;state space exploration;Java PathFinder software model checker;IBM Rational RoseRT MDD tool;MDD industrial application,,2.0,,47.0,,19 Mar 2013,,,IEEE,IEEE Journals
383,384,Construction and Validation of an Instrument for Measuring Programming Skill,G. R. Bergersen; D. I. K. Sjøberg; T. Dybå,"Department of Informatics, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo, Oslo, Norway; Department of Informatics, University of Oslo and SINTEF, Norway",IEEE Transactions on Software Engineering,12 Dec 2014,2014,40,12,1163,1184,"Skilled workers are crucial to the success of software development. The current practice in research and industry for assessing programming skills is mostly to use proxy variables of skill, such as education, experience, and multiple-choice knowledge tests. There is as yet no valid and efficient way to measure programming skill. The aim of this research is to develop a valid instrument that measures programming skill by inferring skill directly from the performance on programming tasks. Over two days, 65 professional developers from eight countries solved 19 Java programming tasks. Based on the developers' performance, the Rasch measurement model was used to construct the instrument. The instrument was found to have satisfactory (internal) psychometric properties and correlated with external variables in compliance with theoretical expectations. Such an instrument has many implications for practice, for example, in job recruitment and project allocation.",1939-3520,,10.1109/TSE.2014.2348997,Research Laboratory and the Research Council of Norway through; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6882243,Skill;programming;performance;instrument;measurement;empirical software engineering,Programming profession;Software development;Personnel;Software quality;Software design,Java;personnel;software development management,programming skill measurement;skilled workers;software development;proxy variables;multiple-choice knowledge tests;programming tasks;professional developers;Java programming tasks;Rasch measurement model;psychometric properties;job recruitment;project allocation,,22.0,,130.0,,22 Aug 2014,,,IEEE,IEEE Journals
384,385,Coordination Breakdowns and Their Impact on Development Productivity and Software Failures,M. Cataldo; J. D. Herbsleb,"Robert Bosch LLC; Carnegie Mellon University, Pittsburgh",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,343,360,"The success of software development projects depends on carefully coordinating the effort of many individuals across the multiple stages of the development process. In software engineering, modularization is the traditional technique intended to reduce the interdependencies among modules that constitute a system. Reducing technical dependencies, the theory argues, results in a reduction of work dependencies between teams developing interdependent modules. Although that research stream has been quite influential, it considers a static view of the problem of coordination in engineering activities. Building on a dynamic view of coordination, we studied the relationship between socio-technical congruence and software quality and development productivity. In order to investigate the generality of our findings, our analyses were performed on two large-scale projects from two companies with distinct characteristics in terms of product and process maturity. Our results revealed that the gaps between coordination requirements and the actual coordination activities carried out by the developers significantly increased software failures. Our analyses also showed that higher levels of congruence are associated with improved development productivity. Finally, our results showed the congruence between dependencies and coordinative actions is critical both in mature development settings as well as in novel and dynamic development contexts.",1939-3520,,10.1109/TSE.2012.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6205767,Metrics/measurement;productivity;organizational management and coordination;quality analysis and evaluation,Productivity;Programming;Software quality;Context;Complexity theory;Organizations,software metrics;software quality;software reliability,coordination breakdowns;development productivity;software failures;software development projects;development process;software engineering;modularization;technical dependency;work dependency;interdependent modules;engineering activity;socio-technical congruence;software quality;large-scale projects;product maturity;process maturity;coordination requirements;coordination activity;dynamic development contexts,,60.0,,78.0,,29 May 2012,,,IEEE,IEEE Journals
385,386,On the Effectiveness of Contracts as Test Oracles in the Detection and Diagnosis of Functional Faults in Concurrent Object-Oriented Software,W. Araujo; L. C. Briand; Y. Labiche,"Juniper Networks, 1194 N Mathilda Ave, Sunnyvale, CA 94089; SnT Centre, University of Luxembourg, 6, rue Richard Coudenhove-Kalergi, L-1359 Luxembourg-Kirchberg, Luxembourg; Systems and Computer Engineering Department, Carleton University, 1125 Colonel By Drive, Ottawa, Canada",IEEE Transactions on Software Engineering,9 Oct 2014,2014,40,10,971,992,"Design by contract (DbC) is a software development methodology that focuses on clearly defining the interfaces between components to produce better quality object-oriented software. Though there exists ample support for DbC for sequential programs, applying DbC to concurrent programs presents several challenges. Using Java as the target programming language, we tackle such challenges by augmenting the Java Modelling Language (JML) and modifying the JML compiler (jmlc) to generate runtime assertion checking code to support DbC in concurrent programs. We applied our solution in a carefully designed case study on a highly concurrent industrial software system from the telecommunications domain to assess the effectiveness of contracts as test oracles in detecting and diagnosing functional faults in concurrent software. Based on these results, clear and objective requirements are defined for contracts to be effective test oracles for concurrent programs whilst balancing the effort to design them. Effort is measured indirectly through the contract complexity measure (CCM), a measure we define. Main results include that contracts of a realistic level of completeness and complexity can detect around 76 percent of faults and reduce the diagnosis effort for such faults tenfold. We, therefore, show that DbC can be applied to concurrent software and can be a valuable tool to improve the economics of software engineering.",1939-3520,,10.1109/TSE.2014.2339829,Juniper Networks; Luxembourg's National Research Fund; NSERC Discovery; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6857355,Software/Program Verification¿Programming by contract;Software Quality/SQA¿Measurement applied to SQA and V&V;Concurrent programming;object-oriented programming,Contracts;Java;Concurrent computing;Programming;Software;Message systems;Interference,concurrency control;contracts;fault diagnosis;Java;object-oriented methods;parallel programming;program compilers;program testing;software quality;software reliability,design by contract;software development methodology;object-oriented software quality;DbC;sequential programs;concurrent programs;target programming language;Java modelling language;JML compiler;JMLC;runtime assertion checking code;concurrent industrial software system;telecommunication domain;test oracles;functional fault diagnosing;functional fault detection;concurrent software;contract complexity measure;CCM;software engineering,,7.0,,39.0,,16 Jul 2014,,,IEEE,IEEE Journals
386,387,A Survey on Load Testing of Large-Scale Software Systems,Z. M. Jiang; A. E. Hassan,"Department of Electrical Engineering and Computer ScienceSoftware Construction, AnaLytics and Evaluation (SCALE) Lab, York University, Toronto, ON, Canada; Software Analysis and Intelligence (SAIL) Lab, School of Computing, Kingston, ON, Canada",IEEE Transactions on Software Engineering,10 Nov 2015,2015,41,11,1091,1118,"Many large-scale software systems must service thousands or millions of concurrent requests. These systems must be load tested to ensure that they can function correctly under load (i.e., the rate of the incoming requests). In this paper, we survey the state of load testing research and practice. We compare and contrast current techniques that are used in the three phases of a load test: (1) designing a proper load, (2) executing a load test, and (3) analyzing the results of a load test. This survey will be useful for load testing practitioners and software engineering researchers with interest in the load testing of large-scale software systems.",1939-3520,,10.1109/TSE.2015.2445340,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7123673,Software Testing;Load Testing;Software Quality;Software testing;load testing;software quality;large-scale software systems;survey,Testing;Stress;Computer bugs;Robustness;Software systems;Stress measurement,program testing;software quality,load testing;large-scale software systems;concurrent requests;load testing research;contrast current techniques;software engineering researchers,,45.0,,196.0,,15 Jun 2015,,,IEEE,IEEE Journals
387,388,On the Evolution of Services,V. Andrikopoulos; S. Benbernou; M. P. Papazoglou,"IAAS, University of Stuttgart, Stuttgart; Université Paris Descartes, Paris; ERISS, Tilburg University, Tilburg",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,609,628,"In an environment of constant change and variation driven by competition and innovation, a software service can rarely remain stable. Being able to manage and control the evolution of services is therefore an important goal for the Service-Oriented paradigm. This work extends existing and widely adopted theories from software engineering, programming languages, service-oriented computing, and other related fields to provide the fundamental ingredients required to guarantee that spurious results and inconsistencies that may occur due to uncontrolled service changes are avoided. The paper provides a unifying theoretical framework for controlling the evolution of services that deals with structural, behavioral, and QoS level-induced service changes in a type-safe manner, ensuring correct versioning transitions so that previous clients can use a versioned service in a consistent manner.",1939-3520,,10.1109/TSE.2011.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728828,Services engineering;service evolution;versioning;service compatibility.,XML;Guidelines;Protocols;Business;Availability;Quality of service;Software,service-oriented architecture;Web services,software service;service-oriented paradigm;software engineering;programming languages;service-oriented computing,,75.0,,55.0,,10 Mar 2011,,,IEEE,IEEE Journals
388,389,Does Software Process Improvement Reduce the Severity of Defects? A Longitudinal Field Study,D. E. Harter; C. F. Kemerer; S. A. Slaughter,"Syracuse University, Syracuse; University of Pittsburgh, Pittsburgh and King Abdul Aziz University, Saudi Arabia; Georgia Institute of Technology, Atlanta",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,810,827,"As firms increasingly rely on information systems to perform critical functions, the consequences of software defects can be catastrophic. Although the software engineering literature suggests that software process improvement can help to reduce software defects, the actual evidence is equivocal. For example, improved development processes may only remove the “easier” syntactical defects, while the more critical defects remain. Rigorous empirical analyses of these relationships have been very difficult to conduct due to the difficulties in collecting the appropriate data on real systems from industrial organizations. This field study analyzes a detailed data set consisting of 7,545 software defects that were collected on software projects completed at a major software firm. Our analyses reveal that higher levels of software process improvement significantly reduce the likelihood of high severity defects. In addition, we find that higher levels of process improvement are even more beneficial in reducing severe defects when the system developed is large or complex, but are less beneficial in development when requirements are ambiguous, unclear, or incomplete. Our findings reveal the benefits and limitations of software process improvement for the removal of severe defects and suggest where investments in improving development processes may have their greatest effects.",1939-3520,,10.1109/TSE.2011.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928358,Software complexity;defect severity;requirements ambiguity;software process;CMM,Complexity theory;Production;Coordinate measuring machines;Testing;Software quality;Programming,program debugging;software process improvement,software process improvement;longitudinal field study;information systems;software defects;software engineering literature;syntactical defects;critical defects;severe defects,,29.0,,68.0,,23 Jun 2011,,,IEEE,IEEE Journals
389,390,"Embedding, Evolution, and Validation of Model-Driven Spreadsheets",J. Cunha; J. P. Fernandes; J. Mendes; J. Saraiva,"Universidade Nova de Lisboa, Portugal, and HASLab / INESC TEC, Portugal; (rel)ease/Universidade da Beira Interior, Portugal, and HASLab / INESC TEC, Portugal; Universidade do Minho & ESTGF, Instituto Politécnico do Porto, Portugal, and HASLab / INESC TEC, Portugal; Universidade do Minho, Portugal, and HASLab / INESC TEC, Portugal",IEEE Transactions on Software Engineering,11 Mar 2015,2015,41,3,241,263,"This paper proposes and validates a model-driven software engineering technique for spreadsheets. The technique that we envision builds on the embedding of spreadsheet models under a widely used spreadsheet system. This means that we enable the creation and evolution of spreadsheet models under a spreadsheet system. More precisely, we embed ClassSheets, a visual language with a syntax similar to the one offered by common spreadsheets, that was created with the aim of specifying spreadsheets. Our embedding allows models and their conforming instances to be developed under the same environment. In practice, this convenient environment enhances evolution steps at the model level while the corresponding instance is automatically co-evolved. Finally, we have designed and conducted an empirical study with human users in order to assess our technique in production environments. The results of this study are promising and suggest that productivity gains are realizable under our model-driven spreadsheet development setting.",1939-3520,,10.1109/TSE.2014.2361141,European Regional Development; FCT; cão para a Ciência e a Tecnologia; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915751,Spreadsheets;Models;ClassSheets;Embedding;Evolution;Empirical Validation;Spreadsheets;models;ClassSheets;embedding;evolution;empirical validation,Data models;Visualization;Atmospheric modeling;Business;Software;Unified modeling language;Syntactics,software development management;spreadsheet programs;visual languages,model driven software engineering technique;spreadsheet model embedding;spreadsheet system;spreadsheet model evolution;ClassSheets;visual language;syntax;model-driven spreadsheet development;spreadsheet model validation,,10.0,,66.0,,2 Oct 2014,,,IEEE,IEEE Journals
390,391,BLISS: Improved Symbolic Execution by Bounded Lazy Initialization with SAT Support,N. Rosner; J. Geldenhuys; N. M. Aguirre; W. Visser; M. F. Frias,"Department of Computer Science, FCEyN, Universidad de Buenos Aires, Buenos Aires, Argentina; Department of Computer Science, University of Stellenbosch, Stellenbosch, South Africa; Department of Computer Science, FCEFQyN, Universidad Nacional de Rio Cuarto, and CONICET, Río Cuarto, Argentina; Department of Computer Science, University of Stellenbosch, Stellenbosch, South Africa; Department of Software Engineering, Instituto Tecnológico de Buenos Aires, and CONICET, Buenos Aires, Argentina",IEEE Transactions on Software Engineering,14 Jul 2015,2015,41,7,639,660,"Lazy Initialization (LI) allows symbolic execution to effectively deal with heap-allocated data structures, thanks to a significant reduction in spurious and redundant symbolic structures. Bounded lazy initialization (BLI) improves on LI by taking advantage of precomputed relational bounds on the interpretation of class fields in order to reduce the number of spurious structures even further. In this paper we present bounded lazy initialization with SAT support (BLISS), a novel technique that refines the search for valid structures during the symbolic execution process. BLISS builds upon BLI, extending it with field bound refinement and satisfiability checks. Field bounds are refined while a symbolic structure is concretized, avoiding cases that, due to the concrete part of the heap and the field bounds, can be deemed redundant. Satisfiability checks on refined symbolic heaps allow us to prune these heaps as soon as they are identified as infeasible, i.e., as soon as it can be confirmed that they cannot be extended to any valid concrete heap. Compared to LI and BLI, BLISS reduces the time required by LI by up to four orders of magnitude for the most complex data structures. Moreover, the number of partially symbolic structures obtained by exploring program paths is reduced by BLISS by over 50 percent, with reductions of over 90 percent in some cases (compared to LI). BLISS uses less memory than LI and BLI, which enables the exploration of states unreachable by previous techniques.",1939-3520,,10.1109/TSE.2015.2389225,NPRP; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004061,Symbolic execution;lazy initialization;tight field bounds;Symbolic PathFinder,Concrete;Binary trees;Java;Periodic structures;Software,computability;data structures;program verification,BLISS;symbolic execution;bounded lazy initialization with SAT support;heap-allocated data structures;symbolic structures;relational bounds;class fields;field bound refinement;satisfiability check;symbolic heap;program path,,10.0,,26.0,,7 Jan 2015,,,IEEE,IEEE Journals
391,392,How Effectively Does Metamorphic Testing Alleviate the Oracle Problem?,H. Liu; F. Kuo; D. Towey; T. Y. Chen,"Australia-India Centre for Automation Software Engineering, RMIT University, Melbourne 3001 VIC, Australia; Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn 3122 VIC, Australia; Division of Computer Science, The University of Nottingham, Ningbo, China; Faculty of Information and Communication Technologies, Swinburne University of Technology, Hawthorn 3122 VIC, Australia",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,1,4,22,"In software testing, something which can verify the correctness of test case execution results is called an oracle. The oracle problem occurs when either an oracle does not exist, or exists but is too expensive to be used. Metamorphic testing is a testing approach which uses metamorphic relations, properties of the software under test represented in the form of relations among inputs and outputs of multiple executions, to help verify the correctness of a program. This paper presents new empirical evidence to support this approach, which has been used to alleviate the oracle problem in various applications and to enhance several software analysis and testing techniques. It has been observed that identification of a sufficient number of appropriate metamorphic relations for testing, even by inexperienced testers, was possible with a very small amount of training. Furthermore, the cost-effectiveness of the approach could be enhanced through the use of more diverse metamorphic relations. The empirical studies presented in this paper clearly show that a small number of diverse metamorphic relations, even those identified in an ad hoc manner, had a similar fault-detection capability to a test oracle, and could thus effectively help alleviate the oracle problem.",1939-3520,,10.1109/TSE.2013.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613484,Software testing;test oracle;oracle problem;metamorphic testing;metamorphic relation,Computer crashes;Software;Educational institutions;Software testing;Training;Benchmark testing,program diagnostics;program testing;software fault tolerance;software quality,metamorphic testing;oracle problem;software testing;metamorphic relations;software properties;program correctness;software analysis;fault-detection capability,,91.0,,42.0,,27 Sep 2013,,,IEEE,IEEE Journals
392,393,Bidirectional Symbolic Analysis for Effective Branch Testing,M. Baluda; G. Denaro; M. Pezzè,"Secure Software Engineering Group, Fraunhofer SIT, Darmstadt, Germany; Department of Informatics, Systems and Communication, Università di Milano-Bicocca, Milano, Italy; Faculty of Informatics, Università della Svizzera italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,12 May 2016,2016,42,5,403,426,"Structural coverage metrics, and in particular branch coverage, are popular approaches to measure the thoroughness of test suites. Unfortunately, the presence of elements that are not executable in the program under test and the difficulty of generating test cases for rare conditions impact on the effectiveness of the coverage obtained with current approaches. In this paper, we propose a new approach that combines symbolic execution and symbolic reachability analysis to improve the effectiveness of branch testing. Our approach embraces the ideal definition of branch coverage as the percentage of executable branches traversed with the test suite, and proposes a new bidirectional symbolic analysis for both testing rare execution conditions and eliminating infeasible branches from the set of test objectives. The approach is centered on a model of the analyzed execution space. The model identifies the frontier between symbolic execution and symbolic reachability analysis, to guide the alternation and the progress of bidirectional analysis towards the coverage targets. The experimental results presented in the paper indicate that the proposed approach can both find test inputs that exercise rare execution conditions that are not identified with state-of-the-art approaches and eliminate many infeasible branches from the coverage measurement. It can thus produce a modified branch coverage metric that indicates the amount of feasible branches covered during testing, and helps team leaders and developers in estimating the amount of not-yet-covered feasible branches. The approach proposed in this paper suffers less than the other approaches from particular cases that may trap the analysis in unbounded loops.",1939-3520,,10.1109/TSE.2015.2490067,SNF; AVATAR; Italian PRIN; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7296670,Structural testing;branch coverage;program analysis;symbolic execution;symbolic reachability analysis,Analytical models;Testing;Reachability analysis;Valves;Computational modeling;Measurement;Concrete,program diagnostics;program testing,bidirectional symbolic analysis;branch testing;structural coverage metrics;branch coverage;test suite thoroughness measure;test case generation;symbolic execution;symbolic reachability analysis;test objectives;coverage measurement,,10.0,,137.0,,12 Oct 2015,,,IEEE,IEEE Journals
393,394,Dynamic Testing for Deadlocks via Constraints,Y. Cai; Q. Lu,"State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; Technology Center of Software Engineering, Institute of Software, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,15 Sep 2016,2016,42,9,825,842,"Existing deadlock detectors are either not scalable or may report false positives when suggesting cycles as potential deadlocks. Additionally, they may not effectively trigger deadlocks and handle false positives. We propose a technique called ConLock+, which firstly analyzes each cycle and its corresponding execution to identify a set of scheduling constraints that are necessary conditions to trigger the corresponding deadlock. The ConLock+ technique then performs a second run to enforce the set of constraints, which will trigger a deadlock if the cycle is a real one. Or if not, ConLock+ reports a steering failure for that cycle and also identifies other similar cycles which would also produce steering failures. For each confirmed deadlock, ConLock+ performs a static analysis to identify conflicting memory access that would also contribute to the occurrence of the deadlock. This analysis is helpful to enable developers to understand and fix deadlocks. ConLock+ has been validated on a suite of real-world programs with 16 real deadlocks. The results show that across all 811 cycles, ConLock+ confirmed all of the 16 deadlocks with a probability of ≥80 percent. For the remaining cycles, ConLock+ reported steering failures and also identified that five deadlocks also involved conflicting memory accesses.",1939-3520,,10.1109/TSE.2016.2537335,National Basic Research (973) Program of China; National Science Foundation of China (NSFC); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7423814,Deadlock triggering;scheduling;should-happen-before relation;constraint;reliability;verification,System recovery;Instruction sets;Schedules;Testing;Synchronization;Detectors;Probabilistic logic,concurrency control;program diagnostics;program testing;scheduling,static analysis;memory access;real-world programs;steering failure;scheduling constraints;ConLock+;deadlock detectors;dynamic testing,,10.0,,55.0,,2 Mar 2016,,,IEEE,IEEE Journals
394,395,An Industrial Survey of Safety Evidence Change Impact Analysis Practice,J. L. de la Vara; M. Borg; K. Wnuk; L. Moonen,"Computer Science Department, Carlos III University of Madrid, Avda. de la Universidad 30, 28911 Leganes, Madrid, Spain; Software and Systems Laboratory, SICS Swedish ICT AB, Ideon Science Park, Building Beta 2, Scheelevägen 17, Lund, Sweden; Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Sweden; Certus Centre for Software V&V, Simula Research Laboratory, P.O. Box 134, Lysaker, Norway",IEEE Transactions on Software Engineering,8 Dec 2016,2016,42,12,1095,1117,"Context. In many application domains, critical systems must comply with safety standards. This involves gathering safety evidence in the form of artefacts such as safety analyses, system specifications, and testing results. These artefacts can evolve during a system's lifecycle, creating a need for change impact analysis to guarantee that system safety and compliance are not jeopardised. Objective. We aim to provide new insights into how safety evidence change impact analysis is addressed in practice. The knowledge about this activity is limited despite the extensive research that has been conducted on change impact analysis and on safety evidence management. Method. We conducted an industrial survey on the circumstances under which safety evidence change impact analysis is addressed, the tool support used, and the challenges faced. Results. We obtained 97 valid responses representing 16 application domains, 28 countries, and 47 safety standards. The respondents had most often performed safety evidence change impact analysis during system development, from system specifications, and fully manually. No commercial change impact analysis tool was reported as used for all artefact types and insufficient tool support was the most frequent challenge. Conclusion. The results suggest that the different artefact types used as safety evidence co-evolve. In addition, the evolution of safety cases should probably be better managed, the level of automation in safety evidence change impact analysis is low, and the state of the practice can benefit from over 20 improvement areas.",1939-3520,,10.1109/TSE.2016.2553032,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450627,Safety-critical system;safety evidence;change impact analysis;state of the practice;survey research,Safety;Market research;Best practices;Industries;Standards;Certification,safety-critical software;software standards,industrial survey;safety evidence change impact analysis;SECIA;safety-critical system;safety standard,,30.0,,71.0,,11 Apr 2016,,,IEEE,IEEE Journals
395,396,Quantitative Evaluation of Model-Driven Performance Analysis and Simulation of Component-Based Architectures,F. Brosig; P. Meier; S. Becker; A. Koziolek; H. Koziolek; S. Kounev,"Department of Computer Science, University of Würzburg, Am Hubland, Würzburg, Germany; Codecentric AG, Elsenheimerstr. 55a, München, Germany; Department of Software Engineering, University of Paderborn, Zukunftsmeile 1, Paderborn, Germany; Karlsruhe Institute of Technology (KIT), Am Fasanengarten 5, Karlsruhe, Germany; ABB Corporate Research, Wallstadter Str. 59, Ladenburg, Germany; Department of Computer Science, University of Würzburg, Am Hubland, Würzburg, Germany",IEEE Transactions on Software Engineering,10 Feb 2015,2015,41,2,157,175,"During the last decade, researchers have proposed a number of model transformations enabling performance predictions. These transformations map performance-annotated software architecture models into stochastic models solved by analytical means or by simulation. However, so far, a detailed quantitative evaluation of the accuracy and efficiency of different transformations is missing, making it hard to select an adequate transformation for a given context. This paper provides an in-depth comparison and quantitative evaluation of representative model transformations to, e.g., queueing petri nets and layered queueing networks. The semantic gaps between typical source model abstractions and the different analysis techniques are revealed. The accuracy and efficiency of each transformation are evaluated by considering four case studies representing systems of different size and complexity. The presented results and insights gained from the evaluation help software architects and performance engineers to select the appropriate transformation for a given context, thus significantly improving the usability of model transformations for performance prediction.",1939-3520,,10.1109/TSE.2014.2362755,DFG; Collaborative Research Center “On-The-Fly Computing”; DFG; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6920061,D.2.11 Software architectures;D.2.10.h Quality analysis and evaluation;D.2.2 Design tools and techniques;Software architectures;quality analysis and evaluation;design tools and techniques,Unified modeling language;Analytical models;Predictive models;Phase change materials;Accuracy;Stochastic processes;Software architecture,object-oriented programming;software architecture;software performance evaluation;stochastic processes,quantitative evaluation;model-driven performance analysis;component-based architectures;performance predictions;transformations map performance-annotated software architecture models;stochastic models;representative model transformations;semantic gaps;source model abstractions,,37.0,,50.0,,13 Oct 2014,,,IEEE,IEEE Journals
396,397,Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs,J. Xuan; M. Martinez; F. DeMarco; M. Clément; S. L. Marcote; T. Durieux; D. Le Berre; M. Monperrus,"State Key Lab of Software Engineering, School of Computer, Wuhan University, Wuhan, China; Faculty of Informatics, University of Lugano, Lugano, Switzerland; University of Buenos Aires, Buenos Aires, Argentina; Department of Computer Science, University of Lille, Lille, France; University of Buenos Aires, Buenos Aires, Argentina; Department of Computer Science, University of Lille, Lille, France; University of Artois & CNRS, Lens, France; University of Lille & INRIA, Lille, France",IEEE Transactions on Software Engineering,9 Jan 2017,2017,43,1,34,55,"We propose Nopol, an approach to automatic repair of buggy conditional statements (i.e., if-then-else statements). This approach takes a buggy program as well as a test suite as input and generates a patch with a conditional expression as output. The test suite is required to contain passing test cases to model the expected behavior of the program and at least one failing test case that reveals the bug to be repaired. The process of Nopol consists of three major phases. First, Nopol employs angelic fix localization to identify expected values of a condition during the test execution. Second, runtime trace collection is used to collect variables and their actual values, including primitive data types and objected-oriented features (e.g., nullness checks), to serve as building blocks for patch generation. Third, Nopol encodes these collected data into an instance of a Satisfiability Modulo Theory (SMT) problem; then a feasible solution to the SMT instance is translated back into a code patch. We evaluate Nopol on 22 real-world bugs (16 bugs with buggy if conditions and six bugs with missing preconditions) on two large open-source projects, namely Apache Commons Math and Apache Commons Lang. Empirical analysis on these bugs shows that our approach can effectively fix bugs with buggy if conditions and missing preconditions. We illustrate the capabilities and limitations of Nopol using case studies of real bug fixes.",1939-3520,,10.1109/TSE.2016.2560811,INRIA Internship program; INRIA postdoctoral research fellowship; CNRS delegation program; National Natural Science Foundation of China; Young Talent Development Program of the China Computer Federation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463060,Automatic repair;patch generation;SMT;fault localization,Maintenance engineering;Computer bugs;Runtime;Java;Encoding;Open source software;Indexes,computability;Java;object-oriented programming;program debugging;public domain software;software fault tolerance;software maintenance,Nopol;automatic conditional statement bug repairing;Java programs;buggy program;conditional expression;angelic fix localization;test execution;runtime trace collection;objected-oriented features;patch generation;satisfiability modulo theory problem;SMT problem;code patch;buggy IF conditions;open-source projects;Apache Commons Math;Apache Commons Lang,,100.0,,56.0,,29 Apr 2016,,,IEEE,IEEE Journals
397,398,Metamorphic Testing for Software Quality Assessment: A Study of Search Engines,Z. Q. Zhou; S. Xiang; T. Y. Chen,"School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, Victoria, Australia",IEEE Transactions on Software Engineering,11 Mar 2016,2016,42,3,264,284,"Metamorphic testing is a testing technique that can be used to verify the functional correctness of software in the absence of an ideal oracle. This paper extends metamorphic testing into a user-oriented approach to software verification, validation, and quality assessment, and conducts large scale empirical studies with four major web search engines: Google, Bing, Chinese Bing, and Baidu. These search engines are very difficult to test and assess using conventional approaches owing to the lack of an objective and generally recognized oracle. The results are useful for both search engine developers and users, and demonstrate that our approach can effectively alleviate the oracle problem and challenges surrounding a lack of specifications when verifying, validating, and evaluating large and complex software systems.",1939-3520,,10.1109/TSE.2015.2478001,Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7254235,Software quality;verification;validation;quality assessment;oracle problem;lack of system specification;metamorphic testing;user-oriented testing;search engine;Software quality;verification;validation;quality assessment;oracle problem;lack of system specification;metamorphic testing;user-oriented testing;search engine,Search engines;Testing;Web pages;Google;Software algorithms;Software quality,Internet;program testing;program verification;search engines;software quality;user interfaces,metamorphic testing;software quality assessment;user-oriented approach;software verification;software validation;Web search engines;Google;Chinese Bing;Baidu,,53.0,,53.0,,10 Sep 2015,,,IEEE,IEEE Journals
398,399,Overcoming the Equivalent Mutant Problem: A Systematic Literature Review and a Comparative Experiment of Second Order Mutation,L. Madeyski; W. Orzeszyna; R. Torkar; M. Józala,"Institute of Informatics, Wroclaw University of Technology, Wyb. Wyspianskiego 27, Poland; Institute of Informatics, Wroclaw University of Technology, Poland; Division of Software Engineering , Department of Computer Science and Engineering, Chalmers University of Technology , SE-41296, Sweden; Institute of Informatics, Wroclaw University of Technology, Wyb. Wyspianskiego 27, Poland",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,1,23,42,"Context. The equivalent mutant problem (EMP) is one of the crucial problems in mutation testing widely studied over decades. Objectives. The objectives are: to present a systematic literature review (SLR) in the field of EMP; to identify, classify and improve the existing, or implement new, methods which try to overcome EMP and evaluate them. Method. We performed SLR based on the search of digital libraries. We implemented four second order mutation (SOM) strategies, in addition to first order mutation (FOM), and compared them from different perspectives. Results. Our SLR identified 17 relevant techniques (in 22 articles) and three categories of techniques: detecting (DEM); suggesting (SEM); and avoiding equivalent mutant generation (AEMG). The experiment indicated that SOM in general and JudyDiffOp strategy in particular provide the best results in the following areas: total number of mutants generated; the association between the type of mutation strategy and whether the generated mutants were equivalent or not; the number of not killed mutants; mutation testing time; time needed for manual classification. Conclusions . The results in the DEM category are still far from perfect. Thus, the SEM and AEMG categories have been developed. The JudyDiffOp algorithm achieved good results in many areas.",1939-3520,,10.1109/TSE.2013.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613487,Mutation testing;equivalent mutant problem;higher order mutation;second order mutation,Testing;Systematics;Educational institutions;Databases;Libraries;Java;Informatics,digital libraries;program testing,JudyDiffOp strategy;SEM;DEM;AEMG;avoiding equivalent mutant generation;suggesting;detecting;FOM;first order mutation;SOM strategies;digital libraries;SLR;mutation testing;EMP;second order mutation;comparative experiment;systematic literature review;equivalent mutant problem,,80.0,,79.0,,27 Sep 2013,,,IEEE,IEEE Journals
399,400,"Detecting, Tracing, and Monitoring Architectural Tactics in Code",M. Mirakhorli; J. Cleland-Huang,"Department of Software Engineering, Rochester, NY; School of Computing, Chicago, IL",IEEE Transactions on Software Engineering,11 Mar 2016,2016,42,3,205,220,"Software architectures are often constructed through a series of design decisions. In particular, architectural tactics are selected to satisfy specific quality concerns such as reliability, performance, and security. However, the knowledge of these tactical decisions is often lost, resulting in a gradual degradation of architectural quality as developers modify the code without fully understanding the underlying architectural decisions. In this paper we present a machine learning approach for discovering and visualizing architectural tactics in code, mapping these code segments to tactic traceability patterns, and monitoring sensitive areas of the code for modification events in order to provide users with up-to-date information about underlying architectural concerns. Our approach utilizes a customized classifier which is trained using code extracted from fifty performance-centric and safety-critical open source software systems. Its performance is compared against seven off-the-shelf classifiers. In a controlled experiment all classifiers performed well; however our tactic detector outperformed the other classifiers when used within the larger context of the Hadoop Distributed File System. We further demonstrate the viability of our approach for using the automatically detected tactics to generate viable and informative messages in a simulation of maintenance events mined from Hadoop's change management system.",1939-3520,,10.1109/TSE.2015.2479217,US National Science Foundation; Research Experience for Undergraduates; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270338,Architecture;traceability;tactics;traceability information models;Architecture;traceability;tactics;traceability information models,Heart beat;Monitoring;Detectors;Reliability;Biomedical monitoring;Authentication,learning (artificial intelligence);pattern classification;program diagnostics;public domain software;software architecture;system monitoring,code architectural tactics monitoring;code architectural tactics detection;code architectural tactics tracing;machine learning;code architectural tactics visualization;tactic traceability patterns;performance-centric software systems;safety-critical open source software systems;off-the-shelf classifiers;Hadoop Distributed File System;Hadoops change management system,,32.0,,73.0,,16 Sep 2015,,,IEEE,IEEE Journals
400,401,Finding and Evaluating the Performance Impact of Redundant Data Access for Applications that are Developed Using Object-Relational Mapping Frameworks,T. Chen; W. Shang; Z. M. Jiang; A. E. Hassan; M. Nasser; P. Flora,"Software Analysis and Intelligence Lab, School of Computing, Queen's University, Kingston, ON, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Electrical Engineering and Computer Science, York University, Toronto, ON, Canada; Software Analysis and Intelligence Lab, School of Computing, Queen's University, Kingston, ON, Canada; BlackBerry, Waterloo, ON, Canada; BlackBerry, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,8 Dec 2016,2016,42,12,1148,1161,"Developers usually leverage Object-Relational Mapping (ORM) to abstract complex database accesses for large-scale systems. However, since ORM frameworks operate at a lower-level (i.e., data access), ORM frameworks do not know how the data will be used when returned from database management systems (DBMSs). Therefore, ORM cannot provide an optimal data retrieval approach for all applications, which may result in accessing redundant data and significantly affect system performance. Although ORM frameworks provide ways to resolve redundant data problems, due to the complexity of modern systems, developers may not be able to locate such problems in the code; hence, may not proactively resolve the problems. In this paper, we propose an automated approach, which we implement as a Java framework, to locate redundant data problems. We apply our framework on one enterprise and two open source systems. We find that redundant data problems exist in 87 percent of the exercised transactions. Due to the large number of detected redundant data problems, we propose an automated approach to assess the impact and prioritize the resolution efforts. Our performance assessment result shows that by resolving the redundant data problems, the system response time for the studied systems can be improved by an average of 17 percent.",1939-3520,,10.1109/TSE.2016.2553039,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451264,Performance;object-relational mapping (ORM);program analysis;database,Databases;System performance;Java;Computer bugs;Complexity theory;Time factors;Object tracking,database management systems;Java;program diagnostics;public domain software;software performance evaluation,performance impact evaluation;redundant data access;object-relational mapping framework;ORM framework;database abstraction;database management system;DBMS;Java framework;open source system;program analysis,,15.0,,84.0,,12 Apr 2016,,,IEEE,IEEE Journals
401,402,Toward Software Technology 2050,C. Ebert; S. Counsell,Vector Consulting Services; Brunel University,IEEE Software,11 Jul 2017,2017,34,4,82,88,"Software defines the future perhaps more than any other discipline. This special installment of the Software Technology department celebrates 200 issues of IEEE Software and looks ahead. Where are innovative software and IT technologies, products, and services heading? What major future trends can we envisage?",1937-4194,,10.1109/MS.2017.100,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974716,future technology;software development;software engineering,Software development;Complexity theory;Business;Technological innovation,software engineering,software technology;IEEE Software,,6.0,,5.0,,11 Jul 2017,,,IEEE,IEEE Magazines
402,403,A Lightweight Innovation Process for Software-Intensive Product Development,T. Gorschek; S. Fricker; K. Palm; S. Kunsman,"Blekinge Institute of Technology , Ronneby; University of Zurich and ABB Switzerland Ltd., Zurich; DanaherMotion Särö AB, Göteborg; ABB Substation Automation Products , Allentown",IEEE Software,31 Dec 2009,2010,27,1,37,45,An innovation process using face-to-face screening and idea refinement with heterogeneous audition teams can enhance the longterm perspective of product planning and development.,1937-4194,,10.1109/MS.2009.164,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5278658,Technology and software product management;requirements engineering;software engineering;product and process innovation model;industry trials;empirical;technology product management;market-driven requirements engineering,Technological innovation;Product development;Refining;Process planning,innovation management;project management;software engineering,lightweight innovation process;software-intensive product development;product planning;heterogeneous audition teams;project management,,33.0,,23.0,,6 Oct 2009,,,IEEE,IEEE Magazines
403,404,Creating Software Product Value in China,S. Barney; G. Hu; A. Aurum; C. Wohlin,Blekinge Institute of Technology; University of New South Wales; University of New South Wales; Blekinge Institute of Technology,IEEE Software,19 Jun 2009,2009,26,4,84,90,"China has become a formidable player and continues to experience strong growth in a dynamic global market for software development. This highly competitive environment makes maximizing the creation of software product value both difficult and important. When looking at a software product, different stakeholder groups-purchasers, users, software managers, and developers-have different notions of value. This study examines the stakeholder perspectives and criteria used to select and prioritize software release requirements in three groups of software development companies: Chinese companies with a domestic market, Chinese companies with an international market, and Western companies operating in China. The results are similar for all three groups, except for after-sales support, which was a significantly greater concern for Chinese companies with an international market.",1937-4194,,10.1109/MS.2009.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076465,China;planning;market-driven software development;requirements analysis;requirements prioritization;requirements selection;scope definition;value-based requirements engineering;value-based software engineering,Costs;Europe;North America;Pricing;Customer satisfaction;Calendars;Software maintenance;Availability;Educational products;Marketing and sales,globalisation;international trade;software engineering;software houses,software product value;China;global market;software development;international market,,11.0,,14.0,,19 Jun 2009,,,IEEE,IEEE Magazines
404,405,How API Documentation Fails,G. Uddin; M. P. Robillard,McGill University; McGill University,IEEE Software,30 Jun 2015,2015,32,4,68,75,"Formal documentation can be a crucial resource for learning to how to use an API. However, producing high-quality documentation can be nontrivial. Researchers investigated how 10 common documentation problems manifested themselves in practice. The results are based on two surveys of a total of 323 professional software developers and analysis of 179 API documentation units. The three severest problems were ambiguity, incompleteness, and incorrectness of content. The respondents often mentioned six of the 10 problems as ""blockers""' that forced them to use another API.",1937-4194,,10.1109/MS.2014.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140676,API;documentation;user study;software engineering;software development,Documentation;Software development;Application programming interfaces;Uniform resource locators;Standards;Databases,application program interfaces;learning (artificial intelligence);software engineering;system documentation,formal documentation;crucial resource;learning;API documentation unit,,58.0,,6.0,,30 Jun 2015,,,IEEE,IEEE Magazines
405,406,"Toward Evidence-Based Organizations: Lessons from Embedded Systems, Online Games, and the Internet of Things",J. Bosch; H. H. Olsson,Chalmers University; Malmö University,IEEE Software,22 Sep 2017,2017,34,5,60,66,"More and more software-intensive companies are adopting data-driven development. Across domains, companies increasingly collect and use data to support development and decision-making activities. Case studies investigated how companies in three domains transition toward data-driven development practices in which continuous collection and analysis of data inform R&D and management. The companies in the online-games and Internet-of-Things domains perform more advanced data collection and analysis, but these practices are also rapidly gaining momentum in the companies in the embedded-systems domain. A proposed model details the levels that software-intensive companies typically move through as they evolve from an opinion-based to an evidence-based organization, in which data informs all the company's processes.",1937-4194,,10.1109/MS.2017.3571569,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048636,evidence-based development;data-driven development;data collection;data analysis;decision making;Stairway to Heaven;software engineering;software development,Companies;Data collection;Data analysis;Manuals;Measurement;Decision making,business data processing;computer games;data analysis;decision making;embedded systems;Internet of Things;software engineering,evidence-based organizations;embedded systems;online games;Internet of Things;software-intensive companies;data-driven development;decision-making activities;data analysis,,1.0,,15.0,,22 Sep 2017,,,IEEE,IEEE Magazines
406,407,The Theory of Relative Dependency: Higher Coupling Concentration in Smaller Modules,A. G. Koru; K. El Emam,"University of Maryland, Baltimore County; University of Ottawa",IEEE Software,25 Feb 2010,2010,27,2,81,89,"Our observations on several large-scale software products has consistently shown that smaller modules are proportionally more defect prone. These findings, challenge the common recommendations from the literature suggesting that quality assurance (QA) and quality control (QC) resources should focus on larger modules. Those recommendations are based on the unfounded assumption that a monotonically increasing linear relationship exists between module size and defects. Given that complexity is correlated with the size.",1937-4194,,10.1109/MS.2010.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420801,software metrics and measurement;product metrics;software science;restructuring;reverse engineering;software maintainability;software quality;SQA;software quality assurance;validation and verification;software engineering,Large-scale systems;Quality assurance;Quality control,modules;quality assurance;quality control;software engineering;software quality,relative dependency theory;higher coupling concentration;large-scale software products;small modules;quality assurance;quality control;large modules;linear relationship;module size,,7.0,,25.0,,25 Feb 2010,,,IEEE,IEEE Magazines
407,408,Process Mass Customization in a Global Software Firm,L. Mathiassen; A. B. Sandberg,Georgia State University; Ericsson AB,IEEE Software,7 Nov 2014,2014,31,6,62,69,"International software firms face particular software process challenges in terms of competing interests and process variations across organizational units and geographical sites. To address this, Ericsson developers applied a general industrial approach to mass customization that focused on four key tactics: adaptive, cosmetic, transparent, and collaborative mass customization. On the basis of this experience, they discovered the strengths, weaknesses, and best deployment conditions for each tactic, and learned several lessons along the way.",1937-4194,,10.1109/MS.2014.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728934,software engineering;software processes;software tailoring;mass customization,Software development;Mass customization;Product development;Business;Collaboration;Process planning,DP industry;product customisation;software engineering,process mass customization;global software firm;international software firms;software process challenges;Ericsson developers;adaptive mass customization;cosmetic mass customization;transparent mass customization;collaborative mass customization,,4.0,,8.0,,30 Jan 2014,,,IEEE,IEEE Magazines
408,409,Why is Stack Overflow Failing? Preserving Sustainability in Community Question Answering,I. Srba; M. Bielikova,Slovak University of Technology in Bratislava; Slovak University of Technology in Bratislava,IEEE Software,23 Jun 2016,2016,33,4,80,89,"Enormous amounts of knowledge sharing occur every day in community question answering (CQA) sites, some of which (for example, Stack Overflow or Ask Ubuntu) have become popular with software developers and users. In spite of these systems' overall success, problems are emerging in some of them - increased failure and churn rates. To investigate this trend, researchers conducted a case study of Stack Overflow. First, they evaluated the community perception that the emerging problems are heavily related to the growing amount of low-quality content created by undesired groups of users (help vampires, noobs, and reputation collectors). Reproducible data analyses of content and community evolution supported these findings. Suggestions to deal with the emerging problems include providing users with responder-oriented adaptive support that involves a whole community in QA. Such approaches represent an eminent attitude change regarding QA support, with the aim to preserve CQA ecosystems' long-term sustainability.",1937-4194,,10.1109/MS.2016.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412622,community question answering;question-answering systems;knowledge sharing;computer-supported cooperative work;software engineering;software development,Knowledge discovery;Ecosystems;Software;Market research;Information exchange;Data analysis;Linear regression,data analysis;question answering (information retrieval);social networking (online);software engineering,stack overflow;community question answering sites;CQA sites;failure rates;churn rates;low-quality content;responder-oriented adaptive support;CQA ecosystem long-term sustainability;reproducible data analysis;knowledge sharing,,22.0,,13.0,,18 Feb 2016,,,IEEE,IEEE Magazines
409,410,Searching under the Streetlight for Useful Software Analytics,P. M. Johnson,University of Hawaii at Manoa,IEEE Software,26 Jun 2013,2013,30,4,57,63,"For more than 15 years, researchers at the Collaborative Software Development Laboratory at the University of Hawaii at Manoa have looked for analytics that help developers understand and improve development processes and products. This article reviews that research and discusses the trade-off between studying easily obtained analytics and studying richer analytics with higher overhead.",1937-4194,,10.1109/MS.2013.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6509376,software engineering;measurement;software quality;software quality assurance;software analytics,Software development;Data collection;Analytical models;Software metrics;Software measurement;Software quality;Data analysis;Collaboration,software engineering,software analytics;Collaborative Software Development Laboratory;University of Hawaii;Manoa,,10.0,,13.0,,26 Apr 2013,,,IEEE,IEEE Magazines
410,411,DevOps,C. Ebert; G. Gallardo; J. Hernantes; N. Serrano,Vector Consulting Services; University of Navarra; University of Navarra; University of Navarra,IEEE Software,25 Apr 2016,2016,33,3,94,100,"Building on lean and agile practices, DevOps means end-to-end automation in software development and delivery. Hardly anybody will be able to approach it with a cookbook-style approach, but most developers will benefit from better connecting the previously isolated silos of development and operations. Many DevOps tools exist that can help them do this.",1937-4194,,10.1109/MS.2016.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458761,DevOps;apache Ant;Maven;Gradle;Jenkins;TeamCity;Bamboo;Puppet;Chef;Ansible;Logging;Loggly;Graylog2;Nagios;New Relic;Cacti;AWS;Amazon Web Services;microservices;continuous integration;configuration management;software development;software engineering,Java;Monitoring;Cloud computing;DSL;Automation;Production,software engineering,DevOps;software development;software delivery;cookbook-style approach,,131.0,,3.0,,25 Apr 2016,,,IEEE,IEEE Magazines
411,412,Worlds Apart: Industrial and Academic Focus Areas in Software Testing,V. Garousi; M. Felderer,Hacettepe University; University of Innsbruck,IEEE Software,22 Sep 2017,2017,34,5,38,45,"To determine how industry and academia approach software testing, researchers compared the titles of presentations from selected conferences in each of the two communities. The results shed light on the root cause of low industry-academia collaboration and led to suggestions on how to improve this situation.",1937-4194,,10.1109/MS.2017.3641116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048625,software engineering;software testing;software conferences;industry–academia collaboration;qualitative analysis;software development,Software testing;Industries;Automatic testing;Mobile communication;Software development,educational institutions;organisational aspects;program testing;research initiatives;software engineering,industrial focus areas;academic focus areas;software testing;industry-academia collaboration,,9.0,,18.0,,22 Sep 2017,,,IEEE,IEEE Magazines
412,413,Commodification of Industrial Software: A Case for Open Source,F. van der Linden; B. Lundell; P. Marttiin,Philips Healthcare; University of Skövde; Nokia Siemens Networks,IEEE Software,19 Jun 2009,2009,26,4,77,83,"As open source development's acceptance has increased, many companies have incorporated it into heterogeneous development, which creates products by combining software that's from many sources and built with many different processes. To be effective, heterogeneous development must bridge the gap between industrial and open source software (OSS) development practices. One aspect of this approach is inner-source development, which aims to deploy key aspects of OSS development within a limited scope - for example, a division, a company, or even a consortium. So, industrial software development must be extended with knowledge of how to cooperate in open source and inner-source communities. To compete successfully, software-intensive companies will need to adopt new forms of collaborative development involving open source software.",1937-4194,,10.1109/MS.2009.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076464,open source;commodification of software;software engineering;software management;computers and society;information systems,Computer industry;Open source software;Companies;Collaborative software;Programming;Navigation;Subcontracting;Collaboration;Costs;Database systems,DP industry;groupware;public domain software;software engineering,industrial software commodification;open source software development;heterogeneous software development;OSS development;industrial software development;software-intensive company;collaborative software development,,43.0,,15.0,,19 Jun 2009,,,IEEE,IEEE Magazines
413,414,Innovation-Driven Software Development: Leveraging Small Companies' Product-Development Capabilities,R. Eito-Brun; M. Sicilia,Universidad Carlos III; University of Alcalá,IEEE Software,24 Aug 2016,2016,33,5,38,46,"A proposed innovation activity model for small companies is based on the relevant literature, an ISO/IEC standard, and the experience of successful small companies. It comprises activities, outcomes, tasks, and work products and establishes interfaces with software development processes.",1937-4194,,10.1109/MS.2016.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436650,innovation management;software process improvement;product development;software development;software engineering,Technological innovation;Innovation management;Innovation management;Sofware engineering;Standards;Systematics;Software development,business data processing;innovation management;small-to-medium enterprises;software engineering,innovation-driven software development;product development capabilities;ISO-IEC standard;software development process;innovation activity model;small companies,,1.0,,17.0,,18 Mar 2016,,,IEEE,IEEE Magazines
414,415,Language Design with the Spoofax Language Workbench,G. H. Wachsmuth; G. D. P. Konat; E. Visser,Delft University of Technology; Delft University of Technology; Delft University of Technology,IEEE Software,15 Sep 2014,2014,31,5,35,43,"IDEs are essential for programming language developers, and state-of-the-art IDE support is mandatory for programming languages to be successful. Although IDE features for mainstream programming languages are typically implemented manually, this often isn't feasible for programming languages that must be developed with significantly fewer resources. The Spoofax language workbench is a platform for developing textual programming languages with state-of-the-art IDE support. Spoofax is a comprehensive environment that integrates syntax definition, name binding, type analysis, program transformation, code generation, and declarative specification of IDE components. It also provides high-level languages for each of these aspects. These languages are highly declarative, abstracting over the implementation of IDE features and letting engineers focus on language design.",1937-4194,,10.1109/MS.2014.100,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898704,software engineering;integrated environments;design languages;programming languages;programming environments;construction tools;integrated development environments;IDE;Spoofax,Syntactics;Programming;Computer languages;Production;Design methodology;DSL,high level languages;software engineering,language design;Spoofax language workbench;textual programming languages;IDE support;high-level languages,,9.0,,18.0,,15 Sep 2014,,,IEEE,IEEE Magazines
415,416,A Roadmap to the Programmable World: Software Challenges in the IoT Era,A. Taivalsaari; T. Mikkonen,Nokia Technologies; Mozilla,IEEE Software,16 Jan 2017,2017,34,1,72,80,"The Internet of Things (IoT) represents the next significant step in the evolution of the Internet and software development. Although most IoT research focuses on data acquisition, analytics, and visualization, a subtler but equally important transition is underway. Hardware advances are making it possible to embed fully fledged virtual machines and dynamic language runtimes virtually everywhere, leading to a Programmable World in which all our everyday things are connected and programmable dynamically. The emergence of millions of remotely programmable devices in our surroundings will pose significant software development challenges. A roadmap from today's cloud-centric, data-centric IoT systems to the Programmable World highlights the technical challenges that deserve to be part of developer education and deserve deeper investigation beyond those IoT topics that receive the most attention today.",1937-4194,,10.1109/MS.2017.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819416,Internet of Things;IoT;edge computing;Programmable World;software engineering;software architecture;software development,Internet of things;Software development;Visualization;Data analysis;Software architecture,cloud computing;data acquisition;data analysis;data visualisation;Internet of Things;software engineering;virtual machines,Internet of Things;software development;data acquisition;data visualization;data analytics;virtual machines;dynamic language runtimes;remotely programmable devices;cloud-centric data-centric IoT systems,,71.0,,20.0,,16 Jan 2017,,,IEEE,IEEE Magazines
416,417,Researcher Bias: The Use of Machine Learning in Software Defect Prediction,M. Shepperd; D. Bowes; T. Hall,"Brunel University, Uxbridge, Middlesex, United Kingdom; Science and Technology Research Institute, University of Hertfordshire, Hatfield, Hertfordshire, United Kingdom; Brunel University, Uxbridge, Middlesex, United Kingdom",IEEE Transactions on Software Engineering,16 Jun 2014,2014,40,6,603,616,"Background. The ability to predict defect-prone software components would be valuable. Consequently, there have been many empirical studies to evaluate the performance of different techniques endeavouring to accomplish this effectively. However no one technique dominates and so designing a reliable defect prediction model remains problematic. Objective. We seek to make sense of the many conflicting experimental results and understand which factors have the largest effect on predictive performance. Method. We conduct a meta-analysis of all relevant, high quality primary studies of defect prediction to determine what factors influence predictive performance. This is based on 42 primary studies that satisfy our inclusion criteria that collectively report 600 sets of empirical prediction results. By reverse engineering a common response variable we build a random effects ANOVA model to examine the relative contribution of four model building factors (classifier, data set, input metrics and researcher group) to model prediction performance. Results. Surprisingly we find that the choice of classifier has little impact upon performance (1.3 percent) and in contrast the major (31 percent) explanatory factor is the researcher group. It matters more who does the work than what is done. Conclusion. To overcome this high level of researcher bias, defect prediction researchers should (i) conduct blind analysis, (ii) improve reporting protocols and (iii) conduct more intergroup studies in order to alleviate expertise issues. Lastly, research is required to determine whether this bias is prevalent in other applications domains.",1939-3520,,10.1109/TSE.2014.2322358,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824804,Software defect prediction;meta-analysis;researcher bias,Software;Predictive models;Correlation;Data models;Buildings;Software engineering;Measurement,learning (artificial intelligence);object-oriented programming;reverse engineering;software metrics;software performance evaluation;statistical analysis,machine learning;software defect prediction;defect-prone software component prediction;performance evaluation;reverse engineering;common response variable;random effects ANOVA model;model building factors;classifier factor;data set factor;input metrics factor;researcher group factor;researcher bias;blind analysis;reporting protocol improvement;intergroup studies,,139.0,,53.0,,3 Jun 2014,,,IEEE,IEEE Journals
417,418,What Makes a Good Bug Report?,T. Zimmermann; R. Premraj; N. Bettenburg; S. Just; A. Schroter; C. Weiss,"Microsoft Research, Redmond; Vrije Universiteit Amsterdam, Amsterdam; Queen's University, Kingston; Saarland University, Saarbruecken; University of Victoria, Victoria; University of Zurich, Zürich",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,618,643,"In software development, bug reports provide crucial information to developers. However, these reports widely differ in their quality. We conducted a survey among developers and users of APACHE, ECLIPSE, and MOZILLA to find out what makes a good bug report. The analysis of the 466 responses revealed an information mismatch between what developers need and what users supply. Most developers consider steps to reproduce, stack traces, and test cases as helpful, which are, at the same time, most difficult to provide for users. Such insight is helpful for designing new bug tracking tools that guide users at collecting and providing more helpful information. Our CUEZILLA prototype is such a tool and measures the quality of new bug reports; it also recommends which elements should be added to improve the quality. We trained CUEZILLA on a sample of 289 bug reports, rated by developers as part of the survey. The participants of our survey also provided 175 comments on hurdles in reporting and resolving bugs. Based on these comments, we discuss several recommendations for better bug tracking systems, which should focus on engaging bug reporters, better tool support, and improved handling of bug duplicates.",1939-3520,,10.1109/TSE.2010.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487527,Testing and debugging;distribution;maintenance;and enhancement;human factors;management;measurement.,Computer bugs;Programming;Prototypes;Software engineering;Information analysis;Software testing;Debugging;Software maintenance;Human factors;Engineering management,program debugging;program testing;software quality,software development;APACHE;ECLIPSE;MOZILLA;CUEZILLA prototype;bug tracking tools,,126.0,,66.0,,17 Jun 2010,,,IEEE,IEEE Journals
418,419,An Eye-Tracking Study of Java Programmers and Application to Source Code Summarization,P. Rodeghero; C. Liu; P. W. McBurney; C. McMillan,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN",IEEE Transactions on Software Engineering,10 Nov 2015,2015,41,11,1038,1054,"Source Code Summarization is an emerging technology for automatically generating brief descriptions of code. Current summarization techniques work by selecting a subset of the statements and keywords from the code, and then including information from those statements and keywords in the summary. The quality of the summary depends heavily on the process of selecting the subset: a high-quality selection would contain the same statements and keywords that a programmer would choose. Unfortunately, little evidence exists about the statements and keywords that programmers view as important when they summarize source code. In this paper, we present an eye-tracking study of 10 professional Java programmers in which the programmers read Java methods and wrote English summaries of those methods. We apply the findings to build a novel summarization tool. Then, we evaluate this tool. Finally, we further analyze the programmers' method summaries to explore specific keyword usage and provide evidence to support the development of source code summarization systems.",1939-3520,,10.1109/TSE.2015.2442238,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7118751,Source code summaries;program comprehension;Source code summaries;program comprehension,Java;Software;Documentation;Navigation;XML;Software engineering,Java;program compilers;source code (software),eye-tracking study;Java programmer;source code summarization;code generation,,15.0,,75.0,,5 Jun 2015,,,IEEE,IEEE Journals
419,420,Evolutionary Optimization of Software Quality Modeling with Multiple Repositories,Y. Liu; T. M. Khoshgoftaar; N. Seliya,"Georgia College & State University, Milledgeville, GA; Florida Atlantic University, Boca Raton, FL; University of Michigan-Dearborn, Dearborn, MI",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,852,864,"A novel search-based approach to software quality modeling with multiple software project repositories is presented. Training a software quality model with only one software measurement and defect data set may not effectively encapsulate quality trends of the development organization. The inclusion of additional software projects during the training process can provide a cross-project perspective on software quality modeling and prediction. The genetic-programming-based approach includes three strategies for modeling with multiple software projects: Baseline Classifier, Validation Classifier, and Validation-and-Voting Classifier. The latter is shown to provide better generalization and more robust software quality models. This is based on a case study of software metrics and defect data from seven real-world systems. A second case study considers 17 different (nonevolutionary) machine learners for modeling with multiple software data sets. Both case studies use a similar majority-voting approach for predicting fault-proneness class of program modules. It is shown that the total cost of misclassification of the search-based software quality models is consistently lower than those of the non-search-based models. This study provides clear guidance to practitioners interested in exploiting their organization's software measurement data repositories for improved software quality modeling.",1939-3520,,10.1109/TSE.2010.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467094,Genetic programming;optimization;software quality;defects;machine learning;software measurement.,Software quality;Software measurement;Predictive models;Software metrics;Electronic mail;Genetic programming;Robustness;Costs;Machine learning;Software engineering,genetic algorithms;software management;software metrics;software quality,evolutionary optimization;software quality modeling;multiple software project repository;genetic programming;baseline classifier;validation classifier;validation-and-voting classifier;robust software quality model;software metrics;machine learner;software data set;search-based software quality model;software measurement data repository,,78.0,,48.0,,20 May 2010,,,IEEE,IEEE Journals
420,421,Pointcut Rejuvenation: Recovering Pointcut Expressions in Evolving Aspect-Oriented Software,R. Khatchadourian; P. Greenwood; A. Rashid; G. Xu,"Ohio State University, Columbus; Lancaster University, Lancaster; Lancaster University, Lancaster; Ohio State University, Columbus",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,642,657,"Pointcut fragility is a well-documented problem in Aspect-Oriented Programming; changes to the base code can lead to join points incorrectly falling in or out of the scope of pointcuts. In this paper, we present an automated approach that limits fragility problems by providing mechanical assistance in pointcut maintenance. The approach is based on harnessing arbitrarily deep structural commonalities between program elements corresponding to join points selected by a pointcut. The extracted patterns are then applied to later versions to offer suggestions of new join points that may require inclusion. To illustrate that the motivation behind our proposal is well founded, we first empirically establish that join points captured by a single pointcut typically portray a significant amount of unique structural commonality by analyzing patterns extracted from 23 AspectJ programs. Then, we demonstrate the usefulness of our technique by rejuvenating pointcuts in multiple versions of three of these programs. The results show that our parameterized heuristic algorithm was able to accurately and automatically infer the majority of new join points in subsequent software versions that were not captured by the original pointcuts.",1939-3520,,10.1109/TSE.2011.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710951,Software development environments;software maintenance;software tools.,Software;Fuels;Software engineering;Observers;Robustness;Programming;Proposals,aspect-oriented programming,pointcut rejuvenation;pointcut expression recovery;aspect-oriented software;pointcut fragility;aspect-oriented programming;pointcut maintenance;deep structural commonalities harnessing;program elements;join points;pattern analysis;AspectJ programs;parameterized heuristic algorithm,,3.0,,43.0,,10 Feb 2011,,,IEEE,IEEE Journals
421,422,Work Item Tagging: Communicating Concerns in Collaborative Software Development,C. Treude; M. Storey,"University of Victoria, Victoria; University of Victoria, Victoria",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,19,34,"In collaborative software development projects, work items are used as a mechanism to coordinate tasks and track shared development work. In this paper, we explore how “tagging,” a lightweight social computing mechanism, is used to communicate matters of concern in the management of development tasks. We present the results from two empirical studies over 36 and 12 months, respectively, on how tagging has been adopted and what role it plays in the development processes of several professional development projects with more than 1,000 developers in total. Our research shows that the tagging mechanism was eagerly adopted by the teams, and that it has become a significant part of many informal processes. Different kinds of tags are used by various stakeholders to categorize and organize work items. The tags are used to support finding of tasks, articulation work, and information exchange. Implicit and explicit mechanisms have evolved to manage the tag vocabulary. Our findings indicate that lightweight informal tool support, prevalent in the social computing domain, may play an important role in improving team-based software development practices.",1939-3520,,10.1109/TSE.2010.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611552,Tagging;collaboration;software development;task management;articulation work;work items.,Tagging;Programming;Collaboration;Software engineering;Data mining,groupware;information retrieval;software development management,work item tagging;collaborative software development project;social computing mechanism;tag vocabulary;lightweight informal tool support;team-based software development practice,,34.0,,44.0,,28 Oct 2010,,,IEEE,IEEE Journals
422,423,A Feature-Based Classification of Model Repair Approaches,N. Macedo; T. Jorge; A. Cunha,"High-Assurance Software Laboratory (HASLab)INESC TEC; European Space Agency (ESA), Paris, France; High-Assurance Software Laboratory (HASLab)INESC TEC",IEEE Transactions on Software Engineering,14 Jul 2017,2017,43,7,615,640,"Consistency management, the ability to detect, diagnose and handle inconsistencies, is crucial during the development process in Model-driven Engineering (MDE). As the popularity and application scenarios of MDE expanded, a variety of different techniques were proposed to address these tasks in specific contexts. Of the various stages of consistency management, this work focuses on inconsistency handling in MDE, particularly in model repair techniques. This paper proposes a feature-based classification system for model repair techniques, based on an systematic literature review of the area. We expect this work to assist developers and researchers from different disciplines in comparing their work under a unifying framework, and aid MDE practitioners in selecting suitable model repair approaches.",1939-3520,,10.1109/TSE.2016.2620145,North Portugal Regional Operational Programme; European Regional Development Fund (ERDF); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7605502,"Model-driven engineering, consistency management, inconsistency handling, model repair",Maintenance engineering;Unified modeling language;Taxonomy;Context;Feature extraction;Software engineering;Systematics,pattern classification;software maintenance,model repair approach;consistency management;model-driven engineering;MDE;feature-based classification system,,4.0,,91.0,,21 Oct 2016,,,IEEE,IEEE Journals
423,424,A Systematic Survey of Program Comprehension through Dynamic Analysis,B. Cornelissen; A. Zaidman; A. van Deursen; L. Moonen; R. Koschke,"Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Delft University of Technology, The Netherlands; Simula Research Laboratory, Norway; University of Bremen, Germany",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,684,702,"Program comprehension is an important activity in software maintenance, as software must be sufficiently understood before it can be properly modified. The study of a program's execution, known as dynamic analysis, has become a common technique in this respect and has received substantial attention from the research community, particularly over the last decade. These efforts have resulted in a large research body of which currently there exists no comprehensive overview. This paper reports on a systematic literature survey aimed at the identification and structuring of research on program comprehension through dynamic analysis. From a research body consisting of 4,795 articles published in 14 relevant venues between July 1999 and June 2008 and the references therein, we have systematically selected 176 articles and characterized them in terms of four main facets: activity, target, method, and evaluation. The resulting overview offers insight in what constitutes the main contributions of the field, supports the task of identifying gaps and opportunities, and has motivated our discussion of several important research directions that merit additional consideration in the near future.",1939-3520,,10.1109/TSE.2009.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815280,Survey;program comprehension;dynamic analysis.,Computer Society;Software maintenance;Software systems;Documentation;Software engineering;Data analysis;Information analysis;Availability;Runtime;Virtual machining,reverse engineering;software maintenance;system monitoring,program comprehension;dynamic analysis;software maintenance;systematic literature survey,,214.0,1.0,154.0,,17 Apr 2009,,,IEEE,IEEE Journals
424,425,The Probabilistic Program Dependence Graph and Its Application to Fault Diagnosis,G. K. Baah; A. Podgurski; M. J. Harrold,"Georgia Institute of Technology, Atlanta; Case Western Reserve University, Cleveland; Georgia Institute of Technology, Atlanta",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,528,545,"This paper presents an innovative model of a program's internal behavior over a set of test inputs, called the probabilistic program dependence graph (PPDG), which facilitates probabilistic analysis and reasoning about uncertain program behavior, particularly that associated with faults. The PPDG construction augments the structural dependences represented by a program dependence graph with estimates of statistical dependences between node states, which are computed from the test set. The PPDG is based on the established framework of probabilistic graphical models, which are used widely in a variety of applications. This paper presents algorithms for constructing PPDGs and applying them to fault diagnosis. The paper also presents preliminary evidence indicating that a PPDG-based fault localization technique compares favorably with existing techniques. The paper also presents evidence indicating that PPDGs can be useful for fault comprehension.",1939-3520,,10.1109/TSE.2009.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374423,Probabilistic graphical models;machine learning;fault diagnosis;program analysis.,Fault diagnosis;Graphical models;Application software;Testing;Software engineering;Automatic control;Information analysis;Runtime;Probability distribution;Computer Society,fault diagnosis;graph theory;probability;program diagnostics;reasoning about programs;uncertainty handling,probabilistic program dependence graph;fault diagnosis;probabilistic analysis;reasoning;uncertain program behavior;fault localization technique;probabilistic graphical models,,54.0,6.0,31.0,,8 Jan 2010,,,IEEE,IEEE Journals
425,426,A Comparison of Tabular Expression-Based Testing Strategies,X. Feng; D. L. Parnas; T. H. Tse; T. O'Callaghan,"University of Limerick, Limerick and United International College, Zhuhai, Guangdong; University of Limerick, Limerick; The University of Hong Kong, Hong Kong; University of Limerick, Limerick",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,616,634,"Tabular expressions have been proposed as a notation to document mathematically precise but readable software specifications. One of the many roles of such documentation is to guide testers. This paper 1) explores the application of four testing strategies (the partition strategy, decision table-based testing, the basic meaningful impact strategy, and fault-based testing) to tabular expression-based specifications, and 2) compares the strategies on a mathematical basis through formal and precise definitions of the subsumption relationship. We also compare these strategies through experimental studies. These results will help researchers improve current methods and will enable testers to select appropriate testing strategies for tabular expression-based specifications.",1939-3520,,10.1109/TSE.2011.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975175,Tabular expression;test case constraint;subsume;unconditionally subsume;conditionally subsume.,Testing;Redundancy;Documentation;Software quality;Software engineering;Electronic mail,formal specification;program testing;system documentation,tabular expression-based testing strategies;readable software specifications;partition strategy;decision table-based testing;meaningful impact strategy;fault-based testing,,7.0,,49.0,,4 Aug 2011,,,IEEE,IEEE Journals
426,427,"Software Dependencies, Work Dependencies, and Their Impact on Failures",M. Cataldo; A. Mockus; J. A. Roberts; J. D. Herbsleb,"Research and Technology Center, Robert Bosch LLC, Pittsburgh; Avaya Labs Research, Basking Ridge; Duquesne University, Pittsburgh; Carnegie Mellon University, Pittsburgh",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,864,878,"Prior research has shown that customer-reported software faults are often the result of violated dependencies that are not recognized by developers implementing software. Many types of dependencies and corresponding measures have been proposed to help address this problem. The objective of this research is to compare the relative performance of several of these dependency measures as they relate to customer-reported defects. Our analysis is based on data collected from two projects from two independent companies. Combined, our data set encompasses eight years of development activity involving 154 developers. The principal contribution of this study is the examination of the relative impact that syntactic, logical, and work dependencies have on the failure proneness of a software system. While all dependencies increase the fault proneness, the logical dependencies explained most of the variance in fault proneness, while workflow dependencies had more impact than syntactic dependencies. These results suggest that practices such as rearchitecting, guided by the network structure of logical dependencies, hold promise for reducing defects.",1939-3520,,10.1109/TSE.2009.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5166450,Distribution/maintenance/enhancement;metrics/measurement;organizational management and coordination;quality analysis and evaluation.,Software systems;Predictive models;Quality management;Software engineering;Humans;Software development management;Programming,software fault tolerance;software maintenance;software metrics;software quality,software dependencies;work dependencies;customer-reported software faults;quality analysis,,139.0,1.0,48.0,,17 Jul 2009,,,IEEE,IEEE Journals
427,428,Model Transformation Modularization as a Many-Objective Optimization Problem,M. Fleck; J. Troya; M. Kessentini; M. Wimmer; B. Alkhazi,"TU Wien, Wien, Austria; Universidad de Sevilla, Sevilla, Spain; University of Michigan, Ann Arbor, MI; TU Wien, Wien, Austria; University of Michigan, Ann Arbor, MI",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1009,1032,"Model transformation programs are iteratively refined, restructured, and evolved due to many reasons such as fixing bugs and adapting existing transformation rules to new metamodels version. Thus, modular design is a desirable property for model transformations as it can significantly improve their evolution, comprehensibility, maintainability, reusability, and thus, their overall quality. Although language support for modularization of model transformations is emerging, model transformations are created as monolithic artifacts containing a huge number of rules. To the best of our knowledge, the problem of automatically modularizing model transformation programs was not addressed before in the current literature. These programs written in transformation languages, such as ATL, are implemented as one main module including a huge number of rules. To tackle this problem and improve the quality and maintainability of model transformation programs, we propose an automated search-based approach to modularize model transformations based on higher-order transformations. Their application and execution is guided by our search framework which combines an in-place transformation engine and a search-based algorithm framework. We demonstrate the feasibility of our approach by using ATL as concrete transformation language and NSGA-III as search algorithm to find a trade-off between different well-known conflicting design metrics for the fitness functions to evaluate the generated modularized solutions. To validate our approach, we apply it to a comprehensive dataset of model transformations. As the study shows, ATL transformations can be modularized automatically, efficiently, and effectively by our approach. We found that, on average, the majority of recommended modules, for all the ATL programs, by NSGA-III are considered correct with more than 84 percent of precision and 86 percent of recall when compared to manual solutions provided by active developers. The statistical analysis of our experiments over several runs shows that NSGA-III performed significantly better than multi-objective algorithms and random search. We were not able to compare with existing model transformations modularization approaches since our study is the first to address this problem. The software developers considered in our experiments confirm the relevance of the recommended modularization solutions for several maintenance activities based on different scenarios and interviews.",1939-3520,,10.1109/TSE.2017.2654255,Christian Doppler Forschungsgesellschaft; BMWFW; European Commission (FEDER); Spanish Government; CICYT project BELI; SEBASE; Andalusian Government project COPAS; Ford Motor Company; Ford Alliance Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820199,Model transformation;modularization;ATL;NSGA-III;MDE;SBSE,Unified modeling language;Object oriented modeling;Adaptation models;Measurement;Algorithm design and analysis;Software engineering;Computer bugs,genetic algorithms;program debugging;search problems;software maintenance;software quality,model transformations modularization;model transformation modularization;model transformation programs;transformation languages;higher-order transformations;in-place transformation engine;concrete transformation language;ATL transformations;bug fixing;transformation rules;many-objective optimization problem;metamodels version;monolithic artifacts;automated search-based approach;NSGA-III;statistical analysis;maintenance activities,,6.0,,96.0,Traditional,17 Jan 2017,,,IEEE,IEEE Journals
428,429,Automatically Detecting and Tracking Inconsistencies in Software Design Models,A. Egyed,"Johannes Kepler University, Linz",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,188,204,"Software models typically contain many inconsistencies and consistency checkers help engineers find them. Even if engineers are willing to tolerate inconsistencies, they are better off knowing about their existence to avoid follow-on errors and unnecessary rework. However, current approaches do not detect or track inconsistencies fast enough. This paper presents an automated approach for detecting and tracking inconsistencies in real time (while the model changes). Engineers only need to define consistency rules-in any language-and our approach automatically identifies how model changes affect these consistency rules. It does this by observing the behavior of consistency rules to understand how they affect the model. The approach is quick, correct, scalable, fully automated, and easy to use as it does not require any special skills from the engineers using it. We evaluated the approach on 34 models with model sizes of up to 162,237 model elements and 24 types of consistency rules. Our empirical evaluation shows that our approach requires only 1.4 ms to reevaluate the consistency of the model after a change (on average); its performance is not noticeably affected by the model size and common consistency rules but only by the number of consistency rules, at the expense of a quite acceptable, linearly increasing memory consumption.",1939-3520,,10.1109/TSE.2010.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432227,Design tools and techniques;design.,Software design;Feedback;Design engineering;Maintenance engineering;Best practices;Software engineering;Programming profession,formal verification;software maintenance,consistency rules;automatic inconsistency tracking;automatic inconsistency detection;empirical evaluation;memory consumption;software design model;consistency checkers,,68.0,,40.0,,18 Mar 2010,,,IEEE,IEEE Journals
429,430,A Flexible Infrastructure for Multilevel Language Engineering,C. Atkinson; M. Gutheil; B. Kennel,"University of Mannheim, Mannheim; itemis AG, Bonn; University of Mannheim, Mannheim",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,742,755,"Although domain-specific modeling tools have come a long way since the modern era of model-driven development started in the early 1990s and now offer an impressive range of features, there is still significant room for enhancing the flexibility they offer to end users and for combining the advantages of domain-specific and general-purpose languages. To do this, however, it is necessary to enhance the way in which the current generation of tools view metamodeling and support the representation of the multiple, ?ontological? classification levels that often exist in subject domains. State-of-the-art tools essentially allow users to describe the abstract and concrete syntaxes of a language in the form of metamodels and to make statements in that language in the form of models. These statements typically convey information in terms of types and instances in the domain (e.g., the classes and objects of UML), but not in terms of types of types (i.e., domain metaclasses), and types of types of types, and so on, across multiple classification levels. In essence, therefore, while they provide rich support for ?linguistic? metamodeling, the current generation of tools provides little if any built-in support for modeling ?ontological? classification across more than one type/instance level in the subject domain. In this paper, we describe a prototype implementation of a new kind of modeling infrastructure that, by providing built-in support for multiple ontological as well as linguistic classification levels, offers various advantages over existing language engineering approaches and tools. These include the ability to view a single model from the perspective of both a general-purpose and a domain-specific modeling language, the ability to define constraints across multiple ontological classification levels, and the ability to tie the rendering of model elements to ontological as well as linguistic types over multiple classification levels. After first outlining the key conceptual ingredients of this new infrastructure and presenting the main elements of our current realization, we show these benefits through two small examples.",1939-3520,,10.1109/TSE.2009.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4907005,Language engineering;metamodeling;multilevel modeling.,Unified modeling language;Ontologies;Metamodeling;Concrete;Design engineering;Software tools;Prototypes;DSL;Production facilities;Software engineering,ontologies (artificial intelligence);software tools;Unified Modeling Language,multilevel language engineering;model-driven development;linguistic metamodeling;ontological classification levels;domain-specific modeling language;UML,,51.0,,37.0,,2 May 2009,,,IEEE,IEEE Journals
430,431,Software Plagiarism Detection with Birthmarks Based on Dynamic Key Instruction Sequences,Z. Tian; Q. Zheng; T. Liu; M. Fan; E. Zhuang; Z. Yang,"Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Department of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Department of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi’an Jiaotong University, Xi’an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Department of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Department of Computer Science and Technology, Xi’an Jiaotong University, Xi’an, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI",IEEE Transactions on Software Engineering,8 Dec 2015,2015,41,12,1217,1235,"A software birthmark is a unique characteristic of a program. Thus, comparing the birthmarks between the plaintiff and defendant programs provides an effective approach for software plagiarism detection. However, software birthmark generation faces two main challenges: the absence of source code and various code obfuscation techniques that attempt to hide the characteristics of a program. In this paper, we propose a new type of software birthmark called DYnamic Key Instruction Sequence (DYKIS) that can be extracted from an executable without the need for source code. The plagiarism detection algorithm based on our new birthmarks is resilient to both weak obfuscation techniques such as compiler optimizations and strong obfuscation techniques implemented in tools such as SandMark, Allatori and Upx. We have developed a tool called DYKIS-PD (DYKIS Plagiarism Detection tool) and conducted extensive experiments on large number of binary programs. The tool, the benchmarks and the experimental results are all publicly available.",1939-3520,,10.1109/TSE.2015.2454508,National Natural Science Foundation of China; Ministry of Education Innovation Research Team; Key Projects in the National Science and Technology Pillar Program of China; Fundamental Research Funds for the Central Universities; National Science Foundation (NSF); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153572,Software plagiarism detection;software birthmark;Software plagiarism detection;software birthmark,Software engineering;Plagiarism;Licenses;Heuristic algorithms;Watermarking,fraud;program diagnostics;security of data,DYKIS plagiarism detection tool;DYKIS-PD;Upx;Allatori;SandMark;compiler optimization;code obfuscation;source code;software birthmark;dynamic key instruction sequences;software plagiarism detection,,29.0,,77.0,,9 Jul 2015,,,IEEE,IEEE Journals
431,432,Automated API Property Inference Techniques,M. P. Robillard; E. Bodden; D. Kawrykow; M. Mezini; T. Ratchford,"McGill University, Montréal; Technische Universität Darmstadt, Darmstadt; McGill University, Montréal; Technische Universität Darmstadt, Darmstadt; McGill University, Montréal",IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,613,637,"Frameworks and libraries offer reusable and customizable functionality through Application Programming Interfaces (APIs). Correctly using large and sophisticated APIs can represent a challenge due to hidden assumptions and requirements. Numerous approaches have been developed to infer properties of APIs, intended to guide their use by developers. With each approach come new definitions of API properties, new techniques for inferring these properties, and new ways to assess their correctness and usefulness. This paper provides a comprehensive survey of over a decade of research on automated property inference for APIs. Our survey provides a synthesis of this complex technical field along different dimensions of analysis: properties inferred, mining techniques, and empirical results. In particular, we derive a classification and organization of over 60 techniques into five different categories based on the type of API property inferred: unordered usage patterns, sequential usage patterns, behavioral specifications, migration mappings, and general information.",1939-3520,,10.1109/TSE.2012.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311409,API property;programming rules;specifications;protocols;interface;data mining;pattern mining;API evolution;API usage pattern,Itemsets;Context;Association rules;Protocols;Programming;Software engineering,application program interfaces;data mining;pattern classification,automated API property inference technique;application programming interfaces;properties inferred;mining techniques;empirical results;technique classification;unordered usage patterns;sequential usage patterns;behavioral specifications;migration mappings;general information,,82.0,,109.0,,24 Sep 2012,,,IEEE,IEEE Journals
432,433,Locating Software Faults Based on Minimum Debugging Frontier Set,F. Li; Z. Li; W. Huo; X. Feng,"State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, P.R.China; Department of Computer Science, Purdue University, West Lafayette, IN; Institute of Information Engineering, Chinese Academy of Sciences, Beijing, P.R.China; State Key Laboratory of Computer Architecture, Institute of Computing Technology, Chinese Academy of Sciences, Beijing, P.R.China",IEEE Transactions on Software Engineering,11 Aug 2017,2017,43,8,760,776,"In this article, we propose a novel state-based fault-localization approach. Given an observed failure that is reproducible under the same program input, this new approach uses two main techniques to reduce the state exploration cost. Firstly, the execution trace to be analyzed for the observed failure is successively narrowed by making the set of trace points in each step a cut of the dynamic dependence graph. Such a cut divides the remaining trace into two parts and, based on the sparse symbolic exploration outcome, one part is removed from further exploration. This process continues until reaching where the fault is determined to be. Second, the cut in each step is chosen such that the union of the program states from the members of the cut is of the minimum size among all candidate cuts. The set of statement instances in the chosen cut is called a minimum debugging frontier set (MDFS). To evaluate our approach, we apply it to 16 real bugs from real world programs and compare our fault reports with those generated by state-of-the-art approaches. Results show that the MDFS approach obtains high quality fault reports for these test cases with considerably higher efficiency than previous approaches.",1939-3520,,10.1109/TSE.2016.2632122,National Natural Science Foundation of China; National High Technology Research and Development Program of China; National Science Foundation of United States; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7755837,Fault localization;minimum debugging frontier set;sparse symbolic exploration;dynamic dependence graph,Debugging;Computer aided software engineering;Computer bugs;Software;Computer architecture;Computers;Indexes,graph theory;program debugging;software fault tolerance,software faults location;minimum debugging frontier set;state-based fault-localization;state exploration cost;execution trace;trace points;dynamic dependence graph;sparse symbolic exploration;MDFS;program bugs,,4.0,,47.0,,23 Nov 2016,,,IEEE,IEEE Journals
433,434,A Multi-Objective Technique to Prioritize Test Cases,A. Marchetto; M. M. Islam; W. Asghar; A. Susi; G. Scanniello,independent researchers; independent researchers; independent researchers; Fondazione Bruno Kessler; DiMIE - University of Basilicata,IEEE Transactions on Software Engineering,13 Oct 2016,2016,42,10,918,940,"While performing regression testing, an appropriate choice for test case ordering allows the tester to early discover faults in source code. To this end, test case prioritization techniques can be used. Several existing test case prioritization techniques leave out the execution cost of test cases and exploit a single objective function (e.g., code or requirements coverage). In this paper, we present a multi-objective test case prioritization technique that determines the ordering of test cases that maximize the number of discovered faults that are both technical and business critical. In other words, our new technique aims at both early discovering faults and reducing the execution cost of test cases. To this end, we automatically recover links among software artifacts (i.e., requirements specifications, test cases, and source code) and apply a metric-based approach to automatically identify critical and fault-prone portions of software artifacts, thus becoming able to give them more importance during test case prioritization. We experimentally evaluated our technique on 21 Java applications. The obtained results support our hypotheses on efficiency and effectiveness of our new technique and on the use of automatic artifacts analysis and weighting in test case prioritization.",1939-3520,,10.1109/TSE.2015.2510633,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7362042,Regression testing;requirements;testing;test case prioritization,Software;Fault diagnosis;Testing;Software engineering;Business;Electronic mail;Optimization,formal specification;formal verification;program testing;regression analysis;software fault tolerance;software metrics;source code (software);systems analysis,multiobjective technique;test case prioritization;regression testing;source code fault;software artifact;requirements specification;metric-based approach,,30.0,,64.0,,22 Dec 2015,,,IEEE,IEEE Journals
434,435,An Enhanced Bailout Protocol for Mixed Criticality Embedded Software,I. Bate; A. Burns; R. I. Davis,"Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, University of York, York, United Kingdom",IEEE Transactions on Software Engineering,14 Apr 2017,2017,43,4,298,320,"To move mixed criticality research into industrial practice requires models whose run-time behaviour is acceptable to systems engineers. Certain aspects of current models, such as abandoning lower criticality tasks when certain situations arise, do not give the robustness required in application domains such as the automotive and aerospace industries. In this paper a new bailout protocol is developed that still guarantees high criticality software but minimises the negative impact on lower criticality software via a timely return to normal operation. We show how the bailout protocol can be integrated with existing techniques, utilising both offline slack and online gain-time to further improve performance. Static analysis is provided for schedulability guarantees, while scenario-based evaluation via simulation is used to explore the effectiveness of the protocol.",1939-3520,,10.1109/TSE.2016.2592907,ESPRC; MCC; EU FP7 IP PROXIMA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516652,Real-time systems;mixed criticality;fixed priority scheduling;mode changes,Protocols;Standards;Software;Analytical models;Job shop scheduling;Software engineering;Safety,embedded systems;safety-critical software;scheduling,scenario-based evaluation;schedulability guarantees;online gain-time;lower criticality software;high criticality software;mixed criticality embedded software;enhanced bailout protocol,,12.0,,44.0,,19 Jul 2016,,,IEEE,IEEE Journals
435,436,Efficient Software Verification: Statistical Testing Using Automated Search,S. Poulding; J. A. Clark,"University of York, York; University of York, York",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,763,777,"Statistical testing has been shown to be more efficient at detecting faults in software than other methods of dynamic testing such as random and structural testing. Test data are generated by sampling from a probability distribution chosen so that each element of the software's structure is exercised with a high probability. However, deriving a suitable distribution is difficult for all but the simplest of programs. This paper demonstrates that automated search is a practical method of finding near-optimal probability distributions for real-world programs, and that test sets generated from these distributions continue to show superior efficiency in detecting faults in the software.",1939-3520,,10.1109/TSE.2010.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406530,Software/program verification;testing strategies;test coverage of code;optimization.,Statistical analysis;Software testing;Automatic testing;Probability distribution;Software engineering;Fault detection;Sampling methods;Software algorithms;Application software;Flow graphs,program testing;program verification;statistical distributions;statistical testing,software verification;statistical testing;automated search;software fault detection;dynamic testing;random testing;structural testing;test data;near-optimal probability distribution,,31.0,,48.0,,5 Feb 2010,,,IEEE,IEEE Journals
436,437,Facilitating Performance Predictions Using Software Components,J. Happe; H. Koziolek; R. Reussner,SAP Research; ABB Corporate Research; Karlsruhe Institute of Technology,IEEE Software,25 Apr 2011,2011,28,3,27,33,"Component-based software engineering (CBSE) poses challenges for predicting and evaluating software performance but also offers several advantages. Software performance engineering can benefit from CBSE ideas and concepts. The MediaStore, a fictional system, demonstrates how to achieve compositional reasoning about software performance.",1937-4194,,10.1109/MS.2011.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5719590,software performance engineering;component-based software architecture;quality assessment,Resource management;Software performance;Servers;Computer architecture;Predictive models;Throughput,software engineering,component-based software engineering;software components;software performance;MediaStore system;compositional reasoning,,19.0,,16.0,,24 Feb 2011,,,IEEE,IEEE Magazines
437,438,Software Architects in Large-Scale Distributed Projects: An Ericsson Case Study,R. Britto; D. Smite; L. Damm,Blekinge Institute of Technology; Blekinge Institute of Technology; Ericsson,IEEE Software,28 Oct 2016,2016,33,6,48,55,"Software architects are key assets for successful development projects. However, not much research has investigated the challenges they face in large-scale distributed projects. So, researchers investigated how architects at Ericsson were organized, their roles and responsibilities, and the effort they spent guarding and governing a large-scale legacy product developed by teams at multiple locations. Despite recent trends such as microservices and agile development, Ericsson had to follow a more centralized approach to deal with the challenges of scale, distribution, and monolithic architecture of a legacy software product. So, the architectural decisions were centralized to a team of architects. The team extensively used code reviews to not only check the code's state but also reveal defects that could turn into maintainability problems. The study results also suggest that the effort architects spend designing architecture, guarding its integrity and evolvability, and mentoring development teams is directly related to team maturity. In addition, significant investment is needed whenever new teams and locations are onboarded.",1937-4194,,10.1109/MS.2016.146,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725230,software architects;global software engineering;large-scale software development;software development;software engineering,Software architecture;Computer architecture;Complexity theory;Mentoring;Atmospheric measurements;Particle measurements;Product development,distributed processing;personnel;software architecture;software development management;software maintenance,software architects;large-scale distributed projects;Ericsson;legacy software product;microservices trend;agile development trend,,16.0,,20.0,,28 Oct 2016,,,IEEE,IEEE Magazines
438,439,Integrating Software Product Line Engineering and Agile Development,K. Mohan; B. Ramesh; V. Sugumaran,"The City University of New York, New York; Georgia State University, Atlanta; Oakland University, Rochester",IEEE Software,19 Apr 2010,2010,27,3,48,55,"A software product line is a set of software-intensive systems sharing a common, managed set of features, developed from reusable core assets and incorporating variations to derive product variants. This involves identifying commonality and variability in the product family and implementing shared artifacts while preserving the ability to implement required variability. Software development organizations that recognize market opportunities for products that share a significant number of common elements, but that also exhibit variations, can reap significant economic benefits with SPLE. Agile methods emphasize improvisation over conventional development approaches. These methods focus on quick development in an uncertain, ill-understood environment in which requirements rapidly evolve. These methods also view people, rather than formal documentation, as a project's most important element.",1937-4194,,10.1109/MS.2010.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406496,software product line engineering;agile software development;complex adaptive systems;software engineering;software construction;software engineering process;software process models,Software reusability;Asset management;Software development management;Programming;Market opportunities;Environmental economics;Documentation,product development;software prototyping;software reusability,software product line engineering;agile development;software-intensive system;software development,,19.0,,16.0,,5 Feb 2010,,,IEEE,IEEE Magazines
439,440,Effective Quality Management: Value- and Risk-Based Software Quality Management,A. Poth; A. Sunyaev,Technical University of Berlin; University of Cologne,IEEE Software,7 Nov 2014,2014,31,6,79,85,"Software quality management (SQM) must effectively deploy resources for quality assurance activities to reflect the achieved product quality. So, quality managers should exploit their creative freedom to direct their courses of action within the economic constraints. Effective Quality Management can increase SQM effectiveness. This value- and risk-based method is applicable for software developers, their customers, and users. This is due to its product function orientation and the independence of the software development procedures.",1937-4194,,10.1109/MS.2013.138,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654156,quality management;verification and validation;value-based software engineering;risk management;supplier management;software engineering,Quality assessment;Product design;Software quality;Context modeling;Product development,product quality;quality assurance;software management;software quality,value-based software quality management;risk-based software quality management;quality assurance activity;product quality;economic constraint;SQM effectiveness;value-based method;risk-based method;software developer;product function orientation;software development procedure,,17.0,,11.0,,4 Nov 2013,,,IEEE,IEEE Magazines
440,441,Overcoming Barriers to Self-Management in Software Teams,N. B. Moe; T. Dingsøyr; T. Dybå,SINTEF Information and Communication Technology; SINTEF Information and Communication Technology; SINTEF Information and Communication Technology,IEEE Software,16 Oct 2009,2009,26,6,20,26,"The basic work unit in innovative software organizations is the team rather than the individual. Such teams consist of ""a small number of people with complementary skills who are committed to a common purpose, set of performance goals, and approach for which they hold themselves mutually accountable"". Work teams have many advantages, such as increased productivity, innovation, and employee satisfaction. However, their implementation doesn't always result in organizational success. It isn't enough to put individuals together and expect that they'll automatically know how to work effectively as a team. Lack of redundancy and conflict between team and individual autonomy are key issues when transforming from traditional command-and-control management to collaborative self-managing teams.",1937-4194,,10.1109/MS.2009.182,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287005,ethnographic studies;case study;empirical software engineering;self-management;organizational management and coordination;organizational change;software process improvement;software engineering;agile software development,Productivity;Technological innovation;Collaborative work,employee welfare;software development management;team working,software team;innovative software organization;basic work unit;complementary skill;performance goal set;work team;innovation;employee satisfaction;increased productivity;redundancy;team conflict;command-and-control management;collaborative self-managing team,,63.0,,13.0,,16 Oct 2009,,,IEEE,IEEE Magazines
441,442,What Do We Know about Agile Software Development?,T. Dyba; T. Dingsoyr,SINTEF Information and Communication Technology; SINTEF Information and Communication Technology,IEEE Software,25 Aug 2009,2009,26,5,6,9,"Agile software development has had a huge impact on how software is developed worldwide. We can view agile methods such as Extreme Programming (XP) and Scrum as a reaction to plan-based or traditional methods, which emphasize a ""rationalized, engineering-based approach, incorporating extensive planning, codified processes, and rigorous reuse. In contrast, agile methods address the challenge of an unpredictable world, emphasizing the value competent people and their relationships bring to software development. To clarify the effectiveness of agile methods, we reviewed the agile development literature and conducted a systematic study of what we know empirically about its benefits and limitations.",1937-4194,,10.1109/MS.2009.145,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222784,empirical software engineering;evidence-based software engineering;research synthesis;agile software development;XP;extreme programming;scrum;lean software development,Programming;Collaborative software;Humans;Social factors;Software development management;ISO standards;Communication system control;Environmental management;Innovation management;Application software,project management;software development management;software reusability,agile software development;extreme programming;Scrum;agile project management;rationalized engineering-based approach;rigorous reuse;extensive planning;codified process,,101.0,,11.0,,25 Aug 2009,,,IEEE,IEEE Magazines
442,443,Architects as Service Providers,R. Faber,Siemens,IEEE Software,25 Feb 2010,2010,27,2,33,40,"Architects provide those system qualities as values to their customers, communicating and implementing them in close cooperation with developers. In this way, architects also can and should play an important role in agile development projects. As a service to application developers, architects participate in coding activities and sustain the architecture's effectiveness throughout a project's lifetime.",1937-4194,,10.1109/MS.2010.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420793,software architecture;agile development;software engineering;management;development teams;software engineering process;software process models,Encoding;Software architecture;Service oriented architecture;Documentation;Prototypes,encoding;software architecture;software development management,service providers;system qualities;application developers;architects;coding activities;agile development projects,,12.0,,8.0,,25 Feb 2010,,,IEEE,IEEE Magazines
443,444,What's the True Hourly Cost of Offshoring?,D. Smite; R. van Solingen,Blekinge Institute of Technology; Delft University of Technology,IEEE Software,24 Aug 2016,2016,33,5,60,70,"Most companies have learned that cost calculations for offshore outsourcing shouldn't be limited to hourly wages. Looking at salaries alone, you could naively hope for cost reductions of up to 90 percent. However, don't underestimate the cost of knowledge transfer, travel, attrition, miscommunication, and so on. But does an opportunity for cost reduction still exist? To answer this question, researchers delved into the collaboration between a Dutch software company and an Indian vendor. They gathered evidence for direct costs and quantified perceptions of indirect costs associated with an in-house team in the Netherlands and the outsourced offshore team in India. The offshore team's true hourly costs took three years to become comparable with those of the in-house team. Getting close to the break-even point took five years. Learning costs due to offshore employee turnover were the primary cost factor to get under control.",1937-4194,,10.1109/MS.2015.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106389,global software engineering;outsourcing;offshoring;offshore outsourcing;costs;cost savings;attrition;retention;learning curves;software development;software engineering,Outsourcing;Collaboration;Software development;Training;Remuneration;Outsourcing;Cost benefit analysis,cost reduction;outsourcing;salaries;software houses,offshoring hourly cost;offshore outsourcing;hourly wages;salaries;cost reduction;knowledge transfer;travel;attrition;miscommunication;Dutch software company;Indian vendor;indirect cost;Netherlands;learning cost;offshore employee turnover,,11.0,,10.0,,13 May 2015,,,IEEE,IEEE Magazines
444,445,Practical Combinatorial Interaction Testing: Empirical Findings on Efficiency and Early Fault Detection,J. Petke; M. B. Cohen; M. Harman; S. Yoo,"Computer Science Department, University College London, London, United Kingdom; Computer Science & Engineering Department, University of Nebraska-Lincoln, Lincoln, Nebraska, United States; Computer Science Department, University College London, London, United Kingdom; Computer Science Department, University College London, London, United Kingdom",IEEE Transactions on Software Engineering,15 Sep 2015,2015,41,9,901,924,"Combinatorial interaction testing (CIT) is important because it tests the interactions between the many features and parameters that make up the configuration space of software systems. Simulated Annealing (SA) and Greedy Algorithms have been widely used to find CIT test suites. From the literature, there is a widely-held belief that SA is slower, but produces more effective tests suites than Greedy and that SA cannot scale to higher strength coverage. We evaluated both algorithms on seven real-world subjects for the well-studied two-way up to the rarely-studied six-way interaction strengths. Our findings present evidence to challenge this current orthodoxy: real-world constraints allow SA to achieve higher strengths. Furthermore, there was no evidence that Greedy was less effective (in terms of time to fault revelation) compared to SA; the results for the greedy algorithm are actually slightly superior. However, the results are critically dependent on the approach adopted to constraint handling. Moreover, we have also evaluated a genetic algorithm for constrained CIT test suite generation. This is the first time strengths higher than 3 and constraint handling have been used to evaluate GA. Our results show that GA is competitive only for pairwise testing for subjects with a small number of constraints.",1939-3520,,10.1109/TSE.2015.2421279,"National Science Foundation; Air Force Office of Scientific Research; Engineering and Physical Sciences Research Council; DAASE: Dynamic Adaptive Automated Software Engineering; GISMO: Genetic Improvement of Software for Multiple Objectives; CREST: Centre for Research on Evolution, Search and Testing; DAASE; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081752,Combinatorial Interaction Testing;Prioritisation;Empirical Studies;Software Testing;Combinatorial interaction testing;prioritisation;empirical studies;software testing,Testing;Simulated annealing;Genetic algorithms;Fault detection;Greedy algorithms;Turning;Flexible printed circuits,genetic algorithms;greedy algorithms;program testing;simulated annealing;software fault tolerance,combinatorial interaction testing;early fault detection;software system configuration space;simulated annealing;SA;greedy algorithm;CIT test suite generation;constraint handling;pairwise testing;genetic algorithm,,50.0,,37.0,,8 Apr 2015,,,IEEE,IEEE Journals
445,446,"Regression Testing, Spoken Language, Crash-Inducing Commits, UML, and Legal Policy",J. C. Carver; J. Cabot; L. L. Minku; M. Torchiano,University of Alabama; Interdisciplinary Internet Institute; University of Leicester; Politecnico di Torino,IEEE Software,26 Feb 2016,2016,33,2,26,28,"This month's column reports on papers from the 2015 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, the 11th International Conference on Predictive Models and Data Analytics in Software Engineering, and the 2015 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems. The paper topics include regression testing, language policies, crash-inducing commits, UML, and model-based development.",1937-4194,,10.1109/MS.2016.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420467,regression testing;language policies;crash-inducing commits;UML;model-based development;software engineering;software development,,,,,,,5.0,,26 Feb 2016,,,IEEE,IEEE Magazines
446,447,"Repairing Games at Runtime or, How We Learned to Stop Worrying and Love Emergence",C. Lewis; J. Whitehead,"University of California, Santa Cruz; University of California, Santa Cruz",IEEE Software,18 Aug 2011,2011,28,5,53,59,"Games must be emergent, constantly surprising players by the possibilities they offer. However, emergence creates unpredictability, preventing developers from verifying that their games won't lead to undesirable states. Worse still, even when a bug is found, finding out how it occurred can be a significant challenge. The authors present Mayet, a system for monitoring software at runtime, and use it to repair a game as it executes. This capability lets developers focus on creating excellent gaming experiences and not worry about edge cases and untraceable bugs.",1937-4194,,10.1109/MS.2011.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5953580,games;reliability;error handling and recovery,Games;Maintenance engineering;Software engineering;Error analysis;Computer bugs;Runtime;Software reliability,computer games;software engineering,game repair;Mayet system;runtime software monitoring,,5.0,,9.0,,14 Jul 2011,,,IEEE,IEEE Magazines
447,448,Software Development Effort Estimation: Formal Models or Expert Judgment?,M. Jørgensen; B. Boehm; S. Rifkin,Simula Research Laboratory; University of Southern California; Master Systems,IEEE Software,24 Feb 2009,2009,26,2,14,19,"Which is better for estimating software project resources: formal models, as instantiated in estimation tools, or expert judgment? Two luminaries, debate this question in this paper. For this debate, they're taking opposite sides and trying to help software project managers figure out when, and under what conditions, each method would be best.",1937-4194,,10.1109/MS.2009.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786946,software project estimation;estimation tools;expert judgment;software development;process improvement,Programming;Software tools;Project management;Resource management;Software engineering;Predictive models;Computer industry;Research initiatives;Electric breakdown,software engineering,software development effort estimation;formal models;expert judgment;software project managers,,57.0,,15.0,,24 Feb 2009,,,IEEE,IEEE Magazines
448,449,What Do Developers Use the Crowd For? A Study Using Stack Overflow,R. Abdalkareem; E. Shihab; J. Rilling,"Concordia University, Montreal; Concordia University, Montreal; Concordia University, Montreal",IEEE Software,28 Mar 2017,2017,34,2,53,60,"Stack Overflow relies on the crowd to construct quality developer-related knowledge. To determine what developers use this knowledge for, researchers analyzed 1,414 Stack Overflow-related code commits. The developers used this knowledge to support development tasks and collect user feedback. The researchers also studied Stack Overflow posts' helpfulness and timeliness. The crowd was the most helpful on topics such as development tools and programming languages. The questions that took the longest to resolve were related to Web frameworks. The study findings can help developers better understand how to effectively use Stack Overflow, can help Stack Overflow designers improve their platform, and can help the research community understand Stack Overflow's strengths and weaknesses as a development tool. This article is part of a special issue on Crowdsourcing for Software Engineering.",1937-4194,,10.1109/MS.2017.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888410,crowdsourcing;Stack Overflow;analyzing commits;software development;software engineering,Computer bugs;Software development;Knowledge engineering;Delays;Browsers;Computer languages;Programming,crowdsourcing;programming;software development management;Web sites,software engineering;crowdsourcing;Stack Overflow designers;Web frameworks;programming languages;development tools;user feedback collection;development task support;Stack Overflow-related code;quality developer-related knowledge,,21.0,,14.0,,28 Mar 2017,,,IEEE,IEEE Magazines
449,450,Dynamic and Automatic Feedback-Based Threshold Adaptation for Code Smell Detection,H. Liu; Q. Liu; Z. Niu; Y. Liu,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China",IEEE Transactions on Software Engineering,10 Jun 2016,2016,42,6,544,558,"Most code smell detection tools expose thresholds to engineers for customization because code smell detection is essentially subjective and application specific. Another reason why engineers should customize these thresholds is that they have different working schedules and different requirements on software quality. They have their own unique need on precision and recall in smell detection. This unique need should be fulfilled by adjusting thresholds of smell detection tools. However, it is difficult for software engineers, especially inexperienced ones, to adjust often contradicting and related thresholds manually. One of the possible reasons is that engineers do not know the exact quantitative relation between threshold values and performance, e.g., precision. In this paper, we propose an approach to adapting thresholds automatically and dynamically. Engineers set a target precision manually according to their working schedules and quality requirements. With feedback from engineers, the proposed approach then automatically searches for a threshold setting to maximize recall while having precision close to the target precision. The proposed approach has been evaluated on open-source applications. Evaluation results suggest that the proposed approach is effective.",1939-3520,,10.1109/TSE.2015.2503740,National Natural Science Foundation of China; Program for New Century Excellent Talents in University; Beijing Higher Education Young Elite Teacher Project; National Natural Science Foundation of China; National Strategic Basic Research Program (“973” Program); Ministry of Science and Technology of China; The 111 Project of Beijing Institute of Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7337457,Software Refactoring;Code Smells;Feedback Control;Smell Identification;Software refactoring;code smells;feedback control;smell identification,Software;Detection algorithms;Cloning;Genetic algorithms;Schedules;Algorithm design and analysis;Measurement,software maintenance;software quality,feedback-based threshold adaptation;code smell detection;software quality;software engineering;open-source applications,,14.0,1.0,56.0,,25 Nov 2015,,,IEEE,IEEE Journals
450,451,Test Automation: Not Just for Test Execution,V. Garousi; F. Elberzhager,Hacettepe University; Fraunhofer Institute for Experimental Software Engineering,IEEE Software,28 Mar 2017,2017,34,2,90,96,"To work more efficiently and effectively, test engineers must be aware of various automated-testing strategies and tools that assist test activities other than test execution. However, automation doesn't come for free, so it must be carefully implemented.",1937-4194,,10.1109/MS.2017.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888399,test automation;software testing;test-case design;test scripting;test execution;test evaluation;test result reporting;test management;test engineering;software development;software engineering,Automation;Software testing;Software development;Automatic testing;Computer bugs,automatic testing;program testing,automated-testing strategies;test activities;test execution;test automation;software testing,,17.0,1.0,24.0,,28 Mar 2017,,,IEEE,IEEE Magazines
451,452,"Probing Questions, Participatory Democracy, Quality Assurance, and Customer Data",J. C. Carver; M. Paasivaara; B. Penzenstadler,"University of Alabama; Aalto University; California State University, Long Beach",IEEE Software,24 Aug 2016,2016,33,5,12,14,"This month's column reports on papers from the 38th International Conference on Software Engineering and the 17th International Conference on Agile Software Development. The topics covered include using requirements knowledge to stimulate architectural thinking, software support for participatory democracy, Scrum and quality assurance, and sharing customer data.",1937-4194,,10.1109/MS.2016.122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548906,agile development;Extreme Programming;software requirements;Scrum;quality assurance;customer data;SafeScrum;AppCivist-PB;participatory democracy;software development;software engineering,,,,,,,4.0,,24 Aug 2016,,,IEEE,IEEE Magazines
452,453,An Empirical Evaluation of Web-Based Fingerprinting,A. F. Khademi; M. Zulkernine; K. Weldemariam,Queen's University; Queen's University; IBM Research--Africa,IEEE Software,30 Jun 2015,2015,32,4,46,52,"Adversaries employ sophisticated fingerprinting techniques to identify Web users and record their browsing history and Web interactions. Fingerprinting leaves no footprint on the browser and is invisible to general Web users, who often lack basic knowledge of it. An analysis of fingerprinting techniques and tools revealed the fingerprinting workflow. This helped define fine-grained properties that precisely model the workflow, allowing development of a client-side fingerprinting-detection tool. This article is part of a special issue on Security and Privacy on the Web.",1937-4194,,10.1109/MS.2015.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106402,Fybrid;iFybrid;fingerprinting;user identification;Web privacy;software development;software engineering,Browsers;Fingerprint recognition;Entropy;Software development;Navigation;Privacy;Web services;Software engineering,data privacy;fingerprint identification;Internet,empirical evaluation;Web based fingerprinting;Web users;Web record;browsing history;Web interactions;fingerprinting techniques;fingerprinting tools;fingerprinting workflow;fine grained properties;client side fingerprinting detection tool,,6.0,,16.0,,13 May 2015,,,IEEE,IEEE Magazines
453,454,Coderetreats: Reflective Practice and the Game of Life,D. Parsons; A. Mathrani; T. Susnjak; A. Leist,Massey University; Massey University; Massey University; Massey University,IEEE Software,13 Jun 2014,2014,31,4,58,64,"A coderetreat is an event where software developers gather to spend a day exploring their craft in an informal yet intellectually challenging environment. It encourages reflective practice by addressing a single programming problem from different perspectives, with multiple coding partners, freed from the daily pressures of deadlines and the need to deliver completed artifacts. This article describes an experiment in which a coderetreat was run with a group of final-year undergraduates studying software architecture. The authors gathered qualitative and quantitative data to explore the ways in which the activity contributed to the participants' reflective practice. The results suggest that coderetreats are an excellent vehicle for reflective practice in software development, providing a context within which multiple aspects of self-reflection and motivation can be developed. The Web extra at http://youtu.be/racyZfkbgnQ is an audio recording in which author David Parsons expands on the article ""Coderetreats: Reflective Practice and the Game of Life,"" discussing how coderetreats can encourage self-reflection in software engineers.",1937-4194,,10.1109/MS.2014.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6756713,software psychology;coding tools and techniques;test design;self-assessment;software engineering;pervasive computing;project management,Software development;Software engineering;Information technology;Programming profession;Reflection;Electronic mail,,,,2.0,,10.0,,5 Mar 2014,,,IEEE,IEEE Magazines
454,455,Examining the Rating System Used in Mobile-App Stores,I. J. Mojica Ruiz; M. Nagappan; B. Adams; T. Berger; S. Dienst; A. E. Hassan,"McAfee; Rochester Institute of Technology; École Polytechnique de Montréal; University of Waterloo; University of Leipzig; Queen's University, Canada",IEEE Software,28 Oct 2016,2016,33,6,86,92,"Unlike products on Amazon.com, mobile apps are continuously evolving, with new versions rapidly replacing the old ones. Nevertheless, many app stores still use an Amazon-style rating system, which aggregates every rating ever assigned to an app into one store rating. To examine whether the store rating captures the changing user satisfaction levels regarding new app versions, researchers mined the store ratings of more than 10,000 mobile apps in Google Play, every day for a year. Even though many apps' version ratings rose or fell, their store rating was resilient to fluctuations once they had gathered a substantial number of raters. The conclusion is that current store ratings aren't dynamic enough to capture changing user satisfaction levels. This resilience is a major problem that can discourage developers from improving app quality.",1937-4194,,10.1109/MS.2015.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7045413,mobile apps;Android;Google Play;review systems;rating;software development;software engineering,Mobile communication;Google;Androids;Humanoid robots;Computer applications;Software engineering,customer satisfaction;mobile computing,mobile-app stores;mobile applications;Amazon-style rating system;user satisfaction level;app versions;Google Play;app quality,,22.0,,10.0,,19 Feb 2015,,,IEEE,IEEE Magazines
455,456,Onboarding in Open Source Projects,F. Fagerholm; A. Sanchez Guinea; J. Borenstein; J. Münch,University of Helsinki; University of Helsinki; Stanford University and Facebook; University of Helsinki,IEEE Software,7 Nov 2014,2014,31,6,54,61,"In today's world, many companies turn to open source projects as a method to increase productivity and innovation. A major challenge with managing this kind of development is the onboarding of new developers into the virtual teams that drive such projects. There's little guidance on how to initiate new members into such teams and how to overcome the learning curve. This case study on open source software projects shows that mentoring can have a significant impact on onboarding new members into virtual software development teams.",1937-4194,,10.1109/MS.2014.107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6879055,onboarding;open source software projects;virtual teams;mentoring;global software development;distributed software development;case study;software engineering,Virtual groups;Open source software;Open systems;Software engineering;Programming;Computer languages;Project management,public domain software;software development management,open source software project;virtual software development team;productivity;innovation,,21.0,,7.0,,15 Aug 2014,,,IEEE,IEEE Magazines
456,457,Using Defect Taxonomies for Testing Requirements,M. Felderer; A. Beer,University of Innsbruck; Beer Test Consulting,IEEE Software,23 Apr 2015,2015,32,3,94,101,"Systematic defect management based on bug-tracking systems such as Bugzilla is well established and has been successfully used in many software organizations. Defect management weights the failures observed during test execution according to their severity and forms the basis for effective defect taxonomies. In practice, most defect taxonomies are used only for the a posteriori allocation of testing resources to prioritize failures for debugging. Thus, these taxonomies' full potential to control and improve all the steps of testing has remained unexploited. This is especially the case for testing a system's user requirements. System-level defect taxonomies can improve the design of requirements-based tests, the tracing of defects to requirements, the quality assessment of requirements, and the control of the relevant defect management. So, we developed requirements-based testing with defect taxonomies (RTDT). This approach is aligned with the standard test process and uses defect taxonomies to support all phases of testing requirements. To illustrate this approach and its benefits, we use an example project (which we call Project A) from a public health insurance institution.",1937-4194,,10.1109/MS.2014.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6799150,requirements-based testing;defect taxonomy;test management;requirements validation;software quality;software engineering,Taxonomy;Software testing;Graphical user interfaces;Requirements engineering;Software engineering;Syntactics,program testing;software quality,systematic defect management;bug-tracking system;Bugzilla;a posteriori allocation;requirements quality assessment;requirements-based testing;defect taxonomies;RTDT,,6.0,,11.0,,16 Apr 2014,,,IEEE,IEEE Magazines
457,458,The Effectiveness of Pair Programming: Software Professionals' Perceptions,W. Sun; G. Marakas; M. Aguirre-Urreta,Washburn University; Florida International University; Texas Tech University,IEEE Software,23 Jun 2016,2016,33,4,72,79,"Researchers surveyed software professionals on their views regarding the effectiveness of pair programming compared to traditional solo programming. The survey produced three main findings. First, the respondents believed that project complexity and pair composition (the individual programmers' expertise and pair-programming experience) affect pair programming's effectiveness in terms of the effort, defect rate, knowledge transfer, and overall project cost. Second, respondents with pair-programming experience viewed pair programming more positively than those without it. Finally, the more pair-programming experience the respondents had, the more favorably they viewed pair programming.",1937-4194,,10.1109/MS.2015.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7274252,pair programming;solo programming;project complexity;pair composition;effort;defect rate;knowledge transfer;software engineering;software development,Programming profession;Complexity theory;Knowledge transfer;Software engineering;Programming;Organizations,programming;project management;software management;software prototyping,pair programming;software professional perception;knowledge transfer;project cost,,5.0,,9.0,,23 Sep 2015,,,IEEE,IEEE Magazines
458,459,The Top 10 Adages in Continuous Deployment,C. Parnin; E. Helms; C. Atlee; H. Boughton; M. Ghattas; A. Glover; J. Holman; J. Micco; B. Murphy; T. Savor; M. Stumm; S. Whitaker; L. Williams,North Carolina State University; Red Hat Software; Mozilla; IBM; Cisco Systems; Netflix; SAS; Google; Microsoft; Facebook; University of Toronto; LexisNexis; North Carolina State University,IEEE Software,15 May 2017,2017,34,3,86,95,"Continuous deployment involves automatically testing incremental software changes and frequently deploying them to production environments. With it, developers' changes can reach customers in days or even hours. Such ultrafast changes create a new reality in software development. To understand the emerging practices surrounding continuous deployment, researchers facilitated a one-day Continuous Deployment Summit at the Facebook campus in July 2015, at which participants from 10 companies described how they used continuous deployment. From the resulting conversation, the researchers derived 10 adages about continuous-deployment practices. These adages represent a working set of approaches and beliefs that guide current practice and establish a tangible target for empirical validation by the research community.",1937-4194,,10.1109/MS.2017.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927896,continuous deployment;rapid release;telemetry;software engineering;software development,Software testing;Telemetry;Software engineering;Software development;Software measurement,automatic testing;continuous improvement;program testing;social networking (online);software quality,automatic incremental software testing;production environments;software development;Continuous Deployment Summit;Facebook campus;research community,,21.0,,13.0,,15 May 2017,,,IEEE,IEEE Magazines
459,460,Verification and Validation for Trustworthy Software Systems,J. B. Michael; D. Drusinsky; T. W. Otani; M. Shing,Naval Postgraduate School; Naval Postgraduate School; Naval Postgraduate School; Naval Postgraduate School,IEEE Software,20 Oct 2011,2011,28,6,86,92,A continuous and proactive process for conducting verification and validation of systems involves using scenario-based testing to validate whether formal assertions correctly capture the intent of the natural language requirements. The process is automated through the use of statechart assertions and runtime execution monitoring. The statechart assertions can be used as part of a system reference model in support of independent verification and validation of trustworthy systems.,1937-4194,,10.1109/MS.2011.151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6055664,requirements;specification;validation;software;program;verification;assertion checker;assertion languages;performance;formal methods;software engineering,Software development;Formal verification;Software engineering;Programming;Validation;Performance evaluation,formal verification;program testing;safety-critical software,trustworthy software systems;software system verification;software system validation;scenario-based testing;natural language requirement;statechart assertion;runtime execution monitoring,,12.0,,17.0,,20 Oct 2011,,,IEEE,IEEE Magazines
460,461,Are We There Yet?: Simple Language Implementation Techniques for the 21st Century,S. Marr; T. Pape; W. De Meuter,"Inria Lille--Nord Europe; Hasso Plattner Institute, University of Potsdam; Vrije Universiteit Brussel",IEEE Software,15 Sep 2014,2014,31,5,60,67,"Research on language implementation techniques has regained importance with the rise of domain-specific languages (DSLs). Although DSLs can help manage a domain's complexity, building highly optimizing compilers or virtual machines is rarely affordable. So, performance remains an issue. Ideally, you would implement a simple interpreter and still be able to achieve acceptable performance. RPython and Truffle are implementation techniques based on simple interpreters; they promise to perform at the same order of magnitude as highly optimizing virtual machines. This case study compares the two techniques to identify their similarities, weaknesses, and areas for further research.",1937-4194,,10.1109/MS.2014.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898728,language implementation;virtual machines;compilers;interpreters;software engineering;programming languages;computer programming;RPython;Truffle;domain-specific languages,Programming;Computer applications;Computer languages;Java;Syntactics;Optimizing compilers;Software engineering,high level languages;operating systems (computers);program compilers;virtual machines,simple language implementation techniques;21st century;domain specific languages;DSL;virtual machines;optimizing compilers;RPython;Truffle,,6.0,,12.0,,15 Sep 2014,,,IEEE,IEEE Magazines
461,462,"Oh Dear, We Bought Our Competitor: Integrating Similar Software Systems",R. Land; I. Crnković,Mälardalen University; Mälardalen University,IEEE Software,28 Feb 2011,2011,28,2,75,82,"A look at 10 case studies addresses the technological, personnel, and organizational challenges. The 10 cases involved seven organizations in different business sectors. Our data collection methods included our participation in projects, several rounds of interviews with project leaders and software architects, and several rounds of questionnaires with software architects and project managers, as well as project and product documentation. 2 Companies we studied included ABB, Bombardier, Ericsson, Saab, and Westinghouse. However, we can't disclose detailed information or relate case descriptions to specific companies or systems. Our observations regarding cultural influences might be skewed because all the organizations involved Sweden and other European or North American countries.",1937-4194,,10.1109/MS.2010.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467014,software engineering;interoperability;process implementation;project management,Software engineering;Software maintenance;Project management;Engineering management;Distributed computing;Software systems;Management information systems;Corporate acquisitions;Software architecture,business data processing;organisational aspects;project management;question answering (information retrieval);software architecture;system documentation,software system;organizational challenge;business sector;data collection method;project leader;software architects;questionnaires;project managers;product documentation,,,,11.0,,20 May 2010,,,IEEE,IEEE Magazines
462,463,Test Better by Exploring: Harnessing Human Skills and Knowledge,J. Itkonen; M. V. Mäntylä; C. Lassenius,Aalto University; University of Oulu; Aalto University,IEEE Software,23 Jun 2016,2016,33,4,90,96,"Users continue to stumble upon software bugs, despite developers' efforts to build and test high-quality software. Although traditional testing and quality assurance techniques are extremely valuable, software testing should pay more attention to exploration. Exploration can directly apply knowledge and learning to the core of industrial software testing, revealing more relevant bugs earlier. This article describes exploration's characteristics, knowledge's role in software testing, and the three levels of exploratory-testing practices. Academics and practitioners should focus on exploiting exploration's strengths in software testing and on reporting existing practices and benefits in different academic and industrial contexts.",1937-4194,,10.1109/MS.2015.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155417,validation;testing strategies;test design;test management;software quality assurance;verification and validation;exploratory testing;session-based test management;confirmatory testing;software engineering;software development;software testing,Software testing;Computer bugs;Human factors;Automation;Documentation;Validation;Software engineering;Design methodology,program debugging;program testing;software quality,software bugs;high-quality software testing;quality assurance techniques;industrial software testing;software development;interactive systems,,3.0,,12.0,,13 Jul 2015,,,IEEE,IEEE Magazines
463,464,Non-functional Requirements in Architectural Decision Making,D. Ameller; C. Ayala; J. Cabot; X. Franch,BarcelonaTech—Universitat Politècnica de Catalunya; BarcelonaTech—Universitat Politècnica de Catalunya; École des Mines de Nantes; BarcelonaTech—Universitat Politècnica de Catalunya,IEEE Software,25 Feb 2013,2013,30,2,61,67,"Software architects often must work with incomplete or ill-specified non-functional requirements (NFRs) and use them to make decisions. Through this process, existing NFRs are refined or modified and new ones emerge. Although much research has centered on how software architects treat NFRs, no empirical studies have investigated the state of the practice. A survey based on interviews with 13 software architects addressed two fundamental issues: how do architects face NFRs from an engineering perspective, and how do NFRs influence their decision-making? The survey revealed that architects usually elicit NFRs themselves in an iterative process; they usually don't document the NFRs and only partially validate them.",1937-4194,,10.1109/MS.2012.176,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381398,nonfunctional requirements;non-functional requirements;NFR;quality requirements;architectural decisions;software engineering;software architecturecontent type,Software devlopment;Documentation;Software architecture;Decision making;Software engineering;Specifications,decision making;formal verification;software architecture,nonfunctional requirements;architectural decision making;software architects;NFR;engineering perspective,,38.0,,13.0,,13 Dec 2012,,,IEEE,IEEE Magazines
464,465,Achieving and Maintaining CMMI Maturity Level 5 in a Small Organization,D. Falessi; M. Shaw; K. Mullen,Fraunhofer CESE; Fraunhofer CESE; Keymind,IEEE Software,15 Sep 2014,2014,31,5,80,86,"CMMI (Capability Maturity Model Integration) models are collections of best practices that help organizations improve their processes. This article reports on the authors' experience in achieving and maintaining CMMI Maturity Level 5 in a small organization. Economic achievements, success factors, and lessons learned are reported by using real-life examples from almost 10 years of improvement process. This article could be a valuable and unique reference for practitioners intending to pursue high-maturity CMMI level, particularly in small organization settings. The importance of this topic and lack of similar experience reports make it a valuable contribution to the state of the practice. The first Web extra at http://youtu.be/HMbgNSFxkpE is an audio recording in which IEEE Software Multimedia Editor Davide Falessi speaks with Shane Oleson and Shannon Taylor of Keymind about how the organization achieved and maintained CMMI Maturity Level 5. The second Web extra at http://youtu.be/RKpKBo7roZI is an audio recording in which author Kathy Mullen introduces a custom Web-based tool called the Keymind Measurement Reporting Tool.",1937-4194,,10.1109/MS.2014.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6728932,process improvement;CMMI;experience report;case study;software engineering,Organizations;Standards organizations;Best practices;Reliability;Capability maturity model;Process control;Software engineering,Capability Maturity Model;Internet;organisational aspects,CMMI maturity level;capability maturity model integration;small organization;economic achievements;success factors;improvement process;Web-based tool;Keymind Measurement Reporting Tool,,15.0,,10.0,,30 Jan 2014,,,IEEE,IEEE Magazines
465,466,Operational and Strategic Learning in Global Software Development,A. Boden; B. Nett; V. Wulf,"University of Siegen, Siegen; University of Siegen, Siegen; University of Siegen, Siegen",IEEE Software,14 Oct 2010,2010,27,6,58,65,"In this paper, distributed software development is discussed. With increasing globalization, distributed software teams have become fairly common. Usually, companies that offshore their software development expect a reduction of costs and access to new markets. However, distributed teams often face problems related to globally distributed work's spatial, temporal, and cultural barriers. This paper also illustrates some of the challenges in organizational learning faced by small and medium enterprises engaged in offshore software development.",1937-4194,,10.1109/MS.2009.113,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5204064,management;software engineering;project and people management;management of computing and information systems;computing milieux;software development;offshoring;SME;software,Programming;Information systems;Project management;Engineering management;Software engineering;Distributed computing;Management information systems;Globalization;Costs;Cultural differences,globalisation;groupware;learning (artificial intelligence);outsourcing;small-to-medium enterprises;software cost estimation;software development management;team working,operational learning;strategic learning;global software development;distributed software development;cost reduction;organizational learning;small enterprise;medium enterprise;offshore software development,,9.0,,19.0,,18 Aug 2009,,,IEEE,IEEE Magazines
466,467,What Do Mobile App Users Complain About?,H. Khalid; E. Shihab; M. Nagappan; A. E. Hassan,Shopify; Concordia University; Rochester Institute of Technology; Queen's University,IEEE Software,23 Apr 2015,2015,32,3,70,77,"Mobile-app quality is becoming an increasingly important issue. These apps are generally delivered through app stores that let users post reviews. These reviews provide a rich data source you can leverage to understand user-reported issues. Researchers qualitatively studied 6,390 low-rated user reviews for 20 free-to-download iOS apps. They uncovered 12 types of user complaints. The most frequent complaints were functional errors, feature requests, and app crashes. Complaints about privacy and ethical issues and hidden app costs most negatively affected ratings. In 11 percent of the reviews, users attributed their complaints to a recent app update. This study provides insight into the user-reported issues of iOS apps, along with their frequency and impact, which can help developers better prioritize their limited quality assurance resources.",1937-4194,,10.1109/MS.2014.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6762802,mobile applications;software quality;user reviews;quality assurance;software engineering,Computer crashes;Privacy;Mobile communication;Tagging;Computer applications;Software quality;Quality assurance;Software engineering,mobile computing;operating systems (computers),mobile App users;mobile app quality;app stores;iOS apps;user complaints;frequent complaints;functional errors;feature requests;app crashes;ethical issues;privacy issues;quality assurance resources,,168.0,,6.0,,10 Mar 2014,,,IEEE,IEEE Magazines
467,468,"Microservices in Practice, Part 1: Reality Check and Service Design",C. Pautasso; O. Zimmermann; M. Amundsen; J. Lewis; N. Josuttis,"University of Lugano; University of Applied Sciences of Eastern Switzerland, Rapperswil; API Academy; ThoughtWorks; NA",IEEE Software,16 Jan 2017,2017,34,1,91,98,"Service-oriented architecture (SOA) and microservices insiders Mike Amundsen, James Lewis, and Nicolai Josuttis share their experiences and predictions with department editors Cesare Pautasso and Olaf Zimmermann.",1937-4194,,10.1109/MS.2017.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819415,microservices;service-oriented architecture;SOA;domain-driven design;DDD;Conway's law;Extreme Programming;XP;Mike Amundsen;James Lewis;Nicolai Josuttis;software engineering;software development,Service-oriented architecture;Software engineering;Semiconductor optical amplifiers;Computer architecture;Context modeling;Writing;Software development,service-oriented architecture,software architecture;software development;service-oriented architecture;microservices;service design;SOA,,47.0,,25.0,,16 Jan 2017,,,IEEE,IEEE Magazines
468,469,Application-Screen Masking: A Hybrid Approach,A. Goldsteen; K. Kveler; T. Domany; I. Gokhman; B. Rozenberg; A. Farkash,IBM Research--Haifa; Technion--Israel Institute of Technology; Intensix; IBM Research--Haifa; IBM Research--Haifa; IBM Research--Haifa,IEEE Software,30 Jun 2015,2015,32,4,40,45,"Large organizations often face difficult tradeoffs in balancing the need to share information with the need to safeguard sensitive data. A prominent way to deal with this tradeoff is on-the-fly screen masking of sensitive data in applications. A proposed hybrid approach for masking Web application screens combines the advantages of the context available at the presentation layer with the flexibility and low overhead of masking at the network layer. This solution can identify sensitive information in the visual context of the application screen and then automatically generate the masking rules to enforce at run time. This approach supports the creation of highly expressive masking rules, while keeping rule authoring easy and intuitive, resulting in an easy to use, effective system. This article is part of a special issue on Security and Privacy on the Web. The Web extra at https://youtu.be/4u2FLqjaIiI is a short demonstration of a proposed hybrid approach for masking Web application screens that combines the advantages of the context available at the presentation layer with the flexibility and low overhead of masking at the network layer. The second Web extra at https://youtu.be/-Hz3P_H0UnU is a full-length demonstration of a proposed hybrid approach for masking Web application screens that combines the advantages of the context available at the presentation layer with the flexibility and low overhead of masking at the network layer.",1937-4194,,10.1109/MS.2015.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106392,Web security;Web privacy;screen masking;data masking;context-based rules;Web applications;Web apps;software engineering;software development,Visualization;Computer security;Web services;Browsers;Context modeling;Security;HTML;Software engineering;Software developmnet,authorisation;data privacy;information management;Internet,application-screen masking;information sharing;sensitive data masking;presentation layer;network layer;rule authoring;data security;data privacy;Web application screens,,4.0,,7.0,,13 May 2015,,,IEEE,IEEE Magazines
469,470,Guidelines for Managing Requirements Rationales,A. K. Thurimella; M. Schubanz; A. Pleuss; G. Botterweck,Harman and Technical University of Munich; Brandenburg University of Technology Cottbus-Senftenberg; Lero; Lero,IEEE Software,16 Jan 2017,2017,34,1,82,90,"Requirements are identified and elaborated on the basis of stakeholders' decisions. The reasoning behind those decisions can be expressed as rationales. Systematic rationale management offers both short-term benefits, such as clearer requirements leading to fewer defects, and long-term benefits, such as simplified requirements evolution. However, little guidance exists for managing requirements rationales. This article presents guidelines to pragmatically capture, trace, maintain, and reuse such rationales. A list of questions augments the guidelines, improving their usability.",1937-4194,,10.1109/MS.2015.157,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325184,requirements engineering;rationale;knowledge management;software evolution;software development;software engineering,Stakeholders;Requirements engineering;Organizations;Software engineering;Systematics,formal specification;formal verification;software maintenance;software reusability,requirements rationale management;requirements rationale reusability;requirements rationale maintainability;requirements rationale traceability,,3.0,,13.0,,11 Nov 2015,,,IEEE,IEEE Magazines
470,471,Components in the Pipeline,I. Gorton; A. Wynne; Y. Liu; J. Yin,Pacific Northwest National Laboratory; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory; Pacific Northwest National Laboratory,IEEE Software,25 Apr 2011,2011,28,3,34,40,"State-of-the-art scientific instruments and simulations routinely produce massive datasets requiring intensive processing to disclose key features of the artifact or model under study. Scientists commonly call these data-processing pipelines, which are structured according to the pipe and-filter architecture pattern.1 Different stages typically communicate using files; each stage is an executable program that performs the processing needed at that point in the pipeline.The MeDICi (Middleware for Data-Intensive Computing) Integration Framework supports constructing complex software pipelines from distributed heterogeneous components and controlling qualities of service to meet performance, reliability and communication requirements.",1937-4194,,10.1109/MS.2011.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5719591,scientific software;pipelines;components;software engineering,Software engineering;Quality of service;Protocols;Data preprocessing,middleware;pipeline processing;software quality;software reliability,state-of-the-art scientific instruments;massive datasets;data-processing pipelines;pipe-and-filter architecture;MeDICi integration framework;qualities of service;reliability;middleware for data-intensive computing,,12.0,,8.0,,24 Feb 2011,,,IEEE,IEEE Magazines
471,472,Creating Self-Adapting Mobile Systems with Dynamic Software Product Lines,N. Gámez; L. Fuentes; J. M. Troya,University of Malaga; University of Malaga; University of Malaga,IEEE Software,10 Mar 2015,2015,32,2,105,112,"Mobile systems must cope with continuous context changes, making them an ideal fit with dynamic software product lines (DSPLs), which enable product adaptation at run time. In this DSPL-based process, devices upload only a small reconfiguration plan rather than the entire variability model, and providers manage diversity without disrupting the base model.",1937-4194,,10.1109/MS.2014.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6730834,dynamic reconfiguration;software product lines;mobile systems;software engineering,Context modeling;Adaptation models;Mobile communication;Unified modeling language;Runtime;Load modeling;Software engineering,mobile computing;software product lines,creating self-adapting mobile systems;dynamic software product lines;DSPL based process;product adaptation;variability model,,8.0,,13.0,,3 Feb 2014,,,IEEE,IEEE Magazines
472,473,Arguing Conformance,P. Graydon; I. Habli; R. Hawkins; T. Kelly; J. Knight,University of York; University of York; University of York; University of York; University of Virginia,IEEE Software,20 Apr 2012,2012,29,3,50,57,"Conformance to software standards plays an essential role in establishing confidence in high-integrity software systems. However, standards conformance suffers from uncertainty about its meaning for three reasons: because requirements of the standard must be interpreted to fit the specifics of the application; because standards can deliberately leave options for developers; and because goal-based software standards exist that simply specify the high-level principles of software assurance without prescribing a specific means of compliance. The overall effect of these issues is that when conformance to a software assurance standard is claimed, there can be a lack of clarity as to exactly what the claim entails. This article draws on principles and practice from the domain of safety argument construction to describe the use of explicit and structured conformance arguments to help address this problem.",1937-4194,,10.1109/MS.2012.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155712,standards;software and system safety;software engineering,Software;IEC standards;Safety;Educational institutions;Software engineering;Context,safety-critical software,arguing conformance;software standards;high integrity software systems;goal based software standards;software assurance;safety argument construction;safety-critical software,,34.0,,9.0,,21 Feb 2012,,,IEEE,IEEE Magazines
473,474,What Differentiates Chilean Niche Software Companies: Business Knowledge and Reputation,S. F. Ochoa; R. Robbes; M. Marques; L. Silvestre; A. Quispe,University of Chile; University of Chile; University of Chile; University of Chile; University of Chile,IEEE Software,15 May 2017,2017,34,3,96,103,"Chilean small software companies suffer a high mortality rate. Focus groups with 20 entrepreneurs and project managers from such companies shed light on what makes niche software companies more likely to survive. The extensive knowledge allowed by specializing in a niche increases the odds of success. Consequently, a company's improved reputation lets it better negotiate contracts and improve its financial situation.",1937-4194,,10.1109/MS.2017.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927917,small software companies;niche software companies;startup sustainability;software engineering;software development;Chilean software companies,Business;Software engineering;Contracts;Knowledge engineering;Encoding;Market opportunities;Market research,business data processing;contracts;financial management;project management;software houses;software management,Chilean small software companies;mortality rate;contracts;financial situation;business reputation;business knowledge;software company success,,2.0,,14.0,,15 May 2017,,,IEEE,IEEE Magazines
474,475,Achieving Reliable High-Frequency Releases in Cloud Environments,L. Zhu; D. Xu; A. B. Tran; X. Xu; L. Bass; I. Weber; S. Dwarakanathan,NICTA; NICTA; NICTA; NICTA; NICTA; NICTA; NICTA,IEEE Software,10 Mar 2015,2015,32,2,73,80,"Continuous delivery and deployment are dramatically shortening release cycles from months to hours. Cloud applications with high-frequency releases often rely heavily on automated tools and cloud infrastructure APIs to deploy new software versions. The authors report on reliability issues and how these tools and APIs contribute to them. They also analyze the trade-offs between using heavily baked and lightly baked virtual-image approaches, on the basis of experiments with Amazon Web Service OpsWorks APIs and the Chef configuration management tool. Finally, they propose error-handling practices for continuous-delivery facilities.",1937-4194,,10.1109/MS.2015.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006340,release engineering;continuous delivery;continuous deployment;DevOps;system administration;software engineering,Continuous production;Software reliability;Software development;Cloud computing;Virtual machining;Software engineering,application program interfaces;cloud computing;software reliability,achieving reliable high frequency releases;cloud environments;cloud applications;automated tools;cloud infrastructure API;software versions;virtual image approaches;Amazon Web Service OpsWorks API;chef configuration management tool,,11.0,,5.0,,12 Jan 2015,,,IEEE,IEEE Magazines
475,476,Embedding Reflection and Learning into Agile Software Development,J. Babb; R. Hoda; J. Nørbjerg,West Texas A&M University; University of Auckland; Aalborg University,IEEE Software,13 Jun 2014,2014,31,4,51,57,"The theoretical underpinnings of agile methods emphasize regular reflection as a means to sustainable development pace and continuous learning, but in practice, high iteration pressure can diminish reflection opportunities. The Reflective Agile Learning Model (REALM) combines insights and results from studies of agile development practices in India, New Zealand, and the US with Schön's theory of reflective practice to embed reflection in everyday agile practices.",1937-4194,,10.1109/MS.2014.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785921,reflective practice;agile software development;reflection-in-action;reflection-on-action;learning teams;learning organizations;software engineering;pervasive computing;project management,Software engineering;Software development;Reflection;Learning systems;Project management;Pervasive computing,learning (artificial intelligence);software prototyping;sustainable development,agile software development;theoretical underpinnings;sustainable development;continuous learning;high iteration pressure;reflective agile learning model;REALM;India;New Zealand;US,,20.0,,12.0,,9 Apr 2014,,,IEEE,IEEE Magazines
476,477,Tangible and Screen-Based Interfaces for End-User Workflow Modeling,A. Boden; C. Dörner; S. Draxler; V. Pipek; G. Stevens; V. Wulf,University of Siegen and Fraunhofer FIT; University of Siegen and Fraunhofer FIT; University of Siegen and Fraunhofer FIT; University of Siegen and Fraunhofer FIT; University of Siegen and Fraunhofer FIT; University of Siegen and Fraunhofer FIT,IEEE Software,13 Jun 2014,2014,31,4,65,71,"Bridging the gap between business needs and IT solutions is a major challenge in service-oriented computing, and recent research emphasizes the importance of including end users in service-based application development. An analysis of two different approaches - tangible and screen-based versions of tools - demonstrates how users can participate in the development of technical workflow models based on their perception of business processes.",1937-4194,,10.1109/MS.2013.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6515478,organizational management and coordination;human factors in software design;process infrastructure;software engineering;pervasive computing;project management,Software engineering;Computational modeling;Software development;User interfaces;Ports (Computers);Computers;Workflow management software,service-oriented architecture;user interfaces;workflow management software,tangible interface;screen-based interface;end-user workflow modeling;service-oriented computing;service-based application development;business process,,,,15.0,,13 May 2013,,,IEEE,IEEE Magazines
477,478,Secure Automotive Software: The Next Steps,L. Pike; J. Sharp; M. Tullsen; P. C. Hickey; J. Bielman,Galois; Galois; Galois; Galois; Galois,IEEE Software,15 May 2017,2017,34,3,49,55,"Previous research revealed pervasive software vulnerabilities in modern automobiles. This article presents a rejoinder to that research, discussing four general approaches to secure automotive software systems: compile-time assurance, runtime protection, automated testing, and architectural security. The authors discuss these approaches in the context of previous automotive exploits and the authors' work to build secure cyber-physical systems.",1937-4194,,10.1109/MS.2017.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927919,automotive software;security;software assurance;HACMS;High-Assurance Cyber Military Systems;software development;software engineering,Software engineering;Software testing;Automotive engineering;Cryptography;Computer security;Military communication,automotive engineering;cyber-physical systems;security of data,secure cyber-physical systems;architectural security;automated testing;runtime protection;compile-time assurance;automotive software system security,,3.0,,27.0,,15 May 2017,,,IEEE,IEEE Magazines
478,479,Projecting a Modular Future,M. Voelter; J. Warmer; B. Kolb,independent consultant; independent consultant; itemis,IEEE Software,21 Aug 2015,2015,32,5,46,52,"Two innovations are enhancing programming languages' capabilities. First, modularity lets you combine independently developed languages without changing their respective definitions. A language is no longer a fixed quantity; you can extend it with domain-specific constructs as needed. Second, projectional editing lets you build editors and IDEs that don't require parsers. Such editors and IDEs support a range of tightly integrated notations, including textual, symbolic, tabular, and graphical notations. In addition, by avoiding parsers, they avoid grammar composition's well-known limitations. Three examples illustrate how these two innovations affect programming-language design. A set of modular extensions of C for embedded programming enables efficient code generation and formal analysis. A language for requirements engineering flexibly combines structured and unstructured (prose) data. Finally, a language for defining insurance rules uses mathematical notation. These examples all rely on the open source JetBrains MPS (Meta Programming System) language workbench. This article is part of a special issue on Software Architecture.",1937-4194,,10.1109/MS.2014.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6866847,language engineering;language workbenches;projectional editing;domain-specific languages;programming languages;software engineering;MPS;Meta Programming System;mbeddr;software development,Syntactics;Generators;Embedded software;Programming;Computer languages;Software engineering;Software development,C language;formal specification;formal verification;program compilers;public domain software,requirements engineering;unstructured data;structured data;insurance rules;projectional editing;IDEs;graphical notations;tabular notations;symbolic notations;textual notations;grammar composition;programming-language design;C modular extensions;embedded programming;code generation;formal analysis;mathematical notation;open source JetBrains MPS;meta programming system language workbench;software architecture,,8.0,,8.0,,28 Jul 2014,,,IEEE,IEEE Magazines
479,480,Challenges to and Solutions for Refactoring Adoption: An Industrial Perspective,T. Sharma; G. Suryanarayana; G. Samarthyam,Siemens Technology and Services Private Limited; Siemens Technology and Services Private Limited; independent consultant and corporate trainer,IEEE Software,28 Oct 2015,2015,32,6,44,51,"Refactoring is a key approach for managing technical debt. In the past few years, refactoring techniques and tools have received considerable attention from researchers and tool vendors. However, several practical challenges must be overcome to facilitate the adoption of refactoring in industrial contexts. Results from a survey at the Siemens Corporate Development Center India highlight common challenges to refactoring adoption. The article also outlines ways to address these challenges and describes key initiatives the development center is planning and launching. This article is part of a special issue on Refactoring.",1937-4194,,10.1109/MS.2015.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7274239,refactoring;software design;design tools and techniques;quality analysis and evaluation;software engineering;software development,Software development;Code refractoring;Organizations;Technological innovation;Programming;Software engineering;Project management,DP industry;software maintenance;software tools,refactoring technique;refactoring tool;technical debt management;industrial context;Siemens Corporate Development Center India,,9.0,,16.0,,23 Sep 2015,,,IEEE,IEEE Magazines
480,481,Collaborative Repositories in Model-Driven Engineering [Software Technology],J. Di Rocco; D. Di Ruscio; L. Iovino; A. Pierantonio,University of L'Aquila; University of L'Aquila; University of L'Aquila; University of L'Aquila,IEEE Software,23 Apr 2015,2015,32,3,28,34,"Recently proposed model repositories aim to support specific needs--for example, collaborative modeling, the ability to use different modeling tools in software life-cycle management, tool interoperability, increased model reuse, and the integration of heterogeneous models.",1937-4194,,10.1109/MS.2015.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093036,model-driven engineering;MDE;model repositories;software engineering;software development;MDEForge,Unified modeling language;Software engineering;Adaptation models;Collaboration;Model driven engineering;Interoperability;Software development,open systems;software development management;software reusability,collaborative repositories;model-driven engineering;collaborative modeling;software life-cycle management;tool interoperability;model reuse;heterogeneous model integration,,27.0,,7.0,,23 Apr 2015,,,IEEE,IEEE Magazines
481,482,A Reference Architecture and Knowledge-Based Structures for Smart Manufacturing Networks,M. P. Papazoglou; W. van den Heuvel; J. E. Mascolo,Tilburg University; Tilburg University; Fiat Research Center,IEEE Software,23 Apr 2015,2015,32,3,61,69,"Smart manufacturing networks describe a production chain as a marketplace that delivers products on demand. In this chain, partners collaborate in product work routings that connect dispersed service-enabled systems with resources, materials, human expertise, and operation-equipment combinations. Researchers have developed a reference architecture for developing a highly connected, knowledge-enabled manufacturing network that decentralizes production control. This network will enable collaborative manufacturing of new products and response to product demand, allowing for greater production flexibility and product variability.",1937-4194,,10.1109/MS.2015.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093038,smart manufacturing networks;reference architecture for manufacturing;manufacturing lifecycle methods;knowledge-based model for smart manufacturing;manufacturing analytics;resource integration and interoperation;automotive systems;software engineering;software development,Manufacturing;Software variability;Computer architecture;Service-oriented architecture;Knowledge management;Automotive engineering;Automotive engineering;Software engineering,knowledge based systems;manufacturing systems,product variability;production flexibility;collaborative manufacturing;production control;knowledge-enabled manufacturing network;operation-equipment combinations;dispersed service-enabled systems;product work routings;production chain;smart manufacturing networks;knowledge-based structures;reference architecture,,35.0,,7.0,,23 Apr 2015,,,IEEE,IEEE Magazines
482,483,Vroom: Faster Build Processes for Java,J. Bell; E. Melski; M. Dattatreya; G. E. Kaiser,Columbia University; Electric Cloud; Electric Cloud; Columbia University,IEEE Software,10 Mar 2015,2015,32,2,97,104,"Build processes are too slow. Because most of the build time for Java projects is spent executing tests, researchers have focused on speeding up testing. They've integrated two complementary approaches into a system that seamlessly supports Ant and Maven JUnit build processes. The first approach, unit test virtualization, isolates in-memory dependencies among test cases, which otherwise are isolated inefficiently by restarting the Java Virtual Machine (JVM) before every test. The system supports just-in-time reinitialization of only the small portion of memory needed by the next test, reusing a single JVM. The implementation of this approach is called VMVM (Virtual Machine in the Virtual Machine, pronounced ""vroom vroom""). In addition, simple setup and tear-down resource management methods designed for sequential execution lead to conflicts when the resources are accessed concurrently. So, the second approach, virtualized unit test virtualization, isolates external dependencies such as files and network ports while long-running tests execute in parallel. For this, the system distributes testing jobs in round-robin manner among OS-level virtual machines. The result is, on average, a 51 percent speedup of application build times. The implementation of this approach is called VMVMVM (Virtual Machine in a Virtual Machine on a Virtual Machine ""vroom vroom vroom"").",1937-4194,,10.1109/MS.2015.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006344,test execution;testing tools;software engineering,Software development;Java;Virtual machining;Ports (Computers);Open source software;Continuous production;Software testing;Software engineering,Java;operating systems (computers);resource allocation;virtual machines;virtualisation,Java projects;Ant and Maven JUnit build processes;unit test virtualization;in-memory dependencies;Java virtual machine;JVM;just-in-time reinitialization;VMVM;tear-down resource management methods;virtualized unit test virtualization;long-running tests;round-robin manner;OS-level virtual machines;vroom vroom vroom;virtual machine in a virtual machine on a virtual machine,,4.0,,5.0,,12 Jan 2015,,,IEEE,IEEE Magazines
483,484,Chaos Engineering,A. Basiri; N. Behnam; R. de Rooij; L. Hochstein; L. Kosewski; J. Reynolds; C. Rosenthal,Netflix; Netflix; Netflix; Netflix; Netflix; Netflix; Netflix,IEEE Software,25 Apr 2016,2016,33,3,35,41,Modern software-based services are implemented as distributed systems with complex behavior and failure modes. Many large tech organizations are using experimentation to verify such systems' reliability. Netflix engineers call this approach chaos engineering. They've determined several principles underlying it and have used it to run experiments. This article is part of a theme issue on DevOps.,1937-4194,,10.1109/MS.2016.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436642,chaos engineering;Chaos Monkey;Netflix;DevOps;software development;software engineering,Chaos theory;Streaming media;Production processes;Steady-state;Software engineering;Organizations,chaos;distributed processing;software reliability;systems analysis,software-based services;distributed systems;system reliability;Netflix engineers;chaos engineering;DevOps,,43.0,,11.0,,18 Mar 2016,,,IEEE,IEEE Magazines
484,485,A Test Framework for Communications-Critical Large-Scale Systems,M. A. Nabulsi; R. M. Hierons,Brunel University; Brunel University,IEEE Software,23 Apr 2015,2015,32,3,86,93,"Today's large-scale systems couldn't function without the reliable availability of a range of network communications capabilities. Software, hardware, and communications technologies have been advancing throughout the past two decades. However, the methods that industry commonly uses to test large-scale systems that incorporate critical communications interfaces haven't kept pace. The need exists for a specifically tailored framework to achieve effective, precise testing of communications-critical large-scale systems. A proposed test framework offers an alternative to the current generic approaches that lead to inefficient, costly testing in industry. A case study illustrates its benefits, which can also be realized with other comparable systems.",1937-4194,,10.1109/MS.2014.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6785925,testing;test framework;communications-critical large-scale systems;IT systems;test case prioritization;requirements prioritization;software engineering,Software testing;Large-scale systems;Requirements engineering;Software engineering;Information technology;ISO standards,program testing;safety-critical software,communications-critical large-scale systems;network communication capability;formal software test methodology;communication technology;software technology;hardware technology,,,,8.0,,9 Apr 2014,,,IEEE,IEEE Magazines
485,486,Automated Synthesis of Service Choreographies,M. Autili; P. Inverardi; M. Tivoli,University of L'Aquila; University of L'Aquila; University of L'Aquila,IEEE Software,4 Feb 2015,2015,32,1,50,57,"Future Internet research promotes the production of a distributed-computing environment that will be increasingly surrounded by a virtually infinite number of software services that can be composed to meet user needs. Services will be increasingly active entities that, communicating peer-to-peer, can proactively make decisions and autonomously perform tasks. Service choreography is a form of decentralized service composition that describes peer-to-peer message exchanges among participant services from a global perspective. In a distributed setting, obtaining the coordination logic required to realize a choreography is nontrivial and error prone. So, automatic support for realizing choreographies is needed. For this purpose, researchers developed a choreography synthesis tool. The Web extra at http://www.di.univaq.it/marco.autili/synthesis/shortdemo/demo.htm is a short demonstration of CHOReOSynt, a choreography synthesis tool.",1937-4194,,10.1109/MS.2014.131,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915593,Future Internet;service choreographies;automated synthesis;distributed coordination;software engineering,Software engineering;Business;Peer-to-peer computing;Collaboration;Internet;XML;Distributed processing,Internet;peer-to-peer computing,service choreography automated synthesis;future Internet research;distributed-computing environment;software services;peer-to-peer communication;decentralized service composition;peer-to-peer message exchange;coordination logic;CHOReOSynt,,23.0,,10.0,,2 Oct 2014,,,IEEE,IEEE Magazines
486,487,Responsibility-Driven Architecture,S. Blair; R. Watt; T. Cull,Outformations; Outformations; Thedwick,IEEE Software,25 Feb 2010,2010,27,2,26,32,"Responsibility-driven architecture (RDA) explores when, how, and who should make architectural decisions. The author's research attempts to answer these questions from an agile perspective and proposes a framework to improve architectural design. It has also provided an opportunity to reframe the role and relevancy of the architect in agile development.",1937-4194,,10.1109/MS.2010.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420795,agile;software architecture;economics;software engineering process,Computer architecture;Security;Economics;Agile manufacturing;Programming;Software engineering,decision making;software architecture;software prototyping,responsibility driven architecture;architectural decision;agile development;architectural design,,8.0,,6.0,,25 Feb 2010,,,IEEE,IEEE Magazines
487,488,Diagnosing Energy Efficiency and Performance for Mobile Internetware Applications,Y. Liu; C. Xu; S. Cheung,The Hong Kong University of Science and Technology; Nanjing University; The Hong Kong University of Science and Technology,IEEE Software,4 Feb 2015,2015,32,1,67,75,"Many smartphone applications' smart services are realized in a way that wastes energy or degrades performance, seriously affecting the user experience. What's worse, developers lack powerful tools to combat such problems, curbing the growth of Internet-based mobile computing. Research communities and industries have issued a strong call for effective techniques to diagnose energy and performance bugs in smartphone applications. This article describes bug characteristics, discusses diagnostic challenges, and reviews state-of-the-art diagnostic techniques. A case study shows how a representative tool analyzed commercial Android applications and the Samsung Mobile Software Developer's Kit, providing useful diagnostic information.",1937-4194,,10.1109/MS.2015.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030255,smartphone applications;energy efficiency;performance bugs;automated diagnosis;Android;Internet;Internetware;software engineering,Computer bugs;Global Positioning System;Sensors;Smart phones;Batteries;Graphical user interfaces;Software engineering;Internet;Androids;Energy efficiency,energy conservation;Internet;mobile computing;program debugging;smart phones,energy efficiency diagnosis;performance bugs;mobile Internetware applications;smartphone application smart services;Internet-based mobile computing;bug characteristics;commercial Android applications;Samsung Mobile Software Developer Kit,,18.0,,15.0,,4 Feb 2015,,,IEEE,IEEE Magazines
488,489,Run-Time Variability for Context-Aware Smart Workflows,A. Murguzur; S. Trujillo; H. Truong; S. Dustdar; Ó. Ortiz; G. Sagardui,IK4-Ikerlan; IK4-Ikerlan; Vienna University of Technology; Vienna University of Technology; Technical University of Madrid; Mondragon University,IEEE Software,23 Apr 2015,2015,32,3,52,60,"In variant-rich workflow-based systems, a major concern for process variability is the context-aware configuration of the variants. This means that context information, not users, drives process configuration. To support context-aware process configuration in a dynamic environment, in which context information is available only at run time, smart workflows must be customized at run time. The LateVa (Late Variability for Context-Aware Smart Workflows) framework lets developers model and manage process variability by composing base models, fragments, and variability models and by deferring binding to run time. Base models and fragments are reusable, thereby reducing the modeling effort for developing variants. LateVa also includes an automated run-time-variability mechanism for context-aware smart workflows.",1937-4194,,10.1109/MS.2015.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093015,reuse models;current awareness systems;late binding;process variability;workflow-based systems;software engineering,Software variability;Context modeling;Data models;Workflow management software;Adaptation models;Software engineering,software development management;software reusability;ubiquitous computing;workflow management software,context-aware smart workflows;variant-rich workflow-based systems;context-aware configuration;process configuration;LateVa framework;late variability for context-aware smart workflows;process variability;automated run-time-variability mechanism,,4.0,,7.0,,23 Apr 2015,,,IEEE,IEEE Magazines
489,490,Scalable-Application Design for the IoT,J. Venkatesh; B. Aksanli; C. S. Chan; A. S. Akyürek; T. S. Rosing,"University of California, San Diego; San Diego State University; University of California, San Diego; University of California, San Diego; University of California, San Diego",IEEE Software,16 Jan 2017,2017,34,1,62,70,"The Internet of Things envisions a Web-connected infrastructure of sensing and actuation devices. However, the current state of the art presents another reality: monolithic end-to-end applications tightly coupled to a limited set of sensors and actuators. Growing such applications with new devices or behaviors, or extending the existing infrastructure with new applications, involves redesign and deployment. A proposed approach breaks these applications up into an equivalent set of functional units called context engines, whose I/O transformations are driven by general-purpose machine learning. This approach decreases computational redundancy and complexity with a minimal impact on accuracy. Researchers evaluated this approach's scalability--how the context engines' overhead grows as the input data and number of computational nodes increase. In a large-scale case study of residential smart-grid control, this approach provided better accuracy and scaling than the state-of-the-art single-stage approach.",1937-4194,,10.1109/MS.2017.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819406,context-aware computing;Internet of Things;software engineering;software development;smart grid;smart-grid control;context engines,Internet of things;Scalability;Context awareness;Software engineering;Smart grids,Internet;Internet of Things;learning (artificial intelligence);power engineering computing;smart power grids,scalable-application design;IoT applications;functional units;context engines;I/O transformations;machine learning;Web-connected infrastructure;sensing devices;actuation devices;computational nodes;input data;residential smart-grid control;Internet of Things,,12.0,,14.0,,16 Jan 2017,,,IEEE,IEEE Magazines
490,491,Toward Data-Driven Requirements Engineering,W. Maalej; M. Nayebi; T. Johann; G. Ruhe,University of Hamburg; University of Calgary; University of Hamburg; University of Calgary,IEEE Software,29 Dec 2015,2016,33,1,48,54,"Nowadays, users can easily submit feedback about software products in app stores, social media, or user groups. Moreover, software vendors are collecting massive amounts of implicit feedback in the form of usage data, error logs, and sensor data. These trends suggest a shift toward data-driven user-centered identification, prioritization, and management of software requirements. Developers should be able to adopt the requirements of masses of users when deciding what to develop and when to release. They could systematically use explicit and implicit user data in an aggregated form to support requirements decisions. The goal is data-driven requirements engineering by the masses and for the masses.",1937-4194,,10.1109/MS.2015.153,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325177,app reviews;decision support;requirements engineering;software analytics;usage data;software engineering;software development,Requirements engineering;Software engineering;Stakeholders;Media;Feature extraction;Market research,formal specification;software management,data-driven requirements engineering;user feedback;software products;software vendors;usage data;error logs;sensor data;data-driven user-centered software requirement identification;data-driven user-centered software requirement prioritization;data-driven user-centered software requirement management;explicit user data;implicit user data,,93.0,,19.0,,11 Nov 2015,,,IEEE,IEEE Magazines
491,492,"Writing Code to Prototype, Ideate, and Discover",J. Brandt; P. J. Guo; J. Lewenstein; M. Dontcheva; S. R. Klemmer,Stanford University; Stanford University; GoodGuide.com; Adobe Systems; Stanford University,IEEE Software,25 Aug 2009,2009,26,5,18,24,"People often write code to prototype, ideate, and discover. To do this, they work opportunistically, emphasizing speed and ease of development over code robustness and maintainability. Quickly hacking a program together can provide both practical and learning benefits for novices and experts: professional programmers and designers prototype to explore and communicate ideas, scientists program laboratory instruments, and entrepreneurs assemble complex spreadsheets to better understand their business. Their diverse activities share an emphasis on speed and ease of development over robustness and maintainability.",1937-4194,,10.1109/MS.2009.147,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222789,opportunistic programming;prototyping;debugging;software engineering,Writing;Prototypes;Programming profession;Hardware;Software prototyping;Software engineering;HTML;Java;Interleaved codes;Compressors,computer crime;software maintenance;software prototyping,opportunistic programming;code writing;code robustness;maintainability;hacking,,18.0,,12.0,,25 Aug 2009,,,IEEE,IEEE Magazines
492,493,Analyzing Ad Library Updates in Android Apps,I. J. Mojica Ruiz; M. Nagappan; B. Adams; T. Berger; S. Dienst; A. E. Hassan,McAfee; Rochester Institute of Technology; Ecole Polytechnique de Montreal; University of Waterloo; University of Leipzig; Queen's University,IEEE Software,26 Feb 2016,2016,33,2,74,80,"Because more than 90 percent of mobile apps are free, advertising on them is a key revenue source for their developers. Advertisements are served on apps through embedded specialized code called ad libraries. Unlike with other types of libraries, app developers can't ignore new ad libraries or new versions of embedded ad libraries without risking revenue loss. However, updating ad libraries incurs costs, which can become problematic as these updates become more frequent. Researchers investigated the costs of updating ad libraries and explored the frequency of ad library updates in Android apps. An analysis of numerous versions of Android apps over 12 months showed that almost half underwent ad library updates (an ad library was added, removed, or updated). Moreover, in nearly 14 percent of the app updates with at least one ad library update, no changes to the app's API occurred. This suggests that maintaining the ad libraries entailed substantial additional effort for the developers.",1937-4194,,10.1109/MS.2014.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420512,mobile apps;advertisement libraries;software maintenance;Android;Google Play;software engineering;software development,Computer applications;Mobile communication;Software maintenance;Software engineering;Androids;Humanoid robots,advertising;Android (operating system);application program interfaces;mobile computing;software libraries,advertisement library update analysis;Android application;mobile applications;revenue loss;library addition;application API;library removal,,14.0,,17.0,,26 Feb 2016,,,IEEE,IEEE Magazines
493,494,The Road Ahead for Architectural Languages,P. Lago; I. Malavolta; H. Muccini; P. Pelliccione; A. Tang,VU University Amsterdam; Gran Sasso Science Institute; Università dellAquila; Chalmers University of Technology and University of Gothenburg; Swinburne University of Technology,IEEE Software,4 Feb 2015,2015,32,1,98,105,"Despite the huge number of architectural languages that have been proposed in the last two decades, evidence today shows that industry-ready, well-accepted, and recognized languages for producing architecture descriptions are still lacking. This article explores the usability requirements of architectural languages from the perspectives of language definition, language mechanisms, and tool support. With a better understanding of architectural-language requirements, the authors explore the use of model-driven engineering to realize next-generation architectural languages, as well as its limitations.",1937-4194,,10.1109/MS.2014.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6756703,software architecture;architectural language;model-driven engineering;MDE;software engineering,Software architecture;Unified modeling language;Computer languages;Software engineering;Computer applications,software architecture;software tools;Unified Modeling Language,next-generation architectural languages;usability requirements;language definition;language mechanisms;tool support;model-driven engineering;UML-based notation,,18.0,,11.0,,5 Mar 2014,,,IEEE,IEEE Magazines
494,495,Infrastructure as a Service and Cloud Technologies,N. Serrano; G. Gallardo; J. Hernantes,University of Navarra; University of Navarra; University of Navarra,IEEE Software,10 Mar 2015,2015,32,2,30,36,"To choose the most appropriate cloud-computing model for your organization, you must analyze your IT infrastructure, usage, and needs. To help with this, this article describes cloud computing's current status.",1937-4194,,10.1109/MS.2015.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057553,infrastructure as a service;IaaS;public clouds;private clouds;hybrid clouds;software engineering;software development;cloud computing;Amazon Web Services;AWS;Microsoft Azure;Rackspace;Google Compute Engine;HP Cloud Compute;IBM Cloud;Eucalyptus;OpenStack;CloudStack;VMware,Cloud computing;Computer security;Servers;Software engineering;Google;Computer architecture,cloud computing,infrastructure as a service;cloud technologies;cloud computing model;IT infrastructure,,26.0,,7.0,,10 Mar 2015,,,IEEE,IEEE Magazines
495,496,Access Control in JavaScript,R. Toledo; E. Tanter,University of Chile; University of Chile,IEEE Software,18 Aug 2011,2011,28,5,76,84,"ZAC is a practical lightweight library for access control in JavaScript based on aspect orientation. Its access control architecture is stack based, similar to those of Java and C#. However, ZAC integrates other features for more expressive access control. First, access control policies can be enforced at the level of objects, which permits more fine-grained control over resource access. Second, policies in ZAC can base their decisions on scripts' execution history. This lets developers express policies that are impossible to define using other models, such as bounded-time execution.",1937-4194,,10.1109/MS.2010.154,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645644,language constructs and features;scripting languages;semantics;software;software engineering,Access control;Java;Computer architecture;Performance analysis;Semantics;Computer languages;Software engineering,aspect-oriented programming;authorisation;Java;software libraries,JavaScript;ZAC;aspect orientation;access control architecture;access control policies;script execution history,,2.0,1.0,8.0,,29 Nov 2010,,,IEEE,IEEE Magazines
496,497,"Developing, Verifying, and Maintaining High-Quality Automated Test Scripts",V. Garousi; M. Felderer,Hacettepe University; University of Innsbruck,IEEE Software,25 Apr 2016,2016,33,3,68,75,"With the increasing importance, size, and complexity of automated test suites, the need exists for suitable methods and tools to develop, assess the quality of, and maintain test code (scripts) in parallel with regular production (application) code. A recent review paper called this subarea of software testing software test code engineering (STCE). This article summarizes STCE tools, techniques, and guidelines. It also presents specific quantitative examples in this area based on experience in projects and raises important issues practitioners and researchers must address to further advance this field.",1937-4194,,10.1109/MS.2016.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412621,software engineering;software testing;test automation;software test code engineering;test scripts;test code,Software engineering;Production processes;Quality assessment;Maintenance engineering;Software testing;Test automation,program testing;program verification;software maintenance,automated test script development;automated test script verification;automated test script maintenance;software testing;software test code engineering;STCE,,21.0,,18.0,,18 Feb 2016,,,IEEE,IEEE Magazines
497,498,Benefit Points: The Best Part of the Story,J. E. Hannay; H. C. Benestad; K. Strand,Simula Research Laboratory; Expertware; PROMIS,IEEE Software,15 May 2017,2017,34,3,73,85,"Delivering valuable software to your customer is the first priority in agile management and development. The product owner is involved along the way, and backlogs are prioritized, with the best of intentions to maximize business value early and eliminate waste. Yet in many IT development projects, bewilderment remains as to how to express business value in process decisions and the delivered system. Also, projects continue to implement functionality that's off the mark or never used. This situation occurs because there isn't sufficient methodological support to determine and monitor business value or to link business value decisions to the development project's mechanics. However, researchers have developed a bundle of easy-to-use core practices that help systematize a project's evolving knowledge. Although these practices are simple, they provide powerful support for monitoring project progress on both the realized business value and the realized costs.",1937-4194,,10.1109/MS.2017.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927918,return on investment;MISHRI;Model for Integrating Soft and Hard Return on Investment;satisficing;business value;agile management;benefit points;software development;software engineering,Software engineering;Stakeholders;Planning;Productivity;Management;Information technology;Agile computing,project management;software prototyping,agile management;agile development;product owner;business value maximization;waste elimination;IT development projects;project progress monitoring,,4.0,,28.0,,15 May 2017,,,IEEE,IEEE Magazines
498,499,A Survey on Open Source Software Trustworthiness,V. del Bianco; L. Lavazza; S. Morasca; D. Taibi,OpenSoftEngineering; Università degli Studi dell'Insubria; Università degli Studi dell'Insubria; Università degli Studi dell'Insubria,IEEE Software,18 Aug 2011,2011,28,5,67,75,"Trustworthiness is a crucial characteristic when it comes to evaluating any product, even more so for open source software, which is now becoming widely used. The authors conducted a survey to identify the reasons and motivations that lead software companies to adopt or reject open source software; they then ranked, according to importance, the specific trust factors used when selecting an open source software component or product. The motivations and importance ranking of factors might be useful for both developers of open source software (to make their products and components more useful for other stakeholders) and to future prospective open source software users.",1937-4194,,10.1109/MS.2011.93,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984797,open source software;trustworthiness;internal software qualities;external software qualities;pragmatic software engineering,Open source software;Software reliability;Reliability;Software engineering,public domain software;security of data,open source software trustworthiness;software companies;open source software users,,30.0,,9.0,,18 Aug 2011,,,IEEE,IEEE Magazines
499,500,On the Value of Ensemble Effort Estimation,E. Kocaguneli; T. Menzies; J. W. Keung,"West Virginia University, Morgantown; West Virginia University, Morgantown; The Hong Kong Polytechnic University, Hong Kong",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1403,1416,"Background: Despite decades of research, there is no consensus on which software effort estimation methods produce the most accurate models. Aim: Prior work has reported that, given M estimation methods, no single method consistently outperforms all others. Perhaps rather than recommending one estimation method as best, it is wiser to generate estimates from ensembles of multiple estimation methods. Method: Nine learners were combined with 10 preprocessing options to generate 9 × 10 = 90 solo methods. These were applied to 20 datasets and evaluated using seven error measures. This identified the best n (in our case n = 13) solo methods that showed stable performance across multiple datasets and error measures. The top 2, 4, 8, and 13 solo methods were then combined to generate 12 multimethods, which were then compared to the solo methods. Results: 1) The top 10 (out of 12) multimethods significantly outperformed all 90 solo methods. 2) The error rates of the multimethods were significantly less than the solo methods. 3) The ranking of the best multimethod was remarkably stable. Conclusion: While there is no best single effort estimation method, there exist best combinations of such effort estimation methods.",1939-3520,,10.1109/TSE.2011.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6081882,Software cost estimation;ensemble;machine learning;regression trees;support vector machines;neural nets;analogy;k-NN,Costs;Software performance;Measurement uncertainty;Taxonomy;Machine learning;Regression tree analysis;Support vector machines;Neural networks,software development management,ensemble effort estimation;software effort estimation;single method;multiple estimation method;error measures,,124.0,,82.0,,15 Nov 2011,,,IEEE,IEEE Journals
500,501,Determining the Cause of a Design Model Inconsistency,A. Reder; A. Egyed,"Johannes Kepler University Linz, Linz; Johannes Kepler University Linz, Linz",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1531,1548,"When a software engineer finds an inconsistency in a model, then the first question is why? What caused it? Obviously, there must be an error. But where could it be? Or is the design rule erroneous and if yes then which part? The cause of an inconsistency identifies the part of the model or design rule where the error must be. We believe that the visualization of an inconsistency ought to visualize the cause. Understanding the cause is of vital importance before a repair can even be formulated. Indeed, any automation (e.g., code generation, refactoring) has to be considered with caution if it involves model elements that cause inconsistencies. This paper analyzes the basic structure of inconsistent design rules as well as their behavior during validation and presents an algorithm for computing its cause. The approach is fully automated, tool supported, and was evaluated on 14,111 inconsistencies across 29 design models. We found that our approach computes correct causes for inconsistencies, these causes are nearly always a subset of the model elements investigated by the design rules' validation (a naive cause computation approximation), and the computation is very fast (99.8 percent of the causes are computable in <; 100 ms).",1939-3520,,10.1109/TSE.2013.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560054,Design tools and techniques;programming environments/construction tools;validation,Unified modeling language;Computational modeling;Context;Maintenance engineering;Visualization;Context modeling;Light emitting diodes,software development management,design model inconsistency;software engineer;code generation;refactoring;model elements;inconsistent design rules,,15.0,,33.0,,16 Jul 2013,,,IEEE,IEEE Journals
501,502,Where Should We Fix This Bug? A Two-Phase Recommendation Model,D. Kim; Y. Tao; S. Kim; A. Zeller,"The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong; Saarland University, Saarland",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1597,1610,"To support developers in debugging and locating bugs, we propose a two-phase prediction model that uses bug reports' contents to suggest the files likely to be fixed. In the first phase, our model checks whether the given bug report contains sufficient information for prediction. If so, the model proceeds to predict files to be fixed, based on the content of the bug report. In other words, our two-phase model ""speaks up"" only if it is confident of making a suggestion for the given bug report; otherwise, it remains silent. In the evaluation on the Mozilla ""Firefox"" and ""Core"" packages, the two-phase model was able to make predictions for almost half of all bug reports; on average, 70 percent of these predictions pointed to the correct files. In addition, we compared the two-phase model with three other prediction models: the Usual Suspects, the one-phase model, and BugScout. The two-phase model manifests the best prediction performance.",1939-3520,,10.1109/TSE.2013.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6517844,Bug reports;machine learning;patch file prediction,Predictive models;Feature extraction;Computer bugs;Software;Computational modeling;Data mining;Noise,formal verification;program debugging,two-phase recommendation model;debugging;two-phase prediction model;bug report;two-phase model;speaks up;Mozilla packages;Firefox packages;Core packages;BugScout,,65.0,1.0,66.0,,21 May 2013,,,IEEE,IEEE Journals
502,503,Matching and Merging of Variant Feature Specifications,S. Nejati; M. Sabetzadeh; M. Chechik; S. Easterbrook; P. Zave,"Simula Research Laboratory, Lysaker; Simula Research Laboratory, Lysaker; University of Toronto, Toronto; University of Toronto, Toronto; AT&T Laboratories-Research, Florham Park",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1355,1375,"Model Management addresses the problem of managing an evolving collection of models by capturing the relationships between models and providing well-defined operators to manipulate them. In this paper, we describe two such operators for manipulating feature specifications described using hierarchical state machine models: Match, for finding correspondences between models, and Merge, for combining models with respect to known or hypothesized correspondences between them. Our Match operator is heuristic, making use of both static and behavioral properties of the models to improve the accuracy of matching. Our Merge operator preserves the hierarchical structure of the input models, and handles differences in behavior through parameterization. This enables us to automatically construct merges that preserve the semantics of hierarchical state machines. We report on tool support for our Match and Merge operators, and illustrate and evaluate our work by applying these operators to a set of telecommunication features built by AT&T.",1939-3520,,10.1109/TSE.2011.112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6086550,Model management;match;merge;hierarchical state machines;statecharts;behavior preservation;variability modeling;parameterization,Computational modeling;Semantics;Hierarchical systems;Pragmatics;Parameterization;Electronic mail;Voice mail,finite state machines;formal specification,variant feature specification;model management;hierarchical state machine model;match operator;static property;behavioral property;merge operator;hierarchical structure;tool support;telecommunication feature,,16.0,,83.0,,22 Nov 2011,,,IEEE,IEEE Journals
503,504,Dealing with Burstiness in Multi-Tier Applications: Models and Their Parameterization,G. Casale; N. Mi; L. Cherkasova; E. Smirni,"Imperial College London, London; Northeastern University, Boston; Hewlett-Packard Laboratories, Palo Alto; College of William and Mary, Williamsburg",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1040,1053,"Workloads and resource usage patterns in enterprise applications often show burstiness resulting in large degradation of the perceived user performance. In this paper, we propose a methodology for detecting burstiness symptoms in multi-tier applications but, rather than identifying the root cause of burstiness, we incorporate this information into models for performance prediction. The modeling methodology is based on the index of dispersion of the service process at a server, which is inferred by observing the number of completions within the concatenated busy times of that server. The index of dispersion is used to derive a Markov-modulated process that captures burstiness and variability of the service process at each resource well and that allows us to define queueing network models for performance prediction. Experimental results and performance model predictions are in excellent agreement and argue for the effectiveness of the proposed methodology under both bursty and nonbursty workloads. Furthermore, we show that the methodology extends to modeling flash crowds that create burstiness in the stream of requests incoming to the application.",1939-3520,,10.1109/TSE.2011.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311395,Capacity planning;multi-tier applications;bursty workload;bottleneck switch;index of dispersion,Servers;Indexes;Dispersion;Switches;Predictive models;Estimation,client-server systems;Markov processes;queueing theory;resource allocation;software architecture,multitier applications;resource usage patterns;workload patterns;enterprise applications;user performance degradation;burstiness symptom detection;burstiness root cause identification;performance prediction model;server busy times;Markov-modulated process;service process variability;queueing network models;nonbursty workloads;flash crowd model,,29.0,,25.0,,24 Sep 2012,,,IEEE,IEEE Journals
504,505,Featured Transition Systems: Foundations for Verifying Variability-Intensive Systems and Their Application to LTL Model Checking,A. Classen; M. Cordy; P. Schobbens; P. Heymans; A. Legay; J. Raskin,"University of Namur (FUNDP), Namur; University of Namur (FUNDP), Namur; University of Namur (FUNDP), Namur; University of Namur (FUNDP), Namur and INRIA Lille-Nord Europe, France; IRISA/INRIA Rennes, France Université de Liège, Rennes Liège; Université Libre de Bruxelles (ULB), Brussels",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1069,1089,"The premise of variability-intensive systems, specifically in software product line engineering, is the ability to produce a large family of different systems efficiently. Many such systems are critical. Thorough quality assurance techniques are thus required. Unfortunately, most quality assurance techniques were not designed with variability in mind. They work for single systems, and are too costly to apply to the whole system family. In this paper, we propose an efficient automata-based approach to linear time logic (LTL) model checking of variability-intensive systems. We build on earlier work in which we proposed featured transitions systems (FTSs), a compact mathematical model for representing the behaviors of a variability-intensive system. The FTS model checking algorithms verify all products of a family at once and pinpoint those that are faulty. This paper complements our earlier work, covering important theoretical aspects such as expressiveness and parallel composition as well as more practical things like vacuity detection and our logic feature LTL. Furthermore, we provide an in-depth treatment of the FTS model checking algorithm. Finally, we present SNIP, a new model checker for variability-intensive systems. The benchmarks conducted with SNIP confirm the speedups reported previously.",1939-3520,,10.1109/TSE.2012.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6389685,Formal methods;model checking;verification;variability;features;software product lines,Unified modeling language;Semantics;Software;Labeling;Automata;Quality assurance,automata theory;formal logic;formal verification;software quality,featured transition systems;variability-intensive system verification;LTL model checking;software product line engineering;quality assurance techniques;automata-based approach;linear time logic model checking;mathematical model;FTS model checking algorithm;SNIP;model checker,,105.0,,74.0,,20 Dec 2012,,,IEEE,IEEE Journals
505,506,Quality-Aware Service Selection for Service-Based Systems Based on Iterative Multi-Attribute Combinatorial Auction,Q. He; J. Yan; H. Jin; Y. Yang,"Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Information Systems and Technology, University of Wollongong, Wollongong, Australia; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China; School of Computer Science and Technology, Anhui University, Hefei, China",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,2,192,215,"The service-oriented paradigm offers support for engineering service-based systems (SBSs) based on service composition where existing services are composed to create new services. The selection of services with the aim to fulfil the quality constraints becomes critical and challenging to the success of SBSs, especially when the quality constraints are stringent. However, none of the existing approaches for quality-aware service composition has sufficiently considered the following two critical issues to increase the success rate of finding a solution: 1) the complementarities between services; and 2) the competition among service providers. This paper proposes a novel approach called combinatorial auction for service selection (CASS) to support effective and efficient service selection for SBSs based on combinatorial auction. In CASS, service providers can bid for combinations of services and apply discounts or premiums to their offers for the multi-dimensional quality of the services. Based on received bids, CASS attempts to find a solution that achieves the SBS owner's optimisation goal while fulfilling all quality constraints for the SBS. When a solution cannot be found based on current bids, the auction iterates so that service providers can improve their bids to increase their chances of winning. This paper systematically describes the auction process and the supporting mechanisms. Experimental results show that by exploiting the complementarities between services and the competition among service providers, CASS significantly outperforms existing quality-aware service selection approaches in finding optimal solutions and guaranteeing system optimality. Meanwhile, the duration and coordination overhead of CASS are kept at satisfactory levels in scenarios on different scales.",1939-3520,,10.1109/TSE.2013.2297911,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6702520,Service-based system;combinatorial auction;quality of service;service composition;service selection;web services;integer programming,Scattering;Quality of service;Optimization;Contracts;Abstracts;Time factors,combinatorial mathematics;iterative methods;quality of service;service-oriented architecture;software quality;Web services,system optimality;optimal solutions;auction mechanisms;auction process;service providers;service quality;CASS approach;quality-aware service composition;quality constraints;service creation;SBS;service-oriented paradigm;iterative multiattribute combinatorial auction;service-based systems;quality-aware service selection,,63.0,,61.0,,9 Jan 2014,,,IEEE,IEEE Journals
506,507,Bristlecone: Language Support for Robust Software Applications,B. Demsky; S. Sundaramurthy,"University of California, Irvine, Irvine; University of California, Irvine, Irvine",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,4,23,"We present Bristlecone, a programming language for robust software systems. Bristlecone applications have two components: a high-level organization specification that describes how the application's conceptual operations interact and a low-level operational specification that describes the sequence of instructions that comprise an individual conceptual operation. Bristlecone uses the high-level organization specification to recover the software system from an error to a consistent state and to reason how to safely continue the software system's execution after the error. We have implemented a compiler and runtime for Bristlecone. We have evaluated this implementation on three benchmark applications: a Web crawler, a Web server, and a multiroom chat server. We developed both a Bristlecone version and a Java version of each benchmark application. We used injected failures to evaluate the robustness of each version of the application. We found that the Bristlecone versions of the benchmark applications more successfully survived the injected failures. The Bristlecone compiler contains a static analysis that operates on the organization specification to generate a set of diagrams that graphically present the task interactions in the application. We have used the analysis to help understand the high-level structure of three Bristlecone applications: a game server, a Web server, and a chat server.",1939-3520,,10.1109/TSE.2010.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416725,Software robustness.,Robustness;Application software;Software systems;Switches;Runtime;Computer languages;Costs;Web server;Java;Software tools,Java;program compilers;program diagnostics;programming languages;software fault tolerance;specification languages,language support;robust software applications;programming language;robust software systems;high-level organization specification;low-level operational specification;runtime;benchmark applications;Web crawler;Web server;multiroom chat server;Java version;injected failures;Bristlecone compiler;static analysis;task interactions;high-level structure;game server,,6.0,,48.0,,18 Feb 2010,,,IEEE,IEEE Journals
507,508,Compositional Dependability Evaluation for STATEMATE,E. Bode; M. Herbstritt; H. Hermanns; S. Johr; T. Peikenkamp; R. Pulungan; J. Rakow; R. Wimmer; B. Becker,"OFFIS Institute for Information Technology, Oldenburg; Albert-Ludwigs-University, Freiburg im Breisgau; Saarland University, Saarbrücken; Saarland University, Saarbrücken; OFFIS Institute for Information Technology, Oldenburg; Saarland University, Saarbrücken; Carl von Ossietzky University, Oldenburg; Albert-Ludwigs-University, Freiburg im Breisgau; Albert-Ludwigs-University, Freiburg im Breisgau",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,274,292,"Software and system dependability is getting ever more important in embedded system design. Current industrial practice of model-based analysis is supported by state-transition diagrammatic notations such as Statecharts. State-of-the-art modelling tools like STATEMATE support safety and failure-effect analysis at design time, but restricted to qualitative properties. This paper reports on a (plug-in) extension of STATEMATE enabling the evaluation of quantitative dependability properties at design time. The extension is compositional in the way the model is augmented with probabilistic timing information. This fact is exploited in the construction of the underlying mathematical model, a uniform continuous-time Markov decision process, on which we are able to check requirements of the form: ""The probability to hit a safety-critical system configuration within a mission time of 3 hours is at most 0.01."" We give a detailed explanation of the construction and evaluation steps making this possible, and report on a nontrivial case study of a high-speed train signalling system where the tool has been applied successfully.",1939-3520,,10.1109/TSE.2008.102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711060,Real-time and embedded systems;Fault tolerance;Modeling techniques;Reliability;availability;and serviceability;Model checking;Reliability;Design notations and documentation;State diagrams;Real-time and embedded systems;Fault tolerance;Modeling techniques;Reliability;availability;and serviceability;Model checking;Reliability;Design notations and documentation;State diagrams,Embedded system;Stochastic processes;Safety;Failure analysis;Timing;Mathematical model;Communication system signaling;Fault tolerant systems;Availability;Documentation,decision theory;embedded systems;failure analysis;fault tolerance;formal specification;Markov processes;probability;safety-critical software;software performance evaluation;system monitoring,compositional dependability evaluation;embedded system design;model-based analysis;state-transition diagrammatic notation;failure-effect analysis;probabilistic timing information;uniform continuous-time Markov decision process;safety-critical system configuration;model checking;fault tolerance;statemate;functional specification,,24.0,,43.0,,12 Dec 2008,,,IEEE,IEEE Journals
508,509,Variability Mining: Consistent Semi-automatic Detection of Product-Line Features,C. Kästner; A. Dreiling; K. Ostermann,"School of Computer Science, Carnegie Mellon University; University of Magdeburg and Deutsche Bank AG, Germany; Department of Mathematics and ComputerScience at Philipps University Marburg, Germany",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,1,67,82,"Software product line engineering is an efficient means to generate a set of tailored software products from a common implementation. However, adopting a product-line approach poses a major challenge and significant risks, since typically legacy code must be migrated toward a product line. Our aim is to lower the adoption barrier by providing semi-automatic tool support-called variability mining -to support developers in locating, documenting, and extracting implementations of product-line features from legacy code. Variability mining combines prior work on concern location, reverse engineering, and variability-aware type systems, but is tailored specifically for the use in product lines. Our work pursues three technical goals: (1) we provide a consistency indicator based on a variability-aware type system, (2) we mine features at a fine level of granularity, and (3) we exploit domain knowledge about the relationship between features when available. With a quantitative study, we demonstrate that variability mining can efficiently support developers in locating features.",1939-3520,,10.1109/TSE.2013.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6613490,Variability;reverse engineering;mining;feature;software product line;LEADT;feature location,Feature extraction;Software;Context;Data mining;Java;Companies;Educational institutions,data mining;reverse engineering;software product lines,variability mining;consistent semi automatic detection;product line features;software product line engineering;product line approach;legacy code;semi automatic tool support;reverse engineering;variability aware type systems,,33.0,,60.0,,27 Sep 2013,,,IEEE,IEEE Journals
509,510,A decentralized self-adaptation mechanism for service-based applications in the cloud,V. Nallur; R. Bahsoon,"University of Birmingham, Birmingham; University of Birmingham, Birmingham",IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,591,612,"Cloud computing, with its promise of (almost) unlimited computation, storage, and bandwidth, is increasingly becoming the infrastructure of choice for many organizations. As cloud offerings mature, service-based applications need to dynamically recompose themselves to self-adapt to changing QoS requirements. In this paper, we present a decentralized mechanism for such self-adaptation, using market-based heuristics. We use a continuous double-auction to allow applications to decide which services to choose, among the many on offer. We view an application as a multi-agent system and the cloud as a marketplace where many such applications self-adapt. We show through a simulation study that our mechanism is effective for the individual application as well as from the collective perspective of all applications adapting at the same time.",1939-3520,,10.1109/TSE.2012.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249687,Self-adaptation;market based;multi-agent systems,Quality of service;Pricing;Reliability;Resource management;Measurement;Adaptation models;Cloud computing,cloud computing;electronic commerce;multi-agent systems;quality of service,decentralized self-adaptation mechanism;service-based applications;cloud computing;QoS requirements;market-based heuristics;continuous double-auction;multiagent system,,52.0,,56.0,,26 Jul 2012,,,IEEE,IEEE Journals
510,511,Monitoring Data Usage in Distributed Systems,D. Basin; M. Harvan; F. Klaedtke; E. Zalinescu,"ETH Zurich, Zurich; ETH Zurich, Zurich; ETH Zurich, Zurich; ETH Zurich, Zurich",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1403,1426,"IT systems manage increasing amounts of sensitive data and there is a growing concern that they comply with policies that regulate data usage. In this paper, we use temporal logic to express policies and runtime monitoring to check system compliance. While well-established methods for monitoring linearly ordered system behavior exist, a major challenge is monitoring distributed and concurrent systems where actions are locally observed in the different system parts. These observations can only be partially ordered, while policy compliance may depend on the actions' actual order of appearance. Technically speaking, it is in general intractable to check compliance of partially ordered traces. We identify fragments of our policy specification language for which compliance can be checked efficiently, namely, by monitoring a single representative trace in which the observed actions are totally ordered. Through a case study we show that the fragments are capable of expressing nontrivial policies and that monitoring representative traces is feasible on real-world data.",1939-3520,,10.1109/TSE.2013.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6493331,Monitors;temporal logic;verification;distributed systems;regulation,Monitoring;Cost accounting;Periodic structures;Semantics;Distributed databases;Standards;Finite element analysis,concurrency control;formal verification;specification languages;temporal logic,data usage monitoring;distributed systems;IT systems;information technology systems;data usage regulation;temporal logic;runtime monitoring;system compliance;concurrent systems;policy compliance;policy specification language,,16.0,,34.0,,3 Apr 2013,,,IEEE,IEEE Journals
511,512,Performance Specification and Evaluation with Unified Stochastic Probes and Fluid Analysis,R. A. Hayden; J. T. Bradley; A. Clark,"Imperial College London, London; Imperial College London, London; University of Edinburgh, Edinburgh",IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,97,118,"Rapid and accessible performance evaluation of complex software systems requires two critical features: the ability to specify useful performance metrics easily and the capability to analyze massively distributed architectures, without recourse to large compute clusters. We present the unified stochastic probe, a performance specification mechanism for process algebra models that combines many existing ideas: state and action-based activation, location-based specification, many-probe specification, and immediate signaling. These features, between them, allow the precise and compositional construction of complex performance measurements. The paper shows how a subset of the stochastic probe language can be used to specify common response-time measures in massive process algebra models. The second contribution of the paper is to show how these response-time measures can be analyzed using so-called fluid techniques to produce rapid results. In doing this, we extend the fluid approach to incorporate immediate activities and a new type of response-time measure. Finally, we calculate various response-time measurements on a complex distributed wireless network of O(10129) states in size.",1939-3520,,10.1109/TSE.2012.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6133297,Performance modeling;performance evaluation tools;stochastic process algebra;measurement probes;fluid approximation;passage-time analysis,Probes;Stochastic processes;Analytical models;Algebra;Computational modeling;Semantics;Syntactics,formal specification;process algebra;software metrics;software performance evaluation,performance specification mechanism;performance evaluation mechanism;unified stochastic probes;fluid analysis;software system;performance metrics;process algebra model;state-based activation;action-based activation;location-based specification;many-probe specification;immediate signaling;stochastic probe language;common response-time measure;complex distributed wireless network,,13.0,,29.0,,17 Jan 2012,,,IEEE,IEEE Journals
512,513,Model Checking Semantically Annotated Services,I. Di Pietro; F. Pagliarecci; L. Spalazzi,"Università Politecnica delle Marche, Ancona; Università Politecnica delle Marche, Ancona; Università Politecnica delle Marche, Ancona",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,592,608,"Model checking is a formal verification method widely accepted in the web service world because of its capability to reason about service behavior at process level. It has been used as a basic tool in several scenarios such as service selection, service validation, and service composition. The importance of semantics is also widely recognized. Indeed, there are several solutions to the problem of providing semantics to web services, most of them relying on some form of Description Logic. This paper presents an integration of model checking and semantic reasoning technologies in an efficient way. This can be considered the first step toward the use of semantic model checking in problems of selection, validation, and composition. The approach relies on a representation of services at process level that is based on semantically annotated state transition systems (asts) and a representation of specifications based on a semantically annotated version of computation tree logic (anctl). This paper proves that the semantic model checking algorithm is sound and complete and can be accomplished in polynomial time. This approach has been evaluated with several experiments.",1939-3520,,10.1109/TSE.2011.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680919,Formal methods;model checking;temporal logic;description logic;intelligent web services;semantic web;web services.,Web services;Semantics;Ontologies;Switches;Computational modeling;Biological system modeling;Syntactics,computational complexity;formal verification;semantic Web;temporal logic;trees (mathematics);Web services,formal verification method;Web service;description logic;semantic reasoning technologies;semantic model checking;annotated state transition systems;computation tree logic;polynomial time;temporal logic;semantically annotated services,,17.0,,63.0,,6 Jan 2011,,,IEEE,IEEE Journals
513,514,Assessing Software Service Quality and Trustworthiness at Selection Time,N. Limam; R. Boutaba,"POSTECH-Pohang University of Science and Technology, Pohang; University of Waterloo, Waterloo",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,559,574,"The integration of external software in project development is challenging and risky, notably because the execution quality of the software and the trustworthiness of the software provider may be unknown at integration time. This is a timely problem and of increasing importance with the advent of the SaaS model of service delivery. Therefore, in choosing the SaaS service to utilize, project managers must identify and evaluate the level of risk associated with each candidate. Trust is commonly assessed through reputation systems; however, existing systems rely on ratings provided by consumers. This raises numerous issues involving the subjectivity and unfairness of the service ratings. This paper describes a framework for reputation-aware software service selection and rating. A selection algorithm is devised for service recommendation, providing SaaS consumers with the best possible choices based on quality, cost, and trust. An automated rating model, based on the expectancy-disconfirmation theory from market science, is also defined to overcome feedback subjectivity issues. The proposed rating and selection models are validated through simulations, demonstrating that the system can effectively capture service behavior and recommend the best possible choices.",1939-3520,,10.1109/TSE.2010.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383370,Software as a service (SaaS);software selection;service utility;review and rating;trust and reputation;risk management;SLA monitoring.,Software quality;Risk management;Software maintenance;Costs;Software performance;Project management;Feedback;Monitoring;Business;Computer industry,quality of service;risk management;software architecture;software quality;software selection,software service quality;selection time;project development;software provider;SaaS model;reputation-aware software service selection;automated rating model;expectancy-disconfirmation theory;software service trustworthiness,,79.0,2.0,30.0,,15 Jan 2010,,,IEEE,IEEE Journals
514,515,Learning Assumptions for CompositionalVerification of Timed Systems,S. Lin; É. André; Y. Liu; J. Sun; J. S. Dong,"Temasek Laboratories, National University of Singapore, 5A, Engineering Drive 1, #09-02, Singapore; Université Paris 13, Sorbonne Paris Cité, Laboratoire d’Informatique de Paris-Nord (LIPN), A204, Institut Galilée, 99 avenue Jean-Baptiste Clément, 93430 Villetaneuse, CNRS, UMR 7030, Villetaneuse, France; School of Computer Engineering , Nanyang Technological University, 50 Nanyang Avenue, Singapore; Singapore University of Technology and Design, BLK1, Level 3, West Wing, Room 9, 20 Dover Drive, Singapore; Computer Science Department, School of Computing, National University of Singapore, 13 Computing Drive, Singapore",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,2,137,153,"Compositional techniques such as assume-guarantee reasoning (AGR) can help to alleviate the state space explosion problem associated with model checking. However, compositional verification is difficult to be automated, especially for timed systems, because constructing appropriate assumptions for AGR usually requires human creativity and experience. To automate compositional verification of timed systems, we propose a compositional verification framework using a learning algorithm for automatic construction of timed assumptions for AGR. We prove the correctness and termination of the proposed learning-based framework, and experimental results show that our method performs significantly better than traditional monolithic timed model checking.",1939-3520,,10.1109/TSE.2013.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682903,Automatic assume-guarantee reasoning;model checking;timed systems,Model checking;Educational institutions;Explosions;Learning automata;Atomic clocks;Cognition,formal verification;inference mechanisms;learning (artificial intelligence),monolithic timed model checking;learning-based framework;timed assumptions;learning algorithm;state space explosion problem;AGR techniques;assume-guarantee reasoning techniques;timed systems;compositional verification framework;learning assumptions,,13.0,,37.0,,12 Dec 2013,,,IEEE,IEEE Journals
515,516,Tuning Temporal Features within the Stochastic π-Calculus,L. Pauleve; M. Magnin; O. Roux,"IRCCyN, École Centrale de Nantes; IRCCyN, École Centrale de Nantes; IRCCyN, École Centrale de Nantes",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,858,871,"The stochastic π-calculus is a formalism that has been used for modeling complex dynamical systems where the stochasticity and the delay of transitions are important features, such as in the case of biochemical reactions. Commonly, durations of transitions within stochastic π-calculus models follow an exponential law. The underlying dynamics of such models are expressed in terms of continuous-time Markov chains, which can then be efficiently simulated and model-checked. However, the exponential law comes with a huge variance, making it difficult to model systems with accurate temporal constraints. In this paper, a technique for tuning temporal features within the stochastic π-calculus is presented. This method relies on the introduction of a stochasticity absorption factor by replacing the exponential distribution with the Erlang distribution, which is a sum of exponential random variables. This paper presents a construction of the stochasticity absorption factor in the classical stochastic π-calculus with exponential rates. Tools for manipulating the stochasticity absorption factor and its link with timed intervals for firing transitions are also presented. Finally, the model-checking of such designed models is tackled by supporting the stochasticity absorption factor in a translation from the stochastic π-calculus to the probabilistic model checker PRISM.",1939-3520,,10.1109/TSE.2010.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611556,Temporal parameters;\pi-calculus;model-checking;Markov processes;stochastic processes.,Stochastic processes;Exponential distribution;Random variables;Analytical models,exponential distribution;formal verification;pi calculus;stochastic processes,temporal feature tuning;stochastic π-calculus;complex dynamical system modeling;biochemical reactions;continuous-time Markov chains;stochasticity absorption factor;exponential distribution;Erlang distribution;exponential random variables;probabilistic model checker;PRISM,,2.0,,36.0,,28 Oct 2010,,,IEEE,IEEE Journals
516,517,Specification and Verification of Normative Texts Using C-O Diagrams,G. Díaz; M. E. Cambronero; E. Martínez; G. Schneider,"Department of Computer Science , University of Castilla-La Mancha, Albacete, Spain; Department of Computer Science , University of Castilla-La Mancha, Albacete, Spain; Department of Computer Science , University of Castilla-La Mancha, Albacete, Spain; Department of Computer Science and Engineering, Chalmers | University of Gothenburg, Sweden",IEEE Transactions on Software Engineering,8 Aug 2014,2014,40,8,795,817,"C-O diagrams have been introduced as a means to have a more visual representation of normative texts and electronic contracts, where it is possible to represent the obligations, permissions and prohibitions of the different signatories, as well as the penalties resulting from non-fulfillment of their obligations and prohibitions. In such diagrams we are also able to represent absolute and relative timing constraints. In this paper we present a formal semantics for C-O diagrams based on timed automata extended with information regarding the satisfaction and violation of clauses in order to represent different deontic modalities. As a proof of concept, we apply our approach to two different case studies, where the method presented here has successfully identified problems in the specification.",1939-3520,,10.1109/TSE.2013.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6657668,Normative documents;electronic contracts;deontic logic;formal verification;visual models;timed automata;C-O diagrams,Automata;Clocks;Contracts;Semantics;Cost accounting;Synchronization;Formal languages,automata theory;formal specification;formal verification;text analysis,normative texts;formal specification;formal verification;C-O diagrams;visual representation;electronic contracts;timing constraints;formal semantics;timed automata;deontic modalities,,5.0,,33.0,,7 Nov 2013,,,IEEE,IEEE Journals
517,518,A Quantitative Approach to Input Generation in Real-Time Testing of Stochastic Systems,L. Carnevali; L. Ridi; E. Vicario,"Università degli Studi di Firenze, Firenze; Università degli Studi di Firenze, Firenze; Università degli Studi di Firenze, Firenze",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,292,304,"In the process of testing of concurrent timed systems, input generation identifies values of temporal parameters that let the Implementation Under Test (IUT) execute selected cases. However, when some parameters are not under control of the driver, test execution may diverge from the selected input and produce an inconclusive behavior. We formulate the problem on the basis of an abstraction of the IUT which we call partially stochastic Time Petri Net (psTPN), where controllable parameters are modeled as nondeterministic values and noncontrollable parameters as random variables with general (GEN) distribution. With reference to this abstraction, we derive the analytical form of the probability that the IUT runs along a selected behavior as a function of choices taken on controllable parameters. In the applicative perspective of real-time testing, this identifies a theoretical upper limit on the probability of a conclusive result, thus providing a means to plan the number of test repetitions that are necessary to guarantee a given probability of test-case coverage. It also provides a constructive technique for an optimal or suboptimal approach to input generation and a way to characterize the probability of conclusive testing under other suboptimal strategies.",1939-3520,,10.1109/TSE.2012.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226426,Real-time testing;input generation;Time Petri Nets;non-Markovian Stochastic Petri Nets;stochastic processes;Difference Bound Matrix,Stochastic processes;Timing;Real time systems;Testing;Tin;Vectors;Automata,Petri nets;program testing;real-time systems,quantitative approach;input generation;real-time testing;stochastic systems;concurrent timed systems;temporal parameters;implementation under test;IUT;test execution;inconclusive behavior;partially stochastic Time Petri Net;psTPN;controllable parameters;nondeterministic values;GEN distribution,,3.0,,44.0,,26 Jun 2012,,,IEEE,IEEE Journals
518,519,The Impact of API Change- and Fault-Proneness on the User Ratings of Android Apps,G. Bavota; M. Linares-Vásquez; C. E. Bernal-Cárdenas; M. D. Penta; R. Oliveto; D. Poshyvanyk,"Department of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy; Department of Computer Science, The College of William and Mary, Williamsburg, VA; Department of Computer Science, The College of William and Mary, Williamsburg, VA; Department of Engineering, University of Sannio, Benevento, Italy; Department of Bioscience and Territory, University of Molise, Pesche (IS), Italy; Department of Computer Science, The College of William and Mary, Williamsburg, VA",IEEE Transactions on Software Engineering,14 Apr 2015,2015,41,4,384,407,"The mobile apps market is one of the fastest growing areas in the information technology. In digging their market share, developers must pay attention to building robust and reliable apps. In fact, users easily get frustrated by repeated failures, crashes, and other bugs; hence, they abandon some apps in favor of their competition. In this paper we investigate how the fault- and change-proneness of APIs used by Android apps relates to their success estimated as the average rating provided by the users to those apps. First, in a study conducted on 5,848 (free) apps, we analyzed how the ratings that an app had received correlated with the fault- and change-proneness of the APIs such app relied upon. After that, we surveyed 45 professional Android developers to assess (i) to what extent developers experienced problems when using APIs, and (ii) how much they felt these problems could be the cause for unfavorable user ratings. The results of our studies indicate that apps having high user ratings use APIs that are less fault- and change-prone than the APIs used by low rated apps. Also, most of the interviewed Android developers observed, in their development experience, a direct relationship between problems experienced with the adopted APIs and the users' ratings that their apps received.",1939-3520,,10.1109/TSE.2014.2367027,NSF; NSF; NSF; European Commission; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6945855,Mining software repositories;empirical studies;android;API changes;Mining software repositories;empirical studies;android;API changes,Androids;Humanoid robots;Software;History;Computer bugs;Educational institutions;Electronic mail,application program interfaces;data mining;mobile computing;program debugging;software fault tolerance;system recovery,API change-proneness;API fault-proneness;user ratings;Android Apps;mobile Apps market;information technology;software repository mining,,86.0,,70.0,,4 Nov 2014,,,IEEE,IEEE Journals
519,520,"Reasoning about the Reliability of Diverse Two-Channel Systems in Which One Channel Is ""Possibly Perfect""",B. Littlewood; J. Rushby,"City University, London; SRI International, Menlo Park",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1178,1194,"This paper refines and extends an earlier one by the first author [1]. It considers the problem of reasoning about the reliability of fault-tolerant systems with two “channels” (i.e., components) of which one, A, because it is conventionally engineered and presumed to contain faults, supports only a claim of reliability, while the other, B, by virtue of extreme simplicity and extensive analysis, supports a plausible claim of “perfection.” We begin with the case where either channel can bring the system to a safe state. The reasoning about system probability of failure on demand (pfd) is divided into two steps. The first concerns aleatory uncertainty about 1) whether channel A will fail on a randomly selected demand and 2) whether channel B is imperfect. It is shown that, conditional upon knowing pA (the probability that A fails on a randomly selected demand) and pB (the probability that channel B is imperfect), a conservative bound on the probability that the system fails on a randomly selected demand is simply pA X pB. That is, there is conditional independence between the events “A fails” and “B is imperfect.” The second step of the reasoning involves epistemic uncertainty, represented by assessors' beliefs about the distribution of (pA, pB), and it is here that dependence may arise. However, we show that under quite plausible assumptions, a conservative bound on system pfd can be constructed from point estimates for just three parameters. We discuss the feasibility of establishing credible estimates for these parameters. We extend our analysis from faults of omission to those of commission, and then combine these to yield an analysis for monitored architectures of a kind proposed for aircraft.",1939-3520,,10.1109/TSE.2011.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975177,Software reliability;software fault tolerance;program correctness;assurance case;software diversity,Uncertainty;Software;Phase frequency detector;Cognition;Software reliability;Safety,aircraft;probability;reasoning about programs;software fault tolerance;uncertainty handling,diverse two-channel system;fault tolerant system;reasoning about the reliability;aleatory uncertainty;randomly selected demand;conditional independence;epistemic uncertainty;assessors belief;PFD;aircraft;probability of failure on demand,,21.0,,47.0,,4 Aug 2011,,,IEEE,IEEE Journals
520,521,Ranking and Clustering Software Cost Estimation Models through a Multiple Comparisons Algorithm,N. Mittas; L. Angelis,"Aristotle University of Thessaloniki, Thessaloniki; Aristotle University of Thessaloniki, Thessaloniki",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,537,551,"Software Cost Estimation can be described as the process of predicting the most realistic effort required to complete a software project. Due to the strong relationship of accurate effort estimations with many crucial project management activities, the research community has been focused on the development and application of a vast variety of methods and models trying to improve the estimation procedure. From the diversity of methods emerged the need for comparisons to determine the best model. However, the inconsistent results brought to light significant doubts and uncertainty about the appropriateness of the comparison process in experimental studies. Overall, there exist several potential sources of bias that have to be considered in order to reinforce the confidence of experiments. In this paper, we propose a statistical framework based on a multiple comparisons algorithm in order to rank several cost estimation models, identifying those which have significant differences in accuracy, and clustering them in nonoverlapping groups. The proposed framework is applied in a large-scale setup of comparing 11 prediction models over six datasets. The results illustrate the benefits and the significant information obtained through the systematic comparison of alternative methods.",1939-3520,,10.1109/TSE.2012.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6235961,Cost estimation;management;metrics/measurement;statistical methods,Predictive models;Estimation;Accuracy;Measurement uncertainty;Prediction algorithms;Clustering algorithms;Systematics,pattern clustering;software cost estimation;software development management;statistical analysis,software cost estimation model;multiple comparisons algorithm;software project;project management;statistical framework;software cost estimation ranking;software cost estimation clustering,,73.0,,54.0,,10 Jul 2012,,,IEEE,IEEE Journals
521,522,Integer Linear Programming-Based Property Checking for Asynchronous Reactive Systems,S. Leue; W. Wei,"University of Konstanz, Konstanz; SAP AG, Darmstadt",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,216,236,"Asynchronous reactive systems form the basis of a wide range of software systems, for instance in the telecommunications domain. It is highly desirable to rigorously show that these systems are correctly designed. However, traditional formal approaches to the verification of these systems are often difficult because asynchronous reactive systems usually possess extremely large or even infinite state spaces. We propose an integer linear program (ILP) solving-based property checking framework that concentrates on the local analysis of the cyclic behavior of each individual component of a system. We apply our framework to the checking of the buffer boundedness and livelock freedom properties, both of which are undecidable for asynchronous reactive systems with an infinite state space. We illustrate the application of the proposed checking methods to Promela, the input language of the SPIN model checker. While the precision of our framework remains an issue, we propose a counterexample guided abstraction refinement procedure based on the discovery of dependences among control flow cycles. We have implemented prototype tools with which we obtained promising experimental results on real-life system models.",1939-3520,,10.1109/TSE.2011.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680910,Software verification;formal methods;property checking;integer linear programming;static analysis;abstraction;refinement;counterexamples;asynchronous communication;buffer boundedness;livelock freedom;control flow cycles;cycle dependences;UML;Promela,Unified modeling language;Complexity theory;Analytical models;Message passing;Integer linear programming;Mathematical model;Cost accounting,data structures;formal languages;formal verification;integer programming;linear programming;program diagnostics;state-space methods,integer linear programming-based property checking;asynchronous reactive systems;software systems;telecommunications domain;formal approaches;infinite state spaces;ILP solving-based property checking framework;cyclic behavior;individual component;buffer boundedness;livelock freedom properties;Promela;SPIN model checker input language;counterexample guided abstraction refinement procedure;control flow cycles;real-life system models,,,,73.0,,6 Jan 2011,,,IEEE,IEEE Journals
522,523,Deriving a Slicing Algorithm via FermaT Transformations,M. P. Ward; H. Zedan,"De Montfort University, Leicester; De Montfort University, Leicester",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,24,47,"In this paper, we present a case study in deriving an algorithm from a formal specification via FermaT transformations. The general method (which is presented in a separate paper) is extended to a method for deriving an implementation of a program transformation from a specification of the program transformation. We use program slicing as an example transformation since this is of interest outside the program transformation community. We develop a formal specification for program slicing in the form of a WSL specification statement which is refined into a simple slicing algorithm by applying a sequence of general purpose program transformations and refinements. Finally, we show how the same methods can be used to derive an algorithm for semantic slicing. The main novel contributions of this paper are: 1) developing a formal specification for slicing, 2) expressing the definition of slicing in terms of a WSL specification statement, and 3) by applying correctness preserving transformations to the specification, we can derive a simple slicing algorithm.",1939-3520,,10.1109/TSE.2010.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401170,Program slicing;program transformations;formal methods;algorithm derivation.,Formal specifications;Logic;Software algorithms;Reverse engineering;Assembly;High level languages,formal specification;program slicing,slicing algorithm;FermaT transformations;program transformation;program slicing;WSL specification statement;semantic slicing,,6.0,,73.0,,29 Jan 2010,,,IEEE,IEEE Journals
523,524,Specifying and Validating Data-Aware Temporal Web Service Properties,S. Halle; R. Villemaire; O. Cherkaoui,"University of California, Santa Barbara, Santa Barbara; Université du Québec à Montréal, Montréal; Université du Québec à Montréal, Montréal",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,669,683,"Most works that extend workflow validation beyond syntactical checking consider constraints on the sequence of messages exchanged between services. These constraints are expressed only in terms of message names and abstract away their actual data content. We provide examples of real-world ""data-aware"" Web service constraints where the sequence of messages and their content are interdependent. To this end, we present CTL-FO+, an extension over computation tree logic that includes first-order quantification on message content in addition to temporal operators. We show how CTL-FO+ is adequate for expressing data-aware constraints, give a sound and complete model checking algorithm for CTL-FO+, and establish its complexity to be PSPACE-complete. A ""naive"" translation of CTL-FO+ into CTL leads to a serious exponential blowup of the problem that prevents existing validation tools to be used. We provide an alternate translation of CTL-FO+ into CTL, where the construction of the workflow model depends on the property to validate. We show experimentally how this translation is significantly more efficient for complex formulas and makes model checking of data-aware temporal properties on real-world Web service workflows tractable using off-the-shelf tools.",1939-3520,,10.1109/TSE.2009.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4907003,Web services;software/program verification;model checking;temporal logic.,Web services;Logic;Formal languages;Computer Society;Web and internet services;Guidelines;Contracts;Terminology;Simple object access protocol,computational complexity;formal specification;program verification;temporal logic;trees (mathematics);Web services,data-aware temporal Web service property;workflow validation;syntactical checking;messages exchange;CTL-FO+;computation tree logic;first-order quantification;model checking algorithm complexity;PSPACE-complete;formal specification,,23.0,,47.0,,2 May 2009,,,IEEE,IEEE Journals
524,525,Finding Bugs in Web Applications Using Dynamic Test Generation and Explicit-State Model Checking,S. Artzi; A. Kiezun; J. Dolby; F. Tip; D. Dig; A. Paradkar; M. D. Ernst,"Thomas J. Watson Research Center, Hawthorne; Women's Hospital/Harvard Medical School, Boston; Thomas J. Watson Research Center, Hawthorne; Thomas J. Watson Research Center, Hawthorne; University of Illinois at Urbana-Champaign, Urbana; Thomas J. Watson Research Center, Hawthorne; University of Washington, Seattle",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,474,494,"Web script crashes and malformed dynamically generated webpages are common errors, and they seriously impact the usability of Web applications. Current tools for webpage validation cannot handle the dynamically generated pages that are ubiquitous on today's Internet. We present a dynamic test generation technique for the domain of dynamic Web applications. The technique utilizes both combined concrete and symbolic execution and explicit-state model checking. The technique generates tests automatically, runs the tests capturing logical constraints on inputs, and minimizes the conditions on the inputs to failing tests so that the resulting bug reports are small and useful in finding and fixing the underlying faults. Our tool Apollo implements the technique for the PHP programming language. Apollo generates test inputs for a Web application, monitors the application for crashes, and validates that the output conforms to the HTML specification. This paper presents Apollo's algorithms and implementation, and an experimental evaluation that revealed 673 faults in six PHP Web applications.",1939-3520,,10.1109/TSE.2010.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416728,Software testing;Web applications;dynamic analysis;PHP;reliability;verification.,Computer bugs;Vehicle crash testing;Automatic testing;Logic testing;Computer crashes;Usability;Internet;Concrete;Computer languages;HTML,program debugging;program testing;program verification;software tools,dynamic test generation;explicit state model checking;Web script;Web pages;Apollo tool;PHP programming language;HTML specification;PHP Web applications;bugs;Internet,,61.0,5.0,48.0,,18 Feb 2010,,,IEEE,IEEE Journals
525,526,Centroidal Voronoi Tessellations- A New Approach to Random Testing,A. Shahbazi; A. F. Tappenden; J. Miller,"University of Alberta, Edmonton; The King's University College, Edmonton; University of Alberta, Edmonton",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,163,183,"Although Random Testing (RT) is low cost and straightforward, its effectiveness is not satisfactory. To increase the effectiveness of RT, researchers have developed Adaptive Random Testing (ART) and Quasi-Random Testing (QRT) methods which attempt to maximize the test case coverage of the input domain. This paper proposes the use of Centroidal Voronoi Tessellations (CVT) to address this problem. Accordingly, a test case generation method, namely, Random Border CVT (RBCVT), is proposed which can enhance the previous RT methods to improve their coverage of the input space. The generated test cases by the other methods act as the input to the RBCVT algorithm and the output is an improved set of test cases. Therefore, RBCVT is not an independent method and is considered as an add-on to the previous methods. An extensive simulation study and a mutant-based software testing investigation have been performed to demonstrate the effectiveness of RBCVT against the ART and QRT methods. Results from the experimental frameworks demonstrate that RBCVT outperforms previous methods. In addition, a novel search algorithm has been incorporated into RBCVT reducing the order of computational complexity of the new approach. To further analyze the RBCVT method, randomness analysis was undertaken demonstrating that RBCVT has the same characteristics as ART methods in this regard.",1939-3520,,10.1109/TSE.2012.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6165316,Adaptive random testing;centroidal Voronoi tessellation;P-measure;random testing;software testing;test case generation;test strategies,Subspace constraints;Software testing;Generators;Software algorithms;Power capacitors;Runtime,computational complexity;computational geometry;program testing,centroidal Voronoi tessellations;adaptive random testing method;ART method;quasi-random testing method;QRT method;test case generation method;random border CVT;RBCVT algorithm;mutant-based software testing;search algorithm;computational complexity;randomness analysis;software defects,,34.0,,68.0,,6 Mar 2012,,,IEEE,IEEE Journals
526,527,Comments on “Researcher Bias: The Use of Machine Learning in Software Defect Prediction”,C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto,"Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan; Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Nara, Japan",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,1092,1094,"Shepperd et al. find that the reported performance of a defect prediction model shares a strong relationship with the group of researchers who construct the models. In this paper, we perform an alternative investigation of Shepperd et al.'s data. We observe that (a) research group shares a strong association with other explanatory variables (i.e., the dataset and metric families that are used to build a model); (b) the strong association among these explanatory variables makes it difficult to discern the impact of the research group on model performance; and (c) after mitigating the impact of this strong association, we find that the research group has a smaller impact than the metric family. These observations lead us to conclude that the relationship between the research group and the performance of a defect prediction model are more likely due to the tendency of researchers to reuse experimental components (e.g., datasets and metrics). We recommend that researchers experiment with a broader selection of datasets and metrics to combat any potential bias in their results.",1939-3520,,10.1109/TSE.2016.2553030,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7450669,Software quality assurance;defect prediction;researcher bias,Measurement;Interference;Analysis of variance;Predictive models;Analytical models;NASA;Data models,learning (artificial intelligence);software fault tolerance;software quality,researcher bias;machine learning;software defect prediction;software quality assurance,,29.0,,18.0,,11 Apr 2016,,,IEEE,IEEE Journals
527,528,Detecting Memory Leaks Statically with Full-Sparse Value-Flow Analysis,Y. Sui; D. Ye; J. Xue,"Programming Language and Compilers Group, School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; Programming Language and Compilers Group, School of Computer Science and Engineering, University of New South Wales, Sydney, Australia; Programming Language and Compilers Group, School of Computer Science and Engineering, University of New South Wales, Sydney, Australia",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,2,107,122,"We introduce a static detector, Saber, for detecting memory leaks in C programs. Leveraging recent advances on sparse pointer analysis, Saber is the first to use a full-sparse value-flow analysis for detecting memory leaks statically. Saber tracks the flow of values from allocation to free sites using a sparse value-flow graph (SVFG) that captures def-use chains and value flows via assignments for all memory locations represented by both top-level and address-taken pointers. By exploiting field-, flow- and context-sensitivity during different phases of the analysis, Saber detects memory leaks in a program by solving a graph reachability problem on its SVFG. Saber, which is fully implemented in Open64, is effective at detecting 254 leaks in the 15 SPEC2000 C programs and seven applications, while keeping the false positive rate at 18.3 percent. Saber compares favorably with several static leak detectors in terms of accuracy (leaks and false alarms reported) and scalability (LOC analyzed per second). In particular, compared with Fastcheck (which analyzes allocated objects flowing only into top-level pointers) using the 15 SPEC2000 C programs, Saber detects 44.1 percent more leaks at a slightly higher false positive rate but is only a few times slower.",1939-3520,,10.1109/TSE.2014.2302311,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6720116,Memory Leaks;sparse value-flow analysis;static analysis;pointer analysis,Detectors;Resource management;Accuracy;Scalability;Abstracts;Standards;Sensitivity,C language;program diagnostics;reachability analysis;storage management,memory leaks detection;full-sparse value-flow analysis;Saber static detector;sparse pointer analysis;sparse value-flow graph;SVFG;def-use chains;value flows;memory locations;top-level pointers;address-taken pointers;field-sensitivity;flow-sensitivity;context-sensitivity;graph reachability problem;Open64;SPEC2000 C programs;false positive rate;static leak detectors;Fastcheck,,32.0,,38.0,,23 Jan 2014,,,IEEE,IEEE Journals
528,529,Technical Debt: From Metaphor to Theory and Practice,P. Kruchten; R. L. Nord; I. Ozkaya,"University of British Columbia, Vancouver; Software Engineering Institute; Software Engineering Institute",IEEE Software,22 Oct 2012,2012,29,6,18,21,"The metaphor of technical debt in software development was introduced two decades ago to explain to nontechnical stakeholders the need for what we call now ""refactoring."" As the term is being used to describe a wide range of phenomena, this paper proposes an organization of the technical debt landscape, and introduces the papers on technical debt contained in the issue.",1937-4194,,10.1109/MS.2012.167,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6336722,technical debt;software quality;refactoring;evolvability;maintainability,Software quality;Investments;Risk management;Sofware testing;Software maintenance,,,,245.0,6.0,10.0,,22 Oct 2012,,,IEEE,IEEE Magazines
529,530,Clearing the Way for Software Product Line Success,L. G. Jones; L. M. Northrop,"Software Engineering Institute, Carnegie Mellon University; Software Engineering Institute, Carnegie Mellon University",IEEE Software,19 Apr 2010,2010,27,3,22,28,"We mostly see two strategic pitfalls across the board: failure to recognize that a SPL approach is both a business and a technical strategy, and failure to manage the product-line-unique aspects of both governance and roll-out appropriately. How would you know if your organization suffers from either or both? These two pitfalls lead naturally to four high-level diagnostic questions, the answers to which are best discovered by answers to subordinate questions. Rather than describe a set of symptoms, we'll begin by letting you be your own doctor and consider a series of self-diagnostic questions based on what we've found lacking.",1937-4194,,10.1109/MS.2010.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452145,software product lines;software product line adoption,Organizations;Product development;Computer architecture;Production facilities;Software,business data processing;product development;software reusability,SPL;software product line;business strategy;technical strategy,,8.0,,8.0,,19 Apr 2010,,,IEEE,IEEE Magazines
530,531,Scientific Software Testing: Analysis with Four Dimensions,D. Kelly; S. Thorsteinson; D. Hook,Royal Military College; Royal Military College; Engineering Seismology Group Solutions,IEEE Software,25 Apr 2011,2011,28,3,84,90,"By analyzing our testing exercise through the four dimensions of context, goals, techniques, and adequacy, we developed a better understanding of how to effectively test a piece of scientific software. Once we considered the scientist-tester as part of the testing system, the exercise evolved in a way that made use of and increased his knowledge of the software. One result was an approach to software assessment that combines inspection with code execution. An other result was the suppression of process-driven testing in favor of goal centric approaches. The combination of software engineer working with scientist was success ful in this case. The software engineer brings a toolkit of ideas, and the scientist chooses and fashions the tools into some thing that works for a specific situation. Unlike many other types of software systems, scientific software includes the scientist as an integral part of the system. The tools that support the scientist must include the scientist's knowledge and goals in their design. This represents a different way of considering the juxtaposition of software engineering with scientific software development.",1937-4194,,10.1109/MS.2010.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467013,scientific software;software testing;multidisciplinary team,Software testing;Software engineering;System testing;Cultural differences;Application software;Time to market,natural sciences computing;program testing,scientific software testing;software assessment;code execution inspection;process-driven testing;software systems;software design;software engineering;scientific software development,,15.0,,8.0,,20 May 2010,,,IEEE,IEEE Magazines
531,532,"The Awareness Network, To Whom Should I Display My Actions? And, Whose Actions Should I Monitor?",C. R. B. de Souza; D. F. Redmiles,"IBM Brazil, Sã o Paulo; University of California, Irvine, Irvine",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,325,340,"The concept of awareness plays a pivotal role in research in Computer-Supported Cooperative Work. Recently, software engineering researchers interested in the collaborative nature of software development have explored the implications of this concept in the design of software development tools. A critical aspect of awareness is the associated coordinative work practices of displaying and monitoring actions. This aspect concerns how colleagues monitor one another's actions to understand how these actions impact their own work and how they display their actions in such a way that others can easily monitor them while doing their own work. In this paper, we focus on an additional aspect of awareness: the identification of the social actors who should be monitored and the actors to whom their actions should be displayed. We address this aspect by presenting software developers' work practices based on ethnographic data from three different software development teams. In addition, we illustrate how these work practices are influenced by different factors, including the organizational setting, the age of the project, and the software architecture. We discuss how our results are relevant for both CSCW and software engineering researchers.",1939-3520,,10.1109/TSE.2011.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710950,Computer-supported cooperative work;organizational management and coordination;programming environments;programming teams;tools.,Software;Programming;Monitoring;Interviews;Collaboration;Servers,groupware;software architecture,awareness network;computer-supported cooperative work;software development;social actor;ethnographic data;organizational setting;project age;software architecture;CSCW,,35.0,,57.0,,10 Feb 2011,,,IEEE,IEEE Journals
532,533,Start with the Most Difficult Part,D. Spinellis,Athens University of Economics and Business,IEEE Software,24 Feb 2009,2009,26,2,70,71,"Any development project involves elements that we don't know at the beginning and discover as we progress. In this paper, the author discusses the advantages of starting with the most difficult part of a software development process.",1937-4194,,10.1109/MS.2009.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786956,process;design;bottom-up;top-down;agility,Wikipedia;Encoding;Data structures;HTML;Sockets;Fitting;Assembly;Uncertainty;Humans;Meeting planning,software engineering,software development process,,,,,,24 Feb 2009,,,IEEE,IEEE Magazines
533,534,Does Involving Users in Software Development Really Influence System Success?,U. Abelein; H. Sharp; B. Paech,University of Heidelberg; The Open University; University of Heidelberg,IEEE Software,28 Oct 2013,2013,30,6,17,23,"Researchers have studied how best to involve users in software development for a long time, primarily in the area of information systems and human-computer interaction. The authors consider the effects of both user participation and user involvement, which they abbreviate to UPI. Existing research describes several benefits of UPI, such as improved quality due to more precise requirements, the prevention of unneeded and expensive features, and an increase in user satisfaction, which leads to higher system use. But even though some researchers consider it to be essential to system success, other studies have found contradicting results. Furthermore, it's not a common practice in today's IT projects to involve users to a large extent. To clarify UPI's effects on system success and to get a deeper understanding of the differences between user participation and user involvement, the authors reviewed the existing UPI literature in software development and conducted a systematic mapping study.",1937-4194,,10.1109/MS.2013.124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648584,user participation;user involvement;software development;systematic mapping study;literature review;meta analysis,User centered design;Software development;Prototypes;Time measurement;Software systems,software engineering;software management;user centred design,software development;user involvement;information systems;human-computer interaction;user satisfaction;IT projects;system success;user participation;UPI literature,,19.0,,11.0,,28 Oct 2013,,,IEEE,IEEE Magazines
534,535,Unmasking Your Software's Ethical Risks,D. Gotterbarn; K. W. Miller,East Tennessee State University; University of Illinois at Springfield,IEEE Software,31 Dec 2009,2010,27,1,12,13,"It's difficult to fully address all our professional obligations as software engineers. Our training focuses on avoiding technical failures, but unfortunately our systems sometimes have unintended consequences. We need to develop products to avoid unintended negative impacts on society, people, and the environment. Professional responsibility requires that we identify the morally salient features of a situation. Some issues are relatively easy to spot; for example, we shouldn't lie to clients, we shouldn't bribe inspectors, and we should respect people's privacy. But some ethical and social risks are harder to recognize. Even developers with the best intentions have walked into ethical traps. When we study technical problems, we apply the project's constraints and priorities to find acceptable possible solutions and choose among them. Here are four suggestions for considering ethical constraints during that process, they are: look for human values in technical decision; identifying who will be affected; examining how stakeholders' right and obligation will be affectedl; and reviewing relevant professional standards to help identify issues.",1937-4194,,10.1109/MS.2010.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370758,Ethics;risks;ethics code;stakeholder rights,Privacy;Humans,ethical aspects;software engineering,software ethical risk;professional obligation;software engineer;unintended negative impact prevention;professional responsibility;projects constraint;human value;technical decision;relevant professional standard,,2.0,,3.0,,31 Dec 2009,,,IEEE,IEEE Magazines
535,536,The Software behind Moore's Law,R. Wester; J. Koster,ASML; ASML,IEEE Software,10 Mar 2015,2015,32,2,37,40,"Moore's law describes exponential productivity in the semiconductor industry. It depends on rapid hardware and software development. Many hardware modules will be replaced in new products, while the total system software must remain consistent and high performing. This brings unique challenges, and this article discusses software development strategies.",1937-4194,,10.1109/MS.2015.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057609,Moore's law;software development;lines of code;ASML;computer chips;TWINSCAN,Software development;Productivity;Ultraviolet sources;Optical sensors;Lithography;Technological innovation;Optical imaging;Semiconductor devices;Moore's Law,software engineering,Moore's law;semiconductor industry;hardware development;software development,,3.0,,3.0,,10 Mar 2015,,,IEEE,IEEE Magazines
536,537,Cyber Dumpster Diving: Creating New Software Systems for Less,I. Gorton,Pacific Northwest National Laboratory,IEEE Software,3 Jan 2013,2013,30,1,9,13,"This is the first article we're fortunate to have from the SATURN 2012 conference. This issue highlights a compelling story of crisis, larceny, and, of course, Fortran-the first programming language I learned, which I did by teaching it to undergrad engineering students. Because I never saw those engineers after they left my class, it's heartening to see that others like them learned some good lessons and developed useful insights. I'm sure you will enjoy reading this architectural tale.",1937-4194,,10.1109/MS.2013.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401107,software architecture;software reuse;scientific user environments,Software architecture;Data models;Licenses;Computer architecture;Numerical models,FORTRAN;software engineering,cyber dumpster diving;software systems creation;SATURN conference;Fortran programming language;undergrad engineering students,,2.0,,2.0,,3 Jan 2013,,,IEEE,IEEE Magazines
537,538,Designing in the Future,R. J. Wirfs-Brock,Wirfs-Brock Associates,IEEE Software,22 Dec 2008,2009,26,1,18,19,"The consequences of poorly structured requirements obviously have enormous consequences on design. Given that problems rarely are well formed, what responsibility should we designers take to bring clarity to the problem? Whether this is official design work or not, I keep backing up to clarify problems in order to bring clarity to my design. If I don't, coming up with simple, comprehensive solutions on the fly is difficult. Messy problems don't lead to clean design. And small refactorings don't always collectively add up to appropriate design abstractions. I hope the future will yield better techniques for understanding and structuring problems as well as design solutions.",1937-4194,,10.1109/MS.2009.7,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721176,software design;up-front design;design-as-you-go;design rhythms,Programming profession;Artificial intelligence;Humans;Marine vehicles;Manufacturing;Costs;Process design;Testing,software engineering,software design,,,,,,22 Dec 2008,,,IEEE,IEEE Magazines
538,539,Software in an Evolving Train Traffic Control System,K. Tomita; K. Ito,Hitachi; East Japan Railway Company,IEEE Software,28 Feb 2011,2011,28,2,19,21,"This contribution is rather different from the other articles we're run in this department to date. Here, software volume isn't an issue as there is only one Tokyo-instead, we look at the incremental development of a network of systems controlling railway lines, which requires adding value without disruption. This particular scenario contains many interesting facets, including the use of COTS and refactoring. We're indebted to Takao Futagami for facilitating this contribution.",1937-4194,,10.1109/MS.2011.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720708,Impact;long-term development;reliability;autonomous decentralized system;refactoring,Servers;Railway communication;Traffic control;Rail transportation;Computer architecture;Maintenance engineering;Real time systems;Intelligent transportation systems,railway engineering;software engineering;traffic engineering computing,railway;software development;COTS;train traffic control system,,6.0,,,,28 Feb 2011,,,IEEE,IEEE Magazines
539,540,Agile Requirements Can We Have Our Cake and Eat It Too?,N. Maiden; S. Jones,City University London; City University London,IEEE Software,19 Apr 2010,2010,27,3,87,88,"Over the last decade, software development has seen a substantial growth in the use of agile techniques. Agile emerged as an alternative way to develop software and manage projects. Unlike traditional methods that focus on modelling and analysis, agile encourages communication and collaboration with end users to develop software without the need for modelling. Documentation that is large, paper-based, and difficult-to-read becomes the enemy because it empedes effective communication among people in projects.",1937-4194,,10.1109/MS.2010.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452150,Requirements;agile techniques;requirements documentation,Collaborative software;Programming;Project management;Software development management;Documentation;Communication effectiveness,software engineering,agile requirements;software development;agile techniques,,4.0,,4.0,,19 Apr 2010,,,IEEE,IEEE Magazines
540,541,The Benefit of Patterns,L. Rising,independent consultant,IEEE Software,19 Aug 2010,2010,27,5,15,17,"This article talks about the role of design patterns in the software development. It discusses about the new and interesting object-oriented designs, vision patterns and mediator design pattern. The real power of patterns is not to hand us exotic solutions, but to give us a way to remember the simple, ordinary, basic solutions that we know but forget.",1937-4194,,10.1109/MS.2010.127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551013,patterns;architecture;design;decision-making;team size,Pattern recognition;Decision making;Computer architecture;Design methodology,object-oriented methods;software engineering,software development;object oriented design;vision pattern;mediator design pattern,,2.0,,4.0,,19 Aug 2010,,,IEEE,IEEE Magazines
541,542,Developing in the Cloud,D. Spinellis,Athens University of Economics and Business,IEEE Software,17 Mar 2014,2014,31,2,41,43,"Many affordable cloud-based offerings that cover software development needs, like version control, issue tracking, remote application monitoring, localization, deployment, payment processing, and continuous integration, do away with the setup, maintenance, and user support costs and complexity associated with running such systems in-house. The most important risks of cloud-based tools concern control of the data stored and the services an organization uses. On the other hand, cloud-based tools dramatically lower the capital requirements and setup costs of a software development organization. They also help organizations adopt best practices in each domain simply by registering with the corresponding service. Using a cloud-based service also means fewer worries regarding scalability, while from the customers' perspective delivering a service through the cloud allows an organization to have a much closer relationship with them. Through cloud-based services the development infrastructure is becoming increasingly homogeneous allowing developers to use the same tools across diverse projects and employers, transferring knowledge and skills from one job to the next, and offering a deeper talent pool of experienced developers. The Web extra at http://youtu.be/szfwWLr30qk is an audio podcast of author Diomidis Spinellis reading his Tools of the Trade column, in which he discusses how cloud-based services are making the software development infrastructure increasingly homogeneous by allowing developers to use the same tools across diverse projects and employers, transferring knowledge and skills from one job to the next, and offering a deeper talent pool of experienced developers.",1937-4194,,10.1109/MS.2014.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774357,cloud;platform as a service;tools;PaaS,Software development;Cloud computing,cloud computing;software engineering,cloud-based offerings;cloud-based tools;software development organization;cloud-based service;software development infrastructure,,1.0,,,,17 Mar 2014,,,IEEE,IEEE Magazines
542,543,Five Facts on the Adoption of Open Source Software,C. P. Ayala; D. Cruzes; Ø. Hauge; R. Conradi,Technical University of Catalunya; Norwegian University of Science and Technology; CapGemini Norge AS; Norwegian University of Science and Technology,IEEE Software,28 Feb 2011,2011,28,2,95,99,"Across the spectrum of software organizations-from traditional software houses to service providers, in both public and private sectors-open source software (OSS) is changing the way they develop, acquire, use, and commercialize software. However, con flicting views about exactly what the OSS phenomenon is remain common. Furthermore, the professional literature doesn't clarify as much as it could-not only because empirical studies are still sparse but also because the studies that do exist reflect different perspectives.",1937-4194,,10.1109/MS.2011.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720716,software development;open source,Standards;Open source software;Licenses;Software development management,public domain software;software engineering;software houses,open source software;software organizations;software houses;service providers;OSS;commercialize software,,17.0,,12.0,,28 Feb 2011,,,IEEE,IEEE Magazines
543,544,Designing with an Agile Attitude,R. J. Wirfs-Brock,Wirfs-Brock Associates,IEEE Software,24 Feb 2009,2009,26,2,68,69,"In this article, we investigate what does it take to be an effective software designer in an agile development environment. An agile design does demand teamwork and cooperation. Agile designers need to sharpen their communication and collaboration skills as well as their technical practices. They should value collaboration and collective understanding as much as good design and development practices. It's a matter of attitude more than any specific technique or process.",1937-4194,,10.1109/MS.2009.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786955,agile software design;pair programming;reflection meetings,Project management;Process design;Software design;IEEE Press;Programming;Testing;Productivity;Meeting planning;Teamwork;Delay,groupware;software engineering,software designer;agile development environment;teamwork;collaboration skills,,1.0,,,,24 Feb 2009,,,IEEE,IEEE Magazines
544,545,The Responsible Designer,R. J. Wirfs-Brock,Wirfs-Brock Associates,IEEE Software,16 Oct 2009,2009,26,6,9,10,"Successful software systems often live far longer than their original designers anticipated. And over their lifetime, most of those systems evolve. Developers who make modifications, fix bugs, and add new features to long-lived systems have an easier time of it if they keep the code base habitable (""Creating Sustainable Designs,"" Rebecca Wirfs-Brock, IEEE Software, May/June 2009) and preserve design integrity. But even so, maintenance can be painful when new requirements invalidate initial design assumptions. This paper discussed about methods and techniques on how to achieve software's flexible design. Flexible design is the byproduct of preparation and continued attention to detail. Where there's a lot of variability in a design problem, a flexible solution will incorporate appropriate design hooks that allow for developers to predictably add planned extensions. Once they've established ways to support specific variations, developers can follow predefined extension recipes rather than hacking in new features that are similar to existing ones.",1937-4194,,10.1109/MS.2009.190,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287000,responsible design;agile development;flexibility;commonality-variability analysis,Software systems;Computer bugs;Computer crime,software engineering,software modification;software debugging;design integrity;software maintenance;software flexible design;software developer;software extension,,,,,,16 Oct 2009,,,IEEE,IEEE Magazines
545,546,Toward Unweaving Streams of Thought for Reflection in Professional Software Design,K. Nakakoji; Y. Yamamoto; N. Matsubara; Y. Shirai,Software Research Associates; Tokyo Institute of Technology; Software Research Associates; NTT Corporation,IEEE Software,22 Dec 2011,2012,29,1,34,38,"Software designers make decisions covering a wide variety of aspects of the software to be designed through nested, intertwined processes. Some of these dependencies among design decisions might not be obvious, especially for people who didn't start with the project at the beginning of the design process. Extending or altering an existing design decision without fully understanding its dependencies might result in a deterioration of the quality of the software design. Design practice streams (DPS) tools help designers browse the segments of video data relevant to a particular topic by specifying a region on a whiteboard or by choosing a few terms used in a meeting transcript to further investigate the point of interest effectively.",1937-4194,,10.1109/MS.2011.125,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035659,software design support;design meeting record viewer;interaction design;DPS (Design Practice Streams),Software design;Product development;Streaming media;Motion pictures;Video signal processing,software engineering,professional software design;software design quality;design practice streams tool;whiteboard,,3.0,,8.0,,6 Oct 2011,,,IEEE,IEEE Magazines
546,547,Creative Requirements Conversations,M. R. Cook; N. Maiden,"NA; City Univ. London, London, UK",IEEE Software,25 Feb 2010,2010,27,2,90,91,"Uscreates projects show that capturing requirements to inform the design of products, services, and systems must involve truly engaging people in conversation. This is a creative process that has to be designed to suit the people involved in the discussion. It's easy to speak to the willing, but often these aren't the people from which the information is needed. Uscreates is often commissioned to reach ""hard to reach"" groups. No group of people is hard to reach if the research and designing is done in the right environments and methods to speak to them. The high levels of technology are necessary to gather information and requirements for human centered projects. It's more about the design of the space and the people facilitating the conversation; spaces that encourage creative conversation are low in technology, but high in facilitation.",1937-4194,,10.1109/MS.2010.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420802,design;creativity;collaboration;behavior change;requirements;engineering,Space technology;Product design;Humans,software engineering;user centred design,Uscreates projects;software designing;people conversation;human-centered project;product design;system design;services;creative requirements conversations,,3.0,,,,25 Feb 2010,,,IEEE,IEEE Magazines
547,548,When Robert Rules,P. Kruchten,University of British Columbia,IEEE Software,22 Dec 2008,2009,26,1,20,21,"This paper discuses how software development is often more about people - collaboration, communication, and coordination - than technology, developing ""soft skills"" such as meeting-management techniques is becoming more important. The author recommends to many people to learn more about Robert's Rules of Order, to take a class or a workshop, to read a book about it, and to go beyond the surface and the funny jargon to transpose what they learn about formal debates to the more informal meetings that now make up a large chunk of a software practitioner's life. Besides, your hockey club, Parent-Teacher Association, or your local IEEE Computer Society chapter will love you for your useful facilitator skills. The author suggests that all software practitioners learn more about Robert's rules.",1937-4194,,10.1109/MS.2009.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721177,Meeting conduct;Robert's Rule of Order,Software;Programming;Books;Career development;Focusing;Lead;Chapters,software engineering,software development;collaboration;communication;coordination;meeting-management techniques,,,,2.0,,22 Dec 2008,,,IEEE,IEEE Magazines
548,549,Going Underground,M. van Malkenhorst; L. Mollinger,Shell; Shell,IEEE Software,20 Apr 2012,2012,29,3,17,20,"Software for oil exploration and production has been a topic for software R&D for decades, and Shell is one of the main players. The role of such applications can't be underestimated. For example, what's the cost of a defect if you drill in the wrong place as a result of a software bug, knowing that without software you wouldn't have a clue where to start drilling? Shell, one of the largest companies in the world, is very specific about which software it wants to develop and which software it wants to buy elsewhere, even for a core competence like oil exploration and production.",1937-4194,,10.1109/MS.2012.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188597,software;oil;exploration;Shell;dynamic;modeling;IT;drilling;Dynamo;MoRes;Modular Reservoir Simulator;impact,Software;Reservoirs;Computational modeling;Production;Computer bugs;Generators;Physics,gas industry;petroleum industry;program debugging;software engineering,oil exploration;Shell;software bug;drilling;oil production;software R&D;software development,,6.0,,7.0,,20 Apr 2012,,,IEEE,IEEE Magazines
549,550,Process Management Tools,F. Garcia; A. Vizcaino; C. Ebert,University of Castilla-La Mancha; University of Castilla-La Mancha; Vector Consulting Services,IEEE Software,28 Feb 2011,2011,28,2,15,18,"Software development is complex, especially with many interacting people and teams. A variety of tools exist to model the development process and thus facilitate communication, automation, and collaboration. This installment looks to support tools for process modeling and their underlying methodologies.",1937-4194,,10.1109/MS.2011.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720707,software process;tools;process modeling;collaboration,Process control;Unified modeling language;Business;Automation;Knowledge engineering;Collaboration;Software development management,software engineering,software development;process modeling,,8.0,,6.0,,28 Feb 2011,,,IEEE,IEEE Magazines
550,551,Context is King: What's Your Software's Operating Range?,F. Torres,GMV Aerospace and Defence,IEEE Software,21 Aug 2015,2015,32,5,9,12,"Unexpected responses to a study questionnaire led to the realization that the context in which software is being used is extremely important. One particular thing to keep in mind is the software's operating range; that is, the conditions in which the software works best.",1937-4194,,10.1109/MS.2015.121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217770,software development;operating range;user interfaces;software configurability;context,Context awareness;Software development;User interfaces;Electronic mail;Mobile communication;Operating range;User interfaces,software engineering,software operating range,,3.0,,4.0,,21 Aug 2015,,,IEEE,IEEE Magazines
551,552,Continuous Integration and Its Tools,M. Meyer,Travis CI,IEEE Software,21 Apr 2014,2014,31,3,14,16,"Continuous integration has been around for a while now, but the habits it suggests are far from common practice. Automated builds, a thorough test suite, and committing to the mainline branch every day sound simple at first, but they require a responsible team to implement and constant care. What starts with improved tooling can be a catalyst for long-lasting change in your company's shipping culture. Continuous integration is more than a set of practices, it's a mindset that has one thing in mind: increasing customer value. The Web extra at http://youtu.be/tDl_cHfrJZo is an audio podcast of the Tools of the Trade column discusses how continuous integration is more than a set of practices, it's a mindset that has one thing in mind: increasing customer value.",1937-4194,,10.1109/MS.2014.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802994,continuous integration;continuous delivery;testing,Production;Servers;Monitoring;Software;Green products;Marine vehicles;Multimedia communication,Internet;program testing;software engineering;software tools;source code (software),automated builds;test suite;software development;Web frameworks;source code;customer value;company shipping culture;continuous integration,,19.0,,,,21 Apr 2014,,,IEEE,IEEE Magazines
552,553,Service Design: It's All in the Brand,N. Maiden,City University London,IEEE Software,19 Aug 2010,2010,27,5,18,19,"This column argues that requirements analysts will soon need to deal with service design, and describes one service design method to demonstrate the challenges that analysts will face.",1937-4194,,10.1109/MS.2010.124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551014,requirements;service design;brand innovation,Technological innovation;Presses;Design methodology;Usability;Cities and towns;Buildings,customer services;software engineering;user centred design,service design;service economy;customer experience,,2.0,,4.0,,19 Aug 2010,,,IEEE,IEEE Magazines
553,554,"Bells, Whistles, Power, and the Requirements Process",T. DeMarco,Atlantic Systems Guild,IEEE Software,26 Jun 2013,2013,30,4,104,104,"As the software industry has matured, the requirements process has had to cope with unanticipated shifts of power, increasing complexity of the non-technological part of the work, and abandonment of some of the comforting myths of past century.",1937-4194,,10.1109/MS.2013.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547598,requirements;organizational politics;system analysis;specification,Software requirements;Software development;Technological innovation,software engineering,software industry;software requirement process,,1.0,,,,26 Jun 2013,,,IEEE,IEEE Magazines
554,555,Requirements Engineering's Next Top Model,O. Gotel; J. Cleland-Huang,NA; DePaul University,IEEE Software,28 Oct 2013,2013,30,6,24,29,"A game-show environment let a panel competitively explore the use of various requirements modeling techniques for specifying a complex problem. Although plain old text and rich pictures emerged as the winners, real-world problems are best modeled using a variety of techniques. The Web extra at http://youtu.be/6vfIwSauj5o is an audio podcast of author Jane Cleland-Huang providing an audio recording of her Requirements column, in which she discusses how a game-show environment at the 2013 European Software Engineering Conference let a panel competitively explore the use of various requirements modeling techniques for specifying a complex problem.",1937-4194,,10.1109/MS.2013.129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648608,requirements;modeling,Unified modeling language;Games;Computational modeling;Adaptation models;Software engineering,,,,,,1.0,,28 Oct 2013,,,IEEE,IEEE Magazines
555,556,Software Agents in Industrial Automation Systems,S. Pech,BASF SE,IEEE Software,18 Apr 2013,2013,30,3,20,24,"Agent orientation is moving from its origins in computer science into applied automation systems engineering. The main benefit of using software agents in industrial automation is the combined application of agent-oriented software engineering with growing fields such as semantic technologies. Software agents also provide flexibility, which is often the key requirement for creating software system architectures that can evolve at runtime.",1937-4194,,10.1109/MS.2013.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6504882,software technologies;agents;software agents;industrial automation;systems engineering,Rail transportation;Automation;System-level design;System analysis and design;Software engineering;Software architecture,,,,5.0,,9.0,,18 Apr 2013,,,IEEE,IEEE Magazines
556,557,Test Management,P. Louridas,Greek Research and Technology Network,IEEE Software,18 Aug 2011,2011,28,5,86,91,"In many projects, testing consumes the single biggest amount of resources of all activities. Companies tend to collect test cases like stamps without clear strategy-just in case. Many companies suffer with insufficient quality, visibility and test progress management. This article introduces test management.",1937-4194,,10.1109/MS.2011.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984799,testing;test management;software;software engineering;defect removal efficiency,Software quality;Software measurement;Computer bugs;Software testing;Testing,program testing;project management;software management;software quality,test progress management;project management,,1.0,,3.0,,18 Aug 2011,,,IEEE,IEEE Magazines
557,558,Trends in Agile: Perspectives from the Practitioners,R. Prikladnicki; C. Lassenius; E. Tian; J. C. Carver,Pontifical Catholic University of Rio Grande do Sul; Aalto University; Ericsson; University of Alabama,IEEE Software,28 Oct 2016,2016,33,6,20,22,"The Agile Conference is the largest global conference on agile software development, catering particularly to practitioners. Agile 2016 had a record 2,500 participants. This article reports on two keynotes and a new IEEE Software conference initiative.",1937-4194,,10.1109/MS.2016.152,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725226,agile development;Agile Conference;Agile 2016;managing for happiness;Modern Agile;Scrum;digital disruption;software practitioners;software engineering;software development;IEEE Software,,software prototyping,agile software development;Agile Conference,,1.0,,2.0,,28 Oct 2016,,,IEEE,IEEE Magazines
558,559,"A Classification System for Testing, Part 2",R. L. Glass,Griffith University,IEEE Software,22 Dec 2008,2009,26,1,104,104,"This article looks at what happens when you combine the four goal-driven approaches to testing classification (requirements-driven, statistics-driven, and risk-driven) with the three phase-driven approaches (unit testing, integration testing, and system testing).",1937-4194,,10.1109/MS.2009.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721193,software engineering;software development;test case classification;goal-driven testing;phase-driven testing;software testing,System testing;Software testing;Permission;Life testing;Books;Libraries;Software quality;Software systems;Heart;Web server,program testing,software-testing classification system;2D testing classification matrix;goal-driven approach;requirements-driven testing;structure-driven testing;statistics-driven testing;risk-driven testing;software life cycle,,,,,,22 Dec 2008,,,IEEE,IEEE Magazines
559,560,Better Selection of Software Providers through Trialsourcing,M. Jørgensen,Simula Research Laboratory,IEEE Software,24 Aug 2016,2016,33,5,48,53,"Software providers differ widely in productivity and quality, yet traditional performance evaluations fail to separate the competent from the incompetent. Trialsourcing- having multiple providers create sample pieces of software for evaluation-can help software clients select providers.",1937-4194,,10.1109/MS.2015.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006382,trialsourcing;provider selection;skill assessment;software development;software engineering,Software development;Sofware engineering;Telecommunications;Collaboration;Proposals;Context awareness;Complexity theory,software management,software provider selection;software provider productivity;software provider quality;trialsourcing;software clients,,5.0,,7.0,,12 Jan 2015,,,IEEE,IEEE Magazines
560,561,Developments in Requirements Engineering,J. C. Carver,University of Alabama,IEEE Software,11 Jul 2017,2017,34,4,8,10,"This issue's column reports on papers from the 23rd International Working Conference on Requirements Engineering: Foundation for Software Quality. Topics include how to support natural-language requirements, collaboration on requirements, feature-relevant information extraction, detecting ambiguity, and detecting requirements defects.",1937-4194,,10.1109/MS.2017.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974678,International Working Conference on Requirements Engineering: Foundation for Software Quality;REFSQ;requirements engineering;natural language;natural-language requirements;collaboration;information extraction;ambiguity;requirements defects;software engineering;software development,,,,,,,,,11 Jul 2017,,,IEEE,IEEE Magazines
561,562,Group-Based Behavior Adaptation Mechanisms in Object-Oriented Systems,P. Rein; S. Ramson; J. Lincke; T. Felgentreff; R. Hirschfeld,"Hasso Plattner Institute, University of Potsdam; Hasso Plattner Institute, University of Potsdam; Hasso Plattner Institute, University of Potsdam; Hasso Plattner Institute, University of Potsdam; Hasso Plattner Institute, University of Potsdam",IEEE Software,13 Nov 2017,2017,34,6,78,82,Dynamic and distributed systems require behavior adaptations for groups of objects. Group-based behavior adaptation mechanisms scope adaptations to objects matching conditions beyond class membership. The specification of groups can be explicit or implicit.,1937-4194,,10.1109/MS.2017.4121224,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106885,group-based behavior adaptation;lively groups;ContextErlang;entity-component-system;predicated generic functions;active layers;reactive object queries;context groups;implied methods;object-oriented languages;software engineering;software development;contextual-variability modeling,Games;Programming;Context modeling;Software architecture;Adaptation models;Object oriented modeling,object-oriented programming,group-based behavior adaptation mechanisms;object-oriented systems;distributed systems;dynamic systems;object matching conditions;class membership,,,,9.0,,13 Nov 2017,,,IEEE,IEEE Magazines
562,563,Improving Software Quality as Customers Perceive It,R. Hackbarth; A. Mockus; J. Palframan; R. Sethi,Avaya Labs Research; Avaya Labs Research; Avaya Labs Research; Avaya Labs Research,IEEE Software,23 Jun 2016,2016,33,4,40,45,"A proposed data-driven software quality improvement method has three elements. First, the downstream Customer Quality Metric (CQM) quantifies quality as customers perceive it. On the basis of data collected after systems are deployed, it measures how serious defects affect customers. Second, the upstream Implementation Quality Index (IQI) measures the effectiveness of error removal during development. IQI predicts future customer quality; it has a positive correlation with CQM. Finally, prioritization tools and techniques help focus limited development resources on the riskiest files in the code. This research is based on a multiyear program to improve the quality of delivered systems at Avaya, a global provider of business communication and collaboration systems. Regular reviews with Avaya's R&D Quality Council provided governance for the program.",1937-4194,,10.1109/MS.2015.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106410,software quality method;customer perceived quality;data-driven software process improvement;software risk mitigation;case study;Customer Quality Metric;Implementation Quality Index;software quality assurance software engineering;software development,Software measurement;Software systems;Computational fluid dynamics;Predictive models;Customer services;Behavioral science,software metrics;software process improvement;software quality,data-driven software quality improvement;customer quality metric;implementation quality index,,6.0,,11.0,,13 May 2015,,,IEEE,IEEE Magazines
563,564,Randomly Right,G. J. Holzmann,Nimble Research,IEEE Software,22 Sep 2017,2017,34,5,87,89,Game strategies used in tools such as Deep Blue and AlphaGo might be the key to improving and automating software verification.,1937-4194,,10.1109/MS.2017.3571567,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048626,software verification;Deep Blue;AlphaGo;FeaVer;feature verification;software verification;software testing;automated software testing;feature interaction problem;model checkers;software development;software engineering,Games;Testing;Search problems;Databases;Software reliability,program testing;program verification,software verification;software testing;model checking,,,,3.0,,22 Sep 2017,,,IEEE,IEEE Magazines
564,565,The Unplanned Journey of a Requirements Engineer in Industry: An Introduction,S. Gregory,Intel Corporation,IEEE Software,22 Sep 2017,2017,34,5,16,19,New department editor Sarah Gregory tells how her professional introduction to requirements engineering both informs the work she does now and drives questions about the discipline that future installments of the Requirements department will explore.,1937-4194,,10.1109/MS.2017.3571561,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048630,requirements engineering;IEEE International Requirements Engineering Conference;software requirements;software development;software engineering,Professional communication;Requirements engineering;Engineering profession;Training,production engineering computing;systems analysis,requirements engineer;industry,,,,6.0,,22 Sep 2017,,,IEEE,IEEE Magazines
565,566,Software Testing: The State of the Practice,M. Kassab; J. F. DeFranco; P. A. Laplante,Penn State Great Valley; Penn State Great Valley; Penn State Great Valley,IEEE Software,22 Sep 2017,2017,34,5,46,52,"A Web-based survey examined how software professionals used testing. The results offer opportunities for further interpretation and comparison to software testers, project managers, and researchers. The data includes characteristics of practitioners, organizations, projects, and practices.",1937-4194,,10.1109/MS.2017.3571582,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048665,software testing;software quality;agile;industrial survey;software development;software engineering,Surveys;Software testing;Project management;Performance evaluation,program testing;software quality,software testing;software quality;software development,,6.0,,14.0,,22 Sep 2017,,,IEEE,IEEE Magazines
566,567,"GitHub, Technical Debt, Code Formatting, and More",J. C. Carver; J. Cabot; R. Capilla; H. Muccini,University of Alabama; Interdisciplinary Internet Institute; Rey Juan Carlos University of Madrid; University of L'Aquila,IEEE Software,28 Mar 2017,2017,34,2,105,107,"This issue's column reports on papers from the 19th International Conference on Model Driven Engineering Languages and Systems, the 2016 ACM SIGPLAN International Conference on Software Language Engineering, the 12th International ACM SIGSOFT Conference on the Quality of Software Architectures, and the 13th Working IEEE/IFIP Conference on Software Architecture. Topics discussed include GitHub and open source, technical debt in model-driven engineering, a universal code formatter, assuring architectural quality, and continuous architecting.",1937-4194,,10.1109/MS.2017.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888414,GitHub;open source;UML;technical debt;code smells;model-driven engineering;code formatting;machine learning;AQAF;Architecture Quality Assurance Framework;AADL;Architecture Analysis and Design Language;architectural quality;continuous architecting;CAFFEA;Continuous Architecture Framework for Embedded and Agile Software Development;software engineering;software development,,,,,,,,,28 Mar 2017,,,IEEE,IEEE Magazines
567,568,"Product Lines, Energy Conservation, Use Cases, Agile Development, and Infotainment",J. C. Carver; E. S. de Almeida; R. Capilla; L. L. Minku; H. Muccini; B. Penzenstadler,"University of Alabama; Federal University of Bahia; Rey Juan Carlos University of Madrid; University of Leicester; University of L'Aquila; California State University, Long Beach",IEEE Software,25 Apr 2016,2016,33,3,29,31,"This issue's column reports on the articles discussing different topics. Topics include software product lines, Android app, GUI energy consumption, use case changes, combining architecture with agile development, and car infotainment systems.",1937-4194,,10.1109/MS.2016.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458764,software product lines;software energy consumption;use cases;software architecture;agile development;infotainment;automotive software;software engineering;software development,,energy conservation;graphical user interfaces;green computing;mobile computing;software architecture;software product lines;software prototyping,software product lines;Android application;GUI energy consumption;graphical user interfaces;use case changes;software architecture;agile software development;car infotainment systems,,,,5.0,,25 Apr 2016,,,IEEE,IEEE Magazines
568,569,"Software Abundance in the Face of Economic Scarcity, Part 2",G. Booch,IBM,IEEE Software,16 Oct 2009,2009,26,6,15,16,"The paper is an editorial that discusses the economics aspect of software industry. The author states that we are in a period of global economic funk, by virtually every measure that we can take. The good news is that we've been here before over the years and we've always seemed to get by. Software is still the most fungible and liquid of resources, and its supply is limited only by human imagination and labor. For this reason, the author began to make the case that software-intensive systems are a necessary element in helping us operate, innovate, and even thrive in the face of lean economic times. There are many opportunities in IT for fueling business, ranging from issues of daily hygiene to opportunities for creating entirely new markets. Effective business strategies must involve some mixture of efficiency-based, innovation-based, and customer-intimacy-based efforts. Software development is an engineering activity. That means not reaching for a perfect solution, but rather evolving to a solution that optimally resolves the static and dynamic forces on that system. For software-intensive systems, these forces include the usual business ones (cost, schedule, and mission) but also development, environmental, operational, and legal/ethical/moral forces. The author also noted that the enterprise's architecture, is the collection of engineering decisions and artifacts that steer the fleet (the organization) through the forces acting upon it and guide it toward its mission. Architecture-as-an-artifact is a manifestation of technical intellectual property and thus serves as an artifact of control. The author concludes that software-intensive systems are an inescapable and necessary element in helping us operate, innovate, and even thrive in the face of lean economic times.",1937-4194,,10.1109/MS.2009.187,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287003,economics;software engineering;innovation;economic scarcity,Environmental economics;Fuel economy;Computer industry;Industrial economics;Humans;Programming;Costs;Job shop scheduling;Law;Legal factors,socio-economic effects;software architecture;software development management,software industry;software-intensive systems;IT business opportunities;software development;enterprise architecture;engineering decisions collection;economic scarcity;architecture-as-an-artifact manifestation;technical intellectual property,,,,,,16 Oct 2009,,,IEEE,IEEE Magazines
569,570,"Death, Taxes, & Scalability",L. Duboc; E. Letier; D. S. Rosenblum,University College London; University College London; University College London,IEEE Software,14 Jun 2010,2010,27,4,20,21,"The London Ambulance System and the online tax return system of Her Majesty's Revenue and Customs are two systems that have experienced significant problems of scalability. However, we've never seen a precise discussion of their scalability concerns. In this column we use those systems to illustrate how the scalability of software systems can be more precisely understood and characterized, and we describe recent research on goal-obstacle analysis that can help elaborate the scalability requirements of such systems, in an effort to mitigate scalability problems early in development.",1937-4194,,10.1109/MS.2010.97,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484110,KAOS;obstacles;requirements;scalability;software engineering,Finance;Scalability;Software systems,formal specification;formal verification;systems analysis,London Ambulance System;online tax return system;scalability;goal-obstacle analysis,,4.0,,6.0,,14 Jun 2010,,,IEEE,IEEE Magazines
570,571,Two-Layer Wrapping for COTS Software Integration: An Experience with Matlab,E. García-Roselló; J. G. Dacosta; M. J. Lado; A. J. Méndez; J. G. Perez-Schofield,University of Vigo; University of Vigo; University of Vigo; University of Vigo; University of Vigo,IEEE Software,10 Aug 2012,2012,29,4,76,82,"Although commercial-off-the-shelf (COTS) product integration presents clear advantages in a variety of engineering fields, several problems can arise in part due to their heterogeneous nature. Little research addresses the integration of particular COTS to specific domains. A University of Vigo project for reusable software development in the engineering domain adopted this approach. The underlying hypothesis was that making COTS integration easier would facilitate the development of domain-specific applications. The solution consists of a two-layer wrapping approach. The first layer captures the COTS domain model, facilitating integration of general-purpose functionality. A second layer provides better integration of more domain-specific functionality. Several real software development projects have used the proposed solution, and the results yielded notable effort savings, showing the approach's utility in reducing COTS integration efforts.",1937-4194,,10.1109/MS.2011.129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051413,software architectures;software engineering;COTS;reusable software,Computer languages;Mathematical model;Software architecture;Libraries;Programming;Software reliability;Software measurement,,,,,,15.0,,18 Oct 2011,,,IEEE,IEEE Magazines
571,572,"Leah Buley: Toward Collaborative, Pragmatic User-Experience Work",J. Patton,ThoughtWorks,IEEE Software,19 Jun 2009,2009,26,4,93,94,"In an interview, Leah Buley of Adaptive Path discusses using design principles and black-hat sessions to foster responsible, collaborative user-experience work.",1937-4194,,10.1109/MS.2009.96,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076467,user experience;software engineering;black-hat session;design principles;software design;user-centered design,Collaborative work;TV;Collaborative software;Testing;Privacy;Robustness;Home appliances;Product design;Writing,computational linguistics;groupware,collaborative user-experience work;pragmatic user-experience work,,,,,,19 Jun 2009,,,IEEE,IEEE Magazines
572,573,Darkitecture: The Reality Skirted by Architecture,B. Prasad,,IEEE Software,16 Jan 2017,2017,34,1,103,105,"Just as physicists infer dark matter's presence on the basis of its gravitational effects on visible matter, we can conceptualize a ""darkitecture"" that outlines visible software architectures.",1937-4194,,10.1109/MS.2017.7,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819405,software architect;darkitecture;shadow IT;software development;software engineering,Computer architecture;Pragmatics;Service-oriented architecture;Context modeling;Software architecture;Investment;Information technology,software architecture,darkitecture;visible software architectures,,,,1.0,,16 Jan 2017,,,IEEE,IEEE Magazines
573,574,Team Performance in Software Development: Research Results versus Agile Principles,T. Dingsøyr; T. E. Fægri; T. Dybå; B. Haugset; Y. Lindsjørn,SINTEF; SINTEF; SINTEF; SINTEF; University of Oslo,IEEE Software,23 Jun 2016,2016,33,4,106,110,"This article reviews scientific studies of factors influencing colocated development teams' performance and proposes five factors that strongly affect performance. In the process, it compares these propositions with the Agile Manifesto's development principles. The Web extra at https://extras.computer.org/extra/mso2016040106s1.pdf details the sources and research methods the authors employed.",1937-4194,,10.1109/MS.2016.100,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498535,software;development teams;agile;Agile Manifesto;Scrum;team coordination;goal orientation;team cohesion;shared mental models;team learning;software development;software engineering,Software development;Cognitive science;Teamwork;Scrum teams;Programming;Agile computing;Collaboration,software prototyping;team working,software development;shared mental model;Agile Manifesto development principles;team performance,,15.0,,17.0,,23 Jun 2016,,,IEEE,IEEE Magazines
574,575,The Architect's Journey,G. Booch,IBM,IEEE Software,25 Apr 2011,2011,28,3,10,11,"When we grow a software-intensive system, we start with something that is deeply technical, something that is constrained by the laws of physics and the realities of information theory. We then shape it into something that is as invisible as it can be. This is, curiously, the polar opposite of what theoretical physicists do: they observe the fierce complexity of the cosmos, labor to tease apart the threads by which the cosmos is cunningly woven, then try to explain the warp and woof as well as the very nature of the strings themselves in as visible and as simple a language as possible. In the case of software-intensive systems, we start with some very simple concepts - specifically, bits and the nature of information. We then apply various human artifacts - namely, our hard ware and our software languages - to make these bits and information manifest, then we bundle them up in these massive, dripping hairballs of scattered and tangled complexity, drop them into the world, and labor mightily to make them disappear in the interstitial spaces, hidden from view. The most interesting technology is technology that doesn't appear to be there at all.",1937-4194,,10.1109/MS.2011.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756290,architecture;software-intensive system;peopleware;software engineering,Computer architecture;Economics;Software architecture;Software development management;Technological innovation,software architecture,software-intensive system;information theory;software language;interstitial space,,1.0,,,,25 Apr 2011,,,IEEE,IEEE Magazines
575,576,Toward Architecture Knowledge Sustainability: Extending System Longevity,R. Capilla; E. Y. Nakagawa; U. Zdun; C. Carrillo,Rey Juan Carlos University of Madrid; University of São Paulo; University of Vienna; Polytechnic University of Madrid,IEEE Software,28 Mar 2017,2017,34,2,108,111,"Complex software systems often require continuous refactoring to ensure longevity in the face of changing requirements. Architects can exploit the concept of architecture knowledge sustainability to measure and increase their architectures' quality, longevity, and stability.",1937-4194,,10.1109/MS.2017.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888418,software architect;sustainability;stability;longevity;architecture knowledge;refactoring;design decisions;long-lived systems;software development;software engineering;architecture knowledge sustainability;architectural sustainability;software architecture,Computer architecture;Software measurement;Stability criteria;Software development;Unified modeling language;Complexity theory,software architecture;sustainable development,architecture knowledge sustainability;system longevity;complex software systems;continuous refactoring;architecture quality,,5.0,,10.0,,28 Mar 2017,,,IEEE,IEEE Magazines
576,577,Trust in Distributed Teams: Support through Continuous Coordination,B. Al-Ani; D. Redmiles,"University of California, Irvine; University of California, Irvine",IEEE Software,16 Oct 2009,2009,26,6,35,40,"In this article we report on our investigation of trust in distributed development teams and the role that software tools can play in supporting teams. Our investigation shows that the continuous coordination paradigm tools Palantir, Ariadne, World View, and Workspace Activity Viewer help distributed teams develop trust by sharing information across boundaries through visualizations and in other ways. Our analysis provides insights into the role existing tools can play in developing trust and how future tools can promote trust.",1937-4194,,10.1109/MS.2009.192,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287007,trust;distributed teams;collaboration;coordination;tools;software engineering,Software tools;Visualization,DP management;software tools,distributed development teams;continuous coordination paradigm tools;Palantir tool;Ariadne tool;World View tool;Workspace Activity Viewer tool;information sharing;team trust development,,10.0,,22.0,,16 Oct 2009,,,IEEE,IEEE Magazines
577,578,"Trust Me, I'm an Analyst",N. Maiden,City University London,IEEE Software,31 Dec 2009,2010,27,1,46,47,"We often need to remind ourselves that, in the end, requirements projects are really all about people. Whatever new processes, techniques and software tools we come up with, it's still us folks who have to provide, analyze, and validate requirements. Success in requirements projects depends heavily on the domain knowledge and skills of the people involved, and the effective collaboration between them. After all, few requirements projects succeed without effective problem solving, collaboration, and negotiation.So let's remind ourselves requirements projects are about people. About people who do the right thing for their own requirements projects.",1937-4194,,10.1109/MS.2010.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370762,requirements;requirements projects;trust;software;software engineering,Collaboration;Software tools;Problem-solving,project management;systems analysis,requirements project;software tool;requirements validation;problem solving;team collaboration;requirements analysis,,2.0,,,,31 Dec 2009,,,IEEE,IEEE Magazines
578,579,Once upon a Time,G. Booch,IBM,IEEE Software,28 Oct 2016,2016,33,6,8,10,"The story of computing is the story of humanity. Civilization is filled with storytelling, which helps us understand our past, reconcile our present, and be intentional of our future. Similarly, as developers, we are the storytellers, using our software and our hardware as our brush and our canvas. The Web Extra at https://youtu.be/S06HKTobvVM is an audio podcast of author Grady Booch reading his column.",1937-4194,,10.1109/MS.2016.141,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725030,storytelling; history of computing; development;software development;software engineering;creation myths;mythology;computer games,History;Software development,social aspects of automation,computing myths;humanity;computing story,,,,9.0,,28 Oct 2016,,,IEEE,IEEE Magazines
579,580,"Software Abundance in the Face of Economic Scarcity, Part 1",G. Booch,IBM,IEEE Software,25 Aug 2009,2009,26,5,12,13,"The paper discusses the abundance of software products in the face of the economic scarcity. The author states that in the face of economic scarcity, the traditional response is to retreat, shrink, slash, and try not to panic. But there's another, more creative reaction to economic scarcity: to attack. While the velocity of money may have greatly decelerated and while credit might still be a scarce resource, human imagination is not similarly constrained. Software is the most fungible and liquid of resources. The supply of software is limited only by human imagination and labor. Software has no mass, it's remarkably malleable and wonderfully versatile, and it never wears out. This is why it also argue that software intensive systems are an inescapable and necessary element in helping software people operate, innovate, and even thrive.Undeniably, software-intensive systems, even in these lean economic times, are the force behind a sea change in communication and connectivity and a force that continues to propel innovation. Innovation in times of abundance is relatively easy; even just staying alive in lean times is a struggle. The thing about abundance is that, well, abundance feels a whole lot better than scarcity.",1937-4194,,10.1109/MS.2009.139,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222786,economics;software engineering;innovation;economic scarcity,Videos;Humans;Wikipedia;Technological innovation;YouTube;Computer architecture;Earth;Government;Costs;Protection,innovation management;socio-economic effects;software packages,software products abundance;economic scarcity;software intensive systems;human innovation,,,,12.0,,25 Aug 2009,,,IEEE,IEEE Magazines
580,581,Software in MRI Scanners,L. Hofland; J. van der Linden,Philips Healthcare; Philips Healthcare,IEEE Software,14 Jun 2010,2010,27,4,87,89,"Software is key to commercial magnetic resonance imaging (MRI) scanners, the medical devices that make images of the living human body for clinical purposes.",1937-4194,,10.1109/MS.2010.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484114,medical imaging;MRI scanners;magnetic resonance imaging;software;software engineering;philips healthcare,Magnetic resonance imaging;Biomedical imaging;Humans,biomedical equipment;biomedical MRI;image scanners,MRI scanners;magnetic resonance imaging scanner;medical devices,,8.0,,2.0,,14 Jun 2010,,,IEEE,IEEE Magazines
581,582,Tiny Tools,G. J. Holzmann,Jet Propulsion Laboratory,IEEE Software,29 Dec 2015,2016,33,1,24,28,Gerard Holzmann offers simple tools for developers who don't use IDEs but prefer to write code using their own screen editor and who do everything else with command-line tools.,1937-4194,,10.1109/MS.2016.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368034,Cscope;shell programming;Bash;tokenizer;C code;IDEs;software engineering;software development,Switches;Standards;Context;Software reliability;Software;Computers,software reliability,software reliability;command-line tool;IDE;tiny tool,,2.0,,3.0,,29 Dec 2015,,,IEEE,IEEE Magazines
582,583,Mining Domain Knowledge [Requirements],J. Cleland-Huang,DePaul University,IEEE Software,23 Apr 2015,2015,32,3,16,19,"Basic data-mining skills can be useful for processing domain documents early during requirements engineering. An example from the electronic-healthcare-records domain shows how. The Web extra at http://youtu.be/tHvi3pHEP8c is an audio podcast in which author Jane Cleland-Huang provides an audio recording of the Requirements column, in which she discusses how basic data-mining skills can be useful for processing domain documents early during requirements engineering.",1937-4194,,10.1109/MS.2015.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093055,data mining;software requirements;domain knowledge;document search;Wordle;topic modeling;electronic healthcare records;software engineering;software development,Data mining;Requirements engineering;Computational modeling;Frequency-domain analysis;Drugs;Medical information processing,data mining;document handling,domain knowledge mining;data mining skills;domain document processing;requirements engineering,,10.0,,1.0,,23 Apr 2015,,,IEEE,IEEE Magazines
583,584,Making Program Refactoring Safer,G. Soares; R. Gheyi; D. Serey; T. Massoni,"Federal University of Campina Grande, Campina Grande; Federal University of Campina Grande, Brazil; Federal University of Campina Grande, Campina Grande; Federal University of Campina Grande, Campina Grande",IEEE Software,14 Jun 2010,2010,27,4,52,57,"Developers rely on compilation, test suites, and tools to preserve observable behavior during refactoring. However, most refactoring tools don't implement all the preconditions that guarantee refactoring correctness because formally identifying them is cost-prohibitive. Therefore, these tools could perform nonbehavior-preserving transformations. The authors present a tool for improving safety during refactoring that automatically generates a test suite suited for detecting behavioral changes. They used this tool to evaluate seven real case study refactorings (from 3 to 100 KLOC).",1937-4194,,10.1109/MS.2010.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5440166,refactoring;behavior preservation;unit testing;software engineering,Safety;Automatic testing,software maintenance,program refactoring;compilation;test suites;nonbehavior preserving transformations,,51.0,,14.0,,29 Mar 2010,,,IEEE,IEEE Magazines
584,585,Monitoring Software Quality Evolution for Defects,H. Zhang; S. Kim,"Tsinghua University, Beijing; Hong Kong University of Science and Technology, Hong Kong",IEEE Software,14 Jun 2010,2010,27,4,58,64,"Quality control charts, especially c-charts, can help monitor software quality evolution for defects over time. c-charts of the Eclipse and Gnome systems showed that for systems experiencing active maintenance and updates, quality evolution is complicated and dynamic. The authors identify six quality evolution patterns and describe their implications. Quality assurance teams can use c-charts and patterns to monitor quality evolution and prioritize their efforts.",1937-4194,,10.1109/MS.2010.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5453334,maintenance management;software quality;software quality assurance;quality evolution;statistical process control;software engineering,Monitoring;Software quality;Quality control;Quality assurance,quality assurance;software quality,software quality evolution monitoring;quality control charts;c-charts;quality assurance teams;quality evolution patterns;Eclipse;Gnome system,,18.0,,11.0,,22 Apr 2010,,,IEEE,IEEE Magazines
585,586,"What Time Is It, Eccles?",N. Maiden,,IEEE Software,23 Jun 2011,2011,28,4,84,85,"Requirements analysts need a new toolbox with both the right tools and the instructions to use them including agile development and user-centered design for techniques such as analysis of Web analytics, wire-framing, and user stories. We can also look to the creativity literature and take techniques such as constraint removal, storytelling, and other worlds.",1937-4194,,10.1109/MS.2011.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929526,software engineering;requirements;techniques;agile;creativity;meaning carriers,Software development management;Research and development;User centered design;Agile manufacturing,,,,,,1.0,,23 Jun 2011,,,IEEE,IEEE Magazines
586,587,"Learning from Failure, Part 1: Scoping and Requirements Woes",F. Buschmann,Siemens Corporate Technology,IEEE Software,16 Oct 2009,2009,26,6,68,69,"The paper is an editorial on software architecture. Software projects fail for the same reasons. The mistakes that can lead software projects to trouble before concrete architecture elaboration even begins include missing, wrong, or creeping system scope; and vague, unnecessary, or extreme nonfunctional requirements. These mistakes aren't the prime responsibility of architects, but architects are directly affected if they occur because without an appropriate system scope and correspondingly appropriate requirements, they can't define sustainable architectures. A system's scope defines its responsibilities, but also its boundaries. Failing to define a precise system scope can result in architectures that support the wrong functionality, too much functionality, too many functionality variations, too few functions, or poor quality. Architects should pay special attention to nonfunctional requirements that too often include vague or unnecessarily extreme specifications. Without precision, architects must guess which nonfunctional qualities are actually needed, and if they must guess, they'll likely guess wrong. An agile, incremental approach to software development define an initial system scope and set of requirements in a reasonable time and adjust this big picture step-wise until it has enough focus, substance, and clarity. Then, architects get concrete guidance for their work and can act rather than react when designing the system's architecture. Only then do architects receive a safety network that allows them to identify and correct design flaws in their own area of responsibility.",1937-4194,,10.1109/MS.2009.179,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287013,software architect;software architecture;software engineering;nonfunctional requirements;requirements engineering;system scope;functionality,Concrete;Computer architecture;Software architecture;Programming;Safety,software architecture;software development management,software architecture;system scope failure;nonfunctional requirements failure;software development incremental approach;software architects,,16.0,,7.0,,16 Oct 2009,,,IEEE,IEEE Magazines
587,588,Software in Automotive Systems,J. Mössinger,Robert Bosch,IEEE Software,25 Feb 2010,2010,27,2,92,94,We're happy to get on the road with the column. Be aware that you may be carrying 100 million lines of code with you the next time you take the car. Jiirgen Moessinger is vice president for automotive systems integration at Bosch and describes the challenges and opportunities that software brings to the automotive industry.,1937-4194,,10.1109/MS.2010.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420803,software engineering;standards;best practices;automotive systems,Software systems;Automotive engineering;Roads;Computer industry,automobile industry;production engineering computing,automotive industry;automotive systems,,21.0,,,,25 Feb 2010,,,IEEE,IEEE Magazines
588,589,Software Process Improvement in Very Small Organizations,X. Larrucea; R. V. O'Connor; R. Colomo-Palacios; C. Y. Laporte,Tecnalia; Dublin City University; Østfold University College; École de technologie supérieur,IEEE Software,26 Feb 2016,2016,33,2,85,89,"Software process improvement (SPI) offers obstacles and opportunities for very small entities (VSEs), which are organizations with 25 or fewer employees. To help with this, the International Organization for Standardization and the International Electrotechnical Commission jointly developed ISO/IEC 29110 as SPI guidelines for VSEs.",1937-4194,,10.1109/MS.2016.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420471,software process improvement;SPI;very small entities;VSEs;ISO/IEC 29110;experience factory;software engineering;software development,Software process improvement;IEC Standards;ISO Standards;Standards organizations;Business,IEC standards;ISO standards;organisational aspects;software process improvement,SPI guideline;ISO/IEC 29110;International Electrotechnical Commission;International Organization-for-Standardization;VSE;very small entity;SPI;software process improvement,,57.0,,11.0,,26 Feb 2016,,,IEEE,IEEE Magazines
589,590,Points of Truth,G. J. Holzmann,NASA/JPL,IEEE Software,30 Jun 2015,2015,32,4,18,21,"The SPOT (Single Point of Truth) principle says that developers should specify key pieces of information in one and only one place in their code. Unfortunately, they frequently violate this principle.",1937-4194,,10.1109/MS.2015.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140686,single point of truth;software engineering;software development,Software development;Software reliability;Standards,software reliability,SPOT principle;single point of truth principle,,11.0,,2.0,,30 Jun 2015,,,IEEE,IEEE Magazines
590,591,The Big Questions,G. Booch,IBM,IEEE Software,13 Jun 2014,2014,31,4,9,11,"Explores how technology shapes the person and the ideas behind our decisions. From developer to architect, from business analyst to user, there are a number of big questions whose answers shape the systems with which we engage. As individuals, we each play many roles in our lives and as such there are some even bigger questions that haunt us in our journey: questions that transcend any specific role, questions that can't be answered by technology. The Web extra at http://youtu.be/elirN-WSq1g is an audio podcast of author Grady Booch reading his On Computing column, in which he discusses the big questions whose answers shape the systems with which we engage.",1937-4194,,10.1109/MS.2014.96,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834680,software engineering;developer;architect;analyst;user;human,Computer science;Philosophical considerations;Social factors;Technology;Decision making;Human factors;Ethical aspects,,,,,,,,13 Jun 2014,,,IEEE,IEEE Magazines
591,592,Model-Based Testing,I. Schieferdecker,Fraunhofer Institute for Open Communication Systems,IEEE Software,22 Dec 2011,2012,29,1,14,18,"Model-based testing (MBT) strives to automatically and systematically generate test cases. In this column, Ina Schieferdecker introduces MBT technologies and methods.",1937-4194,,10.1109/MS.2012.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111361,model-based testing;software;engineering;technology;tools;methods Fokus!MBT;MBT,Software testing;Software design;Modeling;Testing;Model-based testing,program testing,model-based testing;MBT,,37.0,,6.0,,22 Dec 2011,,,IEEE,IEEE Magazines
592,593,Green Software: Greening What and How Much?,K. Sierszecki; T. Mikkonen; M. Steffens; T. Fogdal; J. Savolainen,Danfoss Power Electronics; Tampere University of Technology; Danfoss Power Electronics; Danfoss Power Electronics; Danfoss Power Electronics,IEEE Software,21 Apr 2014,2014,31,3,64,68,"In applications in which embedded devices cooperate with ICT (information and communication technology) systems to make industrial processes more efficient, reduce waste or raw materials, and save the environment, the concept of green software becomes increasingly complex. To deal with this issue, the green-software community has introduced the concepts of greening ICT or greening through ICT.",1937-4194,,10.1109/MS.2014.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802991,green software;green systems;variable-speed drives;embedded control systems;greening information and communication technology;greening ICT;greening through information and communication technology;greening through ICT;software engineering,Software;Green products;Power demand;Energy consumption;Power electronics;Electric motors;Torque,green computing;power aware computing,embedded devices;ICT;information and communication technology systems;industrial processes;waste reduction;raw materials;green-software community,,5.0,,6.0,,21 Apr 2014,,,IEEE,IEEE Magazines
593,594,Developing Software for a Mobile Service in India,B. Seetharam,Vodafone Solutions,IEEE Software,10 Aug 2012,2012,29,4,34,39,"There is a demand in India for venues for purchasing music for mobile phones via means other than the Internet. Although two-thirds of mobile users in India are already listening to music on their mobile devices, often illegally or through unaffiliated vendors, there are more than 700 million mobile phone users that music sales cannot reach through the Internet. This article presents ideas for reaching such users.",1937-4194,,10.1109/MS.2012.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6180162,mobile Internet;offline Internet access;handheld devices;software engineering,Supply and demand;India;Mobile communication;Supply and demand;Smart phones;Handheld devices;Music;Computer applications,,,,2.0,,10.0,,10 Apr 2012,,,IEEE,IEEE Magazines
594,595,Safety Stories in Agile Development,J. Cleland-Huang,University of Notre Dame,IEEE Software,11 Jul 2017,2017,34,4,16,19,"Safety stories specify safety requirements, using the EARS (Easy Requirements Specification) format. Software practitioners can use them in agile projects at lower levels of safety criticality to deal effectively with safety concerns.",1937-4194,,10.1109/MS.2017.108,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974701,safety stories;safety-critical software;safety assurance cases;EARS;Easy Requirements Specification;software requirements;agile software development;software development;software engineering,Hazards;Drones;Software systems;Batteries;Safety,formal specification;safety-critical software;software prototyping,agile development;EARS;easy requirements specification;safety criticality,,4.0,,6.0,,11 Jul 2017,,,IEEE,IEEE Magazines
595,596,"Gardening Your Architecture, Part 2: Reengineering and Rewriting",F. Buschmann,Siemens Corporate Technology,IEEE Software,18 Aug 2011,2011,28,5,21,23,"Reengineering and rewriting are two common approaches for improving system quality-in addition to refactoring, which the last installment of this column explored. Reengineering is a systematic approach to evolve existing software to exhibit new behavior, features, and operational quality. Refactoring and reengineering aren't the same, and they're also different from rewriting-the most radical change-which involves wiping the slate clean and starting over.",1937-4194,,10.1109/MS.2011.97,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984792,refactoring;reengineering;rewriting;functional quality;developmental quality;operational quality;software;software engineering,Computer architecture;Software measurement;Software architecture;Business process re-engineering,software architecture;software maintenance;software quality;systems re-engineering,reengineering;rewriting;system quality improvement;operational quality,,2.0,,3.0,,18 Aug 2011,,,IEEE,IEEE Magazines
596,597,Robotic Testing of Mobile Apps for Truly Black-Box Automation,K. Mao; M. Harman; Y. Jia,University College London; University College London; University College London,IEEE Software,28 Mar 2017,2017,34,2,11,16,"Robots are widely used for many repetitive tasks. Why not software testing? Robotic testing could give testers a new form of testing that's inherently more black-box than anything witnessed previously. Toward that end, researchers developed Axiz, a robotic-test generator for mobile devices.",1937-4194,,10.1109/MS.2017.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888396,robotic testing;automated software testing;software testing;mobile devices;mobile apps;black-box testing;Axiz;Android;Google Calculator;software development;software engineering,Robots;Software testing;Mobile communication;Robot sensing systems;Computer applications,automatic testing;control engineering computing;mobile computing;program testing;robots,robotic testing;mobile application;truly black-box automation;software testing;robotic-test generator;simulation-based test automation;Axiz;Google Calculator application,,17.0,,15.0,,28 Mar 2017,,,IEEE,IEEE Magazines
597,598,A Paradigm Shift for the CAPTCHA Race: Adding Uncertainty to the Process,S. Kwon; S. Cha,Korea University; Korea University,IEEE Software,28 Oct 2016,2016,33,6,80,85,"CAPTCHA (Completely Automated Public Turing Test to Tell Computers and Humans Apart) challenges are often correctly solved by software but have increasingly become too difficult for humans to pass. If the correct response to a challenge remains the same, robots can gather invaluable information from accidental successes and will easily defeat future challenges through heuristic learning. Introducing uncertainty to the challenges will fundamentally change the rules of image-based CAPTCHA systems. This new approach temporarily excludes some images from a challenge's results, assigning them a neutral role. However, future challenges might include these images. So, successful responses might differ between challenges even though the challenges use the same images, thereby eliminating the threat of heuristic attacks. To further reduce the chance of robots accidently passing a challenge, this approach analyzes the decisions made on neutral images. If the outcome would have been different had the challenge results included the neutral images, those images are added to a ""trap"" database and included in future challenges. In experiments, this approach almost always defeated powerful robots (for example, robots using heuristic learning or a search engine), but humans could still easily pass the challenges.",1937-4194,,10.1109/MS.2016.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412614,automated Turing test;CAPTCHA;heuristic attack;software engineering;software development,Robots;CAPTCHAs;Databases;Search engines;Heuristic algorithms;Logic gates,control engineering computing;cryptography;image processing;learning (artificial intelligence);robots;search engines,paradigm shift;completely automated public turing test to tell computers and humans apart;heuristic learning;uncertainty process;image-based CAPTCHA systems;heuristic attacks;neutral images;search engine,,3.0,,7.0,,18 Feb 2016,,,IEEE,IEEE Magazines
598,599,Learning Contextual-Variability Models,P. Temple; M. Acher; J. Jézéquel; O. Barais,University of Rennes 1 and IRISA; University of Rennes 1 and IRISA; University of Rennes 1 and IRISA; University of Rennes 1 and IRISA,IEEE Software,13 Nov 2017,2017,34,6,64,70,This approach described in this article uses machine learning to execute and observe a sample of software configurations within a sample of contexts. It then learns what factors of each context will likely discard or activate some of the software's features.,1937-4194,,10.1109/MS.2017.4121211,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106868,contextual variability;machine learning;software engineering;software development;contextual-variability modeling,Machine learning;Context modeling;Noise level;Computational modeling;Numerical models;Feature extraction;Cameras,learning (artificial intelligence),software configurations;machine learning;contextual-variability models,,,,7.0,,13 Nov 2017,,,IEEE,IEEE Magazines
599,600,Software Architecture in a Changing World,E. Woods,Endava,IEEE Software,28 Oct 2016,2016,33,6,94,97,"As software systems have evolved, so has software architecture, with practices growing to meet each era's new challenges. The next phase of evolution--intelligent connected systems--promises to be an exciting time for software architects.",1937-4194,,10.1109/MS.2016.149,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725217,history of computing;software architect;software engineering;software development;Internet of Things;cloud;artificial intelligence,Computer architecture;Software architecture;Internet;Heuristic algorithms;Market research;Software systems,software architecture,software architecture;intelligent connected systems,,13.0,,13.0,,28 Oct 2016,,,IEEE,IEEE Magazines
600,601,When Software Impacts the Economy and Environment,E. S. de Moura; M. R. Herrera; L. Santos; T. Conte; M. van Genuchten; L. Hatton,Federal University of Amazonas; Neemu; Neemu; Federal University of Amazonas; NA; NA,IEEE Software,28 Oct 2016,2016,33,6,23,26,"When customers visit a Brazilian e-commerce site and search for a product, they're likely using software developed by Neemu, a start-up created in Manaus, a city in the heart of the Amazon rainforest. Nowadays, millions of people throughout Brazil use this software, which demonstrates alternative economic development in Amazonia that has low impact on the environment.",1937-4194,,10.1109/MS.2016.135,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725221,Neemu;Brazil;Brazilian software industry;e-commerce;search software;search algorithms;faceted search;Linx;Choardics;autocompletion;software development;software engineering,Software development;Web search;Electronic commerce;Algorithm design and analysis;Search problems;Navigation;Query processing,electronic commerce;social aspects of automation;Web sites,Brazilian e-commerce site;Amazon rainforest;economic development,,,,4.0,,28 Oct 2016,,,IEEE,IEEE Magazines
601,602,Where Are We? Handling Context,N. Maiden,City University London,IEEE Software,25 Aug 2009,2009,26,5,75,76,"These requirements were often enough for the architects to design the application. But now, technological advances mean that such requirement statements are just not enough. Mobile devices change everything. Suddenly a simple system requirement on a mobile application to support navigation, such as the application shall display a local street map at all times is rendered ambiguous and incomplete by the mobility of the device running the application.",1937-4194,,10.1109/MS.2009.146,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222798,Requirements specifications;software requirements;software engineering,Displays;Computational efficiency;Printers;Temperature;Noise level;Availability;Computer networks;Vehicles;Cities and towns;Character generation,formal specification;mobile computing,context handling;mobile device;system requirement;requirements specification,,,,5.0,,25 Aug 2009,,,IEEE,IEEE Magazines
602,603,Accessible Software Verification with Dafny,K. R. M. Leino,Microsoft Research,IEEE Software,13 Nov 2017,2017,34,6,94,97,"Formal software verification includes specifications, tools, and interactivity with the developer. By combining these key components into a programming language and a familiar programming environment with high automation, Dafny makes verification more easily accessible to programmers and students.",1937-4194,,10.1109/MS.2017.4121212,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106874,software verification;Dafny;IDE;imperative procedures;lemma proofs;software engineering;software development;Reliable Code,Formal verification;Software reliability;Software development;Encoding;Cognition,formal specification;program verification;programming environments;programming languages;software tools,software verification;Dafny;formal specifications;software tools;interactivity;programming language;programming environment,,1.0,,10.0,,13 Nov 2017,,,IEEE,IEEE Magazines
603,604,Implementing Functional Safety,C. Ebert,Vector Consulting Services,IEEE Software,21 Aug 2015,2015,32,5,84,89,"For software-related companies to deliver safe products and to cope with emerging product liability risks, significant improvements to technology and processes are necessary. This column presents industry experiences in adapting product development to conform to safety standards.",1937-4194,,10.1109/MS.2015.126,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217771,product safety;product liability;software engineering;functional safety;ISO standards;safety-critical systems;safety standards,Safety;Software;ISO Standards;Industries;Vehicles;Hardware,DP industry;product development;risk management;safety;software standards,functional safety implementation;software-related companies;product safety;product liability risk;product development;safety standards,,4.0,,4.0,,21 Aug 2015,,,IEEE,IEEE Magazines
604,605,Dead Programs,G. J. Holzmann,Nimble Research,IEEE Software,11 Jul 2017,2017,34,4,89,91,"“Dead programmes” were programs stored in write-only memory. To protect program code, PTERA let users block write access to parts of the drum, using a small plugboard. The term “dead” came back also in references to the plugboard itself as providing “dead registers” that the program couldn't modify.",1937-4194,,10.1109/MS.2017.107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974705,function calls;call stack;computer science history;EDVAC;Willem van der Poel;PTERA;software development;software engineering;computer science pioneers,Computers;Algorithms;Computer science;Reliability engineering;Data structures;History,program diagnostics,dead programs;write-only memory,,,,10.0,,11 Jul 2017,,,IEEE,IEEE Magazines
605,606,A tale of three programs,G. J. Holzmann,Nimble Research,IEEE Software,15 May 2017,2017,34,3,23,26,"A look at the generation of prime numbers offers a cautionary tale about the perils of premature optimization. We can code this in any reasonable programming language, and in quite a few unreasonable ones as well. It can be fun to express the algorithm in Python, C, C++, Scala, or Go, or even in scripting languages such as Tcl or Awk. And, yes, I confess that I've tried most of these, including Awk. Each language offers different features that can simplify the job or make it more interesting. For our current purpose, it'll suffice to stick to just plain old C.In a first attempt, we might come up with the version in Figure 1, which assumes that we provide the value of N in some other way-for example, with a macro directive to the C compiler.",1937-4194,,10.1109/MS.2017.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927921,prime numbers;recursion;Sieve of Eratosthenes;software development;software engineering;programming;Robert Morris Sr.,Mathematics;Encoding,C language;program compilers,programming language;scripting languages;C language;C compiler,,,,1.0,,15 May 2017,,,IEEE,IEEE Magazines
606,607,Pattern-Based Architecture Reviews,N. Harrison; P. Avgeriou,Utah Valley University; University of Groningen,IEEE Software,20 Oct 2011,2011,28,6,66,71,"Software architecture reviews are effective in identifying potential problems in architectures, however, are expensive, time-consuming, and generally rely on extensive architecture documentation. An architecture review that accommodates projects with very short development cycles, minimal documentation, or frequently changing requirements could be useful if it identifies important architectural issues. We developed a useful, inexpensive architecture review method that uses the architecture patterns in a system to identify important issues in the achievement of quality attributes.",1937-4194,,10.1109/MS.2010.156,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661759,Software Architecture;Patterns;Software Engineering Process;Review and Evaluation,Computer architecture;Pattern recognition;Software architecture;Software development;Product life cycle management,software architecture,pattern-based architecture reviews;software architecture review method;quality attributes achievement,,16.0,,14.0,,10 Dec 2010,,,IEEE,IEEE Magazines
607,608,Design for Test,R. J. Wirfs-Brock,Wirfs-Brock Associates,IEEE Software,25 Aug 2009,2009,26,5,92,93,"As developers, we're expected to turn out implementations proven by tests that we or others have written. Doing otherwise is considered unprofessional. But does code that's designed to be testable differ fundamentally from code that isn't? What does it mean to design for test? Advocates of test-driven development (TDD) write tests before implementing any other code. They take to heart Tom Peters' credo, ""Test fast, fail fast, adjust fast."" Testing guides their design as they implement in short, rapid-fire ""write test code - fail the test - write enough code to pass - then pass the test"" cycles. Regardless of whether you adhere to TDD design rhythms, writing unit tests forces you to articulate pesky edge cases and clean up your design.",1937-4194,,10.1109/MS.2009.125,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222803,software engineering;software design;unit tests;debugging;test-driven design,Software testing;System testing;Writing;Collaboration;Wiring;Assembly;Software performance;Heart;Rhythm;Feathers,program testing,design for test;program testing;test-driven development,,1.0,,,,25 Aug 2009,,,IEEE,IEEE Magazines
608,609,Healthy Routes in the Smart City: A Context-Aware Mobile Recommender,F. Casino; C. Patsakis; E. Batista; F. Borràs; A. Martínez-Balleste,Universitat Rovira i Virgili; University of Piraeus; Universitat Rovira i Virgili; Universitat Rovira i Virgili; Universitat Rovira i Virgili,IEEE Software,13 Nov 2017,2017,34,6,42,47,A context-aware recommender system offers personalized recommendations of exercise routes to people according to their medical condition and real-time information from the smart city. Experiments with a simulated dataset and real data verified the system's usefulness.,1937-4194,,10.1109/MS.2017.4121209,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106878,smart health;mobile health;recommender systems;collaborative filtering;context-aware systems;software engineering;software development;context-aware and smart healthcare,Context awareness;Medical services;Real-time systems;Sensors;Smart cities;Recommender systems;Mobile communication,medical information systems;recommender systems;smart cities;ubiquitous computing,smart city;context-aware recommender system;personalized recommendations;exercise routes;medical condition;real-time information;healthy routes;simulated dataset;system usefulness,,5.0,,14.0,,13 Nov 2017,,,IEEE,IEEE Magazines
609,610,Point/Counterpoint,G. D. Everett; B. Meyer,American Software Testing Qualifications Board; ETH Zurich,IEEE Software,19 Jun 2009,2009,26,4,62,65,Bertrand Meyer recently proposed seven principles of software testing. Other sets of principles embraced by testing professionals worldwide suggest that Meyer's list can be improved. One such set is the International Software Testing Qualifications Board Certified Tester Foundation Level Syllabus.,1937-4194,,10.1109/MS.2009.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076460,software testing;International Software Testing Qualifications Board;static testing;dynamic testing;software engineering,Software testing;Automatic testing;Qualifications;Terminology;Vehicle crash testing;Psychology;Quality assurance;Process planning;System testing;Condition monitoring,program testing,software testing principle;international software testing qualifications board;certified tester foundation level syllabus,,1.0,,3.0,,19 Jun 2009,,,IEEE,IEEE Magazines
610,611,Code Clarity,G. J. Holzmann,NASA/JPL,IEEE Software,26 Feb 2016,2016,33,2,22,25,"Naming conventions affect the readability of your code and the ease with which you can find your way around when you're reviewing that code. Naming conventions aren't meant to help the compiler. A compiler has no trouble distinguishing names, no matter how long, short, or obscure they are. But to us humans, they can matter a great deal.",1937-4194,,10.1109/MS.2016.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420491,C language;Linux;function names;identifier names;programming;software development;software engineering,Linux;Standards;Market research;Encoding;White spaces;Software reliability,program compilers;Unix,Unix code clarity;code readability;compiler,,3.0,,1.0,,26 Feb 2016,,,IEEE,IEEE Magazines
611,612,Functional Size Estimation Technologies for Software Maintenance,C. Ebert; H. Soubra,Vector Consulting Services; ESTACA--Engineering School,IEEE Software,7 Nov 2014,2014,31,6,24,29,"Estimating functional software size is the key input for building software models. Unlike direct effort estimates, software size estimation gives a measure of the software product itself and can be used to build objective estimation models for predicting project effort and duration, estimating defects for quality and service cost predictions, and obtaining software development productivity ratios. Although maintenance dominates software projects, the underlying technologies for estimation have been rather poorly described to date. Here, the authors examine estimation technologies based on the COSMIC (Common Software Measurement International Consortium) method as it's applied to maintenance projects.",1937-4194,,10.1109/MS.2014.138,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949529,benchmark;metric;standards;measurement;software engineering,Software reliability;Estimation;Size measurement;Software measurement;Maintenance engineering;Productivity;Project management,project management;software cost estimation;software development management;software maintenance;software quality,software maintenance;functional software size estimation technologies;software models;effort estimates;software product measurement;objective estimation models;project effort;project duration;defects estimation;quality;service cost predictions;software development productivity ratios;software projects;COSMIC;Common Software Measurement International Consortium;maintenance projects,,6.0,,6.0,,7 Nov 2014,,,IEEE,IEEE Magazines
612,613,How Software Is Changing the Automotive Landscape,H. Aerts; H. Schaminée,TomTom Automotive; NA,IEEE Software,13 Nov 2017,2017,34,6,7,12,"In the Impact department article in the July/August 2011 IEEE Software, Hans Aerts and Han Schaminée described how TomTom was a volume leader in consumer navigation systems and how TomTom applied that volume leadership when it entered the automotive market. Here, Aerts and Schaminée present what has occurred over the past six years and predict what will happen in the automotive industry.",1937-4194,,10.1109/MS.2017.4121219,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106884,automotive software;navigation software;TomTom;static analysis;software development productivity;agile software development;connectivity;software development;software engineering;Impact,Navigation;Software development;Automotive engineering;Companies,automobile industry;traffic engineering computing,automotive industry;automotive market;volume leadership;consumer navigation systems;TomTom;IEEE Software;automotive landscape,,1.0,,3.0,,13 Nov 2017,,,IEEE,IEEE Magazines
613,614,"""The Golden Age of Software Architecture"" Revisited",P. Clements; M. Shaw,Carnegie Mellon University; Carnegie Mellon University,IEEE Software,19 Jun 2009,2009,26,4,70,72,"In ""The Golden Age of Software Architecture"" Paul Clements and Mary Shaw reviewed the emergence of software architecture as the principled understanding of the large-scale structures of software systems. Here they reflect on progress since that article, updating the state of practice and reassessing some of the opportunities.",1937-4194,,10.1109/MS.2009.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076462,software architecture;software design;software development;software system;system organization;history of software engineering;technology maturation,Software architecture;Computer architecture;Service oriented architecture;Object oriented programming;Algorithms;Certification;Engineering profession;Documentation;Employee welfare;Application software,software architecture,software architecture;large-scale structure;software system,,23.0,,12.0,,19 Jun 2009,,,IEEE,IEEE Magazines
614,615,Why They Just Don't Get It: Communicating about Architecture with Business Stakeholders,J. Schulenklopper; E. Rommes,Xebia; M&I/Partners,IEEE Software,25 Apr 2016,2016,33,3,13,19,"Following certain best practices for visual communication can help bridge the gap between IT architects and business stakeholders. These practices stem from disciplines such as psychology, graphic design, communication science, and cartooning. They're intended to aid all architecture stakeholders in understanding, analysis, and discussion.",1937-4194,,10.1109/MS.2016.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458757,software architecture;software development;software engineering;collaboration;IT;IT architecture;business stakeholders;effective communication;visualization techniques;visual communication,Visualization;Stakeholders;Image color analysis;Computer architecture;Psychology;Software architecture;Information technology,software architecture,software architecture;business stakeholders;best practices;visual communication,,6.0,,2.0,,25 Apr 2016,,,IEEE,IEEE Magazines
615,616,"Choice of Software Development Methodologies: Do Organizational, Project, and Team Characteristics Matter?",L. R. Vijayasarathy; C. W. Butler,Colorado State University; Colorado State University,IEEE Software,24 Aug 2016,2016,33,5,86,94,"Organizations can choose from software development methodologies ranging from traditional to agile approaches. Researchers surveyed project managers and other team members about their choice of methodologies. The results indicate that although agile methodologies such as Agile Unified Process and Scrum are more prevalent than 10 years ago, traditional methodologies, including the waterfall model, are still popular. Organizations are also taking a hybrid approach, using multiple methodologies on projects. Furthermore, their choice of methodologies is associated with certain organizational, project, and team characteristics.",1937-4194,,10.1109/MS.2015.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006383,software development methodologies;agile methodologies;traditional methodologies;waterfall model;hybrid software development;project characteristics;team characteristics;organizational characteristics;software development;software engineering,Software development;Industries;Organizations;Information systems;Agile software development,project management;software development management;software prototyping;team working,software development methodologies;organizational characteristics;project characteristics;team characteristics;project managers;team members;agile methodologies;agile unified process;Scrum;waterfall model,,48.0,,7.0,,12 Jan 2015,,,IEEE,IEEE Magazines
616,617,Business Roles in the Emerging Open-Data Ecosystem,J. Lindman; T. Kinnari; M. Rossi,Hanken School of Economics; Aalto University School of Business; Aalto University School of Business,IEEE Software,24 Aug 2016,2016,33,5,54,59,"Software specialists know the merits of information visualizations, mashups, and other types of open-data enrichments that serve customers' needs. Commercial services based on these enrichments hold great potential as new businesses. A proposed model categorizes the roles of businesses in enriching open data. This model could help entrepreneurs looking for business opportunities and professionals in companies with underused data resources.",1937-4194,,10.1109/MS.2015.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006350,data;databases;business computer applications;software development;software engineering,Computer applications;Data models;Software development;Data mining;Data visualization;Mobile communication,business data processing;data handling,business role;open-data ecosystem;information visualization;software specialists;customer needs;data resources,,12.0,,14.0,,12 Jan 2015,,,IEEE,IEEE Magazines
617,618,Dynamically Adaptable Software Is All about Modeling Contextual Variability and Avoiding Failures,I. de Sousa Santos; M. L. de Jesus Souza; M. L. Luciano Carvalho; T. Alves Oliveira; E. S. de Almeida; R. M. de Castro Andrade,Federal University of Ceará; Federal University of Bahia; Federal University of Bahia; Federal University of Ceará; Federal University of Bahia; Federal University of Ceará,IEEE Software,13 Nov 2017,2017,34,6,72,77,eCFM is an extension of context-aware feature modeling (CFM) that improves contextual variability's expressiveness. eCFM combined with model checking provides a systematic way to model dynamically adaptable software and avoid failures in it.,1937-4194,,10.1109/MS.2017.4121205,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106890,dynamically adaptable software;contextual-variability modeling;dynamic variability;design faults;model checking;context-aware feature modeling;CFM;extended context-aware feature modeling;eCFM;software engineering;software development,Adaptation models;Context modeling;Model checking;Analytical models;Computational modeling;Runtime,failure analysis;formal verification;software reliability;ubiquitous computing,model checking;contextual variability expressiveness;context-aware feature modeling;eCFM;failure avoidance;contextual variability modelling,,,,14.0,,13 Nov 2017,,,IEEE,IEEE Magazines
618,619,My Autobiography,G. Booch,IBM,IEEE Software,21 Aug 2015,2015,32,5,13,15,"The story of computing is the story of humanity. This is a story of ambition, invention, creativity, vision, avarice, and serendipity, powered by a refusal to accept the limits of our bodies and minds. The Web extra at http://youtu.be/j3RI3dkPCvY is an audio podcast of this column.",1937-4194,,10.1109/MS.2015.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217779,software engineering;computing;history;future,Business;History;Computers;Technology;Computational modeling;Programming;Computer applications,humanities,autobiography;humanity;ambition;invention;creativity;vision;avarice;serendipity,,,,,,21 Aug 2015,,,IEEE,IEEE Magazines
619,620,Code Craft,G. J. Holzmann,Nimble Research,IEEE Software,28 Mar 2017,2017,34,2,18,21,"Errors in safety-critical software can have disastrous consequences. However, tools exist that developers can use to thoroughly analyze software subsystems for critical safety properties.",1937-4194,,10.1109/MS.2017.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888377,software engineering;Spin;Therac-25;hardware interlocks;race conditions;data corruption;software development,Safety;Software testing;Error analysis;Integrated circuit modeling;Software reliability;Analytical models,safety-critical software,software developers;software errors;critical safety properties;software subsystems;disastrous consequences;safety-critical software;code craft,,,,3.0,,28 Mar 2017,,,IEEE,IEEE Magazines
620,621,No Free Lunch for Software after All,A. Rutkowski; M. van Genuchten; L. Hatton,Tilburg University; VitalHealth Software; Oakwood Computing Associates,IEEE Software,22 Sep 2017,2017,34,5,13,15,Software's lack of reproduction costs provides benefits to not just legitimate developers but also people who want to use software for criminal purposes. The software community must address this issue or risk disenfranchising the users on whom the software industry depends.,1937-4194,,10.1109/MS.2017.3571570,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048627,software security;General Data Protection Regulation;GDPR;software development;software engineering,Software development;Computer bugs;Law;Computer crime,computer crime;DP industry;DP management;software cost estimation,software cost reproduction;criminal purposes;software community;risk disenfranchising;software industry,,1.0,,13.0,,22 Sep 2017,,,IEEE,IEEE Magazines
621,622,10 MLOC in Your Office Copier,Y. Tsuchitoi; H. Sugiura,NA; NA,IEEE Software,20 Oct 2011,2011,28,6,93,95,"Amid the obvious volume of digital copiers and multifunction printers, the system size is in the millions of lines of code with functionality creep into several overlapping areas-a theme of many modern systems.",1937-4194,,10.1109/MS.2011.133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6055665,multifunction printer;mfp;model-driven development;mdd;unified modeling language;uml;highly accelerated and yield software testing;hayst;software;engineering;development,Digital images;Printers;Digital printing,photocopying;systems software,office copier;digital copiers;multifunction printers,,4.0,,1.0,,20 Oct 2011,,,IEEE,IEEE Magazines
622,623,"Five Considerations for Software Architecture, Part 2",F. Buschmann; K. Henney,Siemens Corporate Technology; consultant,IEEE Software,14 Jun 2010,2010,27,4,12,14,"What are the top five properties that make a software design elegant? In this column we follow on from the previous column, exploring the remaining two properties: symmetry and emergence. Symmetry offers a form of simplification through regularity. Emergence allows complex behaviors to be governed by simple rules.",1937-4194,,10.1109/MS.2010.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484107,architecture;symmetry;emergence;software;software engineering,Software architecture;Software design,software architecture;symmetry,software architecture;software design;symmetry;emergence,,6.0,,4.0,,14 Jun 2010,,,IEEE,IEEE Magazines
623,624,Component Stacks for Enterprise Applications,P. Louridas,Athens University of Economics and Business,IEEE Software,26 Feb 2016,2016,33,2,93,98,"Until relatively recently, the tools used to develop Web applications followed a well-established architecture called the LAMP stack. Recently, the MEAN stack has taken the Web developer world by storm and is replacing LAMP.",1937-4194,,10.1109/MS.2016.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420497,MEAN;LAMP;Linux;Apache;MySQL;PHP;JavaScript;MongoDB;NoSQL;SQL;Express;Jode.js;AngularJS;relational databases;software development;software engineering,Servers;Databases;HTML;Browsers;Programming;Software;Linux,business data processing,component stacks;enterprise applications;Web applications;LAMP stack;MEAN stack,,6.0,,1.0,,26 Feb 2016,,,IEEE,IEEE Magazines
624,625,Harnessing the Power of Architectural Design Principles,E. Woods,Endava,IEEE Software,23 Jun 2016,2016,33,4,15,17,Architecture principles epitomize architecture's function: to clearly define the necessary constraints on a system's design without prescriptively defining all the design details. A good set of principles can provide context and justification for design decisions and can foster team collaboration and communication.,1937-4194,,10.1109/MS.2016.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498534,software architecture;design;project management;software development;software engineering,Computer architecture;Standards;Context modeling;Software development,architecture;groupware;team working,architectural design principles;architecture function;system design;team collaboration;team communication,,1.0,,3.0,,23 Jun 2016,,,IEEE,IEEE Magazines
625,626,An Architecture-Driven Modernization Tool for Calculating Metrics,J. Canovas; J. G. Molina,"Universidad de Murcia, Murcia; Universidad de Murcia , Murcia",IEEE Software,14 Jun 2010,2010,27,4,37,43,"Model-driven software development (MDD) is gaining increasing acceptance, mainly because it can raise the level of abstraction and automation in software construction. MDD techniques (see the sidebar ""MDD Basic Concepts""), such as metamodeling and model transformation, not only apply to the creation of new software systems but also can be used to evolve existing systems. These techniques can help reduce software evolution costs by automating many basic activities in software change processes, such as representing source code at a higher level of abstraction, providing information to analyze the impact of the changes, or automatically generating software artifacts of the evolved system. Several experiences of applying MDD in platform migration scenarios have recently been published,1'2 but they define ad hoc metamodels that hinder interoperability.",1937-4194,,10.1109/MS.2010.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5440163,domain-specific architectures;process implementation and change;specialized application languages;software engineering;model-driven development,Programming;Automation;Metamodeling;Software systems;Costs;Information analysis,software architecture,architecture driven modernization tool;metrics calculation;model driven software development;MDD;software construction;MDD basic concepts;model transformation;software artifacts;ad hoc metamodels,,26.0,,5.0,,29 Mar 2010,,,IEEE,IEEE Magazines
626,627,The Evolution of Flight Management Systems,D. Avery,Honeywell,IEEE Software,20 Dec 2010,2011,28,1,11,13,Flight management systems (FMSs) have become an essential component of almost every aircraft's cockpit. The FMS is the pilot's primary interface for flight planning operations on the airplane and contains a worldwide aeronautical navigation database for controlled flight into any airport. It optimizes routing to save fuel and time and increases safety by providing a flight plan display and airplane control without the need for costly ground-based infrastructure.,1937-4194,,10.1109/MS.2011.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672514,flight management system;Electronic Flight Instrument System;Honeywell;software failure;software engineering;communications,Aircraft;Safety;Certification;FAA;Trajectory;Aerospace control,aerospace computing;aircraft control;database management systems,flight management systems;FMS;aircraft cockpit;flight planning operations;aeronautical navigation database;flight plan display;airplane control,,10.0,,,,20 Dec 2010,,,IEEE,IEEE Magazines
627,628,Operational: The Forgotten Architectural View,E. Woods,Endava,IEEE Software,25 Apr 2016,2016,33,3,20,23,"Most software architecture books focus on building new systems. However, successful systems spend much more time running in their production environment than being initially developed. That's why the DevOps movement's recent emergence is so heartening. It emphasizes development and operations staff working together as early as possible-sharing tools, processes, and practices to smooth the path to production. DevOps requires embracing new, often unfamiliar technologies and ideas. Architectural thinking and design can help clarify who the stakeholders are, what concerns they have, and how those concerns are being met.",1937-4194,,10.1109/MS.2016.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458767,software architecture;operational viewpoint;production;project management;DevOps;software development;software engineering,Project management;Software architecture;Stakeholders;Computer architecture;Software development;Pragmatics;Production processes,software architecture,software architecture;operational view;DevOps;architectural thinking;architectural design,,8.0,,6.0,,25 Apr 2016,,,IEEE,IEEE Magazines
628,629,Multiparadigm Data Storage for Enterprise Applications,D. Ghosh,Anshin Software,IEEE Software,19 Aug 2010,2010,27,5,57,60,"Regardless of the paradigm used to model the application domain, most enterprise applications use the relational model for data storage. Relational database technology is mature, widely understood, and successfully deployed in countless applications. However, its dominance has also had some undesirable consequences for application development. For an application that models the business logic in an object-oriented way, the developer faces an impedance mismatch between the application's object model and the data's relational model. Object-relational mapping (ORM) frameworks exist to bridge this divide, but ORMs aren't trivial to use and often introduce more complexity than the problem they solve.",1937-4194,,10.1109/MS.2010.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5467015,data management;database;messaging;software engineering,Memory;Object oriented modeling;Application software;Relational databases;Impedance;Engines;Books;H infinity control;Poles and towers;Object oriented databases,business data processing;information storage;relational databases;storage management,multiparadigm data storage;enterprise applications;relational model;relational database technology;business logic;object relational mapping frameworks,,9.0,1.0,9.0,,20 May 2010,,,IEEE,IEEE Magazines
629,630,Code Documentation,D. Spinellis,Athens University of Economics and Business,IEEE Software,14 Jun 2010,2010,27,4,18,19,"The basic principles of good code documentation include the avoidance of repetition, the coexistence of code and its documentation, the documentation of all artifacts, and a preference for clear code and automated processes to explanatory documentation. Existing tools can help us by extracting documentation from specially formatted comments and by formatting code listed in documents. We can also automate the generation of bespoke documentation with a custom-made tool. When you document code, strive for completeness, consistency, effortless accessibility, and an automated low-overhead generation process.",1937-4194,,10.1109/MS.2010.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484109,comments;documentation;principles;tools;best practices;javadoc;POD;software engineering,Documentation;Job production systems,system documentation,code documentation;explanatory documentation;bespoke documentation,,4.0,,,,14 Jun 2010,,,IEEE,IEEE Magazines
630,631,Mobile Content as a Service A Blueprint for a Vendor-Neutral Cloud of Mobile Devices,M. Raatikainen; T. Mikkonen; V. Myllärniemi; N. Mäkitalo; T. Männistö; J. Savolainen,Aalto University; Tampere University of Technology; Aalto University; Tampere University of Technology; Aalto University; Danfoss Power Electronics,IEEE Software,10 Aug 2012,2012,29,4,28,32,"Mobile devices have become a commodity: we use several devices for various purposes. Although we carry only some of our devices with us, we still want to access content originating from any device. To overcome this issue, device users often upload content into a hosting service available in the cloud. However, cloud-based hosting can alienate the control and ownership of the content. A proposed architecture views development of a cloud computing service for mobile devices from a different angle. This approach maintains the content in the device where it was first created. The resulting design leads to a mobile device cloud that treats devices, together with the content and resources they host, as first-class cloud citizens. A proof-of-concept implementation is based on standard Web protocols. The underlying design can be configured for various contexts, such as individuals having several mobile devices, social communities interested in sharing content, or companies.",1937-4194,,10.1109/MS.2012.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6185528,mobile cloud;mobile data;mobile devices;content management;software engineering,Mobile handsets;Servers;Content management;Mobile communication;Cloud computing;Computer architecture,,,,3.0,1.0,8.0,,17 Apr 2012,,,IEEE,IEEE Magazines
631,632,Buzz: A Programming Language for Robot Swarms,C. Pinciroli; G. Beltrame,École Polytechnique de Montréal; École Polytechnique de Montréal,IEEE Software,23 Jun 2016,2016,33,4,97,100,"From drones to self-driving cars, robot swarms are becoming pervasive and are used in many kinds of applications. However, common ""swarm libraries"" for software development do not yet exist, and reusing code is difficult owing to the lack of swarm-centric development platforms. Buzz, a programming language for heterogeneous robot swarms, aims to address these problems.",1937-4194,,10.1109/MS.2016.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498536,Buzz;robot swarms;robotics;software engineering;software development;programming languages,Robot kinematics;Service robots;Particle swarm optimization;Robot sensing systems;Computer languages;Biological system modeling,control engineering computing;multi-robot systems;programming languages;robot programming;swarm intelligence,Buzz;programming language;robot swarm,,7.0,,7.0,,23 Jun 2016,,,IEEE,IEEE Magazines
632,633,An Information and Tracking System for Inland Shipping,T. van der Burgt; A. Baronner,Rijkswaterstaat; Rijkswaterstaat,IEEE Software,15 May 2017,2017,34,3,105,110,"The Information and Tracking System for Inland Shipping (in Dutch, abbreviated as IVS90) functions in one of the busiest areas of inland shipping in the Netherlands. Because the large locks, bridges, and vessel-traffic-service centers operate 24/7 and the occurrence of incidents is unpredictable, IVS90 requires high availability and 24/7 support.",1937-4194,,10.1109/MS.2017.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927904,inland shipping;Information and Tracking System for Inland Shipping;IVS90;Rijkswaterstaat;river information systems;software development;transportation;software engineering,Software development;Marine vehicles;Rivers;Tracking;Information services,goods distribution,information-and-tracking system;inland shipping;Dutch;IVS90;Netherlands,,,,11.0,,15 May 2017,,,IEEE,IEEE Magazines
633,634,Machine-to-Machine Communication,M. Weyrich; J. Schmidt; C. Ebert,University of Stuttgart; University of Stuttgart; Vector Consulting Services,IEEE Software,13 Jun 2014,2014,31,4,19,23,"Imagine a widespread manufacturing plant equipped with smart machinery and RFID-enabled technology. All machines are interconnected and communicate through their sensors and actuators as they work their way through the manufacturing process. Operators use wireless pads and connect to production systems for diagnostics and manufacturing oversight. Machine load, status, and diagnosis data are further aggregated in enterprise systems for resource planning and production optimization. The machines receive usage feedback to adjust production schemes and therefore optimize cost and quality. The machines also communicate with their own manufacturers to request repairs or order new parts to avoid costly outages. Agent-based systems allocate load to machines in a distributed, often global, production setup to optimize supply chain cost. This is a growing reality in what we call the smart factory. The smart factory of the future is far more agile than the approaches in today's flexible manufacturing. The smart factory connects the machines, devices, logistics, and humans to perform the necessary coordination ubiquitously and ad hoc.",1937-4194,,10.1109/MS.2014.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834707,wireless technology;machine-to-machine;smart factory;software engineering;embedded systems;green computing,Wireless communication;Communication system security;Wireless sensor networks;Machine-to-machine communication;Ad hoc networks;Production facilities,enterprise resource planning;factory automation;optimised production technology;production engineering computing;supply chain management,machine-to-machine communication;M2M communication;smart machinery;enterprise systems;resource planning;production optimization;supply chain cost optimization;smart factory,,16.0,,,,13 Jun 2014,,,IEEE,IEEE Magazines
634,635,IEEE Software's 25th-Anniversary Top Picks,,,IEEE Software,22 Dec 2008,2009,26,1,9,11,"Over the past 25 years, IEEE Software has published more than 1,200 peer-reviewed full-length articles. As part of its 25th-anniversary celebration, Software's editorial and advisory boards have examined this content from several perspectives to distill its top picks—a recommended reading list of 35 articles. The list includes title, author, issue, year, topic, and category.",1937-4194,,10.1109/MS.2009.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721173,software engineering reading list;overview;experience report;survey;essay;cutting-edge research,Software quality;Software reusability;Computer architecture;Reflection;Reliability engineering;Project management;Testing;Programming profession;Object oriented programming,,,,,,,,22 Dec 2008,,,IEEE,IEEE Magazines
635,636,Flight Control Software: Mistakes Made and Lessons Learned,Y. Jeppu,Moog India Technology Centre,IEEE Software,18 Apr 2013,2013,30,3,67,72,"Aerospace or flight control systems software development follows a rigorous process according to the RTCA DO-178B standard, yet software errors still occur. A review of the mistakes found during flight control test activities spanning 23 years reveals that the same mistakes tend to recur repeatedly. Moreover, we haven't yet learned everything about the mistakes that can be made in flight controls; new mistakes continue to pop up.",1937-4194,,10.1109/MS.2013.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6471712,software and system safety;test design;certification;software engineering;safety-critical software,Aerospace control;Software reliability;Digital filters;Air traffic control;Safety;Mathematical model;Air safety,,,,5.0,,4.0,,7 Mar 2013,,,IEEE,IEEE Magazines
636,637,Constraint-Based Object-Oriented Programming,P. Hofstedt,Brandenburg University of Technology Cottbus,IEEE Software,19 Aug 2010,2010,27,5,53,56,"The application and importance of constraint programming (CP) has grown remarkably in the past two decades. Developers widely use constraints for many planning, scheduling, and optimization tasks.Both the OO and constraint-based paradigms have advantages for certain application fields and programming techniques. Imperative OO languages such as Java and C++ let us model precisely and efficiently the behavior of state-changing systems.",1937-4194,,10.1109/MS.2010.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473202,Multiparadigm programming;programming languages;object-oriented languages;constraints;software engineering,Object oriented programming;Arithmetic;Object oriented modeling;Java;Production planning;Constraint optimization;Airplanes;Marine vehicles;Assembly;Personnel,constraint handling;object-oriented languages;object-oriented programming,constraint programming;object oriented language;java;C++;object-oriented programming,,1.0,,5.0,,27 May 2010,,,IEEE,IEEE Magazines
637,638,Aligning Requirements and Testing: Working Together toward the Same Goal,E. Bjarnason; M. Borg,Lund University; SICS Swedish ICT,IEEE Software,16 Jan 2017,2017,34,1,20,23,"The proper alignment of requirements engineering and testing (RET) can be key to software's success. Three practices can provide effective RET alignment: using test cases as requirements, harvesting trace links, and reducing distances between requirements engineers and testers. The Web extra https://youtu.be/M65ZKxfxqME is an audio podcast of author Elizabeth Bjarnason reading the the Requirements column she cowrote with Markus Borg.",1937-4194,,10.1109/MS.2017.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819382,software requirements;software testing;requirements engineering;software engineering;software development;requirements engineering and testing;RET;test cases;trace links,Requirements engineering;Software testing;Collaboration;Software development;Testing,formal specification;program testing;software prototyping,requirements engineering and testing;RET alignment;trace links;agile software development,,4.0,,5.0,,16 Jan 2017,,,IEEE,IEEE Magazines
638,639,Infusing Architectural Thinking into Organizations,A. J. Lattanze,Carnegie Mellon University,IEEE Software,22 Dec 2011,2012,29,1,19,22,"As an architectural consultant, the author spends a great deal of time helping organizations fully utilize software architecture to create better products and be more competitive. Here, he explains some of the mistakes he's made and the key lessons learned over the past 10 years working with architects primarily in the consumer electronics and embedded software industries.",1937-4194,,10.1109/MS.2012.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111362,software architecture;software design;software engineering,Software architecture;Software design;Product development,organisational aspects;software architecture,architectural thinking;architectural consultant;software architecture;consumer electronics industry;embedded software industry;organization,,3.0,,2.0,,22 Dec 2011,,,IEEE,IEEE Magazines
639,640,Multi-DSL Applications with Ruby,S. Günther,University of Magdeburg,IEEE Software,19 Aug 2010,2010,27,5,25,30,"Exploiting Ruby's support for the imperative, functional, and object-oriented paradigms, several DSLs' integrated and interwoven multiparadigm expressions can express all concerns, application layers, and artifacts of an application.",1937-4194,,10.1109/MS.2010.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473204,programming languages;multiparadigm languages;specialized application languages;Internet applications;software engineering,DSL;Application software;Computer languages;HTML;Cascading style sheets;Twitter;Functional programming;Object oriented programming;Java;Computer science,object-oriented languages,domain-specific languages;multiDSL applications;Ruby;object-oriented paradigms;application layers,,4.0,,6.0,,27 May 2010,,,IEEE,IEEE Magazines
640,641,The Best Software Development Teams Might be Temporary,R. Prikladnicki; M. G. Perin; S. Marczak; A. C. S. Dutra,Pontifícia Universidade Católica do Rio Grande do Sul; Pontifícia Universidade Católica do Rio Grande do Sul; Pontifícia Universidade Católica do Rio Grande do Sul; Pontifícia Universidade Católica do Rio Grande do Sul,IEEE Software,28 Mar 2017,2017,34,2,22,25,"A study of a large company's software development projects indicates that quality often suffers if team members have worked together previously. Thus, in many cases, temporary teams might be best.",1937-4194,,10.1109/MS.2017.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888427,software development;software development teams;major releases;minor releases;software engineering,Software development;Computer science;Maintenance engineering;Performance evaluation;Computer crashes;Software quality,project management;software development management;team working,software development teams;software development projects;team members;temporary teams,,,,3.0,,28 Mar 2017,,,IEEE,IEEE Magazines
641,642,Web 2.0 for Practitioners,N. Serrano; J. M. Torres,University of Navarra Engineering School; University of Navarra Engineering School,IEEE Software,19 Apr 2010,2010,27,3,11,15,"Web 2.0 has been a buzzword ever since software engineers started connecting different applications and data on the Internet. What are the most promising technologies for applying Web 2.0 in your IT? What tools go beyond gimmicks to help professional developers? Authors Nicolas Serrano and Jose Manuel Torres introduce the major open technologies and show how to integrate them in a professional application. Needless to say, we can't dive into all the interesting details, such as security or performance engineering. We'll have to leave those for later columns.",1937-4194,,10.1109/MS.2010.84,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452143,World Wide Web;software engineering,Data engineering;Joining processes;Application software;Internet;Security,Internet;public domain software;software tools,Web 2.0;software engineers;Internet;open technologies,,9.0,,5.0,,19 Apr 2010,,,IEEE,IEEE Magazines
642,643,Dominant Design,G. Booch,IBM,IEEE Software,28 Feb 2011,2011,28,2,8,9,The article is discussing architecture of software-intensive systems and its application in road traffic management.,1937-4194,,10.1109/MS.2011.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720705,architecture;software-intensive system;dominant design;punctuated equilibrium;software engineering;history of computing;standards;best practices,Design methodology;Computer architecture;Technological innovation;Economics;Innovation management;Technological innovation,road traffic;software architecture;traffic engineering computing,software intensive system;system architecture;road traffic management;dominant design,,,,,,28 Feb 2011,,,IEEE,IEEE Magazines
643,644,Software on a Comet: The Philae Lander's Central Onboard Computer,A. Baksa; A. Balázs; Z. Pálos; P. Spányi; S. Szalai; L. Várhalmi,Wigner Research Centre for Physics; Wigner Research Centre for Physics; Wigner Research Centre for Physics; Wigner Research Centre for Physics; SGF Ltd.; Wigner Research Centre for Physics,IEEE Software,26 Feb 2016,2016,33,2,81,84,"For the Philae lander to land on a comet after 10 years of space travel, its software had to meet rigorous requirements.",1937-4194,,10.1109/MS.2016.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420510,Philae lander;Rosetta;space exploration;fault-tolerant software;software engineering;software development,Space research;Comets;Mars;Computers;Fault tolerance;Fault tolerant systems;Space vehicles,aerospace computing;comets;formal specification,central onboard computer;comet;space travel;software requirement,,2.0,,3.0,,26 Feb 2016,,,IEEE,IEEE Magazines
644,645,Architecture as a Shared Hallucination,G. Booch,IBM,IEEE Software,31 Dec 2009,2010,27,1,96,96,"This paper present the architecture of a software intensive system. An architecture is just a collective hunch, a shared hallucination, an assertion by a set of stakeholders about the nature of their observable world, be it a world that is or a world as they wish it to be. An architecture therefore serves as a means of anchoring an extended set of stakeholders to a common vision of that world, a vision around which they may rally, to which they are led, and for which they work collectively to make manifest. When I say that an architecture is a shared hallucination, I mean that an architecture-as-artifact is a naming of the mutually agreed-upon set of design decisions that shape a software-intensive system. While an architecture is just an abstraction of reality, an architecture-as-artifact is a declaration of that shared reality. In this way, that shared hallucination represents a common vision among a set of stakeholders as observed simultaneously through several different points of view and represented by a set of interlocking models.",1937-4194,,10.1109/MS.2010.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370767,software engineering;architecture;software architecture;modeling;stakeholders,Computer architecture;Software systems;Shape,software architecture;software management,software intensive system architecture;shared hallucination;interlocking models,,1.0,,,,31 Dec 2009,,,IEEE,IEEE Magazines
645,646,Software Retrofit in High-Availability Systems: When Uptime Matters,T. Ronzon,w3logistics AG,IEEE Software,26 Feb 2016,2016,33,2,11,17,A software retrofit can address problems of business-critical systems that are no longer maintainable. This seven-step approach revises software while daily operations are going on. The goal is to reestablish a system that you can extend and maintain with state-of-the-art development and operations technologies.,1937-4194,,10.1109/MS.2016.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420474,software refit;logistics;software development;software engineering,Software;Servers;Companies;Hardware;Documentation;Databases,business data processing;software maintenance,software retrofitting;high-availability systems;business-critical systems;software development technology;software operation technology;software maintenance,,1.0,,10.0,,26 Feb 2016,,,IEEE,IEEE Magazines
646,647,A Framework for Managing Privacy-Enhancing Technology,D. Pelkola,KPMG Canada,IEEE Software,20 Apr 2012,2012,29,3,45,49,"The changing global business environment and continued introduction of new technologies are significantly affecting organizations' privacy practices. In this environment, privacy-enhancing technology (PET) often becomes a key to protecting personal information. A considerable amount of literature has discussed PET technologies and their benefits. However, the lack of clear organizational accountability can become a roadblock to effectively designing and implementing PET solutions. For organizations that don't employ these solutions, the result is increased regulatory and privacy risk and potential costs related to privacy breaches. Establishing a multidisciplinary privacy committee with clear roles and responsibilities assigned to various members is a possible approach to help address accountability.",1937-4194,,10.1109/MS.2012.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175000,privacy-enhancing technology;privacy committee;software engineering,Privacy;Positron emission tomography;Organizations;Data privacy;Security;Process control,business data processing;data privacy,privacy-enhancing technology;global business environment;PET;personal information;clear organizational accountability;privacy risk and;privacy breaches;multidisciplinary privacy committee,,3.0,,5.0,,3 Apr 2012,,,IEEE,IEEE Magazines
647,648,Service Orchestration with Rundeck,D. Spinellis,Athens University of Economics and Business,IEEE Software,13 Jun 2014,2014,31,4,16,18,"Managing and controlling a service's provision is tricky, but tools for service orchestration, like Rundeck, can make our lives easier. Rundeck bridges the gap between software building and system configuration by allowing us to define tasks to deploy the software or configure its operation. After installing Rundeck, administrators typically define the characteristics of the computing nodes (hosts) where jobs will run, as well as the jobs themselves. Defining a job involves specifying its options and its workflow. Administrators define workflows in terms of node steps, which run on each node, or steps that execute once for the entire workflow. When a job is run, administrators have to enter its options and can control the nodes where it will execute. All job activity reports are stored in a queryable database. Sophisticated access control allows administrators to define groups and access control policies by project, group, or job. Rundeck's shiny graphical interface can make it appeal to a wide user base. The Web extra at http://youtu.be/oNJ8ejmfGyg is an audio podcast of the Tools of the Trade column in which author Diomidis Spinellis discusses how managing and controlling a service's provision is tricky, but tools for service orchestration, like Rundeck, can make our lives easier.",1937-4194,,10.1109/MS.2014.92,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834683,workflow automation;service orchestration;configuration management;Rundeck;software engineering,Contracts;Proposals;Service computing;Business;Process control,,,,1.0,,,,13 Jun 2014,,,IEEE,IEEE Magazines
648,649,Exactly How Are Requirements Written?,N. Maiden,City University London,IEEE Software,22 Dec 2011,2012,29,1,26,27,"Few studies of actual requirements practices exist compared to the number of studies on how people program. Thus, we know relatively little about how people actually do requirements work. By considering a simple user story, we can begin to inform our understanding of the cognitive processes that good requirements work requires.",1937-4194,,10.1109/MS.2012.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111364,requirements;software engineering;cognitive process;analysis;analyst,Software design;Programming;Computer languages;Best practices;Cognitive science,formal specification;formal verification,user story;cognitive process;requirements practices;requirements work,,5.0,,4.0,,22 Dec 2011,,,IEEE,IEEE Magazines
649,650,Future Automotive Architecture and the Impact of IT Trends,M. Traub; A. Maier; K. L. Barbehön,BMW; BMW; BMW,IEEE Software,15 May 2017,2017,34,3,27,32,"The transfer of IT and consumer-electronics technologies to the automotive domain will provide major opportunities. However, both these technologies and the automotive industry will require much adaptation. Architectures for automotive electronics are quickly changing. Energy efficiency is evolving the classic powertrain toward high-voltage hybrid and electric engines. Autonomous driving demands multisensor fusion away from functionally isolated control units. Connectivity and infotainment have transformed the car into a distributed IT system with cloud access; over-the-air functional upgrades; and high-bandwidth access to map services, media content, other vehicles, and the surrounding infrastructure.",1937-4194,,10.1109/MS.2017.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927914,E/E architecture;electrical and electronic architecture;automotive software;ECUs;electronic control units;SOA;service-oriented architecture;consumer electronics;IT;software engineering;software development,Computer architecture;Automotive engineering;Service-oriented architecture;Sensors;Servers,automotive electric vehicles;automotive electronics;automotive engineering;cloud computing;energy conservation;hybrid electric vehicles;power transmission (mechanical);sensor fusion,automotive architecture;automotive electronics;automotive domain;automotive industry;energy efficiency;high-voltage hybrid engines;electric engines;powertrain;multisensor fusion;functionally isolated control units;distributed IT system;cloud access;over-the-air functional upgrades;media content;IT transfer,,25.0,,2.0,,15 May 2017,,,IEEE,IEEE Magazines
650,651,Using a Line of Code Metric to Understand Software Rework,E. Morozoff,"Medtronic, Inc. , Mounds View",IEEE Software,31 Dec 2009,2010,27,1,72,77,"A simple method measuring new effective lines of code showed that between 19 and 40 percent of code written on three projects wasn't in the final release. Generally, productivity is a function of input effort and output size. A strong understanding of software productivity, coupled with a good estimate of software size, is key to predicting project effort and, ultimately, producing reliable project duration estimates, schedules, and resource needs. Project managers and engineers often measure or predict the size of released software-the volume of software in the marketed product. However, the final release doesn't include reworked code-code that was changed or deleted during development.",1937-4194,,10.1109/MS.2009.160,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232799,lines of code;software productivity;software rework;software;software engineering,Productivity;Project management;Engineering management;Reliability engineering;Volume measurement;Size measurement;Software measurement,scheduling;software cost estimation;software metrics;systems re-engineering,line of code metric;software rework;software productivity;project duration estimation;project managers;scheduling;software project cost estimations,,3.0,,18.0,,4 Sep 2009,,,IEEE,IEEE Magazines
651,652,Value Stream Architecture,M. Kersten,Tasktop,IEEE Software,22 Sep 2017,2017,34,5,10,12,"This new department aims to elevate the discussion of software architecture beyond code to include all artifacts involved in the software delivery value stream. Here, “value stream” refers to the end-to-end feedback loop of flowing software to customers in a way that maximizes the business value delivered.",1937-4194,,10.1109/MS.2017.3571573,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048647,DevOps;software architecture;value stream;value stream architecture;software delivery;software engineering;software development,Software architecture;Computer architecture;Feedback loop,software architecture,value stream architecture;software architecture;software delivery value stream;end-to-end feedback loop;business value maximization,,,,3.0,,22 Sep 2017,,,IEEE,IEEE Magazines
652,653,Using Documentation for Product Line Scoping,I. John,"Fraunhofer IESE, Kaiserslautern",IEEE Software,19 Apr 2010,2010,27,3,42,47,"The introduction of product line engineering must be well planned. This planning phase, where the product line's characteristics are determined, is called scoping. Product line scoping is the process of identifying and delimiting capabilities (products and features) and areas (subdomains and existing assets) of the product line where investment into reuse would be economical and beneficial to product development. It aims to dispel doubts and uncertainty in decisions about which products will become part of the product line and whether to invest into reuse. Scoping is based heavily on expert knowledge and information from meetings and workshops.",1937-4194,,10.1109/MS.2010.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5416671,product line engineering;product line scoping;user documentation;product line analysis;elicitation;elicitation methods;requirements/specifications;software engineering;domain engineering;reusable software,Documentation;Investments;Product development;Uncertainty,product development;production engineering;production planning;software reusability,product line scoping;product line engineering;product development;expert knowledge,,8.0,,13.0,,18 Feb 2010,,,IEEE,IEEE Magazines
653,654,Context-Aware Software Variability through Adaptable Interpreters,W. Cazzola; A. Shaqiri,Università degli Studi di Milano; Università degli Studi di Milano,IEEE Software,13 Nov 2017,2017,34,6,83,88,A proposed approach moves variability support from the programming language to the language implementation level. This enables contextual variability in any application independently of whether the underlying language supports context-oriented programming. A Neverlang-based prototype implementation illustrates this approach.,1937-4194,,10.1109/MS.2017.4121222,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106869,context-oriented programming;dynamic language evolution;contextual variability;software development;software engineering;Neverlang;contextual-variability modeling,Context awareness;Semantics;Context modeling;Computer languages;Programming;Software development,object-oriented programming;programming languages;ubiquitous computing,contextual variability;underlying language;context-oriented programming;prototype implementation;context-aware software variability;variability support;programming language;language implementation level,,1.0,,16.0,,13 Nov 2017,,,IEEE,IEEE Magazines
654,655,Code Evasion,G. J. Holzmann,NASA/JPL,IEEE Software,21 Aug 2015,2015,32,5,77,80,"Programs sometimes tend to lose their structure and clarity through the addition of error handling. Often, more than half of a code base ends up dedicated to various types of error detection and recovery, obscuring the nominal control flow that defines the basic structure. The challenge in writing reliable code is to find ways to remove code from an application by simplifying and generalizing, rather than continuing to add more.",1937-4194,,10.1109/MS.2015.112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217766,software reliability;software engineering;software development;Unix;fault protection;error handling,Complexity theory;Computers;Software;Writing;Software reliability;Fault protection,error handling;source code (software);system recovery,code evasion;error handling;error detection;error recovery;nominal control flow,,1.0,,6.0,,21 Aug 2015,,,IEEE,IEEE Magazines
655,656,The Weakest Link,G. J. Holzmann,Jet Propulsion Laboratory,IEEE Software,23 Jun 2016,2016,33,4,18,21,"In interactive systems, what's the weakest link: the computer or the human? Explores issue involved with decision making via computer systems versus humans. Should we be more concerned with a computer overruling a human in key decisions, or vice versa?",1937-4194,,10.1109/MS.2016.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498548,critical systems;human-computer interaction;software engineering;software development;intelligent systems,Human factors;Decision making;Interactive systems;Software reliability;Safety,decision making;interactive systems,interactive systems;decision making;computer systems;humans,,,,3.0,,23 Jun 2016,,,IEEE,IEEE Magazines
656,657,A Critical Look at Software Capability Evaluations: An Update,T. Bollinger; C. McGowan,US Department of Defense; Noblis,IEEE Software,25 Aug 2009,2009,26,5,80,83,"Software capability evaluations (SCEs) were the prototype for what's now the standard CMMI appraisal method for process improvement. SCEs used 85 yes/no questions to determine organizations' maturity levels. This was an astonishingly sparse data set from which to assign a label that could bar an organization from bidding on federal contracts. CMMI is our current best answer for what are the set of necessary, but not sufficient, constraints we need to impose for the truly important software systems. We know we can usefully employ certain carefully selected manufacturing-based concepts, as well as well-established software measures. CMMI thus isn't in opposition to effective use of creativity in a project. Instead, it's a collection of reasonable practices that enable and encourage closer attention to the less quantifiable aspects of project success that require much more than just process adherence.",1937-4194,,10.1109/MS.2009.119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222800,software engineering;SCE;CMM;CMMI;CMMI-DEV;Software Capability Evaluations;Software CMMI;Capability Maturity Model;Capability Maturity Model Integration;process adherence;software metrics,Coordinate measuring machines;Humans;Monitoring;Technological innovation;Testing;Scheduling;Quality control;Product safety;Qualifications,Capability Maturity Model;contracts;software metrics,software capability evaluation;standard CMMI appraisal method;software process improvement;federal contract;software measure,,1.0,,6.0,,25 Aug 2009,,,IEEE,IEEE Magazines
657,658,It's About Time to Take JavaScript (More) Seriously,H. M. Kienle,Malardalen University,IEEE Software,19 Apr 2010,2010,27,3,60,62,"JavaScript is a scripting language, of course. The drawbacks and benefits of scripting languages compared to full-fledged programming languages have been explored before. In a previous installment of this column, Diomidis Spinellis points out that with scripting languages, users can benefit from flexible syntax, loose type systems, powerful reflection mechanisms, and shorter build cycles. Scripting languages have proven their usefulness in various application areas. Unix relies heavily on shell scripting to accomplish many complex tasks. Visual Basic, in combination with ActiveX, provides a low-entry barrier into the world of component-based programming. Tcl/Tk is still popular to rapidly develop GUI-based applications. And then there's JavaScript, which has gained considerable importance in realizing clientside functionality on Web apps. In a survey on the most popular programming languages, JavaScript made it to the Top 10.",1937-4194,,10.1109/MS.2010.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452147,javascript;web 2.0;web browser;software engineering,Java;Computer languages;Reflection;Visual BASIC,authoring languages;object-oriented programming;Unix,JavaScript;scripting languages;programming languages;Unix;Visual Basic;component-based programming;Web apps,,8.0,,7.0,,19 Apr 2010,,,IEEE,IEEE Magazines
658,659,"Distributed Teams, Developer Participation, and More",J. C. Carver; H. Muccini; A. Yamashita,University of Alabama; University of L'Aquila; Yamashita Research,IEEE Software,15 May 2017,2017,34,3,114,116,"This instalment reports on two talks from the First International Workshop on Collaborative Modeling in MDE (model-driven engineering) and three papers from the 23rd International Conference on Software Analysis, Evolution, and Reengineering. The topics covered include model-driven engineering, forking and developer participation, FLOSS (free/libre and open source software) software projects, and perceptions of release practices.",1937-4194,,10.1109/MS.2017.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927920,MDE;model-driven engineering;FLOSS;forking;release practices;GenMyModel;COMMitMDE;SANER;software engineering;software development,,,,,1.0,,,,15 May 2017,,,IEEE,IEEE Magazines
659,660,Should Architects Code?,E. Woods,Endava,IEEE Software,22 Sep 2017,2017,34,5,20,21,"Should the people performing a system’s architecture work also develop some of the system’s production code? Involving architects in carefully selected implementation tasks, such as testing, refactoring, or architectural spikes, can yield positive returns on investment for both the architects and their teams.",1937-4194,,10.1109/MS.2017.3571574,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048649,software;software architecture;coding;software development;software engineering,Encoding;Computer architecture;Pragmatics;Software testing;Software architecture,,,,,,2.0,,22 Sep 2017,,,IEEE,IEEE Magazines
660,661,Searching the Internet,M. Andrews,Microsoft,IEEE Software,20 Feb 2012,2012,29,2,13,16,"This column differs somewhat from previous ones in that the software itself isn't shipped-rather, the results of the software are shipped, and in huge numbers. Mike Andrews of Microsoft reveals some of the intricacies and enormous resources required for successful Web search with a fascinating glimpse into the Bing search engine.",1937-4194,,10.1109/MS.2012.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155137,bing;microsoft;search engine;web;internet scale;technology;servers;software engineering;hardware,Search engines;Information retrieval;Search problems;Web and internet services,Internet;search engines,Internet;software;Microsoft;Web search;Bing search engine,,10.0,,1.0,,20 Feb 2012,,,IEEE,IEEE Magazines
661,662,Future of Mining Software Archives: A Roundtable,M. W. Godfrey; A. E. Hassan; J. Herbsleb; G. C. Murphy; M. Robillard; P. Devanbu; A. Mockus; D. E. Perry; D. Notkin,"University of Waterloo; Queen's University Canada; Carnegie Mellon University; University of British Columbia; McGill University; University of California, Davis; Avaya Labs; University of Texas at Austin; University of Washington",IEEE Software,22 Dec 2008,2009,26,1,67,70,"When mining software archives, we want to learn from the past to shape the future. But what does the research so far tell us about the future of the field itself? For this special issue, we invited and collected statements from nine research leaders in the field. These statements show opportunities for data collection and exploitation (Michael Godfrey, Ahmad Hassan, and James Herbsleb), enhancing programmer productivity (Gail Murphy and Martin Robillard), examining the role of social networking (Prem Devanbu), leveraging data for industry (Audris Mockus), and answering open research questions (Dewayne Perry). David Notkin, though, warns against too much enthusiasm: ""Let us not mine for fool's gold."" Enjoy! -Nachiappan Nagappan, Andreas Zeller, and Thomas Zimmermann, Guest Editors ",1937-4194,,10.1109/MS.2009.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721185,software engineering;software development;test case classification;goal-driven testing;phase-driven testing;software testing,Context awareness;Software performance;Costs;Programming profession;Social network services;Psychology;Software development management;Project management;Job shop scheduling;Instruments,,,,6.0,,,,22 Dec 2008,,,IEEE,IEEE Magazines
662,663,IT Infrastructure-Monitoring Tools,J. Hernantes; G. Gallardo; N. Serrano,University of Navarra; University of Navarra; University of Navarra,IEEE Software,30 Jun 2015,2015,32,4,88,93,"Monitoring is critical to IT system health and thus to businesses' bottom line. This article discusses current tools that monitor networks to detect issues, ensure the components' availability, and measure the resources those components use.",1937-4194,,10.1109/MS.2015.96,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140697,IT infrastructure;IT infrastructure-monitoring tools;Nagios;Zabbix;Hyperic;SolarWinds;ManageEngine OpManager;HP Operations Manager;IBM Tivoli;WhatsUp Gold;software engineering;software development,Monitoring;Electronic mail;Information technology;Cloud computing;Maintenance engineering,reliability;system monitoring,IT infrastructure;monitoring tools;IT system health monitoring;component availability,,20.0,,3.0,,30 Jun 2015,,,IEEE,IEEE Magazines
663,664,Crowd-Based Ambient Assisted Living to Monitor the Elderly’s Health Outdoors,A. C. Bicharra Garcia; A. S. Vivacqua; N. Sánchez-Pi; L. Martí; J. M. Molina,Federal University of the State of Rio de Janeiro; Federal University of Rio de Janeiro; Rio de Janeiro State University; Fluminense Federal University; Carlos III University of Madrid,IEEE Software,13 Nov 2017,2017,34,6,53,57,"The SafeNeighborhood approach combines data from multiple sources with collective intelligence. It merges mobile, ambient, and AI technologies with old-fashioned neighborhood ties to create safe outdoor spaces for the elderly. We're exploring AAL techniques in outdoor environments to increase the elderly's independence without them having to interact with technology. Current research in outdoor monitoring relies solely on sensor data.4 Our approach, which we call SafeNeigborhood (SN), crowdsources people in the neighborhood to revise the computer's inferences from contextual and sensor data. So, SN brings the community together to provide a safer environment for the elderly.",1937-4194,,10.1109/MS.2017.4121217,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106875,human-centered computing;handicapped persons;special needs;healthcare;care for the elderly;ambient assisted living;SafeNeighborhood;software engineering;software development;context-aware and smart healthcare,Senior citizens;Monitoring;Temperature sensors;Global Positioning System;Mobile communication;Assisted living;Biomedical monitoring;Smart devices,ambient intelligence;artificial intelligence;assisted living;geriatrics;health care,computer inferences;outdoor monitoring;outdoor environments;AAL techniques;AI technologies;SafeNeighborhood approach;elderly health outdoor monitoring;crowd-based ambient assisted living,,4.0,,10.0,,13 Nov 2017,,,IEEE,IEEE Magazines
664,665,Excellence in Search: An Interview with David Chaiken,J. Favaro,"Intecs SpA, Italy",IEEE Software,22 Dec 2011,2012,29,1,84,86,"In June 2011, IEEE Software associate editor John Favaro interviewed search engine giant Yahoo's chief architect David Chaiken about algorithms and today's practitioner. Chaiken gave a keynote speech at SATURN 2011 on ""Architecture at Internet Scale"" that stressed a set of timeless principles that software engineers seemingly have to relearn continuously. Here, he describes the role algorithms play in the programmer's toolkit.",1937-4194,,10.1109/MS.2012.7,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111368,algorithms;software design;programming basics;software engineering,Interviews;Software architecture;Software algorithms,,,,,,,,22 Dec 2011,,,IEEE,IEEE Magazines
665,666,Architectural Hoisting,G. Fairbanks,Google,IEEE Software,13 Jun 2014,2014,31,4,12,15,Architectural hoisting is a design technique where the responsibility for enforcing an intentional design constraint is implemented in the code rather than by relying solely on the diligence of the developers. This can help teams to achieve a global system property by avoiding inconsistences and lapses in implementing design rules.,1937-4194,,10.1109/MS.2014.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834691,software engineering;software architecture;programming in the large;programming in the small;architectural hoisting;software;IEEE,Design engineering;Pragmatics;Computer architecture,,,,3.0,,1.0,,13 Jun 2014,,,IEEE,IEEE Magazines
666,667,Guest Editors' Introduction: What Kinds of Nails Need a Domain-Specific Hammer?,J. Sprinkle; M. Mernik; J. Tolvanen; D. Spinellis,University of Arizona; University of Maribor; MetaCase; Athens University of Economics and Business,IEEE Software,19 Jun 2009,2009,26,4,15,18,"Domain-specific techniques, languages, tools, and models, such as Fortran and Cobol can easily be viewed as domain-specific languages for scientific and business computing, respectively. Their domain is just very wide. What has changed is the technology for creating domain-specific languages (DSLs). Now it is easier to define languages and get tool support for narrower domains. Such focus offers increased abstraction, making development faster and easier. In domain-specific approaches, developers construct solutions from concepts representing things in the problem domain, not concepts of a given general-purpose programming language. Ideally, a DSL follows the domain abstractions and semantics as closely as possible, letting developers perceive themselves as working directly with domain concepts. The created specifications might then represent simultaneously the design, implementation, and documentation of the system, which can be generated directly from them. The mapping from the high-level domain concepts to implementation is possible because of the domain specificity: the language and code generators fit the requirements of a narrowly defined domain.",1937-4194,,10.1109/MS.2009.92,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076453,domain-specific modeling;domain-specific languages;software engineering,Nails;Domain specific languages;Computer languages;DSL;Documentation;Hardware design languages;Insurance;Home automation;Investments;Assembly,software tools;specification languages,domain abstraction;domain semantics;domain specific language and modelling,,56.0,,12.0,,19 Jun 2009,,,IEEE,IEEE Magazines
667,668,Refactoring Myths,M. Hafiz; J. Overbey,Auburn University; Auburn University,IEEE Software,28 Oct 2015,2015,32,6,39,43,"Refactoring myths are popular misconceptions about tool-based refactoring-about the tools' intent, the principle they follow, their robustness, and support for them. This article is part of a special issue on Refactoring.",1937-4194,,10.1109/MS.2015.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310987,refactoring; refactoring tools; automatic programming; coding tools and techniques; distribution;maintenance;and enhancement; software engineering; software development,Software development;Code refractoring;Computer bugs;Robustness;Programming;Java,software maintenance,refactoring myth;tool-based refactoring;tools intent,,2.0,,14.0,,28 Oct 2015,,,IEEE,IEEE Magazines
668,669,Web Application Tests with Selenium,A. Bruns; A. Kornstadt; D. Wichmann,C1 Workplace Solutions; C1 Workplace Solutions; C1 Workplace Solutions,IEEE Software,25 Aug 2009,2009,26,5,88,91,"Web applications tend to continuously evolve and thus need thorough, yet lean and automatic, regression testing. In this installment of Software Technology, Andreas Kornstadt and his colleagues describe automatic regression testing for Web applications that uses the Selenium testing framework. Selenium is portable open source software available for Windows, Linux, and Macintosh. Tests are written as HTML tables or in a number of programming languages and can run directly in most Web browsers. Andreas and his colleagues also provide many useful testing hints for practitioners. We look forward to hearing from both readers and prospective column authors about this column and the technologies we want to know more about.",1937-4194,,10.1109/MS.2009.144,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222802,rich internet applications;Ajax;acceptance tests;regression;software engineering,Application software;Java;Radio control;Software testing;HTML;Protocols;Software tools;Internet;Vocabulary;Fixtures,hypermedia markup languages;Internet;online front-ends;program testing;public domain software,Web application test;lean testing;automatic testing;regression testing;Selenium testing framework;portable open source software;HTML tables;programming languages;Web browsers;HyperText Markup Language,,29.0,,12.0,,25 Aug 2009,,,IEEE,IEEE Magazines
669,670,Delivering Genuine Emails in an Ocean of Spam,L. Hatton; A. John,SendForensics; SendForensics,IEEE Software,11 Jul 2017,2017,34,4,11,15,"SendForensics has created a system that lets email senders analyze and optimize all outgoing email before sending it. This system aims to widen the gap between legitimate and illegitimate email in terms of the respective forensic footprints, ultimately making it far easier for existing and future filtering technologies to tell the difference.",1937-4194,,10.1109/MS.2017.102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974706,email;spam;email filtering;spam filters;phishing;software security;deliverability;purity;forensic algorithms;SendForensics;software development;software engineering,Electronic mail;Postal services;Forensics;Computer security;Unsolicited electronic mail;Cloud computing;Digital forensics,unsolicited e-mail,genuine emails;software as a service,,1.0,,6.0,,11 Jul 2017,,,IEEE,IEEE Magazines
670,671,Architecture Reviews,G. Booch,IBM,IEEE Software,19 Apr 2010,2010,27,3,96,96,"An architectural review serves several purposes: to gain confidence in the design, to reason about alternatives, to attend to architectural rot. The process of such a review involves the interplay of design decisions, scenarios, and forces on the system.",1937-4194,,10.1109/MS.2010.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452153,Software engineering;software;architecture review;architectural governance,Computer architecture;Unified modeling language;Software design;Software architecture;Performance analysis;Software development management;System analysis and design,,,,4.0,,,,19 Apr 2010,,,IEEE,IEEE Magazines
671,672,An Empirical Analysis of Business Process Execution Language Usage,M. Hertis; M. B. Juric,"Laboratory for Integration of Information Systems, Faculty of Computer and Information Science, University of Ljubljana, Trzaska cesta 25, Ljubljana, Slovenia, and Seltron d.o.o., Trzaska cesta 85 a, Maribor; Faculty, of Computer and Information Science, Ljubljana, Slovenia",IEEE Transactions on Software Engineering,8 Aug 2014,2014,40,8,738,757,"The current state of executable business process languages allows for and demands optimization of design practices and specifications. In this paper, we present the first empirical study that analyses Web Services Business Process Execution Language (WS-BPEL or BPEL) usage and characteristics of real world executable business processes. We have analysed 1,145 BPEL processes by measuring activity usage and process complexity. In addition, we investigated the occurrence of activity usage patterns. The results revealed that the usage frequency of BPEL activities varies and that some activities have a strong co-occurrence. BPEL activities often appear in activity patterns that are repeated in multiple processes. Furthermore, the current process complexity metrics have proved to be inadequate for measuring BPEL process complexity. The empirical results provide fundamental knowledge on how BPEL specification and process design practices can be improved. We propose BPEL design guidelines and BPEL language improvements for the design of more understandable and less complex processes. The results are of interest to business process language designers, business process tool developers, business process designers and developers, and software engineering researchers, and contribute to the general understanding of BPEL and service-oriented architecture.",1939-3520,,10.1109/TSE.2014.2322618,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6812231,WS-BPEL Analysis;complexity measure;service composition;process patterns;process complexity;process comprehension;empirical study,Complexity theory;Business;Measurement;Semantics;XML;Syntactics;Guidelines,service-oriented architecture;Web Services Business Process Execution Language,empirical analysis;design practices;design specifications;Web services business process execution language;WS-BPEL;executable business processes;activity usage;process complexity;BPEL activities;BPEL design guidelines;BPEL language improvements;service-oriented architecture,,14.0,,68.0,,8 May 2014,,,IEEE,IEEE Journals
672,673,Automated Synthesis of Mediators to Support Component Interoperability,A. Bennaceur; V. Issarny,"Department of Computing, The Open University, United Kingdom; MiMove team, Inria, France",IEEE Transactions on Software Engineering,11 Mar 2015,2015,41,3,221,240,"Interoperability is a major concern for the software engineering field, given the increasing need to compose components dynamically and seamlessly. This dynamic composition is often hampered by differences in the interfaces and behaviours of independently-developed components. To address these differences without changing the components, mediators that systematically enforce interoperability between functionally-compatible components by mapping their interfaces and coordinating their behaviours are required. Existing approaches to mediator synthesis assume that an interface mapping is provided which specifies the correspondence between the operations and data of the components at hand. In this paper, we present an approach based on ontology reasoning and constraint programming in order to infer mappings between components' interfaces automatically. These mappings guarantee semantic compatibility between the operations and data of the interfaces. Then, we analyse the behaviours of components in order to synthesise, if possible, a mediator that coordinates the computed mappings so as to make the components interact properly. Our approach is formally-grounded to ensure the correctness of the synthesised mediator. We demonstrate the validity of our approach by implementing the MICS (Mediator synthesis to Connect Components) tool and experimenting it with various real-world case studies.",1939-3520,,10.1109/TSE.2014.2364844,ERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936339,Interoperability;Constraint Programming;Automated Synthesis;Mediators;Protocols;Interoperability;constraint programming;automated synthesis;mediators;protocols,Ontologies;Semantics;Google;Interoperability;Cognition;Programming;Protocols,object-oriented programming;ontologies (artificial intelligence);open systems,automated mediator synthesis;component interoperability;dynamic composition;functionally compatible component;interface mapping;ontology reasoning;constraint programming;component interface;semantic compatibility;MICS;mediator synthesis to connect components,,28.0,,57.0,,24 Oct 2014,,,IEEE,IEEE Journals
673,674,Point Counterpoint,I. Gat; C. Ebert,Cutter Consortium; Vector Consulting Services,IEEE Software,22 Oct 2012,2012,29,6,52,55,"In his Point argument, ""Technical Debt as a Meaningful Metaphor for Code Quality,"" Israel Gat describes how technical debt changes the software engineering playing field from qualitative assessment of code quality to quantitative measurement. In his Counterpoint argument, ""A Useful Metaphor for Risk - Poorly Practiced,"" Christof Ebert argues that technical debt is a useful metaphor for risk and its economic impacts, but that it's often exaggerated and involves number crunching that distracts the target audience.",1937-4194,,10.1109/MS.2012.163,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6336726,technical debt;risk;qualitative assessment;measurement;benchmarks;product development,Risk management;Benchmarking;Product development;Software quality;Economics,software metrics;software quality,technical debt;meaningful metaphor;code quality;software engineering;quantitative measurement;economic impacts,,3.0,,1.0,,22 Oct 2012,,,IEEE,IEEE Magazines
674,675,Innovation Reconsidered,F. Buschmann,Siemens Corporate Technology,IEEE Software,3 Jan 2013,2013,30,1,18,20,"""Innovation"" and ""innovative architecture"" are topics of broad popularity in software engineering. Yet, the two terms appear to mean different things to different people-with interpretations of both driven more by personal interests than by their true meanings. It's therefore essential for architects to have a clear understanding of what ""innovation"" means in the context of their projects if they are to make the right design decisions and communicate the intended messages to project stakeholders.",1937-4194,,10.1109/MS.2013.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401110,innovation;software architecture;deliberate design practice,Software architecture;Technological innovation;Software design,innovation management;software architecture,innovation reconsideration;innovative architecture;software engineering;personal interests;right design decisions;intended message communication;project stakeholders,,1.0,,9.0,,3 Jan 2013,,,IEEE,IEEE Magazines
675,676,Point/Counterpoint,K. Wallnau; P. Kruchten,Carnegie Mellon University; University of British Columbia,IEEE Software,25 Apr 2011,2011,28,3,56,59,"We have the technology to produce software that has predictable behavior, but doing so requires a better understanding of the economics of confidence and better integration of architecting and programming. I have a long-standing interest in understanding how software components (for present purposes, implementations with interfaces) influence software design. From 2002 to 2008, several colleagues and I at the Software Engineering Institute explored how to combine software architecture and software components such that a system design specifies what architects must know and trust about the components, how this determines the kinds of architectural analyses they can perform, and what measure of confidence they can associate with the results. We referred to this combined capability as predictability by construction (PBC).",1937-4194,,10.1109/MS.2011.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756295,software;architecture;components;engineering;predictability by construction;architecture description language;adl;assemblies;programming,Software architecture;Computer architecture;Cognition;Economics;Programming;Reliability,software architecture,predictability by construction;software components;software design;Software Engineering Institute;software architecture,,1.0,,2.0,,25 Apr 2011,,,IEEE,IEEE Magazines
676,677,"Disbanding the ""Process Police"": New Visions for Assuring Compliance",F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,20 Apr 2012,2012,29,3,3,6,"This article presents a vision of future techniques and approaches for software assurance, based on interviews with researchers for NASA's Office of Safety and Mission Assurance, and their sense of research trends and future directions. Key components of this vision include a more constructive role for software assurance, based upon early and effective collaboration with software developers, techniques that aim to ensure the quality of software as it is being built rather than after the fact, and earlier feedback loops of the assessments of software quality.",1937-4194,,10.1109/MS.2012.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188592,software assurance;process assurance;software quality,NASA;Humans;Systems engineering and theory;Software quality;Standards;Safety,,,,,,,,20 Apr 2012,,,IEEE,IEEE Magazines
677,678,A Look at 25 Years of Data,N. Juristo; A. Moreno; S. Vegas; F. Shull,"Universidad Politecnica de Madrid; Universidad Politecnica de Madrid; Universidad Politecnica de Madrid; Fraunhofer Center for Experimental Software Engineering, Maryland",IEEE Software,22 Dec 2008,2009,26,1,15,17,"Is 25 years enough time to build up a coherent body of knowledge that can help point to useful principles? As a testbed for helping us answer this question, software testing techniques are a good place to start. Few software practices are as important as testing, and testing techniques are amenable to measurement and reasoning about their effectiveness. Because they're aimed at removing faults, measuring the number and type of such removed faults seems like a natural part of applying these techniques. To make sense of this data, Universidad Politecnica de Madrid researchers have spent some time worrying about how to put 25 years' worth of work together usefully.",1937-4194,,10.1109/MS.2009.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721175,software testing;data flow testing;control flow testing,Software testing;Programming;System testing;Software quality;Systems engineering and theory;Robustness;Costs;Scheduling;Guidelines;Runtime,program testing;reasoning about programs;software metrics,software testing;software practice;software development;software measurement;software effectiveness reasoning,,10.0,,10.0,,22 Dec 2008,,,IEEE,IEEE Magazines
678,679,Portability: Goodies vs. the Hair Shirt,D. Spinellis,Athens University of Economics and Business,IEEE Software,26 Jun 2013,2013,30,4,22,23,"Deciding whether to write portable code or not should be the outcome of a cost-benefit analysis. The key reason to favor portable code is that it opens up the selection of resources available to our project. Diverse technology choices free us from vendor lock-in, allowing us to select the best technology in each area based on quality and price, and minimize technology risks. However, portable code can degrade functionality, expressiveness, and efficiency. A middle course involves drawing boundaries around the non-portable code to isolate it from the rest of the application. Another approach is to admit defeat and write code that gives the best native experience. In the long term, separately maintained code bases can be less complex than a unified one. The Web extra at http://youtu.be/Lgqu_9Kc2Sc is an audio podcast of author Diomidis Spinellis reading his Tools of the Trade column, in which he discusses how whether to write portable code or not should be the outcome of a cost-benefit analysis.",1937-4194,,10.1109/MS.2013.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547638,portability;platform-specific;compatibility;standards,Software development;Encoding;Software design;Software architecture;Software engineering,,,,,,,,26 Jun 2013,,,IEEE,IEEE Magazines
679,680,Short and Winding Road: Software in Car Navigation Systems,H. Schaminée; H. Aerts,TomTom's Business Unit Automotive; TomTom's Business Unit Automotive,IEEE Software,23 Jun 2011,2011,28,4,19,21,"Car navigation started as an embedded product in expensive cars. Then it became an independent box, sold aftermarket. The volume that companies like TomTom have been able to accumulate now allows them to pursue the automotive original equipment manufacturers market.",1937-4194,,10.1109/MS.2011.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929524,innovation speed;car navigation;agile;buffer management,Automotive engineering;Navigation;Traffic control;Risk management;Software engineering,automobile industry;computerised navigation;road vehicles;traffic engineering computing,car navigation system;TomTom company;automotive equipment manufacturers market,,7.0,,5.0,,23 Jun 2011,,,IEEE,IEEE Magazines
680,681,Tool Building on the Shoulders of Others,H. M. Kienle; A. Kuhn; K. Mens; M. van den Brand; R. Wuyts,University of Victoria; University of Bern; Université catholique de Louvain-la-Neuve; Eindhoven University of Technology; IMEC,IEEE Software,22 Dec 2008,2009,26,1,22,23,"At the first International Workshop on Advanced Software Development Tools and Techniques, four emerging trends in academic tool building were evident. First, tools are increasingly constructed on the basis of external code, reusing, for instance, existing frameworks and integrated development environments. Second, researchers often choose dynamic languages such as Smalltalk to implement prototype tools. Third, Web-based tools are starting to incorporate Web 2.0 technologies to improve user interaction. Finally, increasing computational resources allow tools to tackle larger, real-world code bases.",1937-4194,,10.1109/MS.2009.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721178,tool building;reuse;dynamic languages;Web-based user interfaces;scalability,Java;Software engineering;Visualization;Design engineering;Software prototyping;Object oriented programming;Software tools;Object oriented modeling;User interfaces;Libraries,human computer interaction;Internet;resource allocation;Smalltalk;software reusability;software tools,software development tool;academic tool building;software reusing;Web-based tool;Web 2.0 technology;user interaction;dynamic language;Smalltalk;computational resource,,2.0,,,,22 Dec 2008,,,IEEE,IEEE Magazines
681,682,Reengineering Technologies,R. Perez-Castillo; I. G. d. Guzman; M. Piattini; C. Ebert,NA; NA; NA; NA,IEEE Software,20 Oct 2011,2011,28,6,13,17,"Software systems must continually evolve to meet ever changing needs. However, such systems often become legacy systems as a consequence of uncontrolled maintenance combined with obsolete technology. To control maintenance costs and preserve complex embedded business rules, companies must evolve their legacy systems. This article introduces technologies for software reengineering.",1937-4194,,10.1109/MS.2011.145,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6055657,reengineering;reengineering tools;modernization;ADM;legacy system,Software engineering;Business process re-engineering;Legacy systems,software cost estimation;software maintenance,software systems;software evolution;legacy systems;uncontrolled software maintenance;obsolete technology;maintenance cost control;complex embedded business rules;software reengineering,,8.0,,5.0,,20 Oct 2011,,,IEEE,IEEE Magazines
682,683,Formal Modeling and Verification of Safety-Critical Software,J. Yoo; E. Jee; S. Cha,Konkuk University; Korea Advanced Institute of Science and Technology; Korea University,IEEE Software,17 Apr 2009,2009,26,3,42,49,"Rigorous quality demonstration is important when developing safety-critical software such as a reactor protection system (RPS) for a nuclear power plant. Although using formal methods such as formal modeling and verification is strongly recommended, domain experts often reject formal methods for four reasons: there are too many candidate techniques, the notations appear complex, the tools often work only in isolation, and output is often too difficult for domain experts to understand. A formal-methods-based process that supports development, verification and validation, and safety analysis can help domain experts overcome these obstacles. Nuclear engineers can also use CASE tools to apply formal methods without having to know details of the underlying formalism. The authors spent more than seven years working with nuclear engineers in developing RPS software and applying formal methods. The engineers and regulatory personnel found the process effective and easy to apply with the integrated tool support.",1937-4194,,10.1109/MS.2009.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814957,modeling;verification;safety-critical software;formal methods;function block diagram (FBD),Software safety;Programmable control;Failure analysis;US Department of Transportation;Computer aided software engineering;Logic testing;Embedded software;Software tools;Software testing;Control systems,formal verification;nuclear power stations;power engineering computing;safety-critical software,safety-critical software;formal modeling;formal verification;reactor protection system;nuclear power plant;formal methods;safety analysis;CASE tools,,25.0,1.0,12.0,,17 Apr 2009,,,IEEE,IEEE Magazines
683,684,Tests: The Architect's Best Friend,F. Buschmann,Siemens Corporate Technology,IEEE Software,25 Apr 2011,2011,28,3,7,9,"When explicitly considering the testability of software-centric systems, architects tend to be more conscious and thoughtful about their design decisions, be they related to modularization, interfaces, or design choices. The paper discusses how architects can use tests and test-driven development as a design tool. The goal is to avoid or discover architectural deficiencies before they're realized-when they're less costly to correct.",1937-4194,,10.1109/MS.2011.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756289,test-driven development;testability;design for testability,Computer architecture;Software engineering;Legged locomotion;Programming;Testing;Feedback loop,program testing;software architecture,software-centric system testability;design decisions;design choice;design modularization;design interface;test-driven development,,3.0,,6.0,,25 Apr 2011,,,IEEE,IEEE Magazines
684,685,A Business Case for Feature-Oriented Requirements Engineering,A. Rudorfer; T. Stenzel; G. Herold,Siemens Healthcare Diagnostics; Siemens Healthcare; Siemens Healthcare,IEEE Software,21 Aug 2012,2012,29,5,54,59,"Owing to strong market growth for medical devices deployed in critical-care facilities, development organizations in medical engineering must continually look for opportunities to drive engineering efficiency and cost effectiveness. Furthermore, cycle time must decrease, the alignment of clinical workflow is breaking down departmental barriers, and an increased amount of product functionality is being realized in software. To help meet such challenges, adequate requirements engineering is necessary. Toward that end, Syngo (a business unit of the Imaging and Therapy division of Siemens) introduced Feature-Oriented Requirements Engineering (FORE) and developed a business case for using it in the context of a lean engineering program. FORE integrates with other engineering disciplines such as project management, software architecture, and test management. There was an error in the biographical information for Tobias Stenzel. Stenzel's biography should have indicated that he has an MS in industrial engineering and management from the University of Technology Karlsruhe, Germany.",1937-4194,,10.1109/MS.2012.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226342,requirements engineering;business case;software platform development;business benefits;lean software development;software development,Business;Medical diagnostic imaging;Software management;Medical treatment;Software engineering;Product life cycle management;Software development;Agile manufacturing,formal specification;medical computing;software architecture,feature-oriented requirements engineering;medical devices;critical-care facilities;medical engineering;development organization;clinical workflow alignment;product functionality;Syngo;business unit;FORE;lean engineering program;project management;software architecture;test management;biographical information;University of Technology Karlsruhe;Germany;industrial engineering and management;therapy division;imaging division,,1.0,,7.0,,26 Jun 2012,,,IEEE,IEEE Magazines
685,686,Guest Editors' Introduction: Mining Software Archives,N. Nagappan; A. Zeller; T. Zimmermann,Microsoft Research; Saarland University; Microsoft Research,IEEE Software,22 Dec 2008,2009,26,1,24,25,"Modern programming environments automatically collect lots of data on software development, notably changes and defects. The field of mining software archives is concerned with the automated extraction, collection, and abstraction of information from this data. This is the introduction to a special issue of IEEE Software presenting a selection of the exciting research that is taking place in the field.",1937-4194,,10.1109/MS.2009.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721179,programming environments;construction tools;distribution;maintenance;and enhancement;configuration management;data mining,Software quality;Software maintenance;Programming environments;History;Social network services;Collaborative software;Software engineering;Costs;Humans;Environmental management,,,,1.0,,,,22 Dec 2008,,,IEEE,IEEE Magazines
686,687,Mobile Web Apps,N. Serrano; J. Hernantes; G. Gallardo,University of Navarra; University of Navarra; University of Navarra,IEEE Software,3 Sep 2013,2013,30,5,22,27,"With smartphones being the primary handheld device for more than a billion people, mobile Web apps are a necessity in both technical and commercial fields. There are several approaches to developing mobile Web apps, but given the fast speed of mobile software evolution, in which the leading companies become marginal in months and new gadgets continually appear, it's crucial to understand the basic technologies. Authors Nicolás Serrano, Josune Hernantes, and Gorka Gallardo examine current development approaches that can enhance the decision-making process.",1937-4194,,10.1109/MS.2013.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6588524,mobile Web;apps;mobile Web apps;applications;mobile applications;mobile Web applications;software technology;mobile apps,Mobile communication;Cascading style sheets;Browsers;Software engineering;Mobile handsets;Computer applications,decision making;Internet;mobile computing;smart phones,mobile Web apps;smartphones;handheld device;mobile software evolution;decision-making process,,32.0,2.0,3.0,,3 Sep 2013,,,IEEE,IEEE Magazines
687,688,ReqIF: Seamless Requirements Interchange Format between Business Partners,C. Ebert; M. Jastram,Vector Consulting Services; Formal Mind GmbH,IEEE Software,21 Aug 2012,2012,29,5,82,87,"The primary sources of project risks and product problems are poor, missing, or changing requirements. Often, the underlying root cause is insufficient collaboration between business partners. This article provides insight into how to effectively collaborate in requirements engineering. We describe the Requirements Interchange Format (ReqIF) standard and technologies for seamless requirements development and management. I look forward to hearing from both readers and prospective column authors about this and the technologies and tools you want to know more about.",1937-4194,,10.1109/MS.2012.121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6276299,software technology;ReqIF;requirements engineering,Software engineering;Software management;Standards,business data processing;project management;risk management;software development management;systems analysis,seamless requirements interchange format;business partners;project risks;changing requirements;poor requirements;missing requirements;root cause;insufficient collaboration;requirements engineering;ReqIF standard;seamless requirements development;seamless requirements management,,11.0,,6.0,,21 Aug 2012,,,IEEE,IEEE Magazines
688,689,Discovering Services during Service-Based System Design Using UML,G. Spanoudakis; A. Zisman,"City University, London; City University, London",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,371,389,"Recently, there has been a proliferation of service-based systems, i.e., software systems that are composed of autonomous services but can also use software code. In order to support the development of these systems, it is necessary to have new methods, processes, and tools. In this paper, we describe a UML-based framework to assist with the development of service-based systems. The framework adopts an iterative process in which software services that can provide functional and nonfunctional characteristics of a system being developed are discovered, and the identified services are used to reformulate the design models of the system. The framework uses a query language to represent structural, behavioral, and quality characteristics of services to be identified, and a query processor to match the queries against service registries. The matching process is based on distance measurements between the queries and service specifications. A prototype tool has been implemented. The work has been evaluated in terms of recall, precision, and performance measurements.",1939-3520,,10.1109/TSE.2009.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5374424,Design notations and documentation;software process models;search discovery language;service discovery engine.,Unified modeling language;Software systems;Database languages;Quality of service;Computer Society;Distance measurement;Software prototyping;Prototypes;Documentation;Engines,pattern matching;query languages;query processing;software prototyping;Unified Modeling Language;Web services,service-based system design;software systems;software code;UML-based framework;iterative process;software services;query processor;matching process;distance measurements;query language,,31.0,1.0,60.0,,8 Jan 2010,,,IEEE,IEEE Journals
689,690,Recomputing Coverage Information to Assist Regression Testing,P. K. Chittimalli; M. J. Harrold,"Tata Research Development & Design Centre, India; Georgia Institute of Technology, Atlanta",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,452,469,"This paper presents a technique that leverages an existing regression test selection algorithm to compute accurate, updated coverage data on a version of the software, Pi+1, without rerunning any test cases that do not execute the changes from the previous version of the software, Pi to Pi+1. The technique also reduces the cost of running those test cases that are selected by the regression test selection algorithm by performing a selective instrumentation that reduces the number of probes required to monitor the coverage data. Users of our technique can avoid the expense of rerunning the entire test suite on Pi+1 or the inaccuracy produced by previous approaches that estimate coverage data for Pi+1 or that reuse outdated coverage data from Pi. This paper also presents a tool, RECOVER, that implements our technique, along with a set of empirical studies on a set of subjects that includes several industrial programs, versions, and test cases. The studies show the inaccuracies that can exist when an application-regression test selection-uses estimated or outdated coverage data. The studies also show that the overhead incurred by selective instrumentation used in our technique is negligible and overall our technique provides savings over earlier techniques.",1939-3520,,10.1109/TSE.2009.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4760153,Regression testing;regression test selection;testing;maintenance.,Software testing;Costs;Performance evaluation;Instruments;Software quality;Software algorithms;Probes;Monitoring;Software performance;Error correction,program testing;regression analysis,coverage information;regression testing;software testing;industrial programs,,31.0,,16.0,,23 Jan 2009,,,IEEE,IEEE Journals
690,691,The Effects of Test-Driven Development on External Quality and Productivity: A Meta-Analysis,Y. Rafique; V. B. Mišić,"Ryerson University, Toronto; Ryerson University, Toronto",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,835,856,"This paper provides a systematic meta-analysis of 27 studies that investigate the impact of Test-Driven Development (TDD) on external code quality and productivity. The results indicate that, in general, TDD has a small positive effect on quality but little to no discernible effect on productivity. However, subgroup analysis has found both the quality improvement and the productivity drop to be much larger in industrial studies in comparison with academic studies. A larger drop of productivity was found in studies where the difference in test effort between the TDD and the control group's process was significant. A larger improvement in quality was also found in the academic studies when the difference in test effort is substantial; however, no conclusion could be derived regarding the industrial studies due to the lack of data. Finally, the influence of developer experience and task size as moderator variables was investigated, and a statistically significant positive correlation was found between task size and the magnitude of the improvement in quality.",1939-3520,,10.1109/TSE.2012.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197200,Test-driven development;meta-analysis;code quality;programmer productivity;agile software development,Productivity;Computational modeling;Testing;Process control;Programming;Size measurement,program testing;software development management;software quality,test driven development;systematic meta analysis;code quality;code productivity;TDD;subgroup analysis;quality improvement,,55.0,,71.0,,8 May 2012,,,IEEE,IEEE Journals
691,692,Service-Level Agreements for Electronic Services,J. Skene; F. Raimondi; W. Emmerich,"The University of Auckland, Auckland; Middlesex University, London; University College London, London",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,288,304,"The potential of communication networks and middleware to enable the composition of services across organizational boundaries remains incompletely realized. In this paper, we argue that this is in part due to outsourcing risks and describe the possible contribution of Service-Level Agreements (SLAs) to mitigating these risks. For SLAs to be effective, it should be difficult to disregard their original provisions in the event of a dispute between the parties. Properties of understandability, precision, and monitorability ensure that the original intent of an SLA can be recovered and compared to trustworthy accounts of service behavior to resolve disputes fairly and without ambiguity. We describe the design and evaluation of a domain-specific language for SLAs that tend to exhibit these properties and discuss the impact of monitorability requirements on service-provision practices.",1939-3520,,10.1109/TSE.2009.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5210121,Service-level agreements;electronic services;contracts;domain-specific languages;model-driven engineering.,Outsourcing;Cloud computing;Consumer electronics;Middleware;Service oriented architecture;Domain specific languages;Distributed computing;Computer Society;Communication networks;Monitoring,client-server systems;high level languages;Internet;outsourcing,service level agreements;electronic services;communication networks;middleware;outsourcing risks;SLA;domain specific language,,24.0,1.0,44.0,,21 Aug 2009,,,IEEE,IEEE Journals
692,693,DEC: Service Demand Estimation with Confidence,A. Kalbasi; D. Krishnamurthy; J. Rolia; S. Dawson,"University of Calgary, Calgary; University of Calgary, Calgary; Hewlett Packard Labs, Bristol; SAP Research Center Belfast, Belfast",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,561,578,"We present a new technique for predicting the resource demand requirements of services implemented by multitier systems. Accurate demand estimates are essential to ensure the efficient provisioning of services in an increasingly service-oriented world. The demand estimation technique proposed in this paper has several advantages compared with regression-based demand estimation techniques, which many practitioners employ today. In contrast to regression, it does not suffer from the problem of multicollinearity, it provides more reliable aggregate resource demand and confidence interval predictions, and it offers a measurement-based validation test. The technique can be used to support system sizing and capacity planning exercises, costing and pricing exercises, and to predict the impact of changes to a service upon different service customers.",1939-3520,,10.1109/TSE.2011.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728829,Benchmarking;resource demand prediction;statistical regression.,Benchmark testing;Equations;Software;Mathematical model;Estimation;Frequency modulation;Computers,multiprocessing systems;regression analysis;service-oriented architecture,DEC;service demand estimation technique;resource demand requirements;multitier systems;service-oriented world;regression-based demand estimation techniques;multicollinearity;system sizing;capacity planning,,23.0,,33.0,,10 Mar 2011,,,IEEE,IEEE Journals
693,694,STAR: Stack Trace Based Automatic Crash Reproduction via Symbolic Execution,N. Chen; S. Kim,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong",IEEE Transactions on Software Engineering,10 Feb 2015,2015,41,2,198,220,"Software crash reproduction is the necessary first step for debugging. Unfortunately, crash reproduction is often labor intensive. To automate crash reproduction, many techniques have been proposed including record-replay and post-failure-process approaches. Record-replay approaches can reliably replay recorded crashes, but they incur substantial performance overhead to program executions. Alternatively, post-failure-process approaches analyse crashes only after they have occurred. Therefore they do not incur performance overhead. However, existing post-failure-process approaches still cannot reproduce many crashes in practice because of scalability issues and the object creation challenge. This paper proposes an automatic crash reproduction framework using collected crash stack traces. The proposed approach combines an efficient backward symbolic execution and a novel method sequence composition approach to generate unit test cases that can reproduce the original crashes without incurring additional runtime overhead. Our evaluation study shows that our approach successfully exploited 31 (59.6 percent) of 52 crashes in three open source projects. Among these exploitable crashes, 22 (42.3 percent) are useful reproductions of the original crashes that reveal the crash triggering bugs. A comparison study also demonstrates that our approach can effectively outperform existing crash reproduction approaches.",1939-3520,,10.1109/TSE.2014.2363469,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926857,Crash reproduction;static analysis;symbolic execution;test case generation;optimization;Crash reproduction;static analysis;symbolic execution;test case generation;optimization,Computer crashes;Arrays;Indexes;Color;Optimization;Explosions;Software,program debugging;program testing;project management;public domain software;system recovery,STAR;stack trace based automatic crash reproduction;software crash reproduction;debugging;record-replay approach;post-failure-process approach;scalability issues;object creation challenge;crash stack traces;backward symbolic execution;method sequence composition approach;unit test case generation;open source projects,,24.0,,64.0,,16 Oct 2014,,,IEEE,IEEE Journals
694,695,Exploiting the Essential Assumptions of Analogy-Based Effort Estimation,E. Kocaguneli; T. Menzies; A. Bener; J. W. Keung,"West Virginia University, Morgantown; West Virginia University, Morgantown; Ryerson University, Toronto; The Hong Kong Polytechnic University, Hong Kong",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,425,438,"Background: There are too many design options for software effort estimators. How can we best explore them all? Aim: We seek aspects on general principles of effort estimation that can guide the design of effort estimators. Method: We identified the essential assumption of analogy-based effort estimation, i.e., the immediate neighbors of a project offer stable conclusions about that project. We test that assumption by generating a binary tree of clusters of effort data and comparing the variance of supertrees versus smaller subtrees. Results: For 10 data sets (from Coc81, Nasa93, Desharnais, Albrecht, ISBSG, and data from Turkish companies), we found: 1) The estimation variance of cluster subtrees is usually larger than that of cluster supertrees; 2) if analogy is restricted to the cluster trees with lower variance, then effort estimates have a significantly lower error (measured using MRE, AR, and Pred(25) with a Wilcoxon test, 95 percent confidence, compared to nearest neighbor methods that use neighborhoods of a fixed size). Conclusion: Estimation by analogy can be significantly improved by a dynamic selection of nearest neighbors, using only the project data from regions with small variance.",1939-3520,,10.1109/TSE.2011.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728833,Software cost estimation;analogy;k-NN.,Estimation;Training;Software;Training data;Linear regression;Euclidean distance;Humans,pattern clustering;program testing;project management;software cost estimation;trees (mathematics),analogy-based effort estimation;software effort estimator design;essential assumption;supertree variance;subtree variance;Coc81 data set;Nasa93 data set;Desharnais data set;Albrecht data set;ISBSG data set;Turkish companies;estimation variance;binary cluster tree;cluster subtrees;dynamic selection;nearest neighbor selection;project data,,106.0,,69.0,,10 Mar 2011,,,IEEE,IEEE Journals
695,696,Event Logs for the Analysis of Software Failures: A Rule-Based Approach,M. Cinque; D. Cotroneo; A. Pecchia,"Universitá degli Studi di Napoli Federico II, Naples; Universitá degli Studi di Napoli Federico II, Naples; Universitá degli Studi di Napoli Federico II, Naples",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,806,821,"Event logs have been widely used over the last three decades to analyze the failure behavior of a variety of systems. Nevertheless, the implementation of the logging mechanism lacks a systematic approach and collected logs are often inaccurate at reporting software failures: This is a threat to the validity of log-based failure analysis. This paper analyzes the limitations of current logging mechanisms and proposes a rule-based approach to make logs effective to analyze software failures. The approach leverages artifacts produced at system design time and puts forth a set of rules to formalize the placement of the logging instructions within the source code. The validity of the approach, with respect to traditional logging mechanisms, is shown by means of around 12,500 software fault injection experiments into real-world systems.",1939-3520,,10.1109/TSE.2012.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6320555,Event log;logging mechanism;rule-based logging;error detection;software failures,Unified modeling language;Failure analysis;Analytical models;Systematics;Proposals;Software systems,software fault tolerance,event logs;software failures;rule-based approach;logging mechanism;log-based failure analysis;system design time,,37.0,,52.0,,3 Oct 2012,,,IEEE,IEEE Journals
696,697,A large-scale empirical study of just-in-time quality assurance,Y. Kamei; E. Shihab; B. Adams; A. E. Hassan; A. Mockus; A. Sinha; N. Ubayashi,"Kyushu University, Fukuoka; Rochester Institute of Technology, Rochester; École Polytechnique de Montréal, Montréal; Queen's University, Kingston; Avaya Labs Research, Basking Ridge; Research In Motion, Waterloo; Kyushu University, Fukuoka",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,757,773,"Defect prediction models are a well-known technique for identifying defect-prone files or packages such that practitioners can allocate their quality assurance efforts (e.g., testing and code reviews). However, once the critical files or packages have been identified, developers still need to spend considerable time drilling down to the functions or even code snippets that should be reviewed or tested. This makes the approach too time consuming and impractical for large software systems. Instead, we consider defect prediction models that focus on identifying defect-prone (“risky”) software changes instead of files or packages. We refer to this type of quality assurance activity as “Just-In-Time Quality Assurance,” because developers can review and test these risky changes while they are still fresh in their minds (i.e., at check-in time). To build a change risk model, we use a wide range of factors based on the characteristics of a software change, such as the number of added lines, and developer experience. A large-scale study of six open source and five commercial projects from multiple domains shows that our models can predict whether or not a change will lead to a defect with an average accuracy of 68 percent and an average recall of 64 percent. Furthermore, when considering the effort needed to review changes, we find that using only 20 percent of the effort it would take to inspect all changes, we can identify 35 percent of all defect-inducing changes. Our findings indicate that “Just-In-Time Quality Assurance” may provide an effort-reducing way to focus on the most risky changes and thus reduce the costs of developing high-quality software.",1939-3520,,10.1109/TSE.2012.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6341763,Maintenance;software metrics;mining software repositories;defect prediction;just-in-time prediction,Measurement;Quality assurance;Predictive models;Software;Entropy;Object oriented modeling;Accuracy,program testing;software maintenance;software metrics;software quality,just-in-time quality assurance;defect prediction models;defect-prone file identification;defect-prone package identification;software systems;risk model;open source projects;commercial projects;risky changes;cost reduction;defect-prone software change identification;software metrics;software repository mining;software quality assurance activities;source code inspection;unit testing,,167.0,1.0,63.0,,10 Nov 2012,,,IEEE,IEEE Journals
697,698,Plat_Forms: A Web Development Platform Comparison by an Exploratory Experiment Searching for Emergent Platform Properties,L. Prechelt,"Freie Universität Berlin, Berlin",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,95,108,"Background: For developing Web-based applications, there exist several competing and widely used technological platforms (consisting of a programming language, framework(s), components, and tools), each with an accompanying development culture and style. Research question: Do Web development projects exhibit emergent process or product properties that are characteristic and consistent within a platform, but show relevant substantial differences across platforms or do team-to-team individual differences outweigh such differences, if any? Such a property could be positive (i.e., a platform advantage), negative, or neutral, and it might be unobvious which is which. Method: In a nonrandomized, controlled experiment, framed as a public contest called “Plat_Forms,” top-class teams of three professional programmers competed to implement the same requirements for a Web-based application within 30 hours. Three different platforms (Java EE, PHP, or Perl) were used by three teams each. We compare the resulting nine products and process records along many dimensions, both external (usability, functionality, reliability, security, etc.) and internal (size, structure, modifiability, etc.). Results: The various results obtained cover a wide spectrum: First, there are results that many people would have called “obvious” or “well known,” say, that Perl solutions tend to be more compact than Java solutions. Second, there are results that contradict conventional wisdom, say, that our PHP solutions appear in some (but not all) respects to be actually at least as secure as the others. Finally, one result makes a statement we have not seen discussed previously: Along several dimensions, the amount of within-platform variation between the teams tends to be smaller for PHP than for the other platforms. Conclusion: The results suggest that substantial characteristic platform differences do indeed exist in some dimensions, but possibly not in others.",1939-3520,,10.1109/TSE.2010.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406528,Emergent properties;usability;functionality;reliability;security;product size;design structure;modifiability;Java;PHP;Perl.,Java;Computer languages;Usability;Security;Libraries;Programming profession;Product design;Buildings;Cascading style sheets;Ecosystems,emergent phenomena;Internet;Java;Perl;Web design,Web development platform;emergent platform properties;Web based applications;Java EE;Perl solutions;PHP solutions,,7.0,,26.0,,5 Feb 2010,,,IEEE,IEEE Journals
698,699,Automated Oracle Data Selection Support,G. Gay; M. Staats; M. Whalen; M. P. E. Heimdahl,"Department of Computer Science & Engineering, University of South Carolina; Google, Inc.; Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota",IEEE Transactions on Software Engineering,10 Nov 2015,2015,41,11,1119,1137,"The choice of test oracle-the artifact that determines whether an application under test executes correctly-can significantly impact the effectiveness of the testing process. However, despite the prevalence of tools that support test input selection, little work exists for supporting oracle creation. We propose a method of supporting test oracle creation that automatically selects the oracle data-the set of variables monitored during testing-for expected value test oracles. This approach is based on the use of mutation analysis to rank variables in terms of fault-finding effectiveness, thus automating the selection of the oracle data. Experimental results obtained by employing our method over six industrial systems (while varying test input types and the number of generated mutants) indicate that our method-when paired with test inputs generated either at random or to satisfy specific structural coverage criteria-may be a cost-effective approach for producing small, effective oracle data sets, with fault finding improvements over current industrial best practice of up to 1,435 percent observed (with typical improvements of up to 50 percent).",1939-3520,,10.1109/TSE.2015.2436920,"NASA; NSF; US National Science Foundation (NSF); Fonds National de la Recherche, Luxembourg; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7112189,Testing;Test Oracles;Oracle Data;Oracle Selection;Verification;Testing;test oracles;oracle data;oracle selection;verification,Testing;Monitoring;Software;Aerospace electronics;Training;Electronic mail;Computer crashes,program testing;program verification,automated oracle data selection support;mutation analysis;software testing;test oracle;oracle creation;specific structural coverage criteria,,9.0,,40.0,,22 May 2015,,,IEEE,IEEE Journals
699,700,Size-Constrained Regression Test Case Selection Using Multicriteria Optimization,S. Mirarab; S. Akhlaghi; L. Tahvildari,"University of Texas at Austin, Austin; Shahed University, Tehran; University of Waterloo, Waterloo",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,936,956,"To ensure that a modified software system has not regressed, one approach is to rerun existing test cases. However, this is a potentially costly task. To mitigate the costs, the testing effort can be optimized by executing only a selected subset of the test cases that are believed to have a better chance of revealing faults. This paper proposes a novel approach for selecting and ordering a predetermined number of test cases from an existing test suite. Our approach forms an Integer Linear Programming problem using two different coverage-based criteria, and uses constraint relaxation to find many close-to-optimal solution points. These points are then combined to obtain a final solution using a voting mechanism. The selected subset of test cases is then prioritized using a greedy algorithm that maximizes minimum coverage in an iterative manner. The proposed approach has been empirically evaluated and the results show significant improvements over existing approaches for some cases and comparable results for the rest. Moreover, our approach provides more consistency compared to existing approaches.",1939-3520,,10.1109/TSE.2011.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928351,Software regression testing;test case selection;integer programming;Pareto optimality,Testing;Software;Time factors;Fault detection;Optimization;Estimation;IP networks,greedy algorithms;integer programming;linear programming;program testing;regression analysis,size constrained regression test case selection;multicriteria optimization;modified software system;integer linear programming problem;voting mechanism;greedy algorithm;iterative manner,,39.0,,61.0,,23 Jun 2011,,,IEEE,IEEE Journals
700,701,A Lightweight System for Detecting and Tolerating Concurrency Bugs,M. Zhang; Y. Wu; S. Lu; S. Qi; J. Ren; W. Zheng,"Tsinghua National Laboratory for Information Science and Technology (TNLIST), the Department of Computer Science and Technology, Tsinghua University, Beijing, China; Tsinghua National Laboratory for Information Science and Technology (TNLIST), the Department of Computer Science and Technology, Tsinghua University, Beijing, China; University of Chicago, Chicago, IL; UBER growth team, San Francisco, CA; Tsinghua National Laboratory for Information Science and Technology (TNLIST), the Department of Computer Science and Technology, Tsinghua University, Beijing, China; Tsinghua National Laboratory for Information Science and Technology (TNLIST), the Department of Computer Science and Technology, Tsinghua University, Beijing, China",IEEE Transactions on Software Engineering,13 Oct 2016,2016,42,10,899,917,"Along with the prevalence of multi-threaded programs, concurrency bugs have become one of the most important sources of software bugs. Even worse, due to the non-deterministic nature of concurrency bugs, these bugs are both difficult to detect and fix even after the detection. As a result, it is highly desired to develop an all-around approach that is able to not only detect them during the testing phase but also tolerate undetected bugs during production runs. However, existing bug-detecting and bug-tolerating tools are usually either 1) constrained in types of bugs they can handle or 2) requiring specific hardware supports for achieving an acceptable overhead. In this paper, we present a novel program invariant, name Anticipating Invariant (Ai), that can detect most types of concurrency bugs. More importantly, Ai can be used to anticipate many concurrency bugs before any irreversible changes have been made. Thus it enables us to develop a software-only system that is able to forestall failures with a simple thread stalling technique, which does not rely on execution roll-back and hence has good performance. Experiments with 35 real-world concurrency bugs demonstrate that Ai is capable of detecting and tolerating many important types of concurrency bugs, including both atomicity and order violations. It has also exposed two new bugs (confirmed by developers) that were never reported before in the literature. Performance evaluation with 6 representative parallel programs shows that Ai incurs negligible overhead ( $ < 1\%$ ) for many nontrivial desktop and server applications.",1939-3520,,10.1109/TSE.2016.2531666,Natural Science Foundation of China; National Basic Research (973) Program of China; National High-Tech R&D (863) Program of China; Chinese Special Project of Science and Technology; US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7412768,Concurrency bugs;software reliability;bug tolerating,Computer bugs;Concurrent computing;Artificial intelligence;Turning;Testing;Hardware,,,,4.0,,67.0,,18 Feb 2016,,,IEEE,IEEE Journals
701,702,Language-Independent and Automated Software Composition: The FeatureHouse Experience,S. Apel; C. Kästner; C. Lengauer,"University of Passau, Passau; Philipps University Marburg, Marburg; University of Passau, Passau",IEEE Transactions on Software Engineering,13 Feb 2013,2013,39,1,63,79,"Superimposition is a composition technique that has been applied successfully in many areas of software development. Although superimposition is a general-purpose concept, it has been (re)invented and implemented individually for various kinds of software artifacts. We unify languages and tools that rely on superimposition by using the language-independent model of feature structure trees (FSTs). On the basis of the FST model, we propose a general approach to the composition of software artifacts written in different languages. Furthermore, we offer a supporting framework and tool chain, called FEATUREHOUSE. We use attribute grammars to automate the integration of additional languages. In particular, we have integrated Java, C#, C, Haskell, Alloy, and JavaCC. A substantial number of case studies demonstrate the practicality and scalability of our approach and reveal insights into the properties that a language must have in order to be ready for superimposition. We discuss perspectives of our approach and demonstrate how we extended FEATUREHOUSE with support for XML languages (in particular, XHTML, XMI/UML, and Ant) and alternative composition approaches (in particular, aspect weaving). Rounding off our previous work, we provide here a holistic view of the FEATUREHOUSE approach based on rich experience with numerous languages and case studies and reflections on several years of research.",1939-3520,,10.1109/TSE.2011.120,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095570,FeatureHouse;feature structure trees;software composition;superimposition;language independence,Software;Java;Grammar;Databases;Printers;Latches;Unified modeling language,attribute grammars;C++ language;Java;software tools;Unified Modeling Language;XML,language-independent software composition;automated software composition;FEATUREHOUSE;superimposition;software development;general-purpose concept;language-independent model;feature structure tree;software artifact composition;supporting framework;tool chain;attribute grammar;integrated Java;C#;Haskell;Alloy;JavaCC;XML language;XHTML;XMI/UML;Ant,,35.0,,67.0,,6 Dec 2011,,,IEEE,IEEE Journals
702,703,On the Asymptotic Behavior of Adaptive Testing Strategy for Software Reliability Assessment,J. Lv; B. Yin; K. Cai,"School of Automation Science and Electrical Engineering, Bejing, China; School of Automation Science and Electrical Engineering, Bejing, China; School of Automation Science and Electrical Engineering, Bejing, China",IEEE Transactions on Software Engineering,2 May 2014,2014,40,4,396,412,"In software reliability assessment, one problem of interest is how to minimize the variance of reliability estimator, which is often considered as an optimization goal. The basic idea is that an estimator with lower variance makes the estimates more predictable and accurate. Adaptive Testing (AT) is an online testing strategy, which can be adopted to minimize the variance of software reliability estimator. In order to reduce the computational overhead of decision-making, the implemented AT strategy in practice deviates from its theoretical design that guarantees AT's local optimality. This work aims to investigate the asymptotic behavior of AT to improve its global performance without losing the local optimality. To this end, a new AT strategy named Adaptive Testing with Gradient Descent method (AT-GD) is proposed. Theoretical analysis indicates that AT-GD, a locally optimal testing strategy, converges to the globally optimal solution as the assessment process proceeds. Simulation and experiments are set up to validate AT-GD's effectiveness and efficiency. Besides, sensitivity analysis of AT-GD is also conducted in this study.",1939-3520,,10.1109/TSE.2014.2310194,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6762895,Adaptive testing;operational profile;software reliability;testing strategy,Testing;Software reliability;Software;Global Positioning System;Aircraft;Reliability theory,decision making;gradient methods;optimisation;program testing;sensitivity analysis;software reliability,asymptotic behavior;adaptive testing strategy;software reliability assessment;optimization goal;online testing strategy;software reliability estimator;computational overhead reduction;decision-making;global performance improvement;adaptive testing with gradient descent method;AT-GD;locally optimal testing strategy;sensitivity analysis,,26.0,,35.0,,11 Mar 2014,,,IEEE,IEEE Journals
703,704,Input-Sensitive Profiling,E. Coppa; C. Demetrescu; I. Finocchi,"Department of Computer Science, Sapienza University of Rome, Italy; Department of Computer, Control, and Management Engineering, Sapienza University of Rome, Italy; Department of Computer Science, Sapienza University of Rome, Italy",IEEE Transactions on Software Engineering,12 Dec 2014,2014,40,12,1185,1205,"In this article we present a building block technique and a toolkit towards automatic discovery of workload-dependentperformance bottlenecks. From one or more runs of a program, our profiler automatically measures how the performance of individual routines scales as a function of the input size, yielding clues to their growth rate. The output of the profiler is, for each executed routine of the program, a set of tuples that aggregate performance costs by input size. The collected profiles can be used to produceperformance plots and derive trend functions by statistical curve fitting techniques. A key feature of our method is the ability toautomatically measure the size of the input given to a generic code fragment: to this aim, we propose an effective metric for estimating the input size of a routine and show how to compute it efficiently. We discuss several examples, showing that our approach can reveal asymptotic bottlenecks that other profilers may fail to detect and can provide useful characterizations of the workload and behavior of individual routines in the context of mainstream applications, yielding several code optimizations as well as algorithmic improvements. To prove the feasibility of our techniques, we implemented a Valgrind tool called aprof and performed an extensive experimentalevaluation on the SPEC CPU2006 benchmarks. Our experiments show that aprof delivers comparable performance to otherprominent Valgrind tools, and can generate informative plots even from single runs on typical workloads for mostalgorithmically-critical routines.",1939-3520,,10.1109/TSE.2014.2339825,"Italian Ministry of Education, University, and Research (MIUR); “AMANDA-Algorithmics for MAssive and Networked DAta”; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6858059,Performance profiling;asymptotic analysis;dynamic program analysis;instrumentation,Context modeling;Algorithm design and analysis;Market research;Benchmark testing,curve fitting;program diagnostics;software performance evaluation;software tools;statistical analysis,input-sensitive profiling;building block technique;automatic workload-dependent performance bottleneck discovery;growth rate;program executed routine;tuples;performance plots;statistical curve fitting techniques;generic code fragment;code optimizations;aprof;experimental evaluation;SPEC CPU2006 benchmarks;Valgrind tools,,9.0,,60.0,,17 Jul 2014,,,IEEE,IEEE Journals
704,705,NLP-KAOS for Systems Goal Elicitation: Smart Metering System Case Study,E. Casagrande; S. Woldeamlak; W. L. Woon; H. H. Zeineldin; D. Svetinovic,"Department of Electrical Engineering and Computer Science, Masdar Institute of Science and Technology, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Masdar Institute of Science and Technology, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Masdar Institute of Science and Technology, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Masdar Institute of Science and Technology, Abu Dhabi, UAE; Department of Electrical Engineering and Computer Science, Masdar Institute of Science and Technology, Abu Dhabi, UAE",IEEE Transactions on Software Engineering,9 Oct 2014,2014,40,10,941,956,"This paper presents a computational method that employs Natural Language Processing (NLP) and text mining techniques to support requirements engineers in extracting and modeling goals from textual documents. We developed a NLP-based goal elicitation approach within the context of KAOS goal-oriented requirements engineering method. The hierarchical relationships among goals are inferred by automatically building taxonomies from extracted goals. We use smart metering system as a case study to investigate the proposed approach. Smart metering system is an important subsystem of the next generation of power systems (smart grids). Goals are extracted by semantically parsing the grammar of goal-related phrases in abstracts of research publications. The results of this case study show that the developed approach is an effective way to model goals for complex systems, and in particular, for the research-intensive complex systems.",1939-3520,,10.1109/TSE.2014.2339811,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6857327,Requirements engineering;goal elicitation;NLP;data mining;bibliometrics,Data mining;Taxonomy;Ontologies;Data models;Natural language processing;Abstracts;Data collection,data mining;formal specification;natural language processing;smart meters,NLP-KAOS;systems goal elicitation;smart metering system case study;computational method;natural language processing;text mining techniques;requirements engineers;textual documents;NLP-based goal elicitation approach;KAOS goal-oriented requirements engineering method;hierarchical relationships;power systems;smart grids;goal-related phrases;research publications;complex systems,,22.0,,57.0,,16 Jul 2014,,,IEEE,IEEE Journals
705,706,Synthesis of Partial Behavior Models from Properties and Scenarios,S. Uchitel; G. Brunet; M. Chechik,"Imperial College London and FCEN-University of Buenos Aires; University of Toronto, Toronto; University of Toronto, Toronto",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,384,406,"Synthesis of behavior models from software development artifacts such as scenario-based descriptions or requirements specifications helps reduce the effort of model construction. However, the models favored by existing synthesis approaches are not sufficiently expressive to describe both universal constraints provided by requirements and existential statements provided by scenarios. In this paper, we propose a novel synthesis technique that constructs behavior models in the form of modal transition systems (MTS) from a combination of safety properties and scenarios. MTSs distinguish required, possible, and proscribed behavior, and their elaboration not only guarantees the preservation of the properties and scenarios used for synthesis but also supports further elicitation of new requirements.",1939-3520,,10.1109/TSE.2008.107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721439,Modal transition systems;merge;synthesis;partial behavior models.,Computer Society;Analytical models;Programming;Safety;Process design;Buildings;Animation;Upper bound;Educational institutions;Computer science,formal specification,partial behavior model;software development;modal transition system;safety properties,,80.0,,53.0,,22 Dec 2008,,,IEEE,IEEE Journals
706,707,Probabilistic Interface Automata,E. Pavese; V. Braberman; S. Uchitel,"Departamento de Computación, Universidad de Buenos Aires; Departamento de Computación, Universidad de Buenos Aires and CONICET; Departamento de Computación, Universidad de Buenos Aires; Imperial College London and CONICET",IEEE Transactions on Software Engineering,15 Sep 2016,2016,42,9,843,865,"System specifications have long been expressed through automata-based languages, which allow for compositional construction of complex models and enable automated verification techniques such as model checking. Automata-based verification has been extensively used in the analysis of systems, where they are able to provide yes/no answers to queries regarding their temporal properties. Probabilistic modelling and checking aim at enriching this binary, qualitative information with quantitative information, more suitable to approaches such as reliability engineering. Compositional construction of software specifications reduces the specification effort, allowing the engineer to focus on specifying individual component behaviour to then analyse the composite system behaviour. Compositional construction also reduces the validation effort, since the validity of the composite specification should be dependent on the validity of the components. These component models are smaller and thus easier to validate. Compositional construction poses additional challenges in a probabilistic setting. Numerical annotations of probabilistically independent events must be contrasted against estimations or measurements, taking care of not compounding this quantification with exogenous factors, in particular the behaviour of other system components. Thus, the validity of compositionally constructed system specifications requires that the validated probabilistic behaviour of each component continues to be preserved in the composite system. However, existing probabilistic automata-based formalisms do not support specification of non-deterministic and probabilistic component behaviour which, when observed through logics such as pCTL, is preserved in the composite system. In this paper we present a probabilistic extension to Interface Automata which preserves pCTL properties under probabilistic fairness by ensuring a probabilistic branching simulation between component and composite automata. The extension not only supports probabilistic behaviour but also allows for weaker prerequisites to interfacing composition, that supports delayed synchronisation that may be required because of internal component behaviour. These results are equally applicable as an extension to non-probabilistic Interface Automata.",1939-3520,,10.1109/TSE.2016.2527000,ANPCyT PICT; ANPCyT PICT; ANPCyT PICT; CONICET PIP; CONICET PIP; UBACYT; UBACYT; MEALS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7401103,Behaviour models;probability;interface automata;model checking,Probabilistic logic;Automata;Interconnected systems;Computational modeling;Model checking;Semantics;Synchronization,formal specification;probabilistic automata;program verification,probabilistic interface automata;system specifications;automata-based languages;compositional construction;complex models;automated verification techniques;model checking;automata-based verification;temporal properties;probabilistic modelling;probabilistic checking;binary qualitative information;quantitative information;reliability engineering;software specifications;component behaviour;composite system behaviour;numerical annotations;probabilistically independent events;exogenous factors;system components;compositionally constructed system specifications;nondeterministic behaviour;probabilistic component behaviour;pCTL;probabilistic fairness;probabilistic branching simulation;composite automata;component automata;internal component behaviour;nonprobabilistic interface automata,,,,42.0,,8 Feb 2016,,,IEEE,IEEE Journals
707,708,A Quantitative Investigation of the Acceptable Risk Levels of Object-Oriented Metrics in Open-Source Systems,R. Shatnawi,"Jordan University of Science and Technology, Irbid",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,216,225,"Object-oriented metrics have been validated empirically as measures of design complexity. These metrics can be used to mitigate potential problems in the software complexity. However, there are few studies that were conducted to formulate the guidelines, represented as threshold values, to interpret the complexity of the software design using metrics. Classes can be clustered into low and high risk levels using threshold values. In this paper, we use a statistical model, derived from the logistic regression, to identify threshold values for the Chidamber and Kemerer (CK) metrics. The methodology is validated empirically on a large open-source system-the Eclipse project. The empirical results indicate that the CK metrics have threshold effects at various risk levels. We have validated the use of these thresholds on the next release of the Eclipse project-Version 2.1-using decision trees. In addition, the selected threshold values were more accurate than those were selected based on either intuitive perspectives or on data distribution parameters. Furthermore, the proposed model can be exploited to find the risk level for an arbitrary threshold value. These findings suggest that there is a relationship between risk levels and object-oriented metrics and that risk levels can be used to identify threshold effects.",1939-3520,,10.1109/TSE.2010.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383377,Object-oriented programming;product metrics;CK metrics;threshold values;open-source software.,Open source software;Object oriented modeling;Software metrics;Software quality;Software testing;Software design;Predictive models;Quality assurance;Probability;Fault diagnosis,decision trees;object-oriented programming;public domain software;software fault tolerance;software maintenance;software metrics;statistical analysis,object-oriented metrics;open source systems;software complexity;software design;software metrics;statistical model;logistic regression;Chidamber and Kemerer metrics;Eclipse project version 2.1;decision trees;threshold values;data distribution parameters,,70.0,,49.0,,15 Jan 2010,,,IEEE,IEEE Journals
708,709,Two Studies of Framework-Usage Templates Extracted from Dynamic Traces,A. Heydarnoori; K. Czarnecki; W. Binder; T. T. Bartolomei,"University of Lugano, Lugano; University of Waterloo, Waterloo; University of Lugano, Lugano; University of Waterloo, Waterloo",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1464,1487,"Object-oriented frameworks are widely used to develop new applications. They provide reusable concepts that are instantiated in application code through potentially complex implementation steps such as subclassing, implementing interfaces, and calling framework operations. Unfortunately, many modern frameworks are difficult to use because of their large and complex APIs and frequently incomplete user documentation. To cope with these problems, developers often use existing framework applications as a guide. However, locating concept implementations in those sample applications is typically challenging due to code tangling and scattering. To address this challenge, we introduce the notion of concept-implementation templates, which summarize the necessary concept-implementation steps and identify them in the sample application code, and a technique, named FUDA, to automatically extract such templates from dynamic traces of sample applications. This paper further presents the results of two experiments conducted to evaluate the quality and usefulness of FUDA templates. The experimental evaluation of FUDA with 14 concepts in five widely used frameworks suggests that the technique is effective in producing templates with relatively few false positives and false negatives for realistic concepts by using two sample applications. Moreover, we observed in a user study with 28 programmers that the use of templates reduced the concept-implementation time compared to when documentation was used.",1939-3520,,10.1109/TSE.2011.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975174,Object-oriented application frameworks;framework comprehension;framework documentation;concept-implementation templates;application programming interface (API);dynamic analysis;concept location;feature identification,Dynamic programming;Feature extraction;Documentation;Java;Application programming interfaces;Runtime,application program interfaces;object-oriented methods,framework-usage template extraction;dynamic traces;object-oriented frameworks;application code;subclassing operation;interface implementation;calling framework operations;user documentation;code tangling;code scattering;concept-implementation templates;concept-implementation steps;FUDA templates;framework API understanding through dynamic analysis,,7.0,,68.0,,4 Aug 2011,,,IEEE,IEEE Journals
709,710,Analyzing the Effect of Gain Time on Soft-Task Scheduling Policies in Real-Time Systems,L. Búrdalo; A. Terrasa; A. Espinosa; A. García-Fornes,"Universitat Politèecnica de València, Valencia; Universitat Politèecnica de València, Valencia; Universitat Politèecnica de València, Valencia; Universitat Politèecnica de València, Valencia",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1305,1318,"In hard real-time systems, gain time is defined as the difference between the Worst Case Execution Time (WCET) of a hard task and its actual processor consumption at runtime. This paper presents the results of an empirical study about how the presence of a significant amount of gain time in a hard real-time system questions the advantages of using the most representative scheduling algorithms or policies for aperiodic or soft tasks in fixed-priority preemptive systems. The work presented here refines and complements many other studies in this research area in which such policies have been introduced and compared. This work has been performed by using the authors' testing framework for soft scheduling policies, which produces actual, synthetic, randomly generated applications, executes them in an instrumented Real-Time Operating System (RTOS), and finally processes this information to obtain several statistical outcomes. The results show that, in general, the presence of a significant amount of gain time reduces the performance benefit of the scheduling policies under study when compared to serving the soft tasks in background, which is considered the theoretical worst case. In some cases, this performance benefit is so small that the use of a specific scheduling policy for soft tasks is questionable.",1939-3520,,10.1109/TSE.2011.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6025357,Real-time systems;RT-Linux;scheduling policies,Real time systems;Servers;Time factors;Generators;Scheduling;Heuristic algorithms;Decision support systems,operating systems (computers);real-time systems;scheduling,gain time;soft-task scheduling policies;hard real-time systems;worst case execution time;WCET;processor consumption;representative scheduling algorithms;aperiodic tasks;fixed-priority preemptive systems;author testing framework;instrumented real-time operating system;RTOS;statistical outcomes,,3.0,,31.0,,23 Sep 2011,,,IEEE,IEEE Journals
710,711,Exploiting Model Morphology for Event-Based Testing,F. Belli; M. Beyazıt,"Department of Electrical Engineering and Information Technology, University of Paderborn, Paderborn, Germany; Department of Computer Engineering, Yaşar University, İzmir, Turkey",IEEE Transactions on Software Engineering,10 Feb 2015,2015,41,2,113,134,"Model-based testing employs models for testing. Model-based mutation testing (MBMT) additionally involves fault models, called mutants, by applying mutation operators to the original model. A problem encountered with MBMT is the elimination of equivalent mutants and multiple mutants modeling the same faults. Another problem is the need to compare a mutant to the original model for test generation. This paper proposes an event-based approach to MBMT that is not fixed on single events and a single model but rather operates on sequences of events of length k ≥ 1 and invokes a sequence of models that are derived from the original one by varying its morphology based on k. The approach employs formal grammars, related mutation operators, and algorithms to generate test cases, enabling the following: (1) the exclusion of equivalent mutants and multiple mutants; (2) the generation of a test case in linear time to kill a selected mutant without comparing it to the original model; (3) the analysis of morphologically different models enabling the systematic generation of mutants, thereby extending the set of fault models studied in related literature. Three case studies validate the approach and analyze its characteristics in comparison to random testing and another MBMT approach.",1939-3520,,10.1109/TSE.2014.2360690,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915728,Model-based mutation testing;grammar-based testing;mutant selection;Model-based mutation testing;grammar-based testing;(model) morphology;mutant selection;test generation,Grammar;Testing;Unified modeling language;Production;Context;Morphology;Analytical models,computational complexity;grammars;program testing,model morphology;event-based testing;model-based mutation testing;MBMT;fault models;mutants;mutation operators;test generation;event-based approach;formal grammars;equivalent mutant;multiple mutants;linear time;random testing,,5.0,,68.0,,2 Oct 2014,,,IEEE,IEEE Journals
711,712,An Experience in Testing the Security of Real-World Electronic Voting Systems,D. Balzarotti; G. Banks; M. Cova; V. Felmetsger; R. Kemmerer; W. Robertson; F. Valeur; G. Vigna,"Eurecom Institute, Sophia Antipolis, France; University of California, Santa Barbara, Santa Barbara; University of California, Santa Barbara, Santa Barbara; University of California, Santa Barbara, Santa Barbara; University of California, Santa Barbara, Santa Barbara; University of California, Santa Barbara, Santa Barbara; University of California, Santa Barbara, Santa Barbara; University of California, Santa Barbara, Santa Barbara",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,453,473,"Voting is the process through which a democratic society determines its government. Therefore, voting systems are as important as other well-known critical systems, such as air traffic control systems or nuclear plant monitors. Unfortunately, voting systems have a history of failures that seems to indicate that their quality is not up to the task. Because of the alarming frequency and impact of the malfunctions of voting systems, in recent years a number of vulnerability analysis exercises have been carried out against voting systems to determine if they can be compromised in order to control the results of an election. We have participated in two such large-scale projects, sponsored by the Secretaries of State of California and Ohio, whose goals were to perform the security testing of the electronic voting systems used in their respective states. As the result of the testing process, we identified major vulnerabilities in all of the systems analyzed. We then took advantage of a combination of these vulnerabilities to generate a series of attacks that would spread across the voting systems and would “steal” votes by combining voting record tampering with social engineering approaches. As a response to the two large-scale security evaluations, the Secretaries of State of California and Ohio recommended changes to improve the security of the voting process. In this paper, we describe the methodology that we used in testing the two real-world electronic voting systems we evaluated, the findings of our analysis, our attacks, and the lessons we learned.",1939-3520,,10.1109/TSE.2009.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5210119,Voting systems;security testing;vulnerability analysis.,Electronic equipment testing;System testing;Security;Electronic voting systems;Large-scale systems;Government;Air traffic control;History;Frequency;Control systems,data privacy;government data processing;security of data,security testing;electronic voting system;alarming frequency;vulnerability analysis exercise;California;Ohio;social engineering approache;large scale security evaluation,,26.0,,62.0,,21 Aug 2009,,,IEEE,IEEE Journals
712,713,Balancing Privacy and Utility in Cross-Company Defect Prediction,F. Peters; T. Menzies; L. Gong; H. Zhang,"West Virginia University, Morgantown; West Virginia University, Morgantown; Tsinghua University, Beijing; Tsinghua University, Beijing",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1054,1068,"Background: Cross-company defect prediction (CCDP) is a field of study where an organization lacking enough local data can use data from other organizations for building defect predictors. To support CCDP, data must be shared. Such shared data must be privatized, but that privatization could severely damage the utility of the data. Aim: To enable effective defect prediction from shared data while preserving privacy. Method: We explore privatization algorithms that maintain class boundaries in a dataset. CLIFF is an instance pruner that deletes irrelevant examples. MORPH is a data mutator that moves the data a random distance, taking care not to cross class boundaries. CLIFF+MORPH are tested in a CCDP study among 10 defect datasets from the PROMISE data repository. Results: We find: 1) The CLIFFed+MORPHed algorithms provide more privacy than the state-of-the-art privacy algorithms; 2) in terms of utility measured by defect prediction, we find that CLIFF+MORPH performs significantly better. Conclusions: For the OO defect data studied here, data can be privatized and shared without a significant degradation in utility. To the best of our knowledge, this is the first published result where privatization does not compromise defect prediction.",1939-3520,,10.1109/TSE.2013.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6419712,Privacy;classification;defect prediction,Testing;Software;Genetic algorithms;Sociology;Statistics;Search problems;Arrays,data privacy;program debugging,privacy balancing;utility balancing;cross-company defect prediction;CCDP;defect predictors;privacy preservation;privatization algorithms;class boundaries;pruner;data mutator;PROMISE data repository;CLIFFed-MORPHed algorithm;OO defect data,,70.0,,58.0,,24 Jan 2013,,,IEEE,IEEE Journals
713,714,Reducing Features to Improve Code Change-Based Bug Prediction,S. Shivaji; E. James Whitehead; R. Akella; S. Kim,"University of California, Santa Cruz, Santa Cruz; University of California, Santa Cruz, Santa Cruz; University of California, Santa Cruz, Santa Cruz; Hong Kong University of Science and, Hong Kong",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,552,569,"Machine learning classifiers have recently emerged as a way to predict the introduction of bugs in changes made to source code files. The classifier is first trained on software history, and then used to predict if an impending change causes a bug. Drawbacks of existing classifier-based bug prediction techniques are insufficient performance for practical use and slow prediction times due to a large number of machine learned features. This paper investigates multiple feature selection techniques that are generally applicable to classification-based bug prediction methods. The techniques discard less important features until optimal classification performance is reached. The total number of features used for training is substantially reduced, often to less than 10 percent of the original. The performance of Naive Bayes and Support Vector Machine (SVM) classifiers when using this technique is characterized on 11 software projects. Naive Bayes using feature selection provides significant improvement in buggy F-measure (21 percent improvement) over prior change classification bug prediction results (by the second and fourth authors [28]). The SVM's improvement in buggy F-measure is 9 percent. Interestingly, an analysis of performance for varying numbers of features shows that strong performance is achieved at even 1 percent of the original number of features.",1939-3520,,10.1109/TSE.2012.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226427,Reliability;bug prediction;machine learning;feature selection,Software;Support vector machines;History;Machine learning;Feature extraction;Measurement;Computer bugs,belief networks;learning (artificial intelligence);pattern classification;program debugging;support vector machines,code change-based bug prediction;machine learning classifier;source code file;software history;classifier-based bug prediction;machine learned feature reduction;feature selection technique;classification performance;naive Bayes classifier;support vector machine;SVM classifier;software project;buggy F-measure,,118.0,,53.0,,26 Jun 2012,,,IEEE,IEEE Journals
714,715,Linking Model-Driven Development and Software Architecture: A Case Study,A. Mattsson; B. Lundell; B. Lings; B. Fitzgerald,"Combitech AB, Jönköping; University of Skövde, Skövde; University of Skövde, Skövde; Univerity of Limerick, Limerick",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,83,93,"A basic premise of model driven development (MDD) is to capture all important design information in a set of formal or semi-formal models which are then automatically kept consistent by tools. The concept however is still relatively immature and there is little by way of empirically validated guidelines. In this paper we report on the use of MDD on a significant real-world project over several years. Our research found the MDD approach to be deficient in terms of modelling architectural design rules. Furthermore, the current body of literature does not offer a satisfactory solution as to how architectural design rules should be modelled. As a result developers have to rely on time-consuming and error-prone manual practices to keep a system consistent with its architecture. To realise the full benefits of MDD it is important to find ways of formalizing architectural design rules which then allow automatic enforcement of the architecture on the system model. Without this, architectural enforcement will remain a bottleneck in large MDD projects.",1939-3520,,10.1109/TSE.2008.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4657364,Software Architecture;Model-Driven Development;Case Study Research;Software Architecture;Model-Driven Development;Case Study Research,Joining processes;Software architecture;Computer architecture;Guidelines;Context modeling;Computer industry;Computer errors;Programming;Keyword search;Portals,formal verification;software architecture;systems analysis,model-driven development;software architecture;formal models;semi-formal models;architectural design rules,,25.0,2.0,55.0,,24 Oct 2008,,,IEEE,IEEE Journals
715,716,Toward a Tool-Based Development Methodology for Pervasive Computing Applications,D. Cassou; J. Bruneau; C. Consel; E. Balland,"University of Bordeaux and INRIA, Talence; University of Bordeaux and INRIA, Talence; University of Bordeaux and INRIA, Talence; University of Bordeaux and INRIA, Talence",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1445,1463,"Despite much progress, developing a pervasive computing application remains a challenge because of a lack of conceptual frameworks and supporting tools. This challenge involves coping with heterogeneous devices, overcoming the intricacies of distributed systems technologies, working out an architecture for the application, encoding it in a program, writing specific code to test the application, and finally deploying it. This paper presents a design language and a tool suite covering the development life-cycle of a pervasive computing application. The design language allows us to define a taxonomy of area-specific building-blocks, abstracting over their heterogeneity. This language also includes a layer to define the architecture of an application, following an architectural pattern commonly used in the pervasive computing domain. Our underlying methodology assigns roles to the stakeholders, providing separation of concerns. Our tool suite includes a compiler that takes design artifacts written in our language as input and generates a programming framework that supports the subsequent development stages, namely, implementation, testing, and deployment. Our methodology has been applied on a wide spectrum of areas. Based on these experiments, we assess our approach through three criteria: expressiveness, usability, and productivity.",1939-3520,,10.1109/TSE.2011.107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051438,Methodology;domain-specific language;generative programming;pervasive computing;toolkit;programming support;simulation,Pervasive computing;Taxonomy;Computer architecture;Programming;Domain specific languages;Computational modeling;Software architecture,program compilers;software architecture;ubiquitous computing,tool-based development methodology;pervasive computing applications;distributed systems technologies;development life-cycle;area-specific building-blocks;architectural pattern;compiler;design artifacts,,30.0,,53.0,,18 Oct 2011,,,IEEE,IEEE Journals
716,717,Compositional Verification for Hierarchical Scheduling of Real-Time Systems,L. Carnevali; A. Pinzuti; E. Vicario,Università di Firenze; Università di Firenze; Università di Firenze,IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,638,657,"Hierarchical Scheduling (HS) techniques achieve resource partitioning among a set of real-time applications, providing reduction of complexity, confinement of failure modes, and temporal isolation among system applications. This facilitates compositional analysis for architectural verification and plays a crucial role in all industrial areas where high-performance microprocessors allow growing integration of multiple applications on a single platform. We propose a compositional approach to formal specification and schedulability analysis of real-time applications running under a Time Division Multiplexing (TDM) global scheduler and preemptive Fixed Priority (FP) local schedulers, according to the ARINC-653 standard. As a characterizing trait, each application is made of periodic, sporadic, and jittering tasks with offsets, jitters, and nondeterministic execution times, encompassing intra-application synchronizations through semaphores and mailboxes and interapplication communications among periodic tasks through message passing. The approach leverages the assumption of a TDM partitioning to enable compositional design and analysis based on the model of preemptive Time Petri Nets (pTPNs), which is expressly extended with a concept of Required Interface (RI) that specifies the embedding environment of an application through sequencing and timing constraints. This enables exact verification of intra-application constraints and approximate but safe verification of interapplication constraints. Experimentation illustrates results and validates their applicability on two challenging workloads in the field of safety-critical avionic systems.",1939-3520,,10.1109/TSE.2012.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6264049,Real-time systems;hierarchical scheduling;ARINC-653;time division multiplexing;preemptive fixed priority;compositional verification;preemptive time Petri nets;symbolic state-space analysis,Real time systems;Complexity theory;Time division multiplexing;Job shop scheduling;Timing;Resource management;Petri nets,aerospace computing;formal verification;message passing;microprocessor chips;Petri nets;resource allocation;safety-critical software;scheduling,compositional verification;hierarchical scheduling;realtime system;HS technique;resource partitioning;compositional analysis;architectural verification;high-performance microprocessor;formal specification;schedulability analysis;time division multiplexing;TDM global scheduler;preemptive fixed priority local scheduler;FP local scheduler;ARINC-653 standard;periodic task;sporadic task;jittering task;nondeterministic execution time;intra-application synchronization;interapplication communication;message passing;semaphore;mailbox;compositional design;preemptive time Petri nets model;required interface concept;RI concept;sequencing constraint;timing constraint;safety-critical avionic system,,29.0,,41.0,,9 Aug 2012,,,IEEE,IEEE Journals
717,718,Learning a Metric for Code Readability,R. P. L. Buse; W. R. Weimer,"University of Virginia, Charlottesville; University of Virginia, Charlottesville",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,546,558,"In this paper, we explore the concept of code readability and investigate its relation to software quality. With data collected from 120 human annotators, we derive associations between a simple set of local code features and human notions of readability. Using those features, we construct an automated readability measure and show that it can be 80 percent effective and better than a human, on average, at predicting readability judgments. Furthermore, we show that this metric correlates strongly with three measures of software quality: code changes, automated defect reports, and defect log messages. We measure these correlations on over 2.2 million lines of code, as well as longitudinally, over many releases of selected projects. Finally, we discuss the implications of this study on programming language design and engineering practice. For example, our data suggest that comments, in and of themselves, are less important than simple blank lines to local judgments of readability.",1939-3520,,10.1109/TSE.2009.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5332232,Software readability;program understanding;machine learning;software maintenance;code metrics;FindBugs.,Software quality;Humans;Software maintenance;Readability metrics;Documentation;Software measurement;Computer languages;Design engineering;Machine learning;Costs,human factors;software quality,code readability;software quality;local code features;human notions;code changes;automated defect reports;defect log messages;programming language design,,115.0,,41.0,,13 Nov 2009,,,IEEE,IEEE Journals
718,719,SITAR: GUI Test Script Repair,Z. Gao; Z. Chen; Y. Zou; A. M. Memon,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science, University of Maryland, College Park, MD, USA",IEEE Transactions on Software Engineering,11 Feb 2016,2016,42,2,170,186,"System testing of a GUI-based application requires that test cases, consisting of sequences of user actions/events, be executed and the software's output be verified. To enable automated re-testing, such test cases are increasingly being coded as low-level test scripts, to be replayed automatically using test harnesses. Whenever the GUI changes-widgets get moved around, windows get merged-some scripts become unusable because they no longer encode valid input sequences. Moreover, because the software's output may have changed, their test oracles-assertions and checkpoints-encoded in the scripts may no longer correctly check the intended GUI objects. We present ScrIpT repAireR (SITAR), a technique to automatically repair unusable low-level test scripts. SITAR uses reverse engineering techniques to create an abstract test for each script, maps it to an annotated event-flow graph (EFG), uses repairing transformations and human input to repair the test, and synthesizes a new “repaired” test script. During this process, SITAR also repairs the reference to the GUI objects used in the checkpoints yielding a final test script that can be executed automatically to validate the revised software. SITAR amortizes the cost of human intervention across multiple scripts by accumulating the human knowledge as annotations on the EFG. An experiment using QTP test scripts suggests that SITAR is effective in that 41-89 percent unusable test scripts were repaired. Annotations significantly reduced human cost after 20 percent test scripts had been repaired.",1939-3520,,10.1109/TSE.2015.2454510,National Basic Research Program of China; NSFC; US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7214294,GUI testing;GUI test script;test script repair;human knowledge accumulation;GUI testing;GUI test script;test script repair;human knowledge accumulation,Maintenance engineering;Graphical user interfaces;Software;Testing;Automation;Computational modeling;Electronic mail,graph theory;graphical user interfaces;program testing;software maintenance,SITAR;test script repairer;graphical user interface;GUI-based application;system testing;automated retesting;event-flow graph;EFG;software validation,,18.0,,32.0,,20 Aug 2015,,,IEEE,IEEE Journals
719,720,Supporting Self-Adaptation via Quantitative Verification and Sensitivity Analysis at Run Time,A. Filieri; G. Tamburrelli; C. Ghezzi,"Reliable Software Systems Group, University of Stuttgart, Stuttgart, Germany; Vrije University of Amsterdam, Netherlands; Dipartimento di Elettronica, Informazione e Bioingegneria at Politecnico di Milano, Milan, Italy",IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,75,99,"Modern software-intensive systems often interact with an environment whose behavior changes over time, often unpredictably. The occurrence of changes may jeopardize their ability to meet the desired requirements. It is therefore desirable to design software in a way that it can self-adapt to the occurrence of changes with limited, or even without, human intervention. Self-adaptation can be achieved by bringing software models and model checking to run time, to support perpetual automatic reasoning about changes. Once a change is detected, the system itself can predict if requirements violations may occur and enable appropriate counter-actions. However, existing mainstream model checking techniques and tools were not conceived for run-time usage; hence they hardly meet the constraints imposed by on-the-fly analysis in terms of execution time and memory usage. This paper addresses this issue and focuses on perpetual satisfaction of non-functional requirements, such as reliability or energy consumption. Its main contribution is the description of a mathematical framework for run-time efficient probabilistic model checking. Our approach statically generates a set of verification conditions that can be efficiently evaluated at run time as soon as changes occur. The proposed approach also supports sensitivity analysis, which enables reasoning about the effects of changes and can drive effective adaptation strategies.",1939-3520,,10.1109/TSE.2015.2421318,European Commission; Programme IDEAS-ERC; Project 227977-SMScom; Programme FP7-PEOPLE-2011-IEF; Project 302648-RunMore; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7083754,Self-adaptive Systems;Software Evolution;Non-functional Requirements;Discrete-Time Markov models;Rewards;Software Reliability;Costs;Probabilistic Model Checking;Models at Runtime;Self-adaptive systems;software evolution;non-functional requirements;discrete-time Markov models;rewards;software reliability;costs;probabilistic model checking;models at runtime,Model checking;Adaptation models;Software;Markov processes;Probabilistic logic;Computational modeling;Reliability,probability;program verification;software reliability,self-adaptation;quantitative verification;run time analysis;software-intensive systems;software design;software models;perpetual automatic reasoning;requirements violation;on-the-fly analysis;execution time;memory usage;perpetual satisfaction;nonfunctional requirements;mathematical framework;probabilistic model checking;sensitivity analysis,,59.0,,91.0,,9 Apr 2015,,,IEEE,IEEE Journals
720,721,On the Distribution of Bugs in the Eclipse System,G. Concas; M. Marchesi; A. Murgia; R. Tonelli; I. Turnu,"University of Cagliari, Cagliari; University of Cagliari, Cagliari; University of Cagliari, Cagliari; University of Cagliari, Cagliari; University of Cagliari, Cagliari",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,872,877,"The distribution of bugs in software systems has been shown to satisfy the Pareto principle, and typically shows a power-law tail when analyzed as a rank-frequency plot. In a recent paper, Zhang showed that the Weibull cumulative distribution is a very good fit for the Alberg diagram of bugs built with experimental data. In this paper, we further discuss the subject from a statistical perspective, using as case studies five versions of Eclipse, to show how log-normal, Double-Pareto, and Yule-Simon distributions may fit the bug distribution at least as well as the Weibull distribution. In particular, we show how some of these alternative distributions provide both a superior fit to empirical data and a theoretical motivation to be used for modeling the bug generation process. While our results have been obtained on Eclipse, we believe that these models, in particular the Yule-Simon one, can generalize to other software systems.",1939-3520,,10.1109/TSE.2011.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928349,Software bug distribution;empirical research;object-oriented systems.,Computer bugs;Software systems;Data models;Computational modeling;Weibull distribution;Object oriented modeling,eclipses;Pareto analysis;Weibull distribution,software systems;Pareto principle;Weibull cumulative distribution;statistical perspective;eclipse system,,26.0,,22.0,,23 Jun 2011,,,IEEE,IEEE Journals
721,722,BURN: Enabling Workload Burstiness in Customized Service Benchmarks,G. Casale; A. Kalbasi; D. Krishnamurthy; J. Rolia,"Imperial College London, London; University of Calgary, Calgary; University of Calgary, Calgary; HP Labs, Palo Alto",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,778,793,"We introduce BURN, a methodology to create customized benchmarks for testing multitier applications under time-varying resource usage conditions. Starting from a set of preexisting test workloads, BURN finds a policy that interleaves their execution to stress the multitier application and generate controlled burstiness in resource consumption. This is useful to study, in a controlled way, the robustness of software services to sudden changes in the workload characteristics and in the usage levels of the resources. The problem is tackled by a model-based technique which first generates Markov models to describe resource consumption patterns of each test workload. Then, a policy is generated using an optimization program which sets as constraints a target request mix and user-specified levels of burstiness at the different resources in the system. Burstiness is quantified using a novel metric called overdemand, which describes in a natural way the tendency of a workload to keep a resource congested for long periods of time and across multiple requests. A case study based on a three-tier application testbed shows that our method is able to control and predict burstiness for session service demands at a fine-grained scale. Furthermore, experiments demonstrate that for any given request mix our approach can expose latency and throughput degradations not found with nonbursty workloads having the same request mix.",1939-3520,,10.1109/TSE.2011.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928353,Benchmarking;performance;burstiness;bottleneck migration;overdemand,Benchmark testing;Markov processes;Servers;Aggregates;Analytical models;Computational modeling;Linear regression,benchmark testing;Markov processes,BURN;workload burstiness;customized service benchmarks;customized benchmarks;multitier application;time-varying resource usage condition;controlled burstiness;software services;model-based technique;Markov models;resource consumption pattern;optimization program;target request mix;user-specified levels;three-tier application testbed;session service demands;fine-grained scale;latency;throughput degradation;nonbursty workloads,,9.0,,38.0,,23 Jun 2011,,,IEEE,IEEE Journals
722,723,The Oracle Problem in Software Testing: A Survey,E. T. Barr; M. Harman; P. McMinn; M. Shahbaz; S. Yoo,"Department of Computer Science, University College London, Gower Street, London WC2R 2LS, London, United Kingdom; Department of Computer Science, University College London, Gower Street, London WC2R 2LS, London, United Kingdom; Department of Computer Science, University of Sheffield, Sheffield S1 4DP, South Yorkshire, United Kingdom; Department of Computer Science, University of Sheffield, Sheffield S1 4DP, South Yorkshire, United Kingdom; Department of Computer Science, University College London, Gower Street, London WC2R 2LS, London, United Kingdom",IEEE Transactions on Software Engineering,12 May 2015,2015,41,5,507,525,"Testing involves examining the behaviour of a system in order to discover potential faults. Given an input for a system, the challenge of distinguishing the corresponding desired, correct behaviour from potentially incorrect behavior is called the “test oracle problem”. Test oracle automation is important to remove a current bottleneck that inhibits greater overall test automation. Without test oracle automation, the human has to determine whether observed behaviour is correct. The literature on test oracles has introduced techniques for oracle automation, including modelling, specifications, contract-driven development and metamorphic testing. When none of these is completely adequate, the final source of test oracle information remains the human, who may be aware of informal specifications, expectations, norms and domain specific information that provide informal oracle guidance. All forms of test oracles, even the humble human, involve challenges of reducing cost and increasing benefit. This paper provides a comprehensive survey of current approaches to the test oracle problem and an analysis of trends in this important area of software testing research and practice.",1939-3520,,10.1109/TSE.2014.2372785,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6963470,Test oracle;Automatic testing;Testing formalism;Test oracle;automatic testing;testing formalism,Probabilistic logic;Licenses;Automation;Software testing;Market research;Reliability,formal specification;program testing,test oracle problem;test oracle information;informal specifications;domain specific information;informal oracle guidance;software testing research;software testing practice;oracle automation;contract-driven development;metamorphic testing;oracle automation,,272.0,,211.0,,20 Nov 2014,,,IEEE,IEEE Journals
723,724,Enhanced Code Conversion Approach for the Integrated Cross-Platform Mobile Development (ICPMD),W. S. El-Kassas; B. A. Abdullah; A. H. Yousef; A. M. Wahba,"Department of Computer and Systems Engineering, Faculty of Engineering, Ain Shams University, Cairo, Egypt; Department of Computer and Systems Engineering, Faculty of Engineering, Ain Shams University, Cairo, Egypt; Department of Computer and Systems Engineering, Faculty of Engineering, Ain Shams University, Cairo, Egypt; Department of Computer and Systems Engineering, Faculty of Engineering, Ain Shams University, Cairo, Egypt",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,1036,1053,"Mobile development companies aim to maximize the return on investments by making their mobile applications (Apps) available on different mobile platforms. Consequently, the same App is developed several times; each time the developer uses the programming languages and development tools of a specific platform. Therefore, there is a need to have cross-platform mobile applications development solutions that enable the developers to develop the App once and run it everywhere. The Integrated Cross-Platform Mobile Applications Development (ICPMD) solution is one of the attempts that enables the developers to use the most popular programming languages like Java for Android and C# for Windows Phone 8 (WP8). ICPMD is used to transform both the source code and user interface to another language to generate full Apps on the target platform. This paper extends ICPMD by proposing a new code conversion approach based on XSLT and Regular Expressions to ease the conversion process. In addition, it provides the assessment method to compare the ICPMD efficiency with competing approaches. Several Apps are converted from WP8 to Android and vice versa. The ICPMD evaluation results show reasonable improvement over commercial cross-platform mobile development tools (Titanium and Xamarin).",1939-3520,,10.1109/TSE.2016.2543223,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442177,"Cross-platform mobile development;code conversion;code reuse;generated apps;ICPMD, source code patterns",Mobile communication;Java;Runtime;Titanium;Application programming interfaces;Smart phones,Android (operating system);mobile computing;programming languages;smart phones;software tools;source code (software);user interfaces,code conversion;integrated cross-platform mobile development;ICPMD;mobile application development;mobile platform;programming language;development tool;source code;user interface;smart phone,,10.0,,39.0,,25 Mar 2016,,,IEEE,IEEE Journals
724,725,Quality Requirements in Industrial Practice—An Extended Interview Study at Eleven Companies,R. Berntsson Svensson; T. Gorschek; B. Regnell; R. Torkar; A. Shahrokni; R. Feldt,"Lund University, Lund; Blekinge Institute of Technology, Karlskrona; Lund University, Lund; Blekinge Institute of Technology, Karlskrona; Chalmers University of Technology, Göteborg; Chalmers University of Technology, Göteborg",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,923,935,"In order to create a successful software product and assure its quality, it is not enough to fulfill the functional requirements, it is also crucial to find the right balance among competing quality requirements (QR). An extended, previously piloted, interview study was performed to identify specific challenges associated with the selection, tradeoff, and management of QR in industrial practice. Data were collected through semistructured interviews with 11 product managers and 11 project leaders from 11 software companies. The contribution of this study is fourfold: First, it compares how QR are handled in two cases, companies working in business-to-business markets and companies that are working in business-to-consumer markets. These two are also compared in terms of impact on the handling of QR. Second, it compares the perceptions and priorities of QR by product and project management, respectively. Third, it includes an examination of the interdependencies among quality requirements perceived as most important by the practitioners. Fourth, it characterizes the selection and management of QR in downstream development activities.",1939-3520,,10.1109/TSE.2011.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753901,Management;process;requirements/specifications,Companies;Interviews;Industries;Usability;Telecommunications;Reliability,DP industry;project management;software management;software quality,quality requirements;industrial practice;software product;software quality;QR selection;QR tradeoff;QR management;software company;business-to-business market;business-to-consumer market;project management;QR handling,,37.0,,40.0,,21 Apr 2011,,,IEEE,IEEE Journals
725,726,An Empirical Evaluation of Mutation Testing for Improving the Test Quality of Safety-Critical Software,R. Baker; I. Habli,"Aero Engine Controls, Birmingham; University of York, York",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,787,805,"Testing provides a primary means for assuring software in safety-critical systems. To demonstrate, particularly to a certification authority, that sufficient testing has been performed, it is necessary to achieve the test coverage levels recommended or mandated by safety standards and industry guidelines. Mutation testing provides an alternative or complementary method of measuring test sufficiency, but has not been widely adopted in the safety-critical industry. In this study, we provide an empirical evaluation of the application of mutation testing to airborne software systems which have already satisfied the coverage requirements for certification. Specifically, we apply mutation testing to safety-critical software developed using high-integrity subsets of C and Ada, identify the most effective mutant types, and analyze the root causes of failures in test cases. Our findings show how mutation testing could be effective where traditional structural coverage analysis and manual peer review have failed. They also show that several testing issues have origins beyond the test activity, and this suggests improvements to the requirements definition and coding process. Our study also examines the relationship between program characteristics and mutation survival and considers how program size can provide a means for targeting test areas most likely to have dormant faults. Industry feedback is also provided, particularly on how mutation testing can be integrated into a typical verification life cycle of airborne software.",1939-3520,,10.1109/TSE.2012.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6298894,Mutation;safety-critical software;verification;testing;certification,Testing;Certification;Software systems;Safety;Industries;Guidelines,Ada;aerospace computing;C language;certification;integrated software;program testing;program verification;safety-critical software;software quality,software test quality;safety-critical software;test coverage level;safety standard;industry guideline;test sufficiency measurement;empirical evaluation;mutation testing;airborne software system;certification;coverage requirement satisfaction;C;Ada;software integration;mutant type;software failure;structural coverage analysis;coding process;verification life cycle,,30.0,,41.0,,11 Sep 2012,,,IEEE,IEEE Journals
726,727,Composite Constant Propagation and its Application to Android Program Analysis,D. Octeau; D. Luchaup; S. Jha; P. McDaniel,"Department of Computer Sciences, University of Wisconsin, Madison, WI; CyLab, Carnegie Mellon University, Pittsburgh, PA; Department of Computer Sciences, University of Wisconsin, Madison, WI; Department of Computer Science and Engineering, Pennsylvania State University, University Park, PA",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,999,1014,"Many program analyses require statically inferring the possible values of composite types. However, current approaches either do not account for correlations between object fields or do so in an ad hoc manner. In this paper, we introduce the problem of composite constant propagation. We develop the first generic solver that infers all possible values of complex objects in an interprocedural, flow and context-sensitive manner, taking field correlations into account. Composite constant propagation problems are specified using COAL, a declarative language. We apply our COAL solver to the problem of inferring Android Inter-Component Communication (ICC) values, which is required to understand how the components of Android applications interact. Using COAL, we model ICC objects in Android more thoroughly than the state-of-the-art. We compute ICC values for 489 applications from the Google Play store. The ICC values we infer are substantially more precise than previous work. The analysis is efficient, taking two minutes per application on average. While this work can be used as the basis for many whole-program analyses of Android applications, the COAL solver can also be used to infer the values of composite objects in many other contexts.",1939-3520,,10.1109/TSE.2016.2550446,National Science Foundation; National Science Foundation; Google; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447806,Composite constant;constant propagation;inter-component communication;ICC;Android application analysis,Androids;Humanoid robots;Coal;Correlation;Context;Object oriented modeling;Receivers,Android (operating system);mobile computing;program diagnostics,composite constant propagation;Android program analysis;COAL declarative language;Android inter-component communication value;ICC values;Google Play Store;whole-program analysis;Android applications,,11.0,,44.0,,5 Apr 2016,,,IEEE,IEEE Journals
727,728,Who Will Stay in the FLOSS Community? Modeling Participant’s Initial Behavior,M. Zhou; A. Mockus,"School of Electronics Engineering and Computer Science, Peking University and Key Laboratory of High Confidence Software Technologies, Ministry of Education, Beijing, China; Department of Electrical Engineering and Computer Science, University of Tennessee, Min H. Kao Building, Room 613, 1520 Middle Drive, Knoxville, TN",IEEE Transactions on Software Engineering,7 Jan 2015,2015,41,1,82,99,"Motivation: To survive and succeed, FLOSS projects need contributors able to accomplish critical project tasks. However, such tasks require extensive project experience of long term contributors (LTCs). Aim: We measure, understand, and predict how the newcomers' involvement and environment in the issue tracking system (ITS) affect their odds of becoming an LTC. Method: ITS data of Mozilla and Gnome, literature, interviews, and online documents were used to design measures of involvement and environment. A logistic regression model was used to explain and predict contributor's odds of becoming an LTC. We also reproduced the results on new data provided by Mozilla. Results: We constructed nine measures of involvement and environment based on events recorded in an ITS. Macro-climate is the overall project environment while micro-climate is person-specific and varies among the participants. Newcomers who are able to get at least one issue reported in the first month to be fixed, doubled their odds of becoming an LTC. The macro-climate with high project popularity and the micro-climate with low attention from peers reduced the odds. The precision of LTC prediction was 38 times higher than for a random predictor. We were able to reproduce the results with new Mozilla data without losing the significance or predictive power of the previously published model. We encountered unexpected changes in some attributes and suggest ways to make analysis of ITS data more reproducible. Conclusions: The findings suggest the importance of initial behaviors and experiences of new participants and outline empirically-based approaches to help the communities with the recruitment of contributors for long-term participation and to help the participants contribute more effectively. To facilitate the reproduction of the study and of the proposed measures in other contexts, we provide the data we retrieved and the scripts we wrote at https://www.passion-lab.org/projects/developerfluency.html.",1939-3520,,10.1109/TSE.2014.2349496,National Basic Research Program of China; National Natural Science Foundation of China; National Hi-Tech Research and Development Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6880395,Long term contributor;open source software;issue tracking system;mining software repository;extent of involvement;interaction with environment;initial behavior,Communities;Atmospheric measurements;Particle measurements;Predictive models;Data models;Data mining;Electronic mail,behavioural sciences;project management;public domain software,Free-Libre and/or open source software projects;open source software;Mozilla data;microclimate;macroclimate;logistic regression model;Gnome;ITS data;issue tracking system;LTC;long term contributors;critical project;FLOSS community,,36.0,,47.0,,19 Aug 2014,,,IEEE,IEEE Journals
728,729,A Data Mining Approach for Detecting Higher-Level Clones in Software,H. A. Basit; S. Jarzabek,"Lahore University of Management Sciences, Lahore; National University of Singapore, Singapore",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,497,514,"Code clones are similar program structures recurring in variant forms in software system(s). Several techniques have been proposed to detect similar code fragments in software, so-called simple clones. Identification and subsequent unification of simple clones is beneficial in software maintenance. Even further gains can be obtained by elevating the level of code clone analysis. We observed that recurring patterns of simple clones often indicate the presence of interesting higher-level similarities that we call structural clones. Structural clones show a bigger picture of similarity situation than simple clones alone. Being logical groups of simple clones, structural clones alleviate the problem of huge number of clones typically reported by simple clone detection tools, a problem that is often dealt with postdetection visualization techniques. Detection of structural clones can help in understanding the design of the system for better maintenance and in reengineering for reuse, among other uses. In this paper, we propose a technique to detect some useful types of structural clones. The novelty of our approach includes the formulation of the structural clone concept and the application of data mining techniques to detect these higher-level similarities. We describe a tool called clone miner that implements our proposed technique. We assess the usefulness and scalability of the proposed techniques via several case studies. We discuss various usage scenarios to demonstrate in what ways the knowledge of structural clones adds value to the analysis based on simple clones alone.",1939-3520,,10.1109/TSE.2009.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4796208,Design concepts;maintainability;restructuring;reverse engineering;reengineering;reusable software.,Data mining;Cloning;Software systems;Software maintenance;Collaboration;Portals;Computer Society;Visualization;Scalability;Reverse engineering,data mining;software maintenance;software reusability,data mining approach;higher-level clone detection;program structures;software system;software maintenance;code clone analysis;postdetection visualization techniques;software reusability,,64.0,1.0,53.0,,27 Feb 2009,,,IEEE,IEEE Journals
729,730,A Comprehensive Approach to Naming and Accessibility in Refactoring Java Programs,M. Schäfer; A. Thies; F. Steimann; F. Tip,"IBM T.J. Watson Research Center, Hawthorne; Fernuniversität in Hagen, Hagen; Fernuniversität in Hagen, Hagen; IBM, Hawthorne",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1233,1257,"Automated tool support for refactoring is now widely available for mainstream programming languages such as Java. However, current refactoring tools are still quite fragile in practice and often fail to preserve program behavior or compilability. This is mainly because analyzing and transforming source code requires consideration of many language features that complicate program analysis, in particular intricate name lookup and access control rules. This paper introduces JL, a lookup-free, access control-free representation of Java programs. We present algorithms for translating Java programs into JL and vice versa, thereby making it possible to formulate refactorings entirely at the level of JL and to rely on the translations to take care of naming and accessibility issues. We demonstrate how complex refactorings become more robust and powerful when lifted to JL. Our approach has been implemented using the JastAddJ compiler framework, and evaluated by systematically performing two commonly used refactorings on an extensive suite of real-world Java applications. The evaluation shows that our tool correctly handles many cases where current refactoring tools fail to handle the complex rules for name binding and accessibility in Java.",1939-3520,,10.1109/TSE.2012.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152131,Restructuring;reverse engineering;and reengineering;object-oriented languages;Java,Java;Access control;Feature extraction;Reverse engineering;Object oriented programming;Shadow mapping;Program processors,authorisation;Java;naming services;program compilers;program diagnostics;software maintenance,comprehensive approach;naming issues;accessibility issues;Java program refactoring;mainstream programming languages;source code analysis;source code transformation;language features;program analysis;name lookup;access control rules;JL;lookup-free access control-free representation;JastAddJ compiler framework,,14.0,,43.0,,14 Feb 2012,,,IEEE,IEEE Journals
730,731,Verifying the Evolution of Probability Distributions Governed by a DTMC,Y. Kwon; G. Agha,"Microsoft Corporation, Redmond; University of Illinois at Urbana-Champaign, Urbana",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,126,141,"We propose a new probabilistic temporal logic, iLTL, which captures properties of systems whose state can be represented by probability mass functions (pmfs). Using iLTL, we can specify reachability to a state (i.e., a pmf), as well as properties representing the aggregate (expected) behavior of a system. We then consider a class of systems whose transitions are governed by a Markov Chain-in this case, the set of states a system may be in is specified by the transitions of pmfs from all potential initial states to the final state. We then provide a model checking algorithm to check iLTL properties of such systems. Unlike existing model checking techniques, which either compute the portions of the computational paths that satisfy a specification or evaluate properties along a single path of pmf transitions, our model checking technique enables us to do a complete analysis on the expected behaviors of large-scale systems. Desirable system parameters may also be found as a counterexample of a negated goal. Finally, we illustrate the usefulness of iLTL model checking by means of two examples: assessing software reliability and ensuring the results of administering a drug.",1939-3520,,10.1109/TSE.2010.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5557891,Probabilistic model checking;linear temporal logic;Discrete Time Markov Chain;pharmacokinetics.,Markov processes;Limiting;Eigenvalues and eigenfunctions;Computational modeling;Transient analysis;Probability distribution;Steady-state,formal verification;Markov processes;statistical distributions;temporal logic,probability distribution;DTMC;temporal logic;iLTL;probability mass function;model checking;large scale system;discrete time Markov chain,,10.0,,39.0,,26 Aug 2010,,,IEEE,IEEE Journals
731,732,Static Analysis of Model Transformations,J. S. Cuadrado; E. Guerra; J. de Lara,"Department of Languages and Systems, Universidad de Murcia, Murcia, Spain; Department of Computer Science, Universidad Autónoma de Madrid, Madrid, Spain; Department of Computer Science, Universidad Autónoma de Madrid, Madrid, Spain",IEEE Transactions on Software Engineering,15 Sep 2017,2017,43,9,868,897,"Model transformations are central to Model-Driven Engineering (MDE), where they are used to transform models between different languages; to refactor and simulate models; or to generate code from models. Thus, given their prominent role in MDE, practical methods helping in detecting errors in transformations and automate their verification are needed. In this paper, we present a method for the static analysis of ATL model transformations. The method aims at discovering typing and rule errors, like unresolved bindings, uninitialized features or rule conflicts. It relies on static analysis and type inference, and uses constraint solving to assert whether a source model triggering the execution of a given problematic statement can possibly exist. Our method is supported by a tool that integrates seamlessly with the ATL development environment. To evaluate the usefulness of our method, we have used it to analyse a public repository of ATL transformations. The high number of errors discovered shows that static analysis of ATL transformations is needed in practice. Moreover, we have measured the precision and recall of the method by considering a synthetic set of transformations obtained by mutation techniques, and comparing with random testing. The experiment shows good overall results in terms of false positives and negatives.",1939-3520,,10.1109/TSE.2016.2635137,Spanish MINECO; R&D programme of the Madrid Region; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7765073,Model-driven engineering;model transformation;ATL;static analysis;model finders;verification and testing,Unified modeling language;Analytical models;Testing;Model driven engineering;Transforms;Manuals;Computational modeling,constraint handling;error detection;formal verification;inference mechanisms;program diagnostics;random functions,static analysis;model-driven engineering;MDE;error detection;verification automation;ATL model transformations;typing errors;rule errors;unresolved bindings;uninitialized features;rule conflicts;type inference;constraint solving;public repository analysis;mutation techniques;random testing,,7.0,,70.0,Traditional,2 Dec 2016,,,IEEE,IEEE Journals
732,733,What Industry Needs from Architectural Languages: A Survey,I. Malavolta; P. Lago; H. Muccini; P. Pelliccione; A. Tang,"Università dell'Aquila, Italy; VU University Amsterdam, Amsterdam; Università dell'Aquila, Italy; Università dell'Aquila, Italy; Swinburne University of Technology, Melbourne",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,869,891,"Many times we are faced with the proliferation of definitions, concepts, languages, and tools in certain (research) topics. But often there is a gap between what is provided by existing technologies and what is needed by their users. The strengths, limitations, and needs of the available technologies can be dubious. The same applies to software architectures, and specifically to languages designed to represent architectural models. Tens of different architectural languages have been introduced by the research and industrial communities in the last two decades. However, it is unclear if they fulfill the user's perceived needs in architectural description. As a way to plan for next generation languages for architectural description, this study analyzes practitioners' perceived strengths, limitations, and needs associated with existing languages for software architecture modeling in industry. We run a survey by interviewing 48 practitioners from 40 different IT companies in 15 countries. Each participant is asked to fill in a questionnaire of 51 questions. By analyzing the data collected through this study, we have concluded that 1) while practitioners are generally satisfied with the design capabilities provided by the languages they use, they are dissatisfied with the architectural language analysis features and their abilities to define extra-functional properties; 2) architectural languages used in practice mostly originate from industrial development instead of from academic research; 3) more formality and better usability are required of an architectural language.",1939-3520,,10.1109/TSE.2012.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374194,Software architecture;architecture description languages;ADL;survey;empirical study,Unified modeling language;Software architecture;Computer architecture;Industries;Communities;Software;Google,data analysis;software architecture;specification languages,architectural languages;software architectures;architectural models;next generation languages;architectural description;data collection analysis;industrial development,,136.0,1.0,64.0,,4 Dec 2012,,,IEEE,IEEE Journals
733,734,Context-Aware Adaptive Applications: Fault Patterns and Their Automated Identification,M. Sama; S. Elbaum; F. Raimondi; D. S. Rosenblum; Z. Wang,"University College London, UK; University of Nebraska, Lincoln, NE; University College London, UK; University College, London, UK; University of Nebraska, Lincoln, NE",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,644,661,"Applications running on mobile devices are intensely context-aware and adaptive. Streams of context values continuously drive these applications, making them very powerful but, at the same time, susceptible to undesired configurations. Such configurations are not easily exposed by existing validation techniques, thereby leading to new analysis and testing challenges. In this paper, we address some of these challenges by defining and applying a new model of adaptive behavior called an Adaptation Finite-State Machine (A-FSM) to enable the detection of faults caused by both erroneous adaptation logic and asynchronous updating of context information, with the latter leading to inconsistencies between the external physical context and its internal representation within an application. We identify a number of adaptation fault patterns, each describing a class of faulty behaviors. Finally, we describe three classes of algorithms to detect such faults automatically via analysis of the A-FSM. We evaluate our approach and the trade-offs between the classes of algorithms on a set of synthetically generated Context-Aware Adaptive Applications (CAAAs) and on a simple but realistic application in which a cell phone's configuration profile changes automatically as a result of changes to the user's location, speed, and surrounding environment. Our evaluation describes the faults our algorithms are able to detect and compares the algorithms in terms of their performance and storage requirements.",1939-3520,,10.1109/TSE.2010.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432224,Adaptation;context-awareness;fault detection;mobile computing;model-based analysis;model checking;ordered binary decision diagrams;symbolic verification;ubiquitous computing.,Fault diagnosis;Fault detection;Context modeling;Algorithm design and analysis;Handheld computers;Personal digital assistants;Data structures;Global Positioning System;Computer science;Lead,finite state machines;formal logic;mobile computing;program verification;software fault tolerance,context-aware adaptive applications;mobile devices;validation techniques;adaptation finite-state machine;A-FSM analysis;asynchronous information updating;fault pattern adaptation;cell phone;fault detection,,65.0,1.0,33.0,,18 Mar 2010,,,IEEE,IEEE Journals
734,735,Toward Comprehensible Software Fault Prediction Models Using Bayesian Network Classifiers,K. Dejaeger; T. Verbraken; B. Baesens,"Katholieke Universiteit Leuven, Leuven; Katholieke Universiteit Leuven, Leuven; Katholieke Universiteit Leuven, Leuven",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,237,257,"Software testing is a crucial activity during software development and fault prediction models assist practitioners herein by providing an upfront identification of faulty software code by drawing upon the machine learning literature. While especially the Naive Bayes classifier is often applied in this regard, citing predictive performance and comprehensibility as its major strengths, a number of alternative Bayesian algorithms that boost the possibility of constructing simpler networks with fewer nodes and arcs remain unexplored. This study contributes to the literature by considering 15 different Bayesian Network (BN) classifiers and comparing them to other popular machine learning techniques. Furthermore, the applicability of the Markov blanket principle for feature selection, which is a natural extension to BN theory, is investigated. The results, both in terms of the AUC and the recently introduced H-measure, are rigorously tested using the statistical framework of Demšar. It is concluded that simple and comprehensible networks with less nodes can be constructed using BN classifiers other than the Naive Bayes classifier. Furthermore, it is found that the aspects of comprehensibility and predictive performance need to be balanced out, and also the development context is an item which should be taken into account during model selection.",1939-3520,,10.1109/TSE.2012.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175912,Software fault prediction;Bayesian networks;classification;comprehensibility,Software;Predictive models;Bayesian methods;Measurement;Capability maturity model;Probability distribution;Machine learning,belief networks;feature extraction;learning (artificial intelligence);Markov processes;pattern classification;prediction theory;program testing;software fault tolerance;statistical analysis,software fault prediction models;Bayesian network classifiers;software testing;software development;faulty software code;machine learning literature;Naive Bayes classifier;citing predictive performance;BN classifiers;Markov blanket principle;feature selection;BN theory;AUC;introduced H-measure;statistical framework;Demsar;predictive performance;model selection,,103.0,1.0,109.0,,3 Apr 2012,,,IEEE,IEEE Journals
735,736,A Comparative Study of Software Model Checkers as Unit Testing Tools: An Industrial Case Study,M. Kim; Y. Kim; H. Kim,"KAIST, Daejon; KAIST, Daejon; Samsung Electronics, Suwon",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,146,160,"Conventional testing methods often fail to detect hidden flaws in complex embedded software such as device drivers or file systems. This deficiency incurs significant development and support/maintenance cost for the manufacturers. Model checking techniques have been proposed to compensate for the weaknesses of conventional testing methods through exhaustive analyses. Whereas conventional model checkers require manual effort to create an abstract target model, modern software model checkers remove this overhead by directly analyzing a target C program, and can be utilized as unit testing tools. However, since software model checkers are not fully mature yet, they have limitations according to the underlying technologies and tool implementations, potentially critical issues when applied in industrial projects. This paper reports our experience in applying Blast and CBMC to testing the components of a storage platform software for flash memory. Through this project, we analyzed the strong and weak points of two different software model checking technologies in the viewpoint of real-world industrial application-counterexample-guided abstraction refinement with predicate abstraction and SAT-based bounded analysis.",1939-3520,,10.1109/TSE.2010.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5510242,Embedded software verification;software model checking;bounded model checking;CEGAR-based model checking;flash file systems.,Software tools;Software testing;Computer industry;Manufacturing industries;System testing;Embedded software;File systems;Costs;Flash memory;Refining,C language;program testing;program verification;storage management,software model checkers;unit testing tools;complex embedded software;model checking techniques;abstract target model;C program;Blast;CBMC;storage platform software;flash memory,,21.0,,54.0,,15 Jul 2010,,,IEEE,IEEE Journals
736,737,An Observe-Model-Exercise* Paradigm to Test Event-Driven Systems with Undetermined Input Spaces,B. N. Nguyen; A. M. Memon,"Department of Computer Science, University of Maryland, College Park; Department of Computer Science, University of Maryland, College Park",IEEE Transactions on Software Engineering,31 Mar 2014,2014,40,3,216,234,"System testing of software applications with a graphical-user interface (GUI) front-end requires that sequences of GUI events, that sample the application's input space, be generated and executed as test cases on the GUI. However, the context-sensitive behavior of the GUI of most of today's non-trivial software applications makes it practically impossible to fully determine the software's input space. Consequently, GUI testers-both automated and manual-working with undetermined input spaces are, in some sense, blindly navigating the GUI, unknowingly missing allowable event sequences, and failing to realize that the GUI implementation may allow the execution of some disallowed sequences. In this paper, we develop a new paradigm for GUI testing, one that we call Observe-Model-Exercise* (OME*) to tackle the challenges of testing context-sensitive GUIs with undetermined input spaces. Starting with an incomplete model of the GUI's input space, a set of coverage elements to test, and test cases, OME* iteratively observes the existence of new events during execution of the test cases, expands the model of the GUI's input space, computes new coverage elements, and obtains new test cases to exercise the new elements. Our experiment with 8 open-source software subjects, more than 500,000 test cases running for almost 1,100 machine-days, shows that OME* is able to expand the test space on average by 464.11 percent; it detected 34 faults that had never been detected before.",1939-3520,,10.1109/TSE.2014.2300857,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6714448,Test generation;user interfaces;quality concepts,Graphical user interfaces;Computational modeling;Blogs;Testing;Software;Context;Layout,graphical user interfaces;program testing;public domain software,observe-model-exercise paradigm;test event-driven system;undetermined input spaces;software system testing;graphical-user interface front-end;GUI context-sensitive behavior;open-source software subjects;test generation,,19.0,,44.0,,16 Jan 2014,,,IEEE,IEEE Journals
737,738,Comparing Semi-Automated Clustering Methods for Persona Development,J. Brickey; S. Walczak; T. Burgess,"US Army, Combating Terrorism Center, West Point; University of Colorado Denver, Denver; United States Military Academy, West Point",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,537,546,"Current and future information systems require a better understanding of the interactions between users and systems in order to improve system use and, ultimately, success. The use of personas as design tools is becoming more widespread as researchers and practitioners discover its benefits. This paper presents an empirical study comparing the performance of existing qualitative and quantitative clustering techniques for the task of identifying personas and grouping system users into those personas. A method based on Factor (Principal Components) Analysis performs better than two other methods which use Latent Semantic Analysis and Cluster Analysis as measured by similarity to expert manually defined clusters.",1939-3520,,10.1109/TSE.2011.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928355,Clustering;interaction styles;personas;user-centered design;user interfaces.,Manuals;Clustering methods;Principal component analysis;Software;Interviews;Humans;Organizations,information systems;pattern clustering;principal component analysis,semi-automated clustering methods;persona development;information systems;design tools;quantitative clustering techniques;qualitative clustering techniques;principal components analysis;latent semantic analysis,,13.0,,47.0,,23 Jun 2011,,,IEEE,IEEE Journals
738,739,DECOR: A Method for the Specification and Detection of Code and Design Smells,N. Moha; Y. Gueheneuc; L. Duchien; A. Le Meur,"INRIA, IRISA, Université de Rennes 1, France; École Polytechnique de Montréal, Québec; LIFL, INRIA Lille-Nord Europe, Université de Lille, France; LIFL, INRIA Lille-Nord Europe, Université de Lille, France",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,20,36,"Code and design smells are poor solutions to recurring implementation and design problems. They may hinder the evolution of a system by making it hard for software engineers to carry out changes. We propose three contributions to the research field related to code and design smells: (1) DECOR, a method that embodies and defines all the steps necessary for the specification and detection of code and design smells, (2) DETEX, a detection technique that instantiates this method, and (3) an empirical validation in terms of precision and recall of DETEX. The originality of DETEX stems from the ability for software engineers to specify smells at a high level of abstraction using a consistent vocabulary and domain-specific language for automatically generating detection algorithms. Using DETEX, we specify four well-known design smells: the antipatterns Blob, Functional Decomposition, Spaghetti Code, and Swiss Army Knife, and their 15 underlying code smells, and we automatically generate their detection algorithms. We apply and validate the detection algorithms in terms of precision and recall on XERCES v2.7.0, and discuss the precision of these algorithms on 11 open-source systems.",1939-3520,,10.1109/TSE.2009.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5196681,Antipatterns;design smells;code smells;specification;metamodeling;detection;Java.,Detection algorithms;Vocabulary;Domain specific languages;Algorithm design and analysis;Metamodeling;Java;Design engineering;Object oriented programming;Phase detection;Costs,formal specification;program verification;software quality,code specification;code detection;design smells;DECOR;DETEX;antipatterns Blob;functional decomposition;Spaghetti code;Swiss army knife;empirical validation;domain-specific language;open-source systems,,364.0,,66.0,,7 Aug 2009,,,IEEE,IEEE Journals
739,740,"Comments on ScottKnottESD in response to ""An empirical comparison of model validation techniques for defect prediction models""",S. Herbold,"Institute of Computer Science, University of Goettingen, Goettingen, Germany",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1091,1094,"In this article, we discuss the ScottKnottESD test, which was proposed in a recent paper “An Empirical Comparison of Model Validation Techniques for Defect Prediction Models” that was published in this journal. We discuss the implications and the empirical impact of the proposed normality correction of ScottKnottESD and come to the conclusion that this correction does not necessarily lead to the fulfillment of the assumptions of the original Scott-Knott test and may cause problems with the statistical analysis.",1939-3520,,10.1109/TSE.2017.2748129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024011,"Scott-knott test, log transformation, statistics",Analysis of variance;Measurement;Distributed databases;Predictive models;Sociology,program testing;software metrics;statistical analysis,model validation techniques;defect prediction models;ScottKnottESD test;empirical impact;statistical analysis,,,,23.0,Traditional,1 Sep 2017,,,IEEE,IEEE Journals
740,741,A Game-Theoretic Foundation for the Maximum Software Resilience against Dense Errors,C. Huang; D. A. Peled; S. Schewe; F. Wang,"Graduate Institute of Electronic Engineering, National Taiwan University, Taiwan, ROC; Department of Computer Science, Bar Ilan University, Ramat Gan, Israel; Department of Computer Science, University of Liverpool, Liverpool, United Kingdom; Department of Electrical Engineering, National Taiwan University, Taiwan, ROC",IEEE Transactions on Software Engineering,14 Jul 2016,2016,42,7,605,622,"Safety-critical systems need to maintain their functionality in the presence of multiple errors caused by component failures or disastrous environment events. We propose a game-theoretic foundation for synthesizing control strategies that maximize the resilience of a software system in defense against a realistic error model. The new control objective of such a game is called $k$ -resilience. In order to be $k$ -resilient, a system needs to rapidly recover from infinitely many waves of a small number of up to $k$  close errors provided that the blocks of up to $k$  errors are separated by short time intervals, which can be used by the system to recover. We first argue why we believe this to be the right level of abstraction for safety critical systems when local faults are few and far between. We then show how the analysis of $k$ -resilience problems can be formulated as a model-checking problem of a mild extension to the alternating-time  $\mu$ -calculus (AMC). The witness for $k$  resilience, which can be provided by the model checker, can be used for providing control strategies that are optimal with respect to resilience. We show that the computational complexity of constructing such optimal control strategies is low and demonstrate the feasibility of our approach through an implementation and experimental results.",1939-3520,,10.1109/TSE.2015.2510001,ISF; Efficient Synthesis Method of Control for Concurrent Systems; Engineering and Physical Science Research Council (EPSRC); MOST; Research Center for Information Technology Innovation (CITI); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360234,Fault tolerance;resilience;formal verification;model-checking;game;strategy;complexity,Resilience;Games;Software systems;Safety;Game theory;Computer science,,,,7.0,,44.0,,17 Dec 2015,,,IEEE,IEEE Journals
741,742,Evaluating Dynamic Software Update Safety Using Systematic Testing,C. M. Hayden; E. K. Smith; E. A. Hardisty; M. Hicks; J. S. Foster,"University of Maryland, College Park, College Park; University of Maryland, College Park, College Park; University of Maryland, College Park, College Park; University of Maryland, College Park, College Park; University of Maryland, College Park, College Park",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1340,1354,"Dynamic software updating (DSU) systems patch programs on the fly without incurring downtime. To avoid failures due to the updating process itself, many DSU systems employ timing restrictions. However, timing restrictions are theoretically imperfect, and their practical effectiveness is an open question. This paper presents the first significant empirical evaluation of three popular timing restrictions: activeness safety (AS), which prevents updates to active functions, con-freeness safety (CFS), which only allows modifications to active functions when doing so is provably type-safe, and manual identification of the event-handling loops during which an update may occur. We evaluated these timing restrictions using a series of DSU patches to three programs: OpenSSH, vsftpd, and ngIRCd. We systematically applied updates at each distinct update point reached during execution of a suite of system tests for these programs to determine which updates pass and which fail. We found that all three timing restrictions prevented most failures, but only manual identification allowed none. Further, although CFS and AS allowed many more update points, manual identification still supported updates with minimal delay. Finally, we found that manual identification required the least developer effort. Overall, we conclude that manual identification is most effective.",1939-3520,,10.1109/TSE.2011.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035725,Dynamic software updating (DSU);hot-swapping;software reliability;testing;program tracing,Software reliability;Software testing;Servers,program testing;safety-critical software;software fault tolerance;software maintenance,dynamic software updating safety evaluation;systematic testing;DSU systems;timing restrictions;activeness safety;AS;active functions;con-freeness safety;CFS;event-handling loop identification;OpenSSH;vsftpd;ngIRCd;manual identification;failure prevention,,18.0,2.0,35.0,,6 Oct 2011,,,IEEE,IEEE Journals
742,743,Guided Mutation Testing for JavaScript Web Applications,S. Mirshokraie; A. Mesbah; K. Pattabiraman,"Department of Electrical and Computer Engineering, University of British Columbia, 2332 Main Mall, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, 2332 Main Mall, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, 2332 Main Mall, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,12 May 2015,2015,41,5,429,444,"Mutation testing is an effective test adequacy assessment technique. However, there is a high computational cost in executing the test suite against a potentially large pool of generated mutants. Moreover, there is much effort involved in filtering out equivalent mutants. Prior work has mainly focused on detecting equivalent mutants after the mutation generation phase, which is computationally expensive and has limited efficiency. We propose an algorithm to select variables and branches for mutation as well as a metric, called FunctionRank, to rank functions according to their relative importance from the application's behaviour point of view. We present a technique that leverages static and dynamic analysis to guide the mutation generation process towards parts of the code that are more likely to influence the program's output. Further, we focus on the JavaScript language, and propose a set of mutation operators that are specific to Web applications. We implement our approach in a tool called MUTANDIS. The results of our empirical evaluation show that (1) more than 93 percent of generated mutants are non-equivalent, and (2) more than 75 percent of the surviving non-equivalent mutants are in the top 30 percent of the ranked functions.",1939-3520,,10.1109/TSE.2014.2371458,NSERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6960094,mutation testing;JavaScript;equivalent mutants;guided mutation generation;web applications;Mutation testing;JavaScript;equivalent mutants;guided mutation generation;web applications,Testing;Measurement;Heuristic algorithms;Complexity theory;Performance analysis;Instruments;IEEE Computer Society,Java;program diagnostics;program testing,guided mutation testing;JavaScript Web applications;test adequacy assessment technique;computational cost;test suite execution;equivalent mutants;mutation generation phase;variable selection;FunctionRank;function ranking;relative function importance;application behaviour;static analysis;dynamic analysis;program output;mutation operators;nonequivalent mutants;empirical evaluation;MUTANDIS tool;Web applications,,25.0,,50.0,,20 Nov 2014,,,IEEE,IEEE Journals
743,744,Black-Box String Test Case Generation through a Multi-Objective Optimization,A. Shahbazi; J. Miller,"Department of Electrical and Computer Engineering, Edmonton, AB, Canada; Department of Electrical and Computer Engineering, Edmonton, AB, Canada",IEEE Transactions on Software Engineering,14 Apr 2016,2016,42,4,361,378,"String test cases are required by many real-world applications to identify defects and security risks. Random Testing (RT) is a low cost and easy to implement testing approach to generate strings. However, its effectiveness is not satisfactory. In this research, black-box string test case generation methods are investigated. Two objective functions are introduced to produce effective test cases. The diversity of the test cases is the first objective, where it can be measured through string distance functions. The second objective is guiding the string length distribution into a Benford distribution based on the hypothesis that the population of strings is right-skewed within its range. When both objectives are applied via a multi-objective optimization algorithm, superior string test sets are produced. An empirical study is performed with several real-world programs indicating that the generated string test cases outperform test cases generated by other methods.",1939-3520,,10.1109/TSE.2015.2487958,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7293669,Adaptive random testing;automated test case generation;black-box testing;mutation;random testing;software testing;string distance;string test cases;Adaptive random testing;automated test case generation;black-box testing;mutation;random testing;software testing;string distance;string test cases,Sociology;Statistics;Biological cells;Subspace constraints;Testing;Power capacitors;Genetic algorithms,optimisation;program testing;security of data,black-box string test case generation;security risks;random testing;RT;objective functions;string distance functions;Benford distribution;multiobjective optimization algorithm,,19.0,,76.0,,7 Oct 2015,,,IEEE,IEEE Journals
744,745,Fluid Rewards for a Stochastic Process Algebra,M. Tribastone; J. Ding; S. Gilmore; J. Hillston,"Ludwig-Maximilians-Universität, München; Yangzhou University, Yangzhou; Edinburgh University, Edinburgh; Edinburgh University, Edinburgh",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,861,874,"Reasoning about the performance of models of software systems typically entails the derivation of metrics such as throughput, utilization, and response time. If the model is a Markov chain, these are expressed as real functions of the chain, called reward models. The computational complexity of reward-based metrics is of the same order as the solution of the Markov chain, making the analysis infeasible when evaluating large-scale systems. In the context of the stochastic process algebra PEPA, the underlying continuous-time Markov chain has been shown to admit a deterministic (fluid) approximation as a solution of an ordinary differential equation, which effectively circumvents state-space explosion. This paper is concerned with approximating Markovian reward models for PEPA with fluid rewards, i.e., functions of the solution of the differential equation problem. It shows that (1) the Markovian reward models for typical metrics of performance enjoy asymptotic convergence to their fluid analogues, and that (2) via numerical tests, the approximation yields satisfactory accuracy in practice.",1939-3520,,10.1109/TSE.2011.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975178,Modeling and prediction;ordinary differential equations;Markov processes,Convergence;Markov processes;Approximation methods;Computational modeling;Mathematical model;Servers,computational complexity;Markov processes;mathematics computing;process algebra;stochastic processes,fluid rewards;stochastic process algebra;software systems;metric derivation;Markov chain;computational complexity;ordinary differential equation;state-space explosion,,19.0,,33.0,,4 Aug 2011,,,IEEE,IEEE Journals
745,746,Using Traceability Links to Recommend Adaptive Changes for Documentation Evolution,B. Dagenais; M. P. Robillard,"Resulto Inc., Montreal, QC, Canada; School of Computer Science, McGill University, 3480 University Street, McConnell Engineering Building, Office 114N, Montreal, QC, Canada",IEEE Transactions on Software Engineering,10 Nov 2014,2014,40,11,1126,1146,"Developer documentation helps developers learn frameworks and libraries, yet developing and maintaining accurate documentation requires considerable effort and resources. Contributors who work on developer documentation often need to manually track all changes in the code, determine which changes are significant enough to document, and then, adapt the documentation. We propose AdDoc, a technique that automatically discovers documentation patterns, i.e., coherent sets of code elements that are documented together, and that reports violations of these patterns as the code and the documentation evolves. We evaluated our approach in a retrospective analysis of four Java open source projects and found that at least 50 percent of all the changes in the documentation were related to existing documentation patterns. Our technique allows contributors to quickly adapt existing documentation, so that they can focus their documentation effort on the new features.",1939-3520,,10.1109/TSE.2014.2347969,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6878435,Documentation;maintainability;frameworks,Documentation;Java;Manuals;Libraries;Sections;Joining processes;Concrete,data mining;Java;program diagnostics;public domain software;system documentation,traceability links;adaptive changes;documentation evolution;developer documentation;AdDoc;automatic documentation pattern discovery;code elements;Java open source projects,,11.0,,24.0,,14 Aug 2014,,,IEEE,IEEE Journals
746,747,Managing Technical Debt in Enterprise Software Packages,N. Ramasubbu; C. F. Kemerer,"Joseph M. Katz Graduate School of Business, University of Pittsburgh, Pittsburgh, PA; Joseph M. Katz Graduate School of Business, University of Pittsburgh, Pittsburgh, PA",IEEE Transactions on Software Engineering,8 Aug 2014,2014,40,8,758,772,"We develop an evolutionary model and theory of software technical debt accumulation to facilitate a rigorous and balanced analysis of its benefits and costs in the context of a large commercial enterprise software package. Our theory focuses on the optimization problem involved in managing technical debt, and illustrates the different tradeoff patterns between software quality and customer satisfaction under early and late adopter scenarios at different lifecycle stages of the software package. We empirically verify our theory utilizing a ten year longitudinal data set drawn from 69 customer installations of the software package. We then utilize the empirical results to develop actionable policies for managing technical debt in enterprise software product adoption.",1939-3520,,10.1109/TSE.2014.2327027,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6824267,Technical debt;enterprise software;software platforms;customer satisfaction;software quality;technology adoption;COTS;software evolution;software maintenance;software management;longitudinal data,Software packages;Business;Software quality;Measurement;Maintenance engineering;Context,cost-benefit analysis;evolutionary computation;software development management;software maintenance;software packages;software quality,technical debt management;evolutionary model;software technical debt theory;commercial enterprise software package;optimization problem;software quality;customer satisfaction;early adopter scenario;late adopter scenario;software package lifecycle stage;enterprise software product adoption,,18.0,,57.0,,2 Jun 2014,,,IEEE,IEEE Journals
747,748,Test Oracle Strategies for Model-Based Testing,N. Li; J. Offutt,"Research and Development Division, Medidata Solutions, New York, NY; George Mason University, Fairfax, VA",IEEE Transactions on Software Engineering,14 Apr 2017,2017,43,4,372,395,"Testers use model-based testing to design abstract tests from models of the system's behavior. Testers instantiate the abstract tests into concrete tests with test input values and test oracles that check the results. Given the same test inputs, more elaborate test oracles have the potential to reveal more failures, but may also be more costly. This research investigates the ability for test oracles to reveal failures. We define ten new test oracle strategies that vary in amount and frequency of program state checked. We empirically compared them with two baseline test oracle strategies. The paper presents several main findings. (1) Test oracles must check more than runtime exceptions because checking exceptions alone is not effective at revealing failures. (2) Test oracles do not need to check the entire output state because checking partial states reveals nearly as many failures as checking entire states. (3) Test oracles do not need to check program states multiple times because checking states less frequently is as effective as checking states more frequently. In general, when state machine diagrams are used to generate tests, checking state invariants is a reasonably effective low cost approach to creating test oracles.",1939-3520,,10.1109/TSE.2016.2597136,George Mason University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7529115,Test oracle;RIPR model;test oracle strategy;test automation;subsumption;model-based testing,Unified modeling language;Software;Context;Concrete;System testing;Observability,data flow analysis;diagrams;finite state machines;program testing;software fault tolerance,test oracle strategy;model-based testing;abstract test design;failure revelation;runtime exception;partial state checking;state machine diagram,,21.0,,46.0,,2 Aug 2016,,,IEEE,IEEE Journals
748,749,Are Slice-Based Cohesion Metrics Actually Useful in Effort-Aware Post-Release Fault-Proneness Prediction? An Empirical Study,Y. Yang; Y. Zhou; H. Lu; L. Chen; Z. Chen; B. Xu; H. Leung; Z. Zhang,"State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing, China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing, China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing, China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing, China; State Key Laboratory for Novel Software Technology, School of Software, Nanjing, China; State Key Laboratory for Novel Software Technology, Department of Computer Science and Technology, Nanjing, China; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong, China; State Key Laboratory of Computer Science, Institute of Software, Beijing, China",IEEE Transactions on Software Engineering,14 Apr 2015,2015,41,4,331,357,"Background. Slice-based cohesion metrics leverage program slices with respect to the output variables of a module to quantify the strength of functional relatedness of the elements within the module. Although slice-based cohesion metrics have been proposed for many years, few empirical studies have been conducted to examine their actual usefulness in predicting fault-proneness. Objective. We aim to provide an in-depth understanding of the ability of slice-based cohesion metrics in effort-aware post-release fault-proneness prediction, i.e. their effectiveness in helping practitioners find post-release faults when taking into account the effort needed to test or inspect the code. Method. We use the most commonly used code and process metrics, including size, structural complexity, Halstead's software science, and code churn metrics, as the baseline metrics. First, we employ principal component analysis to analyze the relationships between slice-based cohesion metrics and the baseline metrics. Then, we use univariate prediction models to investigate the correlations between slice-based cohesion metrics and post-release fault-proneness. Finally, we build multivariate prediction models to examine the effectiveness of slice-based cohesion metrics in effort-aware post-release fault-proneness prediction when used alone or used together with the baseline code and process metrics. Results. Based on open-source software systems, our results show that: 1) slice-based cohesion metrics are not redundant with respect to the baseline code and process metrics; 2) most slice-based cohesion metrics are significantly negatively related to post-release fault-proneness; 3) slice-based cohesion metrics in general do not outperform the baseline metrics when predicting post-release fault-proneness; and 4) when used with the baseline metrics together, however, slice-based cohesion metrics can produce a statistically significant and practically important improvement of the effectiveness in effort-aware post-release fault-proneness prediction. Conclusion. Slice-based cohesion metrics are complementary to the most commonly used code and process metrics and are of practical value in the context of effort-aware post-release fault-proneness prediction.",1939-3520,,10.1109/TSE.2014.2370048,National Key Basic Research and Development Program of China; National Natural Science Foundation of China; National Natural Science Foundation of Jiangsu Province; National Science and Technology Major Project of China; Hong Kong Competitive Earmarked Research; PolyU; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6954519,Cohesion;metrics;slice-based;fault-proneness;prediction;effort-aware,Measurement;Software;Predictive models;Context;Complexity theory;Correlation;Laboratories,principal component analysis;public domain software;software metrics,effort aware post-release fault proneness prediction;slice-based cohesion metrics leverage program slices;structural complexity;Halstead's software science;code churn metrics;baseline metrics;principal component analysis;univariate prediction models;multivariate prediction models;baseline code;process metrics;open source software systems,,27.0,,66.0,,12 Nov 2014,,,IEEE,IEEE Journals
749,750,Monitor-Based Instant Software Refactoring,H. Liu; X. Guo; W. Shao,"Beijing Institute of Technology, Beijing; Beijing Institute of Technology, Beijing; Peking University, Beijing",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1112,1126,"Software refactoring is an effective method for improvement of software quality while software external behavior remains unchanged. To facilitate software refactoring, a number of tools have been proposed for code smell detection and/or for automatic or semi-automatic refactoring. However, these tools are passive and human driven, thus making software refactoring dependent on developers' spontaneity. As a result, software engineers with little experience in software refactoring might miss a number of potential refactorings or may conduct refactorings later than expected. Few refactorings might result in poor software quality, and delayed refactorings may incur higher refactoring cost. To this end, we propose a monitor-based instant refactoring framework to drive inexperienced software engineers to conduct more refactorings promptly. Changes in the source code are instantly analyzed by a monitor running in the background. If these changes have the potential to introduce code smells, i.e., signs of potential problems in the code that might require refactorings, the monitor invokes corresponding smell detection tools and warns developers to resolve detected smells promptly. Feedback from developers, i.e., whether detected smells have been acknowledged and resolved, is consequently used to optimize smell detection algorithms. The proposed framework has been implemented, evaluated, and compared with the traditional human-driven refactoring tools. Evaluation results suggest that the proposed framework could drive inexperienced engineers to resolve more code smells (by an increase of 140 percent) promptly. The average lifespan of resolved smells was reduced by 92 percent. Results also suggest that the proposed framework could help developers to avoid similar code smells through timely warnings at the early stages of software development, thus reducing the total number of code smells by 51 percent.",1939-3520,,10.1109/TSE.2013.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6409360,Software refactoring;code smell detection;monitor;instant refactoring,Software;Monitoring;Detection algorithms;Cloning;Detectors;Algorithm design and analysis;Inspection,software maintenance;software quality,monitor-based instant software refactoring;software quality;software external behavior;code smell detection;smell detection algorithm,,28.0,,50.0,,10 Jan 2013,,,IEEE,IEEE Journals
750,751,The Link between Dependency and Cochange: Empirical Evidence,M. M. Geipel; F. Schweitzer,"ETH Zurich, Zurich; ETH Zurich, Zurich",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1432,1444,"We investigate the relationship between class dependency and change propagation (cochange) in software written in Java. On the one hand, we find a strong correlation between dependency and cochange. Furthermore, we provide empirical evidence for the propagation of change along paths of dependency. These findings support the often alleged role of dependencies as propagators of change. On the other hand, we find that approximately half of all dependencies are never involved in cochanges and that the vast majority of cochanges pertain to only a small percentage of dependencies. This means that inferring the cochange characteristics of a software architecture solely from its dependency structure results in a severely distorted approximation of cochange characteristics. Any metric which uses dependencies alone to pass judgment on the evolvability of a piece of Java software is thus unreliable. As a consequence, we suggest to always take both the change characteristics and the dependency structure into account when evaluating software architecture.",1939-3520,,10.1109/TSE.2011.91,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363462,Modularity;class dependency;open source,Software development;Java;Open source software,Java;software architecture,class dependency;change propagation;Java software;cochange characteristic;software architecture,,13.0,,48.0,,29 Nov 2012,,,IEEE,IEEE Journals
751,752,An I/O Efficient Approach for Detecting All Accepting Cycles,L. Wu; K. Su; S. Cai; X. Zhang; C. Zhang; S. Wang,"School of Computer Science and Engineering, University of Electronic Science and Technology, Chengdu, China; Institute for Integrated and Intelligent Systems, Griffith University, Brisbane, Australia; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China; School of Computer Science and Engineering, University of Electronic Science and Technology, Chengdu, China; School of Information Technology and Electrical Engineering, University of Queensland, Brisbane, Australia; School of Computer Science and Engineering, University of Electronic Science and Technology, Chengdu, China",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,730,744,"Existing algorithms for I/O Linear Temporal Logic (LTL) model checking usually output a single counterexample for a system which violates the property. However, in real-world applications, such as diagnosis and debugging in software and hardware system designs, people often need to have a set of counterexamples or even all counterexamples. For this purpose, we propose an I/O efficient approach for detecting all accepting cycles, called Detecting All Accepting Cycles (DAAC), where the properties to be verified are in LTL. Different from other algorithms for finding all cycles, DAAC first searches for the accepting strongly connected components (ASCCs), and then finds all accepting cycles of every ASCC, which can avoid searching for a great many paths that are impossible to be extended to accepting cycles. In order to further lower DAAC's I/O complexity and improve its performance, we propose an intersection computation technique and a dynamic path management technique, and exploit a minimal perfect hash function (MPHF). We carry out both complexity and experimental comparisons with the state-of-the-art algorithms including Detect Accepting Cycle (DAC), Maximal Accepting Predecessors (MAP) and Iterative-Deepening Depth-First Search (IDDFS). The comparative results show that our approach is better on the whole in terms of I/O complexity and practical performance, despite the fact that it finds all counterexamples.",1939-3520,,10.1109/TSE.2015.2411284,National Natural Science Foundation of China; China National; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7056483,Model Checking;Detection of All Accepting Cycles;Breath-First Search;Model checking;detection of all accepting cycles;state space explosion;accepting strongly connected component;breath-first search,Complexity theory;Model checking;Algorithm design and analysis;Educational institutions;Heuristic algorithms;Software algorithms;Software,formal verification;temporal logic,input-output efficient approach;I/O linear temporal logic;LTL model checking;DAAC approach;detecting all accepting cycles approach;accepting strongly connected components;ASCC;I/O complexity;intersection computation technique;dynamic path management technique;minimal perfect hash function;MPHF;detect accepting cycle algorithm;DAC algorithm;maximal accepting predecessors algorithm;iterative-deepening depth-first search algorithm;IDDFS algorithm,,2.0,,36.0,,9 Mar 2015,,,IEEE,IEEE Journals
752,753,Compositional Control of IP Media,P. Zave; E. Cheung,"AT&T Laboratories-Research, Florham Park; AT&T Laboratories-Research, Florham Park",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,46,66,"In many IP media services, the media channels are point-to-point, dynamic, and set up with the participation of one or more application servers, even thou the media packets themselves travel directly between media endpoints. The application servers must be programmed so that media behavior is globally correct, even though the servers may attempt to manipulate the same media channels concurrently and without knowledge of each other. Our proposed solution to this problem of compositional media control includes an architecture-independent descriptive model, a set of high-level programming primitives, a formal specification of their compositional semantics, a signaling protocol, an implementation, and partial verification of correctness. The paper includes performance analysis, comparison to related work, and principles for making other networked applications more compositional.",1939-3520,,10.1109/TSE.2008.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4569853,distributed applications;domain-specific architectures;protocol verification;protocol design;software/program verification;networks;streaming media;multimedia services;telecommunications;feature interaction;distributed applications;domain-specific architectures;protocol verification;protocol design;software/program verification;networks;streaming media;multimedia services;telecommunications;feature interaction,Application software;Network servers;Streaming media;Protocols;Internet telephony;Web server;Performance analysis;Computer architecture;Computer networks;Home computing,formal specification;IP networks;multimedia communication;signalling protocols,compositional control;IP media services;media channels;media packets;media endpoints;architecture-independent descriptive model;high-level programming primitives;formal specification;signaling protocol,,8.0,1.0,16.0,,18 Jul 2008,,,IEEE,IEEE Journals
753,754,Identification of Move Method Refactoring Opportunities,N. Tsantalis; A. Chatzigeorgiou,"University of Macedonia, Thessaloniki; University of Macedonia, Thessaloniki",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,347,367,"Placement of attributes/methods within classes in an object-oriented system is usually guided by conceptual criteria and aided by appropriate metrics. Moving state and behavior between classes can help reduce coupling and increase cohesion, but it is nontrivial to identify where such refactorings should be applied. In this paper, we propose a methodology for the identification of Move Method refactoring opportunities that constitute a way for solving many common feature envy bad smells. An algorithm that employs the notion of distance between system entities (attributes/methods) and classes extracts a list of behavior-preserving refactorings based on the examination of a set of preconditions. In practice, a software system may exhibit such problems in many different places. Therefore, our approach measures the effect of all refactoring suggestions based on a novel entity placement metric that quantifies how well entities have been placed in system classes. The proposed methodology can be regarded as a semi-automatic approach since the designer will eventually decide whether a suggested refactoring should be applied or not based on conceptual or other design quality criteria. The evaluation of the proposed approach has been performed considering qualitative, metric, conceptual, and efficiency aspects of the suggested refactorings in a number of open-source projects.",1939-3520,,10.1109/TSE.2009.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4752842,Move Method refactoring;Feature Envy;object-oriented design;Jaccard distance;design quality.,Software systems;Performance evaluation;Open source software;Runtime;Productivity;Data mining,object-oriented programming;software maintenance;software metrics,Move Method refactoring opportunity identification;object-oriented system;conceptual criteria;software metrics;feature envy,,188.0,,33.0,,19 Jan 2009,,,IEEE,IEEE Journals
754,755,Modeling Product Line Software Assets Using Domain-Specific Kits,N. I. Altintas; S. Cetin; A. H. Dogru; H. Oguztuzun,"Cybersoft Information Technologies, Istanbul; Cybersoft Information Technologies, Istanbul; Middle East Technical University, Ankara; Middle East Technical University, Ankara",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1376,1402,"Software Product Line Engineering (SPLE) is a prominent paradigm for the assembly of a family of products using product line core assets. The modeling of software assets that together form the actual products is critical for achieving the strategic benefits of Software Product Lines (SPLs). We propose a feature-based approach to software asset modeling based on abstractions provided by Domain-Specific Kits (DSKs). This approach involves a software Asset Metamodel (AMM) used to derive Asset Modeling Languages (AMLs) that define reusable software assets in domain-specific terms. The approach also prescribes a roadmap for modeling these software assets in conjunction with the product line reference architecture. Asset capabilities can be modeled using feature diagrams as the external views of the software assets. Internal views can be expressed in terms of Domain-Specific Artifacts (DSAs) with Variability Points (VPs), where the domain-specific artifacts are created using Domain-Specific Kits. This approach produces loosely coupled and highly cohesive software assets that are reusable for multiple product lines. The approach is validated by assessing software asset reuse in two different product lines in the finance domain. We also evaluated the productivity gains in large-scale complex projects, and found that the approach yielded a significant reduction in the total project effort.",1939-3520,,10.1109/TSE.2011.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065739,Asset modeling;domain-specific kits;feature models;reuse;software asset;software product lines,Software reliability;Computer architecture;Productivity;Programming;Complexity theory;Systematics,financial data processing;product development;project management;simulation languages;software reusability,product line software asset modelling;domain-specific kits;software product line engineering;SPLE;product line core assets;feature-based approach;DSK;software asset metamodel;AMM;asset modeling languages;AML;software asset reusability;domain-specific terms;product line reference architecture;feature diagrams;internal views;domain-specific artifacts;DSA;variability points;VP;finance domain;productivity gains;large-scale complex projects,,5.0,,86.0,,1 Nov 2011,,,IEEE,IEEE Journals
755,756,Identifying Code of Individual Features in Client-Side Web Applications,J. Maras; M. Stula; J. Carlson; I. Crnkovic,"University of Split, Split; University of Split, Split; Mälardalen University, Västerås; Mälardalen University, Västerås",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1680,1697,"Web applications are one of today's fastest growing software systems. Structurally, they are composed of two parts: the server side, used for data access and business logic, and the client side, used as a user interface. In recent years, with developers building complex interfaces, the client side is playing an increasingly important role. Unfortunately, the techniques and tools used to support development are not as advanced as in other disciplines. From the user's perspective, the client side offers a number of features that are relatively easy to distinguish. However, the same cannot be said for their implementation details. This makes the understanding, maintenance, and reuse of code difficult. The goal of the work presented in this paper is to improve reusability, maintainability, and performance of client-side web applications by identifying the code that implements a particular feature. We have evaluated the approach based on three different experiments: extracting features, extracting library functionalities, and page optimization. The evaluation shows that the method is able to identify the implementation details of individual features, and that by extracting the identified code, a considerable reduction in code size and increase in performance can be achieved.",1939-3520,,10.1109/TSE.2013.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6576749,Web applications;feature location;program slicing;code extraction,Feature extraction;HTML;Cascading style sheets;Browsers;Web and internet services;Optimization;Codes,feature extraction;Internet;user interfaces,individual features code identification;client-side Web application reusability;software systems;server side;data access;business logic;user interface;client-side Web application maintainability;client-side Web application performance;feature extraction;library functionality extraction;page optimization,,9.0,,35.0,,8 Aug 2013,,,IEEE,IEEE Journals
756,757,Measuring the Discriminative Power of Object-Oriented Class Cohesion Metrics,J. Al Dallal,"Kuwait University, Kuwait",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,788,804,"Several object-oriented cohesion metrics have been proposed in the literature. These metrics aim to measure the relationship between class members, namely, methods and attributes. Different metrics use different models to represent the connectivity pattern of cohesive interactions (CPCI) between class members. Most of these metrics are normalized to allow for easy comparison of the cohesion of different classes. However, in some cases, these metrics obtain the same cohesion values for different classes that have the same number of methods and attributes but different CPCIs. This leads to incorrectly considering the classes to be the same in terms of cohesion, even though their CPCIs clearly indicate that the degrees of cohesion are different. We refer to this as a lack of discrimination anomaly (LDA) problem. In this paper, we list and discuss cases in which the LDA problem exists, as expressed through the use of 16 cohesion metrics. In addition, we empirically study the frequent occurrence of the LDA problem when the considered metrics are applied to classes in five open source Java systems. Finally, we propose a metric and a simulation-based methodology to measure the discriminative power of cohesion metrics. The discrimination metric measures the probability that a cohesion metric will produce distinct cohesion values for classes with the same number of attributes and methods but different CPCIs. A highly discriminating cohesion metric is more desirable because it exhibits a lower chance of incorrectly considering classes to be cohesively equal when they have different CPCIs.",1939-3520,,10.1109/TSE.2010.97,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5639020,Cohesive interactions;connectivity pattern;discrimination metric;discriminative power;lack of discrimination anomaly;object-oriented class cohesion.,Power measurement;Object oriented modeling;Software measurement;Phase measurement,Java;laser Doppler anemometry;object-oriented methods;public domain software,discriminative power measurement;object oriented class cohesion metrics;cohesive interactions;discrimination anomaly;open source Java systems;simulation based methodology,,33.0,,41.0,,18 Nov 2010,,,IEEE,IEEE Journals
757,758,A Model of Data Warehousing Process Maturity,A. Sen; K. Ramamurthy; A. P. Sinha,"Texas A&M University, College Station; University of Wisconsin-Milwaukee, Milwaukee; University of Wisconsin-Milwaukee, Milwaukee",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,336,353,"Even though data warehousing (DW) requires huge investments, the data warehouse market is experiencing incredible growth. However, a large number of DW initiatives end up as failures. In this paper, we argue that the maturity of a data warehousing process (DWP) could significantly mitigate such large-scale failures and ensure the delivery of consistent, high quality, “single-version of truth” data in a timely manner. However, unlike software development, the assessment of DWP maturity has not yet been tackled in a systematic way. In light of the critical importance of data as a corporate resource, we believe that the need for a maturity model for DWP could not be greater. In this paper, we describe the design and development of a five-level DWP maturity model (DWP-M) over a period of three years. A unique aspect of this model is that it covers processes in both data warehouse development and operations. Over 20 key DW executives from 13 different corporations were involved in the model development process. The final model was evaluated by a panel of experts; the results strongly validate the functionality, productivity, and usability of the model. We present the initial and final DWP-M model versions, along with illustrations of several key process areas at different levels of maturity.",1939-3520,,10.1109/TSE.2011.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680911,Data warehousing process;design-science research;model validation;software maturity models.,Data warehouses;Business;Warehousing;Software;Programming;Data mining;Standards organizations,data warehouses,data warehousing process maturity;data warehouse market;large-scale failures;DWP-M model,,28.0,,75.0,,6 Jan 2011,,,IEEE,IEEE Journals
758,759,Using Stochastic State Classes in Quantitative Evaluation of Dense-Time Reactive Systems,E. Vicario; L. Sassoli; L. Carnevali,"Università di Firenze, Firenze; Università di Firenze, Firenze; Università di Firenze, Firenze",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,703,719,"In the verification of reactive systems with nondeterministic densely valued temporal parameters, the state-space can be covered through equivalence classes, each composed of a discrete logical location and a dense variety of clock valuations encoded as a difference bounds matrix (DBM). The reachability relation among such classes enables qualitative verification of properties pertaining events ordering and stimulus/response deadlines, but it does not provide any measure of probability for feasible behaviors. We extend DBM equivalence classes with a density-function which provides a measure for the probability of individual states. To this end, we extend time Petri nets by associating a probability density-function to the static firing interval of each nondeterministic transition. We then explain how this stochastic information induces a probability distribution for the states contained within a DBM class and how this probability evolves in the enumeration of the reachability relation among classes. This enables the construction of a stochastic transition system which supports correctness verification based on the theory of TPNs, provides a measure of probability for each feasible run, enables steady-state analysis based on Markov renewal theory. In so doing, we provide a means to identify feasible behaviors and to associate them with a measure of probability in models with multiple concurrent generally distributed nondeterministic timers.",1939-3520,,10.1109/TSE.2009.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5010440,Correctness verification;performance and dependability evaluation;stochastic Time Petri nets;non-Markovian Stochastic Petri Nets;dense-time state-space analysis;Difference Bounds Matrix;Markov Renewal Theory.,Stochastic systems;Stochastic processes;Petri nets;Delay;Clocks;Timing;Density functional theory;Concurrent computing;Computer Society;Cost accounting,equivalence classes;Markov processes;matrix algebra;Petri nets;program verification;reachability analysis;statistical distributions,stochastic state-space class analysis;dense-time reactive system verification;quantitative evaluation;nondeterministic densely-valued temporal parameter;equivalence class;discrete logical location;difference bound matrix;DBM;reachability relation;qualitative correctness verification;event ordering;stimulus/response deadline;stochastic timed Petri net;probability density distribution function measure;static firing interval;nondeterministic transition;stochastic transition system;STPN theory;Markov renewal theory;nondeterministic timer,,44.0,,43.0,,29 May 2009,,,IEEE,IEEE Journals
759,760,Automated Trace Analysis of Discrete-Event System Models,P. Kemper; C. Tepper,"College of William and Mary, Williamsburg; ITGAIN Consulting, Hanover",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,195,208,"In this paper, we describe a novel technique that helps a modeler gain insight into the dynamic behavior of a complex stochastic discrete event simulation model based on trace analysis. We propose algorithms to distinguish progressive from repetitive behavior in a trace and to extract a minimal progressive fragment of a trace. The implied combinatorial optimization problem for trace reduction is solved in linear time with dynamic programming. We present and compare several approximate and one exact solution method. Information on the reduction operation as well as the reduced trace itself helps a modeler to recognize the presence of certain errors and to identify their cause. We track down a subtle modeling error in a dependability model of a multi-class server system to illustrate the effectiveness of our approach in revealing the cause of an observed effect. The proposed technique has been implemented and integrated in Traviando, a trace analyzer to debug stochastic simulation models.",1939-3520,,10.1109/TSE.2008.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4620122,Testing and Debugging;Simulation;Trace analysis;Cycle reduction;Testing and Debugging;Simulation;Trace analysis;Cycle reduction,Discrete event systems;Discrete event simulation;Context modeling;Communication system software;Software performance;Automatic control;Control systems;Stochastic systems;Debugging;Data mining,combinatorial mathematics;discrete event simulation;dynamic programming;program diagnostics,automated trace analysis;discrete event system models;dynamic behavior;complex stochastic discrete event simulation model;minimal progressive fragment;combinatorial optimization problem;trace reduction;linear time;dynamic programming;reduction operation;modeling error;dependability model;multiclass server system;Traviando;trace analyzer;stochastic simulation model,,20.0,,22.0,,5 Sep 2008,,,IEEE,IEEE Journals
760,761,Estimating Computational Requirements in Multi-Threaded Applications,J. F. Pérez; G. Casale; S. Pacheco-Sanchez,"Department of Computing, Imperial College London, United Kingdom; Department of Computing, Imperial College London, United Kingdom; SAP HANA Cloud Computing, Systems Engineering, Belfast, United Kingdom",IEEE Transactions on Software Engineering,11 Mar 2015,2015,41,3,264,278,"Performance models provide effective support for managing quality-of-service (QoS) and costs of enterprise applications. However, expensive high-resolution monitoring would be needed to obtain key model parameters, such as the CPU consumption of individual requests, which are thus more commonly estimated from other measures. However, current estimators are often inaccurate in accounting for scheduling in multi-threaded application servers. To cope with this problem, we propose novel linear regression and maximum likelihood estimators. Our algorithms take as inputs response time and resource queue measurements and return estimates of CPU consumption for individual request types. Results on simulated and real application datasets indicate that our algorithms provide accurate estimates and can scale effectively with the threading levels.",1939-3520,,10.1109/TSE.2014.2363472,Seventh Framework Programme; InvestNI/SAP VIRTEX; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926798,Demand estimation;Multi-threaded application servers;Application performance management;Demand estimation;multi-threaded application servers;application performance management,Time factors;Servers;Instruction sets;Maximum likelihood estimation;Computational modeling;Time measurement,maximum likelihood estimation;multi-threading;quality of service;queueing theory;regression analysis;software performance evaluation;systems analysis,computational requirement estimation;expensive high-resolution monitoring;quality-of-service;QoS management;cost management;performance models;CPU consumption;multithreaded application server scheduling;linear regression;maximum likelihood estimators;input response time;resource queue measurements;enterprise applications,,21.0,,41.0,,16 Oct 2014,,,IEEE,IEEE Journals
761,762,Software Reliability Modeling with Software Metrics Data via Gaussian Processes,N. Torrado; M. P. Wiper; R. E. Lillo,"Universidad Carlos III de Madrid, Madrid; Universidad Carlos III de Madrid, Madrid; Universidad Carlos III de Madrid, Madrid",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1179,1186,"In this paper, we describe statistical inference and prediction for software reliability models in the presence of covariate information. Specifically, we develop a semiparametric, Bayesian model using Gaussian processes to estimate the numbers of software failures over various time periods when it is assumed that the software is changed after each time period and that software metrics information is available after each update. Model comparison is also carried out using the deviance information criterion, and predictive inferences on future failures are shown. Real-life examples are presented to illustrate the approach.",1939-3520,,10.1109/TSE.2012.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392172,Software metrics;software failures;reliability;statistical methods;Markov chain Monte Carlo method,Software;Gaussian processes;Software reliability;Software metrics;Predictive models;Bayesian methods,Bayes methods;Gaussian processes;inference mechanisms;software metrics;software reliability;statistical analysis;system recovery,software reliability modeling;statistical inference;covariate information;semiparametric Bayesian model;Gaussian process;software failure;software metrics information;deviance information criterion;predictive inference;future failure,,8.0,,30.0,,21 Dec 2012,,,IEEE,IEEE Journals
762,763,COVERT: Compositional Analysis of Android Inter-App Permission Leakage,H. Bagheri; A. Sadeghi; J. Garcia; S. Malek,"Department of Computer Science, George Mason University, Fairfax, VA; Department of Computer Science, George Mason University, Fairfax, VA 22030; Computer Science and Artificial Intelligence Laboratory at MIT, Cambridge, MA; Computer Science and Artificial Intelligence Laboratory at MIT, Cambridge, MA",IEEE Transactions on Software Engineering,15 Sep 2015,2015,41,9,866,886,"Android is the most popular platform for mobile devices. It facilitates sharing of data and services among applications using a rich inter-app communication system. While access to resources can be controlled by the Android permission system, enforcing permissions is not sufficient to prevent security violations, as permissions may be mismanaged, intentionally or unintentionally. Android's enforcement of the permissions is at the level of individual apps, allowing multiple malicious apps to collude and combine their permissions or to trick vulnerable apps to perform actions on their behalf that are beyond their individual privileges. In this paper, we present COVERT, a tool for compositional analysis of Android inter-app vulnerabilities. COVERT's analysis is modular to enable incremental analysis of applications as they are installed, updated, and removed. It statically analyzes the reverse engineered source code of each individual app, and extracts relevant security specifications in a format suitable for formal verification. Given a collection of specifications extracted in this way, a formal analysis engine (e.g., model checker) is then used to verify whether it is safe for a combination of applications-holding certain permissions and potentially interacting with each other-to be installed together. Our experience with using COVERT to examine over 500 real-world apps corroborates its ability to find inter-app vulnerabilities in bundles of some of the most popular apps on the market.",1939-3520,,10.1109/TSE.2015.2419611,US Defense Advanced Research Projects Agency; US National Security Agency; US Department of Homeland Security; US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7079508,Formal Verification;Static Analysis;Android;Inter-App Vulnerabilities;Formal verification;static analysis;Android;Inter-App vulnerabilities,Smart phones;Androids;Humanoid robots;Security;Analytical models;Data mining;Metals,Android (operating system);formal specification;formal verification;mobile computing;program diagnostics;security of data,COVERT tool;compositional analysis;formal analysis engine;security specification;formal verification;incremental analysis;Android inter-app vulnerabilities analysis;security violation;Android permission system;inter-app communication system;mobile devices;Android inter-app permission leakage,,59.0,1.0,60.0,,3 Apr 2015,,,IEEE,IEEE Journals
763,764,WAM—The Weighted Average Method for Predicting the Performance of Systems with Bursts of Customer Sessions,D. Krishnamurthy; J. Rolia; M. Xu,"University of Calgary, Calgary; Hewlett Packard Labs, Bristol; University of Calgary, Calgary",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,718,735,"Predictive performance models are important tools that support system sizing, capacity planning, and systems management exercises. We introduce the Weighted Average Method (WAM) to improve the accuracy of analytic predictive performance models for systems with bursts of concurrent customers. WAM considers the customer population distribution at a system to reflect the impact of bursts. The WAM approach is robust with respect to distribution functions, including heavy-tail-like distributions, for workload parameters. We demonstrate the effectiveness of WAM using a case study involving a multitier TPC-W benchmark system. To demonstrate the utility of WAM with multiple performance modeling approaches, we developed both Queuing Network Models and Layered Queuing Models for the system. Results indicate that WAM improves prediction accuracy for bursty workloads for QNMs and LQMs by 10 and 12 percent, respectively, with respect to a Markov Chain approach reported in the literature.",1939-3520,,10.1109/TSE.2011.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5953602,Performance of systems;modeling techniques;queuing theory;operational analysis.,Markov processes;Analytical models;Predictive models;Accuracy;Queueing analysis;Time factors;Software,Markov processes;queueing theory;software performance evaluation;systems analysis,weighted average method;system performance prediction;customer session bursts;system sizing;capacity planning;systems management exercises;analytic predictive performance models;heavy tail like distributions;multitier TPC-W benchmark system;queuing network models;layered queuing models;bursty workloads;Markov chain approach,,10.0,,41.0,,14 Jul 2011,,,IEEE,IEEE Journals
764,765,A Study of Causes and Consequences of Client-Side JavaScript Bugs,F. S. Ocariza; K. Bajaj; K. Pattabiraman; A. Mesbah,"Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,13 Feb 2017,2017,43,2,128,144,"Client-side JavaScript is widely used in web applications to improve user-interactivity and minimize client-server communications. Unfortunately, JavaScript is known to be error-prone. While prior studies have demonstrated the prevalence of JavaScript faults, no attempts have been made to determine their causes and consequences. The goal of our study is to understand the root causes and impact of JavaScript faults and how the results can impact JavaScript programmers, testers and tool developers. We perform an empirical study of 502 bug reports from 19 bug repositories. The bug reports are thoroughly examined to classify and extract information about each bug' cause (the error) and consequence (the failure and impact). Our results show that the majority (68 percent) of JavaScript faults are DOM-related, meaning they are caused by faulty interactions of the JavaScript code with the Document Object Model (DOM). Further, 80 percent of the highest impact JavaScript faults are DOM-related. Finally, most JavaScript faults originate from programmer mistakes committed in the JavaScript code itself, as opposed to other web application components. These results indicate that JavaScript programmers and testers need tools that can help them reason about the DOM. Additionally, developers can use the error patterns we found to design more powerful static analysis tools for JavaScript.",1939-3520,,10.1109/TSE.2016.2586066,Natural Sciences and Engineering Research Council of Canada (NSERC); Intel Corporation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7501855,Faults;JavaScript;Document Object Model (DOM);bug reports;empirical study,Computer bugs;Servers;Market research;HTML;Data mining;Reliability;Cascading style sheets,client-server systems;Internet;Java;program debugging;software fault tolerance,client-side JavaScript bugs;user-interactivity;client-server communications;JavaScript programmers;bug repositories;information extraction;DOM-related JavaScript faults;JavaScript code;document object model;Web application components;static analysis tools,,16.0,,55.0,,29 Jun 2016,,,IEEE,IEEE Journals
765,766,Improving Automated Bug Triaging with Specialized Topic Model,X. Xia; D. Lo; Y. Ding; J. M. Al-Kofahi; T. N. Nguyen; X. Wang,"College of Computer Science and Technology, Zhejiang University, Hangzhou, China; School of Information Systems, Singapore Management University, Singapore, Singapore; School of Information Systems, Singapore Management University, Singapore, Singapore; Electrical and Computer Engineering Department, Iowa State University, Ames, IA, USA; Electrical and Computer Engineering Department, Iowa State University, Ames, IA, USA; College of Computer Science and Technology, Zhejiang University, Hangzhou, China",IEEE Transactions on Software Engineering,13 Mar 2017,2017,43,3,272,297,"Bug triaging refers to the process of assigning a bug to the most appropriate developer to fix. It becomes more and more difficult and complicated as the size of software and the number of developers increase. In this paper, we propose a new framework for bug triaging, which maps the words in the bug reports (i.e., the term space) to their corresponding topics (i.e., the topic space). We propose a specialized topic modeling algorithm named  multi-feature topic model (MTM) which extends Latent Dirichlet Allocation (LDA) for bug triaging. MTM  considers product and component information of bug reports to map the term space to the topic space. Finally, we propose an incremental learning method named TopicMiner which considers the topic distribution of a new bug report to assign an appropriate fixer based on the affinity of the fixer to the topics. We pair  TopicMiner with MTM (TopicMiner$^{MTM}$ ). We have evaluated our solution on 5 large bug report datasets including GCC, OpenOffice, Mozilla, Netbeans, and Eclipse containing a total of 227,278 bug reports. We show that TopicMiner $^{MTM}$  can achieve top-1 and top-5 prediction accuracies of 0.4831-0.6868, and 0.7686-0.9084, respectively. We also compare TopicMiner$^{MTM}$  with Bugzie, LDA-KL, SVM-LDA, LDA-Activity, and Yang et al.'s approach. The results show that TopicMiner $^{MTM}$  on average improves top-1 and top-5 prediction accuracies of Bugzie by 128.48 and 53.22 percent, LDA-KL by 262.91 and 105.97 percent, SVM-LDA by 205.89 and 110.48 percent, LDA-Activity by 377.60 and 176.32 percent, and Yang et al.'s approach by 59.88 and 13.70 percent, respectively.",1939-3520,,10.1109/TSE.2016.2576454,National Basic Research Program of China (the 973 Program); NSFC; National Key Technology R&D Program; Ministry of Science and Technology of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7484672,Developer;bug triaging;feature information;topic model,Software;Resource management;Software algorithms;Support vector machines;Learning systems;Indexes;Computer bugs,,,,53.0,,46.0,,7 Jun 2016,,,IEEE,IEEE Journals
766,767,GreenDroid: Automated Diagnosis of Energy Inefficiency for Smartphone Applications,Y. Liu; C. Xu; S. C. Cheung; J. Lü,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; State Key Laboratory for Novel Software Technology and Department of Computer Science and Technology, Nanjing University, 163 Xianlin Avenue, Nanjing, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; State Key Laboratory for Novel Software Technology and Department of Computer Science and Technology, Nanjing University, 163 Xianlin Avenue, Nanjing, China",IEEE Transactions on Software Engineering,4 Sep 2014,2014,40,9,911,940,"Smartphone applications' energy efficiency is vital, but many Android applications suffer from serious energy inefficiency problems. Locating these problems is labor-intensive and automated diagnosis is highly desirable. However, a key challenge is the lack of a decidable criterion that facilitates automated judgment of such energy problems. Our work aims to address this challenge. We conducted an in-depth study of 173 open-source and 229 commercial Android applications, and observed two common causes of energy problems: missing deactivation of sensors or wake locks, and cost-ineffective use of sensory data. With these findings, wepropose an automated approach to diagnosing energy problems in Android applications. Our approach explores an application's state space by systematically executing the application using Java PathFinder (JPF). It monitors sensor and wake lock operations to detect missing deactivation of sensors and wake locks. It also tracks the transformation and usage of sensory data and judges whether they are effectively utilized by the application using our state-sensitive data utilization metric. In this way, our approach can generate detailed reports with actionable information to assist developers in validating detected energy problems. We built our approach as a tool, GreenDroid, on top of JPF. Technically, we addressed the challenges of generating user interaction events and scheduling event handlers in extending JPF for analyzing Android applications. We evaluated GreenDroid using 13 real-world popular Android applications. GreenDroid completed energy efficiency diagnosis for these applications in a few minutes. It successfully located real energy problems in these applications, and additionally found new unreported energy problems that were later confirmed by developers.",1939-3520,,10.1109/TSE.2014.2323982,Research Grants Council; National High-Tech Research & Development Program; National Natural Science Foundation; New Century Excellent Talents in University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815752,Smartphone application;energy inefficiency;automated diagnosis;sensory data utilization;green computing,Androids;Humanoid robots;Computer bugs;Sensors;Open source software;Green products;Google,Android (operating system);Java;power aware computing;program diagnostics;public domain software;smart phones,GreenDroid;automated energy inefficiency diagnosis;smartphone applications;labor-intensive diagnosis;automated diagnosis;open-source Android applications;commercial Android applications;Java PathFinder;JPF;wake lock operations;state-sensitive data utilization metric;user interaction events;scheduling event handlers,,40.0,,72.0,,14 May 2014,,,IEEE,IEEE Journals
767,768,A Controlled Experiment for Program Comprehension through Trace Visualization,B. Cornelissen; A. Zaidman; A. van Deursen,"Software Improvement Group, Amsterdam; Delft University of Technology, Delft; Delft University of Technology, Delft",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,341,355,"Software maintenance activities require a sufficient level of understanding of the software at hand that unfortunately is not always readily available. Execution trace visualization is a common approach in gaining this understanding, and among our own efforts in this context is Extravis, a tool for the visualization of large traces. While many such tools have been evaluated through case studies, there have been no quantitative evaluations to the present day. This paper reports on the first controlled experiment to quantitatively measure the added value of trace visualization for program comprehension. We designed eight typical tasks aimed at gaining an understanding of a representative subject system, and measured how a control group (using the Eclipse IDE) and an experimental group (using both Eclipse and Extravis) performed these tasks in terms of time spent and solution correctness. The results are statistically significant in both regards, showing a 22 percent decrease in time requirements and a 43 percent increase in correctness for the group using trace visualization.",1939-3520,,10.1109/TSE.2010.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5441291,Program comprehension;dynamic analysis;controlled experiment.,Visualization;Computer Society;Time measurement;Programming;Documentation;Scalability;Software maintenance;Gain measurement;Control systems;Performance evaluation,data visualisation;software maintenance,program comprehension;software maintenance;execution trace visualization,,63.0,,56.0,,1 Apr 2010,,,IEEE,IEEE Journals
768,769,Loupe: Verifying Publish-Subscribe Architectures with a Magnifying Lens,L. Baresi; C. Ghezzi; L. Mottola,"Politecnico di Milano, Milano; Politecnico di Milano, Milano; Politecnico di Milano, Milano",IEEE Transactions on Software Engineering,24 Mar 2011,2011,37,2,228,246,"The Publish-Subscribe (P/S) communication paradigm fosters high decoupling among distributed components. This facilitates the design of dynamic applications, but also impacts negatively on their verification, making it difficult to reason on the overall federation of components. In addition, existing P/S infrastructures offer radically different features to the applications, e.g., in terms of message reliability. This further complicates the verification as its outcome depends on the specific guarantees provided by the underlying P/S system. Although model checking has been proposed as a tool for the verification of P/S architectures, existing solutions overlook many characteristics of the underlying communication infrastructure to avoid state explosion problems. To overcome these limitations, the Loupe domain-specific model checker adopts a different approach. The P/S infrastructure is not modeled on top of a general-purpose model checker. Instead, it is embedded within the checking engine, and the traditional P/S operations become part of the modeling language. In this paper, we describe Loupe's design and the dedicated state abstractions that enable accurate verification without incurring state explosion problems. We also illustrate our use of state-of-the-art software verification tools to assess some key functionality in Loupe's current implementation. A complete case study shows how Loupe eases the verification of P/S architectures. Finally, we quantitatively compare Loupe's performance against alternative approaches. The results indicate that Loupe is effective and efficient in enabling accurate verification of P/S architectures.",1939-3520,,10.1109/TSE.2010.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432228,Publish-subscribe;verification;model-checking.,Publish-subscribe;Lenses;Application software;Explosions;Computer architecture;Context;Engines;Software tools;Software systems;Business communication,formal verification;message passing;middleware,publish-subscribe architectures;lens magnification;publish-subscribe communication paradigm;distributed component;P-S infrastructures;message reliability;P-S architectures verification;communication infrastructure;state explosion problem;Loupe domain-specific model checker;general purpose model checker;P-S operation;modeling language;Loupe design;dedicated state abstraction;state-of-the-art software verification tool,,10.0,,64.0,,18 Mar 2010,,,IEEE,IEEE Journals
769,770,Exploiting Dynamic Information in IDEs Improves Speed and Correctness of Software Maintenance Tasks,D. Rothlisberger; M. Harry; W. Binder; P. Moret; D. Ansaloni; A. Villazon; O. Nierstrasz,"Universitát Bern, Bern; Universitát Bern, Bern; University of Lugano (USI), Lugano; University of Lugano (USI), Lugano; University of Lugano (USI), Lugano; Universidad Privada Boliviana (UPB), Cochabamba; Universitát Bern, Bern",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,579,591,"Modern IDEs such as Eclipse offer static views of the source code, but such views ignore information about the runtime behavior of software systems. Since typical object-oriented systems make heavy use of polymorphism and dynamic binding, static views will miss key information about the runtime architecture. In this paper, we present an approach to gather and integrate dynamic information in the Eclipse IDE with the goal of better supporting typical software maintenance activities. By means of a controlled experiment with 30 professional developers, we show that for typical software maintenance tasks, integrating dynamic information into the Eclipse IDE yields a significant 17.5 percent decrease of time spent while significantly increasing the correctness of the solutions by 33.5 percent. We also provide a comprehensive performance evaluation of our approach.",1939-3520,,10.1109/TSE.2011.42,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6178187,Object-oriented programming;integrated environments;restructuring;reverse engineering;reengineering;complexity measures;performance measures.,Runtime;Measurement;Java;Context;Software maintenance;Concrete;Weaving,dynamic programming;object-oriented programming;program compilers;software maintenance,exploiting dynamic information;IDE;software maintenance tasks;Eclipse;source code;runtime behavior;software systems;object-oriented systems;dynamic binding;runtime architecture;dynamic information,,18.0,,35.0,,5 Apr 2012,,,IEEE,IEEE Journals
770,771,A Dynamic Slicing Technique for UML Architectural Models,J. T. Lallchandani; R. Mall,"Indian Institute of Technology Kharagpur, WB INDIA; Indian Institute of Technology Kharagpur, WB INDIA",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,737,771,"This paper proposes a technique for dynamic slicing of UML architectural models. The presence of related information in diverse model parts (or fragments) makes dynamic slicing of Unified Modeling Language (UML) models a complex problem. We first extract all relevant information from a UML model specifying a software architecture into an intermediate representation, which we call a Model Dependency Graph (MDG). For a given slicing criterion, our slicing algorithm traverses the constructed MDG to identify the relevant model parts that are directly or indirectly affected during the execution of a specified scenario. One novelty of our approach is computation of dynamic slice based on the structural and behavioral (interactions only) UML models as against independently processing separate UML models, and determining the implicit interdependencies among different model elements distributed across model views. We also briefly discuss a prototype tool named Archlice, which we have developed to implement our algorithm.",1939-3520,,10.1109/TSE.2010.112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680909,Software architecture;UML;architectural metamodel;dynamic slicing;impact analysis.,Unified modeling language;Computational modeling;Heuristic algorithms;Computer architecture;Analytical models;Software architecture;Software algorithms,program slicing;software architecture;software prototyping;Unified Modeling Language,dynamic slicing technique;UML architectural models;unified modeling language models;model dependency graph;software architecture;prototype tool;Archlice,,16.0,,46.0,,6 Jan 2011,,,IEEE,IEEE Journals
771,772,Putting Preemptive Time Petri Nets to Work in a V-Model SW Life Cycle,L. Carnevali; L. Ridi; E. Vicario,"Università di Firenze, Firenze; Università di Firenze, Firenze; Università di Firenze, Firenze",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,826,844,"Preemptive Time Petri Nets (pTPNs) support modeling and analysis of concurrent timed SW components running under fixed priority preemptive scheduling. The model is supported by a well-established theory based on symbolic state space analysis through Difference Bounds Matrix (DBM) zones, with specific contributions on compositional modularization, trace analysis, and efficient overapproximation and cleanup in the management of suspension deriving from preemptive behavior. In this paper, we devise and implement a framework that brings the theory to application. To this end, we cast the theory into an organic tailoring of design, coding, and testing activities within a V-Model SW life cycle in respect of the principles of regulatory standards applied to the construction of safety-critical SW components. To implement the toolchain subtended by the overall approach into a Model Driven Development (MDD) framework, we complement the theory of state space analysis with methods and techniques supporting semiformal specification and automated compilation into pTPN models and real-time code, measurement-based Execution Time estimation, test case selection and execution, coverage evaluation.",1939-3520,,10.1109/TSE.2011.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680913,Real-time systems;safety-critical SW components;SW life cycle;V-Model;preemptive Time Petri Nets;symbolic state space analysis;model driven development;automated model transformation;automated code generation;Execution Time estimation;real-time testing;test case selection and execution;coverage analysis.,Real time systems;Analytical models;Unified modeling language;Petri nets;Mathematical model;Computer architecture,formal specification;Petri nets;program diagnostics;program testing;safety-critical software;scheduling,preemptive time Petri nets;V-model SW life cycle;concurrent timed SW components;fixed priority preemptive scheduling;symbolic state space analysis;difference bounds matrix zones;compositional modularization;trace analysis;overapproximation;safety-critical SW components;model driven development framework;semiformal specification;automated compilation;pTPN models;real-time code;measurement-based execution time estimation;test case selection;test case execution;coverage evaluation,,11.0,,71.0,,6 Jan 2011,,,IEEE,IEEE Journals
772,773,"A General Testability Theory: Classes, Properties, Complexity, and Testing Reductions",I. Rodríguez; L. Llana; P. Rabanal,"Department of Sistemas Informáticos y Computación, Universidad Complutense de Madrid, Madrid, Spain; Department of Sistemas Informáticos y Computación, Universidad Complutense de Madrid, Madrid, Spain; Department of Sistemas Informáticos y Computación, Universidad Complutense de Madrid, Madrid, Spain",IEEE Transactions on Software Engineering,5 Sep 2014,2014,40,9,862,894,"In this paper we develop a general framework to reason about testing. The difficulty of testing is assessed in terms of the amount of tests that must be applied to determine whether the system is correct or not. Based on this criterion, five testability classes are presented and related. We also explore conditions that enable and disable finite testability, and their relation to testing hypotheses is studied. We measure how far incomplete test suites are from being complete, which allows us to compare and select better incomplete test suites. The complexity of finding that measure, as well as the complexity of finding minimum complete test suites, is identified. Furthermore, we address the reduction of testing problems to each other, that is, we study how the problem of finding test suites to test systems of some kind can be reduced to the problem of finding test suites for another kind of systems. This enables to export testing methods. In order to illustrate how general notions are applied to specific cases, many typical examples from the formal testing techniques domain are presented.",1939-3520,,10.1109/TSE.2014.2331690,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6839051,Formal testing techniques;general testing frameworks,Testing;Complexity theory;Proposals;Computational modeling;Probabilistic logic;Abstracts;Computer languages,formal languages;formal verification,general testability theory;complexity;testing reductions;testability classes;finite testability;incomplete test suites;formal testing techniques domain,,17.0,,35.0,,18 Jun 2014,,,IEEE,IEEE Journals
773,774,Methodbook: Recommending Move Method Refactorings via Relational Topic Models,G. Bavota; R. Oliveto; M. Gethers; D. Poshyvanyk; A. De Lucia,"University of Sannio, Benevento, Italy; University of Molise, Pesche (IS), Italy; Information Systems Department , University of Maryland, Baltimore County, 1000 Hilltop Circle, Baltimore; College of William and Mary, McGlothlin-Street Hall 006, Williamsburg; University of Salerno, Fisciano (SA), Italy",IEEE Transactions on Software Engineering,8 Jul 2014,2014,40,7,671,694,"During software maintenance and evolution the internal structure of the software system undergoes continuous changes. These modifications drift the source code away from its original design, thus deteriorating its quality, including cohesion and coupling of classes. Several refactoring methods have been proposed to overcome this problem. In this paper we propose a novel technique to identify Move Method refactoring opportunities and remove the Feature Envy bad smell from source code. Our approach, coined as Methodbook, is based on relational topic models (RTM), a probabilistic technique for representing and modeling topics, documents (in our case methods) and known relationships among these. Methodbook uses RTM to analyze both structural and textual information gleaned from software to better support move method refactoring. We evaluated Methodbook in two case studies. The first study has been executed on six software systems to analyze if the move method operations suggested by Methodbook help to improve the design quality of the systems as captured by quality metrics. The second study has been conducted with eighty developers that evaluated the refactoring recommendations produced by Methodbook. The achieved results indicate that Methodbook provides accurate and meaningful recommendations for move method refactoring operations.",1939-3520,,10.1109/TSE.2013.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6684534,Refactoring;relational topic models;empirical studies,Software systems;Couplings;Measurement;Object oriented modeling;Educational institutions;Electronic mail,software maintenance;software metrics;source code (software),Methodbook;recommending move method refactorings;relational topic model;software maintenance;source code;modifications drift;quality metrics;software development,,70.0,,57.0,,16 Dec 2013,,,IEEE,IEEE Journals
774,775,Atomicity Analysis of Service Composition across Organizations,C. Ye; S. C. Cheung; W. K. Chan; C. Xu,"The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong; City University of Hong Kong, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,2,28,"Atomicity is a highly desirable property for achieving application consistency in service compositions. To achieve atomicity, a service composition should satisfy the atomicity sphere, a structural criterion for the backend processes of involved services. Existing analysis techniques for atomicity sphere generally assume complete knowledge of all involved backend processes. Such an assumption is invalid when some service providers do not release all details of their backend processes to service consumers outside the organizations. To address this problem, we propose a process algebraic framework to publish atomicity-equivalent public views from the backend processes. These public views extract relevant task properties and reveal only partial process details that service providers need to expose. Our framework enables the analysis of atomicity sphere for service compositions using these public views instead of their backend processes. This allows service consumers to choose suitable services such that their composition satisfies the atomicity sphere without disclosing the details of their backend processes. Based on the theoretical result, we present algorithms to construct atomicity-equivalent public views and to analyze the atomicity sphere for a service composition. Two case studies from supply chain and insurance domains are given to evaluate our proposal and demonstrate the applicability of our approach.",1939-3520,,10.1109/TSE.2008.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4641941,Analysis;Specification;Software and System Safety;System integration and implementation;Formal methods;Model checking;Validation;Analysis;Specification;Software and System Safety;System integration and implementation;Formal methods;Model checking;Validation,Web services;Privacy;System recovery;Supply chains;Protection;Application software;Algorithm design and analysis;Insurance;Algebra;Internet,process algebra;Web services,atomicity sphere analysis;Web service composition;backend process;process algebraic framework;atomicity-equivalent public view;supply chain;insurance,,22.0,,76.0,,10 Oct 2008,,,IEEE,IEEE Journals
775,776,Quantifying the Effect of Code Smells on Maintenance Effort,D. I. K. Sjøberg; A. Yamashita; B. C. D. Anda; A. Mockus; T. Dybå,"University of Oslo, Oslo; University of Oslo, Oslo; University of Oslo, Oslo; Avaya Labs Research, Basking Ridge; University of Oslo, Oslo and SINTEF, Trondheim",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1144,1156,"Context: Code smells are assumed to indicate bad design that leads to less maintainable code. However, this assumption has not been investigated in controlled studies with professional software developers. Aim: This paper investigates the relationship between code smells and maintenance effort. Method: Six developers were hired to perform three maintenance tasks each on four functionally equivalent Java systems originally implemented by different companies. Each developer spent three to four weeks. In total, they modified 298 Java files in the four systems. An Eclipse IDE plug-in measured the exact amount of time a developer spent maintaining each file. Regression analysis was used to explain the effort using file properties, including the number of smells. Result: None of the 12 investigated smells was significantly associated with increased effort after we adjusted for file size and the number of changes; Refused Bequest was significantly associated with decreased effort. File size and the number of changes explained almost all of the modeled variation in effort. Conclusion: The effects of the 12 smells on maintenance effort were limited. To reduce maintenance effort, a focus on reducing code size and the work practices that limit the number of changes may be more beneficial than refactoring code smells.",1939-3520,,10.1109/TSE.2012.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392174,Maintainability;object-oriented design;product metrics;code churn,Maintenance engineering;Java;Software;Surgery;Time measurement;Context;Electronic mail,Java;regression analysis;software maintenance,code smell effect quantification;maintenance effort;maintainable code;maintenance tasks;Java systems;Java files;Eclipse IDE plug-in;regression analysis;file properties;refused bequest;file size;code size reduction;code smell refactoring,,142.0,,46.0,,21 Dec 2012,,,IEEE,IEEE Journals
776,777,GUI Interaction Testing: Incorporating Event Context,X. Yuan; M. B. Cohen; A. M. Memon,"Google Kirkland; University of Nebraska-Lincoln, Lincoln; University of Maryland, College Park",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,559,574,"Graphical user interfaces (GUIs), due to their event-driven nature, present an enormous and potentially unbounded way for users to interact with software. During testing, it is important to “adequately cover” this interaction space. In this paper, we develop a new family of coverage criteria for GUI testing grounded in combinatorial interaction testing. The key motivation of using combinatorial techniques is that they enable us to incorporate “context” into the criteria in terms of event combinations, sequence length, and by including all possible positions for each event. Our new criteria range in both efficiency (measured by the size of the test suite) and effectiveness (the ability of the test suites to detect faults). In a case study on eight applications, we automatically generate test cases and systematically explore the impact of context, as captured by our new criteria. Our study shows that by increasing the event combinations tested and by controlling the relative positions of events defined by the new criteria, we can detect a large number of faults that were undetectable by earlier techniques.",1939-3520,,10.1109/TSE.2010.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444885,GUI testing;automated testing;model-based testing;combinatorial interaction testing;GUITAR testing system.,Graphical user interfaces;System testing;Software testing;Automatic testing;Fault detection;Context modeling;Computer science;Software performance;Logic testing;User interfaces,automatic test pattern generation;graphical user interfaces;program testing,GUI interaction testing;graphical user interface;event driven nature;combinatorial interaction testing;automatic test case generation,,89.0,4.0,44.0,,8 Apr 2010,,,IEEE,IEEE Journals
777,778,Directed Explicit State-Space Search in the Generation of Counterexamples for Stochastic Model Checking,H. Aljazzar; S. Leue,"University of Konstanz, Konstanz; University of Konstanz, Konstanz",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,37,60,"Current stochastic model checkers do not make counterexamples for property violations readily available. In this paper, we apply directed explicit state-space search to discrete and continuous-time Markov chains in order to compute counterexamples for the violation of PCTL or CSL properties. Directed explicit state-space search algorithms explore the state space on-the-fly, which makes our method very efficient and highly scalable. They can also be guided using heuristics which usually improve the performance of the method. Counterexamples provided by our method have two important properties. First, they include those traces which contribute the greatest amount of probability to the property violation. Hence, they show the most probable offending execution scenarios of the system. Second, the obtained counterexamples tend to be small. Hence, they can be effectively analyzed by a human user. Both properties make the counterexamples obtained by our method very useful for debugging purposes. We implemented our method based on the stochastic model checker PRISM and applied it to a number of case studies in order to illustrate its applicability.",1939-3520,,10.1109/TSE.2009.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5262946,Directed explicit state-space search;heuristic search;counterexamples;stochastic model checking.,Stochastic processes;Debugging;Probabilistic logic;Safety;Performance analysis;Space exploration;State-space methods;Humans;Shape;Sampling methods,formal verification;Markov processes;program debugging;tree searching,directed explicit state-space search;stochastic model checking;discrete-time Markov chains;continuous-time Markov chains;PCTL properties;CSL properties;heuristic search;debugging,,31.0,,49.0,,25 Sep 2009,,,IEEE,IEEE Journals
778,779,"Conservative Reasoning about the Probability of Failure on Demand of a 1-out-of-2 Software-Based System in Which One Channel Is ""Possibly Perfect""",B. Littlewood; A. Povyakalo,"City University London, London; City University London, London",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1521,1530,"In earlier work, [11] (henceforth LR), an analysis was presented of a 1-out-of-2 software-based system in which one channel was “possibly perfect”. It was shown that, at the aleatory level, the system pfd (probability of failure on demand) could be bounded above by the product of the pfd of channel A and the pnp (probability of nonperfection) of channel B. This result was presented as a way of avoiding the well-known difficulty that for two certainly-fallible channels, failures of the two will be dependent, i.e., the system pfd cannot be expressed simply as a product of the channel pfds. A price paid in this new approach for avoiding the issue of failure dependence is that the result is conservative. Furthermore, a complete analysis requires that account be taken of epistemic uncertainty-here concerning the numeric values of the two parameters pfdA and pnpB. Unfortunately this introduces a different difficult problem of dependence: estimating the dependence between an assessor's beliefs about the parameters. The work reported here avoids this problem by obtaining results that require only an assessor's marginal beliefs about the individual channels, i.e., they do not require knowledge of the dependence between these beliefs. The price paid is further conservatism in the results.",1939-3520,,10.1109/TSE.2013.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574864,Software reliability;fault tolerance;software perfection;probability of failure;epistemic uncertainty;software diversity;multiversion software,Phase frequency detector;Uncertainty;Cognition;Software reliability;Software;Safety,belief networks;failure analysis;probability;software reliability;uncertainty handling,conservative reasoning;probability of failure on demand;1-out-of-2 software-based system;PFD;PNP;probability of nonperfection;certainly fallible channel;assessor marginal belief;epistemic uncertainty;software perfection,,4.0,,15.0,,5 Aug 2013,,,IEEE,IEEE Journals
779,780,An Empirical Study of RefactoringChallenges and Benefits at Microsoft,M. Kim; T. Zimmermann; N. Nagappan,"Department of Electrical and Computer Engineering, University of Texas, Austin; Microsoft Research at Redmond; Microsoft Research at Redmond",IEEE Transactions on Software Engineering,8 Jul 2014,2014,40,7,633,649,"It is widely believed that refactoring improves software quality and developer productivity. However, few empirical studies quantitatively assess refactoring benefits or investigate developers' perception towards these benefits. This paper presents a field study of refactoring benefits and challenges at Microsoft through three complementary study methods: a survey, semi-structured interviews with professional software engineers, and quantitative analysis of version history data. Our survey finds that the refactoring definition in practice is not confined to a rigorous definition of semantics-preserving code transformations and that developers perceive that refactoring involves substantial cost and risks. We also report on interviews with a designated refactoring team that has led a multi-year, centralized effort on refactoring Windows. The quantitative analysis of Windows 7 version history finds the top 5 percent of preferentially refactored modules experience higher reduction in the number of inter-module dependencies and several complexity measures but increase size more than the bottom 95 percent. This indicates that measuring the impact of refactoring requires multi-dimensional assessment.",1939-3520,,10.1109/TSE.2014.2318734,National Science Foundation; Microsoft SEIF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802406,Refactoring;empirical study;software evolution;component dependencies;defects;churn,Computer bugs;Software;Interviews;History;Complexity theory;Size measurement;Software metrics,data analysis;software maintenance;software metrics;software quality,refactoring challenges;refactoring benefits;Microsoft;software quality improvement;survey;semi-structured interviews;quantitative Windows 7 version history data analysis;intermodule dependencies;complexity measures;software evolution,,62.0,,58.0,,18 Apr 2014,,,IEEE,IEEE Journals
780,781,Mining Crosscutting Concerns through Random Walks,C. Zhang; H. Jacobsen,"The Hong Kong University of Science and Technology, Hong Kong; University of Toronto, Toronto",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1123,1137,"Inspired by our past manual aspect mining experiences, this paper describes a probabilistic random walk model to approximate the process of discovering crosscutting concerns (CCs) in the absence of the domain knowledge about the investigated application. The random walks are performed on the concept graphs extracted from the program sources to calculate metrics of “utilization” and “aggregation” for each of the program elements. We rank all the program elements based on these metrics and use a threshold to produce a set of candidates that represent crosscutting concerns. We implemented the algorithm as the Prism CC miner (PCM) and evaluated PCM on Java applications ranging from a small-scale drawing application to a medium-sized middleware application and to a large-scale enterprise application server. Our quantification shows that PCM is able to produce comparable results (95 percent accuracy for the top 125 candidates) with respect to the manual mining effort. PCM is also significantly more effective as compared to the conventional approach.",1939-3520,,10.1109/TSE.2011.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5989837,Aspect mining;mining crosscutting concerns,Phase change materials;Radiation detectors;Data mining;Manuals;Mathematical model;Computational modeling;Algorithm design and analysis,aspect-oriented programming;data mining;graph theory;Java;middleware;probability;small-to-medium enterprises,crosscutting concerns mining;probabilistic random walk model;concept graphs;utilization metric;aggregation metric;program sources;program elements;Prism CC miner;Java applications;small-scale drawing application;medium-sized middleware application;large-scale enterprise application server;aspect mining,,6.0,,37.0,,18 Aug 2011,,,IEEE,IEEE Journals
781,782,A Framework for Programming Robust Context-Aware Applications,D. Kulkarni; A. Tripathi,"University of Minnesota, Minneapolis; University of Minnesota, Minneapolis",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,184,197,"In this paper, we present a forward recovery model for programming robust context-aware applications. The mechanisms devised as part of this model fall into two categories: asynchronous event handling and synchronous exception handling. These mechanisms enable designing recovery actions to handle different kinds of failure conditions arising in context-aware applications. These include service discovery failures, service binding failures, exceptions raised by a service, and context invalidations. This model is integrated in the high-level programming framework that we have designed for building context-aware collaborative (CSCW) applications. In this paper, we demonstrate the capabilities of this model for programming various kinds of recovery patterns in context-aware applications.",1939-3520,,10.1109/TSE.2010.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5396345,Exception handling;context-aware applications;robustness;fault tolerance;design methodology.,Robustness;Context-aware services;Context modeling;Access control;Application software;Collaboration;Information systems;Buildings;Fault tolerance;Design methodology,exception handling;groupware;object-oriented programming;software fault tolerance;system recovery;ubiquitous computing,robust context aware application programming;forward recovery model;asynchronous event handling;synchronous exception handling;recovery patterns;service discovery failures;service binding failures;context invalidations;high level programming framework;context aware collaborative applications;CSCW,,40.0,,30.0,,22 Jan 2010,,,IEEE,IEEE Journals
782,783,Analyzing Critical Decision-Based Processes,C. Damas; B. Lambeau; A. van Lamsweerde,"Department of Computing, Icteam Institute, Université Catholique de Louvain, Louvain-La-Neuve, Belgium; Department of Computing, Icteam Institute, Université Catholique de Louvain, Louvain-La-Neuve, Belgium; Department of Computing, Icteam Institute, Université Catholique de Louvain, Louvain-La-Neuve, Belgium",IEEE Transactions on Software Engineering,2 May 2014,2014,40,4,338,365,"Decision-based processes are composed of tasks whose application may depend on explicit decisions relying on the state of the process environment. In specific domains such as healthcare, decision-based processes are often complex and critical in terms of timing and resources. The paper presents a variety of tool-supported techniques for analyzing models of such processes. The analyses allow a variety of errors to be detected early and incrementally on partial models, notably: inadequate decisions resulting from inaccurate or outdated information about the environment state; incomplete decisions; non-deterministic task selections; unreachable tasks along process paths; and violations of non-functional process requirements involving time, resources or costs. The proposed techniques are based on different instantiations of the same generic algorithm that propagates decorations iteratively through the process model. This algorithm in particular allows event-based models to be automatically decorated with state-based invariants. A formal language supporting both event-based and state-based specifications is introduced as a process modeling language to enable such analyses. This language mimics the informal flowcharts commonly used by process stakeholders. It extends High-Level Message Sequence Charts with guards on task-related and environment-related variables. The language provides constructs for specifying task compositions, task refinements, decision trees, multi-agent communication scenarios, and time and resource constraints. The proposed techniques are demonstrated on the incremental building and analysis of a complex model of a real protocol for cancer therapy.",1939-3520,,10.1109/TSE.2014.2312954,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6776491,Process modeling;process analysis;model verification;decision errors;safety-critical workflows;non-functional requirements;domain-specific languages;formal specification,Analytical models;Unified modeling language;Algorithm design and analysis;Semantics;Blood;Flowcharts;Medical treatment,cancer;decision trees;formal languages;formal specification;multi-agent systems;patient treatment,critical decision-based process analysis;tool-supported techniques;partial models;environment state;incomplete decisions;nondeterministic task selections;unreachable tasks;process paths;nonfunctional process requirement violation;event-based models;state-based invariants;formal language;event-based specification;state-based specification;process modeling language;informal flowcharts;high-level message sequence charts;task-related variables;environment-related variables;task compositions;task refinements;decision trees;multiagent communication scenarios;time constraints;resource constraints;cancer therapy,,2.0,,80.0,,20 Mar 2014,,,IEEE,IEEE Journals
783,784,Software Architecture Optimization Methods: A Systematic Literature Review,A. Aleti; B. Buhnova; L. Grunske; A. Koziolek; I. Meedeniya,"Monash University, Australia; Masaryk University, Brno; University of Kaiserslautern, Kaiserslautern; University of Zurich, Zurich; Swinburne University of Technology, Hawthorn",IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,658,683,"Due to significant industrial demands toward software systems with increasing complexity and challenging quality requirements, software architecture design has become an important development activity and the research domain is rapidly evolving. In the last decades, software architecture optimization methods, which aim to automate the search for an optimal architecture design with respect to a (set of) quality attribute(s), have proliferated. However, the reported results are fragmented over different research communities, multiple system domains, and multiple quality attributes. To integrate the existing research results, we have performed a systematic literature review and analyzed the results of 188 research papers from the different research communities. Based on this survey, a taxonomy has been created which is used to classify the existing research. Furthermore, the systematic analysis of the research literature provided in this review aims to help the research community in consolidating the existing research efforts and deriving a research agenda for future developments.",1939-3520,,10.1109/TSE.2012.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311410,Software architecture optimization;systematic literature review;optimization methods;problem overview,Taxonomy;Computer architecture;Software;Software architecture;Systematics;Optimization methods,software architecture;software quality,software architecture optimization method;software system;software architecture design;software quality attribute,,138.0,,245.0,,24 Sep 2012,,,IEEE,IEEE Journals
784,785,CHARMY: A Framework for Designing and Verifying Architectural Specifications,P. Pelliccione; P. Inverardi; H. Muccini,"Università dell' Aquila, L'Aquila; Università dell' Aquila, L'Aquila; Università dell' Aquila, L'Aquila",IEEE Transactions on Software Engineering,2 Jun 2009,2009,35,3,325,346,"Introduced in the early stages of software development, the Charmy framework assists the software architect in making and evaluating architectural choices. Rarely, the software architecture of a system can be established once and forever. Most likely poorly defined and understood architectural constraints and requirements force the software architect to accept ambiguities and move forward to the construction of a suboptimal software architecture. Charmy aims to provide an easy and practical tool for supporting the iterative modeling and evaluation of software architectures. From an UML-based architectural design, an executable prototype is automatically created. Charmy simulation and model checking features help in understanding the functioning of the system and discovering potential inconsistencies of the design. When a satisfactory and stable software architecture is reached, Java code conforming to structural software architecture constraints is automatically generated through suitable transformations. The overall approach is tool supported.",1939-3520,,10.1109/TSE.2008.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711062,Software architectures;model checking.;Software Architectures;Model checking;Design notations and documentation;State diagrams;Rapid prototyping,Software architecture;Computer architecture;Software prototyping;Software systems;Prototypes;Connectors;Unified modeling language;Programming;Java;Topology,Java;program verification;software architecture;Unified Modeling Language,software development;Charmy framework;UML-based architectural design;model checking;Java code;structural software architecture constraints,,39.0,,39.0,,12 Dec 2008,,,IEEE,IEEE Journals
785,786,Aspectizing Java Access Control,R. Toledo; A. Nunez; E. Tanter; J. Noye,"University of Chile, Santiago; École des Mines de Nantes-INRIA, LINA, Nantes; University of Chile, Santiago; École des Mines de Nantes-INRIA, LINA, Nantes",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,101,117,"It is inevitable that some concerns crosscut a sizeable application, resulting in code scattering and tangling. This issue is particularly severe for security-related concerns: It is difficult to be confident about the security of an application when the implementation of its security-related concerns is scattered all over the code and tangled with other concerns, making global reasoning about security precarious. In this study, we consider the case of access control in Java, which turns out to be a crosscutting concern with a nonmodular implementation based on runtime stack inspection. We describe the process of modularizing access control in Java by means of Aspect-Oriented Programming (AOP). We first show a solution based on AspectJ, the most popular aspect-oriented extension to Java, that must rely on a separate automata infrastructure. We then put forward a novel solution via dynamic deployment of aspects and scoping strategies. Both solutions, apart from providing a modular specification of access control, make it possible to easily express other useful policies such as the Chinese wall policy. However, relying on expressive scope control results in a compact implementation, which, at the same time, permits the straightforward expression of even more interesting policies. These new modular implementations allowed by AOP alleviate maintenance and evolution issues produced by the crosscutting nature of access control.",1939-3520,,10.1109/TSE.2011.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680915,Programming languages;security;aspect-oriented programming;access control.,Aspect-oriented programming;Access control;Computer architecture;Java;Programming;Computer security,aspect-oriented programming;authorisation;automata theory;Java,Java access control aspectization;code scattering;code tangling;security-related concerns;runtime stack inspection;aspect-oriented programming;AspectJ;automata infrastructure;aspects strategies;scoping strategies;Chinese wall policy,,6.0,,45.0,,6 Jan 2011,,,IEEE,IEEE Journals
786,787,A Component Model for Model Transformations,J. S. Cuadrado; E. Guerra; J. de Lara,"Department of Computer Science, Universidad Autónoma de Madrid, Spain; Department of Computer Science, Universidad Autónoma de Madrid, Spain; Department of Computer Science, Universidad Autónoma de Madrid, Spain",IEEE Transactions on Software Engineering,10 Nov 2014,2014,40,11,1042,1060,"Model-driven engineering promotes an active use of models to conduct the software development process. In this way, models are used to specify, simulate, verify, test and generate code for the final systems. Model transformations are key enablers for this approach, being used to manipulate instance models of a certain modelling language. However, while other development paradigms make available techniques to increase productivity through reutilization, there are few proposals for the reuse of model transformations across different modelling languages. As a result, transformations have to be developed from scratch even if other similar ones exist. In this paper, we propose a technique for the flexible reutilization of model transformations. Our proposal is based on generic programming for the definition and instantiation of transformation templates, and on component-based development for the encapsulation and composition of transformations. We have designed a component model for model transformations, supported by an implementation currently targeting the Atlas Transformation Language (ATL). To evaluate its reusability potential, we report on a generic transformation component to analyse workflow models through their transformation into Petri nets, which we have reused for eight workflow languages, including UML Activity Diagrams, YAWL and two versions of BPMN.",1939-3520,,10.1109/TSE.2014.2339852,Spanish Ministry of Economy and Competitivity with project Go-Lite; EU commission with project MONDO; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6858077,Model-driven engineering;model transformation;reusability;genericity;component-based development,Unified modeling language;Adaptation models;Petri nets;Analytical models;Logic gates;Software;Proposals,object-oriented programming;Petri nets;software reusability,BPMN;YAWL;UML activity diagrams;workflow languages;Petri nets;workflow models;generic transformation component;ATL;Atlas transformation language;component-based development;generic programming;modelling language instance models;software development process;model-driven engineering;model transformations;component model,,25.0,,69.0,,17 Jul 2014,,,IEEE,IEEE Journals
787,788,Dependence Guided Symbolic Execution,H. Wang; T. Liu; X. Guan; C. Shen; Q. Zheng; Z. Yang,"Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI",IEEE Transactions on Software Engineering,13 Mar 2017,2017,43,3,252,271,"Symbolic execution is a powerful technique for systematically exploring the paths of a program and generating the corresponding test inputs. However, its practical usage is often limited by the path explosion problem, that is, the number of explored paths usually grows exponentially with the increase of program size. In this paper, we argue that for the purpose of fault detection it is not necessary to systematically explore the paths, and propose a new symbolic execution approach to mitigate the path explosion problem by predicting and eliminating the redundant paths based on symbolic value. Our approach can achieve the equivalent fault detection capability as traditional symbolic execution without exhaustive path exploration. In addition, we develop a practical implementation called Dependence Guided Symbolic Execution (DGSE) to soundly approximate our approach. Through exploiting program dependence, DGSE can predict and eliminate the redundant paths at a reasonable computational cost. Our empirical study shows that the redundant paths are abundant and widespread in a program. Compared with traditional symbolic execution, DGSE only explores 6.96 to 96.57 percent of the paths and achieves a speedup of 1.02 $\times$  to 49.56$\times$ . We have released our tool and the benchmarks used to evaluate DGSE$^\ast$ .",1939-3520,,10.1109/TSE.2016.2584063,National Natural Science Foundation of China; Fok Ying-Tong Education Foundation; National Research Program of China; Ministry of Education Innovation Research Team; Fundamental Research Funds for the Central Universities; US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7497518,Symbolic execution;path coverage;program dependence,Fault detection;Explosions;Benchmark testing;Electronic mail;Computational efficiency;Input variables,,,,19.0,,65.0,,22 Jun 2016,,,IEEE,IEEE Journals
788,789,CoMoM: Efficient Class-Oriented Evaluation of Multiclass Performance Models,G. Casale,"College of William and Mary, Williamsburg",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,162,177,"We introduce the class-oriented method of moments (CoMoM), a new exact algorithm to compute performance indexes in closed multiclass queuing networks. Closed models are important for performance evaluation of multitier applications, but when the number of service classes is large, they become too expensive to solve with exact methods such as mean value analysis (MVA). CoMoM addresses this limitation by a new recursion that scales efficiently with the number of classes. Compared to the MVA algorithm, which recursively computes mean queue lengths, CoMoM also carries on in the recursion information on higher-order moments of queue lengths. We show that this additional information greatly reduces the number of operations needed to solve the model and makes CoMoM the best-available algorithm for networks with several classes. We conclude the paper by generalizing CoMoM to the efficient computation of marginal queue-length probabilities, which finds application in the evaluation of state-dependent attributes such as quality-of-service metrics.",1939-3520,,10.1109/TSE.2008.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4641939,Performance of Systems;Modeling techniques;Queuing theory;Performance of Systems;Modeling techniques;Queuing theory,Performance analysis;Moment methods;Quality of service;Queueing analysis;Network servers;Computer networks;Capacity planning;Web server;Transaction databases;Algorithm design and analysis,method of moments;probability;quality of service;queueing theory,class-oriented method of moment;closed multiclass queueing network;marginal queue-length probability;performance evaluation;multitier application;mean value analysis;higher-order moment;J2EE application;state-dependent index evaluation;energy consumption;quality-of-service metrics,,6.0,,24.0,,10 Oct 2008,,,IEEE,IEEE Journals
789,790,Equality to Equals and Unequals: A Revisit of the Equivalence and Nonequivalence Criteria in Class-Level Testing of Object-Oriented Software,H. Y. Chen; T. H. Tse,"Jinan University, Guangzhou; The University of Hong Kong, Hong Kong",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1549,1563,"Algebraic specifications have been used in the testing of object-oriented programs and received much attention since the 1990s. It is generally believed that class-level testing based on algebraic specifications involves two independent aspects: the testing of equivalent and nonequivalent ground terms. Researchers have cited intuitive examples to illustrate the philosophy that even if an implementation satisfies all the requirements specified by the equivalence of ground terms, it may still fail to satisfy some of the requirements specified by the nonequivalence of ground terms. Thus, both the testing of equivalent ground terms and the testing of nonequivalent ground terms have been considered as significant and cannot replace each other. In this paper, we present an innovative finding that, given any canonical specification of a class with proper imports, a complete implementation satisfies all the observationally equivalent ground terms if and only if it satisfies all the observationally nonequivalent ground terms. As a result, these two aspects of software testing cover each other and can therefore replace each other. These findings provide a deeper understanding of software testing based on algebraic specifications, rendering the theory more elegant and complete. We also highlight a couple of important practical implications of our theoretical results.",1939-3520,,10.1109/TSE.2013.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6570471,Software testing;equivalence criterion;nonequivalence criterion;algebraic specification;object-oriented software,Software;Software testing;Observers;Context;Semantics;Computer science,algebraic specification;object-oriented programming;program testing,nonequivalence criteria;class-level testing;object-oriented software;algebraic specifications;object-oriented programs;equivalent ground terms;canonical specification;software testing,,7.0,,33.0,,26 Jul 2013,,,IEEE,IEEE Journals
790,791,A Survey on Metamorphic Testing,S. Segura; G. Fraser; A. B. Sanchez; A. Ruiz-Cortés,"Department of Computer Languages and Systems, Universidad de Sevilla, Spain; Department of Computer Science, University of Sheffield, Sheffield, United Kingdom; Department of Computer Languages and Systems, Universidad de Sevilla, Spain; Department of Computer Languages and Systems, Universidad de Sevilla, Spain",IEEE Transactions on Software Engineering,15 Sep 2016,2016,42,9,805,824,"A test oracle determines whether a test execution reveals a fault, often by comparing the observed program output to the expected output. This is not always practical, for example when a program's input-output relation is complex and difficult to capture formally. Metamorphic testing provides an alternative, where correctness is not determined by checking an individual concrete output, but by applying a transformation to a test input and observing how the program output “morphs” into a different one as a result. Since the introduction of such metamorphic relations in 1998, many contributions on metamorphic testing have been made, and the technique has seen successful applications in a variety of domains, ranging from web services to computer graphics. This article provides a comprehensive survey on metamorphic testing: It summarises the research results and application areas, and analyses common practice in empirical studies of metamorphic testing as well as the main open challenges.",1939-3520,,10.1109/TSE.2016.2532875,European Commission (FEDER); Spanish Government; CICYT projects TAPAS; BELI; Andalusian Government projects THEOS; COPAS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7422146,Metamorphic testing;oracle problem;survey,Testing;Search engines;Google;Libraries;Concrete;Distance measurement;Web services,program testing,metamorphic testing;test oracle;test execution;metamorphic relations,,120.0,,148.0,,29 Feb 2016,,,IEEE,IEEE Journals
791,792,Test Case Prioritization Using Lexicographical Ordering,S. Eghbali; L. Tahvildari,"Department of Electrical and Computer Engineering, 200 University Ave West, University of Waterloo, Waterloo, Ontario; Department of Electrical and Computer Engineering, 200 University Ave West, University of Waterloo, Waterloo, Ontario",IEEE Transactions on Software Engineering,8 Dec 2016,2016,42,12,1178,1195,"Test case prioritization aims at ordering test cases to increase the rate of fault detection, which quantifies how fast faults are detected during the testing phase. A common approach for test case prioritization is to use the information of previously executed test cases, such as coverage information, resulting in an iterative (greedy) prioritization algorithm. Current research in this area validates the fact that using coverage information can improve the rate of fault detection in prioritization algorithms. The performance of such iterative prioritization schemes degrade as the number of ties encountered in prioritization steps increases. In this paper, using the notion of lexicographical ordering, we propose a new heuristic for breaking ties in coverage based techniques. Performance of the proposed technique in terms of the rate of fault detection is empirically evaluated using a wide range of programs. Results indicate that the proposed technique can resolve ties and in turn noticeably increases the rate of fault detection.",1939-3520,,10.1109/TSE.2016.2550441,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7456343,Regression testing;test case prioritization;lexicographical ordering,Software testing;Fault detection;Feature extraction;Regression analysis;Fault diagnosis,fault diagnosis;greedy algorithms;iterative methods;program testing;regression analysis,regression testing;coverage information;iterative greedy prioritization algorithm;fault detection;lexicographical ordering;test case prioritization,,24.0,,60.0,,21 Apr 2016,,,IEEE,IEEE Journals
792,793,Abstracting runtime heaps for program understanding,M. Marron; C. Sanchez; Z. Su; M. Fahndrich,"Imdea Software Institute, Boadilla del Monte; Imdea Software Institute, Boadilla del Monte; University of California, Davis, Davis; Microsoft Research",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,774,786,"Modern programming environments provide extensive support for inspecting, analyzing, and testing programs based on the algorithmic structure of a program. Unfortunately, support for inspecting and understanding runtime data structures during execution is typically much more limited. This paper provides a general purpose technique for abstracting and summarizing entire runtime heaps. We describe the abstract heap model and the associated algorithms for transforming a concrete heap dump into the corresponding abstract model as well as algorithms for merging, comparing, and computing changes between abstract models. The abstract model is designed to emphasize high-level concepts about heap-based data structures, such as shape and size, as well as relationships between heap structures, such as sharing and connectivity. We demonstrate the utility and computational tractability of the abstract heap model by building a memory profiler. We use this tool to identify, pinpoint, and correct sources of memory bloat for programs from DaCapo.",1939-3520,,10.1109/TSE.2012.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331492,Heap structure;runtime analysis;memory profiling;program understanding,Abstracts;Concrete;Shape;Runtime;Arrays;Computational modeling,data structures;merging;program diagnostics;program testing,program testing;program analysis;program inspection;program algorithmic structure;runtime data structure relationships;runtime heap abstracting;runtime heap summarization;concrete heap dump;program merging;program comparison;program computing;high-level concepts;heap structure sharing;heap structure connectivity;abstract heap model utility;abstract heap model computational tractability;memory profiler;memory bloat;DaCapo,,10.0,,37.0,,16 Oct 2012,,,IEEE,IEEE Journals
793,794,A Systematic Study on Explicit-State Non-Zenoness Checking for Timed Automata,T. Wang; J. Sun; X. Wang; Y. Liu; Y. Si; J. S. Dong; X. Yang; X. Li,"College of Computer Science, Zhejiang University, P.R., China; ISTD, Singapore University of Technology and Design, Singapore; College of Computer Science, Zhejiang University, P.R., China; School of Computer Engineering, Nanyang Technological University, Singapore; College of Computer Science, Zhejiang University, P.R., China; School of Computing, National University of Singapore, Singapore; College of Computer Science, Zhejiang University, P.R., China; School of Computer Science and Technology, Tianjin University, P.R., China",IEEE Transactions on Software Engineering,7 Jan 2015,2015,41,1,3,18,"Zeno runs, where infinitely many actions occur within finite time, may arise in Timed Automata models. Zeno runs are not feasible in reality and must be pruned during system verification. Thus it is necessary to check whether a run is Zeno or not so as to avoid presenting Zeno runs as counterexamples during model checking. Existing approaches on non-Zenoness checking include either introducing an additional clock in the Timed Automata models or additional accepting states in the zone graphs. In addition, there are approaches proposed for alternative timed modeling languages, which could be generalized to Timed Automata. In this work, we investigate the problem of non-Zenoness checking in the context of model checking LTL properties, not only evaluating and comparing existing approaches but also proposing a new method. To have a systematic evaluation, we develop a software toolkit to support multiple non-Zenoness checking algorithms. The experimental results show the effectiveness of our newly proposed algorithm, and demonstrate the strengths and weaknesses of different approaches.",1939-3520,,10.1109/TSE.2014.2359893,National Natural Science Foundation Program; National Key Technology Support Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6908008,Timed automata;non-Zenoness;model checking;verification tool,Automata;Clocks;Safety;Educational institutions;Systematics;Cost accounting;Model checking,automata theory;formal verification;graph theory;real-time systems,explicit-state nonzenoness checking;timed automata models;zeno runs;system verification;clocks;zone graphs;timed modeling languages;model checking LTL properties;systematic evaluation;software toolkit,,3.0,,37.0,,23 Sep 2014,,,IEEE,IEEE Journals
794,795,Parallel Performance Problems on Shared-Memory Multicore Systems: Taxonomy and Observation,R. Atachiants; G. Doherty; D. Gregg,"Trinity College Dublin, Ireland; Trinity College Dublin, Ireland; Trinity College Dublin, Ireland",IEEE Transactions on Software Engineering,11 Aug 2016,2016,42,8,764,785,"The shift towards multicore processing has led to a much wider population of developers being faced with the challenge of exploiting parallel cores to improve software performance. Debugging and optimizing parallel programs is a complex and demanding task. Tools which support development of parallel programs should provide salient information to allow programmers of multicore systems to diagnose and distinguish performance problems. Appropriate design of such tools requires a systematic analysis of the problems which might be identified, and the information used to diagnose them. Building on the literature, we put forward a potential taxonomy of parallel performance problems, and an observational model which links measurable performance data to these problems. We present a validation of this model carried out with parallel programming experts, identifying areas of agreement and disagreement. This is accompanied with a survey of the prevalence of these problems in software development. From this we can identify contentious areas worthy of further exploration, as well as those with high prevalence and strong agreement, which are natural candidates for initial moves towards better tool support.",1939-3520,,10.1109/TSE.2016.2519346,Science Foundation Ireland; Irish Software Research Centre; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7386691,"Parallel programming, multicore, multi-threaded, optimization, performance problems, performance analysis, diagnosis, debugging, taxonomy.",Multicore processing;Software;Taxonomy;Computers;Context;Parallel programming;Hardware,parallel programming;performance evaluation;program debugging;shared memory systems;software tools,shared-memory multicore systems;parallel performance problems;multicore processing;software performance;parallel program debugging;parallel program optimization;tool support,,4.0,,97.0,,19 Jan 2016,,,IEEE,IEEE Journals
795,796,Assessing the Cost Effectiveness of Fault Prediction in Acceptance Testing,A. Monden; T. Hayashi; S. Shinoda; K. Shirai; J. Yoshida; M. Barker; K. Matsumoto,"Nara Institute of Science and Technology, Ikoma; NTT West Corporation, Osaka; NTT West Corporation, Osaka; NTT West Corporation, Osaka; NTT West Corporation, Osaka; Nara Institute of Science and Technology, Ikoma; Nara Institute of Science and Technology, Ikoma",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1345,1357,"Until now, various techniques for predicting fault-prone modules have been proposed and evaluated in terms of their prediction performance; however, their actual contribution to business objectives such as quality improvement and cost reduction has rarely been assessed. This paper proposes using a simulation model of software testing to assess the cost effectiveness of test effort allocation strategies based on fault prediction results. The simulation model estimates the number of discoverable faults with respect to the given test resources, the resource allocation strategy, a set of modules to be tested, and the fault prediction results. In a case study applying fault prediction of a small system to acceptance testing in the telecommunication industry, results from our simulation model showed that the best strategy was to let the test effort be proportional to ""the number of expected faults in a module × log(module size)."" By using this strategy with our best fault prediction model, the test effort could be reduced by 25 percent while still detecting as many faults as were normally discovered in testing, although the company required about 6 percent of the test effort for metrics collection, data cleansing, and modeling. The simulation results also indicate that the lower bound of acceptable prediction accuracy is around 0.78 in terms of an effort-aware measure, Norm(Popt). The results indicate that reduction of the test effort can be achieved by fault prediction only if the appropriate test strategy is employed with high enough fault prediction accuracy. Based on these preliminary results, we expect further research to assess their general validity with larger systems.",1939-3520,,10.1109/TSE.2013.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6497441,Complexity measures;fault prediction;quality assurance;resource allocation;simulation,Testing;Predictive models;Measurement;Software;Resource management;Companies;Accuracy,program testing;resource allocation;software cost estimation;software fault tolerance;software metrics,cost effectiveness assessment;fault prediction;acceptance testing;quality improvement;cost reduction;software testing;test effort allocation strategies;fault discovery;resource allocation strategy;test resources;telecommunication industry;metrics collection;data cleansing;data modeling;effort-aware measure,,33.0,,34.0,,12 Apr 2013,,,IEEE,IEEE Journals
796,797,Predicting Consistency-Maintenance Requirement of Code Clonesat Copy-and-Paste Time,X. Wang; Y. Dang; L. Zhang; D. Zhang; E. Lan; H. Mei,"Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, and with the Department of Computer Science, University of Texas, San Antonio; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Research Asia, Beijing, China; Microsoft Corporation, One Microsoft Way, Redmond, WA; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, and with the Department of Computer Science, University of Texas, San Antonio",IEEE Transactions on Software Engineering,8 Aug 2014,2014,40,8,773,794,"Code clones have always been a double edged sword in software development. On one hand, it is a very convenient way to reuse existing code, and to save coding effort. On the other hand, since developers may need to ensure consistency among cloned code segments, code clones can lead to extra maintenance effort and even bugs. Recently studies on the evolution of code clones show that only some of the code clones experience consistent changes during their evolution history. Therefore, if we can accurately predict whether a code clone will experience consistent changes, we will be able to provide useful recommendations to developers onleveraging the convenience of some code cloning operations, while avoiding other code cloning operations to reduce future consistency maintenance effort. In this paper, we define a code cloning operation as consistency-maintenance-required if its generated code clones experience consistent changes in the software evolution history, and we propose a novel approach that automatically predicts whether a code cloning operation requires consistency maintenance at the time point of performing copy-and-paste operations. Our insight is that whether a code cloning operation requires consistency maintenance may relate to the characteristics of the code to be cloned and the characteristics of its context. Based on a number of attributes extracted from the cloned code and the context of the code cloning operation, we use Bayesian Networks, a machine-learning technique, to predict whether an intended code cloning operation requires consistency maintenance. We evaluated our approach on four subjects-two large-scale Microsoft software projects, and two popular open-source software projects-under two usage scenarios: 1) recommend developers to perform only the cloning operations predicted to be very likely to be consistency-maintenance-free, and 2) recommend developers to perform all cloning operations unless they are predicted very likely to be consistency-maintenance-required. In the first scenario, our approach is able to recommend developers to perform more than 50 percent cloning operations with a precision of at least 94 percent in the four subjects. In the second scenario, our approach is able to avoid 37 to 72 percent consistency-maintenance-required code clones by warning developers on only 13 to 40 percent code clones, in the four subjects.",1939-3520,,10.1109/TSE.2014.2323972,National 863 Program; National 973 Program; Science Fund for Creative Research Groups; Natural Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815760,Code cloning;consistency maintenance;programming aid,Cloning;Software;Maintenance engineering;Bayes methods;History;Training;Educational institutions,belief networks;learning (artificial intelligence);public domain software;software maintenance,consistency-maintenance requirement;code clones;copy-and-paste time;software development;maintenance effort;code cloning operations;consistency maintenance effort;Bayesian networks;machine-learning technique;Microsoft software projects;open-source software projects,,12.0,,46.0,,14 May 2014,,,IEEE,IEEE Journals
797,798,Magiclock: Scalable Detection of Potential Deadlocks in Large-Scale Multithreaded Programs,Y. Cai; W. K. Chan,"Department of Computer Science, City University of Hong Kong, Tat Chee Avenue; Department of Computer Science, City University of Hong Kong, Tat Chee Avenue",IEEE Transactions on Software Engineering,31 Mar 2014,2014,40,3,266,281,"We present Magiclock, a novel potential deadlock detection technique by analyzing execution traces (containing no deadlock occurrence) of large-scale multithreaded programs. Magiclock iteratively eliminates removable lock dependencies before potential deadlock localization. It divides lock dependencies into thread specific partitions, consolidates equivalent lock dependencies, and searches over the set of lock dependency chains without the need to examine any duplicated permutations of the same lock dependency chains. We validate Magiclock through a suite of real-world, large-scale multithreaded programs. The experimental results show that Magiclock is significantly more scalable and efficient than existing dynamic detectors in analyzing and detecting potential deadlocks in execution traces of large-scale multithreaded programs.",1939-3520,,10.1109/TSE.2014.2301725,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6718069,Deadlock detection;multithreaded programs;concurrency;lock order graph;scalability,System recovery;Message systems;Classification algorithms;Instruction sets;Image edge detection;Monitoring;Multicore processing,concurrency control;multi-threading;operating systems (computers);system recovery,Magiclock;potential deadlocks scalable detection;large-scale multithreaded programs;potential deadlock localization;lock order graph;scalability,,25.0,,47.0,,21 Jan 2014,,,IEEE,IEEE Journals
798,799,Predicting Project Velocity in XP Using a Learning Dynamic Bayesian Network Model,P. Hearty; N. Fenton; D. Marquez; M. Neil,"Queen Mary University of London-Computer, London; Queen Mary University of London-Computer, London; Queen Mary University of London-Computer, London; Queen Mary University of London-Computer, London",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,124,137,"Bayesian networks, which can combine sparse data, prior assumptions and expert judgment into a single causal model, have already been used to build software effort prediction models. We present such a model of an extreme programming environment and show how it can learn from project data in order to make quantitative effort predictions and risk assessments without requiring any additional metrics collection program. The model's predictions are validated against a real world industrial project, with which they are in good agreement.",1939-3520,,10.1109/TSE.2008.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4624275,extreme programming;Bayesian networks;causal models;risk assessment;extreme programming;Bayesian networks;causal models;risk assessment,Bayesian methods;Predictive models;Project management;Risk management;Programming environments;Testing;Large-scale systems;Size measurement;Calendars;Uncertainty,belief networks;project management;risk management;software metrics,project velocity;XP;extreme programming;learning dynamic Bayesian network model;software effort prediction models;quantitative effort predictions;risk assessments;metrics collection program;software development,,31.0,,41.0,,12 Sep 2008,,,IEEE,IEEE Journals
799,800,Probabilistic Model Checking of Regenerative Concurrent Systems,M. Paolieri; A. Horváth; E. Vicario,"Department of Information Engineering, Università di Firenze, Firenze, Italy; Department of Computer Science, Università di Torino, Torino, Italy; Department of Information Engineering, Università di Firenze, Firenze, Italy",IEEE Transactions on Software Engineering,11 Feb 2016,2016,42,2,153,169,"We consider the problem of verifying quantitative reachability properties in stochastic models of concurrent activities with generally distributed durations. Models are specified as stochastic time Petri nets and checked against Boolean combinations of interval until operators imposing bounds on the probability that the marking process will satisfy a goal condition at some time in the interval [α, β] after an execution that never violates a safety property. The proposed solution is based on the analysis of regeneration points in model executions: a regeneration is encountered after a discrete event if the future evolution depends only on the current marking and not on its previous history, thus satisfying the Markov property. We analyze systems in which multiple generally distributed timers can be started or stopped independently, but regeneration points are always encountered with probability 1 after a bounded number of discrete events. Leveraging the properties of regeneration points in probability spaces of execution paths, we show that the problem can be reduced to a set of Volterra integral equations, and we provide algorithms to compute their parameters through the enumeration of finite sequences of stochastic state classes encoding the joint probability density function (PDF) of generally distributed timers after each discrete event. The computation of symbolic PDFs is limited to discrete events before the first regeneration, and the repetitive structure of the stochastic process is exploited also before the lower bound α, providing crucial benefits for large time bounds. A case study is presented through the probabilistic formulation of Fischer's mutual exclusion protocol, a well-known real-time verification benchmark.",1939-3520,,10.1109/TSE.2015.2468717,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7202875,Probabilistic Model Checking;Reachability;Stochastic Petri Net;Markov Regenerative Process;Markov Renewal Theory;Probabilistic model checking;reachability;stochastic Petri net;Markov regenerative process;Markov renewal theory,Probabilistic logic;Probability density function;Markov processes;Computational modeling;Numerical models;Petri nets,concurrency control;Markov processes;Petri nets;program verification;Volterra equations,probabilistic model checking;regenerative concurrent systems;quantitative reachability properties;stochastic models;concurrent activities;stochastic time Petri nets;Boolean combinations;regeneration point analysis;model executions;discrete event;Markov property;distributed timers;Volterra integral equations;stochastic state classes;joint probability density function;symbolic PDFs;stochastic process;Fischer's mutual exclusion protocol;real-time verification benchmark,,16.0,,47.0,,14 Aug 2015,,,IEEE,IEEE Journals
800,801,"Proactive Self-Adaptation for Improving the Reliability of Mission-Critical, Embedded, and Mobile Software",D. Cooray; E. Kouroshfar; S. Malek; R. Roshandel,"VeriSign Inc., Reston; George Mason University, Fairfax; George Mason University, Fairfax; Seattle University, Seattle",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1714,1735,"Embedded and mobile software systems are marked with a high degree of unpredictability and dynamism in the execution context. At the same time, such systems are often mission-critical, meaning that they need to satisfy strict reliability requirements. Most current software reliability analysis approaches are not suitable for these types of software systems, as they do not take the changes in the execution context of the system into account. We propose an approach geared to such systems which continuously furnishes refined reliability predictions at runtime by incorporating various sources of information, including the execution context of the system. The reliability predictions are leveraged to proactively place the software in the (near-)optimal configuration with respect to changing conditions. Our approach considers two representative architectural reconfiguration decisions that impact the system's reliability: reallocation of components to processes and changing the number of component replicas. We have realized the approach as part of a framework intended for mission-critical settings, called REsilient SItuated SofTware system (RESIST), and evaluated it using a mobile emergency response system.",1939-3520,,10.1109/TSE.2013.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6574866,Context awareness;software architecture;self-adaptive systems;reliability;mobility,Mobile communication;Software reliability;Context awareness;Reliability engineering;Software  architecture;Computer architecture,embedded systems;mobile computing;software architecture;software reliability,proactive self-adaptation;mission-critical software;embedded software;mobile software;unpredictability degree;dynamism degree;execution context;reliability requirements;software reliability analysis approach;architectural reconfiguration decisions;component reallocation;component replicas;RESIST approach;resilient situated software system;mobile emergency response system,,9.0,,52.0,,5 Aug 2013,,,IEEE,IEEE Journals
801,802,SymbexNet: Testing Network Protocol Implementations with Symbolic Execution and Rule-Based Specifications,J. Song; C. Cadar; P. Pietzuch,"Department of Computer and Information Security, Sejong University, Seoul, Republic of Korea; Department of Computing, Imperial College London, London, SW7 2AZ, U.K.; Department of Computer and Information Security, Sejong University, Seoul, Republic of Korea",IEEE Transactions on Software Engineering,8 Jul 2014,2014,40,7,695,709,"Implementations of network protocols, such as DNS, DHCP and Zeroconf, are prone to flaws, security vulnerabilities and interoperability issues caused by developer mistakes and ambiguous requirements in protocol specifications. Detecting such problems is not easy because (i) many bugs manifest themselves only after prolonged operation; (ii) reasoning about semantic errors requires a machine-readable specification; and (iii) the state space of complex protocol implementations is large. This article presents a novel approach that combines symbolic execution and rule-based specifications to detect various types of flaws in network protocol implementations. The core idea behind our approach is to (1) automatically generate high-coverage test input packets for a network protocol implementation using single- and multi-packet exchange symbolic execution (targeting stateless and stateful protocols, respectively) and then (2) use these packets to detect potential violations of manual rules derived from the protocol specification, and check the interoperability of different implementations of the same network protocol. We present a system based on these techniques, SymbexNet, and evaluate it on multiple implementations of two network protocols: Zeroconf, a service discovery protocol, and DHCP, a network configuration protocol. SymbexNet is able to discover non-trivial bugs as well as interoperability problems, most of which have been confirmed by the developers.",1939-3520,,10.1109/TSE.2014.2323977,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6815719,Symbolic execution;network security;testing;interoperability testing,Protocols;IP networks;Interoperability;Servers;Concrete;Testing;Computer bugs,formal specification;open systems;program debugging;program testing,SymbexNet;testing network protocol implementations;symbolic execution;rule based specifications;DNS;DHCP;Zeroconf;interoperability issues;security vulnerabilities;protocol specifications;semantic errors;machine readable specification;protocol implementations;protocol specification;network protocol;interoperability problems,,9.0,,50.0,,14 May 2014,,,IEEE,IEEE Journals
802,803,Synthesizing Modal Transition Systems from Triggered Scenarios,G. E. Sibay; V. Braberman; S. Uchitel; J. Kramer,"Imperial College London, London; University of Buenos Aires, Buenos Aires; Imperial College London, London and University of Buenos Aires, Buenos Aires; Imperial College, London",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,975,1001,"Synthesis of operational behavior models from scenario-based specifications has been extensively studied. The focus has been mainly on either existential or universal interpretations. One noteworthy exception is Live Sequence Charts (LSCs), which provides expressive constructs for conditional universal scenarios and some limited support for nonconditional existential scenarios. In this paper, we propose a scenario-based language that supports both existential and universal interpretations for conditional scenarios. Existing model synthesis techniques use traditional two-valued behavior models, such as Labeled Transition Systems. These are not sufficiently expressive to accommodate specification languages with both existential and universal scenarios. We therefore shift the target of synthesis to Modal Transition Systems (MTS), an extension of labeled Transition Systems that can distinguish between required, unknown, and proscribed behavior to capture the semantics of existential and universal scenarios. Modal Transition Systems support elaboration of behavior models through refinement, which complements an incremental elicitation process suitable for specifying behavior with scenario-based notations. The synthesis algorithm that we define constructs a Modal Transition System that uses refinement to characterize all the Labeled Transition Systems models that satisfy a mixed, conditional existential and universal scenario-based specification. We show how this combination of scenario language, synthesis, and Modal Transition Systems supports behavior model elaboration.",1939-3520,,10.1109/TSE.2012.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311408,Scenarios;MTS;synthesis;partial behavior models,Semantics;Analytical models;Online banking;Merging;Unified modeling language;Indexes;Cognition,formal verification;reasoning about programs,modal transition systems;triggered scenarios;operational behavior models;scenario-based specifications;live sequence charts;LSC;conditional universal scenarios;nonconditional existential scenarios;scenario-based language;model synthesis techniques;two-valued behavior models;specification languages;MTS;incremental elicitation process;scenario-based notations;conditional existential scenario-based specification;universal scenario-based specification;labeled transition system models;behavior model elaboration,,13.0,,40.0,,24 Sep 2012,,,IEEE,IEEE Journals
803,804,Finding Atomicity-Violation Bugs through Unserializable Interleaving Testing,S. Lu; S. Park; Y. Zhou,"University of Wisconsin-Madison, Madison; University of California, San Diego, La Jolla; University of California, San Diego, La Jolla",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,844,860,"Multicore hardware is making concurrent programs pervasive. Unfortunately, concurrent programs are prone to bugs. Among different types of concurrency bugs, atomicity violations are common and important. How to test the interleaving space and expose atomicity-violation bugs is an open problem. This paper makes three contributions. First, it designs and evaluates a hierarchy of four interleaving coverage criteria using 105 real-world concurrency bugs. This study finds a coverage criterion (Unserializable Interleaving Coverage) that balances the complexity and the capability of exposing atomicity-violation bugs well. Second, it studies stress testing to understand why this common practice cannot effectively expose atomicity-violation bugs from the perspective of unserializable interleaving coverage. Third, it designs CTrigger following the unserializable interleaving coverage criterion. CTrigger uses trace analysis to identify feasible unserializable interleavings, and then exercises low-probability interleavings to expose atomicity-violation bugs. We evaluate CTrigger with real-world atomicity-violation bugs from seven applications. CTrigger efficiently exposes these bugs within 1-235 seconds, two to four orders of magnitude faster than stress testing. Without CTrigger, some of these bugs do not manifest even after seven days of stress testing. Furthermore, once a bug is exposed, CTrigger can reliably reproduce it, usually within 5 seconds, for diagnosis.",1939-3520,,10.1109/TSE.2011.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740930,Testing and debugging;debugging aids;diagnostics;testing strategies;test coverage of code;concurrent programming;bug characteristics,Computer bugs;Testing;Instruction sets;Concurrent computing;Stress;Complexity theory;Synchronization,formal verification;multiprocessing systems;probability;program debugging;ubiquitous computing,finding atomicity violation bugs;unserializable interleaving testing;multicore hardware;pervasive concurrent programs;concurrency bugs;unserializable interleaving coverage;trace analysis;low probability interleavings,,17.0,,48.0,,5 Apr 2011,,,IEEE,IEEE Journals
804,805,Developing a Single Model and Test Prioritization Strategies for Event-Driven Software,R. C. Bryce; S. Sampath; A. M. Memon,"Utah State University, Logan; University of Maryland, Baltimore; University of Maryland, College Park",IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,48,64,"Event-Driven Software (EDS) can change state based on incoming events; common examples are GUI and Web applications. These EDSs pose a challenge to testing because there are a large number of possible event sequences that users can invoke through a user interface. While valuable contributions have been made for testing these two subclasses of EDS, such efforts have been disjoint. This work provides the first single model that is generic enough to study GUI and Web applications together. In this paper, we use the model to define generic prioritization criteria that are applicable to both GUI and Web applications. Our ultimate goal is to evolve the model and use it to develop a unified theory of how all EDS should be tested. An empirical study reveals that the GUI and Web-based applications, when recast using the new model, show similar behavior. For example, a criterion that gives priority to all pairs of event interactions did well for GUI and Web applications; another criterion that gives priority to the smallest number of parameter value settings did poorly for both. These results reinforce our belief that these two subclasses of applications should be modeled and studied together.",1939-3520,,10.1109/TSE.2010.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401169,Combinatorial interaction testing;covering arrays;event-driven software (EDS);t-way interaction coverage;test suite prioritization;user-session testing;Web application testing;GUI testing.,Software testing;Graphical user interfaces;Application software;Computer science;User interfaces;Protocols;Embedded software;Information systems;Educational institutions;Abstracts,graphical user interfaces;Internet;program testing;service-oriented architecture,event-driven software;test prioritization strategy;EDS;GUI testing;Web application testing;graphical user interface,,73.0,1.0,28.0,,29 Jan 2010,,,IEEE,IEEE Journals
805,806,Forecasting Risk Impact on ERP Maintenance with Augmented Fuzzy Cognitive Maps,J. L. Salmeron; C. Lopez,"University Pablo de Olavide, Seville; Pablo de Olavide University, Seville",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,439,452,"Worldwide, firms have made great efforts to implement Enterprise Resource Planning (ERP) systems. Despite these efforts, ERP adoption success is not guaranteed. Successful adoption of an ERP system also depends on proper system maintenance. For this reason, companies should follow a maintenance strategy that drives the ERP system toward success. However, in general, ERP maintenance managers do not know what conditions they should target to successfully maintain their ERP systems. Furthermore, numerous risks threaten these projects, but they are normally dealt with intuitively. To date, there has been limited literature published regarding ERP maintenance risks or ERP maintenance success. To address this need, we have built a dynamic simulation tool that allows ERP managers to foresee the impact of risks on maintenance goals. This research would help professionals manage their ERP maintenance projects. Moreover, it covers a significant gap in the literature.",1939-3520,,10.1109/TSE.2011.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680917,ERP;fuzzy cognitive maps;risk management;simulation;software maintenance.,Decision support systems,cognition;enterprise resource planning;forecasting theory;fuzzy set theory;project management;risk analysis;software maintenance;software management,enterprise resource planning system;ERP adoption success;ERP system maintenance;ERP maintenance risks;dynamic simulation tool;ERP maintenance project management;augmented fuzzy cognitive maps;risk impact forecasting,,55.0,,111.0,,6 Jan 2011,,,IEEE,IEEE Journals
806,807,The Impact of Classifier Configuration and Classifier Combination on Bug Localization,S. W. Thomas; M. Nagappan; D. Blostein; A. E. Hassan,"Queen's University, Kingston; Queen's University, Kingston; Queen's University, Kingston; Queen's University, Kingston",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1427,1443,"Bug localization is the task of determining which source code entities are relevant to a bug report. Manual bug localization is labor intensive since developers must consider thousands of source code entities. Current research builds bug localization classifiers, based on information retrieval models, to locate entities that are textually similar to the bug report. Current research, however, does not consider the effect of classifier configuration, i.e., all the parameter values that specify the behavior of a classifier. As such, the effect of each parameter or which parameter values lead to the best performance is unknown. In this paper, we empirically investigate the effectiveness of a large space of classifier configurations, 3,172 in total. Further, we introduce a framework for combining the results of multiple classifier configurations since classifier combination has shown promise in other domains. Through a detailed case study on over 8,000 bug reports from three large-scale projects, we make two main contributions. First, we show that the parameters of a classifier have a significant impact on its performance. Second, we show that combining multiple classifiers--whether those classifiers are hand-picked or randomly chosen relative to intelligently defined subspaces of classifiers--improves the performance of even the best individual classifiers.",1939-3520,,10.1109/TSE.2013.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6520844,Software maintenance;bug localization;information retrieval;VSM;LSI;LDA;classifier combination,Large scale integration;Measurement;Vectors;Information retrieval;Matrix decomposition;Indexes;Resource management,information retrieval;pattern classification;program debugging,classifier configuration;classifier combination;source code entity determination;bug report;bug localization classifiers;information retrieval models;parameter value;classifier parameter,,44.0,,62.0,,27 May 2013,,,IEEE,IEEE Journals
807,808,"Input Domain Reduction through Irrelevant Variable Removal and Its Effect on Local, Global, and Hybrid Search-Based Structural Test Data Generation",P. McMinn; M. Harman; K. Lakhotia; Y. Hassoun; J. Wegener,"University of Sheffield, Sheffield; University College London, London; University College London, London; King's College London, London; Berner & Mattner Systemtechnik GmbH, Berlin",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,453,477,"Search-Based Test Data Generation reformulates testing goals as fitness functions so that test input generation can be automated by some chosen search-based optimization algorithm. The optimization algorithm searches the space of potential inputs, seeking those that are “fit for purpose,” guided by the fitness function. The search space of potential inputs can be very large, even for very small systems under test. Its size is, of course, a key determining factor affecting the performance of any search-based approach. However, despite the large volume of work on Search-Based Software Testing, the literature contains little that concerns the performance impact of search space reduction. This paper proposes a static dependence analysis derived from program slicing that can be used to support search space reduction. The paper presents both a theoretical and empirical analysis of the application of this approach to open source and industrial production code. The results provide evidence to support the claim that input domain reduction has a significant effect on the performance of local, global, and hybrid search, while a purely random search is unaffected.",1939-3520,,10.1109/TSE.2011.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5710949,Search-based software testing;evolutionary testing;automated test data generation;input domain reduction.,Input variables;Software testing;Optimization;Algorithm design and analysis;Search problems;Software algorithms,automatic test pattern generation;optimisation;program compilers;program slicing;program testing;public domain software;search problems,input domain reduction;irrelevant variable removal;hybrid search-based structural test data generation;fitness functions;test input generation;search-based optimization algorithm;key determining factor;search-based software testing;search space reduction;static dependence analysis;program slicing;open source approach;industrial production code,,33.0,,52.0,,10 Feb 2011,,,IEEE,IEEE Journals
808,809,A Practical Approach to Size Estimation of Embedded Software Components,K. Lind; R. Heldal,"Saab Automobile AB, Trollhättan; Chalmers University of Technology, Göteborg",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,993,1007,"To estimate software code size early in the development process is important for developing cost-efficient embedded systems. We have applied the COSMIC Functional Size Measurement (FSM) method for size estimation of embedded software components in the automotive industry. Correlational studies were conducted using data from two automotive companies. The studies show strong correlation between functional size and software code size, which is important for obtaining accurate estimation results. This paper presents the characteristics and results of our work, and aims to provide a practical framework for how to use COSMIC FSM for size estimation purposes. We investigate the results from our earlier correlational studies, and conduct further studies to identify such a framework. Based on these activities, we conclude that a clear purpose of the estimation process, a well-defined domain allowing categorization of software, consistent content and quality of requirements, and historical data from implemented software are key factors for size estimation of embedded software components.",1939-3520,,10.1109/TSE.2011.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999672,Real-time and embedded systems;software product metrics;COSMIC FSM;software components,Software;Estimation;Vehicles;Size measurement;Automotive engineering;Industries;Memory management,automotive engineering;object-oriented programming;production engineering computing;software cost estimation;software metrics,software code size estimation;embedded software components;development process;cost-efficient embedded systems;COSMIC functional size measurement method;FSM method;automotive industry;automotive companies;domain allowing categorization;consistent content;requirements quality;historical data;software product metrics,,7.0,,48.0,,25 Aug 2011,,,IEEE,IEEE Journals
809,810,"Aligning Qualitative, Real-Time, and Probabilistic Property Specification Patterns Using a Structured English Grammar",M. Autili; L. Grunske; M. Lumpe; P. Pelliccione; A. Tang,"Dipartimento di Ingegneria e Scienze dell’Informazione e Matematica, Università dell’Aquila, Aquila, Italy; Institute of Software Technology, University of Stuttgart, Stuttgart, Germany; Swinburne University of Technology, Hawthorn, Australia; Dipartimento di Ingegneria e Scienze dell’Informazione e Matematica, Università dell’Aquila, Aquila, Italy; Swinburne University of Technology, Hawthorn, Australia",IEEE Transactions on Software Engineering,14 Jul 2015,2015,41,7,620,638,"Formal methods offer an effective means to assert the correctness of software systems through mathematical reasoning. However, the need to formulate system properties in a purely mathematical fashion can create pragmatic barriers to the application of these techniques. For this reason, Dwyer et al. invented property specification patterns which is a system of recurring solutions to deal with the temporal intricacies that would make the construction of reactive systems very hard otherwise. Today, property specification patterns provide general rules that help practitioners to qualify order and occurrence, to quantify time bounds, and to express probabilities of events. Nevertheless, a comprehensive framework combining qualitative, real-time, and probabilistic property specification patterns has remained elusive. The benefits of such a framework are twofold. First, it would remove the distinction between qualitative and quantitative aspects of events; and second, it would provide a structure to systematically discover new property specification patterns. In this paper, we report on such a framework and present a unified catalogue that combines all known plus 40 newly identified or extended patterns. We also offer a natural language front-end to map patterns to a temporal logic of choice. To demonstrate the virtue of this new framework, we applied it to a variety of industrial requirements, and use PSPWizard, a tool specifically developed to work with our unified pattern catalogue, to automatically render concrete instances of property specification patterns to formulae of an underlying temporal logic of choice.",1939-3520,,10.1109/TSE.2015.2398877,PRESTO; European Commission; DFG; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7029714,Specification Patterns;Real-time Properties;Probabilistic Properties;Specification patterns;real-time properties;probabilistic properties,Probabilistic logic;Real-time systems;Natural languages;Software;Grammar;Electronic mail;Educational institutions,formal specification;natural language processing;probability;temporal logic,qualitative property specification pattern;real-time property specification pattern;probabilistic property specification pattern;structured English grammar;formal methods;software system correctness;mathematical reasoning;temporal intricacies;order qualification;occurrence qualification;time bound quantification;event probability;event qualitative aspect;event quantitative aspect;natural language front-end;pattern mapping;temporal logic;PSPWizard;unified pattern catalogue,,48.0,1.0,47.0,,3 Feb 2015,,,IEEE,IEEE Journals
810,811,OBEY: Optimal Batched Refactoring Plan Execution for Class Responsibility Redistribution,H. C. Jiau; L. W. Mar; J. C. Chen,"National Cheng Kung University, Tainan; National Cheng Kung University, Tainan; National Cheng Kung University, Tainan",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1245,1263,"The redistribution of class responsibilities is a common reengineering practice in object-oriented (OO) software evolution. During the redistribution, developers frequently construct batched refactoring plans for moving multiple methods and fields among various classes. With an objective of carefully maintaining the cohesion and coupling degree of the class design, executing a batched refactoring plan without introducing any objective-violating side effect into the refactored code is essential. However, using most refactoring engines for batched refactoring plan execution introduces coupling-increasing Middle Man bad smell in the final refactored code and therefore makes the refactoring execution suboptimal in achieving the redistribution objective. This work proposes Obey, a methodology for optimal batched refactoring plan execution. Obey analyzes a batched refactoring plan, identifies Middle Man symptoms that cause suboptimal execution, and renovates the plan for optimal execution. We have conducted an empirical study on three open-source software projects to confirm the effectiveness of Obey in a practical context.",1939-3520,,10.1109/TSE.2013.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6493333,Reengineering;class responsibility redistribution;batched refactoring execution;change impact analysis;optimization,Couplings;Engines;Software systems;Measurement;Optimization;Context,object-oriented programming;software maintenance,OBEY methodology;optimal batched refactoring plan execution;class responsibility redistribution;software reengineering practice;object-oriented software evolution;OO software evolution;refactoring engine;coupling-increasing middle man bad smell;open-source software project,,7.0,,74.0,,3 Apr 2013,,,IEEE,IEEE Journals
811,812,Model Checking Probabilistic and Stochastic Extensions of the π-Calculus,G. Norman; C. Palamidessi; D. Parker; P. Wu,"Oxford University, Oxford; INRIA Saclay and École Polytechnique, Paris; Oxford University, Oxford; University College London, Ipswich",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,209,223,"We present an implementation of model checking for probabilistic and stochastic extensions of the pi-calculus, a process algebra which supports modelling of concurrency and mobility. Formal verification techniques for such extensions have clear applications in several domains, including mobile ad-hoc network protocols, probabilistic security protocols and biological pathways. Despite this, no implementation of automated verification exists. Building upon the pi-calculus model checker MMC, we first show an automated procedure for constructing the underlying semantic model of a probabilistic or stochastic pi-calculus process. This can then be verified using existing probabilistic model checkers such as PRISM. Secondly, we demonstrate how for processes of a specific structure a more efficient, compositional approach is applicable, which uses our extension of MMC on each parallel component of the system and then translates the results into a high-level modular description for the PRISM tool. The feasibility of our techniques is demonstrated through a number of case studies from the pi-calculus literature.",1939-3520,,10.1109/TSE.2008.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4626962,Model checking;Markov processes;Stochastic processes;Model checking;Markov processes;Stochastic processes,Stochastic processes;Biological system modeling;Protocols;Stochastic systems;Calculus;Algebra;Formal verification;Mobile ad hoc networks;Mobile communication;Communication system security,formal verification;pi calculus;probability;stochastic processes,model checking;probabilisty;stochastic extension;pi-calculus;process algebra;formal verification;mobile ad-hoc network protocol;probabilistic security protocol;biological pathway;semantic model;high-level modular description,,16.0,,43.0,,19 Sep 2008,,,IEEE,IEEE Journals
812,813,Pert: The Application-Aware Tailoring of Java Object Persistence,P. Liu; C. Zhang,"Hong Kong University of Science and Technology, Hong Kong; Hong Kong University of Science and Technology, Hong Kong",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,909,922,"Persistence is a widely used technique which allows the objects that represent the results of lengthy computations to outlive the process that creates it in order to considerably speed up subsequent program executions. We observe that conventional persistence techniques usually do not consider the application contexts of the persistence operations, where not all of the object states need to be persisted. Leveraging this observation, we have designed and implemented a framework called Pert, which first performs static program analysis to estimate the actual usage of the persisted object, given the context of its usage in the program. The Pert runtime uses the statically computed information to efficiently make tailoring decisions to prune the redundant and unused object states during the persistence operations. Our evaluation result shows that the Pert-based optimization can speed up the conventional persistence operations by 1 to 45 times. The amount of persisted data is also dramatically reduced, as the result of the application-aware tailoring.",1939-3520,,10.1109/TSE.2011.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963692,Object persistence;program analysis;performance optimization,Runtime;Anodes;Optimization;Context;Libraries;Java;Algorithm design and analysis,Java;optimisation,application aware tailoring;Java object persistence;lengthy computations;subsequent program executions;persistence techniques;static program analysis;Pert based optimization,,2.0,,20.0,,28 Jul 2011,,,IEEE,IEEE Journals
813,814,QoS Assurance for Dynamic Reconfiguration of Component-Based Software Systems,W. Li,"Central Quneensland University, Rockhampton",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,658,676,"A major challenge of dynamic reconfiguration is Quality of Service (QoS) assurance, which is meant to reduce application disruption to the minimum for the system's transformation. However, this problem has not been well studied. This paper investigates the problem for component-based software systems from three points of view. First, the whole spectrum of QoS characteristics is defined. Second, the logical and physical requirements for QoS characteristics are analyzed and solutions to achieve them are proposed. Third, prior work is classified by QoS characteristics and then realized by abstract reconfiguration strategies. On this basis, quantitative evaluation of the QoS assurance abilities of existing work and our own approach is conducted through three steps. First, a proof-of-concept prototype called the reconfigurable component model is implemented to support the representation and testing of the reconfiguration strategies. Second, a reconfiguration benchmark is proposed to expose the whole spectrum of QoS problems. Third, each reconfiguration strategy is tested against the benchmark and the testing results are evaluated. The most important conclusion from our investigation is that the classified QoS characteristics can be fully achieved under some acceptable constraints.",1939-3520,,10.1109/TSE.2011.37,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740932,Change management;componentware;dynamic reconfiguration;modeling the QoS assurance process;system evolution.,Quality of service;Encryption;Protocols;Connectors;Receivers;Benchmark testing,quality of service;software quality,QoS assurance;dynamic reconfiguration;component based software systems;Quality of Service;application disruption;physical requirements;logical requirements;abstract reconfiguration;quantitative evaluation;reconfigurable component;reconfiguration benchmark,,21.0,,39.0,,5 Apr 2011,,,IEEE,IEEE Journals
814,815,Aspect-Oriented Refactoring of Legacy Applications: An Evaluation,M. Mortensen; S. Ghosh; J. Bieman,"Google, Boulder; Colorado State University, Fort Collins; Colorado State University, Fort Collins",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,118,140,"The primary claimed benefits of aspect-oriented programming (AOP) are that it improves the understandability and maintainability of software applications by modularizing crosscutting concerns. Before there is widespread adoption of AOP, developers need further evidence of the actual benefits as well as costs. Applying AOP techniques to refactor legacy applications is one way to evaluate costs and benefits. We replace crosscutting concerns with aspects in three industrial applications to examine the effects on qualities that affect the maintainability of the applications. We study several revisions of each application, identifying crosscutting concerns in the initial revision and also crosscutting concerns that are added in later revisions. Aspect-oriented refactoring reduced code size and improved both change locality and concern diffusion. Costs include the effort required for application refactoring and aspect creation, as well as a decrease in performance.",1939-3520,,10.1109/TSE.2010.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661792,Aspect-oriented programming;crosscutting concerns;legacy systems;refactoring;maintainability.,Software measurement;Maintenance engineering;Legacy systems;Java;Programming;Aspect-oriented programming,aspect-oriented programming;software maintenance,aspect-oriented refactoring;legacy applications;primary claimed benefits;aspect-oriented programming;software understandability;software maintainability;crosscutting concerns;AOP techniques;cost evaluation;benefits evaluation;code size;change locality;concern diffusion;application refactoring;aspect creation,,14.0,,37.0,,10 Dec 2010,,,IEEE,IEEE Journals
815,816,Counterexample Generation in Probabilistic Model Checking,T. Han; J. Katoen; D. Berteun,"RWTH Aachen University, Aachen and University of Twente, Enschede; RWTH Aachen University, Aachen and University of Twente, Enschede; RWTH Aachen University, Aachen and University of Twente, Enschede",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,241,257,"Providing evidence for the refutation of a property is an essential, if not the most important, feature of model checking. This paper considers algorithms for counterexample generation for probabilistic CTL formulae in discrete-time Markov chains. Finding the strongest evidence (i.e., the most probable path) violating a (bounded) until-formula is shown to be reducible to a single-source (hop-constrained) shortest path problem. Counterexamples of smallest size that deviate most from the required probability bound can be obtained by applying (small amendments to) k-shortest (hop-constrained) paths algorithms. These results can be extended to Markov chains with rewards, to LTL model checking, and are useful for Markov decision processes. Experimental results show that typically the size of a counterexample is excessive. To obtain much more compact representations, we present a simple algorithm to generate (minimal) regular expressions that can act as counterexamples. The feasibility of our approach is illustrated by means of two communication protocols: leader election in an anonymous ring network and the Crowds protocol.",1939-3520,,10.1109/TSE.2009.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4770111,Model checking;Diagnostics,Protocols;Logic;Biological system modeling;Quantum computing;Feedback;Biology computing;Distributed computing;Computer Society;Shortest path problem;Nominations and elections,decision theory;formal verification;Markov processes;probabilistic logic;probability;temporal logic;trees (mathematics),counterexample generation;probabilistic model checking;property refutation;discrete-time Markov chain;single-source shortest path problem;k-shortest path algorithm;Markov decision process;linear temporal logic;computation tree logic,,57.0,,61.0,,2 Feb 2009,,,IEEE,IEEE Journals
816,817,A Controlled Experiment for Evaluating the Impact of Coupling on the Maintainability of Service-Oriented Software,M. Perepletchikov; C. Ryan,"RMIT University, Melbourne; RMIT University, Melbourne",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,449,465,"One of the goals of Service-Oriented Computing (SOC) is to improve software maintainability as businesses become more agile, and thus underlying processes and rules change more frequently. This paper presents a controlled experiment examining the relationship between coupling in service-oriented designs, as measured using a recently proposed suite of SOC-specific coupling metrics and software maintainability in terms of the specific subcharacteristics of analyzability, changeability, and stability. The results indicate a statistically significant causal relationship between the investigated coupling metrics and the maintainability of service-oriented software. As such, the investigated metrics can facilitate coupling related design decisions with the aim of producing more maintainable service-oriented software products.",1939-3520,,10.1109/TSE.2010.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482590,Services systems;design concepts;maintainability;product metrics;empirical studies.,Software maintenance;Programming;Software measurement;Logic;Software design;Stability analysis;Product design;Application software;Costs;Software metrics,service-oriented architecture;software maintenance;software metrics,software maintainability improvement;service-oriented computing;service-oriented designs;specific coupling metrics;specific subcharacteristics;statistically significant causal relationship;service-oriented software products,,28.0,,48.0,,7 Jun 2010,,,IEEE,IEEE Journals
817,818,AutoSense: A Framework for Automated Sensitivity Analysis of Program Data,B. Nongpoh; R. Ray; S. Dutta; A. Banerjee,"Department of Computer Science & Engineering, National Institute of Technology Meghalaya, Shillong, India; Department of Computer Science & Engineering, National Institute of Technology Meghalaya, Shillong, India; Department of Computer Science & Engineering, Jadavpur University, Kolkata, India; Advanced Computing and Microelectronics Unit, Indian Statistical Institute, Kolkata, India",IEEE Transactions on Software Engineering,8 Dec 2017,2017,43,12,1110,1124,"In recent times, approximate computing is being increasingly adopted across the computing stack, from algorithms to computing hardware, to gain energy and performance efficiency by trading accuracy within acceptable limits. Approximation aware programming languages have been proposed where programmers can annotate data with type qualifiers (e.g., precise and approx) to denote its reliability. However, programmers need to judiciously annotate so that the accuracy loss remains within the desired limits. This can be non-trivial for large applications where error resilient and non-resilient program data may not be easily identifiable. Mis-annotation of even one data as error resilient/insensitive may result in an unacceptable output. In this paper, we present AutoSense, a framework to automatically classify resilient (insensitive) program data versus the sensitive ones with probabilistic reliability guarantee. AutoSense implements a combination of dynamic and static analysis methods for data sensitivity analysis. The dynamic analysis is based on statistical hypothesis testing, while the static analysis is based on classical data flow analysis. Experimental results compare our automated data classification with reported manual annotations on popular benchmarks used in approximate computing literature. AutoSense achieves promising reliability results compared to manual annotations and earlier methods, as evident from the experimental results.",1939-3520,,10.1109/TSE.2017.2654251,National Institute of Technology Meghalaya and Visvesvaraya Ph.D. Scheme; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7820185,Approximate computing;sensitivity analysis;hypothesis testing;sequential probability ratio test,Quality of service;Sensitivity analysis;Approximate computing;Probabilistic logic;Sequential analysis,data flow analysis;pattern classification;probability;program diagnostics;program verification;sensitivity analysis;statistical analysis,approximate computing literature;AutoSense;automated sensitivity analysis;probabilistic reliability;energy efficiency;manual annotations;automated data classification;classical data flow analysis;dynamic analysis;data sensitivity analysis;static analysis;resilient program data;accuracy loss;approximation aware programming languages;trading accuracy;performance efficiency;computing hardware;computing stack,,4.0,,31.0,Traditional,17 Jan 2017,,,IEEE,IEEE Journals
818,819,Dynamic Analysis for Diagnosing Integration Faults,L. Mariani; F. Pastore; M. Pezze,"University of Milano Bicocca, Milan; University of Milano Bicocca, Milan; University of Milan Bicocca, Milano",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,486,508,"Many software components are provided with incomplete specifications and little access to the source code. Reusing such gray-box components can result in integration faults that can be difficult to diagnose and locate. In this paper, we present Behavior Capture and Test (BCT), a technique that uses dynamic analysis to automatically identify the causes of failures and locate the related faults. BCT augments dynamic analysis techniques with model-based monitoring. In this way, BCT identifies a structured set of interactions and data values that are likely related to failures (failure causes), and indicates the components and the operations that are likely responsible for failures (fault locations). BCT advances scientific knowledge in several ways. It combines classic dynamic analysis with incremental finite state generation techniques to produce dynamic models that capture complementary aspects of component interactions. It uses an effective technique to filter false positives to reduce the effort of the analysis of the produced data. It defines a strategy to extract information about likely causes of failures by automatically ranking and relating the detected anomalies so that developers can focus their attention on the faults. The effectiveness of BCT depends on the quality of the dynamic models extracted from the program. BCT is particularly effective when the test cases sample the execution space well. In this paper, we present a set of case studies that illustrate the adequacy of BCT to analyze both regression testing failures and rare field failures. The results show that BCT automatically filters out most of the false alarms and provides useful information to understand the causes of failures in 69 percent of the case studies.",1939-3520,,10.1109/TSE.2010.93,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611554,Dynamic Analysis;diagnosis;fault localization;false positive filters;regression failure analysis;field failure analysis.,Automata;Monitoring;Analytical models;Engines;Software;Testing;Inference algorithms,fault diagnosis;object-oriented programming;program testing;software fault tolerance,software components;Integration Faults;behavior capture and test technique;BCT;dynamic analysis;model-based monitoring;incremental finite state generation techniques,,54.0,,71.0,,28 Oct 2010,,,IEEE,IEEE Journals
819,820,"How We Refactor, and How We Know It",E. Murphy-Hill; C. Parnin; A. P. Black,"North Carolina State University, Raleigh; Georgia Institute of Technology, Atlanta; Portland State University, Portland",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,5,18,"Refactoring is widely practiced by developers, and considerable research and development effort has been invested in refactoring tools. However, little has been reported about the adoption of refactoring tools, and many assumptions about refactoring practice have little empirical support. In this paper, we examine refactoring tool usage and evaluate some of the assumptions made by other researchers. To measure tool usage, we randomly sampled code changes from four Eclipse and eight Mylyn developers and ascertained, for each refactoring, if it was performed manually or with tool support. We found that refactoring tools are seldom used: 11 percent by Eclipse developers and 9 percent by Mylyn developers. To understand refactoring practice at large, we drew from a variety of data sets spanning more than 39,000 developers, 240,000 tool-assisted refactorings, 2,500 developer hours, and 12,000 version control commits. Using these data, we cast doubt on several previously stated assumptions about how programmers refactor, while validating others. Finally, we interviewed the Eclipse and Mylyn developers to help us understand why they did not use refactoring tools and to gather ideas for future research.",1939-3520,,10.1109/TSE.2011.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112738,Refactoring;refactoring tools;floss refactoring;root-canal refactoring.,Java;Software tools;Refactoring,software maintenance;software tools,research and development;refactoring tools;randomly sampled code;Eclipse developers;Mylyn developers,,204.0,,22.0,,27 Dec 2011,,,IEEE,IEEE Journals
820,821,Software Numerical Instability Detection and Diagnosis by Combining Stochastic and Infinite-Precision Testing,E. Tang; X. Zhang; N. T. Müller; Z. Chen; X. Li,"State Key Laboratory for Novel Software Technology and Software Institute of Nanjing University, Jiangsu, China; Department of Computer Science, Purdue University, 305 North University Street, West Lafayette, IN; Abteilung Informatik, University of Trier, Trier, Germany; State Key Laboratory for Novel Software Technology and Software Institute of Nanjing University, Jiangsu, China; State Key Laboratory for Novel Software Technology and Software Institute of Nanjing University, Jiangsu, China",IEEE Transactions on Software Engineering,13 Oct 2017,2017,43,10,975,994,"Numerical instability is a well-known problem that may cause serious runtime failures. This paper discusses the reason of instability in software development process, and presents a toolchain that not only detects the potential instability in software, but also diagnoses the reason for such instability. We classify the reason of instability into two categories. When it is introduced by software requirements, we call the instability caused by problem . In this case, it cannot be avoided by improving software development, but requires inspecting the requirements, especially the underlying mathematical properties. Otherwise, we call the instability caused by practice. We design our toolchain as four loosely-coupled tools, which combine stochastic arithmetic with infinite-precision testing. Each tool in our toolchain can be configured with different strategies according to the properties of the analyzed software. We evaluate our toolchain on subjects from literature. The results show that it effectively detects and separates the instabilities caused by problems from others. We also conduct an evaluation on the latest version of GNU Scientific Library, and the toolchain finds a few real bugs in the well-maintained and widely deployed numerical library. With the help of our toolchain, we report the details and fixing advices to the GSL buglist.",1939-3520,,10.1109/TSE.2016.2642956,National Basic Research Program of China 973 Program; NSF Award; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7792694,Numerical analysis;infinite-precision arithmetic;stochastic arithmetic;software testing,Software;Software algorithms;Algorithm design and analysis;Libraries;Computer bugs;Software testing,fault diagnosis;formal specification;mathematics computing;numerical stability;program debugging;program testing;software quality;software reliability;software tools;stochastic processes,software requirements;toolchain;loosely-coupled tools;stochastic arithmetic;numerical library;software development process;potential instability;mathematical properties;infinite-precision testing;software numerical instability detection;software numerical instability diagnosis;runtime failures;GNU scientific library;GSL buglist,,2.0,,64.0,Traditional,21 Dec 2016,,,IEEE,IEEE Journals
821,822,Preventing Temporal Violations in Scientific Workflows: Where and How,X. Liu; Y. Yang; Y. Jiang; J. Chen,"Swinburne University of Technology, Melbourne; Anhui University, Hefei and Swinburne University of Technology, Melbourne; Hefei University of Technology, Hefei and University of Pittsburgh, Pittsburgh; University of Technology, Sydney and Swinburne University of Technology, Melbourne",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,805,825,"Due to the dynamic nature of the underlying high-performance infrastructures for scientific workflows such as grid and cloud computing, failures of timely completion of important scientific activities, namely, temporal violations, often take place. Unlike conventional exception handling on functional failures, nonfunctional QoS failures such as temporal violations cannot be passively recovered. They need to be proactively prevented through dynamically monitoring and adjusting the temporal consistency states of scientific workflows at runtime. However, current research on workflow temporal verification mainly focuses on runtime monitoring, while the adjusting strategy for temporal consistency states, namely, temporal adjustment, has so far not been thoroughly investigated. For this issue, two fundamental problems of temporal adjustment, namely, where and how, are systematically analyzed and addressed in this paper. Specifically, a novel minimum probability time redundancy-based necessary and sufficient adjustment point selection strategy is proposed to address the problem of where and an innovative genetic-algorithm-based effective and efficient local rescheduling strategy is proposed to tackle the problem of how. The results of large-scale simulation experiments with generic workflows and specific real-world applications demonstrate that our temporal adjustment strategy can remarkably prevent the violations of both local and global temporal constraints in scientific workflows.",1939-3520,,10.1109/TSE.2010.99,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5645643,Workflow management;exception handling;reliability;software verification;statistical methods.,Decision support systems;Software reliability;Quality of service;Workflow management software,genetic algorithms;middleware;quality of service;workflow management software,temporal violation prevention;scientific workflows;grid computing;cloud computing;nonfunctional QoS failures;workflow temporal verification;adjustment point selection;rescheduling strategy;generic workflows,,39.0,,53.0,,29 Nov 2010,,,IEEE,IEEE Journals
822,823,Software Architecture Reconstruction: A Process-Oriented Taxonomy,S. Ducasse; D. Pollet,"INRIA, Lille Nord Europe; University of Lille 1, Francr",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,573,591,"To maintain and understand large applications, it is important to know their architecture. The first problem is that unlike classes and packages, architecture is not explicitly represented in the code. The second problem is that successful applications evolve over time, so their architecture inevitably drifts. Reconstructing the architecture and checking whether it is still valid is therefore an important aid. While there is a plethora of approaches and techniques supporting architecture reconstruction, there is no comprehensive software architecture reconstruction state of the art and it is often difficult to compare the approaches. This paper presents a state of the art in software architecture reconstruction approaches.",1939-3520,,10.1109/TSE.2009.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815276,Software architecture reconstruction.,Software architecture;Taxonomy;Computer architecture;Application software;Data mining;Programming;Europe;Packaging;Cognitive science;Bridges,software architecture;software maintenance;software packages,software architecture reconstruction;process-oriented taxonomy;software development,,168.0,2.0,181.0,,17 Apr 2009,,,IEEE,IEEE Journals
823,824,Software Reliability Analysis Using Weakest Preconditions in Linear Assignment Programs,H. Luo; X. Liu; X. Chen; T. Long; R. Jiang,"Department of Measurement and Control Engineering, School of Manufacturing Science and Engineering, Sichuan University, Chengdu, P.R.China; School of Computer Science, McGill University, Montreal H3A0E9, Canada; School of Computer Science, McGill University, Montreal H3A0E9, Canada; Department of Control Engineering, Chengdu University of Information Technology, Shuangliu, P.R.China; School of Electrical Engineering and Information, Sichuan University, Chengdu, P.R.China",IEEE Transactions on Software Engineering,15 Sep 2016,2016,42,9,866,885,"Weakest preconditions derived from triple axiomatic semantics have been widely used to prove the correctness of programs. They can also be applied to evaluate the reliability of software. However, deducing a weakest precondition, as well as determining its propagation path, encounters challenges such as unknown constraint conditions, symbol computation and means of representation. To address these challenges, in this paper, we utilize the disjunctive normal form of if-else branch structure to capture reasonable propagation paths of the weakest precondition. Meanwhile, by removing the sequential dependencies, we demonstrate how to get the weakest precondition of loop-structure by leveraging program function. Moreover, we extensively explore three modeling characteristics (i.e., path extension, innermost connection and condition leap) for deducing the weakest precondition of structured programs. Finally, taking the definition of program node and storage structure of weakest precondition as bases, we design a serial of modeling algorithms. Based on symbol computation and recursive call technology with Depth-First Search (DFS), our algorithms can not only be used to deduce the weakest precondition, but also to capture the propagate path of the weakest precondition. Experiments illustrate the efficacy and effectiveness of our proposed models and designed deductive algorithms.",1939-3520,,10.1109/TSE.2016.2521379,Research Foundation of Young Teachers in Sichuan University of P.R. China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7398131,Weakest precondition;path extension;innermost connection;condition leap;node;cell-structure,Algorithm design and analysis;Semantics;Software reliability;Computational modeling;Computer bugs;Cognition,linear programming;search problems;software reliability,software reliability analysis;weakest preconditions;linear assignment program;triple axiomatic semantics;program correctness;propagation path;if-else branch structure;loop-structure precondition;path extension characteristic;innermost connection characteristic;condition leap characteristic;symbol computation;recursive call technology;depth-first search;DFS;deductive algorithms,,1.0,,31.0,,3 Feb 2016,,,IEEE,IEEE Journals
824,825,Empirical Studies of Pair Programming for CS/SE Teaching in Higher Education: A Systematic Literature Review,N. Salleh; E. Mendes; J. Grundy,"International Islamic University of Malaysia, Kuala Lumpur and University of Auckland, Auckland; University of Auckland, Auckland; Swinburne University of Technology, Hawthorn",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,509,525,"The objective of this paper is to present the current evidence relative to the effectiveness of pair programming (PP) as a pedagogical tool in higher education CS/SE courses. We performed a systematic literature review (SLR) of empirical studies that investigated factors affecting the effectiveness of PP for CS/SE students and studies that measured the effectiveness of PP for CS/SE students. Seventy-four papers were used in our synthesis of evidence, and 14 compatibility factors that can potentially affect PP's effectiveness as a pedagogical tool were identified. Results showed that students' skill level was the factor that affected PP's effectiveness the most. The most common measure used to gauge PP's effectiveness was time spent on programming. In addition, students' satisfaction when using PP was overall higher than when working solo. Our meta-analyses showed that PP was effective in improving students' grades on assignments. Finally, in the studies that used quality as a measure of effectiveness, the number of test cases succeeded, academic performance, and expert opinion were the quality measures mostly applied. The results of this SLR show two clear gaps in this research field: 1) a lack of studies focusing on pair compatibility factors aimed at making PP an effective pedagogical tool and 2) a lack of studies investigating PP for software design/modeling tasks in conjunction with programming tasks.",1939-3520,,10.1109/TSE.2010.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482588,Empirical studies;pair programming;systematic review.,Programming profession;Education;Educational programs;Computer science;Performance evaluation;Time measurement;Testing;Software design;Collaborative work;Algorithm design and analysis,educational technology;further education;software prototyping;teaching,pair programming;CS/SE teaching;higher education;systematic literature review;PP,,135.0,,75.0,,7 Jun 2010,,,IEEE,IEEE Journals
825,826,A System for Profiling and Monitoring Database Access Patterns by Application Programs for Anomaly Detection,L. Bossi; E. Bertino; S. R. Hussain,"Department of Computer Science, Purdue University, West Lafayette, IN; Department of Computer Science, Purdue University, West Lafayette, IN; Department of Computer Science, Purdue University, West Lafayette, IN",IEEE Transactions on Software Engineering,12 May 2017,2017,43,5,415,431,"Database Management Systems (DBMSs) provide access control mechanisms that allow database administrators (DBAs) to grant application programs access privileges to databases. Though such mechanisms are powerful, in practice finer-grained access control mechanism tailored to the semantics of the data stored in the DMBS is required as a first class defense mechanism against smart attackers. Hence, custom written applications which access databases implement an additional layer of access control. Therefore, securing a database alone is not enough for such applications, as attackers aiming at stealing data can take advantage of vulnerabilities in the privileged applications and make these applications to issue malicious database queries. An access control mechanism can only prevent application programs from accessing the data to which the programs are not authorized, but it is unable to prevent misuse of the data to which application programs are authorized for access. Hence, we need a mechanism able to detect malicious behavior resulting from previously authorized applications. In this paper, we present the architecture of an anomaly detection mechanism, DetAnom, that aims to solve such problem. Our approach is based the analysis and profiling of the application in order to create a succinct representation of its interaction with the database. Such a profile keeps a signature for every submitted query and also the corresponding constraints that the application program must satisfy to submit the query. Later, in the detection phase, whenever the application issues a query, a module captures the query before it reaches the database and verifies the corresponding signature and constraints against the current context of the application. If there is a mismatch, the query is marked as anomalous. The main advantage of our anomaly detection mechanism is that, in order to build the application profiles, we need neither any previous knowledge of application vulnerabilities nor any example of possible attacks. As a result, our mechanism is able to protect the data from attacks tailored to database applications such as code modification attacks, SQL injections, and also from other data-centric attacks as well. We have implemented our mechanism with a software testing technique called concolic testing and the PostgreSQL DBMS. Experimental results show that our profiling technique is close to accurate, requires acceptable amount of time, and the detection mechanism incurs low runtime overhead.",1939-3520,,10.1109/TSE.2016.2598336,Northrop Grumman Systems Corporation; Department of Homeland Security (DHS); Science and Technology Directorate; Homeland Security Advanced Research Projects Agency; Cyber Security Division; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7534833,Database;insider attacks;anomaly detection;application profile;SQL injection,Databases;Access control;Software testing;Software;Engines,authorisation;database management systems;digital signatures;program diagnostics;program testing;query processing;software architecture,database access patterns profiling;database access patterns monitoring;application programs;anomaly detection mechanism architecture;database management systems;DBMS;database administrator;DBA;defense mechanism;smart attackers;access control mechanism;malicious behavior detection;DetAnom;signature;query submission;software testing technique;concolic testing;PostgreSQL,,13.0,,40.0,,5 Aug 2016,,,IEEE,IEEE Journals
826,827,A Classification Framework for Software Component Models,I. Crnkovic; S. Sentilles; A. Vulgarakis; M. R. V. Chaudron,"Mälardalen University, Västerås; Mälardalen University, Västerås; Mälardalen University, Västerås; Universiteit Leiden, Leiden",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,593,615,"In the last decade, a large number of different software component models have been developed, with different aims and using different principles and technologies. This has resulted in a number of models which have many similarities, but also principal differences, and in many cases unclear concepts. Component-based development has not succeeded in providing standard principles, as has, for example, object-oriented development. In order to increase the understanding of the concepts and to differentiate component models more easily, this paper identifies, discusses, and characterizes fundamental principles of component models and provides a Component Model Classification Framework based on these principles. Further, the paper classifies a large number of component models using this framework.",1939-3520,,10.1109/TSE.2010.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5587419,Software components;software component models;component lifecycle;extra-functional properties;component composition.,Data models;Bismuth;Packaging,object-oriented programming;pattern classification,software component models;component based development;object oriented development;component model classification framework,,121.0,6.0,53.0,,27 Sep 2010,,,IEEE,IEEE Journals
827,828,Modular Software Model Checking for Distributed Systems,W. Leungwattanakit; C. Artho; M. Hagiya; Y. Tanabe; M. Yamamoto; K. Takahashi,"Department of Mathematics and Informatics, Faculty of Science, Chiba University, 1-3-3 Yayoicho, Inage Ward, Chiba, Japan; Research Institute for Secure Systems at the National Institute of Advanced Industrial Science and Technology (AIST), Amagasaki, Japan; Department of Computer Science, University of Tokyo, Science Building No. 7, 7-3-1 Hongo, Tokyo, Japan; National Institute of Informatics (NII), 2-1-2 Hitotsubashi, Japan; Department of Mathematics and Informatics, Faculty of Science, Chiba University, 1-3-3 Yayoicho, Inage Ward, Chiba, Japan; Research Institute for Secure Systems at the National Institute of Advanced Industrial Science and Technology (AIST), Amagasaki, Japan",IEEE Transactions on Software Engineering,14 May 2014,2014,40,5,483,501,"Distributed systems are complex, being usually composed of several subsystems running in parallel. Concurrent execution and inter-process communication in these systems are prone to errors that are difficult to detect by traditional testing, which does not cover every possible program execution. Unlike testing, model checking can detect such faults in a concurrent system by exploring every possible state of the system. However, most model-checking techniques require that a system be described in a modeling language. Although this simplifies verification, faults may be introduced in the implementation. Recently, some model checkers verify program code at runtime but tend to be limited to stand-alone programs. This paper proposes cache-based model checking, which relaxes this limitation to some extent by verifying one process at a time and running other processes in another execution environment. This approach has been implemented as an extension of Java PathFinder, a Java model checker. It is a scalable and promising technique to handle distributed systems. To support a larger class of distributed systems, a checkpointing tool is also integrated into the verification system. Experimental results on various distributed systems show the capability and scalability of cache-based model checking.",1939-3520,,10.1109/TSE.2013.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645368,Software model checking;software verification;distributed systems;checkpointing,Model checking;Software;Java;Checkpointing;Synchronization;Scalability;Message systems,cache storage;checkpointing;concurrency control;distributed processing;Java;program testing;program verification,modular software model checking;distributed systems;parallel subsystems;concurrent execution;interprocess communication;program execution;fault detection;model-checking techniques;modeling language;program code verification;stand-alone programs;cache-based model checking;execution environment;Java PathFinder extension;Java model checker;checkpointing tool,,16.0,,50.0,,23 Oct 2013,,,IEEE,IEEE Journals
828,829,RELAI Testing: A Technique to Assess and Improve Software Reliability,D. Cotroneo; R. Pietrantuono; S. Russo,"Dipartimento di Ingegneria Elettrica e delle Tecnologie dell’Informazione (DIETI), Università di Napoli Federico II, Via Claudio 21, Naples, Italy; Dipartimento di Ingegneria Elettrica e delle Tecnologie dell’Informazione (DIETI), Università di Napoli Federico II, Via Claudio 21, Naples, Italy; Dipartimento di Ingegneria Elettrica e delle Tecnologie dell’Informazione (DIETI), Università di Napoli Federico II, Via Claudio 21, Naples, Italy",IEEE Transactions on Software Engineering,12 May 2016,2016,42,5,452,475,"Testing software to assess or improve reliability presents several practical challenges. Conventional operational testing is a fundamental strategy that simulates the real usage of the system in order to expose failures with the highest occurrence probability. However, practitioners find it unsuitable for assessing/achieving very high reliability levels; also, they do not see the adoption of a “real” usage profile estimate as a sensible idea, being it a source of non-quantifiable uncertainty. Oppositely, debug testing aims to expose as many failures as possible, but regardless of their impact on runtime reliability. These strategies are used either to assess or to improve reliability, but cannot improve and assess reliability in the same testing session. This article proposes Reliability Assessment and Improvement (RELAI) testing, a new technique thought to improve the delivered reliability by an adaptive testing scheme, while providing, at the same time, a continuous assessment of reliability attained through testing and fault removal. The technique also quantifies the impact of a partial knowledge of the operational profile. RELAI is positively evaluated on four software applications compared, in separate experiments, with techniques conceived either for reliability improvement or for reliability assessment, demonstrating substantial improvements in both cases.",1939-3520,,10.1109/TSE.2015.2491931,European Commission; FP7 Marie Curie Industry-Academia Partnerships and Pathways (IAPP); MIUR; SVEVIA; COSMIC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7299696,Software Testing;Reliability;Operational Testing;Random Testing;Sampling;Operational Profile;Software testing;reliability;operational testing;random testing;sampling;operational profile,Testing;Software reliability;Software;Uncertainty;Estimation error,probability;program debugging;program testing;software reliability,RELAI testing;software testing;operational testing;nonquantifiable uncertainty;debug testing;software failures;runtime reliability;reliability assessment and improvement testing;software reliability;adaptive testing scheme;continuous reliability assessment;fault removal;software applications,,14.0,,65.0,,16 Oct 2015,,,IEEE,IEEE Journals
829,830,Verifying Linearizability via Optimized Refinement Checking,Y. Liu; W. Chen; Y. A. Liu; J. Sun; S. J. Zhang; J. S. Dong,"Nanyang Technological University, Singapore; Microsoft Research Asia, Beijing; State University of New York at Stony Brook, Stony Brook; Singapore University of Technology and Design, Singapore; National University of Singapore, Singapore; National University of Singapore, Singapore",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,1018,1039,"Linearizability is an important correctness criterion for implementations of concurrent objects. Automatic checking of linearizability is challenging because it requires checking that: (1) All executions of concurrent operations are serializable, and (2) the serialized executions are correct with respect to the sequential semantics. In this work, we describe a method to automatically check linearizability based on refinement relations from abstract specifications to concrete implementations. The method does not require that linearization points in the implementations be given, which is often difficult or impossible. However, the method takes advantage of linearization points if they are given. The method is based on refinement checking of finite-state systems specified as concurrent processes with shared variables. To tackle state space explosion, we develop and apply symmetry reduction, dynamic partial order reduction, and a combination of both for refinement checking. We have built the method into the PAT model checker, and used PAT to automatically check a variety of implementations of concurrent objects, including the first algorithm for scalable nonzero indicators. Our system is able to find all known and injected bugs in these implementations.",1939-3520,,10.1109/TSE.2012.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363443,Linearizability;refinement;model checking;PAT,History;Sun;Educational institutions;Optimization;Electronic mail;Semantics,concurrency control;formal specification;program debugging;program verification;programming language semantics;refinement calculus,linearizability verification;optimized refinement checking;concurrent objects;automatic linearizability checking;concurrent operations;serialized executions;sequential semantics;refinement relations;linearization points;finite-state systems;shared variables;symmetry reduction;dynamic partial-order reduction;PAT model checker;scalable nonzero indicators;bug detection,,18.0,,62.0,,29 Nov 2012,,,IEEE,IEEE Journals
830,831,GossipKit: A Unified ComponentFramework for Gossip,F. Taïani; S. Lin; G. S. Blair,"University of Rennes 1 / IRISA Rennes, France; SAP Labs, China; University of Lancaster, United Kingdom",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,2,123,136,"Although the principles of gossip protocols are relatively easy to grasp, their variety can make their design and evaluation highly time consuming. This problem is compounded by the lack of a unified programming framework for gossip, which means developers cannot easily reuse, compose, or adapt existing solutions to fit their needs, and have limited opportunities to share knowledge and ideas. In this paper, we consider how component frameworks, which have been widely applied to implement middleware solutions, can facilitate the development of gossip-based systems in a way that is both generic and simple. We show how such an approach can maximize code reuse, simplify the implementation of gossip protocols, and facilitate dynamic evolution and redeployment.Also known as “epidemic” protocols.",1939-3520,,10.1109/TSE.2013.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6645372,Distributed systems;components;frameworks;protocols,Protocols;Peer-to-peer computing;Programming;Wireless sensor networks;Ad hoc networks;Software;Assembly,distributed processing;object-oriented programming;protocols,GossipKit;unified component framework;gossip protocols;protocol design;protocol evaluation;unified programming framework;middleware solutions;gossip-based systems;code reuse;epidemic protocols,,3.0,,77.0,,23 Oct 2013,,,IEEE,IEEE Journals
831,832,Optimizing Ordered Throughput Using Autonomic Cloud Bursting Schedulers,S. Kailasam; N. Gnanasambandam; J. Dharanipragada; N. Sharma,"Indian Institute of Technology Madras, Chennai; Xerox Research Center Webster, New York; Indian Institute of Technology Madras, Chennai; Xerox Research Center Webster, New York",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1564,1581,"Optimizing ordered throughput not only improves the system efficiency but also makes cloud bursting transparent to the user. This is critical from the perspective of user fairness in customer-facing systems, correctness in stream processing systems, and so on. In this paper, we consider optimizing ordered throughput for near real-time, data-intensive, independent computations using cloud bursting. Intercloud computation of data-intensive applications is a challenge due to large data transfer requirements, low intercloud bandwidth, and best-effort traffic on the Internet. The system model we consider is comprised of two processing stages. The first stage uses cloud bursting opportunistically for parallel processing, while the second stage (sequential) expects the output of the first stage to be in the same order as the arrival sequence. We propose three scheduling heuristics as part of an autonomic cloud bursting approach that adapt to changing workload characteristics, variation in bandwidth, and available resources to optimize ordered throughput. We also characterize the operational regimes for cloud bursting as stabilization mode versus acceleration mode, depending on the workload characteristics like the size of data to be transferred for a given compute load. The operational regime characterization helps in deciding how many instances can be optimally utilized in the external cloud.",1939-3520,,10.1109/TSE.2013.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6520852,Cloud bursting;ordered throughput;autonomic;data-intensive,Cloud computing;Optimization;Scheduling,cloud computing;fault tolerant computing;parallel processing;scheduling,external cloud;operational regime characterization;data size;acceleration mode;stabilization mode;bandwidth variation;workload characteristics;scheduling heuristics;arrival sequence;parallel processing;Internet traffic;intercloud bandwidth;large data transfer requirements;data-intensive applications;intercloud computation;near real-time data-intensive independent computation;stream processing system correctness;customer-facing systems;user fairness;system efficiency improvement;autonomic cloud bursting schedulers;ordered throughput optimization,,16.0,,41.0,,27 May 2013,,,IEEE,IEEE Journals
832,833,Comparing the Defect Reduction Benefits of Code Inspection and Test-Driven Development,J. W. Wilkerson; J. F. Nunamaker; R. Mercer,"Pennsylvania State University, Erie, Erie; University of Arizona, Tucson; University of Arizona, Tucson",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,547,560,"This study is a quasi experiment comparing the software defect rates and implementation costs of two methods of software defect reduction: code inspection and test-driven development. We divided participants, consisting of junior and senior computer science students at a large Southwestern university, into four groups using a two-by-two, between-subjects, factorial design and asked them to complete the same programming assignment using either test-driven development, code inspection, both, or neither. We compared resulting defect counts and implementation costs across groups. We found that code inspection is more effective than test-driven development at reducing defects, but that code inspection is also more expensive. We also found that test-driven development was no more effective at reducing defects than traditional programming methods.",1939-3520,,10.1109/TSE.2011.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750007,Agile programming;code inspections and walk throughs;reliability;test-driven development;testing strategies;empirical study.,Inspection;Software;Testing;Java;Writing;Programming profession,program testing;system recovery,defect reduction benefits;code inspection;test driven development;quasi experiment;software defect rates;software defect reduction;senior computer science students;junior computer science students;programming assignment,,17.0,,47.0,,15 Apr 2011,,,IEEE,IEEE Journals
833,834,Designing Autonomic Management Systems by Using Reactive Control Techniques,N. Berthier; É. Rutten; N. De Palma; S. M. Gueye,"ERODS team, University of Grenoble LIG Bât. C, 220 rue de la Chimie, St Martin d'Hères, France; LIG/INRIA Grenoble - Rhône-Alpes, Inovallée, 655 av. de l'Europe, Montbonnot, St Ismier, France; ERODS team, University of Grenoble, LIG Bât. C, 220 rue de la Chimie, St Martin d'Hères, France; ERODS team, University of Grenoble, LIG Bât. C, 220 rue de la Chimie, St Martin d'Hères, France",IEEE Transactions on Software Engineering,14 Jul 2016,2016,42,7,640,657,"The ever growing complexity of software systems has led to the emergence of automated solutions for their management. The software assigned to this work is usually called an Autonomic Management System (AMS). It is ordinarily designed as a composition of several managers, which are pieces of software evaluating the dynamics of the system under management through measurements (e.g., workload, memory usage), taking decisions, and acting upon it so that it stays in a set of acceptable operating states. However, careless combination of managers may lead to inconsistencies in the taken decisions, and classical approaches dealing with these coordination problems often rely on intricate and ad hoc solutions. To tackle this problem, we take a global view and underscore that AMSs are intrinsically reactive, as they react to flows of monitoring data by emitting flows of reconfiguration actions. Therefore we propose a new approach for the design of AMSs, based on synchronous programming and discrete controller synthesis techniques. They provide us with high-level languages for modeling the system to manage, as well as means for statically guaranteeing the absence of logical coordination problems. Hence, they suit our main contribution, which is to obtain guarantees at design time about the absence of logical inconsistencies in the taken decisions. We detail our approach, illustrate it by designing an AMS for a realistic multi-tier application, and evaluate its practicality with an implementation.",1939-3520,,10.1109/TSE.2015.2510004,French ANR project Ctrl-Green; ANR INFRA; MINALOGIC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7360217,Autonomic computing;coordination;discrete control;reactive programming,Software;Programming;Automata;Sensor systems;Actuators,software management;software performance evaluation,autonomic management systems;reactive control techniques;software systems;AMS;software evaluation;software measurements;ad hoc solutions;monitoring data flow;emitting flows;synchronous programming;discrete controller synthesis techniques;logical coordination problems;realistic multitier application,,4.0,,47.0,,17 Dec 2015,,,IEEE,IEEE Journals
834,835,Validating Second-Order Mutation at System Level,P. Reales Mateo; M. Polo Usaola; J. L. Fernández Alemán,"University of Castilla-La Mancha, Ciudad Real; University of Castilla-La Mancha, Ciudad Real; University of Murcia, Murcia",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,570,587,"Mutation has been recognized to be an effective software testing technique. It is based on the insertion of artificial faults in the system under test (SUT) by means of a set of mutation operators. Different operators can mutate each program statement in several ways, which may produce a huge number of mutants. This leads to very high costs for test case execution and result analysis. Several works have approached techniques for cost reduction in mutation testing, like n-order mutation where each mutant contains n artificial faults instead of one. There are two approaches to n-order mutation: increasing the effectiveness of mutation by searching for good n-order mutants, and decreasing the costs of mutation testing by reducing the mutants set through the combination of the first-order mutants into n-order mutants. This paper is focused on the second approach. However, this second use entails a risk: the possibility of leaving undiscovered faults in the SUT, which may distort the perception of the test suite quality. This paper describes an empirical study of different combination strategies to compose second-order mutants at system level as well as a cost-risk analysis of n-order mutation at system level.",1939-3520,,10.1109/TSE.2012.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216382,Empirical evaluation;high-order mutation;mutation testing,Algorithm design and analysis;Concrete;Educational institutions;Benchmark testing;Optimization;Software testing,program testing;software fault tolerance,second order mutation;system level;software testing technique;system under test;SUT;mutation operators;test case execution;cost risk analysis,,13.0,,53.0,,12 Jun 2012,,,IEEE,IEEE Journals
835,836,An Efficient and Scalable Approach to Correct Class Model Refinement,W. Shen; K. Wang; A. Egyed,"Western Michigan University, Kalamazoo; Siemens PLM Software, Ann Arbor; Johannes Kepler University, Linz",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,515,533,"Today, programmers benefit immensely from Integrated Development Environments (IDEs), where errors are highlighted within seconds of their introduction. Yet, designers rarely benefit from such an instant feedback in modeling tools. This paper focuses on the refinement of UML-style class models with instant feedback on correctness. Following the Model-Driven Architecture (MDA) paradigm, we strongly believe in the benefit of maintaining high-level and low-level models separately to 1) document the lower level model and 2) continuously ensure the correctness of the low-level model during later evolution (i.e., high- or low-level models may be evolved independently). However, currently the refinement and subsequent evolution lack automated support, let alone an instant feedback on their correctness (i.e., consistency). Traditional approaches to consistency checking fail here because of the computational cost of comparing class models. Our proposed instant approach first transforms the low-level model into an intermediate model that is then easier comparable with the high-level model. The key to computational scalability is the separation of transformation and comparison so that each can react optimally to changes-changes that could happen concurrently in both the high- and low-level class models. We evaluate our approach on eight third-party design models. The empirical data show that the separation of transformation and comparison results in a 6 to 11-fold performance gain and a ninefold reduction in producing irrelevant feedback. While this work emphasizes the refinement of class models, we do believe that the concepts are more generally applicable to other kinds of modeling languages, where transformation and subsequent comparison are computationally expensive.",1939-3520,,10.1109/TSE.2009.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815278,Class models;consistency checking;refinement;separation of concerns;and UML.,Feedback;Programming profession;Unified modeling language;Software systems;Error correction;Computational efficiency;Concurrent computing;Scalability;Performance gain;System recovery,software architecture;Unified Modeling Language,class model refinement;integrated development environment;UML-style class models;Unified Modeling Language;model-driven architecture;computational scalability,,8.0,,43.0,,17 Apr 2009,,,IEEE,IEEE Journals
836,837,Precise Calling Context Encoding,W. N. Sumner; Y. Zheng; D. Weeratunge; X. Zhang,"Purdue University, West Lafayette; Purdue University, West Lafayette; Purdue University, West Lafayette; Purdue University, West Lafayette",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1160,1177,"Calling contexts (CCs) are very important for a wide range of applications such as profiling, debugging, and event logging. Most applications perform expensive stack walking to recover contexts. The resulting contexts are often explicitly represented as a sequence of call sites and hence are bulky. We propose a technique to encode the current calling context of any point during an execution. In particular, an acyclic call path is encoded into one number through only integer additions. Recursive call paths are divided into acyclic subsequences and encoded independently. We leverage stack depth in a safe way to optimize encoding: If a calling context can be safely and uniquely identified by its stack depth, we do not perform encoding. We propose an algorithm to seamlessly fuse encoding and stack depth-based identification. The algorithm is safe because different contexts are guaranteed to have different IDs. It also ensures contexts can be faithfully decoded. Our experiments show that our technique incurs negligible overhead (0-6.4 percent). For most medium-sized programs, it can encode all contexts with just one number. For large programs, we are able to encode most calling contexts to a few numbers. We also present our experience of applying context encoding to debugging crash-based failures.",1939-3520,,10.1109/TSE.2011.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963696,Calling context;context sensitivity;profiling;path encoding;calling context encoding;call graph,Context;Encoding;Instruments;Image edge detection;Runtime;Decoding;Software algorithms,optimisation;program compilers;program debugging,precise calling context encoding;CC;profiling;event logging;stack walking;context recovery;call sites;recursive call paths;acyclic subsequences;encoding optimization;stack depth-based identification;ID;medium-sized programs;crash-based failure debugging,,12.0,,54.0,,28 Jul 2011,,,IEEE,IEEE Journals
837,838,A Uniform Representation of Hybrid Criteria for Regression Testing,S. Sampath; R. Bryce; A. M. Memon,"University of Maryland, Baltimore; University of North Texas, Denton; University of Maryland, Baltimore",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1326,1344,"Regression testing tasks of test case prioritization, test suite reduction/minimization, and regression test selection are typically centered around criteria that are based on code coverage, test execution costs, and code modifications. Researchers have developed and evaluated new individual criteria; others have combined existing criteria in different ways to form what we--and some others--call hybrid criteria. In this paper, we formalize the notion of combining multiple criteria into a hybrid. Our goal is to create a uniform representation of such combinations so that they can be described unambiguously and shared among researchers. We envision that such sharing will allow researchers to implement, study, extend, and evaluate the hybrids using a common set of techniques and tools. We precisely formulate three hybrid combinations, Rank, Merge, and Choice, and demonstrate their usefulness in two ways. First, we recast, in terms of our formulations, others' previously reported work on hybrid criteria. Second, we use our previous results on test case prioritization to create and evaluate new hybrid criteria. Our findings suggest that hybrid criteria of others can be described using our Merge and Rank formulations, and that the hybrid criteria we developed most often outperformed their constituent individual criteria.",1939-3520,,10.1109/TSE.2013.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6484067,Test case prioritization;test criteria;hybrid test criteria;web testing;GUI testing,Testing;Fault detection;Educational institutions;Genetic algorithms;Vectors;Loss measurement;Minimization,program testing;regression analysis,uniform representation;hybrid test criteria;regression testing;rank-merge-and-choice hybrid combination;test case prioritization;merge-and-rank formulations,,21.0,,74.0,,21 Mar 2013,,,IEEE,IEEE Journals
838,839,The Use of Summation to Aggregate Software Metrics Hinders the Performance of Defect Prediction Models,F. Zhang; A. E. Hassan; S. McIntosh; Y. Zou,"School of Computing, Queen's University, Kingston, ON, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, McGill University, Montréal, QC, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,12 May 2017,2017,43,5,476,491,"Defect prediction models help software organizations to anticipate where defects will appear in the future. When training a defect prediction model, historical defect data is often mined from a Version Control System (VCS, e.g., Subversion), which records software changes at the file-level. Software metrics, on the other hand, are often calculated at the class- or method-level (e.g., McCabe's Cyclomatic Complexity). To address the disagreement in granularity, the class- and method-level software metrics are aggregated to file-level, often using summation (i.e., McCabe of a file is the sum of the McCabe of all methods within the file). A recent study shows that summation significantly inflates the correlation between lines of code (Sloc) and cyclomatic complexity (Cc) in Java projects. While there are many other aggregation schemes (e.g., central tendency, dispersion), they have remained unexplored in the scope of defect prediction. In this study, we set out to investigate how different aggregation schemes impact defect prediction models. Through an analysis of 11 aggregation schemes using data collected from 255 open source projects, we find that: (1) aggregation schemes can significantly alter correlations among metrics, as well as the correlations between metrics and the defect count; (2) when constructing models to predict defect proneness, applying only the summation scheme (i.e., the most commonly used aggregation scheme in the literature) only achieves the best performance (the best among the 12 studied configurations) in 11 percent of the studied projects, while applying all of the studied aggregation schemes achieves the best performance in 40 percent of the studied projects; (3) when constructing models to predict defect rank or count, either applying only the summation or applying all of the studied aggregation schemes achieves similar performance, with both achieving the closest to the best performance more often than the other studied aggregation schemes; and (4) when constructing models for effort-aware defect prediction, the mean or median aggregation schemes yield performance values that are significantly closer to the best performance than any of the other studied aggregation schemes. Broadly speaking, the performance of defect prediction models are often underestimated due to our community's tendency to only use the summation aggregation scheme. Given the potential benefit of applying additional aggregation schemes, we advise that future defect prediction models should explore a variety of aggregation schemes.",1939-3520,,10.1109/TSE.2016.2599161,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7539677,Defect prediction;aggregation scheme;software metrics,Predictive models;Correlation;Software metrics;Indexes;Software;Data models,data aggregation;data mining;Java;public domain software;software metrics,software metrics aggregation;defect prediction models;software organizations;historical defect data mining;version control system;software changes recording;McCabe cyclomatic complexity;granularity disagreement;class-level software metrics;method-level software metrics;lines of code;Sloc;Cc;Java projects;open source projects;effort-aware defect prediction;summation,,31.0,,87.0,,10 Aug 2016,,,IEEE,IEEE Journals
839,840,Effects of Personality on Pair Programming,J. E. Hannay; E. Arisholm; H. Engvik; D. I. K. Sjoberg,"Simula Research Laboratory, Lysaker and University of Oslo, Oslo; Simula Research Laboratory, Lysaker and University of Oslo, Oslo; University of Oslo, Oslo; University of Oslo, Oslo",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,61,80,"Personality tests in various guises are commonly used in recruitment and career counseling industries. Such tests have also been considered as instruments for predicting the job performance of software professionals both individually and in teams. However, research suggests that other human-related factors such as motivation, general mental ability, expertise, and task complexity also affect the performance in general. This paper reports on a study of the impact of the Big Five personality traits on the performance of pair programmers together with the impact of expertise and task complexity. The study involved 196 software professionals in three countries forming 98 pairs. The analysis consisted of a confirmatory part and an exploratory part. The results show that: (1) Our data do not confirm a meta-analysis-based model of the impact of certain personality traits on performance and (2) personality traits, in general, have modest predictive value on pair programming performance compared with expertise, task complexity, and country. We conclude that more effort should be spent on investigating other performance-related predictors such as expertise, and task complexity, as well as other promising predictors, such as programming skill and learning. We also conclude that effort should be spent on elaborating on the effects of personality on various measures of collaboration, which, in turn, may be used to predict and influence performance. Insights into such malleable, rather than static, factors may then be used to improve pair programming performance.",1939-3520,,10.1109/TSE.2009.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5089333,Pair programming;personality;Big Five;expertise;task complexity;performance.,Programming profession;Collaborative work;Keyboards;Books;Recruitment;Engineering profession;Employee welfare;Software testing;Instruments;Software performance,human factors;personnel;programming;recruitment;team working,personality tests;pair programming;recruitment industries;career counseling industries;job performance;software professionals;personality traits;task complexity;meta-analysis-based model;performance-related predictors,,64.0,,121.0,,19 Jun 2009,,,IEEE,IEEE Journals
840,841,Automated Extraction and Clustering of Requirements Glossary Terms,C. Arora; M. Sabetzadeh; L. Briand; F. Zimmer,"SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Alphonse Weicker, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Alphonse Weicker, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Alphonse Weicker, Luxembourg; SES Techcom, Betzdorf, Luxembourg",IEEE Transactions on Software Engineering,13 Oct 2017,2017,43,10,918,945,"A glossary is an important part of any software requirements document. By making explicit the technical terms in a domain and providing definitions for them, a glossary helps mitigate imprecision and ambiguity. A key step in building a glossary is to decide upon the terms to include in the glossary and to find any related terms. Doing so manually is laborious, particularly for large requirements documents. In this article, we develop an automated approach for extracting candidate glossary terms and their related terms from natural language requirements documents. Our approach differs from existing work on term extraction mainly in that it clusters the extracted terms by relevance, instead of providing a flat list of terms. We provide an automated, mathematically-based procedure for selecting the number of clusters. This procedure makes the underlying clustering algorithm transparent to users, thus alleviating the need for any user-specified parameters. To evaluate our approach, we report on three industrial case studies, as part of which we also examine the perceptions of the involved subject matter experts about the usefulness of our approach. Our evaluation notably suggests that: (1) Over requirements documents, our approach is more accurate than major generic term extraction tools. Specifically, in our case studies, our approach leads to gains of 20 percent or more in terms of recall when compared to existing tools, while at the same time either improving precision or leaving it virtually unchanged. And, (2) the experts involved in our case studies find the clusters generated by our approach useful as an aid for glossary construction.",1939-3520,,10.1109/TSE.2016.2635134,Luxembourg’s National Research Fund; European Research Council; European Union’s Horizon 2020 research and innovation program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7765062,Requirements glossaries;term extraction;natural language processing;clustering;case study research,Terminology;Servers;Pipelines;Natural languages;Monitoring;Software;Clustering algorithms,natural language processing;pattern clustering;text analysis,natural language requirements documents;mathematically-based procedure;user-specified parameters;candidate glossary terms;technical terms;clustering algorithm;automated approach;software requirements document;requirements glossary terms;glossary construction;generic term extraction tools,,11.0,,100.0,Traditional,2 Dec 2016,,,IEEE,IEEE Journals
841,842,Efficient Dynamic Updates of Distributed Components Through Version Consistency,L. Baresi; C. Ghezzi; X. Ma; V. P. L. Manna,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy; State Key Laboratory for Novel Software Technology and the Collaborative Innovation Center of Novel Software Technology and Industrialization, Nanjing University, Nanjing, Jiangsu, China; Holst Centre/imec the Netherlands, Eindhoven, AE, The Netherlands",IEEE Transactions on Software Engineering,14 Apr 2017,2017,43,4,340,358,"Modern component-based distributed software systems are increasingly required to offer non-stop service and thus their updates must be carried out at runtime. Different authors have already proposed solutions for the safe management of dynamic updates. Our contribution aims at improving their efficiency without compromising safety. We propose a new criterion, called version consistency, which defines when a dynamic update can be safely and efficiently applied to the components that execute distributed transactions. Version consistency ensures that distributed transactions be served as if they were operated on a single coherent version of the system despite possible concurrent updates. The paper presents a distributed algorithm for checking version consistency efficiently, formalizes the proposed approach by means of a graph transformation system, and verifies its correctness through model checking. The paper also presents ConUp, a novel prototype framework that supports the approach and offers a viable, concrete solution for the use of version consistency. Both the approach and ConUp are evaluated on a significant third-party application. Obtained results witness the benefits of the proposed solution with respect to both timeliness and disruption.",1939-3520,,10.1109/TSE.2016.2592913,The 973 Program of China; NSFC; EEB-Edifici a zero consumo energetico in distretti urbani intelligenti; Italian Technology Cluster For Smart Communities; Telecom Italia; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7516718,Component-based distributed system;dynamic update;version-consistency,Portals;Runtime;Software systems;Safety;Model checking;Concrete,distributed programming;formal verification;graph theory,distributed components;version consistency;distributed software systems;dynamic update;graph transformation system,,9.0,,41.0,,19 Jul 2016,,,IEEE,IEEE Journals
842,843,An Autonomous Engine for Services Configuration and Deployment,F. Cuadrado; J. C. Duenas; R. Garcia-Carmona,"Queen Mary University of London, London; Universidad Politécnica de Madrid, Madrid; Universidad Politécnica de Madrid, Madrid",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,520,536,"The runtime management of the infrastructure providing service-based systems is a complex task, up to the point where manual operation struggles to be cost effective. As the functionality is provided by a set of dynamically composed distributed services, in order to achieve a management objective multiple operations have to be applied over the distributed elements of the managed infrastructure. Moreover, the manager must cope with the highly heterogeneous characteristics and management interfaces of the runtime resources. With this in mind, this paper proposes to support the configuration and deployment of services with an automated closed control loop. The automation is enabled by the definition of a generic information model, which captures all the information relevant to the management of the services with the same abstractions, describing the runtime elements, service dependencies, and business objectives. On top of that, a technique based on satisfiability is described which automatically diagnoses the state of the managed environment and obtains the required changes for correcting it (e.g., installation, service binding, update, or configuration). The results from a set of case studies extracted from the banking domain are provided to validate the feasibility of this proposal.",1939-3520,,10.1109/TSE.2011.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728830,Autonomic systems;model-based management;satisfiability;service configuration.,Runtime;Containers;Servers;Web services;Context;Business;Engines,computability;fault tolerant computing;service-oriented architecture,autonomous engine;services configuration;runtime management;service-based systems;dynamically composed distributed services;distributed elements;runtime resources;automated closed control loop;generic information model;runtime elements;service dependencies;business objectives;satisfiability;banking domain,,10.0,,38.0,,10 Mar 2011,,,IEEE,IEEE Journals
843,844,TACO: Efficient SAT-Based Bounded Verification Using Symmetry Breaking and Tight Bounds,J. P. Galeotti; N. Rosner; C. G. López Pombo; M. F. Frias,"Universidad de Buenos Aires and CONICET, Argentina; Universidad de Buenos Aires, Argentina; Universidad de Buenos Aires and CONICET, Argentina; Instituto Tecnológico de Buenos Aires and CONICET, Argentina",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1283,1307,"SAT-based bounded verification of annotated code consists of translating the code together with the annotations to a propositional formula, and analyzing the formula for specification violations using a SAT-solver. If a violation is found, an execution trace exposing the failure is exhibited. Code involving linked data structures with intricate invariants is particularly hard to analyze using these techniques. In this paper, we present Translation of Annotated COde (TACO), a prototype tool which implements a novel, general, and fully automated technique for the SAT-based analysis of JML-annotated Java sequential programs dealing with complex linked data structures. We instrument code analysis with a symmetry-breaking predicate which, on one hand, reduces the size of the search space by ignoring certain classes of isomorphic models and, on the other hand, allows for the parallel, automated computation of tight bounds for Java fields. Experiments show that the translations to propositional formulas require significantly less propositional variables, leading to an improvement of the efficiency of the analysis of orders of magnitude, compared to the noninstrumented SAT--based analysis. We show that in some cases our tool can uncover bugs that cannot be detected by state-of-the-art tools based on SAT-solving, model checking, or SMT-solving.",1939-3520,,10.1109/TSE.2013.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6482141,Static analysis;SAT-based code analysis;Alloy;KodKod;DynAlloy,Metals;Java;Cost accounting;Instruments;Analytical models;Contracts;Context,computability;formal specification;formal verification;program diagnostics;program interpreters,TACO tool;translation-of-annotated code tool;SAT-based bounded verification;satisfiability;code translation;specification violation;JML-annotated Java sequential program;data structure;code analysis;symmetry-breaking predicate;isomorphic model;automated tight bound computation;model checking;SAT-solving;SMT-solving,,26.0,,47.0,,19 Mar 2013,,,IEEE,IEEE Journals
844,845,On Fault Representativeness of Software Fault Injection,R. Natella; D. Cotroneo; J. A. Duraes; H. S. Madeira,"Federico II University of Naples, Naples; Federico II University of Naples, Naples; Rua Pedro Nunes-Quinta da Nora, Coimbra; University of Coimbra, Polo II-Pinhal de Marrocos, Coimbra",IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,80,96,"The injection of software faults in software components to assess the impact of these faults on other components or on the system as a whole, allowing the evaluation of fault tolerance, is relatively new compared to decades of research on hardware fault injection. This paper presents an extensive experimental study (more than 3.8 million individual experiments in three real systems) to evaluate the representativeness of faults injected by a state-of-the-art approach (G-SWFIT). Results show that a significant share (up to 72 percent) of injected faults cannot be considered representative of residual software faults as they are consistently detected by regression tests, and that the representativeness of injected faults is affected by the fault location within the system, resulting in different distributions of representative/nonrepresentative faults across files and functions. Therefore, we propose a new approach to refine the faultload by removing faults that are not representative of residual software faults. This filtering is essential to assure meaningful results and to reduce the cost (in terms of number of faults) of software fault injection campaigns in complex software. The proposed approach is based on classification algorithms, is fully automatic, and can be used for improving fault representativeness of existing software fault injection approaches.",1939-3520,,10.1109/TSE.2011.124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6122035,Software fault injection;experimental dependability evaluation;software reliability;fault-tolerant systems,Software;Testing;Fault tolerance;Fault tolerant systems;Hardware;Fault location;Emulation,software fault tolerance,fault representativeness;software components;software fault injection approaches;fault tolerance;hardware fault injection;G-SWFIT;regression tests;fault location;nonrepresentative faults;classification algorithms,,87.0,,62.0,,3 Jan 2012,,,IEEE,IEEE Journals
845,846,Scalable and Effective Test Generation for Role-Based Access Control Systems,A. Masood; R. Bhatti; A. Ghafoor; A. P. Mathur,"Air University, Islamabad; Oracle, Redwood Shores; Purdue University, West Lafayette; Purdue University, West Lafayette",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,654,668,"Conformance testing procedures for generating tests from the finite state model representation of Role-Based Access Control (RBAC) policies are proposed and evaluated. A test suite generated using one of these procedures has excellent fault detection ability but is astronomically large. Two approaches to reduce the size of the generated test suite were investigated. One is based on a set of six heuristics and the other directly generates a test suite from the finite state model using random selection of paths in the policy model. Empirical studies revealed that the second approach to test suite generation, combined with one or more heuristics, is most effective in the detection of both first-order mutation and malicious faults and generates a significantly smaller test suite than the one generated directly from the finite state models.",1939-3520,,10.1109/TSE.2009.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967616,Role-Based Access Control (RBAC);finite state models;fault model;first-order mutants;malicious faults.,System testing;Access control;Fault detection;Application software;Genetic mutations;Permission;Aerospace electronics;Computer Society;Authentication;Operating systems,authorisation;fault tolerance;finite state machines,for role-based access control system;conformance testing;finite state model;malicious fault detection;first-order mutant,,21.0,1.0,30.0,,26 May 2009,,,IEEE,IEEE Journals
846,847,Elaborating Requirements Using Model Checking and Inductive Learning,D. Alrajeh; J. Kramer; A. Russo; S. Uchitel,"Imperial College London, London; Imperial College London, London; Imperial College London, London; Imperial College London, London",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,361,383,"The process of Requirements Engineering (RE) includes many activities, from goal elicitation to requirements specification. The aim is to develop an operational requirements specification that is guaranteed to satisfy the goals. In this paper, we propose a formal, systematic approach for generating a set of operational requirements that are complete with respect to given goals. We show how the integration of model checking and inductive learning can be effectively used to do this. The model checking formally verifies the satisfaction of the goals and produces counterexamples when incompleteness in the operational requirements is detected. The inductive learning process then computes operational requirements from the counterexamples and user-provided positive examples. These learned operational requirements are guaranteed to eliminate the counterexamples and be consistent with the goals. This process is performed iteratively until no goal violation is detected. The proposed framework is a rigorous, tool-supported requirements elaboration technique which is formally guided by the engineer's knowledge of the domain and the envisioned system.",1939-3520,,10.1109/TSE.2012.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216384,Requirements elaboration;goal operationalization;behavior model refinement;model checking;inductive learning,Wheels;Computational modeling;Software;Adaptation models;Calculus;Switches;Semantics,formal specification;formal verification;learning by example,model checking;requirement engineering;RE;goal elicitation;requirement specification;operational requirements specification;formal verification;inductive learning process;tool-supported requirements elaboration,,14.0,,52.0,,12 Jun 2012,,,IEEE,IEEE Journals
847,848,Test Code Quality and Its Relation to Issue Handling Performance,D. Athanasiou; A. Nugroho; J. Visser; A. Zaidman,"Software Improvement Group, Amstelplein 1, 1096HA Amsterdam, The Netherlands; Software Improvement Group, Amstelplein 1, 1096HA Amsterdam, The Netherlands; Software Improvement Group, Amstelplein 1, 1096HA Amsterdam, The Netherlands; Faculty of Electrical Engineering, Mathematics and Computer Science, Delft University of Technology, Mekelweg 4, 2628CD Delft, The Netherlands",IEEE Transactions on Software Engineering,10 Nov 2014,2014,40,11,1100,1125,"Automated testing is a basic principle of agile development. Its benefits include early defect detection, defect causelocalization and removal of fear to apply changes to the code. Therefore, maintaining high quality test code is essential. This study introduces a model that assesses test code quality by combining source code metrics that reflect three main aspects of test codequality: completeness, effectiveness and maintainability. The model is inspired by the Software Quality Model of the SoftwareImprovement Group which aggregates source code metrics into quality ratings based on benchmarking. To validate the model we assess the relation between test code quality, as measured by the model, and issue handling performance. An experiment isconducted in which the test code quality model is applied to $18$  open source systems. The test quality ratings are tested for correlation with issue handling indicators, which are obtained by mining issue repositories. In particular, we study the (1) defect resolution speed, (2) throughput and (3) productivity issue handling metrics. The results reveal a significant positive correlation between test code quality and two out of the three issue handling metrics (throughput and productivity), indicating that good test code quality positively influences issue handling performance.",1939-3520,,10.1109/TSE.2014.2342227,NWO TestRoots project; RAAK-PRO project EQuA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6862882,Testing;defects;bugs;metrics;measurement,Measurement;Software;Productivity;Throughput;Benchmark testing;Correlation,,,,42.0,,90.0,,23 Jul 2014,,,IEEE,IEEE Journals
848,849,Identifying Renaming Opportunities by Expanding Conducted Rename Refactorings,H. Liu; Q. Liu; Y. Liu; Z. Wang,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, China",IEEE Transactions on Software Engineering,15 Sep 2015,2015,41,9,887,900,"To facilitate software refactoring, a number of approaches and tools have been proposed to suggest where refactorings should be conducted. However, identification of such refactoring opportunities is usually difficult because it often involves difficult semantic analysis and it is often influenced by many factors besides source code. For example, whether a software entity should be renamed depends on the meaning of its original name (natural language understanding), the semantics of the entity (source code semantics), experience and preference of developers, and culture of companies. As a result, it is difficult to identify renaming opportunities. To this end, in this paper we propose an approach to identify renaming opportunities by expanding conducted renamings. Once a rename refactoring is conducted manually or with tool support, the proposed approach recommends to rename closely related software entities whose names are similar to that of the renamed entity. The rationale is that if an engineer makes a mistake in naming a software entity it is likely for her to make the same mistake in naming similar and closely related software entities. The main advantage of the proposed approach is that it does not involve difficult semantic analysis of source code or complex natural language understanding. Another advantage of this approach is that it is less influenced by subjective factors, e.g., experience and preference of software engineers. The proposed approach has been evaluated on four open-source applications. Our evaluation results show that the proposed approach is accurate in recommending entities to be renamed (average precision 82 percent) and in recommending new names for such entities (average precision 93 percent). Evaluation results also suggest that a substantial percentage (varying from 20 to 23 percent) of rename refactorings are expansible.",1939-3520,,10.1109/TSE.2015.2427831,National Natural Science Foundation of China; Program for New Century Excellent Talents in University; Beijing Higher Education Young Elite Teacher Project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7097720,Software Refactoring;Rename;Code Smells;Refactoring Opportunity;Identification;Software refactoring;rename;code smells;refactoring opportunity;identification,Semantics;Natural languages;Open source software;Engines;Context;IEEE Potentials,software maintenance,renaming opportunities identification;conducted rename refactorings;software refactoring;semantic analysis;software entity naming,,10.0,,36.0,,29 Apr 2015,,,IEEE,IEEE Journals
849,850,The Risks of Coverage-Directed Test Case Generation,G. Gay; M. Staats; M. Whalen; M. P. E. Heimdahl,"Department of Computer Science & Engineering, University of South Carolina; Google, Inc; Department of Computer Science and Engineering, University of Minnesota; Department of Computer Science and Engineering, University of Minnesota",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,803,819,"A number of structural coverage criteria have been proposed to measure the adequacy of testing efforts. In the avionics and other critical systems domains, test suites satisfying structural coverage criteria are mandated by standards. With the advent of powerful automated test generation tools, it is tempting to simply generate test inputs to satisfy these structural coverage criteria. However, while techniques to produce coverage-providing tests are well established, the effectiveness of such approaches in terms of fault detection ability has not been adequately studied. In this work, we evaluate the effectiveness of test suites generated to satisfy four coverage criteria through counterexample-based test generation and a random generation approach-where tests are randomly generated until coverage is achieved-contrasted against purely random test suites of equal size. Our results yield three key conclusions. First, coverage criteria satisfaction alone can be a poor indication of fault finding effectiveness, with inconsistent results between the seven case examples (and random test suites of equal size often providing similar-or even higher-levels of fault finding). Second, the use of structural coverage as a supplement-rather than a target-for test generation can have a positive impact, with random test suites reduced to a coverage-providing subset detecting up to 13.5 percent more faults than test suites generated specifically to achieve coverage. Finally, Observable MC/DC, a criterion designed to account for program structure and the selection of the test oracle, can-in part-address the failings of traditional structural coverage criteria, allowing for the generation of test suites achieving higher levels of fault detection than random test suites of equal size. These observations point to risks inherent in the increase in test automation in critical systems, and the need for more research in how coverage criteria, test generation approaches, the test oracle used, and system structure jointly influence test effectiveness.",1939-3520,,10.1109/TSE.2015.2421011,"NASA; NSF; Fonds National de la Recherche, Luxembourg; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7081779,Software Testing;System Testing;Software testing;system testing,Testing;Aerospace electronics;NASA;Standards;Fault detection;Measurement;Software packages,program testing;risk management;software fault tolerance,risks;coverage-directed test case generation;structural coverage criteria;automated test generation tools;fault detection;counterexample-based test generation;random generation approach;random test suites;coverage criteria satisfaction;fault finding effectiveness;observable MC/DC;program structure;test oracle selection;test automation;critical systems;system structure;software testing,,50.0,,56.0,,8 Apr 2015,,,IEEE,IEEE Journals
850,851,Generating Event Sequence-Based Test Cases Using GUI Runtime State Feedback,X. Yuan; A. M. Memon,"University of Maryland, College Park; University of Maryland, College Park",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,81,95,"This paper presents a fully automatic model-driven technique to generate test cases for graphical user interfaces (GUIs)-based applications. The technique uses feedback from the execution of a ¿seed test suite,¿ which is generated automatically using an existing structural event interaction graph model of the GUI. During its execution, the runtime effect of each GUI event on all other events pinpoints event semantic interaction (ESI) relationships, which are used to automatically generate new test cases. Two studies on eight applications demonstrate that the feedback-based technique 1) is able to significantly improve existing techniques and helps identify serious problems in the software and 2) the ESI relationships captured via GUI state yield test suites that most often detect more faults than their code, event, and event-interaction-coverage equivalent counterparts.",1939-3520,,10.1109/TSE.2009.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5306073,GUI testing;automated testing;model-based testing;GUITAR testing system.,Graphical user interfaces;Runtime;State feedback;Automatic testing;Software testing;System testing;Application software;Costs;Fault diagnosis;Event detection,graphical user interfaces;program testing;software quality,event sequence based test cases;graphical user interfaces;GUI runtime state feedback;automatic model driven technique;event interaction coverage equivalent counterparts;software quality;event semantic interaction relationships,,70.0,2.0,49.0,,30 Oct 2009,,,IEEE,IEEE Journals
851,852,Model Checking Timed and Stochastic Properties with CSL^{TA},S. Donatelli; S. Haddad; J. Sproston,"Università di Torino, Torino; LSV, CBRS and École Normale Supérieure de Cachan, Cachan; Università di Torino, Torino",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,224,240,"Markov chains are a well-known stochastic process that provide a balance between being able to adequately model the system's behavior and being able to afford the cost of the model solution. The definition of stochastic temporal logics like continuous stochastic logic (CSL) and its variant asCSL, and of their model-checking algorithms, allows a unified approach to the verification of systems, allowing the mix of performance evaluation and probabilistic verification. In this paper we present the stochastic logic CSLTA, which is more expressive than CSL and asCSL, and in which properties can be specified using automata (more precisely, timed automata with a single clock). The extension with respect to expressiveness allows the specification of properties referring to the probability of a finite sequence of timed events. A typical example is the responsiveness property ""with probability at least 0.75, a message sent at time 0 by a system A will be received before time 5 by system B and the acknowledgment will be back at A before time 7"", a property that cannot be expressed in either CSL or asCSL. We also present a model-checking algorithm for CSLTA.",1939-3520,,10.1109/TSE.2008.108,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721440,Model checking;Markov processes;Temporal logic,Stochastic processes;Stochastic systems;Costs;Automata;Probabilistic logic;Quality of service;Unified modeling language;Telecommunication computing;Clocks;Delay,formal logic;formal verification;Markov processes;probability,timed properties;stochastic properties;Markov chains;stochastic process;stochastic temporal logics;continuous stochastic logic;model checking algorithm;systems verification;performance evaluation;probabilistic verification;finite sequence;timed events,,54.0,,30.0,,22 Dec 2008,,,IEEE,IEEE Journals
852,853,Common Trends in Software Fault and Failure Data,M. Hamill; K. Goseva-Popstojanova,"West Virginia University, Morgantown; West Virginia University, Morgantown",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,484,496,"The benefits of the analysis of software faults and failures have been widely recognized. However, detailed studies based on empirical data are rare. In this paper, we analyze the fault and failure data from two large, real-world case studies. Specifically, we explore: 1) the localization of faults that lead to individual software failures and 2) the distribution of different types of software faults. Our results show that individual failures are often caused by multiple faults spread throughout the system. This observation is important since it does not support several heuristics and assumptions used in the past. In addition, it clearly indicates that finding and fixing faults that lead to such software failures in large, complex systems are often difficult and challenging tasks despite the advances in software development. Our results also show that requirement faults, coding faults, and data problems are the three most common types of software faults. Furthermore, these results show that contrary to the popular belief, a significant percentage of failures are linked to late life cycle activities. Another important aspect of our work is that we conduct intra- and interproject comparisons, as well as comparisons with the findings from related studies. The consistency of several main trends across software systems in this paper and several related research efforts suggests that these trends are likely to be intrinsic characteristics of software faults and failures rather than project specific.",1939-3520,,10.1109/TSE.2009.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4760152,Software faults and failures;fault location;fault types;software fault distribution;software reliability;empirical studies.,Failure analysis;Software quality;Programming;Software systems;Fault location;Software reliability;Fault detection;Humans;Terminology;Computer bugs,software fault tolerance;system recovery;systems analysis,software fault analysis;software failure data;complex system;software development;requirement fault;coding fault;software life cycle activity;software system,,67.0,,26.0,,23 Jan 2009,,,IEEE,IEEE Journals
853,854,Software Reliability and Testing Time Allocation: An Architecture-Based Approach,R. Pietrantuono; S. Russo; K. S. Trivedi,"Federico II University of Naples, Naples; Federico II University of Naples, Naples; Duke University, Durham",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,323,337,"With software systems increasingly being employed in critical contexts, assuring high reliability levels for large, complex systems can incur huge verification costs. Existing standards usually assign predefined risk levels to components in the design phase, to provide some guidelines for the verification. It is a rough-grained assignment that does not consider the costs and does not provide sufficient modeling basis to let engineers quantitatively optimize resources usage. Software reliability allocation models partially address such issues, but they usually make so many assumptions on the input parameters that their application is difficult in practice. In this paper, we try to reduce this gap, proposing a reliability and testing resources allocation model that is able to provide solutions at various levels of detail, depending upon the information the engineer has about the system. The model aims to quantitatively identify the most critical components of software architecture in order to best assign the testing resources to them. A tool for the solution of the model is also developed. The model is applied to an empirical case study, a program developed for the European Space Agency, to verify model's prediction abilities and evaluate the impact of the parameter estimation errors on the prediction accuracy.",1939-3520,,10.1109/TSE.2010.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383374,Reliability;software architecture;software testing.,Software reliability;Software testing;Reliability engineering;Predictive models;Software systems;Guidelines;Cost function;Application software;System testing;Resource management,program testing;software architecture;software reliability,software reliability;testing time allocation;architecture-based approach;rough-grained assignment,,48.0,,40.0,,15 Jan 2010,,,IEEE,IEEE Journals
854,855,Dynamic Software Updating Using a Relaxed Consistency Model,H. Chen; J. Yu; C. Hang; B. Zang; P. Yew,"Fudan University, Shanghai; University of Michigan, Ann Arbor; Microsoft (China) Ltd., Shanghai; Fudan University, Shanghai; University of Minnesota at Twin Cities, Minneapolis",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,679,694,"Software is inevitably subject to changes. There are patches and upgrades that close vulnerabilities, fix bugs, and evolve software with new features. Unfortunately, most traditional dynamic software updating approaches suffer some level of limitations; few of them can update multithreaded applications when involving data structure changes, while some of them lose binary compatibility or incur nonnegligible performance overhead. This paper presents POLUS, a software maintenance tool capable of iteratively evolving running unmodified multithreaded software into newer versions, yet with very low performance overhead. The main idea in POLUS is a relaxed consistency model that permits the concurrent activity of the old and new code. POLUS borrows the idea of cache-coherence protocol in computer architecture and uses a ”bidirectional write-through” synchronization protocol to ensure system consistency. To demonstrate the applicability of POLUS, we report our experience in using POLUS to dynamically update three prevalent server applications: vsftpd, sshd, and Apache HTTP server. Performance measurements show that POLUS incurs negligible runtime overhead on the three applications-a less than 1 percent performance degradation (but 5 percent for one case). The time to apply an update is also minimal.",1939-3520,,10.1109/TSE.2010.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551162,Maintainability;reliability;runtime environments.,Software;Synchronization;Protocols;Bidirectional control;Registers;Runtime,computer architecture;hypermedia;multi-threading;program testing;software maintenance;software tools;transport protocols,dynamic software update;relaxed consistency model;data structure;binary compatibility;nonnegligible performance;POLUS;software maintenance tool;iteratively evolving running unmodified multithreaded software;concurrent activity;cache-coherence protocol;computer architecture;bidirectional write-through synchronization protocol;prevalent server application;HTTP server,,27.0,4.0,42.0,,19 Aug 2010,,,IEEE,IEEE Journals
855,856,Patterns of Knowledge in API Reference Documentation,W. Maalej; M. P. Robillard,"University of Hamburg, Germany; McGill University, Montréal",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1264,1282,"Reading reference documentation is an important part of programming with application programming interfaces (APIs). Reference documentation complements the API by providing information not obvious from the API syntax. To improve the quality of reference documentation and the efficiency with which the relevant information it contains can be accessed, we must first understand its content. We report on a study of the nature and organization of knowledge contained in the reference documentation of the hundreds of APIs provided as a part of two major technology platforms: Java SDK 6 and .NET 4.0. Our study involved the development of a taxonomy of knowledge types based on grounded methods and independent empirical validation. Seventeen trained coders used the taxonomy to rate a total of 5,574 randomly sampled documentation units to assess the knowledge they contain. Our results provide a comprehensive perspective on the patterns of knowledge in API documentation: observations about the types of knowledge it contains and how this knowledge is distributed throughout the documentation. The taxonomy and patterns of knowledge we present in this paper can be used to help practitioners evaluate the content of their API documentation, better organize their documentation, and limit the amount of low-value content. They also provide a vocabulary that can help structure and facilitate discussions about the content of APIs.",1939-3520,,10.1109/TSE.2013.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6473801,API documentation;software documentation;empirical study;content analysis;grounded method;data mining;pattern mining;Java;.NET,Documentation;Taxonomy;Encoding;Reliability;Java;Software;Sociology,application program interfaces;learning (artificial intelligence);pattern classification,knowledge taxonomy;.NET 4.0 API;Java SDK 6 API;knowledge organization;knowledge nature;reference documentation efficiency;reference documentation quality;application program interface;API reference documentation;knowledge pattern,,65.0,,35.0,,7 Mar 2013,,,IEEE,IEEE Journals
856,857,Reverse Engineering Input Syntactic Structure from Program Execution and Its Applications,Z. Lin; X. Zhang; D. Xu,"Purdue University, West Lafayette; Purdue University, West Lafayette; Purdue University, West Lafayette",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,688,703,"Program input syntactic structure is essential for a wide range of applications such as test case generation, software debugging, and network security. However, such important information is often not available (e.g., most malware programs make use of secret protocols to communicate) or not directly usable by machines (e.g., many programs specify their inputs in plain text or other random formats). Furthermore, many programs claim they accept inputs with a published format, but their implementations actually support a subset or a variant. Based on the observations that input structure is manifested by the way input symbols are used during execution and most programs take input with top-down or bottom-up grammars, we devise two dynamic analyses, one for each grammar category. Our evaluation on a set of real-world programs shows that our technique is able to precisely reverse engineer input syntactic structure from execution. We apply our technique to hierarchical delta debugging (HDD) and network protocol reverse engineering. Our technique enables the complete automation of HDD, in which programmers were originally required to provide input grammars, and improves the runtime performance of HDD. Our client study on network protocol reverse engineering also shows that our technique supersedes existing techniques.",1939-3520,,10.1109/TSE.2009.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5210120,Input syntactic structure;reverse engineering;control dependence;grammar inference;delta debugging;top-down grammar;bottom-up grammar.,Reverse engineering;Application software;Protocols;Computer science;Software debugging;Information security;Runtime;XML;Software testing;Automation,data structures;grammars;program debugging;protocols;reverse engineering,program input syntactic structure;test case generation;software debugging;network security;bottom-up grammars;top-down grammars;hierarchical delta debugging;network protocol reverse engineering;HDD automation,,12.0,1.0,36.0,,21 Aug 2009,,,IEEE,IEEE Journals
857,858,Replicating and Re-Evaluating the Theory of Relative Defect-Proneness,M. D. Syer; M. Nagappan; B. Adams; A. E. Hassan,"School of Computing, Queen’s University, Kingston, ON, Canada; School of Computing, Queen’s University, Kingston, ON, Canada; Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Campus de l’Universite de Montreal; School of Computing, Queen’s University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,10 Feb 2015,2015,41,2,176,197,"A good understanding of the factors impacting defects in software systems is essential for software practitioners, because it helps them prioritize quality improvement efforts (e.g., testing and code reviews). Defect prediction models are typically built using classification or regression analysis on product and/or process metrics collected at a single point in time (e.g., a release date). However, current defect prediction models only predict if a defect will occur, but not when, which makes the prioritization of software quality improvements efforts difficult. To address this problem, Koru et al. applied survival analysis techniques to a large number of software systems to study how size (i.e., lines of code) influences the probability that a source code module (e.g., class or file) will experience a defect at any given time. Given that 1) the work of Koru et al. has been instrumental to our understanding of the size-defect relationship, 2) the use of survival analysis in the context of defect modelling has not been well studied and 3) replication studies are an important component of balanced scholarly debate, we present a replication study of the work by Koru et al. In particular, we present the details necessary to use survival analysis in the context of defect modelling (such details were missing from the original paper by Koru et al.). We also explore how differences between the traditional domains of survival analysis (i.e., medicine and epidemiology) and defect modelling impact our understanding of the size-defect relationship. Practitioners and researchers considering the use of survival analysis should be aware of the implications of our findings.",1939-3520,,10.1109/TSE.2014.2361131,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6914599,Survival Analysis;Cox Models;Defect Modelling;Survival analysis;Cox models;defect modelling,Analytical models;Hazards;Software;Measurement;Data models;Mathematical model;Predictive models,program diagnostics;software quality;software reliability,relative defect-proneness theory;survival analysis techniques;source code module;size-defect relationship;defect modelling;software system defects,,7.0,,47.0,,1 Oct 2014,,,IEEE,IEEE Journals
858,859,Evaluation and Measurement of Software Process Improvement—A Systematic Literature Review,M. Unterkalmsteiner; T. Gorschek; A. K. M. M. Islam; C. K. Cheng; R. B. Permadi; R. Feldt,"Blekinge Institute of Technology, Karlskrona; Blekinge Institute of Technology, Karlskrona; University of Kaiserslautern, Kaiserslautern; General Electrics Healthcare, Freiburg; Amadeus S.A.S, Sophia Antipolis; Blekinge Institute of Technology, Karlskrona",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,398,424,"BACKGROUND-Software Process Improvement (SPI) is a systematic approach to increase the efficiency and effectiveness of a software development organization and to enhance software products. OBJECTIVE-This paper aims to identify and characterize evaluation strategies and measurements used to assess the impact of different SPI initiatives. METHOD-The systematic literature review includes 148 papers published between 1991 and 2008. The selected papers were classified according to SPI initiative, applied evaluation strategies, and measurement perspectives. Potential confounding factors interfering with the evaluation of the improvement effort were assessed. RESULTS-Seven distinct evaluation strategies were identified, wherein the most common one, “Pre-Post Comparison,” was applied in 49 percent of the inspected papers. Quality was the most measured attribute (62 percent), followed by Cost (41 percent), and Schedule (18 percent). Looking at measurement perspectives, “Project” represents the majority with 66 percent. CONCLUSION-The evaluation validity of SPI initiatives is challenged by the scarce consideration of potential confounding factors, particularly given that “Pre-Post Comparison” was identified as the most common evaluation strategy, and the inaccurate descriptions of the evaluation context. Measurements to assess the short and mid-term impact of SPI initiatives prevail, whereas long-term measurements in terms of customer satisfaction and return on investment tend to be less used.",1939-3520,,10.1109/TSE.2011.26,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728832,Process implementation and change;process measurement;metrics/measurement;systematic literature review.,Software;Software measurement;Systematics;Current measurement;Data mining;Organizations,software process improvement,software process improvement;SPI;software development organization;customer satisfaction;return on investment,,117.0,,266.0,,10 Mar 2011,,,IEEE,IEEE Journals
859,860,Where Do Configuration Constraints Stem From? An Extraction Approach and an Empirical Study,S. Nadi; T. Berger; C. Kästner; K. Czarnecki,"Department of Computer Science, Technische Universität Darmstadt, Darmstadt, Hessen, Germany; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON; School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,820,841,"Highly configurable systems allow users to tailor software to specific needs. Valid combinations of configuration options are often restricted by intricate constraints. Describing options and constraints in a variability model allows reasoning about the supported configurations. To automate creating and verifying such models, we need to identify the origin of such constraints. We propose a static analysis approach, based on two rules, to extract configuration constraints from code. We apply it on four highly configurable systems to evaluate the accuracy of our approach and to determine which constraints are recoverable from the code. We find that our approach is highly accurate (93% and 77% respectively) and that we can recover 28% of existing constraints. We complement our approach with a qualitative study to identify constraint sources, triangulating results from our automatic extraction, manual inspections, and interviews with 27 developers. We find that, apart from low-level implementation dependencies, configuration constraints enforce correct runtime behavior, improve users' configuration experience, and prevent corner cases. While the majority of constraints is extractable from code, our results indicate that creating a complete model requires further substantial domain knowledge and testing. Our results aim at supporting researchers and practitioners working on variability model engineering, evolution, and verification techniques.",1939-3520,,10.1109/TSE.2015.2415793,NSERC; ARTEMIS JU; NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7065312,Variability models;Reverse-engineering;qualitative studies;Variability models;reverse-engineering;qualitative studies;static analyses;configuration constraints,Feature extraction;Kernel;Accuracy;Linux;Manuals;Interviews,configuration management;program diagnostics,configuration constraints;extraction approach;configuration combination;variability model;static analysis approach;configuration constraints extraction;constraint sources identification;variability model engineering;variability model evolution;variability model verification techniques,,31.0,,80.0,,23 Mar 2015,,,IEEE,IEEE Journals
860,861,HYDRA: Massively Compositional Model for Cross-Project Defect Prediction,X. Xia; D. Lo; S. J. Pan; N. Nagappan; X. Wang,"College of Computer Science and Technology, Zhejiang University Hangzhou, Zhejiang, China; School of Information Systems, Singapore Management University, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; Testing, Verification and Measurement Research, Microsoft Research, Redmond, WA; College of Computer Science and Technology, Zhejiang University Hangzhou, Zhejiang, China",IEEE Transactions on Software Engineering,13 Oct 2016,2016,42,10,977,998,"Most software defect prediction approaches are trained and applied on data from the same project. However, often a new project does not have enough training data. Cross-project defect prediction, which uses data from other projects to predict defects in a particular project, provides a new perspective to defect prediction. In this work, we propose a HYbrid moDel Reconstruction Approach (HYDRA) for cross-project defect prediction, which includes two phases: genetic algorithm (GA) phase and ensemble learning (EL) phase. These two phases create a massive composition of classifiers. To examine the benefits of HYDRA, we perform experiments on 29 datasets from the PROMISE repository which contains a total of 11,196 instances (i.e., Java classes) labeled as defective or clean. We experiment with logistic regression as the underlying classification algorithm of HYDRA. We compare our approach with the most recently proposed cross-project defect prediction approaches: TCA+ by Nam et al., Peters filter by Peters et al., GP by Liu et al., MO by Canfora et al., and CODEP by Panichella et al. Our results show that HYDRA achieves an average F1-score of 0.544. On average, across the 29 datasets, these results correspond to an improvement in the F1-scores of 26.22 , 34.99, 47.43, 28.61, and 30.14 percent over TCA+, Peters filter, GP, MO, and CODEP, respectively. In addition, HYDRA on average can discover 33 percent of all bugs if developers inspect the top 20 percent lines of code, which improves the best baseline approach (TCA+) by 44.41 percent. We also find that HYDRA improves the F1-score of Zero-R which predict all the instances to be defective by 5.42 percent, but improves Zero-R by 58.65 percent when inspecting the top 20 percent lines of code. In practice, Zero-R can be hard to use since it simply predicts all of the instances to be defective, and thus developers have to inspect all of the instances to find the defective ones. Moreover, we notice the improvement of HYDRA over other baseline approaches in terms of F1-score and when inspecting the top 20 percent lines of code are substantial, and in most cases the improvements are significant and have large effect sizes across the 29 datasets.",1939-3520,,10.1109/TSE.2016.2543218,National Basic Research Program of China; NSFC; National Key Technology R&D Program; Ministry of Science and Technology of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7435328,Cross-project defect prediction;transfer learning;genetic algorithm;ensemble learning,Genetic algorithms;Predictive models;Training;Buildings;Architecture;Data models;Measurement,genetic algorithms;learning (artificial intelligence);pattern classification;regression analysis;software fault tolerance,HYDRA model;massively compositional model;cross-project defect prediction;software defect prediction approach;hybrid model reconstruction approach;genetic algorithm phase;GA phase;phase and ensemble learning phase;EL phase;PROMISE repository;logistic regression;classification algorithm,,117.0,,58.0,,17 Mar 2016,,,IEEE,IEEE Journals
861,862,Data Mining Techniques for Software Effort Estimation: A Comparative Study,K. Dejaeger; W. Verbeke; D. Martens; B. Baesens,"Katholieke Universiteit Leuven, Leuven; Katholieke Universiteit Leuven, Leuven; University of Antwerp, Antwerp; Katholieke Universiteit Leuven, Leuven and University of Southampton, Highfield Southampton",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,375,397,"A predictive model is required to be accurate and comprehensible in order to inspire confidence in a business setting. Both aspects have been assessed in a software effort estimation setting by previous studies. However, no univocal conclusion as to which technique is the most suited has been reached. This study addresses this issue by reporting on the results of a large scale benchmarking study. Different types of techniques are under consideration, including techniques inducing tree/rule-based models like M5 and CART, linear models such as various types of linear regression, nonlinear models (MARS, multilayered perceptron neural networks, radial basis function networks, and least squares support vector machines), and estimation techniques that do not explicitly induce a model (e.g., a case-based reasoning approach). Furthermore, the aspect of feature subset selection by using a generic backward input selection wrapper is investigated. The results are subjected to rigorous statistical testing and indicate that ordinary least squares regression in combination with a logarithmic transformation performs best. Another key finding is that by selecting a subset of highly predictive attributes such as project size, development, and environment related attributes, typically a significant increase in estimation accuracy can be obtained.",1939-3520,,10.1109/TSE.2011.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928350,Data mining;software effort estimation;regression.,Software;Estimation;Data models;Data mining;Cognition;Artificial neural networks;Regression tree analysis,data mining;program testing;regression analysis;software cost estimation,data mining techniques;software effort estimation;predictive model;rule-based models;CART;M5;linear regression;nonlinear models;estimation techniques;feature subset selection;generic backward input selection wrapper;rigorous statistical testing;ordinary least squares regression;logarithmic transformation,,110.0,1.0,108.0,,23 Jun 2011,,,IEEE,IEEE Journals
862,863,Aspect-Oriented Race Detection in Java,E. Bodden; K. Havelund,"Technical University Darmstadt, Darmstadt; California Institute of Technology, Pasadena",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,509,527,"In the past, researchers have developed specialized programs to aid programmers in detecting concurrent programming errors such as deadlocks, livelocks, starvation, and data races. In this work, we propose a language extension to the aspect-oriented programming language AspectJ, in the form of three new pointcuts, lock(), unlock(), and maybeShared(). These pointcuts allow programmers to monitor program events where locks are granted or handed back, and where values are accessed that may be shared among multiple Java threads. We decide thread locality using a static thread-local-objects analysis developed by others. Using the three new primitive pointcuts, researchers can directly implement efficient monitoring algorithms to detect concurrent-programming errors online. As an example, we describe a new algorithm which we call RACER, an adaption of the well-known ERASER algorithm to the memory model of Java. We implemented the new pointcuts as an extension to the AspectBench Compiler, implemented the RACER algorithm using this language extension, and then applied the algorithm to the NASA K9 Rover Executive and two smaller programs. Our experiments demonstrate that our implementation is effective in finding subtle data races. In the Rover Executive, RACER finds 12 data races, with no false warnings. Only one of these races was previously known.",1939-3520,,10.1109/TSE.2010.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406531,Race detection;runtime verification;aspect-oriented programming;semantic pointcuts;static analysis.,Java;Programming profession;Computer languages;System recovery;Monitoring;Runtime;Protection;Instruments;Libraries,aspect-oriented programming;concurrency control;Java;multi-threading;program compilers;program debugging,aspect-oriented race detection;concurrent programming error detection;aspect-oriented programming language;AspectJ;multiple Java threads;static thread-local-objects analysis;ERASER algorithm;primitive pointcuts;AspectBench compiler;RACER algorithm;NASA K9 Rover Executive,,18.0,,52.0,,5 Feb 2010,,,IEEE,IEEE Journals
863,864,To Be Optimal or Not in Test-Case Prioritization,D. Hao; L. Zhang; L. Zang; Y. Wang; X. Wu; T. Xie,"Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, P. R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, Beijing, P. R. China; Department of Computer Science, University of Illinois at Urbana-Champaign",IEEE Transactions on Software Engineering,12 May 2016,2016,42,5,490,505,"Software testing aims to assure the quality of software under test. To improve the efficiency of software testing, especially regression testing, test-case prioritization is proposed to schedule the execution order of test cases in software testing. Among various test-case prioritization techniques, the simple additional coverage-based technique, which is a greedy strategy, achieves surprisingly competitive empirical results. To investigate how much difference there is between the order produced by the additional technique and the optimal order in terms of coverage, we conduct a study on various empirical properties of optimal coverage-based test-case prioritization. To enable us to achieve the optimal order in acceptable time for our object programs, we formulate optimal coverage-based test-case prioritization as an integer linear programming (ILP) problem. Then we conduct an empirical study for comparing the optimal technique with the simple additional coverage-based technique. From this empirical study, the optimal technique can only slightly outperform the additional coverage-based technique with no statistically significant difference in terms of coverage, and the latter significantly outperforms the former in terms of either fault detection or execution time. As the optimal technique schedules the execution order of test cases based on their structural coverage rather than detected faults, we further implement the ideal optimal test-case prioritization technique, which schedules the execution order of test cases based on their detected faults. Taking this ideal technique as the upper bound of test-case prioritization, we conduct another empirical study for comparing the optimal technique and the simple additional technique with this ideal technique. From this empirical study, both the optimal technique and the additional technique significantly outperform the ideal technique in terms of coverage, but the latter significantly outperforms the former two techniques in terms of fault detection. Our findings indicate that researchers may need take cautions in pursuing the optimal techniques in test-case prioritization with intermediate goals.",1939-3520,,10.1109/TSE.2015.2496939,National 973 Program of China; National Natural Science Foundation of China; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314957,Test-Case Prioritization;Integer Linear Programming;Greedy Algorithm;Empirical Study;Test-case prioritization;integer linear programming;greedy algorithm;empirical study,Software;Measurement;Schedules;Fault detection;Integer linear programming;Software testing,integer programming;linear programming;program testing,test-case prioritization techniques;software testing;software quality;regression testing;simple additional coverage-based technique;optimal coverage-based test-case prioritization;integer linear programming;ILP problem,,34.0,,47.0,,2 Nov 2015,,,IEEE,IEEE Journals
864,865,Domain-Specific Service Selection for Composite Services,O. Moser; F. Rosenberg; S. Dustdar,"Vienna University of Technology, Vienna; IBM T.J. Watson Research Center, Hawthorne; Vienna University of Technology, Vienna",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,828,843,"We propose a domain-specific service selection mechanism and system implementation to address the issue of runtime adaptation of composite services that implement mission-critical business processes. To this end, we leverage quality of service (QoS) as a means to specify rigid dependability requirements. QoS does not include only common attributes such as availability or response time but also attributes specific to certain business domains and processes. Therefore, we combine both domain-agnostic and domain-specific QoS attributes in an adaptive QoS model. For specifying the service selection strategy, we propose a domain-specific language called VieDASSL to specify so-called selectors. This language can be used to specify selector implementations based on the available QoS attributes. Both the QoS model implementation and the selectors can be adapted at runtime to deal with changing business and QoS requirements. Our approach is implemented on top of an existing WS-BPEL engine. We demonstrate its feasibility by implementing a case study from the telecommunication domain.",1939-3520,,10.1109/TSE.2011.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6231591,Service composition;quality of service;monitoring;service selection;domain specific languages,Quality of service;Runtime;Business;Adaptation models;Time factors;Availability;Engines,business data processing;quality of service;reliability;specification languages;Web services,domain-specific service selection mechanism;composite services;runtime adaptation;mission-critical business processes;quality of service;domain-agnostic QoS attributes;domain-specific QoS attributes;adaptive QoS model;domain-specific language;VieDASSL;selectors;business requirements;QoS requirements;WS-BPEL engine;telecommunication;Web services,,24.0,,56.0,,3 Jul 2012,,,IEEE,IEEE Journals
865,866,Bayesian Approaches to Matching Architectural Diagrams,D. Kimelman; M. Kimelman; D. Mandelin; D. Yellin,"IBM Thomas J. Watson Research Center, Yorktown Heights; Independent Consultant; Mozilla Corporation, Mountain View; IBM Israel Software Lab, Jerusalem",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,248,274,"IT system architectures and many other kinds of structured artifacts are often described by formal models or informal diagrams. In practice, there are often a number of versions of a model or diagram, such as a series of revisions, divergent variants, or multiple views of a system. Understanding how versions correspond or differ is crucial, and thus, automated assistance for matching models and diagrams is essential. We have designed a framework for finding these correspondences automatically based on Bayesian methods. We represent models and diagrams as graphs whose nodes have attributes such as name, type, connections to other nodes, and containment relations, and we have developed probabilistic models for rating the quality of candidate correspondences based on various features of the nodes in the graphs. Given the probabilistic models, we can find high-quality correspondences using search algorithms. Preliminary experiments focusing on architectural models suggest that the technique is promising.",1939-3520,,10.1109/TSE.2009.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232811,Bayesian techniques;IT system architecture;modeling tools;change control.,Bayesian methods;Context modeling;Large-scale systems;Network topology;Centralized control;Merging;Collaboration;Adaptation model;Application software;Security,Bayes methods;configuration management;graphs;probability;software architecture,Bayesian methods;formal models;informal diagrams;IT system architectures;divergent variants;graphs;probabilistic models;architectural diagram matching;search algorithms,,4.0,,37.0,,4 Sep 2009,,,IEEE,IEEE Journals
866,867,Rate-Based Queueing Simulation Model of Open Source Software Debugging Activities,C. Lin; Y. Li,"Department of Computer Science and Information Engineering, National Chiayi University, Chiayi, Taiwan; Laboratory of Industrial Engineering, Ecole Centrale Paris, Paris, France",IEEE Transactions on Software Engineering,10 Nov 2014,2014,40,11,1075,1099,"Open source software (OSS) approach has become increasingly prevalent for software development. As the widespread utilization of OSS, the reliability of OSS products becomes an important issue. By simulating the testing and debugging processes of software life cycle, the rate-based queueing simulation model has shown its feasibility for closed source software (CSS) reliability assessment. However, the debugging activities of OSS projects are different in many ways from those of CSS projects and thus the simulation approach needs to be calibrated for OSS projects. In this paper, we first characterize the debugging activities of OSS projects. Based on this, we propose a new rate-based queueing simulation framework for OSS reliability assessment including the model and the procedures. Then a decision model is developed to determine the optimal version-updating time with respect to two objectives: minimizing the time for version update, and maximizing OSS reliability. To illustrate the proposed framework, three real datasets from Apache and GNOME projects are used. The empirical results indicate that our framework is able to effectively approximate the real scenarios. Moreover, the influences of the core contributor staffing levels are analyzed and the optimal version-updating times are obtained.",1939-3520,,10.1109/TSE.2014.2354032,National Science Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6891380,Queueing theory;rate-based simulation;open source software (OSS);bug reporting;report judgment;bug fixing;optimal version-updating time;non-homogeneous continuous time Markov chain (NHCTMC);multi-attribute utility theory (MAUT),Software reliability;Debugging;Software;Stochastic processes;Analytical models;Cascading style sheets,configuration management;program debugging;program testing;project management;public domain software;queueing theory;software reliability,open source software;OSS approach;software development;OSS products reliability;testing processes;debugging processes;software life cycle;rate-based queueing simulation model;closed source software;CSS reliability assessment;debugging activities;OSS projects;decision model;optimal version-updating time,,14.0,,50.0,,4 Sep 2014,,,IEEE,IEEE Journals
867,868,Random Testing: Theoretical Results and Practical Implications,A. Arcuri; M. Z. Iqbal; L. Briand,"Simula, Oslo; Simula Research Laboratory, Lysaker; Simula Research Laboratory, Lysaker",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,258,277,"A substantial amount of work has shed light on whether random testing is actually a useful testing technique. Despite its simplicity, several successful real-world applications have been reported in the literature. Although it is not going to solve all possible testing problems, random testing appears to be an essential tool in the hands of software testers. In this paper, we review and analyze the debate about random testing. Its benefits and drawbacks are discussed. Novel results addressing general questions about random testing are also presented, such as how long does random testing need, on average, to achieve testing targets (e.g., coverage), how does it scale, and how likely is it to yield similar results if we rerun it on the same testing problem (predictability). Due to its simplicity that makes the mathematical analysis of random testing tractable, we provide precise and rigorous answers to these questions. Results show that there are practical situations in which random testing is a viable option. Our theorems are backed up by simulations and we show how they can be applied to most types of software and testing criteria. In light of these results, we then assess the validity of empirical analyzes reported in the literature and derive guidelines for both practitioners and scientists.",1939-3520,,10.1109/TSE.2011.121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6104067,Coupon collector;random testing;theory;Schur function;predictability;partition testing;adaptive random testing.,Testing;Software;Upper bound;Color;Random variables;Algorithm design and analysis;Generators,program testing;software tools,random testing;software testing;software tool;mathematical analysis;partition testing,,76.0,,52.0,,13 Dec 2011,,,IEEE,IEEE Journals
868,869,Linear and Branching System Metrics,L. de Alfaro; M. Faella; M. Stoelinga,"University of California, Santa Cruz, Santa Cruz; Università di Napoli, Napoli; University of Twente, Enschede",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,258,273,"We extend the classical system relations of trace inclusion, trace equivalence, simulation, and bisimulation to a quantitative setting in which propositions are interpreted not as boolean values, but as elements of arbitrary metric spaces. Trace inclusion and equivalence give rise to asymmetrical and symmetrical linear distances, while simulation and bisimulation give rise to asymmetrical and symmetrical branching distances. We study the relationships among these distances and we provide a full logical characterization of the distances in terms of quantitative versions of LTL and mu-calculus. We show that, while trace inclusion (respectively, equivalence) coincides with simulation (respectively, bisimulation) for deterministic boolean transition systems, linear and branching distances do not coincide for deterministic metric transition systems. Finally, we provide algorithms for computing the distances over finite systems, together with a matching lower complexity bound.",1939-3520,,10.1109/TSE.2008.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721438,Logics of programs;Specification techniques;Modal logic,Logic;Extraterrestrial measurements;Cost accounting;Computational modeling;Reasoning about programs;Formal languages;Software tools;Digital audio players;Clocks;Automata,Boolean functions;formal specification;process algebra;program diagnostics;program verification;software metrics;temporal logic,linear system metrics;branching system metric;software trace inclusion;software trace equivalence;software bisimulation;LTL;mu-calculus;deterministic Boolean transition system;software verification;linear temporal logic property;system specification,,59.0,,18.0,,22 Dec 2008,,,IEEE,IEEE Journals
869,870,Reducing Masking Effects in CombinatorialInteraction Testing: A Feedback DrivenAdaptive Approach,C. Yilmaz; E. Dumlu; M. B. Cohen; A. Porter,"Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Borsa Istanbul, Istanbul, Turkey; Department of Computer Science and Engineering, University of Nebraska-Lincoln, NE; Department of Computer Science , University of Maryland, College Park, MD",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,1,43,66,"The configuration spaces of modern software systems are too large to test exhaustively. Combinatorial interaction testing (CIT) approaches, such as covering arrays, systematically sample the configuration space and test only the selected configurations. The basic justification for CIT approaches is that they can cost-effectively exercise all system behaviors caused by the settings of t or fewer options. We conjecture, however, that in practice some of these behaviors are not actually tested because of unanticipated masking effects - test case failures that perturb system execution so as to prevent some behaviors from being exercised. While prior research has identified this problem, most solutions require knowing the masking effects a priori. In practice this is impractical, if not impossible. In this work, we reduce the harmful consequences of masking effects. First we define a novel interaction testing criterion, which aims to ensure that each test case has a fair chance to test all valid t-way combinations of option settings. We then introduce a feedback driven adaptive combinatorial testing process (FDA-CIT) to materialize this criterion in practice. At each iteration of FDA-CIT, we detect potential masking effects, heuristically isolate their likely causes (i.e., fault characterization), and then generate new samples that allow previously masked combinations to be tested in configurations that avoid the likely failure causes. The iterations end when the new interaction testing criterion has been satisfied. This paper compares two different fault characterization approaches - an integral part of the proposed approach, and empirically assesses their effectiveness and efficiency in removing masking effects on two widely used open source software systems. It also compares FDA-CIT against error locating arrays, a state of the art approach for detecting and locating failures. Furthermore, the scalability of the proposed approach is evaluated by comparing it with perfect test scenarios, in which all masking effects are known a priori. Our results suggest that masking effects do exist in practice, and that our approach provides a promising and efficient way to work around them, without requiring that masking effects be known a priori.",1939-3520,,10.1109/TSE.2013.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6654147,Combinatorial testing;adaptive testing;covering arrays;software quality assurance,Testing;Adaptive arrays;Educational institutions;Scalability;Servers;Electronic mail;Software systems,program testing;public domain software;software fault tolerance,perfect test scenarios;fault location;fault detection;error locating arrays;open source software systems;fault characterization approaches;potential masking effects detection;t-way combinations;FDA-CIT process;interaction testing criterion;system execution;test case failures;covering arrays;software systems;configuration spaces;feedback driven adaptive approach;CIT approach;combinatorial interaction testing;masking effects reduction,,26.0,,44.0,,4 Nov 2013,,,IEEE,IEEE Journals
870,871,Automatic Contract Insertion with CCBot,S. A. Carr; F. Logozzo; M. Payer,"Purdue University, West Lafayette, IN; FaceBook, Seattle, WA; Purdue University, West Lafayette, IN",IEEE Transactions on Software Engineering,11 Aug 2017,2017,43,8,701,714,"Existing static analysis tools require significant programmer effort. On large code bases, static analysis tools produce thousands of warnings. It is unrealistic to expect users to review such a massive list and to manually make changes for each warning. To address this issue we propose CCBot (short for CodeContracts Bot), a new tool that applies the results of static analysis to existing code through automatic code transformation. Specifically, CCBot instruments the code with method preconditions, postconditions, and object invariants which detect faults at runtime or statically using a static contract checker. The only configuration the programmer needs to perform is to give CCBot the file paths to code she wants instrumented. This allows the programmer to adopt contract-based static analysis with little effort. CCBot's instrumented version of the code is guaranteed to compile if the original code did. This guarantee means the programmer can deploy or test the instrumented code immediately without additional manual effort. The inserted contracts can detect common errors such as null pointer dereferences and out-of-bounds array accesses. CCBot is a robust large-scale tool with an open-source C# implementation. We have tested it on real world projects with tens of thousands of lines of code. We discuss several projects as case studies, highlighting undiscovered bugs found by CCBot, including 22 new contracts that were accepted by the project authors.",1939-3520,,10.1109/TSE.2016.2625248,NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7736073,Contract-based verification;automated patching;assertions;class invariants,Contracts;C# languages;Instruments;Computer bugs;Reactive power;Semantics;Runtime,C# language;program compilers;program diagnostics;program verification;software fault tolerance,automatic contract insertion;CCBot;static analysis tools;CodeContracts Bot;automatic code transformation;object invariants;fault detection;static contract checker;file paths;contract-based static analysis;null pointer dereferences;out-of-bounds array accesses;open-source C# implementation;contract-based verification,,2.0,,43.0,,4 Nov 2016,,,IEEE,IEEE Journals
871,872,Exception Handling for Repair in Service-Based Processes,G. Friedrich; M. G. Fugini; E. Mussi; B. Pernici; G. Tagni,"Alpen-Adria Universität Klagenfurt, Kalgenfurt; Politecnico di Milano, Milano; Politecnico di Milano, Milano; Politecnico di Milano, Milano; Vrije Universiteit Amsterdam, Amsterdam",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,198,215,"This paper proposes a self-healing approach to handle exceptions in service-based processes and to repair the faulty activities with a model-based approach. In particular, a set of repair actions is defined in the process model, and repairability of the process is assessed by analyzing the process structure and the available repair actions. During execution, when an exception arises, repair plans are generated by taking into account constraints posed by the process structure, dependencies among data, and available repair actions. The paper also describes the main features of the prototype developed to validate the proposed repair approach for composed Web services; the self-healing architecture for repair handling and the experimental results are illustrated.",1939-3520,,10.1109/TSE.2010.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383376,Exception handling;failures;faults;repair;self-healing processes;Web services;process management.,Web services;Prototypes;Service oriented architecture;Logic design;Proposals,exception handling;program verification;software fault tolerance;software maintenance;software prototyping;Web services,exception handling;service based process repairing;Web services;self-healing architecture;process structure analysis;prototype development,,73.0,,60.0,,15 Jan 2010,,,IEEE,IEEE Journals
872,873,Enforcing Exception Handling Policies with a Domain-Specific Language,E. A. Barbosa; A. Garcia; M. P. Robillard; B. Jakobus,"OPUS Research Group, Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rua Marquês de São Vicente, 255-Gávea, Rio de Janeiro, Brazil; OPUS Research Group, Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rua Marquês de São Vicente, 255-Gávea, Rio de Janeiro, Brazil; School of Computer Science, McGill University, Montreal, Canada; OPUS Research Group, Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rua Marquês de São Vicente, 255-Gávea, Rio de Janeiro, Brazil",IEEE Transactions on Software Engineering,10 Jun 2016,2016,42,6,559,584,"Current software projects deal with exceptions in implementation and maintenance phases without a clear definition of exception handling policies. We call an exception handling policy the set of design decisions that govern the use of exceptions in a software project. Without an explicit exception handling policy, developers can remain unaware of the originally intended use of exceptions. In this paper, we present Exception Handling Policies Language (EPL), a domain-specific language to specify and verify exception handling policies. The evaluation of EPL was based on a user-centric observational study and case studies. The user-centric study was performed to observe how potential users of the language actually use it. With this study, we could better understand the trade-offs related to different language design decisions based on concrete and well-documented observations and experiences reported by participants. We identified some language characteristics that hindered its use and that motivated new language constructs. In addition, we performed case studies with one open-source project and two industry-strength systems to investigate how specifying and verifying exception handling policies may assist in detecting exception handling problems. The results show that violations of exception handling policies help to indicate potential faults in the exception handling code.",1939-3520,,10.1109/TSE.2015.2506164,Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro (FAPERJ); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7348692,Exception handling;Exception handling policy;Policy specification;Domain-specific language;Exception handling;exception handling policy;policy specification;domain-specific language,Java;Software reliability;Robustness;Software systems,exception handling;formal specification;formal verification;programming languages;project management;public domain software;software maintenance,industry-strength systems;open-source project;user-centric study;exception handling policy verification;exception handling policy specification;EPL evaluation;language design decisions;maintenance phase;implementation phase;software projects;domain-specific language;exception handling policies language,,8.0,,46.0,,7 Dec 2015,,,IEEE,IEEE Journals
873,874,Automatic Source Code Summarization of Context for Java Methods,P. W. McBurney; C. McMillan,"College of Computer Science and Engineering, University Notre Dame, Notre Dame, IN; Computer Science, University of Notre Dame, South Bend, VA",IEEE Transactions on Software Engineering,11 Feb 2016,2016,42,2,103,119,"Source code summarization is the task of creating readable summaries that describe the functionality of software. Source code summarization is a critical component of documentation generation, for example as Javadocs formed from short paragraphs attached to each method in a Java program. At present, a majority of source code summarization is manual, in that the paragraphs are written by human experts. However, new automated technologies are becoming feasible. These automated techniques have been shown to be effective in select situations, though a key weakness is that they do not explain the source code's context. That is, they can describe the behavior of a Java method, but not why the method exists or what role it plays in the software. In this paper, we propose a source code summarization technique that writes English descriptions of Java methods by analyzing how those methods are invoked. We then performed two user studies to evaluate our approach. First, we compared our generated summaries to summaries written manually by experts. Then, we compared our summaries to summaries written by a state-of-the-art automatic summarization tool. We found that while our approach does not reach the quality of human-written summaries, we do improve over the state-of-the-art summarization tool in several dimensions by a statistically-significant margin.",1939-3520,,10.1109/TSE.2015.2465386,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7181703,Source code summarization;automatic documentation;program comprehension;Source code summarization;automatic documentation;program comprehension,Context;Documentation;Java;Natural languages;Software;Generators;XML,Java;object-oriented methods,source code summarization technique;Java methods;software functionality;documentation generation;Javadocs;Java program;user studies;automatic summarization tool;human-written summaries,,46.0,,51.0,,6 Aug 2015,,,IEEE,IEEE Journals
874,875,Fault Localization for Dynamic Web Applications,S. Artzi; J. Dolby; F. Tip; M. Pistoia,"IBM Software Group, Littleton; IBM Thomas J. Watson Research Center, Yorktown Heights; IBM Thomas J. Watson Research Center, Yorktown Heights; IBM Thomas J. Watson Research Center, Yorktown Heights",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,314,335,"In recent years, there has been significant interest in fault-localization techniques that are based on statistical analysis of program constructs executed by passing and failing executions. This paper shows how the Tarantula, Ochiai, and Jaccard fault-localization algorithms can be enhanced to localize faults effectively in web applications written in PHP by using an extended domain for conditional and function-call statements and by using a source mapping. We also propose several novel test-generation strategies that are geared toward producing test suites that have maximal fault-localization effectiveness. We implemented various fault-localization techniques and test-generation strategies in Apollo, and evaluated them on several open-source PHP applications. Our results indicate that a variant of the Ochiai algorithm that includes all our enhancements localizes 87.8 percent of all faults to within 1 percent of all executed statements, compared to only 37.4 percent for the unenhanced Ochiai algorithm. We also found that all the test-generation strategies that we considered are capable of generating test suites with maximal fault-localization effectiveness when given an infinite time budget for test generation. However, on average, a directed strategy based on path-constraint similarity achieves this maximal effectiveness after generating only 6.5 tests, compared to 46.8 tests for an undirected test-generation strategy.",1939-3520,,10.1109/TSE.2011.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5975173,Fault localization;statistical debugging;program analysis;web applications;PHP.,HTML;Databases;Servers;Open source software;Browsers;Algorithm design and analysis;Concrete,program testing;software fault tolerance;statistical analysis,fault localization;dynamic Web applications;statistical analysis;source mapping;fault localization effectiveness;test generation strategies;path constraint;Tarantula;Ochiai;Jaccard;Apollo;open-source PHP applications,,15.0,,50.0,,4 Aug 2011,,,IEEE,IEEE Journals
875,876,An Empirical Comparison of Model Validation Techniques for Defect Prediction Models,C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto,"Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan; Department of Electrical and Computer Engineering, Montreal, QC, McGill UniversityCanada; School of Computing, Queen’s University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan",IEEE Transactions on Software Engineering,9 Jan 2017,2017,43,1,1,18,"Defect prediction models help software quality assurance teams to allocate their limited resources to the most defect-prone modules. Model validation techniques, such as $k$ -fold cross-validation, use historical data to estimate how well a model will perform in the future. However, little is known about how accurate the estimates of model validation techniques tend to be. In this paper, we investigate the bias and variance of model validation techniques in the domain of defect prediction. Analysis of 101 public defect datasets suggests that 77 percent of them are highly susceptible to producing unstable results– - selecting an appropriate model validation technique is a critical experimental design choice. Based on an analysis of 256 studies in the defect prediction literature, we select the 12 most commonly adopted model validation techniques for evaluation. Through a case study of 18 systems, we find that single-repetition holdout validation tends to produce estimates with 46-229 percent more bias and 53-863 percent more variance than the top-ranked model validation techniques. On the other hand, out-of-sample bootstrap validation yields the best balance between the bias and variance of estimates in the context of our study. Therefore, we recommend that future defect prediction studies avoid single-repetition holdout validation, and instead, use out-of-sample bootstrap validation.",1939-3520,,10.1109/TSE.2016.2584050,JSPS; Advancing Strategic International Networks to Accelerate the Circulation of Talented Researchers; Interdisciplinary Global Networks for Accelerating Theory and Practice in Software Ecosystem; JSPS Fellows; Natural Sciences and Engineering Research Council of Canada (NSERC); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7497471,Defect prediction models;model validation techniques;bootstrap validation;cross validation;holdout validation,Predictive models;Data models;Analytical models;Context;Context modeling;Software;Logistics,,,,150.0,,122.0,,22 Jun 2016,,,IEEE,IEEE Journals
876,877,Self-Management of Adaptable Component-Based Applications,L. Rosa; L. Rodrigues; A. Lopes; M. Hiltunen; R. Schlichting,"INESC-ID and Universidade Técnica de Lisboa, Lisboa; INESC-ID and Universidade Técnica de Lisboa, Lisboa; University of Lisbon, Lisbon; AT&T Labs-Research, Florham Park; AT&T Labs Research, Florham Park",IEEE Transactions on Software Engineering,25 Feb 2013,2013,39,3,403,421,"The problem of self-optimization and adaptation in the context of customizable systems is becoming increasingly important with the emergence of complex software systems and unpredictable execution environments. Here, a general framework for automatically deciding on when and how to adapt a system whenever it deviates from the desired behavior is presented. In this framework, the system's target behavior is described as a high-level policy that establishes goals for a set of performance indicators. The decision process is based on information provided independently for each component that describes the available adaptations, their impact on performance indicators, and any limitations or requirements. The technique consists of both offline and online phases. Offline, rules are generated specifying component adaptations that may help to achieve the established goals when a given change in the execution context occurs. Online, the corresponding rules are evaluated when a change occurs to choose which adaptations to perform. Experimental results using a prototype framework in the context of a web-based application demonstrate the effectiveness of this approach.",1939-3520,,10.1109/TSE.2012.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6197201,Adaptive systems;self-management;autonomic computing;goal policies,Runtime;Context;Software systems;Optimization;Catalogs,fault tolerant computing;optimisation,adaptable component based applications;customizable systems;complex software systems;unpredictable execution environments;desired behavior;target behavior;performance indicators;decision process;Web based application;autonomic computing,,21.0,,28.0,,8 May 2012,,,IEEE,IEEE Journals
877,878,A Taxonomy and Qualitative Comparison of Program Analysis Techniques for Security Assessment of Android Software,A. Sadeghi; H. Bagheri; J. Garcia; S. Malek,"School of Information and Computer Sciences, University of California, Irvine, CA; Department of Computer Science and Engineering, University of Nebraska, Lincoln, NE; School of Information and Computer Sciences, University of California, Irvine, CA; School of Information and Computer Sciences, University of California, Irvine, CA",IEEE Transactions on Software Engineering,13 Jun 2017,2017,43,6,492,530,"In parallel with the meteoric rise of mobile software, we are witnessing an alarming escalation in the number and sophistication of the security threats targeted at mobile platforms, particularly Android, as the dominant platform. While existing research has made significant progress towards detection and mitigation of Android security, gaps and challenges remain. This paper contributes a comprehensive taxonomy to classify and characterize the state-of-the-art research in this area. We have carefully followed the systematic literature review process, and analyzed the results of more than 300 research papers, resulting in the most comprehensive and elaborate investigation of the literature in this area of research. The systematic analysis of the research literature has revealed patterns, trends, and gaps in the existing literature, and underlined key challenges and opportunities that will shape the focus of future research efforts.",1939-3520,,10.1109/TSE.2016.2615307,National Science Foundation; Defense Advanced Research Projects Agency; Army Research Office; Department of Homeland Security; Air Force Office of Scientific Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583740,Taxonomy and survey;security assessment;android platform;program analysis,Androids;Humanoid robots;Security;Taxonomy;Mobile communication;Malware;Systematics,Android (operating system);mobile computing;program diagnostics;security of data,taxonomy;program analysis;security assessment;Android software;mobile software;security threats;mobile platforms;dominant platform;Android security,,51.0,,517.0,,5 Oct 2016,,,IEEE,IEEE Journals
878,879,A Systematic Review of the Application and Empirical Investigation of Search-Based Test Case Generation,S. Ali; L. C. Briand; H. Hemmati; R. K. Panesar-Walawege,"Simula Research Laboratory, Lysaker and University of Oslo, Norway; Simula Research Laboratory, Lysaker and University of Oslo, Norway; Simula Research Laboratory, Lysaker and University of Oslo, Norway; Simula Research Laboratory, Lysaker and University of Oslo, Norway",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,742,762,"Metaheuristic search techniques have been extensively used to automate the process of generating test cases, and thus providing solutions for a more cost-effective testing process. This approach to test automation, often coined “Search-based Software Testing” (SBST), has been used for a wide variety of test case generation purposes. Since SBST techniques are heuristic by nature, they must be empirically investigated in terms of how costly and effective they are at reaching their test objectives and whether they scale up to realistic development artifacts. However, approaches to empirically study SBST techniques have shown wide variation in the literature. This paper presents the results of a systematic, comprehensive review that aims at characterizing how empirical studies have been designed to investigate SBST cost-effectiveness and what empirical evidence is available in the literature regarding SBST cost-effectiveness and scalability. We also provide a framework that drives the data collection process of this systematic review and can be the starting point of guidelines on how SBST techniques can be empirically assessed. The intent is to aid future researchers doing empirical studies in SBST by providing an unbiased view of the body of empirical evidence and by guiding them in performing well-designed and executed empirical studies.",1939-3520,,10.1109/TSE.2009.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5210118,Evolutionary computing and genetic algorithms;frameworks;heuristics design;review and evaluation;test generation;testing strategies;validation.,System testing;Automatic testing;Software testing;Automation;Costs;Logic testing;Scalability;Guidelines;Genetic algorithms;Algorithm design and analysis,program testing;search problems,search based test case generation;metaheuristic search technique;cost effective testing process;test automation;search based software testing,,215.0,,55.0,,21 Aug 2009,,,IEEE,IEEE Journals
879,880,Name-Based Analysis of Equally Typed Method Arguments,M. Pradel; T. R. Gross,"ETH Zurich, Zurich; ETH Zurich, Zurich",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1127,1143,"When calling a method that requires multiple arguments, programmers must pass the arguments in the expected order. For statically typed languages, the compiler helps programmers by checking that the type of each argument matches the type of the formal parameter. Unfortunately, types are futile for methods with multiple parameters of the same type. How can a programmer check that equally typed arguments are passed in the correct order? This paper presents two simple, yet effective, static program analyses that detect problems related to the order of equally typed arguments. The key idea is to leverage identifier names to infer the semantics of arguments and their intended positions. The analyses reveal problems that affect the correctness, understandability, and maintainability of a program, such as accidentally reversed arguments and misleading parameter names. Most parts of the analyses are language-agnostic. We evaluate the approach with 24 real-world programs written in Java and C. Our results show the analyses to be effective and efficient. One analysis reveals anomalies in the order of equally typed arguments; it finds 54 relevant problems with a precision of 82 percent. The other analysis warns about misleading parameter names and finds 31 naming bugs with a precision of 39 percent.",1939-3520,,10.1109/TSE.2013.7,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6419711,Testing and debugging;maintenance;documentation;static program analysis;anomaly detection;method arguments,Java;Access control;Engines;Feature extraction;Context;Robustness;Program processors,C language;Java;program diagnostics,name-based analysis;equally typed method argument;statically typed language;formal parameter;static program analysis;program correctness;program understandability;program maintainability;Java language;C language,,9.0,,40.0,,24 Jan 2013,,,IEEE,IEEE Journals
880,881,Invariant-Based Automatic Testing of Modern Web Applications,A. Mesbah; A. van Deursen; D. Roest,"University of British Columbia, Vancouver; Delft University of Technology, Delft; Delft University of Technology, Delft",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,35,53,"Ajax-based Web 2.0 applications rely on stateful asynchronous client/server communication, and client-side runtime manipulation of the DOM tree. This not only makes them fundamentally different from traditional web applications, but also more error-prone and harder to test. We propose a method for testing Ajax applications automatically, based on a crawler to infer a state-flow graph for all (client-side) user interface states. We identify Ajax-specific faults that can occur in such states (related to, e.g., DOM validity, error messages, discoverability, back-button compatibility) as well as DOM-tree invariants that can serve as oracles to detect such faults. Our approach, called Atusa, is implemented in a tool offering generic invariant checking components, a plugin-mechanism to add application-specific state validators, and generation of a test suite covering the paths obtained during crawling. We describe three case studies, consisting of six subjects, evaluating the type of invariants that can be obtained for Ajax applications as well as the fault revealing capabilities, scalability, required manual effort, and level of automation of our testing approach.",1939-3520,,10.1109/TSE.2011.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728834,Automated testing;web applications;Ajax.,Web and internet services;Browsers;User interfaces;Robots;Servers,automatic testing;client-server systems;Internet;Java;program testing;trees (mathematics);user interfaces;XML,invariant-based automatic testing;AJAX-based Web 2.0 application;stateful asynchronous client-server communication;client-side runtime manipulation;state-flow graph;user interface;AJAX-specific fault identification;DOM-tree invariant;fault detection;generic invariant checking component;application-specific state validator;fault revealing capability,,70.0,1.0,40.0,,10 Mar 2011,,,IEEE,IEEE Journals
881,882,Trustrace: Mining Software Repositories to Improve the Accuracy of Requirement Traceability Links,N. Ali; Y. Guéhéneuc; G. Antoniol,"École Polytechnique de Montréal, Montréal; École Polytechnique de Montréal, Montréal; École Polytechnique de Montréal, Montréal",IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,725,741,"Traceability is the only means to ensure that the source code of a system is consistent with its requirements and that all and only the specified requirements have been implemented by developers. During software maintenance and evolution, requirement traceability links become obsolete because developers do not/cannot devote effort to updating them. Yet, recovering these traceability links later is a daunting and costly task for developers. Consequently, the literature has proposed methods, techniques, and tools to recover these traceability links semi-automatically or automatically. Among the proposed techniques, the literature showed that information retrieval (IR) techniques can automatically recover traceability links between free-text requirements and source code. However, IR techniques lack accuracy (precision and recall). In this paper, we show that mining software repositories and combining mined results with IR techniques can improve the accuracy (precision and recall) of IR techniques and we propose Trustrace, a trust--based traceability recovery approach. We apply Trustrace on four medium-size open-source systems to compare the accuracy of its traceability links with those recovered using state-of-the-art IR techniques from the literature, based on the Vector Space Model and Jensen-Shannon model. The results of Trustrace are up to 22.7 percent more precise and have 7.66 percent better recall values than those of the other techniques, on average. We thus show that mining software repositories and combining the mined data with existing results from IR techniques improves the precision and recall of requirement traceability links.",1939-3520,,10.1109/TSE.2012.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6341764,Traceability;requirements;feature;source code;repositories;experts;trust-based model,Accuracy;Data mining;Software maintenance;Information retrieval;Open source software;Principal component analysis,data mining;data privacy;information retrieval;software maintenance,software repository mining;requirement traceability link;traceability method;software maintenance;software evolution;information retrieval technique;IR technique;precision accuracy;recall accuracy;Trustrace approach;trust-based traceability recovery approach;medium-size open-source system;vector space model;Jensen-Shannon model,,45.0,,41.0,,10 Nov 2012,,,IEEE,IEEE Journals
882,883,Proactive and Reactive Runtime Service Discovery: A Framework and Its Evaluation,A. Zisman; G. Spanoudakis; J. Dooley; I. Siveroni,"City University London, London; City University London, London; University of Essex, Colchester; City University London, London",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,954,974,"The identification of services during the execution of service-based applications to replace services in them that are no longer available and/or fail to satisfy certain requirements is an important issue. In this paper, we present a framework to support runtime service discovery. This framework can execute service discovery queries in pull and push mode. In pull mode, it executes queries when a need for finding a replacement service arises. In push mode, queries are subscribed to the framework to be executed proactively and, in parallel with the operation of the application, to identify adequate services that could be used if the need for replacing a service arises. Hence, the proactive (push) mode of query execution makes it more likely to avoid interruptions in the operation of service-based applications when a service in them needs to be replaced at runtime. In both modes of query execution, the identification of services relies on distance-based matching of structural, behavioral, quality, and contextual characteristics of services and applications. A prototype implementation of the framework has been developed and an evaluation was carried out to assess the performance of the framework. This evaluation has shown positive results, which are discussed in the paper.",1939-3520,,10.1109/TSE.2012.84,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6375710,Web-services discovery;composite web services;context-aware QoS model;application development in services,Runtime;Context;Servers;Educational institutions;Database languages;Unified modeling language;Informatics,quality of service;query processing;software quality;ubiquitous computing;Web services,proactive runtime service discovery;reactive runtime service discovery;service identification;service-based applications;service discovery queries execution;pull mode;push mode;replacement service;distance-based matching;structural characteristics;behavioral characteristics;quality characteristics;contextual characteristics;composite Web-services discovery;context-aware QoS model,,23.0,,62.0,,10 Dec 2012,,,IEEE,IEEE Journals
883,884,Whitening SOA Testing via Event Exposure,C. Ye; H. Jacobsen,"University of Toronto, Toronto; University of Toronto, Toronto",IEEE Transactions on Software Engineering,25 Sep 2013,2013,39,10,1444,1465,"Whitening the testing of service-oriented applications can provide service consumers confidence on how well an application has been tested. However, to protect business interests of service providers and to prevent information leakage, the implementation details of services are usually invisible to service consumers. This makes it challenging to determine the test coverage of a service composition as a whole and design test cases effectively. To address this problem, we propose an approach to whiten the testing of service compositions based on events exposed by services. By deriving event interfaces to explore only necessary test coverage information from service implementations, our approach allows service consumers to determine test coverage based on selected events exposed by services at runtime without releasing the service implementation details. We also develop an approach to design test cases effectively based on event interfaces concerning both effectiveness and information leakage. The experimental results show that our approach outperforms existing testing approaches for service compositions with up to 49 percent more test coverage and an up to 24 percent higher fault-detection rate. Moreover, our solution can trade off effectiveness, efficiency, and information leakage for test case generation.",1939-3520,,10.1109/TSE.2013.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6495456,Web service composition;white-box testing;event interface;events,Testing;Service-oriented architecture;Books;Runtime;Catalogs;Jacobian matrices,program testing;service-oriented architecture;Web services,SOA testing whitening;service-oriented architecture;event exposure;service consumers;service providers;service composition;test coverage;test case design approach;fault-detection rate;test case generation;information leakage;Web services,,22.0,,84.0,,8 Apr 2013,,,IEEE,IEEE Journals
884,885,A Semi-Automatic Approach for Extracting Software Product Lines,M. T. Valente; V. Borges; L. Passos,"University of Minas Gerais, Belo Horizonte; COTEMIG, Brazil; University of Waterloo, Waterloo",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,737,754,"The extraction of nontrivial software product lines (SPL) from a legacy application is a time-consuming task. First, developers must identify the components responsible for the implementation of each program feature. Next, they must locate the lines of code that reference the components discovered in the previous step. Finally, they must extract those lines to independent modules or annotate them in some way. To speed up product line extraction, this paper describes a semi-automatic approach to annotate the code of optional features in SPLs. The proposed approach is based on an existing tool for product line development, called CIDE, that enhances standard IDEs with the ability to associate background colors with the lines of code that implement a feature. We have evaluated and successfully applied our approach to the extraction of optional features from three nontrivial systems: Prevayler (an in-memory database system), JFreeChart (a chart library), and ArgoUML (a UML modeling tool).",1939-3520,,10.1109/TSE.2011.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928352,Software product lines;virtual separation of concerns;refactoring tools;annotations,Feature extraction;Color;Image color analysis;Multithreading;Semantics;Software;Context,feature extraction;product development;software maintenance;software reusability;Unified Modeling Language,semiautomatic approach;software product lines extraction;SPL;legacy application;program feature;code lines localization;optional feature code annotation;product line development;CIDE;background colors;optional feature extraction;Prevayler nontrivial systems;JFreeChart nontrivial systems;ArgoUML nontrivial systems,,13.0,,46.0,,23 Jun 2011,,,IEEE,IEEE Journals
885,886,Systematic Elaboration of Scalability Requirements through Goal-Obstacle Analysis,L. Duboc; E. Letier; D. S. Rosenblum,"State University of Rio de Janeiro, Rio de Janeiro; University College London, London; National University of Singapore, Singapore",IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,119,140,"Scalability is a critical concern for many software systems. Despite the recognized importance of considering scalability from the earliest stages of development, there is currently little support for reasoning about scalability at the requirements level. This paper presents a goal-oriented approach for eliciting, modeling, and reasoning about scalability requirements. The approach consists of systematically identifying scalability-related obstacles to the satisfaction of goals, assessing the likelihood and severity of these obstacles, and generating new goals to deal with them. The result is a consolidated set of requirements in which important scalability concerns are anticipated through the precise, quantified specification of scaling assumptions and scalability goals. The paper presents results from applying the approach to a complex, large-scale financial fraud detection system.",1939-3520,,10.1109/TSE.2012.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6152130,Requirements/specifications;analysis;performance measures;quality analysis and evaluation;goal-oriented requirements engineering;KAOS;scalability,Scalability;Software;Batch production systems;Educational institutions;Analytical models;Natural languages,financial data processing;fraud;large-scale systems;reasoning about programs;systems analysis,systematic elaboration;goal-obstacle analysis;software systems;reasoning about scalability;scalability requirement elicitation;scalability requirement modeling;systematic scalability-related obstacle identification;goal satisfaction;complex large-scale financial fraud detection system;goal-oriented requirements engineering,,16.0,,56.0,,14 Feb 2012,,,IEEE,IEEE Journals
886,887,On the Positive Effect of Reactive Programming on Software Comprehension: An Empirical Study,G. Salvaneschi; S. Proksch; S. Amann; S. Nadi; M. Mezini,"Department of Computer Science, Reactive Systems Group, Technische Universität Darmstadt, Darmstadt, Germany; Department of Computer Science, Software Technology Group, Technische Universität Darmstadt, Darmstadt, Germany; Department of Computer Science, Software Technology Group, Technische Universität Darmstadt, Darmstadt, Germany; Department of Computing Science, AB, University of AlbertaCanada; Department of Computer Science, Software Technology Group, Technische Universität Darmstadt, Darmstadt, Germany",IEEE Transactions on Software Engineering,8 Dec 2017,2017,43,12,1125,1143,"Starting from the first investigations with strictly functional languages, reactive programming has been proposed as the programming paradigm for reactive applications. Over the years, researchers have enriched reactive languages with more powerful abstractions, embedded these abstractions into mainstream languages-including object-oriented languages-and applied reactive programming to several domains, such as GUIs, animations, Web applications, robotics, and sensor networks. However, an important assumption behind this line of research is that, beside other claimed advantages, reactive programming makes a wide class of otherwise cumbersome applications more comprehensible. This claim has never been evaluated. In this paper, we present the first empirical study that evaluates the effect of reactive programming on comprehension. The study involves 127 subjects and compares reactive programming to the traditional object-oriented style with the Observer design pattern. Our findings show that program comprehension is significantly enhanced by the reactive-programming paradigm-a result that suggests to further develop research in this field.",1939-3520,,10.1109/TSE.2017.2655524,European Research Council; German Federal Ministry of Education and Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7827078,Reactive programming;empirical study;controlled experiment;software comprehension,Programming;Runtime;Software development;Robot sensing systems,functional languages;object-oriented languages;object-oriented programming,object-oriented languages;software comprehension;functional languages;observer design pattern;program comprehension;reactive languages;reactive programming,,8.0,,72.0,Traditional,19 Jan 2017,,,IEEE,IEEE Journals
887,888,Generating Test Cases for Real-Time Systems Based on Symbolic Models,W. L. Andrade; P. D. L. Machado,"Federal University of Campina Grande, Campina Grande; Federal University of Campina Grande, Campina Grande",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1216,1229,"The state space explosion problem is one of the challenges to be faced by test case generation techniques, particularly when data values need to be enumerated. This problem gets even worse for real-time systems (RTS) that also have time constraints. The usual solution in this context, based on finite state machines or time automata, consists of enumerating data values (restricted to finite domains) while treating time symbolically. In this paper, a symbolic model for conformance testing of real-time systems software named TIOSTS that addresses both data and time symbolically is presented. Moreover, a test case generation process is defined to select more general test cases with variables and parameters that can be instantiated at testing execution time. Generation is based on a combination of symbolic execution and constraint solving for the data part and symbolic analysis for timed aspects. Furthermore, the practical application of the process is investigated through a case study.",1939-3520,,10.1109/TSE.2013.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6475130,Real-time systems and embedded systems;formal methods;symbolic execution;testing strategies,Testing;Clocks;Cost accounting;Real-time systems;Data models;Automata;Semantics,conformance testing;finite state machines;program testing;real-time systems,test case generation techniques;real-time systems;symbolic models;state space explosion problem;RTS;time constraints;finite state machines;time automata;conformance testing;TIOSTS;symbolic execution;constraint solving;data part;symbolic analysis;timed aspects,,9.0,1.0,38.0,,6 Mar 2013,,,IEEE,IEEE Journals
888,889,Symbolic Crosschecking of Data-Parallel Floating-Point Code,P. Collingbourne; C. Cadar; P. H. J. Kelly,"Google Inc,; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom",IEEE Transactions on Software Engineering,8 Jul 2014,2014,40,7,710,737,"We present a symbolic execution-based technique for cross-checking programs accelerated using SIMD or OpenCL against an unaccelerated version, as well as a technique for detecting data races in OpenCL programs. Our techniques are implemented in KLEE-CL, a tool based on the symbolic execution engine KLEE that supports symbolic reasoning on the equivalence between expressions involving both integer and floating-point operations. While the current generation of constraint solvers provide effective support for integer arithmetic, the situation is different for floating-point arithmetic, due to the complexity inherent in such computations. The key insight behind our approach is that floating-point values are only reliably equal if they are essentially built by the same operations. This allows us to use an algorithm based on symbolic expression matching augmented with canonicalisation rules to determine path equivalence. Under symbolic execution, we have to verify equivalence along every feasible control-flow path. We reduce the branching factor of this process by aggressively merging conditionals, if-converting branches into select operations via an aggressive phi-node folding transformation. To support the Intel Streaming SIMD Extension (SSE) instruction set, we lower SSE instructions to equivalent generic vector operations, which in turn are interpreted in terms of primitive integer and floating-point operations. To support OpenCL programs, we symbolically model the OpenCL environment using an OpenCL runtime library targeted to symbolic execution. We detect data races by keeping track of all memory accesses using a memory log, and reporting a race whenever we detect that two accesses conflict. By representing the memory log symbolically, we are also able to detect races associated with symbolically-indexed accesses of memory objects. We used KLEE-CL to prove the bounded equivalence between scalar and data-parallel versions of floating-point programs and find a number of issues in a variety of open source projects that use SSE and OpenCL, including mismatches between implementations, memory errors, race conditions and a compiler bug.",1939-3520,,10.1109/TSE.2013.2297120,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6698391,Data-parallel code;floating point;symbolic execution;SIMD;OpenCL;KLEE-CL,Vectors;Kernel;Computational modeling;Computer architecture;Semantics;Programming;Parallel processing,data handling;floating point arithmetic;parallel processing;program debugging,symbolic crosschecking;data parallel floating point code;symbolic execution based technique;crosschecking programs;SIMD;OpenCL programs;KLEE-CL;symbolic execution engine;symbolic reasoning;floating-point operations;integer operations;integer arithmetic;floating point arithmetic;symbolic expression matching;phi node folding transformation;intel streaming SIMD extension;SSE instruction set;equivalent generic vector operations;floating point operations;primitive integer operations;OpenCL environment;memory accesses;memory log;open source projects;floating-point programs;compiler bug;memory errors;race conditions,,9.0,,55.0,,2 Jan 2014,,,IEEE,IEEE Journals
889,890,Asymptotic Perturbation Bounds for Probabilistic Model Checking with Empirically Determined Probability Parameters,G. Su; Y. Feng; T. Chen; D. S. Rosenblum,"Department of Computer Science, School of Computing, National University of Singapore; Quantum Computation and Intelligent Systems, University of Technology Sydney; Department of Computer Science, Middlesex University London; Department of Computer Science, School of Computing, National University of Singapore",IEEE Transactions on Software Engineering,14 Jul 2016,2016,42,7,623,639,"Probabilistic model checking is a verification technique that has been the focus of intensive research for over a decade. One important issue with probabilistic model checking, which is crucial for its practical significance but is overlooked by the state-of-the-art largely, is the potential discrepancy between a stochastic model and the real-world system it represents when the model is built from statistical data. In the worst case, a tiny but nontrivial change to some model quantities might lead to misleading or even invalid verification results. To address this issue, in this paper, we present a mathematical characterization of the consequences of model perturbations on the verification distance. The formal model that we adopt is a parametric variant of discrete-time Markov chains equipped with a vector norm to measure the perturbation. Our main technical contributions include a closed-form formulation of asymptotic perturbation bounds, and computational methods for two arguably most useful forms of those bounds, namely linear bounds and quadratic bounds. We focus on verification of reachability properties but also address automata-based verification of omega-regular properties. We present the results of a selection of case studies that demonstrate that asymptotic perturbation bounds can accurately estimate maximum variations of verification results induced by model perturbations.",1939-3520,,10.1109/TSE.2015.2508444,Ministry of Education - Singapore; Australian Research Council; National Natural Science Foundation of China; CAS/SAFEA; State Key Laboratory of Novel Software Technology at Nanjing University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7355393,Asymptotic perturbation bound;discrete-time Markov chain;numerical iteration;optimization;parametric Markov chain;perturbation analysis;probabilistic model checking;quadratic programming,Model checking;Markov processes;Probabilistic logic;Computational modeling;Mathematical model;Perturbation methods,automata theory;formal verification;linear programming;Markov processes;probability;quadratic programming;reachability analysis,probabilistic model checking;empirically determined probability parameters;verification technique;stochastic model;real-world system;statistical data;mathematical characterization;model perturbations;verification distance;formal model;parametric discrete-time Markov chains;vector norm;perturbation measure;closed-form formulation;asymptotic perturbation bounds;computational methods;linear bounds;quadratic bounds;reachability property verification;automata-based verification;omega-regular properties;maximum verification variation estimation,,4.0,,53.0,,17 Dec 2015,,,IEEE,IEEE Journals
890,891,Coverage Estimation in Model Checking with Bitstate Hashing,S. Ikeda; M. Jibiki; Y. Kuno,"NEC Corporation, Kawasaki; National Institute of Information and Communication Technology, Koganei; University of Tsukuba, Bunkyo",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,477,486,"Explicit-state model checking which is conducted by state space search has difficulty in exploring satisfactory state space because of its memory requirements. Though bitstate hashing achieves memory efficiency, it cannot guarantee complete verification. Thus, it is desirable to provide a reliability indicator such as a coverage estimate. However, the existing approaches for coverage estimation are not very accurate when a verification run covers a small portion of state space. This mainly stems from the lack of information that reflects characteristics of models. Therefore, we propose coverage estimation methods using a growth curve that approximates an increase in reached states by enlarging a bloom filter. Our approaches improve estimation accuracy by leveraging the statistics from multiple verification runs. Coverage is estimated by fitting the growth curve to these statistics. Experimental results confirm the validity of the proposed growth curve and the applicability of our approaches to practical models. In fact, for practical models, our approaches outperformed the conventional ones when the actual coverage is relatively low.",1939-3520,,10.1109/TSE.2012.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226428,Coverage estimation;model checking;bitstate hashing,Estimation;Reliability;Probabilistic logic;Accuracy;Mathematical model;Space exploration;Equations,curve fitting;file organisation;formal verification;statistics,bitstate hashing;explicit-state model checking;state space search;memory requirement;memory efficiency;formal verification;growth curve fitting;Bloom filter;statistics;coverage estimation;reliability indicator,,1.0,,19.0,,26 Jun 2012,,,IEEE,IEEE Journals
891,892,Using Timed Automata for Modeling Distributed Systems with Clocks: Challenges and Solutions,G. Rodriguez-Navas; J. Proenza,"Universitat de les Illes Balears, Palma de Mallorca; Universitat de les Illes Balears, Palma de Mallorca",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,857,868,"The application of model checking for the formal verification of distributed embedded systems requires the adoption of techniques for realistically modeling the temporal behavior of such systems. This paper discusses how to model with timed automata the different types of relationships that may be found among the computer clocks of a distributed system, namely, ideal clocks, drifting clocks, and synchronized clocks. For each kind of relationship, a suitable modeling pattern is thoroughly described and formally verified.",1939-3520,,10.1109/TSE.2012.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374193,Embedded systems;real-time systems;clock synchronization;model checking;timed automata;hybrid automata,Real-time systems;Automata;Formal verification;Distributed processing;Embedded systems,automata theory;distributed processing;embedded systems;formal verification,timed automata;modeling distributed systems;model checking;formal verification;distributed embedded systems;temporal behavior;distributed system computer clocks;ideal clocks;drifting clocks;synchronized clocks,,12.0,,27.0,,4 Dec 2012,,,IEEE,IEEE Journals
892,893,Engineering Privacy,S. Spiekermann; L. F. Cranor,"Humboldt University, Berin; Carnegie Mellon University, Pittsburgh",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,67,82,"In this paper we integrate insights from diverse islands of research on electronic privacy to offer a holistic view of privacy engineering and a systematic structure for the discipline's topics. First we discuss privacy requirements grounded in both historic and contemporary perspectives on privacy. We use a three-layer model of user privacy concerns to relate them to system operations (data transfer, storage and processing) and examine their effects on user behavior. In the second part of the paper we develop guidelines for building privacy-friendly systems. We distinguish two approaches: ""privacy-by-policy"" and ""privacy-by-architecture."" The privacy-by-policy approach focuses on the implementation of the notice and choice principles of fair information practices (FIPs), while the privacy-by-architecture approach minimizes the collection of identifiable personal data and emphasizes anonymization and client-side data storage and processing. We discuss both approaches with a view to their technical overlaps and boundaries as well as to economic feasibility. The paper aims to introduce engineers and computer scientists to the privacy research domain and provide concrete guidance on how to design privacy-friendly systems.",1939-3520,,10.1109/TSE.2008.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4657365,Privacy;Legal Aspects of Computing;Security and Protection;Requirements/Specifications;Privacy;Legal Aspects of Computing;Security and Protection;Requirements/Specifications,Design engineering;Protection;Systems engineering and theory;Data privacy;Companies;Social network services;Law;Radiofrequency identification;Guidelines;Memory,data privacy;security of data,electronic privacy;privacy engineering;user privacy;privacy-friendly systems;privacy-by-policy;privacy-by-architecture,,214.0,,116.0,,24 Oct 2008,,,IEEE,IEEE Journals
893,894,Predicting Vulnerable Software Components via Text Mining,R. Scandariato; J. Walden; A. Hovsepyan; W. Joosen,"IBBT-DistriNet, KU Leuven, 3001 Leuven, Belgium; Department of Computer Science, Northern Kentucky University, Highland Heights, KY; IBBT-DistriNet, KU Leuven, 3001 Leuven, Belgium; IBBT-DistriNet, KU Leuven, 3001 Leuven, Belgium",IEEE Transactions on Software Engineering,9 Oct 2014,2014,40,10,993,1006,"This paper presents an approach based on machine learning to predict which components of a software application contain security vulnerabilities. The approach is based on text mining the source code of the components. Namely, each component is characterized as a series of terms contained in its source code, with the associated frequencies. These features are used to forecast whether each component is likely to contain vulnerabilities. In an exploratory validation with 20 Android applications, we discovered that a dependable prediction model can be built. Such model could be useful to prioritize the validation activities, e.g., to identify the components needing special scrutiny.",1939-3520,,10.1109/TSE.2014.2340398,EU FP7; Research Fund KU Leuven; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6860243,Vulnerabilities;prediction model;machine learning,Software;Predictive models;Measurement;Security;Androids;Humanoid robots;Text mining,data mining;learning (artificial intelligence);program verification;security of data,vulnerable software component;text mining;machine learning;security vulnerability;source code;Android application,,119.0,,40.0,,18 Jul 2014,,,IEEE,IEEE Journals
894,895,Customizing the Representation Capabilities of Process Models: Understanding the Effects of Perceived Modeling Impediments,B. M. Samuel; L. A. Watkins III; A. Ehle; V. Khatri,"Ivey Business School, Western University 1255 Western Road, London, ON, Canada; Kelley School of Business, Indiana University 1309 East 10th Street BU 570, Bloomington, IN; Kelley School of Business, Indiana University 1309 East 10th Street BU 570, Bloomington, IN; Kelley School of Business, Indiana University 1309 East 10th Street BU 570, Bloomington, IN",IEEE Transactions on Software Engineering,7 Jan 2015,2015,41,1,19,39,"Process modeling is useful during the analysis and design of systems. Prior research acknowledges both impediments to process modeling that limits its use as well as customizations that can be employed to help improve the creation of process models. However, no research to date has provided a rich examination of the linkages between perceived process modeling impediments and process modeling customizations. In order to help address this gap, we first conceptualized perceived impediments to using process models as a “lack of fit” between process modeling and another factor: (1) the role the process model is intended for; and (2) the task at hand. We conducted a case study at two large health insurance carriers to understand why the lack of fit existed and then show different types of process modeling customizations used to address the lack of fit and found a variety of “physical” and “process” customizations employed to overcome the lack of fits. We generalize our findings into propositions for future research that examine the dynamic interaction between process models and their need to be understood by individuals during systems analysis and design.",1939-3520,,10.1109/TSE.2014.2354043,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898868,Software process models;requirements/specifications management;requirements/specifications process;requirements/specification stools;UML;use cases;activity diagrams,Unified modeling language;Analytical models;Organizations;Software;Interviews;Context,formal specification;software process improvement,process model representation capability customization;system design;system analysis;process model creation improvement;perceived process modeling impediments;process modeling customizations;lack-of-fit;health insurance carriers;physical customization;process customization;dynamic process model interaction,,5.0,,97.0,,15 Sep 2014,,,IEEE,IEEE Journals
895,896,Clone Management for Evolving Software,H. A. Nguyen; T. T. Nguyen; N. H. Pham; J. Al-Kofahi; T. N. Nguyen,"Iowa State University, Ames; Iowa State University, Ames; Iowa State University, Ames; Iowa State University, Ames; Iowa State University, Ames",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1008,1026,"Recent research results suggest a need for code clone management. In this paper, we introduce JSync, a novel clone management tool. JSync provides two main functions to support developers in being aware of the clone relation among code fragments as software systems evolve and in making consistent changes as they create or modify cloned code. JSync represents source code and clones as (sub)trees in Abstract Syntax Trees, measures code similarity based on structural characteristic vectors, and describes code changes as tree editing scripts. The key techniques of JSync include the algorithms to compute tree editing scripts, to detect and update code clones and their groups, to analyze the changes of cloned code to validate their consistency, and to recommend relevant clone synchronization and merging. Our empirical study on several real-world systems shows that JSync is efficient and accurate in clone detection and updating, and provides the correct detection of the defects resulting from inconsistent changes to clones and the correct recommendations for change propagation across cloned code.",1939-3520,,10.1109/TSE.2011.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007141,Clone management;clone consistency analysis;clone synchronization;clone merging,Cloning;Feature extraction;Software systems;Synchronization;Vegetation;Merging;Databases,Java;program compilers,evolving software;code clone management;JSync;clone management tool;code fragments;software systems;source code;abstract syntax trees;structural characteristic vectors;tree editing scripts;change propagation,,57.0,,50.0,,1 Sep 2011,,,IEEE,IEEE Journals
896,897,Automated Behavioral Testing of Refactoring Engines,G. Soares; R. Gheyi; T. Massoni,"Federal University of Campina Grande, Campina Grande; Federal University of Campina Grande, Campina Grande; Federal University of Campina Grande, Campina Grande",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,147,162,"Refactoring is a transformation that preserves the external behavior of a program and improves its internal quality. Usually, compilation errors and behavioral changes are avoided by preconditions determined for each refactoring transformation. However, to formally define these preconditions and transfer them to program checks is a rather complex task. In practice, refactoring engine developers commonly implement refactorings in an ad hoc manner since no guidelines are available for evaluating the correctness of refactoring implementations. As a result, even mainstream refactoring engines contain critical bugs. We present a technique to test Java refactoring engines. It automates test input generation by using a Java program generator that exhaustively generates programs for a given scope of Java declarations. The refactoring under test is applied to each generated program. The technique uses SafeRefactor, a tool for detecting behavioral changes, as an oracle to evaluate the correctness of these transformations. Finally, the technique classifies the failing transformations by the kind of behavioral change or compilation error introduced by them. We have evaluated this technique by testing 29 refactorings in Eclipse JDT, NetBeans, and the JastAdd Refactoring Tools. We analyzed 153,444 transformations, and identified 57 bugs related to compilation errors, and 63 bugs related to behavioral changes.",1939-3520,,10.1109/TSE.2012.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6175911,Refactoring;automated testing;program generation,Java;Metals;Engines;Computer bugs;Testing;Automatic programming;Unified modeling language,automatic programming;Java;program testing,automated behavioral testing;compilation errors;refactoring transformation;refactoring engine developers;Java refactoring engines;Java program generator;SafeRefactor;JastAdd refactoring tools,,59.0,,49.0,,3 Apr 2012,,,IEEE,IEEE Journals
897,898,Grammar Recovery from Parse Trees and Metrics-Guided Grammar Refactoring,N. A. Kraft; E. B. Duffy; B. A. Malloy,"University of Alabama, Tuscaloosa; Clemson University, Clemson; Clemson University, Clemson",IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,780,794,"Many software development tools that assist with tasks such as testing and maintenance are specific to a particular development language and require a parser for that language. Because a grammar is required to develop a parser, construction of these software development tools is dependent upon the availability of a grammar for the development language. However, a grammar is not always available for a language and, in these cases, acquiring a grammar is the most difficult, costly, and time-consuming phase of tool construction. In this paper, we describe a methodology for grammar recovery from a hard-coded parser. Our methodology is comprised of manual instrumentation of the parser, a technique for automatic grammar recovery from parse trees, and a semi-automatic metrics-guided approach to refactoring an iterative grammar to obtain a recursive grammar. We present the results of a case study in which we recover and refactor a grammar from version 4.0.0 of the GNU C++ parser and then refactor the recovered grammar using our metrics-guided approach. Additionally, we present an evaluation of the recovered and refactored grammar by comparing it to the ISO C++98 grammar.",1939-3520,,10.1109/TSE.2009.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5278661,Grammar;grammar recovery;grammar refactoring;grammar metrics;parse tree.,Programming;Software testing;Instruments;Software maintenance;Java;Computer Society;Manuals;Iterative methods;ISO;Debugging,C++ language;grammars;software maintenance;software metrics;system recovery,grammar recovery;parse trees;metrics-guided grammar refactoring;software development tools;hard-coded parser;iterative grammar;recursive grammar;GNU C++ parser;ISO C++98 grammar,,7.0,,49.0,,6 Oct 2009,,,IEEE,IEEE Journals
898,899,Identifying Extract Method Refactoring Opportunities Based on Functional Relevance,S. Charalampidou; A. Ampatzoglou; A. Chatzigeorgiou; A. Gkortzis; P. Avgeriou,"Institute of Mathematics and Computer Science, University of Groningen, Groningen, Netherlands; Institute of Mathematics and Computer Science, University of Groningen, Groningen, Netherlands; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Institute of Mathematics and Computer Science, University of Groningen, Groningen, Netherlands; Institute of Mathematics and Computer Science, University of Groningen, Groningen, Netherlands",IEEE Transactions on Software Engineering,13 Oct 2017,2017,43,10,954,974,"`Extract Method' is considered one of the most frequently applied and beneficial refactorings, since the corresponding Long Method smell is among the most common and persistent ones. Although Long Method is conceptually related to the implementation of diverse functionalities within a method, until now, this relationship has not been utilized while identifying refactoring opportunities. In this paper we introduce an approach (accompanied by a tool) that aims at identifying source code chunks that collaborate to provide a specific functionality, and propose their extraction as separate methods. The accuracy of the proposed approach has been empirically validated both in an industrial and an open-source setting. In the former case, the approach was capable of identifying functionally related statements within two industrial long methods (approx. 500 LoC each), with a recall rate of 93 percent. In the latter case, based on a comparative study on open-source data, our approach ranks better compared to two well-known techniques of the literature. To assist software engineers in the prioritization of the suggested refactoring opportunities the approach ranks them based on an estimate of their fitness for extraction. The provided ranking has been validated in both settings and proved to be strongly correlated with experts' opinion.",1939-3520,,10.1109/TSE.2016.2645572,ITEA2; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801138,Design tools and techniques;object-oriented programming;metrics/measurement,Measurement;Open source software;Mathematics;Data mining;Computer science;Syntactics,public domain software;software maintenance,open-source data;functional relevance;beneficial refactorings;diverse functionalities;specific functionality;open-source setting;functionally related statements;industrial long methods;refactoring opportunities;Extract Method;Long Method smell;source code chunks,,3.0,,44.0,Traditional,28 Dec 2016,,,IEEE,IEEE Journals
899,900,DECAF: A Platform-Neutral Whole-System Dynamic Binary Analysis Platform,A. Henderson; L. K. Yan; X. Hu; A. Prakash; H. Yin; S. McCamant,"Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY; Department of RIG, Rome Laboratory, Rome, NY; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY; Department of Electrical Engineering and Computer Science, Syracuse University, Syracuse, NY; Department of Computer Science & Engineering, University of Minnesota (Twin Cities), Minneapolis, MN",IEEE Transactions on Software Engineering,13 Feb 2017,2017,43,2,164,184,"Dynamic binary analysis is a prevalent and indispensable technique in program analysis. While several dynamic binary analysis tools and frameworks have been proposed, all suffer from one or more of: prohibitive performance degradation, a semantic gap between the analysis code and the program being analyzed, architecture/OS specificity, being user-mode only, and lacking APIs. We present DECAF, a virtual machine based, multi-target, whole-system dynamic binary analysis framework built on top of QEMU. DECAF provides Just-In-Time Virtual Machine Introspection and a plugin architecture with a simple-to-use event-driven programming interface. DECAF implements a new instruction-level taint tracking engine at bit granularity, which exercises fine control over the QEMU Tiny Code Generator (TCG) intermediate representation to accomplish on-the-fly optimizations while ensuring that the taint propagation is sound and highly precise. We perform a formal analysis of DECAF's taint propagation rules to verify that most instructions introduce neither false positives nor false negatives. We also present three platform-neutral plugins-Instruction Tracer, Keylogger Detector, and API Tracer, to demonstrate the ease of use and effectiveness of DECAF in writing cross-platform and system-wide analysis tools. Implementation of DECAF consists of 9,550 lines of C++ code and 10,270 lines of C code and we evaluate DECAF using CPU2006 SPEC benchmarks and show average overhead of 605 percent for system wide tainting and 12 percent for VMI.",1939-3520,,10.1109/TSE.2016.2589242,US National Science Foundation; US National Science Foundation; McAfee Inc.; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7506264,Dynamic binary analysis;dynamic taint analysis;virtual machine introspection,Instruments;Virtual machining;Kernel;Semantics;Computer architecture;Registers;Context,application program interfaces;C++ language;program compilers;program diagnostics;software architecture;software performance evaluation;software portability;software tools;source code (software);virtual machines,DECAF;platform-neutral whole-system dynamic binary analysis platform;program analysis;dynamic binary analysis tools;prohibitive performance degradation;code analysis;architecture-OS specificity;virtual machine based multitarget whole-system dynamic binary analysis;QEMU;just-in-time virtual machine introspection;plug-in architecture;event-driven programming interface;instruction-level taint tracking engine;QEMU tiny code generator;TCG;on-the-fly optimizations;taint propagation;formal analysis;platform-neutral plugins;instruction tracer;keylogger detector;API tracer;cross-platform analysis tools;system- wide analysis tools;C++ code;C code;CPU2006 SPEC benchmarks;system wide tainting,,16.0,,43.0,,7 Jul 2016,,,IEEE,IEEE Journals
900,901,Automated Synthesis and Dynamic Analysis of Tradeoff Spaces for Object-Relational Mapping,H. Bagheri; C. Tang; K. Sullivan,"Department of Computer Science and Engineering, University of Nebraska-Lincoln, Lincoln, NE; Department of Computer Sciences, University of Virginia, Charlottesville, VA 22903; Department of Computer Sciences, University of Virginia, Charlottesville, VA 22903",IEEE Transactions on Software Engineering,13 Feb 2017,2017,43,2,145,163,"Producing software systems that achieve acceptable tradeoffs among multiple non-functional properties remains a significant engineering problem. We propose an approach to solving this problem that combines synthesis of spaces of design alternatives from logical specifications and dynamic analysis of each point in the resulting spaces. We hypothesize that this approach has potential to help engineers understand important tradeoffs among dynamically measurable properties of system components at meaningful scales within reach of existing synthesis tools. To test this hypothesis, we developed tools to enable, and we conducted, a set of experiments in the domain of relational databases for object-oriented data models. For each of several data models, we used our approach to empirically test the accuracy of a published suite of metrics to predict tradeoffs based on the static schema structure alone. The results show that exhaustive synthesis and analysis provides a superior view of the tradeoff spaces for such designs. This work creates a path forward toward systems that achieve significantly better tradeoffs among important system properties.",1939-3520,,10.1109/TSE.2016.2587646,National Science Foundation; US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7506009,Specification-driven synthesis;tradespace analysis;ORM;static analysis;dynamic analysis;relational logic,Data models;Load modeling;Object oriented modeling;Semantics;Relational databases;Measurement,data models;formal specification;object-oriented methods;program diagnostics,object-relational mapping;automated tradeoff space synthesis;dynamic tradeoff space analysis;software systems;nonfunctional properties;logical specifications;dynamic analysis;dynamically measurable properties;relational databases;object-oriented data models;static schema structure;system properties,,9.0,,44.0,,7 Jul 2016,,,IEEE,IEEE Journals
901,902,Round-Up: Runtime Verification of Quasi Linearizability for Concurrent Data Structures,L. Zhang; A. Chattopadhyay; C. Wang,"Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University (Virginia Tech), Blacksburg, VA; Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University (Virginia Tech), Blacksburg, VA; Bradley Department of Electrical and Computer Engineering, Virginia Polytechnic Institute and State University (Virginia Tech), Blacksburg, VA",IEEE Transactions on Software Engineering,8 Dec 2015,2015,41,12,1202,1216,"We propose a new method for runtime checking of a relaxed consistency property called quasi linearizability for concurrent data structures.Quasi linearizability generalizes the standard notion of linearizability by introducing nondeterminism into the parallel computations quantitatively and then exploiting such nondeterminism to improve the runtime performance. However, ensuring the quantitative aspects of this correctness condition in the low-level code of the concurrent data structure implementation is a difficult task.Our runtime verification method is the first fully automated method for checking quasi linearizability in the C/C++ code of concurrent data structures. It guarantees that all the reported quasi linearizability violations manifested by the concurrent executions are real violations. We have implemented our method in a software tool based on the LLVM compiler and a systematic concurrency testing tool called Inspect. Our experimental evaluation shows that the new method is effective in detecting quasi linearizability violations in the source code implementations of concurrent data structures.",1939-3520,,10.1109/TSE.2015.2467371,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7192659,Runtime verification;linearizability;serializability;atomicity;relaxed consistency;systematic concurrency testing;partial order reduction;Runtime verification;linearizability;serializability;atomicity;relaxed consistency;systematic concurrency testing;partial order reduction,History;Data structures;Legal aspects;Runtime;Concurrent computing,C++ language;data structures;program compilers;software tools,source code;Inspect;systematic concurrency testing tool;LLVM compiler;software tool;concurrent executions;quasi linearizability violations;C/C++ code;fully automated method;runtime verification method;low-level code;correctness condition;nondeterminism;relaxed consistency property;runtime checking;concurrent data structures,,3.0,,48.0,,12 Aug 2015,,,IEEE,IEEE Journals
902,903,"Task Environment Complexity, Global Team Dispersion, Process Capabilities, and Coordination in Software Development",G. Lee; J. A. Espinosa; W. H. DeLone,"American University, Washington; American University, Washington; American University, Washington",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1753,1771,"Software development teams are increasingly global. Team members are separated by multiple boundaries such as geographic location, time zone, culture, and organization, presenting substantial coordination challenges. Global software development becomes even more challenging when user requirements change dynamically. However, little empirical research has investigated how team dispersion across multiple boundaries and user requirements dynamism, which collectively increase task environment complexity, influence team coordination and software development success in the global context. Further, we have a limited understanding of how software process capabilities such as rigor, standardization, agility, and customizability mitigate the negative effects of global team dispersion and user requirements dynamism. To address these important issues, we test a set of relevant hypotheses using field survey data obtained from both project managers and stakeholders. Our results show that global team dispersion and user requirements dynamism have a negative effect on coordination effectiveness. We find that the negative effect of global team dispersion on coordination effectiveness decreases as process standardization increases and that the negative effect of user requirements dynamism on coordination effectiveness decreases as process agility increases. We find that coordination effectiveness has a positive effect on global software development success in terms of both process and product aspects.",1939-3520,,10.1109/TSE.2013.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6583162,Global boundaries;global software development;user requirements dynamism;software process capability;task environment complexity;team coordination;team dispersion,User centered design;Complexity theory;Dispersion;Global communication;Software development;Process capability;Globalization,software development management;team working,task environment complexity;global team dispersion;process capabilities;coordination;software development teams;geographic location;time zone;culture;organization;global software development;user requirements dynamism;rigor capability;standardization capability;agility capability;customizability capability;coordination effectiveness;process aspect;product aspect,,14.0,,101.0,,21 Aug 2013,,,IEEE,IEEE Journals
903,904,EDZL Schedulability Analysis in Real-Time Multicore Scheduling,J. Lee; I. Shin,"The University of Michigan, Ann Arbor; KAIST, Daejeon",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,910,916,"In real-time systems, correctness depends not only on functionality but also on timeliness. A great number of scheduling theories have been developed for verification of the temporal correctness of jobs (software) in such systems. Among them, the Earliest Deadline first until Zero-Laxity (EDZL) scheduling algorithm has received growing attention thanks to its effectiveness in multicore real-time scheduling. However, the true potential of EDZL has not yet been fully exploited in its schedulability analysis as the state-of-the-art EDZL analysis techniques involve considerable pessimism. In this paper, we propose a new EDZL multicore schedulability test. We first introduce an interesting observation that suggests an insight toward pessimism reduction in the schedulability analysis of EDZL. We then incorporate it into a well-known existing Earliest Deadline First (EDF) schedulability test, resulting in a new EDZL schedulability test. We demonstrate that the proposed EDZL test not only has lower time complexity than existing EDZL schedulability tests, but also significantly improves the schedulability of EDZL by up to 36.6 percent compared to the best existing EDZL schedulability tests.",1939-3520,,10.1109/TSE.2012.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6374195,Earliest Deadline first until Zero-Laxity (EDZL);real-time scheduling;schedulability analysis;multicore platform;real-time systems,Real-time systems;Silicon;Scheduling algorithms;Scheduling;Exponential distribution;Time factors;Aerospace electronics,multiprocessing systems;processor scheduling;real-time systems,EDZL schedulability analysis;real-time multicore scheduling;correctness;earliest deadline first until zero-laxity scheduling algorithm;time complexity,,10.0,,22.0,,4 Dec 2012,,,IEEE,IEEE Journals
904,905,Supporting Process Model Validation through Natural Language Generation,H. Leopold; J. Mendling; A. Polyvyanyy,"WU Vienna, Austria.; WU Vienna, Austria.; Queensland University of Technology, Brisbane, Australia.",IEEE Transactions on Software Engineering,8 Aug 2014,2014,40,8,818,840,"The design and development of process-aware information systems is often supported by specifying requirements as business process models. Although this approach is generally accepted as an effective strategy, it remains a fundamental challenge to adequately validate these models given the diverging skill set of domain experts and system analysts. As domain experts often do not feel confident in judging the correctness and completeness of process models that system analysts create, the validation often has to regress to a discourse using natural language. In order to support such a discourse appropriately, so-called verbalization techniques have been defined for different types of conceptual models. However, there is currently no sophisticated technique available that is capable of generating natural-looking text from process models. In this paper, we address this research gap and propose a technique for generating natural language texts from business process models. A comparison with manually created process descriptions demonstrates that the generated texts are superior in terms of completeness, structure, and linguistic complexity. An evaluation with users further demonstrates that the texts are very understandable and effectively allow the reader to infer the process model semantics. Hence, the generated texts represent a useful input for process model validation.",1939-3520,,10.1109/TSE.2014.2327044,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823180,Business process model validation;natural language text generation;verbalization,Unified modeling language;Natural languages;Business;Analytical models;Adaptation models;Context modeling;Context,information systems;natural language processing,process model validation;linguistic complexity;structure complexity;completeness complexity;natural language text generation;natural-looking text generation;verbalization techniques;process model completeness;process model correctness;business process models;process-aware information systems;natural language generation,,42.0,,110.0,,29 May 2014,,,IEEE,IEEE Journals
905,906,Verification and Trade-Off Analysis of Security Properties in UML System Models,G. Georg; K. Anastasakis; B. Bordbar; S. H. Houmb; I. Ray; M. Toahchoodee,"Colorado State University, Fort Collins, CO; University of Birmingham, Birmingham, UK; University of Birmingham, Birmingham, UK; Telenor GBDR, Trondheim, Norway; Colorado State University, Fort Collins, CO; Colorado State University, Fort Collins, CO",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,338,356,"Designing secure systems is a nontrivial task. Incomplete or faulty designs can cause security mechanisms to be incorrectly incorporated in a system, allowing them to be bypassed and resulting in a security breach. We advocate the use of the Aspect-Oriented Risk-Driven Development (AORDD) methodology for developing secure systems. This methodology begins with designers defining system assets, identifying potential attacks against them, and evaluating system risks. When a risk is unacceptable, designers must mitigate the associated threat by incorporating security mechanisms methodically into the system design. Designers next formally evaluate the resulting design to ensure that the threat has been mitigated, while still allowing development to meet other project constraints. In this paper, we focus on the AORDD analysis, which consists of: (1) a formal security evaluation and (2) a trade-off analysis that enables system designers to position alternative security solutions against each other. The formal security evaluation uses the Alloy Analyzer to provide assurance that an incorporated security mechanism performs as expected and makes the system resilient to previously identified attacks. The trade-off analysis uses a Bayesian Belief Network topology to allow equally effective security mechanisms to be compared against system security requirements and other factors such as time-to-market and budget constraints.",1939-3520,,10.1109/TSE.2010.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432225,Aspect-oriented modeling (AOM);Bayesian belief network (BBN);security analysis;trade-off analysis.,Unified modeling language;Protection;Standards development;ISO standards;Data security;Design methodology;Bayesian methods;Risk management;Computer security;Computer Society,aspect-oriented programming;belief networks;formal verification;security of data;Unified Modeling Language,trade-off analysis;security properties verification;UML system models;secure systems design;aspect-oriented risk-driven development;AORDD methodology;risk evaluation;formal security evaluation;Alloy Analyzer;Bayesian belief network topology;time-to-market;budget constraints,,19.0,,51.0,,18 Mar 2010,,,IEEE,IEEE Journals
906,907,Programmer-Friendly Refactoring Errors,E. Murphy-Hill; A. P. Black,"North Carolina State University, Raleigh; Portland State University, Portland",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1417,1431,"Refactoring tools, common to many integrated development environments, can help programmers to restructure their code. These tools sometimes refuse to restructure the programmer's code, instead giving the programmer a textual error message that she must decode if she wishes to understand the reason for the tool's refusal and what corrective action to take. This paper describes a graphical alternative to textual error messages called Refactoring Annotations. It reports on two experiments, one using an integrated development environment and the other using paper mockups, that show that programmers can use Refactoring Annotations to quickly and accurately understand the cause of refactoring errors.",1939-3520,,10.1109/TSE.2011.110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6072219,Refactoring;refactoring errors;usability;programmers;tools,Taxonomy;Programming;Prototypes;Visualization;Java,computer graphics;software maintenance,programmer-friendly refactoring errors;refactoring tools;textual error message;graphical alternative;textual error messages;refactoring annotations;integrated development environment;paper mockups,,7.0,,22.0,,8 Nov 2011,,,IEEE,IEEE Journals
907,908,A Tool-Supported Methodology for Validation and Refinement of Early-Stage Domain Models,M. Autili; A. Bertolino; G. De Angelis; D. D. Ruscio; A. D. Sandro,"Department of Information Engineering Computer Science and Mathematics University of L’Aquila, Italy; CNR-ISTI of Pisa, Italy; CNR-ISTI of Pisa, Italy; Department of Information Engineering Computer Science and Mathematics University of L’Aquila, Italy; Department of Computer Science, University of Toronto, Toronto, ON, Canada",IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,2,25,"Model-driven engineering (MDE) promotes automated model transformations along the entire development process. Guaranteeing the quality of early models is essential for a successful application of MDE techniques and related tool-supported model refinements. Do these models properly reflect the requirements elicited from the owners of the problem domain? Ultimately, this question needs to be asked to the domain experts. The problem is that a gap exists between the respective backgrounds of modeling experts and domain experts. MDE developers cannot show a model to the domain experts and simply ask them whether it is correct with respect to the requirements they had in mind. To facilitate their interaction and make such validation more systematic, we propose a methodology and a tool that derive a set of customizable questionnaires expressed in natural language from each model to be validated. Unexpected answers by domain experts help to identify those portions of the models requiring deeper attention. We illustrate the methodology and the current status of the developed tool MOTHIA, which can handle UML Use Case, Class, and Activity diagrams. We assess MOTHIA effectiveness in reducing the gap between domain and modeling experts, and in detecting modeling faults on the European Project CHOReOS.",1939-3520,,10.1109/TSE.2015.2449319,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7132782,Domain Modeling;Early Stage Model;Model Driven Engineering;Model Refinement;Model Validation;Natural Language Questionnaires;Semantic Model Quality;Domain modeling;early stage model;model driven engineering;model refinement;model validation;natural language questionnaires;semantic model quality,Unified modeling language;Semantics;Context modeling;Load modeling;Engines;Biological system modeling;Context,natural language processing;Unified Modeling Language,early-stage domain model;model-driven engineering;automated model transformation;MDE technique;tool-supported model refinement;natural language;MOTHIA;UML;activity diagram,,2.0,,50.0,,24 Jun 2015,,,IEEE,IEEE Journals
908,909,Variability Analysis of Requirements: Considering Behavioral Differences and Reflecting Stakeholders’ Perspectives,N. Itzik; I. Reinhartz-Berger; Y. Wand,"Department of Information Systems, University of Haifa, Haifa, Israel; Department of Information Systems, University of Haifa, Haifa, Israel; Sauder School of Business, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,14 Jul 2016,2016,42,7,687,706,"Adoption of Software Product Line Engineering (SPLE) to support systematic reuse of software-related artifacts within product families is challenging, time-consuming and error-prone. Analyzing the variability of existing artifacts needs to reflect different perspectives and preferences of stakeholders in order to facilitate decisions in SPLE adoption. Considering that requirements drive many development methods and activities, we introduce an approach to analyze variability of behaviors as presented in functional requirements. The approach, called semantic and ontological variability analysis (SOVA), uses ontological and semantic considerations to automatically analyze differences between initial states (preconditions), external events (triggers) that act on the system, and final states (post-conditions) of behaviors. The approach generates feature diagrams typically used in SPLE to model variability. Those diagrams are organized according to perspective profiles, reflecting the needs and preferences of the potential stakeholders for given tasks. We conducted an empirical study to examine the usefulness of the approach by comparing it to an existing tool which is mainly based on a latent semantic analysis measurement. SOVA appears to create outputs that are more comprehensible in significantly shorter times. These results demonstrate SOVA's potential to allow for flexible, behavior-oriented variability analysis.",1939-3520,,10.1109/TSE.2015.2512599,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7366597,Software product line engineering;variability analysis;feature diagrams;requirements specifications;ontology,Stakeholders;Software;Semantics;Feature extraction;Software product lines;Systematics,formal specification;ontologies (artificial intelligence);software product lines,behavior-oriented variability analysis;latent semantic analysis measurement;model variability;feature diagrams;SOVA;semantic-and-ontological variability analysis;SPLE adoption;software product line engineering;requirements variability analysis,,23.0,,53.0,,25 Dec 2015,,,IEEE,IEEE Journals
909,910,A Static Approach to Prioritizing JUnit Test Cases,H. Mei; D. Hao; L. Zhang; L. Zhang; J. Zhou; G. Rothermel,"Peking University, Beijing; Peking University, Beijing; Peking University, Beijing; Peking University, Beijing; Peking University, Beijing; University of Nebraska, Lincoln",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1258,1275,"Test case prioritization is used in regression testing to schedule the execution order of test cases so as to expose faults earlier in testing. Over the past few years, many test case prioritization techniques have been proposed in the literature. Most of these techniques require data on dynamic execution in the form of code coverage information for test cases. However, the collection of dynamic code coverage information on test cases has several associated drawbacks including cost increases and reduction in prioritization precision. In this paper, we propose an approach to prioritizing test cases in the absence of coverage information that operates on Java programs tested under the JUnit framework-an increasingly popular class of systems. Our approach, JUnit test case Prioritization Techniques operating in the Absence of coverage information (JUPTA), analyzes the static call graphs of JUnit test cases and the program under test to estimate the ability of each test case to achieve code coverage, and then schedules the order of these test cases based on those estimates. To evaluate the effectiveness of JUPTA, we conducted an empirical study on 19 versions of four Java programs ranging from 2K-80K lines of code, and compared several variants of JUPTA with three control techniques, and several other existing dynamic coverage-based test case prioritization techniques, assessing the abilities of the techniques to increase the rate of fault detection of test suites. Our results show that the test suites constructed by JUPTA are more effective than those in random and untreated test orders in terms of fault-detection effectiveness. Although the test suites constructed by dynamic coverage-based techniques retain fault-detection effectiveness advantages, the fault-detection effectiveness of the test suites constructed by JUPTA is close to that of the test suites constructed by those techniques, and the fault-detection effectiveness of the test suites constructed by some of JUPTA's variants is better than that of the test suites constructed by several of those techniques.",1939-3520,,10.1109/TSE.2011.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363461,Software testing;regression testing;test case prioritization;JUnit;call graph,Software testing;Regression analysis;Scheduling,Java;program testing;regression analysis;software fault tolerance,static approach;regression testing;test case prioritization techniques;dynamic code coverage information;Java programs;JUnit test case prioritization techniques operating in the absence of coverage information;JUPTA;static call graphs;fault-detection effectiveness;dynamic coverage-based techniques,,74.0,,44.0,,29 Nov 2012,,,IEEE,IEEE Journals
910,911,A Qualitative Study of Application-Level Caching,J. Mertz; I. Nunes,"Instituto de Informática, Universidade Federal do Rio Grande do Sul, Porto Alegre-RS, Brazil; Instituto de Informática, Universidade Federal do Rio Grande do Sul, Porto Alegre-RS, Brazil",IEEE Transactions on Software Engineering,15 Sep 2017,2017,43,9,798,816,"Latency and cost of Internet-based services are encouraging the use of application-level caching to continue satisfying users' demands, and improve the scalability and availability of origin servers. Despite its popularity, this level of caching involves the manual implementation by developers and is typically addressed in an ad-hoc way, given that it depends on specific details of the application. As a result, application-level caching is a time-consuming and error-prone task, becoming a common source of bugs. Furthermore, it forces application developers to reason about a crosscutting concern, which is unrelated to the application business logic. In this paper, we present the results of a qualitative study of how developers handle caching logic in their web applications, which involved the investigation of ten software projects with different characteristics. The study we designed is based on comparative and interactive principles of grounded theory, and the analysis of our data allowed us to extract and understand how developers address cache-related concerns to improve performance and scalability of their web applications. Based on our analysis, we derived guidelines and patterns, which guide developers while designing, implementing and maintaining application-level caching, thus supporting developers in this challenging task that is crucial for enterprise web applications.",1939-3520,,10.1109/TSE.2016.2633992,CNPq; CNPq; CAPES; BRA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7762909,Application-level caching;qualitative study;pattern;guideline;web application,Databases;Guidelines;Maintenance engineering;Servers;Software;Scalability;HTML,cache storage;Internet;project management;software management,application-level caching;Internet-based services;caching logic;Web applications;software projects,,3.0,,59.0,Traditional,1 Dec 2016,,,IEEE,IEEE Journals
911,912,Mutable Protection Domains: Adapting System Fault Isolation for Reliability and Efficiency,G. Parmer; R. West,"The George Washington University, Washtington, DC; Boston University, Boston",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,875,888,"As software systems are becoming increasingly complex, the likelihood of faults and unexpected behaviors will naturally increase. Today, mobile devices to large-scale servers feature many millions of lines of code. Compile-time checks and offline verification methods are unlikely to capture all system states and control flow interactions of a running system. For this reason, many researchers have developed methods to contain faults at runtime by using software and hardware-based techniques to define protection domains. However, these approaches tend to impose isolation boundaries on software components that are static, and thus remain intact while the system is running. An unfortunate consequence of statically structured protection domains is that they may impose undue overhead on the communication between separate components. This paper proposes a new runtime technique that trades communication cost for fault isolation. We describe Mutable Protection Domains (MPDs) in the context of our Composite operating system. MPD dynamically adapts hardware isolation between interacting software components, depending on observed communication “hot-paths,” with the purpose of maximizing fault isolation where possible. In this sense, MPD naturally tends toward a system of maximal component isolation, while collapsing protection domains where costs are prohibitive. By increasing isolation for low-cost interacting components, MPD limits the scope of impact of future unexpected faults. We demonstrate the utility of MPD using a webserver, and identify different hot-paths for different workloads that dictate adaptations to system structure. Experiments show up to 40 percent improvement in throughput compared to a statically organized system, while maintaining high-fault isolation.",1939-3520,,10.1109/TSE.2011.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5928356,Component-based;operating systems;reliability;fault isolation;performance,Kernel;Reliability;Hardware;Servers;Switches,fault tolerant computing;mobile computing;object-oriented programming;operating systems (computers),mutable protection domains;system fault isolation;software systems;mobile devices;large-scale servers;compile-time checks;offline verification methods;control flow interactions;hardware-based techniques;software -based techniques;software components;MPD;composite operating system;fault isolation;maximal component isolation;mobile computing,,4.0,,40.0,,23 Jun 2011,,,IEEE,IEEE Journals
912,913,An Approach to Checking Consistency between UML Class Model and Its Java Implementation,H. M. Chavez; W. Shen; R. B. France; B. A. Mechling; G. Li,"Computer Science, Kalamazoo, MI; Computer Science, Kalamazoo, MI; Computer Science, Fort Collins, United States; Computer Science, Kalamazoo, MI; State Key Lab. of Computer Science, Institute of Software, Beijing, China",IEEE Transactions on Software Engineering,14 Apr 2016,2016,42,4,322,344,"Model Driven Engineering (MDE) aims to expedite the software development process by providing support for transforming models to running systems. Many modeling tools provide forward engineering features, which automatically translate a model into a skeletal program that developers must complete. Inconsistencies between a design model and its implementation, however, can arise, particularly when a final implementation is developed dependently on the code from which it was generated. Manually checking that an implementation conforms to its model is a daunting task. Thus, an MDE tool that developers can use to check that implementations conform to their models can significantly improve a developer's productivity. This paper presents a model-based approach for testing whether or not an implementation satisfies the constraints imposed by its design model. Our model-based testing approach aims to efficiently reduce the test input space while supporting branch coverage criteria. To evaluate the approach's ability to uncover inconsistencies, we developed a prototypical tool and applied it to the Eclipse UML2 projects. We were able to uncover inconsistencies between the models and their implementations using the tool.",1939-3520,,10.1109/TSE.2015.2488645,National Natural Science Foundation of China; Open Project of Shanghai Key Lab. of Trustworthy Computing; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294689,Class Diagrams;UML;Java;Model checking;Class diagrams;UML;Java;model checking,Unified modeling language;Java;Software;Object oriented modeling;Testing;Semantics,,,,3.0,,43.0,,8 Oct 2015,,,IEEE,IEEE Journals
913,914,Automatic Detection of Unsafe Dynamic Component Loadings,T. Kwon; Z. Su,"University of California, Davis, Davis; University of California, Davis, Davis",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,293,313,"Dynamic loading of software components (e.g., libraries or modules) is a widely used mechanism for an improved system modularity and flexibility. Correct component resolution is critical for reliable and secure software execution. However, programming mistakes may lead to unintended or even malicious components being resolved and loaded. In particular, dynamic loading can be hijacked by placing an arbitrary file with the specified name in a directory searched before resolving the target component. Although this issue has been known for quite some time, it was not considered serious because exploiting it requires access to the local file system on the vulnerable host. Recently, such vulnerabilities have started to receive considerable attention as their remote exploitation became realistic. It is now important to detect and fix these vulnerabilities. In this paper, we present the first automated technique to detect vulnerable and unsafe dynamic component loadings. Our analysis has two phases: 1) apply dynamic binary instrumentation to collect runtime information on component loading (online phase), and 2) analyze the collected information to detect vulnerable component loadings (offline phase). For evaluation, we implemented our technique to detect vulnerable and unsafe component loadings in popular software on Microsoft Windows and Linux. Our evaluation results show that unsafe component loading is prevalent in software on both OS platforms, and it is more severe on Microsoft Windows. In particular, our tool detected more than 4,000 unsafe component loadings in our evaluation, and some can lead to remote code execution on Microsoft Windows.",1939-3520,,10.1109/TSE.2011.108,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6065738,Unsafe component loading;dynamic analysis.,Loading;Instruments;Image resolution;Operating systems;Linux;Security,Linux;object-oriented programming;operating systems (computers);security of data;software libraries;software reliability;system monitoring,automatic detection;unsafe dynamic component loadings;dynamic loading;software components;software libraries;software modules;system modularity;system flexibility;component resolution;software execution;malicious components;arbitrary file;file system;vulnerable host;remote exploitation;automated technique;vulnerable dynamic component loadings;dynamic binary instrumentation;runtime information;vulnerable component loadings;Microsoft Windows;Linux;unsafe component loading;OS platforms;remote code execution,,2.0,1.0,50.0,,1 Nov 2011,,,IEEE,IEEE Journals
914,915,Formal Specification-Based Inspection for Verification of Programs,S. Liu; Y. Chen; F. Nagoya; J. A. McDermid,"Hosei University, Koganei-shi; Shanghai Jiaotong University, Shanghai; Aoyama Gakuin University, Tokyo; University of York, York",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1100,1122,"Software inspection is a static analysis technique that is widely used for defect detection, but which suffers from a lack of rigor. In this paper, we address this problem by taking advantage of formal specification and analysis to support a systematic and rigorous inspection method. The aim of the method is to use inspection to determine whether every functional scenario defined in the specification is implemented correctly by a set of program paths and whether every program path of the program contributes to the implementation of some functional scenario in the specification. The method is comprised of five steps: deriving functional scenarios from the specification, deriving paths from the program, linking scenarios to paths, analyzing paths against the corresponding scenarios, and producing an inspection report, and allows for a systematic and automatic generation of a checklist for inspection. We present an example to show how the method can be used, and describe an experiment to evaluate its performance by comparing it to perspective-based reading (PBR). The result shows that our method may be more effective in detecting function-related defects than PBR but slightly less effective in detecting implementation-related defects. We also describe a prototype tool to demonstrate the supportability of the method, and draw some conclusions about our work.",1939-3520,,10.1109/TSE.2011.102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035726,Specification-based program inspection;software inspection;formal specification;program verification,DH-HEMTs;High definition video;Three dimensional displays,formal specification;formal verification,formal specification based inspection;program verification;software inspection;defect detection;automatic generation;systematic generation;perspective based reading;PBR;prototype tool,,21.0,,80.0,,6 Oct 2011,,,IEEE,IEEE Journals
915,916,Providing Architectural Languages and Tools Interoperability through Model Transformation Technologies,I. Malavolta; H. Muccini; P. Pelliccione; D. Tamburri,"University of L'Aquila, L'Aquila; University of L'Aquila, L'Aquila; University of L'Aquila, L'Aquila; University of L'Aquila, L'Aquila",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,119,140,"Many architectural languages have been proposed in the last 15 years, each one with the chief aim of becoming the ideal language for specifying software architectures. What is evident nowadays, instead, is that architectural languages are defined by stakeholder concerns. Capturing all such concerns within a single, narrowly focused notation is impossible. At the same time, it is also impractical to define and use a ""universal"" notation, such as UML. As a result, many domain-specific notations for architectural modeling have been proposed, each one focusing on a specific application domain, analysis type, or modeling environment. As a drawback, a proliferation of languages exists, each one with its own specific notation, tools, and domain specificity. No effective interoperability is possible to date. Therefore, if a software architect has to model a concern not supported by his own language/tool, he has to manually transform (and, eventually, keep aligned) the available architectural specification into the required language/tool. This paper presents DUALLy, an automated framework that allows architectural languages and tools interoperability. Given a number of architectural languages and tools, they can all interoperate thanks to automated model transformation techniques. DUALLy is implemented as an Eclipse plugin. Putting it in practice, we apply the DUALLy approach to the Darwin/FSP ADL and to a UML2.0 profile for software architectures. By making use of an industrial complex system, we transform a UML software architecture specification in Darwin/FSP, make some verifications by using LTSA, and reflect changes required by the verifications back to the UML specification.",1939-3520,,10.1109/TSE.2009.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5204094,Software architectures;interoperability;domain-specific architectures;design tools and techniques;model transformations.,Software architecture;Unified modeling language;Computer architecture;Application software;Software tools;Computer industry;Architecture description languages;LAN interconnection;Domain specific languages;Software systems,open systems;software architecture;Unified Modeling Language,architectural languages;tools interoperability;automated model transformation techniques;Eclipse plugin;UML2.0 profile;DUALLy approach;Darwin-FSP ADL;industrial complex system;UML software architecture specification,,49.0,,35.0,,18 Aug 2009,,,IEEE,IEEE Journals
916,917,Online Reliability Prediction via Motifs-Based Dynamic Bayesian Networks for Service-Oriented Systems,H. Wang; L. Wang; Q. Yu; Z. Zheng; A. Bouguettaya; M. R. Lyu,"School of Computer Science and Engineering and Key Laboratory of Computer Network and Information Integration, Southeast University, SIPAILOU 2, Nanjing, China; School of Computer Science and Engineering and Key Laboratory of Computer Network and Information Integration, Southeast University, SIPAILOU 2, Nanjing, China; College of Computing and Information Sciences, Rochester Institute of Technology, 102 Lomb Memorial Drive, Rochester, NY; School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China; School of Information Technologies, The University of Sydney, NSW, Australia; Department of Computer Science and Engineering, Shenzhen Research Institute, The Chinese University of Hong Kong, Shatin, Hong Kong, China",IEEE Transactions on Software Engineering,12 Jun 2017,2017,43,6,556,579,"A service-oriented System of Systems (SoS) considers a system as a service and constructs a robust and value-added SoS by outsourcing external component systems through service composition techniques. Online reliability prediction for the component systems for the purpose of assuring the overall Quality of Service (QoS) is often a major challenge in coping with a loosely coupled SoS operating under dynamic and uncertain running environments. It is also a prerequisite for guaranteeing runtime QoS of a SoS through optimal service selection for reliable system construction. We propose a novel online reliability time series prediction approach for the component systems in a service-oriented SoS. We utilize Probabilistic Graphical Models (PGMs) to yield near-future, time series predictions. We assess the approach via invocation records collected from widely used real Web services. Experimental results have confirmed the effectiveness of the approach.",1939-3520,,10.1109/TSE.2016.2615615,NSFC; Novel Software Technology and Industrialization and Wireless Communications Technology; Australian Research Council’s; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7585067,Online reliability prediction;time series;service-oriented computing;system of systems,Time series analysis;Quality of service;Web services;Throughput;Software reliability;Time factors,belief networks;service-oriented architecture,online reliability prediction;motifs-based dynamic Bayesian networks;service-oriented system of systems;service composition;component systems;quality of service;QoS;uncertain running environments;optimal service selection;reliable system construction;online reliability time series prediction;service-oriented SoS;probabilistic graphical models;PGM;time series predictions;invocation records;real Web services,,17.0,,70.0,,6 Oct 2016,,,IEEE,IEEE Journals
917,918,Enhanced Modeling and Solution of Layered Queueing Networks,G. Franks; T. Al-Omari; M. Woodside; O. Das; S. Derisavi,"Carleton University, Ottawa; IBM, Toronto; Carleton University , Ottawa; Ryerson University, Toronto; IBM, Toronto",IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,148,161,"Layered queues are a canonical form of extended queueing network for systems with nested multiple resource possession, in which successive depths of nesting define the layers. The model has been applied to most modern distributed systems, which use different kinds of client-server and master-slave relationships, and scales up well. The layered queueing network (LQN) model is described here in a unified fashion, including its many more extensions to match the semantics of sophisticated practical distributed and parallel systems. These include efficient representation of replicated services, parallel and quorum execution, and dependability analysis under failure and reconfiguration. The full LQN model is defined here and its solver is described. A substantial case study to an air traffic control system shows errors (compared to simulation) of a few percent. The LQN model is compared to other models and solutions, and is shown to cover all their features.",1939-3520,,10.1109/TSE.2008.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4620121,Performance;Modeling and prediction;Queuing theory;Performance;Modeling and prediction;Queuing theory,Network servers;Application software;File servers;Master-slave;Failure analysis;Air traffic control;Error correction;Computational modeling;Queueing analysis;Distributed computing,client-server systems;parallel processing;queueing theory,layered queueing network;canonical form;nested multiple resource possession;distributed system;client-server system;master-slave system;semantics matching;parallel system;replicated service;quorum execution;dependability analysis;air traffic control system,,88.0,,42.0,,5 Sep 2008,,,IEEE,IEEE Journals
918,919,Solving the Class Responsibility Assignment Problem in Object-Oriented Analysis with Multi-Objective Genetic Algorithms,M. Bowman; L. C. Briand; Y. Labiche,"Carleton University, Ottawa; Simula Research Laboratory, Lysaker and University of Oslo, Norway; Carleton University, Ottawa",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,817,837,"In the context of object-oriented analysis and design (OOAD), class responsibility assignment is not an easy skill to acquire. Though there are many methodologies for assigning responsibilities to classes, they all rely on human judgment and decision making. Our objective is to provide decision-making support to reassign methods and attributes to classes in a class diagram. Our solution is based on a multi-objective genetic algorithm (MOGA) and uses class coupling and cohesion measurement for defining fitness functions. Our MOGA takes as input a class diagram to be optimized and suggests possible improvements to it. The choice of a MOGA stems from the fact that there are typically many evaluation criteria that cannot be easily combined into one objective, and several alternative solutions are acceptable for a given OO domain model. Using a carefully selected case study, this paper investigates the application of our proposed MOGA to the class responsibility assignment problem, in the context of object-oriented analysis and domain class models. Our results suggest that the MOGA can help correct suboptimal class responsibility assignment decisions and perform far better than simpler alternative heuristics such as hill climbing and a single-objective GA.",1939-3520,,10.1109/TSE.2010.70,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5530324,Object-oriented analysis and design;class responsibility assignment;UML;genetic algorithm.,Algorithm design and analysis;Genetic algorithms;Object oriented modeling;Context modeling;Unified modeling language;Decision making;Humans;Software quality;Genetic engineering;Laboratories,decision making;genetic algorithms;object-oriented methods,class responsibility assignment problem;object-oriented analysis;multiobjective genetic algorithm;object-oriented design;decision making support;class coupling;cohesion measurement;class diagram;object-oriented domain model;domain class model;hill climbing;single-objective genetic algorithm,,56.0,,40.0,,29 Jul 2010,,,IEEE,IEEE Journals
919,920,"First, Debug the Test Oracle",X. Guo; M. Zhou; X. Song; M. Gu; J. Sun,"School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China; Department of Electrical and Computer Engineering, Portland State University, Portland, OR; School of Software, Tsinghua University, Beijing, China; School of Software, Tsinghua University, Beijing, China",IEEE Transactions on Software Engineering,13 Oct 2015,2015,41,10,986,1000,"Opposing to the oracle assumption, a trustworthy test oracle is not always available in real practice. Since manually written oracles and human judgements are still widely used, testers and programmers are in fact facing a high risk of erroneous test oracles. However, test oracle errors can bring much confusion thus causing extra time consumption in the debugging process. As substantiated by our experiment on the Siemens Test Suite, automatic fault localization algorithms suffer severely from erroneous test oracles, which impede them from reducing debugging time to the full extent. This paper proposes a simple but effective approach to debug the test oracle. Based on the observation that test cases covering similar lines of code usually generate similar results, we are able to identify suspicious test cases that are differently judged by the test oracle from their neighbors. To validate the effectiveness of our approach, experiments are conducted on both the Siemens Test Suite and grep. The results show that averagely over 75 percent of the highlighted test cases are actually test oracle errors. Moreover, performance of fault localization algorithms recovered remarkably with the debugged oracles.",1939-3520,,10.1109/TSE.2015.2425392,NSFC Program; National Key Technologies R&D Program; Postdoctoral Science Foundation of China; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7091939,test oracle;debugging;spectrum-based fault localization;Test oracle;debugging;spectrum-based fault localization,Accuracy;Debugging;Measurement;Manuals;Error analysis;Software;Algorithm design and analysis,fault diagnosis;program debugging;program testing,test oracle debugging;oracle error testing;Siemens Test Suite;automatic fault localization algorithm,,3.0,,34.0,,22 Apr 2015,,,IEEE,IEEE Journals
920,921,Automating Live Update for Generic Server Programs,C. Giuffrida; C. Iorgulescu; G. Tamburrelli; A. S. Tanenbaum,"Vrije Universiteit Amsterdam, De Boelelaan, Amsterdam, Netherlands; École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland; Vrije Universiteit Amsterdam, De Boelelaan, Amsterdam, Netherlands; Vrije Universiteit Amsterdam, De Boelelaan, Amsterdam, Netherlands",IEEE Transactions on Software Engineering,14 Mar 2017,2017,43,3,207,225,"The pressing demand to deploy software updates without stopping running programs has fostered much research on live update systems in the past decades. Prior solutions, however, either make strong assumptions on the nature of the update or require extensive and error-prone manual effort, factors which discourage the adoption of live update. This paper presents Mutable Checkpoint-Restart (MCR), a new live update solution for generic (multiprocess and multithreaded) server programs written in C. Compared to prior solutions, MCR can support arbitrary software updates and automate most of the common live update operations. The key idea is to allow the running version to safely reach a quiescent state and then allow the new version to restart as similarly to a fresh program initialization as possible, relying on existing code paths to automatically restore the old program threads and reinitialize a relevant portion of the program data structures. To transfer the remaining data structures, MCR relies on a combination of precise and conservative garbage collection techniques to trace all the global pointers and apply the required state transformations on the fly. Experimental results on popular server programs (Apache httpd, nginx, OpenSSH and vsftpd) confirm that our techniques can effectively automate problems previously deemed difficult at the cost of negligible performance overhead (2 percent on average) and moderate memory overhead (3.9$\times$  on average, without optimizations).",1939-3520,,10.1109/TSE.2016.2584066,European Research Council; ERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7497481,Live update;DSU;checkpoint-restart;quiescence detection;record-replay;garbage collection,Servers;Data structures;Convergence;Software;Manuals;System recovery;Buildings,,,,5.0,,57.0,,22 Jun 2016,,,IEEE,IEEE Journals
921,922,"Conservative Bounds for the pfd of a 1-out-of-2 Software-Based System Based on an Assessor's Subjective Probability of ""Not Worse Than Independence""",B. Littlewood; A. Povyakalo,"City University, London, London; City University, London, London",IEEE Transactions on Software Engineering,22 Nov 2013,2013,39,12,1641,1653,"We consider the problem of assessing the reliability of a 1-out-of-2 software-based system, in which failures of the two channels cannot be assumed to be independent with certainty. An informal approach to this problem assesses the channel probabilities of failure on demand (pfds) conservatively, and then multiplies these together in the hope that the conservatism will be sufficient to overcome any possible dependence between the channel failures. Our intention here is to place this kind of reasoning on a formal footing. We introduce a notion of ""not worse than independence""' and assume that an assessor has a prior belief about this, expressed as a probability. We obtain a conservative prior system pfd, and show how a conservative posterior system pfd can be obtained following the observation of a number of demands without system failure. We present some illustrative numerical examples, discuss some of the difficulties involved in this way of reasoning, and suggest some avenues of future research.",1939-3520,,10.1109/TSE.2013.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6564279,System reliability;software fault tolerance;1-out-of-2 system;dependent failures;subjective probability,Phase frequency detector;Cognition;Software reliability;Fault tolerant systems;Software reliability;Reliability engineering;Failure analysis,probability;software reliability,conservative bounds;1-out-of-2 software-based system reliability;assessor subjective probability;channel probabilities of failure on demand;formal footing;not worse than independence;conservative posterior system PFD,,6.0,,14.0,,19 Jul 2013,,,IEEE,IEEE Journals
922,923,Multi-Objective Quality-Driven Service Selection—A Fully Polynomial Time Approximation Scheme,I. Trummer; B. Faltings; W. Binder,"Artificial Intelligence Laboratory , École Polytechnique Fédérale de Lausanne, Switzerland; Artificial Intelligence Laboratory , École Polytechnique Fédérale de Lausanne, Switzerland; Faculty of Informatics, University of Lugano, Via Giuseppe Buffi 13, Switzerland",IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,2,167,191,"The goal of multi-objective quality-driven service selection (QDSS) is to find service selections for a workflow whose quality-of-service (QoS) values are Pareto-optimal. We consider multiple QoS attributes such as response time, cost, and reliability. A selection is Pareto-optimal if no other selection has better QoS values for some attributes and at least equivalent values for all others. Exact algorithms have been proposed that find all Pareto-optimal selections. They suffer however from exponential complexity. Randomized algorithms scale well but do not offer any formal guarantees on result precision. We present the first approximation scheme for QDSS. It aims at the sweet spot between exact and randomized algorithms: It combines polynomial complexity with formal result precision guarantees. A parameter allows to seamlessly trade result precision against efficiency. We formally analyze complexity and precision guarantees and experimentally compare our algorithm against exact and randomized approaches. Comparing with exact algorithms, our approximation scheme allows to reduce optimization time from hours to seconds. Its approximation error remains below 1.4 percent while randomized algorithms come close to the theoretical maximum.",1939-3520,,10.1109/TSE.2013.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6687160,Quality-driven service selection;multi-objective optimization;approximation algorithms,Quality of service;Approximation methods;Approximation algorithms;Polynomials;Complexity theory;Optimization;Motion pictures,Pareto optimisation;polynomial approximation;quality of service;software quality,approximation error;optimization time;polynomial complexity;randomized algorithms;exponential complexity;Pareto optimal selections;least equivalent values;QoS values;Pareto optimal;quality-of-service;QDSS;fully polynomial time approximation scheme;multiobjective quality driven service selection,,35.0,,35.0,,18 Dec 2013,,,IEEE,IEEE Journals
923,924,You Are the Only Possible Oracle: Effective Test Selection for End Users of Interactive Machine Learning Systems,A. Groce; T. Kulesza; C. Zhang; S. Shamasunder; M. Burnett; W. -K. Wong; S. Stumpf; S. Das; A. Shinsel; F. Bice; K. McIntosh,"School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; Centre for HCI Design, School of Informatics, City University London, London, United Kingdom; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis; School of Electrical Engineering and Computer Science, Oregon State University, Corvallis",IEEE Transactions on Software Engineering,31 Mar 2014,2014,40,3,307,323,"How do you test a program when only a single user, with no expertise in software testing, is able to determine if the program is performing correctly? Such programs are common today in the form of machine-learned classifiers. We consider the problem of testing this common kind of machine-generated program when the only oracle is an end user: e.g., only you can determine if your email is properly filed. We present test selection methods that provide very good failure rates even for small test suites, and show that these methods work in both large-scale random experiments using a “gold standard” and in studies with real users. Our methods are inexpensive and largely algorithm-independent. Key to our methods is an exploitation of properties of classifiers that is not possible in traditional software testing. Our results suggest that it is plausible for time-pressured end users to interactively detect failures-even very hard-to-find failures-without wading through a large number of successful (and thus less useful) tests. We additionally show that some methods are able to find the arguably most difficult-to-detect faults of classifiers: cases where machine learning algorithms have high confidence in an incorrect result.",1939-3520,,10.1109/TSE.2013.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6682887,Machine learning;end-user testing;test suite size,Testing;Software;Training;Training data;Electronic mail;Software algorithms;Machine learning algorithms,interactive systems;learning (artificial intelligence);program testing,effective test selection;interactive machine learning systems;end users;program testing;software testing;machine learned classifiers;machine generated program;email;hard-to-find failures;interactive failure detection,,16.0,,63.0,,12 Dec 2013,,,IEEE,IEEE Journals
924,925,"A Two-Component Language for Adaptation: Design, Semantics and Program Analysis",P. Degano; G. Ferrari; L. Galletta,"Dipartimento di Informatica, Università di Pisa, Pisa, Italia; Dipartimento di Informatica, Università di Pisa, Pisa, Italia; Dipartimento di Informatica, Università di Pisa, Pisa, Italia",IEEE Transactions on Software Engineering,10 Jun 2016,2016,42,6,505,529,"Adaptive systems are designed to modify their behaviour in response to changes of their operational environment. We propose a two-component language for adaptive programming, within the Context-Oriented Programming paradigm. It has a declarative constituent for programming the context and a functional one for computing. We equip our language with a dynamic formal semantics. Since wrong adaptation could severely compromise the correct behaviour of applications and violate their properties, we also introduce a two-phase verification mechanism. It is based on a type and effect system that type-checks programs and computes, as an effect, a sound approximation of their behaviour. The effect is exploited at load time to mechanically verify that programs correctly adapt themselves to all possible running environments.",1939-3520,,10.1109/TSE.2015.2496941,MIUR Prin Project; Università di Pisa PRA project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7314969,Adaptive Software;Context Oriented Programming;Formal Methods;Datalog;Functional Programming;Semantics;Type Systems;Verification;Adaptive software;context oriented programming;formal methods;datalog;functional programming;semantics;type systems;verification,Context;Programming;Software;Semantics;Standards;Adaptation models;Computer languages,high level languages;program diagnostics;program verification,two-component language;program analysis;adaptive programming;context-oriented programming paradigm;dynamic formal semantics;two-phase verification mechanism;program type-check,,9.0,,95.0,,2 Nov 2015,,,IEEE,IEEE Journals
925,926,GenProg: A Generic Method for Automatic Software Repair,C. Le Goues; T. Nguyen; S. Forrest; W. Weimer,"University of Virginia, Charlottesville; University of New Mexico, Albuquerque; University of New Mexico, Albuquerque; University of Virginia, Charlottesville",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,54,72,"This paper describes GenProg, an automated method for repairing defects in off-the-shelf, legacy programs without formal specifications, program annotations, or special coding practices. GenProg uses an extended form of genetic programming to evolve a program variant that retains required functionality but is not susceptible to a given defect, using existing test suites to encode both the defect and required functionality. Structural differencing algorithms and delta debugging reduce the difference between this variant and the original program to a minimal repair. We describe the algorithm and report experimental results of its success on 16 programs totaling 1.25 M lines of C code and 120K lines of module code, spanning eight classes of defects, in 357 seconds, on average. We analyze the generated repairs qualitatively and quantitatively to demonstrate that the process efficiently produces evolved programs that repair the defect, are not fragile input memorizations, and do not lead to serious degradation in functionality.",1939-3520,,10.1109/TSE.2011.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6035728,Automatic programming;corrections;testing and debugging.,Maintenance engineering;Encoding;Computer bugs;Automatic programming;Debugging;Syntactics,formal specification;genetic algorithms;software maintenance,GenProg;automatic software repair;defects repair;legacy programs;formal specifications;program annotations;special coding practices;genetic programming,,350.0,4.0,75.0,,6 Oct 2011,,,IEEE,IEEE Journals
926,927,Autofolding for Source Code Summarization,J. Fowkes; P. Chanthirasegaran; R. Ranca; M. Allamanis; M. Lapata; C. Sutton,"School of Informatics, University of Edinburgh, Edinburgh, UK; School of Informatics, University of Edinburgh, Edinburgh, UK; Tractable, Oval Office, London, UK; School of Informatics, University of Edinburgh, Edinburgh, UK; School of Informatics, University of Edinburgh, Edinburgh, UK; School of Informatics, University of Edinburgh, Edinburgh, UK",IEEE Transactions on Software Engineering,8 Dec 2017,2017,43,12,1095,1109,"Developers spend much of their time reading and browsing source code, raising new opportunities for summarization methods. Indeed, modern code editors provide code folding, which allows one to selectively hide blocks of code. However this is impractical to use as folding decisions must be made manually or based on simple rules. We introduce the autofolding problem, which is to automatically create a code summary by folding less informative code regions. We present a novel solution by formulating the problem as a sequence of AST folding decisions, leveraging a scoped topic model for code tokens. On an annotated set of popular open source projects, we show that our summarizer outperforms simpler baselines, yielding a 28 percent error reduction. Furthermore, we find through a case study that our summarizer is strongly preferred by experienced developers. More broadly, we hope this work will aid program comprehension by turning code folding into a usable and valuable tool.",1939-3520,,10.1109/TSE.2017.2664836,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7843666,"Source code summarization, program comprehension, topic modelling",Software development;Natural languages;Source coding;Feature extraction;Complexity theory,public domain software;source code (software),source code summarization;modern code editors;code folding;autofolding problem;informative code regions;AST folding decisions;code tokens;open source projects,,6.0,,62.0,Traditional,6 Feb 2017,,,IEEE,IEEE Journals
927,928,Generating Domain-Specific Visual Language Tools from Abstract Visual Specifications,J. C. Grundy; J. Hosking; K. N. Li; N. M. Ali; J. Huh; R. L. Li,"Swinburne University University of Technology, Hawthorn; Australian National University, Canberra; SolNet Solutions Ltd, Wellington; Universiti Putra Malaysia, Kuala Lumpur; University of Auckland, Auckland; Beefand Lamb New Zealand Ltd, Wellington",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,487,515,"Domain-specific visual languages support high-level modeling for a wide range of application domains. However, building tools to support such languages is very challenging. We describe a set of key conceptual requirements for such tools and our approach to addressing these requirements, a set of visual language-based metatools. These support definition of metamodels, visual notations, views, modeling behaviors, design critics, and model transformations and provide a platform to realize target visual modeling tools. Extensions support collaborative work, human-centric tool interaction, and multiplatform deployment. We illustrate application of the metatoolset on tools developed with our approach. We describe tool developer and cognitive evaluations of our platform and our exemplar tools, and summarize key future research directions.",1939-3520,,10.1109/TSE.2012.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6205768,Metatool;domain-specific visual language;software tool;visual specification;model-driven engineering,Visualization;Unified modeling language;Software;Computational modeling;Business;Abstracts;Electronic mail,cognition;formal specification;groupware;simulation languages;software tools;visual languages;visual programming,domain-specific visual language tool generation;abstract visual specifications;high-level modeling;application domains;conceptual requirements;visual language-based metatools;metamodels;visual notations;modeling behaviors;design critics;model transformations;visual modeling tools;collaborative work;human-centric tool interaction;multiplatform deployment;cognitive evaluations,,18.0,,79.0,,29 May 2012,,,IEEE,IEEE Journals
928,929,An Extensible Framework for Improving a Distributed Software System's Deployment Architecture,S. Malek; N. Medvidovic; M. Mikic-Rakic,"George Mason University, Fairfax; University of Southern California, Los Angeles; Google Inc., Santa Monica",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,73,100,"A distributed system's allocation of software components to hardware nodes (i.e., deployment architecture) can have a significant impact on its quality of service (QoS). For a given system, there may be many deployment architectures that provide the same functionality, but with different levels of QoS. The parameters that influence the quality of a system's deployment architecture are often not known before the system's initial deployment and may change at runtime. This means that redeployment of the software system may be necessary to improve the system's QoS properties. This paper presents and evaluates a framework aimed at finding the most appropriate deployment architecture for a distributed software system with respect to multiple, possibly conflicting QoS dimensions. The framework supports formal modeling of the problem and provides a set of tailorable algorithms for improving a system's deployment. We have realized the framework on top of a visual deployment architecture modeling and analysis environment. The framework has been evaluated for precision and execution-time complexity on a large number of simulated distributed system scenarios, as well as in the context of two third-party families of distributed applications.",1939-3520,,10.1109/TSE.2011.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680912,Software architecture;software deployment;quality of service;self-adaptive software.,Software architecture;Quality of service;Distributed processing,computational complexity;distributed processing;object-oriented methods;quality of service;resource allocation,extensible framework;distributed software system;software component allocation;hardware nodes;quality of service;QoS;tailorable algorithms;system deployment;visual deployment architecture modeling environment;visual deployment architecture analysis environment;precision-time complexity;execution-time complexity,,52.0,1.0,66.0,,6 Jan 2011,,,IEEE,IEEE Journals
929,930,Language Inclusion Checking of Timed Automata with Non-Zenoness,X. Wang; J. Sun; T. Wang; S. Qin,"College of Computer Science, Zhejiang University, Hangzhou, P.R. China; Shenzhen University; College of Computer Science, Zhejiang University of Technology, Hangzhou, P.R. China; School of Computing, Teesside University, Middlesbrough, United Kingdom",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,995,1008,"Given a timed automaton P modeling an implementation and a timed automaton S as a specification, the problem of language inclusion checking is to decide whether the language of P is a subset of that of S. It is known to be undecidable. The problem gets more complicated if non-Zenoness is taken into consideration. A run is Zeno if it permits infinitely many actions within finite time. Otherwise it is non-Zeno. Zeno runs might present in both P and S. It is necessary to check whether a run is Zeno or not so as to avoid presenting Zeno runs as counterexamples of language inclusion checking. In this work, we propose a zone-based semi-algorithm for language inclusion checking with non-Zenoness. It is further improved with simulation reduction based on LU-simulation. Though our approach is not guaranteed to terminate, we show that it does in many cases through empirical study. Our approach has been incorporated into the PAT model checker, and applied to multiple systems to show its usefulness.",1939-3520,,10.1109/TSE.2017.2653778,National Natural Science Foundation of China; Singapore University of Technology and Design; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819478,Timed automata;language inclusion;non-Zenoness,Automata;Clocks;Safety;Analytical models;Sun;Real-time systems;Semantics,automata theory;formal specification;formal verification,timed automata;language inclusion checking;nonZenoness;finite time;timed automaton modeling;specification;undecidability;zone-based semi-algorithm;simulation reduction;LU-simulation;PAT model checker,,,,40.0,Traditional,16 Jan 2017,,,IEEE,IEEE Journals
930,931,Self-Adapting Reliability in Distributed Software Systems,Y. Brun; J. y. Bang; G. Edwards; N. Medvidovic,"School of Computer Science, University of Massachusetts, Amherst, MA; Computer Science Department, University of Southern California, Los Angeles, CA; Computer Science Department, University of Southern California, Los Angeles, CA; Computer Science Department, University of Southern California, Los Angeles, CA",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,764,780,"Developing modern distributed software systems is difficult in part because they have little control over the environments in which they execute. For example, hardware and software resources on which these systems rely may fail or become compromised and malicious. Redundancy can help manage such failures and compromises, but when faced with dynamic, unpredictable resources and attackers, the system reliability can still fluctuate greatly. Empowering the system with self-adaptive and self-managing reliability facilities can significantly improve the quality of the software system and reduce reliance on the developer predicting all possible failure conditions. We present iterative redundancy, a novel approach to improving software system reliability by automatically injecting redundancy into the system's deployment. Iterative redundancy self-adapts in three ways: (1) by automatically detecting when the resource reliability drops, (2) by identifying unlucky parts of the computation that happen to deploy on disproportionately many compromised resources, and (3) by not relying on a priori estimates of resource reliability. Further, iterative redundancy is theoretically optimal in its resource use: Given a set of resources, iterative redundancy guarantees to use those resources to produce the most reliable version of that software system possible; likewise, given a desired increase in the system's reliability, iterative redundancy guarantees achieving that reliability using the least resources possible. Iterative redundancy handles even the Byzantine threat model, in which compromised resources collude to attack the system. We evaluate iterative redundancy in three ways. First, we formally prove its self-adaptation, efficiency, and optimality properties. Second, we simulate it at scale using discrete event simulation. Finally, we modify the existing, open-source, volunteer-computing BOINC software system and deploy it on the globally-distributed PlanetLab testbed network to empirically evaluate that iterative redundancy is self-adaptive and more efficient than existing techniques.",1939-3520,,10.1109/TSE.2015.2412134,DARPA; IARPA; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058381,Redundancy;reliability;fault-tolerance;iterative redundancy;self-adaptation;optimal redundancy;Redundancy;reliability;fault-tolerance;iterative redundancy;self-adaptation;optimal redundancy,Redundancy;Software reliability;Software systems;Computational modeling;Servers;Reliability engineering,discrete event simulation;distributed processing;public domain software;resource allocation;security of data;software quality;software reliability;system recovery,self-adapting reliability;distributed software systems;hardware resources;software resources;failure management;compromise management;dynamic unpredictable resources;system reliability;self-adaptive reliability;self-managing reliability;software system quality;failure condition;iterative redundancy;resource reliability estimate;Byzantine threat model;compromised resource collusion;optimality property;discrete event simulation;open-source volunteer-computing BOINC software system;globally-distributed PlanetLab testbed network,,7.0,,53.0,,11 Mar 2015,,,IEEE,IEEE Journals
931,932,Active learning and effort estimation: Finding the essential content of software effort estimation data,E. Kocaguneli; T. Menzies; J. Keung; D. Cok; R. Madachy,"West Virginia University, Morgantown; West Virginia University, Morgantown; The City University of Hong Kong, Hong Kong; Grammatech Inc., Ithaca; Naval Postgraduate School, Monterrey",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1040,1053,"Background: Do we always need complex methods for software effort estimation (SEE)? Aim: To characterize the essential content of SEE data, i.e., the least number of features and instances required to capture the information within SEE data. If the essential content is very small, then 1) the contained information must be very brief and 2) the value added of complex learning schemes must be minimal. Method: Our QUICK method computes the euclidean distance between rows (instances) and columns (features) of SEE data, then prunes synonyms (similar features) and outliers (distant instances), then assesses the reduced data by comparing predictions from 1) a simple learner using the reduced data and 2) a state-of-the-art learner (CART) using all data. Performance is measured using hold-out experiments and expressed in terms of mean and median MRE, MAR, PRED(25), MBRE, MIBRE, or MMER. Results: For 18 datasets, QUICK pruned 69 to 96 percent of the training data (median = 89 percent). K = 1 nearest neighbor predictions (in the reduced data) performed as well as CART's predictions (using all data). Conclusion: The essential content of some SEE datasets is very small. Complex estimation methods may be overelaborate for such datasets and can be simplified. We offer QUICK as an example of such a simpler SEE method.",1939-3520,,10.1109/TSE.2012.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6392173,Software cost estimation;active learning;analogy;k-NN,Estimation;Indexes;Labeling;Frequency selective surfaces;Euclidean distance;Complexity theory;Principal component analysis,data handling;learning (artificial intelligence);software cost estimation;statistical analysis,software effort estimation;SEE data content;complex learning scheme;QUICK method;Euclidean distance;CART learner;mean;median;K-nearest neighbor prediction,,42.0,,50.0,,21 Dec 2012,,,IEEE,IEEE Journals
932,933,Reducing Feedback Delay of Software Development Tools via Continuous Analysis,K. Muşlu; Y. Brun; M. D. Ernst; D. Notkin,"Department of Computer Science & Engineering, University of Washington, Seattle, WA; School of Computer Science, University of Massachusetts, Amherst, MA; Department of Computer Science & Engineering, University of Washington, Seattle, WA; Department of Computer Science & Engineering, University of Washington, Seattle, WA",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,745,763,"During software development, the sooner a developer learns how code changes affect program analysis results, the more helpful that analysis is. Manually invoking an analysis may interrupt the developer's workflow or cause a delay before the developer learns the implications of the change. A better approach is continuous analysis tools that always provide up-to-date results. We present Codebase Replication, a technique that eases the implementation of continuous analysis tools by converting an existing offline analysis into an IDE-integrated, continuous tool with two desirable properties: isolation and currency. Codebase Replication creates and keeps in sync a copy of the developer's codebase. The analysis runs on the copy codebase without disturbing the developer and without being disturbed by the developer's changes. We developed Solstice, an open-source, publicly-available Eclipse plug-in that implements Codebase Replication. Solstice has less than 2.5 milliseconds overhead for most common developer actions. We used Solstice to implement four Eclipse-integrated continuous analysis tools based on the offline versions of FindBugs, PMD, data race detection, and unit testing. Each conversion required on average 710 LoC and 20 hours of implementation effort. Case studies indicate that Solstice-based continuous analysis tools are intuitive and easy-to-use.",1939-3520,,10.1109/TSE.2015.2417161,NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7069257,Continuous analysis;Codebase Replication;Solstice;Continuous analysis;Codebase Replication;Solstice,Delays;Software;Testing;Servers;Synchronization;Electronic mail;Interrupters,program diagnostics;program testing;software tools,feedback delay reduction;software development tools;program analysis;codebase replication;offline analysis;IDE-integrated;Solstice;open-source Eclipse plug-in;Eclipse-integrated continuous analysis tools;FindBugs;PMD;data race detection;unit testing,,6.0,,80.0,,26 Mar 2015,,,IEEE,IEEE Journals
933,934,"Light-Weight, Inter-Procedural and Callback-Aware Resource Leak Detection for Android Apps",T. Wu; J. Liu; Z. Xu; C. Guo; Y. Zhang; J. Yan; J. Zhang,"State Key Laboratory of Computer ScienceInstitute of SoftwareChinese Academy of Sciences; State Key Laboratory of Computer ScienceInstitute of SoftwareChinese Academy of Sciences; State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China; State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China; State Key Lab. of Comput. Sci., Inst. of Software, Beijing, China; State Key Laboratory of Computer ScienceInstitute of SoftwareChinese Academy of Sciences; State Key Laboratory of Computer ScienceInstitute of SoftwareChinese Academy of Sciences",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,1054,1076,"Android devices include many embedded resources such as Camera, Media Player and Sensors. These resources require programmers to explicitly request and release them. Missing release operations might cause serious problems such as performance degradation or system crash. This kind of defects is called resource leak. Despite a large body of existing works on testing and analyzing Android apps, there still remain several challenging problems. In this work, we present Relda2, a light-weight and precise static resource leak detection tool. We first systematically collected a resource table, which includes the resources that the Android reference requires developers release manually. Based on this table, we designed a general approach to automatically detect resource leaks. To make a more precise inter-procedural analysis, we construct a Function Call Graph for each Android application, which handles function calls of user-defined methods and the callbacks invoked by the Android framework at the same time. To evaluate Relda2's effectiveness and practical applicability, we downloaded 103 apps from popular app stores and an open source community, and found 67 real resource leaks, which we have confirmed manually.",1939-3520,,10.1109/TSE.2016.2547385,National Basic Research (973); National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7442579,Android apps;resource leak;static analysis;byte-code analysis;inter-procedural analysis,Androids;Humanoid robots;Smart phones;Java;Testing;Leak detection;Computer bugs,Android (operating system);embedded systems;graph theory;program diagnostics;resource allocation,Android application;embedded resources;Relda2;interprocedural analysis;function call graph;static analysis;callback-aware resource leak detection tool,,24.0,,74.0,,28 Mar 2016,,,IEEE,IEEE Journals
934,935,Solving the Large Scale Next Release Problem with a Backbone-Based Multilevel Algorithm,J. Xuan; H. Jiang; Z. Ren; Z. Luo,"Dalian University of Technology, Dalian; Dalian University of Technology, Dalian; Dalian University of Technology, Dalian; Dalian University of Technology, Dalian",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1195,1212,"The Next Release Problem (NRP) aims to optimize customer profits and requirements selection for the software releases. The research on the NRP is restricted by the growing scale of requirements. In this paper, we propose a Backbone-based Multilevel Algorithm (BMA) to address the large scale NRP. In contrast to direct solving approaches, the BMA employs multilevel reductions to downgrade the problem scale and multilevel refinements to construct the final optimal set of customers. In both reductions and refinements, the backbone is built to fix the common part of the optimal customers. Since it is intractable to extract the backbone in practice, the approximate backbone is employed for the instance reduction while the soft backbone is proposed to augment the backbone application. In the experiments, to cope with the lack of open large requirements databases, we propose a method to extract instances from open bug repositories. Experimental results on 15 classic instances and 24 realistic instances demonstrate that the BMA can achieve better solutions on the large scale NRP instances than direct solving approaches. Our work provides a reduction approach for solving large scale problems in search-based requirements engineering.",1939-3520,,10.1109/TSE.2011.92,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6261327,The next release problem;backbone;soft backbone;multilevel algorithm;requirements instance generation;search-based requirements engineering,Approximation algorithms;Software;Software algorithms;Algorithm design and analysis;Optimization;Polynomials;Search problems,customer services;formal specification;program debugging;software development management;systems analysis,large scale next release problem;backbone-based multilevel algorithm;customer profit optimization;requirements selection;software releases;BMA;multilevel reductions;optimal customers;instance reduction;soft backbone;open large requirements databases;open bug repositories;large scale NRP instances;search-based requirements engineering;backbone extraction,,44.0,,69.0,,6 Aug 2012,,,IEEE,IEEE Journals
935,936,Engineering Adaptive Model-Driven User Interfaces,P. A. Akiki; A. K. Bandara; Y. Yu,"Department of Computer Science, Notre Dame University—Louaize, Zouk Mosbeh, Lebanon; Computing and Communications Department, The Open University, Walton Hall, Milton Keynes, United Kingdom; Computing and Communications Department, The Open University, Walton Hall, Milton Keynes, United Kingdom",IEEE Transactions on Software Engineering,8 Dec 2016,2016,42,12,1118,1147,"Software applications that are very large-scale, can encompass hundreds of complex user interfaces (UIs). Such applications are commonly sold as feature-bloated off-the-shelf products to be used by people with variable needs in the required features and layout preferences. Although many UI adaptation approaches were proposed, several gaps and limitations including: extensibility and integration in legacy systems, still need to be addressed in the state-of-the-art adaptive UI development systems. This paper presents Role-Based UI Simplification (RBUIS) as a mechanism for increasing usability through adaptive behavior by providing end-users with a minimal feature-set and an optimal layout, based on the context-of-use. RBUIS uses an interpreted runtime model-driven approach based on the Cedar Architecture, and is supported by the integrated development environment (IDE), Cedar Studio. RBUIS was evaluated by integrating it into OFBiz, an open-source ERP system. The integration method was assessed and measured by establishing and applying technical metrics. Afterwards, a usability study was carried out to evaluate whether UIs simplified with RBUIS show an improvement over their initial counterparts. This study leveraged questionnaires, checking task completion times and output quality, and eye-tracking. The results showed that UIs simplified with RBUIS significantly improve end-user efficiency, effectiveness, and perceived usability.",1939-3520,,10.1109/TSE.2016.2553035,Computing and Communications Department; The Open University; ERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7451279,Design tools and techniques;software architectures;support for adaptation;user interfaces,Adaptation models;Adaptive systems;User interfaces;Usability;Computer architecture,ergonomics;programming environments;software architecture;software maintenance;user interfaces,IDE;integrated development environment;Cedar architecture;adaptive behavior;system usability;RBUIS;role-based UI simplification;legacy system integration;legacy system extensibility;engineering adaptive model-driven user interface,,15.0,,85.0,,12 Apr 2016,,,IEEE,IEEE Journals
936,937,On the Composability of Design Patterns,H. Zhu; I. Bayley,"Oxford Brookes University, Oxford, United Kingdom; Oxford Brookes University, Oxford, United Kingdom",IEEE Transactions on Software Engineering,10 Nov 2015,2015,41,11,1138,1152,"In real applications, design patterns are almost always to be found composed with each other. It is crucial that these compositions be validated. This paper examines the notion of validity, and develops a formal method for proving or disproving it, in a context where composition is performed with formally defined operators on formally specified patterns. In particular, for validity, we require that pattern compositions preserve the features, semantics and soundness of the composed patterns. The application of the theory is demonstrated by a formal analysis of overlap-based pattern compositions and a case study of a real pattern-oriented software design.",1939-3520,,10.1109/TSE.2015.2445341,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7123660,Design Patterns;Pattern composition;Composibility;Feature preservation;Semantics preservation;Soundness preservation;Formal methods;Design patterns;pattern composition;composibility;feature preservation;semantics preservation;soundness preservation;formal methods,Semantics;Unified modeling language;Context;Software systems;Software design;Cognition,formal specification;object-oriented methods,design pattern composability;formally specified patterns;formal analysis method;overlap-based pattern compositions;pattern-oriented software design,,9.0,,70.0,,15 Jun 2015,,,IEEE,IEEE Journals
937,938,Session Reliability of Web Systems under Heavy-Tailed Workloads: An Approach Based on Design and Analysis of Experiments,N. Janevski; K. Goseva-Popstojanova,"West Virginia University, Morgantown; West Virginia University, Morgantown",IEEE Transactions on Software Engineering,25 Jul 2013,2013,39,8,1157,1178,"While workload characterization and performance of web systems have been studied extensively, reliability has received much less attention. In this paper, we propose a framework for session reliability modeling which integrates the user view represented by the session layer and the system view represented by the service layer. A unique characteristic of the session layer is that, in addition to the user navigation patterns, it incorporates the session length in number of requests and allows us to account for heavy-tailed workloads shown to exist in real web systems. The service layer is focused on the request reliability as it is observed at the service provider side. It considers the multifier web server architecture and the way components interact in serving each request. Within this framework, we develop a session reliability model and solve it using simulation. Instead of the traditional one-factor-at-a-time sensitivity analysis, we use statistical design and analysis of experiments, which allow us to identify the factors and interactions that have statistically significant effect on session reliability. Our findings indicate that session reliability, which accounts for the distribution of failed requests within sessions, provides better representation of the user perceived quality than the request-based reliability.",1939-3520,,10.1109/TSE.2013.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6409359,Reliability;statistical methods;modeling and prediction;simulation;web servers;Internet applications,Software reliability;Availability;Navigation;Web servers;Reliability engineering;Analytical models,design of experiments;Internet;sensitivity analysis;user interfaces,session reliability;Web system;design-of-experiment;analysis-of-experiment;workload characterization;user view;session layer;system view;service layer;user navigation pattern;heavy-tailed workload;request reliability;multifier Web server architecture;sensitivity analysis;user perceived quality;request-based reliability,,4.0,,58.0,,10 Jan 2013,,,IEEE,IEEE Journals
938,939,An Analysis and Survey of the Development of Mutation Testing,Y. Jia; M. Harman,"University College London, London; University College London, London",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,649,678,"Mutation Testing is a fault-based software testing technique that has been widely studied for over three decades. The literature on Mutation Testing has contributed a set of approaches, tools, developments, and empirical results. This paper provides a comprehensive analysis and survey of Mutation Testing. The paper also presents the results of several development trend analyses. These analyses provide evidence that Mutation Testing techniques and tools are reaching a state of maturity and applicability, while the topic of Mutation Testing itself is the subject of increasing interest.",1939-3520,,10.1109/TSE.2010.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487526,Mutation testing;survey.,Genetic mutations;Software testing;Fault detection;History;Books;Programming profession;Computer languages;Java;Educational institutions;Automata,fault diagnosis;program testing,mutation testing development;fault-based software testing technique;empirical results;comprehensive analysis;development trend analysis;mutation testing technique;mutation testing tool,,684.0,1.0,264.0,,17 Jun 2010,,,IEEE,IEEE Journals
939,940,Static Fault Localization in Model Transformations,L. Burgueño; J. Troya; M. Wimmer; A. Vallecillo,"Dept. Lenguajes y Ciencias de la Computación, Universidad de Málaga, Bulevar Louis Pasteur, 35, Malaga, Spain; Vienna University of Technology, Business Informatics Group, Vienna, Austria; Vienna University of Technology, Business Informatics Group, Vienna, Austria; Dept. Lenguajes y Ciencias de la Computación, Universidad de Málaga, Bulevar Louis Pasteur, 35, Malaga, Spain",IEEE Transactions on Software Engineering,12 May 2015,2015,41,5,490,506,"As the complexity of model transformations grows, there is an increasing need to count on methods, mechanisms, and tools for checking their correctness, i.e., the alignment between specifications and implementations. In this paper we present a light-weight and static approach for locating the faulty rules in model transformations, based on matching functions that automatically establish these alignments using the metamodel footprints, i.e., the metamodel elements used. The approach is implemented for the combination of Tracts and ATL, both residing in the Eclipse Modeling Framework, and is supported by the corresponding toolkit. An evaluation discussing the accuracy and the limitations of the approach is also provided. Furthermore, we identify the kinds of transformations which are most suitable for validation with the proposed approach and use mutation techniques to evaluate its effectiveness.",1939-3520,,10.1109/TSE.2014.2375201,Spanish Project; Austrian Research Promotion Agency; EC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6967841,Model transformation;transformation testing;model alignment;Model transformation;transformation testing;model alignment,Contracts;Context;Context modeling;Navigation;Testing;Complexity theory;Analytical models,fault tolerant computing;Unified Modeling Language,static fault localization;model transformations;faulty rules;matching functions;metamodel footprints;metamodel elements;Eclipse modeling framework;mutation techniques,,29.0,,67.0,,26 Nov 2014,,,IEEE,IEEE Journals
940,941,A Machine Learning Approach to Software Requirements Prioritization,A. Perini; A. Susi; P. Avesani,"Fondazione Bruno Kessler. CIT - IRST, Trento; Fondazione Bruno Kessler. CIT - IRST, Trento; Fondazione Bruno Kessler. CIT - IRST, Trento",IEEE Transactions on Software Engineering,26 Mar 2013,2013,39,4,445,461,"Deciding which, among a set of requirements, are to be considered first and in which order is a strategic process in software development. This task is commonly referred to as requirements prioritization. This paper describes a requirements prioritization method called Case-Based Ranking (CBRank), which combines project's stakeholders preferences with requirements ordering approximations computed through machine learning techniques, bringing promising advantages. First, the human effort to input preference information can be reduced, while preserving the accuracy of the final ranking estimates. Second, domain knowledge encoded as partial order relations defined over the requirement attributes can be exploited, thus supporting an adaptive elicitation process. The techniques CBRank rests on and the associated prioritization process are detailed. Empirical evaluations of properties of CBRank are performed on simulated data and compared with a state-of-the-art prioritization method, providing evidence of the method ability to support the management of the tradeoff between elicitation effort and ranking accuracy and to exploit domain knowledge. A case study on a real software project complements these experimental measurements. Finally, a positioning of CBRank with respect to state-of-the-art requirements prioritization methods is proposed, together with a discussion of benefits and limits of the method.",1939-3520,,10.1109/TSE.2012.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249686,Requirements management;requirements prioritization;machine learning,Approximation methods;Accuracy;Software;Humans;Data models;Boosting,formal specification;learning (artificial intelligence);project management;software development management,machine learning approach;software requirements prioritization;strategic process;software development;case-based ranking;CBRank;project stakeholder preference;requirements ordering approximations;domain knowledge;partial order relations;requirement attributes;adaptive elicitation process;elicitation effort;ranking accuracy;software project,,70.0,,42.0,,26 Jul 2012,,,IEEE,IEEE Journals
941,942,Carving and Replaying Differential Unit Test Cases from System Test Cases,S. Elbaum; H. N. Chin; M. B. Dwyer; M. Jorde,"University of Nebraska, Lincoln; University of Nebraska, Lincoln; University of Nebraska, Lincoln; University of Nebraska, Lincoln",IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,29,45,"Unit test cases are focused and efficient. System tests are effective at exercising complex usage patterns. Differential unit tests (DUT) are a hybrid of unit and system tests that exploits their strengths. They are generated by carving the system components, while executing a system test case, that influence the behavior of the target unit, and then re-assembling those components so that the unit can be exercised as it was by the system test. In this paper we show that DUTs retain some of the advantages of unit tests, can be automatically generated, and have the potential for revealing faults related to intricate system executions. We present a framework for carving and replaying DUTs that accounts for a wide variety of strategies and tradeoffs, we implement an automated instance of the framework with several techniques to mitigate test cost and enhance flexibility and robustness, and we empirically assess the efficacy of carving and replaying DUTs on three software artifacts.",1939-3520,,10.1109/TSE.2008.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4711061,Testing strategies;Test execution;Test design;Testing strategies;Test execution;Test design,System testing;Software testing;Automatic testing;Costs;Robustness;Packaging;Debugging;Systems engineering and theory;Software systems;Humans,automatic test software;program testing,differential unit test cases;system test cases;complex usage patterns;system components;software artifacts,,25.0,2.0,41.0,,12 Dec 2008,,,IEEE,IEEE Journals
942,943,"Using Declarative Specification to Improve the Understanding, Extensibility, and Comparison of Model-Inference Algorithms",I. Beschastnikh; Y. Brun; J. Abrahamson; M. D. Ernst; A. Krishnamurthy,"Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; School of Computer Science, University of Massachusetts, Amherst, MA; Facebook Inc., Seattle, WA; Computer Science & Engineering, University of Washington, Seattle, WA; Computer Science & Engineering, University of Washington, Seattle, WA",IEEE Transactions on Software Engineering,14 Apr 2015,2015,41,4,408,428,"It is a staple development practice to log system behavior. Numerous powerful model-inference algorithms have been proposed to aid developers in log analysis and system understanding. Unfortunately, existing algorithms are typically declared procedurally, making them difficult to understand, extend, and compare. This paper presents InvariMint, an approach to specify model-inference algorithms declaratively. We applied the InvariMint declarative approach to two model-inference algorithms. The evaluation results illustrate that InvariMint (1) leads to new fundamental insights and better understanding of existing algorithms, (2) simplifies creation of new algorithms, including hybrids that combine or extend existing algorithms, and (3) makes it easy to compare and contrast previously published algorithms. InvariMint's declarative approach can outperform procedural implementations. For example, on a log of 50,000 events, InvariMint's declarative implementation of the kTails algorithm completes in 12 seconds, while a procedural implementation completes in 18 minutes. We also found that InvariMint's declarative version of the Synoptic algorithm can be over 170 times faster than the procedural implementation.",1939-3520,,10.1109/TSE.2014.2369047,NSERC; Google; Microsoft Research via a SEIF; DARPA; NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6951474,Model inference;API mining;specification mining;process mining;declarative specification;inference understanding;inference extensibility;inference comparison;InvariMint;kTails;synoptic;Model inference;API mining;specification mining;process mining;declarative specification;inference understanding;inference extensibility;inference comparison;InvariMint;kTails;synoptic,Inference algorithms;Postal services;Electronic mail;Algorithm design and analysis;Software algorithms;Educational institutions;Approximation algorithms,formal specification;inference mechanisms;system monitoring,log system behavior analysis;model inference algorithm specification;system understanding;InvariMint declarative specification approach;kTails algorithm;synoptic algorithm,,21.0,,42.0,,10 Nov 2014,,,IEEE,IEEE Journals
943,944,"Pair Programming and Software Defects--A Large, Industrial Case Study",E. di Bella; I. Fronza; N. Phaphoom; A. Sillitti; G. Succi; J. Vlasenko,"University of Genova, Genova; Free University of Bolzano - Bozen, Bolzano; Free University of Bolzano - Bozen, Bolzano; Free University of Bolzano - Bozen, Bolzano; Free University of Bozen - Bolzano, Bolzano; Free University of Bolzano - Bozen, Bolzano",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,930,953,"In the last decade, there has been increasing interest in pair programming (PP). However, despite the existing work, there is still a lack of substantial evidence of the effects of PP in industrial environments. To address this issue, we have analyzed the work of a team of 17 industrial developers for 14 months. The team is part of the IT department of a large Italian manufacturing company; it adopts a customized version of extreme programming (XP). We have investigated the effects of PP on software quality in five different scenarios. The results show that PP appears to provide a perceivable but small effect on the reduction of defects in these settings.",1939-3520,,10.1109/TSE.2012.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6331491,Pair programming;software defects;case study,Programming;Software,configuration management;manufacturing industries;production engineering computing;software fault tolerance;software prototyping;software quality;team working,pair programming;software defects;industrial case study;IT department;large Italian manufacturing company;extreme programming;customized version;software quality,,40.0,,94.0,,16 Oct 2012,,,IEEE,IEEE Journals
944,945,Toward a Formalism for Conservative Claims about the Dependability of Software-Based Systems,P. Bishop; R. Bloomfield; B. Littlewood; A. Povyakalo; D. Wright,"City University, London and Adelard LLP, London; City University, London and Adelard LLP, London; City University, London; City University, London; City University, London",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,708,717,"In recent work, we have argued for a formal treatment of confidence about the claims made in dependability cases for software-based systems. The key idea underlying this work is ""the inevitability of uncertainty"": It is rarely possible to assert that a claim about safety or reliability is true with certainty. Much of this uncertainty is epistemic in nature, so it seems inevitable that expert judgment will continue to play an important role in dependability cases. Here, we consider a simple case where an expert makes a claim about the probability of failure on demand (pfd) of a subsystem of a wider system and is able to express his confidence about that claim probabilistically. An important, but difficult, problem then is how such subsystem (claim, confidence) pairs can be propagated through a dependability case for a wider system, of which the subsystems are components. An informal way forward is to justify, at high confidence, a strong claim, and then, conservatively, only claim something much weaker: ""I'm 99 percent confident that the pfd is less than 10-5, so it's reasonable to be 100 percent confident that it is less than 10-3."" These conservative pfds of subsystems can then be propagated simply through the dependability case of the wider system. In this paper, we provide formal support for such reasoning.",1939-3520,,10.1109/TSE.2010.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5492693,Bayesian probability;safety case;software reliability.,Uncertainty;Software reliability;Phase frequency detector;Battery powered vehicles;Software systems;Software safety;Programming;Power engineering computing;Reliability engineering;Power engineering and energy,probability;software fault tolerance;uncertainty handling,software-based system dependability;software-based system safety;software-based system reliability;probability of failure on demand;conservative claims;formal support,,22.0,,24.0,,28 Jun 2010,,,IEEE,IEEE Journals
945,946,Coverage-Aware Test Database Reduction,J. Tuya; C. de la Riva; M. J. Suárez-Cabal; R. Blanco,"Dpto. Informática, University of Oviedo, Campus Universitario de Gijón, Gijón, Spain; Dpto. Informática, University of Oviedo, Campus Universitario de Gijón, Gijón, Spain; Dpto. Informática, University of Oviedo, Campus Universitario de Gijón, Gijón, Spain; Dpto. Informática, University of Oviedo, Campus Universitario de Gijón, Gijón, Spain",IEEE Transactions on Software Engineering,13 Oct 2016,2016,42,10,941,959,"Functional testing of applications that process the information stored in databases often requires a careful design of the test database. The larger the test database, the more difficult it is to develop and maintain tests as well as to load and reset the test data. This paper presents an approach to reduce a database with respect to a set of SQL queries and a coverage criterion. The reduction procedures search the rows in the initial database that contribute to the coverage in order to find a representative subset that satisfies the same coverage as the initial database. The approach is automated and efficiently executed against large databases and complex queries. The evaluation is carried out over two real life applications and a well-known database benchmark. The results show a very large degree of reduction as well as scalability in relation to the size of the initial database and the time needed to perform the reduction.",1939-3520,,10.1109/TSE.2016.2519032,Spanish Ministry of Economy and Competitiveness; Principality of Asturias; ERDF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7384760,Test database reduction;test coverage of code;test design;testing tools,Databases;Production;Minimization;Fault detection;Benchmark testing;Scalability,database management systems;design;information storage;program testing;software tools;SQL,coverage-aware test database reduction;functional testing;information storage;SQL queries;coverage criterion;database benchmark;test design;testing tools,,6.0,,105.0,,18 Jan 2016,,,IEEE,IEEE Journals
946,947,Proofs from Tests,N. E. Beckman; A. V. Nori; S. K. Rajamani; R. J. Simmons; S. D. Tetali; A. V. Thakur,"Carnegie Mellon University, Pittsburgh; Microsoft Research India, Bangalore; Microsoft Research India, Bangalore; Carnegie Mellon University, Pittsburgh; University of California, Los Angeles, Los Angeles; University of Wisconsin-Madison, Madison",IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,495,508,"We present an algorithm DASH to check if a program P satisfies a safety property φ. The unique feature of this algorithm is that it uses only test generation operations, and it refines and maintains a sound program abstraction as a consequence of failed test generation operations. Thus, each iteration of the algorithm is inexpensive, and can be implemented without any global may-alias information. In particular, we introduce a new refinement operator WPα that uses only the alias information obtained by symbolically executing a test to refine abstractions in a sound manner. We present a full exposition of the DASH algorithm and its theoretical properties. We have implemented DASH in a tool called YOGI that plugs into Microsoft's Static Driver Verifier framework. We have used this framework to run YOGI on 69 Windows Vista drivers with 85 properties and find that YOGI scales much better than SLAM, the current engine driving Microsoft's Static Driver Verifier.",1939-3520,,10.1109/TSE.2010.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5444886,Software model checking;directed testing;abstraction refinement.,Acoustic testing;Safety;Performance evaluation;Iterative algorithms;Plugs;Simultaneous localization and mapping;Engines;Instruments;Automatic testing;Algorithm design and analysis,operating systems (computers);program testing;program verification,DASH algorithm;test generation operations;YOGI tool;Microsoft static driver verifier framework;Windows Vista drivers;software model checking,,31.0,,27.0,,8 Apr 2010,,,IEEE,IEEE Journals
947,948,Exemplar: A Source Code Search Engine for Finding Highly Relevant Applications,C. McMillan; M. Grechanik; D. Poshyvanyk; C. Fu; Q. Xie,"College of William and Mary, Williamsburg; Accenture Technology Labs, Chicago; College of William and Mary, Williamsburg; Accenture Technology Labs, Chicago; Accenture Technology Labs, Chicago",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1069,1087,"A fundamental problem of finding software applications that are highly relevant to development tasks is the mismatch between the high-level intent reflected in the descriptions of these tasks and low-level implementation details of applications. To reduce this mismatch we created an approach called EXEcutable exaMPLes ARchive (Exemplar) for finding highly relevant software projects from large archives of applications. After a programmer enters a natural-language query that contains high-level concepts (e.g., MIME, datasets), Exemplar retrieves applications that implement these concepts. Exemplar ranks applications in three ways. First, we consider the descriptions of applications. Second, we examine the Application Programming Interface (API) calls used by applications. Third, we analyze the dataflow among those API calls. We performed two case studies (with professional and student developers) to evaluate how these three rankings contribute to the quality of the search results from Exemplar. The results of our studies show that the combined ranking of application descriptions and API documents yields the most-relevant search results. We released Exemplar and our case study data to the public.",1939-3520,,10.1109/TSE.2011.84,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5989838,Source code search engines;information retrieval;concept location;open source software;mining software repositories;software reuse,Search engines;Engines;Software;Java;Cryptography;Vocabulary;Data mining,application program interfaces;data flow analysis;document handling;natural language processing;project management;query processing;software management;software reusability;system documentation,source code search engine;software application;development task;executable examples archive;Exemplar;software project;natural-language query;application programming interface;dataflow;API call;search quality;application description ranking;API document;software reuse,,59.0,2.0,52.0,,18 Aug 2011,,,IEEE,IEEE Journals
948,949,The ManyBugs and IntroClass Benchmarks for Automated Repair of C Programs,C. Le Goues; N. Holtschulte; E. K. Smith; Y. Brun; P. Devanbu; S. Forrest; W. Weimer,"School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Department of Computer Science at the University of New Mexico, Albuquerque, NM; College of Information and Computer Science, University of Massachusetts at Amherst, MA; College of Information and Computer Science, University of Massachusetts at Amherst, MA; Department of Computer Science, University of California at Davis, Davis, CA; Department of Computer Science at the University of New Mexico, Albuquerque, NM; Department of Computer Science, University of Virginia, Charlottesville, VA",IEEE Transactions on Software Engineering,8 Dec 2015,2015,41,12,1236,1256,"The field of automated software repair lacks a set of common benchmark problems. Although benchmark sets are used widely throughout computer science, existing benchmarks are not easily adapted to the problem of automatic defect repair, which has several special requirements. Most important of these is the need for benchmark programs with reproducible, important defects and a deterministic method for assessing if those defects have been repaired. This article details the need for a new set of benchmarks, outlines requirements, and then presents two datasets, ManyBugs and IntroClass, consisting between them of 1,183 defects in 15 C programs. Each dataset is designed to support the comparative evaluation of automatic repair algorithms asking a variety of experimental questions. The datasets have empirically defined guarantees of reproducibility and benchmark quality, and each study object is categorized to facilitate qualitative evaluation and comparisons by category of bug or program. The article presents baseline experimental results on both datasets for three existing repair methods, GenProg, AE, and TrpAutoRepair, to reduce the burden on researchers who adopt these datasets for their own comparative evaluations.",1939-3520,,10.1109/TSE.2015.2454513,AFOSR; US Defense Advanced Research Projects Agency (DARPA); US Department of Energy (DOE); US National Science Foundation (NSF); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7153570,Automated program repair;benchmark;subject defect;reproducibility;ManyBugs;IntroClass;Automated program repair;benchmark;subject defect;reproducibility;ManyBugs;IntroClass,Maintenance engineering;Benchmark testing;Computer bugs;Software systems;Electronic mail,benchmark testing;C language;program debugging;software maintenance;software performance evaluation;software quality,TrpAutoRepair;GenProg;qualitative evaluation;benchmark quality;reproducibility;automatic repair algorithms;defects assessment;deterministic method;benchmark programs;automatic defect repair;computer science;benchmark sets;benchmark problems;automated software repair;C programs;IntroClass benchmarks;ManyBugs benchmarks,,97.0,,80.0,,9 Jul 2015,,,IEEE,IEEE Journals
949,950,"Mapping Bug Reports to Relevant Files: A Ranking Model, a Fine-Grained Benchmark, and Feature Evaluation",X. Ye; R. Bunescu; C. Liu,"School of Electrical Engineering and Computer Science, Ohio University, Athens, OH; School of Electrical Engineering and Computer Science, Ohio University, Athens, OH; School of Electrical Engineering and Computer Science, Ohio University, Athens, OH",IEEE Transactions on Software Engineering,14 Apr 2016,2016,42,4,379,402,"When a new bug report is received, developers usually need to reproduce the bug and perform code reviews to find the cause, a process that can be tedious and time consuming. A tool for ranking all the source files with respect to how likely they are to contain the cause of the bug would enable developers to narrow down their search and improve productivity. This paper introduces an adaptive ranking approach that leverages project knowledge through functional decomposition of source code, API descriptions of library components, the bug-fixing history, the code change history, and the file dependency graph. Given a bug report, the ranking score of each source file is computed as a weighted combination of an array of features, where the weights are trained automatically on previously solved bug reports using a learning-to-rank technique. We evaluate the ranking system on six large scale open source Java projects, using the before-fix version of the project for every bug report. The experimental results show that the learning-to-rank approach outperforms three recent state-of-the-art methods. In particular, our method makes correct recommendations within the top 10 ranked source files for over 70 percent of the bug reports in the Eclipse Platform and Tomcat projects.",1939-3520,,10.1109/TSE.2015.2479232,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7270328,Bug reports;software maintenance;learning to rank;Bug reports;software maintenance;learning to rank,Software;History;Computational modeling;Computer bugs;Collaboration;Benchmark testing;Standards,,,,25.0,,72.0,,16 Sep 2015,,,IEEE,IEEE Journals
950,951,Zebu: A Language-Based Approach for Network Protocol Message Processing,L. Burgy; L. Reveillere; J. Lawall; G. Muller,"Princeton University, Princeton; University of Bordeaux, LaBRI, Talence; DIKU, University of Copenhagen, Paris; INRIA-Regal, LIP6, Paris",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,575,591,"A network application communicates with other applications according to a set of rules known as a protocol. This communication is managed by the part of the application known as the protocol-handling layer, which enables the manipulation of protocol messages. The protocol-handling layer is a critical component of a network application since it represents the interface between the application and the outside world. It must thus satisfy two constraints: It must be efficient to be able to treat a large number of messages and it must be robust to face various attacks targeting the application itself or the underlying platform. Despite these constraints, the development process of this layer still remains rudimentary and requires a high level of expertise. It includes translating the protocol specification written in a high-level formalism such as ABNF toward low-level code such as C. The gap between these abstraction levels can entail many errors. This paper proposes a new language-based approach to developing protocol-handling layers, to improve their robustness without compromising their performance. Our approach is based on the use of a domain-specific language, Zebu, to specify the protocol-handling layer of network applications that use textual HTTP-like application protocols. The Zebu syntax is very close to that of ABNF, facilitating the adoption of Zebu by domain experts. By annotating the original ABNF specification of a protocol, the Zebu user can dedicate the protocol-handling layer to the needs of a given application. The Zebu compiler first checks the annotated specification for inconsistencies, and then generates a protocol-handling layer according to the annotations. This protocol-handling layer is made up of a set of data structures that represent a message, a parser that fills in these data structures, and various stub functions to access these data structures or drive the parsing of a message.",1939-3520,,10.1109/TSE.2010.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5487528,Network protocols;message parsing;message composing;domain-specific languages.,Electronic mail;Data structures;Robustness;Domain specific languages;Access protocols;Streaming media;IP networks;Network servers;Web server;Computer bugs,computational linguistics;formal specification;Internet;program compilers;protocols;specification languages;telecommunication computing,Zebu syntax;language-based approach;network protocol message processing;protocol-handling layer;protocol specification;ABNF;textual HTTP-like application protocols;Zebu compiler;data structures;message parsing;Internet era;domain-specific languages,,9.0,2.0,34.0,,17 Jun 2010,,,IEEE,IEEE Journals
951,952,Automated Steering of Model-Based Test Oracles to Admit Real Program Behaviors,G. Gay; S. Rayadurgam; M. P. E. Heimdahl,"Department of Computer Science & Engineering, University of South Carolina, Columbia, SC; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN",IEEE Transactions on Software Engineering,12 Jun 2017,2017,43,6,531,555,"The test oracle-a judge of the correctness of the system under test (SUT)-is a major component of the testing process. Specifying test oracles is challenging for some domains, such as real-time embedded systems, where small changes in timing or sensory input may cause large behavioral differences. Models of such systems, often built for analysis and simulation, are appealing for reuse as test oracles. These models, however, typically represent an idealized system, abstracting away certain issues such as non-deterministic timing behavior and sensor noise. Thus, even with the same inputs, the model's behavior may fail to match an acceptable behavior of the SUT, leading to many false positives reported by the test oracle. We propose an automated steering framework that can adjust the behavior of the model to better match the behavior of the SUT to reduce the rate of false positives. This model steering is limited by a set of constraints (defining the differences in behavior that are acceptable) and is based on a search process attempting to minimize a dissimilarity metric. This framework allows non-deterministic, but bounded, behavioral differences, while preventing future mismatches by guiding the oracle-within limits-to match the execution of the SUT. Results show that steering significantly increases SUT-oracle conformance with minimal masking of real faults and, thus, has significant potential for reducing false positives and, consequently, testing and debugging costs while improving the quality of the testing process.",1939-3520,,10.1109/TSE.2016.2615311,US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7583721,Software testing;test oracles;model-based testing;model-based development;verification,Testing;Analytical models;Computational modeling;Software;Delays;Hardware;Pacemakers,program debugging;program testing;program verification,automated steering;model-based test oracles;real program behaviors;system under test correctness;SUT correctness;model steering;search process;fault masking;debugging costs;testing process quality,,5.0,,54.0,,5 Oct 2016,,,IEEE,IEEE Journals
952,953,Test Case-Aware Combinatorial Interaction Testing,C. Yilmaz,"Sabanci University, Istanbul",IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,684,706,"The configuration spaces of modern software systems are too large to test exhaustively. Combinatorial interaction testing (CIT) approaches, such as covering arrays, systematically sample the configuration space and test only the selected configurations by using a battery of test cases. Traditional covering arrays, while taking system-wide interoption constraints into account, do not provide a systematic way of handling test case-specific interoption constraints. The basic justification for t-way covering arrays is that they can cost effectively exercise all system behaviors caused by the settings of t or fewer options. In this paper, we hypothesize, however, that in the presence of test case-specific interoption constraints, many such behaviors may not be tested due to masking effects caused by the overlooked test case-specific constraints. For example, if a test case refuses to run in a configuration due to an unsatisfied test case-specific constraint, none of the valid option setting combinations appearing in the configuration will be tested by that test case. To account for test case-specific constraints, we introduce a new combinatorial object, called a test case-aware covering array. A t-way test case-aware covering array is not just a set of configurations, as is the case in traditional covering arrays, but a set of configurations, each of which is associated with a set of test cases such that all test case-specific constraints are satisfied and that, for each test case, each valid combination of option settings for every combination of t options appears at least once in the set of configurations that the test case is associated with. We furthermore present three algorithms to compute test case-aware covering arrays. Two of the algorithms aim to minimize the number of configurations required (one is fast, but produces larger arrays, the other is slower, but produces smaller arrays), whereas the remaining algorithm aims to minimize the number of test runs required. The results of our empirical studies conducted on two widely used highly configurable software systems suggest that test case-specific constraints do exist in practice, that traditional covering arrays suffer from masking effects caused by ignorance of such constraints, and that test case-aware covering arrays are better than other approaches in handling test case-specific constraints, thus avoiding masking effects.",1939-3520,,10.1109/TSE.2012.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311411,Software quality assurance;combinatorial interaction testing;covering arrays,Testing;Servers;Software algorithms;Software systems;Systematics;Computational modeling,program testing;software quality,test case-aware combinatorial interaction testing;software system;CIT approach;interoption constraint;masking effect;t-way test case-aware covering array;highly configurable software system,,14.0,,34.0,,24 Sep 2012,,,IEEE,IEEE Journals
953,954,Reducing Unauthorized Modification of Digital Objects,P. C. Van Oorschot; G. Wurster,"Carleton University, Ottawa; Carleton University, Ottawa",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,191,204,"We consider the problem of malicious modification of digital objects. We present a protection mechanism designed to protect against unauthorized replacement or modification of digital objects while still allowing authorized updates transparently. We use digital signatures without requiring any centralized public key infrastructure. To explore the viability of our proposal, we apply the approach to file-system binaries, implementing a prototype in Linux which protects operating system and application binaries on disk. To test the prototype and related kernel modifications, we show that it protects against various rootkits currently available while incurring minimal overhead costs. The general approach can be used to restrict updates to general digital objects.",1939-3520,,10.1109/TSE.2011.7,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5680916,Protection mechanisms;software release management and delivery;system integration and implementation;access controls;file organization;operating systems.,Public key;Digital signatures;Access controls;Malware;File organization;Operating systems,authorisation;digital signatures;file organisation;industrial property;operating system kernels,unauthorized modification reduction;malicious modification problem;unauthorized digital object replacement;digital signatures;file-system binaries;Linux;operating system protection;kernel modification;overhead cost minimisation,,1.0,1.0,63.0,,6 Jan 2011,,,IEEE,IEEE Journals
954,955,Model-Transformation Design Patterns,K. Lano; S. Kolahdouz-Rahimi,"Department of Informatics, King’s College London, London WC2R 2LS, United Kingdom; Department of Informatics, King’s College London, London WC2R 2LS, United Kingdom",IEEE Transactions on Software Engineering,12 Dec 2014,2014,40,12,1224,1259,"This paper defines a catalogue of patterns for the specification and design of model transformations, and provides a systematic scheme and classification of these patterns, together with pattern application examples in leading model transformation languages such as ATL, QVT, GrGen.NET, and others. We consider patterns for improving transformation modularization and efficiency and for reducing data storage requirements. We define a metamodel-based formalization of model transformation design patterns, and measurement-based techniques to guide the selection of patterns. We also provide an evaluation of the effectiveness of transformation patterns on a range of different case studies.",1939-3520,,10.1109/TSE.2014.2354344,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6891324,Model transformations;design patterns;model-driven development,Unified modeling language;Software development;Systematics;Analytical models;Semantics;Complexity theory;Syntactics,formal specification;object-oriented programming;pattern classification,metamodel-based formalization;data storage;transformation modularization improvement;GrGen.NET;QVT;ATL;model transformation languages;pattern application;pattern classification;systematic scheme;model-transformation design patterns,,30.0,,72.0,,4 Sep 2014,,,IEEE,IEEE Journals
955,956,A General Software Defect-Proneness Prediction Framework,Q. Song; Z. Jia; M. Shepperd; S. Ying; J. Liu,"Xi'an Jiaotong University, Xi'an; Xi'an Jiaotong University, Xi'an; Brunel University, Uxbridge; Wuhan University, Wuhan; Wuhan University, Wuhan",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,356,370,"BACKGROUND - Predicting defect-prone software components is an economically important activity and so has received a good deal of attention. However, making sense of the many, and sometimes seemingly inconsistent, results is difficult. OBJECTIVE - We propose and evaluate a general framework for software defect prediction that supports 1) unbiased and 2) comprehensive comparison between competing prediction systems. METHOD - The framework is comprised of 1) scheme evaluation and 2) defect prediction components. The scheme evaluation analyzes the prediction performance of competing learning schemes for given historical data sets. The defect predictor builds models according to the evaluated learning scheme and predicts software defects with new data according to the constructed model. In order to demonstrate the performance of the proposed framework, we use both simulation and publicly available software defect data sets. RESULTS - The results show that we should choose different learning schemes for different data sets (i.e., no scheme dominates), that small details in conducting how evaluations are conducted can completely reverse findings, and last, that our proposed framework is more effective and less prone to bias than previous approaches. CONCLUSIONS - Failure to properly or fully evaluate a learning scheme can be misleading; however, these problems may be overcome by our proposed framework.",1939-3520,,10.1109/TSE.2010.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611551,Software defect prediction;software defect-proneness prediction;machine learning;scheme evaluation.,Software;Training data;Predictive models;Buildings;Data models;Prediction algorithms;Training,learning (artificial intelligence);software fault tolerance;software performance evaluation,software defect proneness prediction framework;scheme evaluation;competing learning schemes;defect predictor,,160.0,1.0,44.0,,28 Oct 2010,,,IEEE,IEEE Journals
956,957,Formal Analysis of the Probability of Interaction Fault Detection Using Random Testing,A. Arcuri; L. Briand,"Simula Research Laboratory, Lysaker; Simula Research Laboratory, Lysaker",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1088,1099,"Modern systems are becoming highly configurable to satisfy the varying needs of customers and users. Software product lines are hence becoming a common trend in software development to reduce cost by enabling systematic, large-scale reuse. However, high levels of configurability entail new challenges. Some faults might be revealed only if a particular combination of features is selected in the delivered products. But testing all combinations is usually not feasible in practice, due to their extremely large numbers. Combinatorial testing is a technique to generate smaller test suites for which all combinations of t features are guaranteed to be tested. In this paper, we present several theorems describing the probability of random testing to detect interaction faults and compare the results to combinatorial testing when there are no constraints among the features that can be part of a product. For example, random testing becomes even more effective as the number of features increases and converges toward equal effectiveness with combinatorial testing. Given that combinatorial testing entails significant computational overhead in the presence of hundreds or thousands of features, the results suggest that there are realistic scenarios in which random testing may outperform combinatorial testing in large systems. Furthermore, in common situations where test budgets are constrained and unlike combinatorial testing, random testing can still provide minimum guarantees on the probability of fault detection at any interaction level. However, when constraints are present among features, then random testing can fare arbitrarily worse than combinatorial testing. As a result, in order to have a practical impact, future research should focus on better understanding the decision process to choose between random testing and combinatorial testing, and improve combinatorial testing in the presence of feature constraints.",1939-3520,,10.1109/TSE.2011.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999671,Combinatorial testing;random testing;interaction testing;theory;constraint;feature diagram;lower bound,Software;Context;Fault detection;Feature extraction;Scalability;Benchmark testing,cost reduction;customer satisfaction;probability;program testing;program verification;random processes;software cost estimation;software fault tolerance,interaction fault detection probability;formal analysis;random testing;customer satisfaction;user satisfaction;software product lines;software development;cost reduction;large-scale reusability;combinatorial testing;computational overhead;feature constraints,,36.0,,37.0,,25 Aug 2011,,,IEEE,IEEE Journals
957,958,GK-Tail+ An Efficient Approach to Learn Software Models,L. Mariani; M. Pezzè; M. Santoro,"Department of Informatics, Systems and Communication, University of Milano Bicocca, Milano, Italy; Faculty of Informatics, Universitá della Svizzera Italiana, Lugano, Switzerland; Faculty of Informatics, Universitá della Svizzera Italiana, Lugano, Switzerland",IEEE Transactions on Software Engineering,11 Aug 2017,2017,43,8,715,738,"Inferring models of program behavior from execution samples can provide useful information about a system, also in the increasingly common case of systems that evolve and adapt in their lifetime, and without requiring large developers' effort. Techniques for learning models of program behavior from execution traces shall address conflicting challenges of recall, specificity and performance: They shall generate models that comprehensively represent the system behavior (recall) while limiting the amount of illegal behaviors that may be erroneously accepted by the model (specificity), and should infer the models within a reasonable time budget to process industrial scale systems (performance). In our early work, we designed GK-tail, an approach that can infer guarded finite state machines that model the behavior of object-oriented programs in terms of sequences of method calls and constraints on the parameter values. GK-tail addresses well two of the three main challenges, since it infers guarded finite state machines with a high level of recall and specificity, but presents severe limitations in terms of performance that reduce its scalability. In this paper, we present GK-tail+, a new approach to infer guarded finite state machines from execution traces of object-oriented programs. GK-tail+ proposes a new set of inference criteria that represent the core element of the inference process: It largely reduces the inference time of GK-tail while producing guarded finite state machines with a comparable level of recall and specificity. Thus, GK-tail+ advances the preliminary results of GK-tail by addressing all the three main challenges of learning models of program behavior from execution traces.",1939-3520,,10.1109/TSE.2016.2623623,The H2020 Learn project; ERC Consolidator Grant 2014 program; ERC; Swiss National Foundation; SNF; ASysT: Automatic System Testing; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7728088,Dynamic model learning;software models;state based models;guarded finite state machines;specification mining,Object oriented modeling;Merging;Analytical models;Adaptation models;Software systems;Limiting,finite state machines;learning (artificial intelligence);object-oriented programming,GK-Tail+;software models;inferring models;program behavior;learning models;system behavior;illegal behaviors;reasonable time budget;industrial scale systems;object-oriented programs;guarded finite state machines;inference criteria;inference process;inference time;execution traces,,9.0,,55.0,,1 Nov 2016,,,IEEE,IEEE Journals
958,959,Seer: A Lightweight Online Failure Prediction Approach,B. Ozcelik; C. Yilmaz,"freelance software developer; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey",IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,26,46,"Online failure prediction approaches aim to predict the manifestation of failures at runtime before the failures actually occur. Existing approaches generally refrain themselves from collecting internal execution data, which can further improve the prediction quality. One reason behind this general trend is the runtime overhead incurred by the measurement instruments that collect the data. Since these approaches are targeted at deployed software systems, excessive runtime overhead is generally undesirable. In this work we conjecture that large cost reductions in collecting internal execution data for online failure prediction may derive from pushing the substantial parts of the data collection work onto the hardware. To test this hypothesis, we present a lightweight online failure prediction approach, called Seer, in which most of the data collection work is performed by fast hardware performance counters. The hardware-collected data is augmented with further data collected by a minimal amount of software instrumentation that is added to the systems software. In our empirical evaluations conducted on three open source projects, Seer performed significantly better than other related approaches in predicting the manifestation of failures.",1939-3520,,10.1109/TSE.2015.2442577,Marie Curie International Reintegration; European Community Framework Programme; Scientific and Technological Research Council of Turkey; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7120143,Online failure prediction;hardware performance counters;software quality assurance;software reliability;Online failure prediction;hardware performance counters;software quality assurance;software reliability,Radiation detectors;Hardware;Runtime;Predictive models;Instruments;Software;Indexes,data handling;public domain software;quality assurance;software cost estimation;software quality;software reliability;system recovery,Seer;lightweight online failure prediction;internal execution data collection;prediction quality improvement;measurement instruments;software systems;runtime overhead;cost reduction;fast hardware performance counters;software instrumentation;open source projects;software quality assurance;software reliability,,10.0,,60.0,,9 Jun 2015,,,IEEE,IEEE Journals
959,960,Deriving Bisimulation Relations from Path Extension Based Equivalence Checkers,K. Banerjee; D. Sarkar; C. Mandal,"Intel Parallel Computing Lab, Bangalore, Karnataka, India; Department of Computer Science and Engineering, Indian Institute of Technology Kharagpur, India; Department of Computer Science and Engineering, Indian Institute of Technology Kharagpur, India",IEEE Transactions on Software Engineering,13 Oct 2017,2017,43,10,946,953,"Constructing bisimulation relations between programs as a means of translation validation has been an active field of study. The problem is in general undecidable. Currently available mechanisms suffer from drawbacks such as non-termination and significant restrictions on the structures of programs to be checked. We have developed a path extension based equivalence checking method as an alternative translation validation technique to alleviate these drawbacks. In this work, path extension based equivalence checking of programs (flowcharts) is leveraged to establish a bisimulation relation between a program and its translated version by constructing the relation from the outputs of the equivalence checker.",1939-3520,,10.1109/TSE.2016.2645687,Tata Consultancy Services (TCS); Department of Science and Technology (DST); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7801117,Translation validation;bisimulation relation;equivalence checking;path extension based equivalence checker,Computational modeling;Inference algorithms;Processor scheduling;Computer science;Electronic mail;Optimization;Integrated circuit modeling,bisimulation equivalence;flowcharting;program interpreters;program verification,bisimulation relation;equivalence checker;path extension based equivalence checking method;alternative translation validation technique;program checking;flowcharts,,,,19.0,Traditional,28 Dec 2016,,,IEEE,IEEE Journals
960,961,Forecasting Java Software Evolution Trends Employing Network Models,T. Chaikalis; A. Chatzigeorgiou,"Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece",IEEE Transactions on Software Engineering,10 Jun 2015,2015,41,6,582,602,"The evolution of networks representing systems in various domains, including social networks, has been extensively studied enabling the development of growth models which govern their behavior over time. The architecture of software systems can also be naturally represented in the form of networks, whose properties change as software evolves. In this paper we attempt to model several aspects of graphs representing object-oriented software systems as they evolve over a number of versions. The goal is to develop a prediction model by considering global phenomena such as preferential attachment, past evolutionary trends such as the tendency of classes to create fewer relations as they age, as well as domain knowledge in terms of principles that have to be followed in object-oriented design. The derived models can provide insight into the future trends of software and potentially form the basis for eliciting improved or novel laws of software evolution. The forecasting power of the proposed model is evaluated against the actual evolution of 10 open-source projects and the achieved accuracy in the prediction of several network and software properties, which reflect the underlying system design, appears to be promising.",1939-3520,,10.1109/TSE.2014.2381249,European Union (European Social Fund—ESF); National Strategic Reference Framework; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6985636,Graphs and networks;Restructuring;reverse engineering;reengineering;Software Architectures;Objectoriented design methods;Graphs and networks;restructuring;reverse engineering;and reengineering;software architectures;object-oriented design methods,Object oriented modeling;Predictive models;Forecasting;Software systems;Analytical models;Market research,graph theory;Java;object-oriented programming;social networking (online);software architecture;software maintenance,Java software evolution trend;social network;software system architecture;object-oriented software system;prediction model;preferential attachment,,20.0,,96.0,,18 Dec 2014,,,IEEE,IEEE Journals
961,962,The Effect of GoF Design Patterns on Stability: A Case Study,A. Ampatzoglou; A. Chatzigeorgiou; S. Charalampidou; P. Avgeriou,"Institute of Mathematics and Computer Science, University of Groningen, Groningen, Netherlands; Department of Applied Informatics, University of Macedonia, Thessaloniki, Greece; Institute of Mathematics and Computer Science, University of Groningen, Groningen, Netherlands; Institute of Mathematics and Computer Science, University of Groningen, Groningen, Netherlands",IEEE Transactions on Software Engineering,11 Aug 2015,2015,41,8,781,802,"Stability refers to a software system's resistance to the “ripple effect”, i.e., propagation of changes. In this paper, we investigate the stability of classes that participate in instances/occurrences of GoF design patterns. We examine whether the stability of such classes is affected by (a) the pattern type, (b) the role that the class plays in the pattern, (c) the number of pattern occurrences in which the class participates, and (d) the application domain. To this end, we conducted a case study on about 65.000 Java open-source classes, where we performed change impact analysis on classes that participate in zero, one (single pattern), or more than one (coupled) pattern occurrences. The results suggest that, the application of design patterns can provide the expected “shielding” of certain pattern-participating classes against changes, depending on their role in the pattern. Moreover, classes that participate in coupled pattern occurrences appear to be the least stable. The results can be used for assessing the benefits and liabilities of the use of patterns and for testing and refactoring prioritization, because less stable classes are expected to require more effort while testing, and urge for refactoring activities that would make them more resistant to change propagation.",1939-3520,,10.1109/TSE.2015.2414917,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7066925,"D.2.2 Design Tools and Techniques;D.2.3.a Object-oriented programming,;D.2.8 Metrics/Measurement;Design Tools and Techniques;Object-oriented programming;Metrics/Measurement",Stability analysis;Couplings;Abstracts;Measurement;Production facilities;Open source software,Java;object-oriented programming;public domain software,GoF design pattern;stability;software system resistance;ripple effect;Java open-source class;change impact analysis;coupled pattern occurrence;pattern-participating class;refactoring prioritization;refactoring activity;change propagation,,34.0,,53.0,,24 Mar 2015,,,IEEE,IEEE Journals
962,963,Capsule-Based User Interface Modeling for Large-Scale Applications,D. Milicev; Z. Mijailovic,"University of Belgrade, Belgrade; SOL Software, Belgrade",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1190,1207,"We present a novel approach to modeling and implementing user interfaces (UI) of large business applications. The approach is based on the concept of capsule, a profiled structured class from UML which models a simple UI component or a coherent UI fragment of logically and functionally coupled components or other fragments with a clear interface. Consequently, the same modeling concept of capsule with internal structure can be reapplied recursively at successively lower levels of detail within a model, starting from high architectural modeling levels down to the lowest levels of modeling simple UI components. The interface of capsules is defined in terms of pins, while the functional coupling of capsules is specified declaratively by simply wiring their pins. Pins and wires transport messages between capsules, ensuring strict encapsulation. The approach includes a method for formal coupling of capsules' behavior with the underlying object space that provides proper impedance matching between the UI and the business logic while preserving clear separation of concerns between them. We also briefly describe an implementation of a framework that supports the proposed method, including a rich library of ready-to-use capsules, and report on our experience in applying the approach in large-scale industrial systems.",1939-3520,,10.1109/TSE.2013.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6464270,Graphical user interface (GUI);Unified Modeling Language (UML);modeling;model-driven development;software architecture;business applications;data-centric applications;information systems,Unified modeling language;Business;Couplings;Complexity theory;Object oriented modeling;Buildings;User interfaces,business data processing;Unified Modeling Language;user interfaces,profiled structured class;ready-to-use capsule library;object space;business logic;functional capsule coupling;capsule interface;UI component;UI fragment;Unified Modeling Language;UML;capsule concept;business application;capsule-based user interface modeling,,3.0,,43.0,,18 Feb 2013,,,IEEE,IEEE Journals
963,964,Synthesizing Multithreaded Code from Real-Time Object-Oriented Models via Schedulability-Aware Thread Derivation,S. Kim,"Department of Information Communications Engineering, Hankuk University of Foreign Studies, Global Campus, San 89, Mohyun-myun, Cheoin-gu, Yongin-si, South Korea",IEEE Transactions on Software Engineering,2 May 2014,2014,40,4,413,426,"One of the major difficulties in developing embedded systems with object-oriented modeling is to translate a designed model into code that satisfies required real-time performance. This paper proposes scenario-based implementation synthesis architecture with timing guarantee (SISAtime) that addresses these difficulties. The problems that SISAtime must solve are: how to synthesize multithreaded-code from a real-time object-oriented model; and how to design supporting development tools and runtime system architecture while ensuring that the scenarios in the system have minimal response times and the code satisfies the given timing constraints with a minimal number of threads. SISAtime provides a new scheduling algorithm which minimizes scenario response times. SISAtime also provides a new thread derivation method that derives tasks and maps tasks to threads while automatically assigning task scheduling attributes. We have fully implemented SISAtime by extending the RoseRT development tool that uses UML 2.0 as a modeling language, and we applied it to an existing industrial private branch exchange system. The performance evaluation results show that the response times, context switches, and the number of threads of the system with SISAtime were reduced by 21.6, 33.2, and 65.2 percent, respectively, compared to the system with the best known existing thread derivation method.",1939-3520,,10.1109/TSE.2013.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6617637,Multitasking;object-oriented design methods;real-time systems and embedded systems;system integration and implementation,Unified modeling language;Object oriented modeling;Message systems;Timing;Time factors;Real-time systems;Ports (Computers),embedded systems;multi-threading;object-oriented methods;scheduling;software architecture;software performance evaluation;Unified Modeling Language,multithreaded code synthesis;real-time object-oriented models;schedulability-aware thread derivation;embedded systems;real-time performance evaluation;scenario-based implementation synthesis architecture-with-timing guarantee;SISAtime;development tools;runtime system architecture;timing constraints;scenario response time minimization;thread derivation method;task derivation;task mapping;automatic task scheduling attribute assignment;RoseRT development tool;UML 2.0;modeling language;industrial private branch exchange system;context switches,,5.0,,42.0,,2 Oct 2013,,,IEEE,IEEE Journals
964,965,Defining and Evaluating a Measure of Open Source Project Survivability,U. Raja; M. J. Tretter,"The University of Alabama, Tuscaloosa; Texas A&M University, College Station",IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,163,174,"In this paper, we define and validate a new multidimensional measure of Open Source Software (OSS) project survivability, called Project Viability. Project viability has three dimensions: vigor, resilience, and organization. We define each of these dimensions and formulate an index called the Viability Index (VI) to combine all three dimensions. Archival data of projects hosted at SourceForge.net are used for the empirical validation of the measure. An Analysis Sample (n=136) is used to assign weights to each dimension of project viability and to determine a suitable cut-off point for VI. Cross-validation of the measure is performed on a hold-out Validation Sample (n=96). We demonstrate that project viability is a robust and valid measure of OSS project survivability that can be used to predict the failure or survival of an OSS project accurately. It is a tangible measure that can be used by organizations to compare various OSS projects and to make informed decisions regarding investment in the OSS domain.",1939-3520,,10.1109/TSE.2011.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6127835,Evaluation framework;external validity;open source software;project evaluation;software measurement;software survivability.,Software measurement;Indexes;Maintenance engineering,project management;public domain software;software metrics,open source project survivability;multidimensional measure;open source software project survivability;project viability;vigor;resilience;organization;viability index,,18.0,,69.0,,10 Jan 2012,,,IEEE,IEEE Journals
965,966,Mining Version Histories for Detecting Code Smells,F. Palomba; G. Bavota; M. D. Penta; R. Oliveto; D. Poshyvanyk; A. De Lucia,"University of Salerno, Fisciano, SA, Italy; Free University of Bozen-Bolzano, Bolzano, Italy; University of Sannio, Benevento, Italy; University of Molise, Pesche, IS, Italy; College of William and Mary, Williamsburg, VA; University of Salerno, Fisciano, SA, Italy",IEEE Transactions on Software Engineering,13 May 2015,2015,41,5,462,489,"Code smells are symptoms of poor design and implementation choices that may hinder code comprehension, and possibly increase changeand fault-proneness. While most of the detection techniques just rely on structural information, many code smells are intrinsically characterized by how code elements change overtime. In this paper, we propose Historical Information for Smell deTection (HIST), an approach exploiting change history information to detect instances of five different code smells, namely Divergent Change, Shotgun Surgery, Parallel Inheritance, Blob, and Feature Envy. We evaluate HIST in two empirical studies. The first, conducted on 20 open source projects, aimed at assessing the accuracy of HIST in detecting instances of the code smells mentioned above. The results indicate that the precision of HIST ranges between 72 and 86 percent, and its recall ranges between 58 and 100 percent. Also, results of the first study indicate that HIST is able to identify code smells that cannot be identified by competitive approaches solely based on code analysis of a single system's snapshot. Then, we conducted a second study aimed at investigating to what extent the code smells detected by HIST (and by competitive code analysis techniques) reflect developers' perception of poor design and implementation choices. We involved 12 developers of four open source projects that recognized more than 75 percent of the code smell instances identified by HIST as actual design/implementation problems.",1939-3520,,10.1109/TSE.2014.2372760,EU; grants; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6963448,Code smells;mining software repositories;empirical studies;Code smells;mining software repositories;empirical studies,History;Feature extraction;Surgery;Accuracy;Association rules;Detectors,data mining;program compilers;public domain software,code smell detection;historical information for smell detection;divergent change;shotgun surgery;parallel inheritance;blob;feature envy;HIST;code analysis;single system snapshot;open source project;mining version history,,112.0,,55.0,,20 Nov 2014,,,IEEE,IEEE Journals
966,967,Structural Complexity and Programmer Team Strategy: An Experimental Test,N. Ramasubbu; C. F. Kemerer; J. Hong,"University of Pittsburgh, Pittsburgh; University of Pittsburgh, Pittsburgh and King Abdul Aziz University, Saudi Arabia; Singapore Management University, Singapore",IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1054,1068,"This study develops and empirically tests the idea that the impact of structural complexity on perfective maintenance of object-oriented software is significantly determined by the team strategy of programmers (independent or collaborative). We analyzed two key dimensions of software structure, coupling and cohesion, with respect to the maintenance effort and the perceived ease-of-maintenance by pairs of programmers. Hypotheses based on the distributed cognition and task interdependence theoretical frameworks were tested using data collected from a controlled lab experiment employing professional programmers. The results show a significant interaction effect between coupling, cohesion, and programmer team strategy on both maintenance effort and perceived ease-of-maintenance. Highly cohesive and low-coupled programs required lower maintenance effort and were perceived to be easier to maintain than the low-cohesive programs and high-coupled programs. Further, our results would predict that managers who strategically allocate maintenance tasks to either independent or collaborative programming teams depending on the structural complexity of software could lower their team's maintenance effort by as much as 70 percent over managers who use simple uniform resource allocation policies. These results highlight the importance of achieving congruence between team strategies employed by collaborating programmers and the structural complexity of software.",1939-3520,,10.1109/TSE.2011.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999673,Object-oriented programming;complexity measures;software quality;software productivity;programming teams;maintenance process;CK metrics;software management,Maintenance engineering;Complexity theory;Couplings;Collaboration;Software;Programming profession,computational complexity;object-oriented programming;resource allocation;software maintenance,programmer team strategy;structural complexity;object-oriented software;perfective maintenance;software structure;perceived ease-of-maintenance;distributed cognition;task interdependence;controlled lab experiment;professional programmers;significant interaction;low-cohesive programs;high-coupled programs;collaborative programming teams;resource allocation policies,,10.0,,62.0,,25 Aug 2011,,,IEEE,IEEE Journals
967,968,Mutation-Driven Generation of Unit Tests and Oracles,G. Fraser; A. Zeller,"Saarland University, Saarbrücken; Saarland University, Saarbrücken",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,278,292,"To assess the quality of test suites, mutation analysis seeds artificial defects (mutations) into programs; a nondetected mutation indicates a weakness in the test suite. We present an automated approach to generate unit tests that detect these mutations for object-oriented classes. This has two advantages: First, the resulting test suite is optimized toward finding defects modeled by mutation operators rather than covering code. Second, the state change caused by mutations induces oracles that precisely detect the mutants. Evaluated on 10 open source libraries, our μtest prototype generates test suites that find significantly more seeded defects than the original manually written test suites.",1939-3520,,10.1109/TSE.2011.93,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6019060,Mutation analysis;test case generation;unit testing;test oracles;assertions;search-based testing.,Testing;Genetic algorithms;Biological cells;Software;Software algorithms;Generators;Libraries,automatic test pattern generation;object-oriented programming;optimisation;program testing,mutation driven generation;unit test;oracle;test suites quality;artificial defects;automated test case generation;object-oriented classes;optimization;mutation operators;open source libraries,,139.0,,52.0,,15 Sep 2011,,,IEEE,IEEE Journals
968,969,Model Checking Software with First Order Logic Specifications Using AIG Solvers,M. A. Noureddine; F. A. Zaraket,"Department of Computer Science, University of Illinois at Urbana Champaign, IL; Department of Electrical and Computer Engineering, American University of Beirut, Beirut, Lebanon",IEEE Transactions on Software Engineering,11 Aug 2016,2016,42,8,741,763,"Static verification techniques leverage Boolean formula satisfiability solvers such as SAT and SMT solvers that operate on conjunctive normal form and first order logic formulae, respectively, to validate programs. They force bounds on variable ranges and execution time and translate the program and its specifications into a Boolean formula. They are limited to programs of relatively low complexity for the following reasons. (1) A small increase in the bounds can cause a large increase in the size of the translated formula. (2) Boolean satisfiability solvers are restricted to using optimizations that apply at the level of the formula. Finally, (3) the Boolean formulae often need to be regenerated with higher bounds to ensure the correctness of the translation. We present a method that uses And-Inverter-Graph (AIG) sequential circuits, and AIG synthesis and verification frameworks to validate programs. An AIG is a Boolean formula with memory elements, logically complete negated conjunction gates, and a hierarchical structure. Encoding the validation problem of a program as an AIG (1) typically provides a more succinct representation than a Boolean formulae encoding with no memory elements, (2) preserves the high-level structure of the program, and (3) enables the use of a number of powerful automated analysis techniques that have no counterparts for other Boolean formulae such as CNF. Our method takes an imperative program with a first order logic specification consisting of a precondition and a postcondition pair, and a bound on the program variable ranges, and produces an AIG with a designated output that is ${true}$  when the program violates the specification. Our method uses AIG synthesis reduction techniques to reduce the AIG, and then uses AIG verification techniques to check the satisfiability of the designated output. The results show that our method can validate designs that are not possible with other state of the art techniques, and with bounds that are an order of magnitude larger.",1939-3520,,10.1109/TSE.2016.2520468,University Research Board; American University of Beirut; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7389426,Software verification;static analysis;Boolean satisfiability solvers;Hoare triplet,Sequential circuits;Model checking;Software;Encoding;Optimization;Radiation detectors;Interpolation,,,,2.0,,57.0,,21 Jan 2016,,,IEEE,IEEE Journals
969,970,Tools for the Rapid Prototyping of Provably Correct Ambient Intelligence Applications,A. Coronato; G. De Pietro,"National Research Council (CNR), Naples; National Research Council (CNR), Naples",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,975,991,"Ambient Intelligence technologies have not yet been widely adopted in safety critical scenarios. This principally has been due to fact that acceptable degrees of dependability have not been reached for the applications that rely on such technologies. However, the new critical application domains, like Ambient Assisted Living and Smart Hospitals, which are currently emerging, are increasing the need for methodologies and tools that can improve the reliability of the final systems. This paper presents a middleware architecture for safety critical Ambient Intelligence applications which provides the developer with services for runtime verification. It is now possible to continuously monitor and check the running system against correctness properties defined at design time. Moreover, a visual tool which allows the formal design of several of the characteristics of an Ambient Intelligence application and the automatic generation of setting up parameters and code for the middleware infrastructure is also presented.",1939-3520,,10.1109/TSE.2011.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963693,Safety critical ambient intelligence systems;middleware infrastructures;designing tools,Calculus;Runtime;Middleware;Ambient intelligence;Monitoring;Biomembranes;Mobile communication,middleware;safety-critical software;software prototyping;ubiquitous computing,rapid prototyping;ambient intelligence applications;safety critical scenarios;new critical application domains;ambient assisted living;smart hospitals;middleware architecture;runtime verification;visual tool;formal design;automatic generation;pervasive computing,,15.0,,48.0,,28 Jul 2011,,,IEEE,IEEE Journals
970,971,Making CEGAR More Efficient in Software Model Checking,C. Tian; Z. Duan; Z. Duan,"ICTT and ISN Laboratory, Xidian University, Xi’an, China; ICTT and ISN Laboratory, Xidian University, Xi’an, China; ICTT and ISN Laboratory, Xidian University, Xi’an, China",IEEE Transactions on Software Engineering,12 Dec 2014,2014,40,12,1206,1223,"Counter-example guided abstraction refinement (CEGAR) is widely used in software model checking. With an abstract model, the state space is largely reduced, however, a counterexample found in such a model that does not satisfy the desired property may not exist in the concrete model. Therefore, how to check whether a reported counterexample is spurious is a key problem in the abstraction-refinement loop. Next, in the case that a spurious counterexample is found, the abstract model needs to be further refined where an NP-hard state separation problem is often involved. Thus, how to refine the abstract model efficiently has attracted a great attention in the past years. In this paper, by re-analyzing spurious counterexamples, a new formal definition of spurious paths is given. Based on it, efficient algorithms for detecting spurious counterexamples are presented. By the new algorithms, when dealing with infinite counterexamples, the finite prefix to be analyzed will be polynomially shorter than the one dealt with by the existing algorithms. Moreover, in practical terms, the new algorithms can naturally be parallelized that enables multi-core processors contributes more in spurious counterexample checking. In addition, a novel refining approach by adding extra Boolean variables to the abstract model is presented. With this approach, not only the NP-hard state separation problem can be avoided, but also a smaller refined abstract model can be obtained. Experimental results show that the new algorithms perform well in practice.",1939-3520,,10.1109/TSE.2014.2357442,NSFC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6895263,Model checking;formal verification;abstraction;refinement;CEGAR,Model checking;Software design;Computational modeling;Benchmark testing,multiprocessing systems;parallel algorithms;program verification,Boolean variables;spurious counterexample checking;multicore processors;parallelized algorithms;polynomially-shorter finite prefix;infinite counterexamples;spurious counterexample detection;spurious paths;spurious counterexample reanalysis;NP-hard state separation problem;abstraction-refinement loop;state space reduction;abstract model;counter-example guided abstraction refinement;software model checking;CEGAR,,16.0,,30.0,,11 Sep 2014,,,IEEE,IEEE Journals
971,972,Architecture-Based Reliability Prediction with the Palladio Component Model,F. Brosch; H. Koziolek; B. Buhnova; R. Reussner,"FZI Forschungszentrum Informatik, Karlsruhe; ABB Corporate Research, Ladenburg; Masaryk University, Brno; Karlsruhe Institute of Technology (KIT), Karlsruhe",IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1319,1339,"With the increasing importance of reliability in business and industrial software systems, new techniques of architecture-based reliability engineering are becoming an integral part of the development process. These techniques can assist system architects in evaluating the reliability impact of their design decisions. Architecture-based reliability engineering is only effective if the involved reliability models reflect the interaction and usage of software components and their deployment to potentially unreliable hardware. However, existing approaches either neglect individual impact factors on reliability or hard-code them into formal models, which limits their applicability in component-based development processes. This paper introduces a reliability modeling and prediction technique that considers the relevant architectural factors of software systems by explicitly modeling the system usage profile and execution environment and automatically deriving component usage profiles. The technique offers a UML-like modeling notation whose models are automatically transformed into a formal analytical model. Our work builds upon the Palladio Component Model (PCM), employing novel techniques of information propagation and reliability assessment. We validate our technique with sensitivity analyses and simulation in two case studies. The case studies demonstrate effective support of usage profile analysis and architectural configuration ranking, together with the employment of reliability-improving architecture tactics.",1939-3520,,10.1109/TSE.2011.94,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6018968,Software architectures;quality analysis and evaluation;reliability;design tools and techniques,Unified modeling language;Software reliability;Markov processes;Phase change materials;Software architecture;Software quality;Design methodology,object-oriented programming;software architecture;software reliability;Unified Modeling Language,architecture based reliability prediction;palladio component model;industrial software system;architecture based reliability engineering;assist system architects;reliability impact;software component;component based development process;reliability modeling;system usage profile;execution environment;component usage profiles;UML like modeling notation;formal analytical model;information propagation;reliability assessment;sensitivity analysis;usage profile analysis;architectural configuration ranking;architecture tactics,,50.0,,63.0,,15 Sep 2011,,,IEEE,IEEE Journals
972,973,Specifying Dynamic Analyses by Extending Language Semantics,A. Lienhard; T. Girba; O. Nierstrasz,"University of Bern, Bern; University of Bern, Bern; University of Bern, Bern",IEEE Transactions on Software Engineering,29 May 2012,2012,38,3,694,706,"Dynamic analysis is increasingly attracting attention for debugging, profiling, and program comprehension. Ten to twenty years ago, many dynamic analyses investigated only simple method execution traces. Today, in contrast, many sophisticated dynamic analyses exist, for instance, for detecting memory leaks, analyzing ownership properties, measuring garbage collector performance, or supporting debugging tasks. These analyses depend on complex program instrumentations and analysis models, making it challenging to understand, compare, and reproduce the proposed approaches. While formal specifications and proofs are common in the field of static analysis, most dynamic analyses are specified using informal, textual descriptions. In this paper, we propose a formal framework using operational semantics that allows researchers to precisely specify their dynamic analysis. Our goal is to provide an accessible and reusable basis on which researchers who may not be familiar with rigorous specifications of dynamic analyses can build. By extending the provided semantics, one can concisely specify how runtime events are captured and how this data is transformed to populate the analysis model. Furthermore, our approach provides the foundations to reason about properties of a dynamic analysis.",1939-3520,,10.1109/TSE.2011.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5740933,Dynamic analysis;formal definitions and theory;tracing;debugging.,Semantics;Runtime;Arrays;Context;Analytical models;Performance analysis;Syntactics,formal specification;program debugging;programming language semantics,dynamic analysis specification;program debugging;memory leaks detection;ownership properties;garbage collector performance;complex program instrumentations;formal specifications;textual descriptions;informal descriptions;language semantics extending;program comprehension;program profiling,,,,26.0,,5 Apr 2011,,,IEEE,IEEE Journals
973,974,The Effects of Time Constraints on Test Case Prioritization: A Series of Controlled Experiments,H. Do; S. Mirarab; L. Tahvildari; G. Rothermel,"North Dakota State University, Fargo; IBM, Vancouver; University of Waterloo, Waterloo; University of Nebraska—Lincoln, Lincoln",IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,593,617,"Regression testing is an expensive process used to validate modified software. Test case prioritization techniques improve the cost-effectiveness of regression testing by ordering test cases such that those that are more important are run earlier in the testing process. Many prioritization techniques have been proposed and evidence shows that they can be beneficial. It has been suggested, however, that the time constraints that can be imposed on regression testing by various software development processes can strongly affect the behavior of prioritization techniques. If this is correct, a better understanding of the effects of time constraints could lead to improved prioritization techniques and improved maintenance and testing processes. We therefore conducted a series of experiments to assess the effects of time constraints on the costs and benefits of prioritization techniques. Our first experiment manipulates time constraint levels and shows that time constraints do play a significant role in determining both the cost-effectiveness of prioritization and the relative cost-benefit trade-offs among techniques. Our second experiment replicates the first experiment, controlling for several threats to validity including numbers of faults present, and shows that the results generalize to this wider context. Our third experiment manipulates the number of faults present in programs to examine the effects of faultiness levels on prioritization and shows that faultiness level affects the relative cost-effectiveness of prioritization techniques. Taken together, these results have several implications for test engineers wishing to cost-effectively regression test their software systems. These include suggestions about when and when not to prioritize, what techniques to employ, and how differences in testing processes may relate to prioritization cost--effectiveness.",1939-3520,,10.1109/TSE.2010.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482587,Regression testing;test case prioritization;cost-benefits;Bayesian networks;empirical studies.,Time factors;Software testing;Automatic testing;Maintenance engineering;Programming;System testing;Computer Society;Software systems;Bayesian methods;Software quality,belief networks;program testing;regression analysis;software fault tolerance,time constraints;test case prioritization techniques;regression testing;various software development processes;cost-benefit trade-offs;Bayesian networks,,83.0,,62.0,,7 Jun 2010,,,IEEE,IEEE Journals
974,975,The Impact of View Histories on Edit Recommendations,S. Lee; S. Kang; S. Kim; M. Staats,"Department of Computer Science, KAIST, Daejeon 305-701, Republic of Korea, Guseong-dong, Yuseong-gu; Department of Computer Science, KAIST, Daejeon 305-701, Republic of Korea, Guseong-dong, Yuseong-gu; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; is with the Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg",IEEE Transactions on Software Engineering,11 Mar 2015,2015,41,3,314,330,"Recommendation systems are intended to increase developer productivity by recommending files to edit. These systems mine association rules in software revision histories. However, mining coarse-grained rules using only edit histories produces recommendations with low accuracy, and can only produce recommendations after a developer edits a file. In this work, we explore the use of finer-grained association rules, based on the insight that view histories help characterize the contexts of files to edit. To leverage this additional context and fine-grained association rules, we have developed MI, a recommendation system extending ROSE, an existing edit-based recommendation system. We then conducted a comparative simulation of ROSE and MI using the interaction histories stored in the Eclipse Bugzilla system. The simulation demonstrates that MI predicts the files to edit with significantly higher recommendation accuracy than ROSE (about 63 over 35 percent), and makes recommendations earlier, often before developers begin editing. Our results clearly demonstrate the value of considering both views and edits in systems to recommend files to edit, and results in more accurate, earlier, and more flexible recommendations.",1939-3520,,10.1109/TSE.2014.2362138,"National Research Foundation of Korea; National Research Foundation of Korea; Ministry of Education; Ministry of Science, ICT & Future Planning; Information Technology Research Center; National IT Industry Promotion Agency; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6926851,Programming environments/construction tools;interactive environments;software maintenance;data mining;association rules;programmer interaction histories;Programming environments/construction tools;interactive environments;software maintenance;data mining;association rules;programmer interaction histories,Context;History;Association rules;Software;Accuracy;Predictive models,data mining;interactive programming;recommender systems,association rules mining;software revision histories;coarse grained rules mining;edit histories;finer grained association rules;MI;ROSE;edit-based recommendation system;programmer interaction histories,,11.0,,38.0,,16 Oct 2014,,,IEEE,IEEE Journals
975,976,Model-Based Test Oracle Generation for Automated Unit Testing of Agent Systems,L. Padgham; Z. Zhang; J. Thangarajah; T. Miller,"RMIT University, Melbourne; RMIT University, Melbourne; RMIT University, Melbourne; University of Melbourne, Melbourne",IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1230,1244,"Software testing remains the most widely used approach to verification in industry today, consuming between 30-50 percent of the entire development cost. Test input selection for intelligent agents presents a problem due to the very fact that the agents are intended to operate robustly under conditions which developers did not consider and would therefore be unlikely to test. Using methods to automatically generate and execute tests is one way to provide coverage of many conditions without significantly increasing cost. However, one problem using automatic generation and execution of tests is the oracle problem: How can we automatically decide if observed program behavior is correct with respect to its specification? In this paper, we present a model-based oracle generation method for unit testing belief-desire-intention agents. We develop a fault model based on the features of the core units to capture the types of faults that may be encountered and define how to automatically generate a partial, passive oracle from the agent design models. We evaluate both the fault model and the oracle generation by testing 14 agent systems. Over 400 issues were raised, and these were analyzed to ascertain whether they represented genuine faults or were false positives. We found that over 70 percent of issues raised were indicative of problems in either the design or the code. Of the 19 checks performed by our oracle, faults were found by all but 5 of these checks. We also found that 8 out the 11 fault types identified in our fault model exhibited at least one fault. The evaluation indicates that the fault model is a productive conceptualization of the problems to be expected in agent unit testing and that the oracle is able to find a substantial number of such faults with relatively small overhead in terms of false positives.",1939-3520,,10.1109/TSE.2013.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6464272,Test oracles;unit testing;BDI agents,Testing;Context;Object oriented modeling;Computational modeling;Fault diagnosis;Arrays;Robustness,fault diagnosis;multi-agent systems;program testing,model-based test oracle generation;agent system automated unit testing;software testing;test input selection;intelligent agents;test automatic generation;test execution;belief-desire-intention agents;fault model;core units;agent design models,,26.0,1.0,31.0,,18 Feb 2013,,,IEEE,IEEE Journals
976,977,Better Debugging via Output Tracing and Callstack-Sensitive Slicing,S. Horwitz; B. Liblit; M. Polishchuk,"University of Wisconsin-Madison, Madison; University of Wisconsin-Madison, Madison; Microsoft Corporation, Redmond",IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,7,19,"Debugging often involves 1) finding the point of failure (the first statement that produces bad output) and 2) finding and fixing the actual bug. Print statements and debugger break points can help with step 1. Slicing the program back from values used at the point of failure can help with step 2. However, neither approach is ideal: Debuggers and print statements can be clumsy and time-consuming and backward slices can be almost as large as the original program. This paper addresses both problems. We present callstack-sensitive slicing, which reduces slice sizes by leveraging the series of calls active when a program fails. We also show how slice intersections may further reduce slice sizes. We then describe a set of tools that identifies points of failure for programs that produce bad output. Finally, we apply our point-of-failure tools to a suite of buggy programs and evaluate callstack-sensitive slicing and slice intersection as applied to debugging. Callstack-sensitive slicing is very effective: On average, a callstack-sensitive slice is about 0.31 time the size of the corresponding full slice, down to just 0.06 time in the best case. Slice intersection is less impressive, on average, but may sometimes prove useful in practice.",1939-3520,,10.1109/TSE.2009.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5282499,Static program slicing;callstack-sensitive analysis;points of failure;output tracing and attribution.,Debugging;Programming profession;Computer crashes;Failure analysis;Testing;Linux,program debugging;program slicing;software reliability,callstack-sensitive slicing;program debugging;program slicing;point-of-failure tools;buggy programs;slice intersection,,21.0,,38.0,,9 Oct 2009,,,IEEE,IEEE Journals
977,978,A Flowchart Language for Quantum Programming,M. Ying; Y. Feng,"University of Technology, Sydney and Tsinghua University, Beijing; University of Technology, Sydney and Tsinghua University, Beijing",IEEE Transactions on Software Engineering,28 Jul 2011,2011,37,4,466,485,"Several high-level quantum programming languages have been proposed in the previous research. In this paper, we define a low-level flowchart language for quantum programming, which can be used in implementation of high-level quantum languages and in design of quantum compilers. The formal semantics of the flowchart language is given, and the notion of correctness for programs written in this language is introduced. A structured quantum programming theorem is presented, which provides a technique of translating quantum flowchart programs into programs written in a high-level language, namely, a quantum extension of the while-language.",1939-3520,,10.1109/TSE.2010.94,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611555,Quantum programming;flowchart language;while-language;structured programming.,Quantum computing;Semantics;Quantum mechanics;Programming;Computer languages;Probabilistic logic;Computers,flowcharting;formal languages;program compilers;program interpreters;programming language semantics;quantum computing,high level quantum programming language;low level flowchart language;quantum compiler design;formal semantics;structured quantum programming theorem;quantum flowchart program translation,,8.0,1.0,34.0,,28 Oct 2010,,,IEEE,IEEE Journals
978,979,Using Reduced Execution Flow Graph to Identify Library Functions in Binary Code,J. Qiu; X. Su; P. Ma,"School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, China",IEEE Transactions on Software Engineering,11 Feb 2016,2016,42,2,187,202,"Discontinuity and polymorphism of a library function create two challenges for library function identification, which is a key technique in reverse engineering. A new hybrid representation of dependence graph and control flow graph called Execution Flow Graph (EFG) is introduced to describe the semantics of binary code. Library function identification turns to be a subgraph isomorphism testing problem since the EFG of a library function instance is isomorphic to the sub-EFG of this library function. Subgraph isomorphism detection is time-consuming. Thus, we introduce a new representation called Reduced Execution Flow Graph (REFG) based on EFG to speed up the isomorphism testing. We have proved that EFGs are subgraph isomorphic as long as their corresponding REFGs are subgraph isomorphic. The high efficiency of the REFG approach in subgraph isomorphism detection comes from fewer nodes and edges in REFGs and new lossless filters for excluding the unmatched subgraphs before detection. Experimental results show that precisions of both the EFG and REFG approaches are higher than the state-of-the-art tool and the REFG approach sharply decreases the processing time of the EFG approach with consistent precision and recall.",1939-3520,,10.1109/TSE.2015.2470241,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7210204,Reverse engineering;static analysis;inline function;library function identification;subgraph isomorphism and graph mining;Reverse engineering;static analysis;inline function;library function identification;subgraph isomorphism and graph mining,Libraries;Registers;Binary codes;Testing;Joining processes;Flow graphs;Reverse engineering,binary codes;graph theory;reverse engineering;software libraries,reduced execution flow graph;library function identification;binary code;reverse engineering;hybrid representation;dependence graph;control flow graph;subgraph isomorphism testing problem;library function instance;subgraph isomorphism detection;REFG;lossless filters,,13.0,,29.0,,19 Aug 2015,,,IEEE,IEEE Journals
979,980,A Multi-Site Joint Replication of a Design Patterns Experiment Using Moderator Variables to Generalize across Contexts,J. L. Krein; L. Prechelt; N. Juristo; A. Nanthaamornphong; J. C. Carver; S. Vegas; C. D. Knutson; K. D. Seppi; D. L. Eggett,"Department of Computer Science, Provo, UT; Institut für Informatik, Germany; Computing School, Spain; Department of Information and Communication Technology, Thailand; Department of Computer Science, Tuscaloosa, AL; Computing School, Spain; Department of Computer Science, Provo, UT; Department of Computer Science, Provo, UT; Department of Statistics, Provo, UT",IEEE Transactions on Software Engineering,14 Apr 2016,2016,42,4,302,321,"Context. Several empirical studies have explored the benefits of software design patterns, but their collective results are highly inconsistent. Resolving the inconsistencies requires investigating moderators—i.e., variables that cause an effect to differ across contexts. Objectives. Replicate a design patterns experiment at multiple sites and identify sufficient moderators to generalize the results across prior studies. Methods. We perform a close replication of an experiment investigating the impact (in terms of time and quality) of design patterns (Decorator and Abstract Factory) on software maintenance. The experiment was replicated once previously, with divergent results. We execute our replication at four universities—spanning two continents and three countries—using a new method for performing distributed replications based on closely coordinated, small-scale instances (“joint replication”). We perform two analyses: 1) a  post-hoc analysis of moderators, based on frequentist and Bayesian statistics; 2) an a priori  analysis of the original hypotheses, based on frequentist statistics. Results. The main effect differs across the previous instances of the experiment and across the sites in our distributed replication. Our analysis of moderators (including developer experience and pattern knowledge) resolves the differences sufficiently to allow for cross-context (and cross-study) conclusions. The final conclusions represent 126 participants from five universities and 12 software companies, spanning two continents and at least four countries. Conclusions. The Decorator pattern is found to be preferable to a simpler solution during maintenance, as long as the developer has at least some prior knowledge of the pattern. For Abstract Factory, the simpler solution is found to be mostly equivalent to the pattern solution. Abstract Factory is shown to require a higher level of knowledge and/or experience than Decorator for the pattern to be beneficial.",1939-3520,,10.1109/TSE.2015.2488625,Spanish Ministry of Economy and Competitiveness; LLC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7294706,Design patterns;software maintenance;moderator variables;multi-site;joint replication;controlled experiment;Design patterns;software maintenance;moderator variables;multi-site;joint replication;controlled experiment,Production facilities;Design methodology;Training;Context modeling,,,,4.0,,42.0,,8 Oct 2015,,,IEEE,IEEE Journals
980,981,Integer Parameter Synthesis for Real-Time Systems,A. Jovanović; D. Lime; O. H. Roux,"Ecole Centrale de Nantes - IRCCyN UMR CNRS 6597, Nantes, France; Ecole Centrale de Nantes - IRCCyN UMR CNRS 6597, Nantes, France; Ecole Centrale de Nantes - IRCCyN UMR CNRS 6597, Nantes, France",IEEE Transactions on Software Engineering,12 May 2015,2015,41,5,445,461,"We provide a subclass of parametric timed automata (PTA) that we can actually and efficiently analyze, and we argue that it retains most of the practical usefulness of PTA for the modeling of real-time systems. The currently most useful known subclass of PTA, L/U automata, has a strong syntactical restriction for practical purposes, and we show that the associated theoretical results are mixed. We therefore advocate for a different restriction scheme: since in classical timed automata, real-valued clocks are always compared to integers for all practical purposes, we also search for parameter values as bounded integers. We show that the problem of the existence of parameter values such that some TCTL property is satisfied is PSPACE-complete. In such a setting, we can of course synthesize all the values of parameters and we give symbolic algorithms, for reachability and unavoidability properties, to do it efficiently, i.e., without an explicit enumeration. This also has the practical advantage of giving the result as symbolic constraints between the parameters. We finally report on a few experimental results to illustrate the practical usefulness of our approach.",1939-3520,,10.1109/TSE.2014.2357445,ANR; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6895298,Timed automata;parameters;synthesis;model-checking;real-time systems;symbolic algorithms,Cost accounting;Automata;Clocks;Radiation detectors;Upper bound;Delays;Real-time systems,automata theory;reachability analysis;real-time systems,integer parameter synthesis;real-time systems;parametric timed automata;PTA;real-valued clocks;TCTL property;PSPACE-complete;symbolic algorithms;reachability;symbolic constraints,,38.0,,36.0,,11 Sep 2014,,,IEEE,IEEE Journals
981,982,Automatically Generating Test Cases for Specification Mining,V. Dallmeier; N. Knopp; C. Mallon; G. Fraser; S. Hack; A. Zeller,"Universität des Saarlandes, Saarbrücken; Universität des Saarlandes, Saarbrücken; Universität des Saarlandes, Saarbrücken; Universität des Saarlandes, Saarbrücken; Universität des Saarlandes, Saarbrücken; Universität des Saarlandes, Saarbrücken",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,243,257,"Dynamic specification mining observes program executions to infer models of normal program behavior. What makes us believe that we have seen sufficiently many executions? The TAUTOKO (“Tautoko” is the Mãori word for “enhance, enrich.”) typestate miner generates test cases that cover previously unobserved behavior, systematically extending the execution space, and enriching the specification. To our knowledge, this is the first combination of systematic test case generation and typestate mining-a combination with clear benefits: On a sample of 800 defects seeded into six Java subjects, a static typestate verifier fed with enriched models would report significantly more true positives and significantly fewer false positives than the initial models.",1939-3520,,10.1109/TSE.2011.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6044587,Specification mining;test case generation;typestate analysis.,Testing;Java;Instruments;Schedules;Software;Heuristic algorithms;Fault detection,automatic test pattern generation;data mining;formal specification;Java;program verification,automatic test case generation;dynamic specification mining;program executions;normal program behavior;TAUTOKO;typestate mining;Java;static typestate verifier,,44.0,,31.0,,13 Oct 2011,,,IEEE,IEEE Journals
982,983,Timed Automata Modeling and Verification for Publish-Subscribe Structures Using Distributed Resources,V. Valero; G. Díaz; M. Cambronero,"Department of Computer Science, University of Castilla-La Mancha, Albacete, Spain; Department of Computer Science, University of Castilla-La Mancha, Albacete, Spain; Department of Computer Science, University of Castilla-La Mancha, Albacete, Spain",IEEE Transactions on Software Engineering,9 Jan 2017,2017,43,1,76,99,"In this paper we present a Timed Automata model for the Publish/Subscribe paradigm in the context of Web Service Compositions with distributed resources, on the basis of an algebraic language inspired by the WSRF standard constructions. This framework allows a set of participants in a Web Service composition to interact with one another and also to manage a collection of distributed resources. The model includes operations for clients to publish, discover and subscribe to resources, so as to be notified when the resource property values fulfill certain conditions (topic-based subscription). Simulation and model-checking techniques can therefore be applied to the obtained network of timed automata, in order to check whether certain properties of interest are satisfied. A specific case study is finally presented to illustrate the model and the verification of the relevant properties on the obtained timed automata model.",1939-3520,,10.1109/TSE.2016.2560842,Spanish Government; FEDER; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7463051,Publish/subscribe;formal modeling;timed automata;verification;model checking,Web services;Automata;Unified modeling language;Semantics;Clocks;Probabilistic logic;Context modeling,algebra;automata theory;formal verification;message passing;middleware;resource allocation;Web services,timed automata modeling;timed automata verification;publish-subscribe structures;resource distribution;publish-subscribe paradigm;Web service compositions;algebraic language;WSRF standard constructions;resource property values;topic-based subscription;model checking,,7.0,,24.0,,29 Apr 2016,,,IEEE,IEEE Journals
983,984,"Inferring Loop Invariants by Mutation, Dynamic Analysis, and Static Checking",J. P. Galeotti; C. A. Furia; E. May; G. Fraser; A. Zeller,"Saarland University, Saarbrücken, Germany; ETH Zurich, Switzerland; Google Inc, London, United Kingdom; Department of Computer Science, University of Sheffield, United Kingdom; Saarland University, Saarbrücken, Germany",IEEE Transactions on Software Engineering,13 Oct 2015,2015,41,10,1019,1037,"Verifiers that can prove programs correct against their full functional specification require, for programs with loops, additional annotations in the form of loop invariants-properties that hold for every iteration of a loop. We show that significant loop invariant candidates can be generated by systematically mutating postconditions; then, dynamic checking (based on automatically generated tests) weeds out invalid candidates, and static checking selects provably valid ones. We present a framework that automatically applies these techniques to support a program prover, paving the way for fully automatic verification without manually written loop invariants: Applied to 28 methods (including 39 different loops) from various java.util classes (occasionally modified to avoid using Java features not fully supported by the static checker), our DYNAMATE prototype automatically discharged 97 percent of all proof obligations, resulting in automatic complete correctness proofs of 25 out of the 28 methods-outperforming several state-of-the-art tools for fully automatic verification.",1939-3520,,10.1109/TSE.2015.2431688,European Research Council; European Union’s Seventh Framework Programme; ERC; EU FP7; Swiss SNF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7105412,Loop invariants;inference;automatic verification;functional properties;dynamic analysis;Loop invariants;inference;automatic verification;functional properties;dynamic analysis,Heuristic algorithms;Java;Generators;Detectors;Arrays;Prototypes;Instruments,formal specification;Java;program control structures;program testing;program verification;system monitoring,loop invariant inference;mutation;dynamic analysis;static checking;functional specification;program prover;automatic verification;Java.util classes;DYNAMATE prototype;automatic complete correctness proofs;test automatic generation,,13.0,,80.0,,11 May 2015,,,IEEE,IEEE Journals
984,985,"Evaluating Complexity, Code Churn, and Developer Activity Metrics as Indicators of Software Vulnerabilities",Y. Shin; A. Meneely; L. Williams; J. A. Osborne,"DePaul University, Chicago; North Carolina State University, Raleigh; North Carolina State University, Raleigh; North Carolina State University, Raleigh",IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,772,787,"Security inspection and testing require experts in security who think like an attacker. Security experts need to know code locations on which to focus their testing and inspection efforts. Since vulnerabilities are rare occurrences, locating vulnerable code locations can be a challenging task. We investigated whether software metrics obtained from source code and development history are discriminative and predictive of vulnerable code locations. If so, security experts can use this prediction to prioritize security inspection and testing efforts. The metrics we investigated fall into three categories: complexity, code churn, and developer activity metrics. We performed two empirical case studies on large, widely used open-source projects: the Mozilla Firefox web browser and the Red Hat Enterprise Linux kernel. The results indicate that 24 of the 28 metrics collected are discriminative of vulnerabilities for both projects. The models using all three types of metrics together predicted over 80 percent of the known vulnerable files with less than 25 percent false positives for both projects. Compared to a random selection of files for inspection and testing, these models would have reduced the number of files and the number of lines of code to inspect or test by over 71 and 28 percent, respectively, for both projects.",1939-3520,,10.1109/TSE.2010.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560680,Fault prediction;software metrics;software security;vulnerability prediction.,Fault diagnosis;Software security;Complexity theory;Predictive models;Charge coupled devices,Linux;online front-ends;program testing;public domain software;software fault tolerance;software metrics,code churn;software vulnerabilities;developer activity metrics;security inspection;software metrics;source code;vulnerable code locations;open-source projects;Mozilla Firefox Web browser;Red Hat enterprise Linux kernel,,224.0,2.0,43.0,,2 Sep 2010,,,IEEE,IEEE Journals
985,986,Examining the Potentially Confounding Effect of Class Size on the Associations between Object-Oriented Metrics and Change-Proneness,Y. Zhou; H. Leung; B. Xu,"State Key Laboratory for Novel Software Technology and Nanjing University, Jiangsu; Hong Kong Polytechnic University, Hong Kong; State Key Laboratory for Novel Software Technology and Nanjing University, Jiangsu",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,607,623,"Previous research shows that class size can influence the associations between object-oriented (OO) metrics and fault-proneness and therefore proposes that it should be controlled as a confounding variable when validating OO metrics on fault-proneness. Otherwise, their true associations may be distorted. However, it has not been determined whether this practice is equally applicable to other external quality attributes. In this paper, we use three size metrics, two of which are available during the high-level design phase, to examine the potentially confounding effect of class size on the associations between OO metrics and change-proneness. The OO metrics that are investigated include cohesion, coupling, and inheritance metrics. Our results, based on Eclipse, indicate that: 1) The confounding effect of class size on the associations between OO metrics and change-proneness, in general, exists, regardless of whichever size metric is used; 2) the confounding effect of class size generally leads to an overestimate of the associations between OO metrics and change-proneness; and 3) for many OO metrics, the confounding effect of class size completely accounts for their associations with change-proneness or results in a change of the direction of the associations. These results strongly suggest that studies validating OO metrics on change-proneness should also consider class size as a confounding variable.",1939-3520,,10.1109/TSE.2009.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4967613,Object-oriented;metrics;validation;class size;confounding;change-proneness.,Size control;Maintenance;Predictive models;Size measurement;Laboratories,inheritance;object-oriented programming;program verification;programming environments;software maintenance;software metrics;software quality,object-oriented metrics;change-proneness;fault-proneness;potentially confounding class size effect;high-level design phase;external quality attribute;cohesion metrics;coupling metrics;inheritance metrics;Eclipse;program validation,,70.0,,57.0,,26 May 2009,,,IEEE,IEEE Journals
986,987,An Empirical Methodology to Evaluate Vulnerability Discovery Models,F. Massacci; V. H. Nguyen,"DISI, University of Trento, Trento, TN, Italy; DISI, University of Trento, Trento, TN, Italy",IEEE Transactions on Software Engineering,12 Dec 2014,2014,40,12,1147,1162,"Vulnerability discovery models (VDMs) operate on known vulnerability data to estimate the total number of vulnerabilities that will be reported after a software is released. VDMs have been proposed by industry and academia, but there has been no systematic independent evaluation by researchers who are not model proponents. Moreover, the traditional evaluation methodology has some issues that biased previous studies in the field. In this work we propose an empirical methodology that systematically evaluates the performance of VDMs along two dimensions (quality and predictability) and addresses all identified issues of the traditional methodology. We conduct an experiment to evaluate most existing VDMs on popular web browsers' vulnerability data. Our comparison shows that the results obtained by the proposed methodology are more informative than those by the traditional methodology. Among evaluated VDMs, the simplest linear model is the most appropriate choice in terms of both quality and predictability for the first 6-12 months since a release date. Otherwise, logistics-based models are better choices.",1939-3520,,10.1109/TSE.2014.2354037,Seventh Framework Programme; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6891367,Software security;empirical evaluation;vulnerability discovery model;vulnerability analysis,Data models;Computer security;Operating systems;Browsers;Computer bugs;Predictive models,online front-ends;security of data;software quality,empirical methodology;vulnerability discovery model evaluation;VDM;quality;predictability;Web browser vulnerability data;logistics-based model;time 6 month to 12 month,,25.0,,54.0,,4 Sep 2014,,,IEEE,IEEE Journals
987,988,An Integrative Economic Optimization Approach to Systems Development Risk Management,M. Benaroch; J. Goldstein,"Syracuse University, Syracuse; Syracuse University, Syracuse",IEEE Transactions on Software Engineering,2 Oct 2009,2009,35,5,638,653,"Despite significant research progress on the problem of managing systems development risk, we are yet to see this problem addressed from an economic optimization perspective. Doing so entails answering the question: What mitigations should be planned and deployed throughout the life of a systems development project in order to control risk and maximize project value? We introduce an integrative economic optimization approach to solving this problem. The approach is integrative since it bridges two complementary research streams: one takes a traditional microlevel technical view on the software development endeavor alone, another takes a macrolevel business view on the entire life cycle of a systems project. Bridging these views requires recognizing explicitly that value-based risk management decisions pertaining to one level impact and can be impacted by decisions pertaining to the other level. The economic optimization orientation follows from reliance on real options theory in modeling risk management decisions within a dynamic stochastic optimization setting. Real options theory is well suited to formalizing the impacts of risk as well as the asymmetric and contingent economic benefits of mitigations, in a way that enables their optimal balancing. We also illustrate how the approach is applied in practice to a small realistic example.",1939-3520,,10.1109/TSE.2009.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815277,Risk management;systems development;economics.,Risk management;Programming;Control systems;Bridges;Costs;Risk analysis;Research and development management;Stochastic processes;Information analysis;Information management,business data processing;dynamic programming;macroeconomics;project management;risk management;software prototyping;stochastic programming,integrative economic optimization approach;system development risk management;system development project life cycle;microlevel technical view;software development;macrolevel business view;value-based risk management decision;dynamic stochastic optimization setting;real option theory,,6.0,,43.0,,17 Apr 2009,,,IEEE,IEEE Journals
988,989,An Ontology-Based Product Architecture Derivation Approach,H. A. Duran-Limon; C. A. Garcia-Rios; F. E. Castillo-Barrera; R. Capilla,"Department of Information Systems, University of Guadalajara, CUCEA, Mexico; Department of Information Systems, University of Guadalajara, CUCEA, Mexico; School of Engineering, Autonomous University of San Luis Potosi, Mexico; Department of Computer Science, Rey Juan Carlos University of Madrid, Spain",IEEE Transactions on Software Engineering,9 Dec 2015,2015,41,12,1153,1168,"Software product line (SPL) engineering has proven to improve software quality and shorten development cycles, cost and time. In product line engineering, product derivation is concerned with the realization of the variability at the implementation level. However, the majority of research works focuses on instantiating the variants selected in the final product, while the derivation at the architecture level has been poorly explored. As product line engineers often customize the product architecture by hand during the application engineering phase, the derivation and customization processes of the product line architecture (PLA) might be in some cases error-prone. Consequently, in this research we present an Ontology-based product Architecture Derivation (OntoAD) framework which automates the derivation of product-specific architectures from an SPL architecture. Our solution uses a language-independent model to specify the product line architecture and a model-driven engineering approach for architecture derivation activities. We use an ontology formalism to reason about the automatic generation of model-to-model transformation rules based on the selection of features and we illustrate our approach using a voice over IP motivating example. Finally, we report results about scalability and performance regarding the size of the variability model.",1939-3520,,10.1109/TSE.2015.2449854,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7134799,Software Product Lines;Feature Models;Software Architecture;Product Derivation;Architecture Derivation;Ontologies;Model-Driven Engineering;Scalability;Software product lines;feature models;software architecture;product derivation;architecture derivation;ontologies;model-driven engineering;scalability,Unified modeling language;Computer architecture;Ontologies;Software product lines;Software architecture;Scalability,ontologies (artificial intelligence);software architecture;software product lines;software quality,ontology-based product architecture derivation approach;software product line engineering;SPL engineering;software quality;software development cycles;software development cost;software development time;product derivation;product customization;product line architecture;PLA;OntoAD;product-specific architectures;SPL architecture;language-independent model;model-driven engineering;architecture derivation activities;model-to-model transformation rules;features selection;voice over IP,,3.0,,53.0,,25 Jun 2015,,,IEEE,IEEE Journals
989,990,GoPrime: A Fully Decentralized Middleware for Utility-Aware Service Assembly,M. Caporuscio; V. Grassi; M. Marzolla; R. Mirandola,"Department of Computer Science, Linnaeus University, Växjö, Sweden; Informatica, Sistemi e Produzione, University of Roma “Tor Vergata,”, Roma, Italy; Dipartimento di Informatica Scienza e Ingegneria, University of Bologna, Bologna, Italy; Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, Italy",IEEE Transactions on Software Engineering,11 Feb 2016,2016,42,2,136,152,"Modern applications, e.g., for pervasive computing scenarios, are increasingly reliant on systems built from multiple distributed components, which must be suitably composed to meet some specified functional and non-functional requirements. A key challenge is how to efficiently and effectively manage such complex systems. The use of self-management capabilities has been suggested as a possible way to address this challenge. To cope with the scalability and robustness issues of large distributed systems, self-management should ideally be architected in a decentralized way, where the overall system behavior emerges from local decisions and interactions. Within this context, we propose GOPRIME, a fully decentralized middleware solution for the adaptive self-assembly of distributed services. The GOPRIME goal is to build and maintain an assembly of services that, besides functional requirements, fulfils also global quality-of-service and structural requirements. The key aspect of GOPRIME is the use of a gossip protocol to achieve decentralized information dissemination and decision making. To show the validity of our approach, we present results from the experimentation of a prototype implementation of GOPRIME in a mobile health application, and an extensive set of simulation experiments that assess the effectiveness of GOPRIME in terms of scalability, robustness and convergence speed.",1939-3520,,10.1109/TSE.2015.2476797,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7243346,Service-oriented architecture;pervasive computing;runtime adaptation;quality of service;gossip protocol;Service-oriented architecture;pervasive computing;runtime adaptation;quality of service;gossip protocol,Assembly;Compounds;Quality of service;Peer-to-peer computing;Scalability;Middleware;Robustness,distributed processing;middleware;ubiquitous computing,GOPRIME;fully decentralized middleware;utility-aware service assembly;pervasive computing;distributed components;self-management capabilities;gossip protocol;decentralized information dissemination;decision making;mobile health application,,11.0,,30.0,,4 Sep 2015,,,IEEE,IEEE Journals
990,991,Usability through Software Design,L. Carvajal; A. M. Moreno; M. Sánchez-Segura; A. Seffah,"Universidad Politécnica de Madrid, Madrid; Universidad Politécnica de Madrid, Madrid; Carlos III University of Madrid, Leganes; Concordia University, Montreal",IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1582,1596,"Over the past two decades, the HCI community has proposed specific features that software applications should include to overcome some of the most common usability problems. However, incorporating such usability features into software applications may not be a straightforward process for software developers who have not been trained in usability (i.e., determining when, how, and why usability features should been considered). We have defined a set of usability guidelines for software development to help software engineers incorporate particular usability features into their applications. In this paper, we focus on the software design artifacts provided by the guidelines. We detail the structure of the proposed design artifacts and how they should be used according to the software development process and software architecture used in each application. We have tested our guidelines in an academic setting. Preliminary validation shows that the use of the guidelines reduces development time, improves the quality of the resulting designs, and significantly decreases the perceived complexity of the usability features from the developers' perspective.",1939-3520,,10.1109/TSE.2013.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6523225,Software usability;software design;software design patterns,Usability;Guidelines;Human computer interaction;Unified modeling language;Communities,human computer interaction;object-oriented methods;software architecture;software quality;user interfaces,software usability;software design patterns;HCI community;human computer interaction;software development process;software design artifacts;software architecture;integral software development quality aspect,,17.0,,24.0,,4 Jun 2013,,,IEEE,IEEE Journals
991,992,"DESSERT: a DividE-and-conquer methodology for identifying categorieS, choiceS, and choicE Relations for Test case generation",T. Y. Chen; P. Poon; S. Tang; T. H. Tse,"Swinburne University of Technology, Melbourne; The Hong Kong Polytechnic University, Hong Kong; Swinburne University of Technology, Melbourne; The University of Hong Kong, Hong Kong",IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,794,809,"This paper extends the choce relation framework, abbreviated as choc'late, which assists software testers in the application of category/choice methods to testing. choc'late assumes that the tester is able to construct a single choice relation table from the entire specification; this table then forms the basis for test case generation using the associated algorithms. This assumption, however, may not hold true when the specification is complex and contains many specification components. For such a specification, the tester may construct a preliminary choice relation table from each specification component, and then consolidate all the preliminary tables into a final table to be processed by choc'late for test case generation. However, it is often difficult to merge these preliminary tables because such merging may give rise to inconsistencies among choice relations or overlaps among choices. To alleviate this problem, we introduce a DividE-and-conquer methodology for identifying categorieS, choiceS, and choicE Relations for Test case generation, abbreviated as dessert. The theoretical framework and the associated algorithms are discussed. To demonstrate the viability and effectiveness of our methodology, we describe case studies using the specifications of three real-life commercial software systems.",1939-3520,,10.1109/TSE.2011.69,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5963695,Black-box testing;category-partition method;choice relation framework;choice relation table;software testing;test case generation,Awards activities;Electronic mail;Software systems;Encoding;Software testing,divide and conquer methods;formal specification;program testing,DESSERT;divide-and-conquer methodology;category identification;choice identification;choice relation identification;test case generation;specification components;real-life commercial software systems;software testing;CHOC'LATE;black-box testing,,12.0,,18.0,,28 Jul 2011,,,IEEE,IEEE Journals
992,993,Program Behavior Discovery and Verification: A Graph Grammar Approach,C. Zhao; J. Kong; K. Zhang,"The University of Texas at Dallas, Richardson; North Dakota State University, Fargo; The University of Texas at Dallas, Richardson",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,431,448,"Discovering program behaviors and functionalities can ease program comprehension and verification. Existing program analysis approaches have used text mining algorithms to infer behavior patterns or formal models from program execution. When one tries to identify the hierarchical composition of a program behavior at different abstraction levels, textual descriptions are not informative and expressive enough. To address this, we present a semi-automatic graph grammar approach to retrieving the hierarchical structure of the program behavior. The hierarchical structure is built on recurring substructures in a bottom-up fashion. We formulate the behavior discovery and verification problem as a graph grammar induction and parsing problem, i.e., automatically iteratively mining qualified patterns and then constructing graph rewriting rules. Furthermore, using the induced grammar to parse the behavioral structure of a new program could verify if the program has the same behavioral properties specified by the grammar.",1939-3520,,10.1109/TSE.2010.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383371,Visual language;graph grammar induction;program comprehension;reengineering.,Software maintenance;Reverse engineering;Learning automata;Software systems;Data mining;Clustering algorithms;Pattern analysis;Algorithm design and analysis;Text mining;Documentation,data mining;graph grammars;program verification,program behavior discovery;program behavior verification;program comprehension;text mining algorithms;behavior patterns;formal models;program execution;semi-automatic graph grammar approach;graph rewriting rules;mining qualified patterns,,17.0,,60.0,,15 Jan 2010,,,IEEE,IEEE Journals
993,994,An Attack Surface Metric,P. K. Manadhata; J. M. Wing,"Symantec Research Labs, Culver City; Carnegie Mellon University, Pittsburgh and US National Science Foundation, Arlington",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,371,386,"Measurement of software security is a long-standing challenge to the research community. At the same time, practical security metrics and measurements are essential for secure software development. Hence, the need for metrics is more pressing now due to a growing demand for secure software. In this paper, we propose using a software system's attack surface measurement as an indicator of the system's security. We formalize the notion of a system's attack surface and introduce an attack surface metric to measure the attack surface in a systematic manner. Our measurement method is agnostic to a software system's implementation language and is applicable to systems of all sizes; we demonstrate our method by measuring the attack surfaces of small desktop applications and large enterprise systems implemented in C and Java. We conducted three exploratory empirical studies to validate our method. Software developers can mitigate their software's security risk by measuring and reducing their software's attack surfaces. Our attack surface reduction approach complements the software industry's traditional code quality improvement approach for security risk mitigation and is useful in multiple phases of the software development lifecycle. Our collaboration with SAP demonstrates the use of our metric in the software development process.",1939-3520,,10.1109/TSE.2010.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5482589,Code design;life cycle;product metrics;protection mechanisms;risk mitigation;software security.,Software measurement;Security;Programming;Software systems;Size measurement;Time measurement;Pressing;Application software;Java;Software quality,C language;Java;security;software metrics,attack surface metric;software security;security metrics;software development;implementation language;C language;Java language,,268.0,7.0,53.0,,7 Jun 2010,,,IEEE,IEEE Journals
994,995,Improving Multi-Objective Test Case Selection by Injecting Diversity in Genetic Algorithms,A. Panichella; R. Oliveto; M. D. Penta; A. De Lucia,"Department of Mathematics and Computer Science, University of Salerno, Fisciano, Salerno, Italy; Department of Bioscience and Territory, University of Molise, Pesche, Isernia, Italy; Department of Engineering, University of Sannio, Benevento, Italy; Department of Mathematics and Computer Science, University of Salerno, Fisciano, Salerno, Italy",IEEE Transactions on Software Engineering,14 Apr 2015,2015,41,4,358,383,"A way to reduce the cost of regression testing consists of selecting or prioritizing subsets of test cases from a test suite according to some criteria. Besides greedy algorithms, cost cognizant additional greedy algorithms, multi-objective optimization algorithms, and multi-objective genetic algorithms (MOGAs), have also been proposed to tackle this problem. However, previous studies have shown that there is no clear winner between greedy and MOGAs, and that their combination does not necessarily produce better results. In this paper we show that the optimality of MOGAs can be significantly improved by diversifying the solutions (sub-sets of the test suite) generated during the search process. Specifically, we introduce a new MOGA, coined as DIversity based Genetic Algorithm (DIV-GA), based on the mechanisms of orthogonal design and orthogonal evolution that increase diversity by injecting new orthogonal individuals during the search process. Results of an empirical study conducted on eleven programs show that DIV-GA outperforms both greedy algorithms and the traditional MOGAs from the optimality point of view. Moreover, the solutions (sub-sets of the test suite) provided by DIV-GA are able to detect more faults than the other algorithms, while keeping the same test execution cost.",1939-3520,,10.1109/TSE.2014.2364175,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6936894,Test Case Selection;Regression Testing;Orthogonal Design;Singular Value Decomposition;Genetic Algorithms;Empirical Studies;Test case selection;regression testing;orthogonal design;singular value decomposition;genetic algorithms;empirical studies,Optimization;Greedy algorithms;Testing;Linear programming;Genetic algorithms;Genetics;Sociology,genetic algorithms;greedy algorithms;program testing;search problems,multiobjective test case selection improvement;regression testing cost reduction;test case subset prioritization;test case subset selection;greedy algorithms;multiobjective optimization algorithms;multiobjective genetic algorithms;MOGA optimality improvement;test suite subsets;search process;diversity-based genetic algorithm;DIV-GA;orthogonal design mechanism;orthogonal evolution mechanism;empirical analysis,,51.0,,76.0,,27 Oct 2014,,,IEEE,IEEE Journals
995,996,Efficient Consistency Measurement Based on Behavioral Profiles of Process Models,M. Weidlich; J. Mendling; M. Weske,"Hasso Plattner Institute, Potsdam; Humboldt-Universität zu Berlin, Berlin; Hasso Plattner Institute, Berlin",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,410,429,"Engineering of process-driven business applications can be supported by process modeling efforts in order to bridge the gap between business requirements and system specifications. However, diverging purposes of business process modeling initiatives have led to significant problems in aligning related models at different abstract levels and different perspectives. Checking the consistency of such corresponding models is a major challenge for process modeling theory and practice. In this paper, we take the inappropriateness of existing strict notions of behavioral equivalence as a starting point. Our contribution is a concept called behavioral profile that captures the essential behavioral constraints of a process model. We show that these profiles can be computed efficiently, i.e., in cubic time for sound free-choice Petri nets w.r.t. their number of places and transitions. We use behavioral profiles for the definition of a formal notion of consistency which is less sensitive to model projections than common criteria of behavioral equivalence and allows for quantifying deviation in a metric way. The derivation of behavioral profiles and the calculation of a degree of consistency have been implemented to demonstrate the applicability of our approach. We also report the findings from checking consistency between partially overlapping models of the SAP reference model.",1939-3520,,10.1109/TSE.2010.96,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5611557,Process model analysis;process model alignment;behavioral abstraction;consistency checking;consistency measures.,Unified modeling language;Business;Analytical models;Semantics;Computational modeling;Petri nets;Software,commerce;corporate modelling;Petri nets,efficient consistency measurement;behavioral profiles;process-driven business applications;business requirements;system specifications;business process modeling;behavioral constraints;Petri nets;SAP reference model,,113.0,,82.0,,28 Oct 2010,,,IEEE,IEEE Journals
996,997,Developer Micro Interaction Metrics for Software Defect Prediction,T. Lee; J. Nam; D. Han; S. Kim; H. Peter In,"Korea University, Seoul, South Korea; University of Waterloo, ON, Canada; University Colleage London, London, United Kingdom; Hong Kong University of Science and Technology, Hong Kong, China; Korea University, Seoul, South Korea",IEEE Transactions on Software Engineering,10 Nov 2016,2016,42,11,1015,1035,"To facilitate software quality assurance, defect prediction metrics, such as source code metrics, change churns, and the number of previous defects, have been actively studied. Despite the common understanding that developer behavioral interaction patterns can affect software quality, these widely used defect prediction metrics do not consider developer behavior. We therefore propose micro interaction metrics (MIMs), which are metrics that leverage developer interaction information. The developer interactions, such as file editing and browsing events in task sessions, are captured and stored as information by Mylyn, an Eclipse plug-in. Our experimental evaluation demonstrates that MIMs significantly improve overall defect prediction accuracy when combined with existing software measures, perform well in a cost-effective manner, and provide intuitive feedback that enables developers to recognize their own inefficient behaviors during software development.",1939-3520,,10.1109/TSE.2016.2550458,"Next-Generation Information Computing Development Program; National Research Foundation of Korea; Ministry of Education, Science and Technology; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7447797,Defect prediction;software quality;software metrics;developer interaction;Mylyn,Software quality;Software metrics;Quality assurance;Complexity theory,software maintenance;software metrics;software quality,developer microinteraction metrics;software quality assurance;software defect prediction;defect prediction metrics;developer behavioral interaction patterns;MIM metric;developer interaction information;Mylyn plug-in;Eclipse plug-in;software development,,25.0,,66.0,,5 Apr 2016,,,IEEE,IEEE Journals
997,998,A fluid model for layered queueing networks,M. Tribastone,"Ludwig-Maximilians University of Munich, Munich",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,744,756,"Layered queueing networks are a useful tool for the performance modeling and prediction of software systems that exhibit complex characteristics such as multiple tiers of service, fork/join interactions, and asynchronous communication. These features generally result in nonproduct form behavior for which particularly efficient approximations based on mean value analysis (MVA) have been devised. This paper reconsiders the accuracy of such techniques by providing an interpretation of layered queueing networks as fluid models. Mediated by an automatic translation into a stochastic process algebra, PEPA, a network is associated with a set of ordinary differential equations (ODEs) whose size is insensitive to the population levels in the system under consideration. A substantial numerical assessment demonstrates that this approach significantly improves the quality of the approximation for typical performance indices such as utilization, throughput, and response time. Furthermore, backed by established theoretical results of asymptotic convergence, the error trend shows monotonic decrease with larger population sizes-a behavior which is found to be in sharp contrast with that of approximate mean value analysis, which instead tends to increase.",1939-3520,,10.1109/TSE.2012.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6314480,Modeling and prediction;Markov processes;PEPA;ordinary differential equations;queueing networks;mean value analysis,Approximation methods;Unified modeling language;Stochastic processes;Sociology;Statistics;Servers;Accuracy,approximation theory;differential equations;queueing theory;software performance evaluation,performance modeling;performance prediction;software systems;layered queueing networks;nonproduct form behavior;mean value analysis;MVA;fluid models;automatic translation;stochastic process algebra;PEPA;ordinary differential equations;numerical assessment;approximation quality;performance indices;asymptotic convergence,,22.0,,33.0,,27 Sep 2012,,,IEEE,IEEE Journals
998,999,Local versus Global Lessons for Defect Prediction and Effort Estimation,T. Menzies; A. Butcher; D. Cok; A. Marcus; L. Layman; F. Shull; B. Turhan; T. Zimmermann,"West Virginia University, Morgantown; West Virginia University, Morgantown; GrammaTech, Ithaca; Wayne State University, Detroit; Fraunhofer Center, College Park; Fraunhofer Center, College Park; University of Oulu, Oulu; Microsoft Research, Redmond",IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,822,834,"Existing research is unclear on how to generate lessons learned for defect prediction and effort estimation. Should we seek lessons that are global to multiple projects or just local to particular projects? This paper aims to comparatively evaluate local versus global lessons learned for effort estimation and defect prediction. We applied automated clustering tools to effort and defect datasets from the PROMISE repository. Rule learners generated lessons learned from all the data, from local projects, or just from each cluster. The results indicate that the lessons learned after combining small parts of different data sources (i.e., the clusters) were superior to either generalizations formed over all the data or local lessons formed from particular projects. We conclude that when researchers attempt to draw lessons from some historical data source, they should 1) ignore any existing local divisions into multiple sources, 2) cluster across all available data, then 3) restrict the learning of lessons to the clusters from other sources that are nearest to the test data.",1939-3520,,10.1109/TSE.2012.83,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363444,Data mining;clustering;defect prediction;effort estimation,Estimation;Data models;Context;Java;Telecommunications;Measurement;Software,automatic test pattern generation;data mining;pattern clustering,defect prediction;effort estimation;global lessons;local lessons;automated clustering tools;PROMISE repository;data source;learned lesson generated rule;defect dataset,,105.0,,71.0,,29 Nov 2012,,,IEEE,IEEE Journals
999,1000,"Class Schema Evolution for Persistent Object-Oriented Software: Model, Empirical Study, and Automated Support",M. Piccioni; M. Oriol; B. Meyer,"ETH Zurich, Zurich; ABB Corporate Research, Industrial Software Systems, Baden-Dättwil and University of York, York; ETH Zurich, Zurich",IEEE Transactions on Software Engineering,24 Jan 2013,2013,39,2,184,196,"With the wide support for object serialization in object-oriented programming languages, persistent objects have become commonplace and most large object-oriented software systems rely on extensive amounts of persistent data. Such systems also evolve over time. Retrieving previously persisted objects from classes whose schema has changed is, however, difficult, and may lead to invalidating the consistency of the application. The ESCHER framework addresses these issues through an IDE-integrated approach that handles class schema evolution by managing versions of the code and generating transformation functions automatically. The infrastructure also enforces class invariants to prevent the introduction of potentially corrupt objects. This paper describes a model for class attribute changes, a measure for class evolution robustness, four empirical studies, and the design and implementation of the ESCHER system.",1939-3520,,10.1109/TSE.2011.123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6122034,Versioning;persistence;serialization;object-oriented class schema evolution;IDE integration,Object oriented modeling;Java;Databases;Software;Robustness;Dictionaries;Atomic measurements,object-oriented languages;object-oriented programming;persistent objects,persistent object-oriented software;object serialization;object-oriented programming languages;object-oriented software systems;IDE-integrated approach;class schema evolution;automatic transformation function generation;potentially corrupt objects;class evolution robustness;ESCHER system implementation;ESCHER system design,,6.0,,43.0,,3 Jan 2012,,,IEEE,IEEE Journals
1000,1001,"On the Accuracy, Efficiency, and Reusability of Automated Test Oracles for Android Devices",Y. Lin; J. F. Rojas; E. T. -. Chu; Y. Lai,"Department of Computer Science, National Chiao Tung University, University Road, Hsinchu, Taiwan; Department of Computer Science, National Chiao Tung University, University Road, Hsinchu, Taiwan; Department of Computer Science and Information Engineering, National Yunlin University of Science and Technology, Yunlin, Taiwan; Department of Information Management, National Taiwan University of Science and Technology, Keelung Road, Taipei, Taiwan",IEEE Transactions on Software Engineering,9 Oct 2014,2014,40,10,957,970,"Automated GUI testing consists of simulating user events and validating the changes in the GUI in order to determine if an Android application meets specifications. Traditional record-replay testing tools mainly focus on facilitating the test case writing process but not the replay and verification process. The accuracy of testing tools degrades significantly when the device under test (DUT) is under heavy load. In order to improve the accuracy, our previous work, SPAG, uses event batching and smart wait function to eliminate the uncertainty of the replay process and adopts GUI layout information to verify the testing results. SPAG maintains an accuracy of up to 99.5 percent and outperforms existing methods. In this work, we propose smart phone automated GUI testing tool with camera (SPAG-C), an extension of SPAG, to test an Android hardware device. Our goal is to further reduce the time required to record test cases and increase reusability of the test oracle without compromising test accuracy. In the record stage, SPAG captures screenshots from device's frame buffer and writes verification commands into the test case. Unlike SPAG, SPAG-C captures the screenshots from an external camera instead of frame buffer. In the replay stage, SPAG-C automatically performs image comparison while SPAG simply performs a string comparison to verify the test results. In order to make SPAG-C reusable for different devices and to allow bettersynchronization at the time of capturing images, we develop a new architecture that uses an external camera and Web services to decouple the test oracle. Our experiments show that recording a test case using SPAG-C's automatic verification is as fast as SPAG's but more accurate. Moreover, SPAG-C is 50 to 75 percent faster than SPAG in achieving the same test accuracy. With reusability, SPAG-C reduces the testing time from days to hours for heterogeneous devices.",1939-3520,,10.1109/TSE.2014.2331982,National Science Council (NSC) and Institute of Information Industry (III) in Taiwan; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6840332,Reusable software;test execution;testing tools;user interfaces,Graphical user interfaces;Testing;Androids;Humanoid robots;Accuracy;Smart phones;Performance evaluation,graphical user interfaces;program testing;smart phones;software reusability;Web services,automated test oracles;Android devices;user events;Android application;traditional record-replay testing tools;test case writing process;replay process;verification process;device under test;DUT;event batching;smart wait function;GUI layout information;smart phone automated GUI testing tool;with camera;SPAG-C;Android hardware device;test accuracy;frame buffer;replay stage;image comparison;capturing images;Web services;automatic verification,,20.0,,35.0,,19 Jun 2014,,,IEEE,IEEE Journals
1001,1002,The Impact of Design and Code Reviews on Software Quality: An Empirical Study Based on PSP Data,C. F. Kemerer; M. C. Paulk,"University of Pittsburgh, Pittsburgh; Carnegie Mellon University, Pittsburgh",IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,534,550,"This research investigates the effect of review rate on defect removal effectiveness and the quality of software products, while controlling for a number of potential confounding factors. Two data sets of 371 and 246 programs, respectively, from a personal software process (PSP) approach were analyzed using both regression and mixed models. Review activities in the PSP process are those steps performed by the developer in a traditional inspection process. The results show that the PSP review rate is a significant factor affecting defect removal effectiveness, even after accounting for developer ability and other significant process variables. The recommended review rate of 200 LOC/hour or less was found to be an effective rate for individual reviews, identifying nearly two-thirds of the defects in design reviews and more than half of the defects in code reviews.",1939-3520,,10.1109/TSE.2009.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4815279,Code reviews;design reviews;inspections;software process;software quality;defects;software measurement;mixed models;personal software process (PSP).,Software quality;Inspection;Business continuity;Software performance;Computer Society;Lab-on-a-chip;Software design;Software measurement;Costs;Job shop scheduling,program debugging;program testing;regression analysis;software metrics;software process improvement;software quality,design review impact;code review impact;software product quality;empirical study;PSP review rate;personal software process improvement approach;defect removal effectiveness;regression model;mixed model;inspection process;software measurement;business chain reaction,,51.0,1.0,55.0,,17 Apr 2009,,,IEEE,IEEE Journals
1002,1003,Which Crashes Should I Fix First?: Predicting Top Crashes at an Early Stage to Prioritize Debugging Efforts,D. Kim; X. Wang; S. Kim; A. Zeller; S. C. Cheung; S. Park,"Sogang University, Seoul; The Hong Kong University of Science and Technology, Hong Kong; The Hong Kong University of Science and Technology, Hong Kong; Saarland University, Saarbrücken; The Hong Kong University of Science and Technology, Hong Kong; Sogang University, Seoul",IEEE Transactions on Software Engineering,27 May 2011,2011,37,3,430,447,"Many popular software systems automatically report failures back to the vendors, allowing developers to focus on the most pressing problems. However, it takes a certain period of time to assess which failures occur most frequently. In an empirical investigation of the Firefox and Thunderbird crash report databases, we found that only 10 to 20 crashes account for the large majority of crash reports; predicting these “top crashes” thus could dramatically increase software quality. By training a machine learner on the features of top crashes of past releases, we can effectively predict the top crashes well before a new release. This allows for quick resolution of the most important crashes, leading to improved user experience and better allocation of maintenance efforts.",1939-3520,,10.1109/TSE.2011.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5711013,Top crash;machine learning;crash reports;social network analysis;data mining.,Fires;Feature extraction;Software;Testing;Computer bugs;Training,program debugging;software maintenance;software quality;system recovery,debugging;software systems;software failures;Firefox crash report databases;Thunderbird crash report databases;software quality;software maintenance,,44.0,,59.0,,10 Feb 2011,,,IEEE,IEEE Journals
1003,1004,Exception Handling Patterns for Process Modeling,B. S. Lerner; S. Christov; L. J. Osterweil; R. Bendraou; U. Kannengiesser; A. Wise,"Mount Holyoke College, South Hadley; University of Massachusetts, Amherst; University of Massachusetts, Amherst; Université Pierre & Marie Curie, Paris; NICTA, Alexandria and University of New South Wales, Sydney; University of Massachusetts, Amherst",IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,162,183,"Process modeling allows for analysis and improvement of processes that coordinate multiple people and tools working together to carry out a task. Process modeling typically focuses on the normative process, that is, how the collaboration transpires when everything goes as desired. Unfortunately, real-world processes rarely proceed that smoothly. A more complete analysis of a process requires that the process model also include details about what to do when exceptional situations arise. We have found that, in many cases, there are abstract patterns that capture the relationship between exception handling tasks and the normative process. Just as object-oriented design patterns facilitate the development, documentation, and maintenance of object-oriented programs, we believe that process patterns can facilitate the development, documentation, and maintenance of process models. In this paper, we focus on the exception handling patterns that we have observed over many years of process modeling. We describe these patterns using three process modeling notations: UML 2.0 Activity Diagrams, BPMN, and Little-JIL. We present both the abstract structure of the pattern as well as examples of the pattern in use. We also provide some preliminary statistical survey data to support the claim that these patterns are found commonly in actual use and discuss the relative merits of the three notations with respect to their ability to represent these patterns.",1939-3520,,10.1109/TSE.2010.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383369,Exception handling patterns;process modeling;process modeling languages.,Object oriented modeling;Documentation;Humans;Pattern analysis;Collaborative work;Unified modeling language;Collaboration;Data processing;Manufacturing processes;Medical services,exception handling;groupware;object-oriented programming;software maintenance;system documentation,exception handling patterns;process modeling;collaboration process;normative process;object-oriented design patterns;object-oriented programs;process development;process documentation;process maintenance;UML 2.0 activity diagrams;BPMN;Little-JIL,,77.0,,51.0,,15 Jan 2010,,,IEEE,IEEE Journals
1004,1005,A Genetic Algorithm-Based Stress Test Requirements Generator Tool and Its Empirical Evaluation,V. Garousi,"University of Calgary, Calgary",IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,778,797,"Genetic algorithms (GAs) have been applied previously to UML-driven stress test requirements generation with the aim of increasing chances of discovering faults relating to network traffic in distributed real-time systems. However, since evolutionary algorithms are heuristic, their performance can vary across multiple executions, which may affect robustness and scalability. To address this, we present the design and technical detail of a UML-driven, GA-based stress test requirements generation tool, together with its empirical analysis. The main goal is to analyze and improve the applicability, efficiency, and effectiveness and also to validate the design choices of the GA used in the tool. Findings of the empirical evaluation reveal that the tool is robust and reasonably scalable when it is executed on large-scale experimental design models. The study also reveals the main bottlenecks and limitations of the tools, e.g., there is a performance bottleneck when the system under test has a large number of sequence diagrams which could be triggered independently from each other. In addition, issues specific to stress testing, e.g., the impact of variations in task arrival pattern types, reveal that the tool generally generates effective test requirements, although the features of those test requirements might be different in different runs (e.g., different stress times from the test start time might be chosen). While the use of evolutionary algorithms to generate software test cases has been widely reported, the extent, depth, and detail of the empirical findings presented in this paper are novel and suggest that the proposed approach is effective and efficient in generating stress test requirements. It is hoped that the findings of this empirical study will help other SBSE researchers with the empirical evaluation of their own techniques and tools.",1939-3520,,10.1109/TSE.2010.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5383373,Index Term—Search-based testing;genetic algorithms;stress testing;test tools;test automation;empirical analysis.,Stress;System testing;Robustness;Genetic algorithms;Telecommunication traffic;Real time systems;Evolutionary computation;Scalability;Large-scale systems;Design for experiments,distributed algorithms;genetic algorithms;program testing;real-time systems;Unified Modeling Language,genetic algorithm;UML;distributed real time system;empirical analysis;software test cases;stress test requirement generation,,18.0,1.0,32.0,,15 Jan 2010,,,IEEE,IEEE Journals
1005,1006,Verifying Synchronization for Atomicity Violation Fixing,Q. Shi; J. Huang; Z. Chen; B. Xu,"State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China; Texas A&M University, College Station, TX; State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China; State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China",IEEE Transactions on Software Engineering,11 Mar 2016,2016,42,3,280,296,"Atomicity is a fundamental property to guarantee the isolation of a work unit (i.e., a sequence of related events in a thread) from concurrent threads. However, ensuring atomicity is often very challenging due to complex thread interactions. We present an approach to help developers verify whether such work units, which have triggered bugs due to certain violations of atomicity, are sufficiently synchronized or not by locks introduced for fixing the bugs. A key feature of our approach is that it combines the fortes of both bug-driven and change-aware techniques, which enables it to effectively verify synchronizations by testing only a minimal set of suspicious atomicity violations without any knowledge on the to-be-isolated work units, thus being more efficient and practical than other approaches. Besides, unlike existing approaches, our approach effectively utilizes all the inferred execution traces even they may not be completely feasible, such that the verification algorithm can converge much faster. We demonstrate via extensive evaluation that our approach is much more effective and efficient than the state-of-the-arts. Besides, we show that although there have existed sound automatic fixing techniques for atomicity violations, our approach is still necessary and useful for quality assurance of concurrent programs, because the assumption behind our approach is much weaker. We have also investigated one of the largest bug databases and found that insufficient synchronizations are common and difficult to be found in software development.",1939-3520,,10.1109/TSE.2015.2477820,National Basic Research Program of China; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7254228,Atomicity violations;insufficient synchronization;fix;dynamic trace analysis;maximal sound verification;Atomicity violations;insufficient synchronization;fix;dynamic trace analysis;maximal sound verification,Synchronization;Schedules;Optimization;Java;Computer bugs;Runtime;Instruction sets,program debugging;software quality;synchronisation,synchronization verification;atomicity violation fixing;work unit isolation;concurrent threads;complex thread interactions;triggered bugs;bug-driven techniques;change-aware techniques;suspicious atomicity violations;to-be-isolated work units;verification algorithm;extensive evaluation;automatic fixing techniques;concurrent programs;quality assurance;bug databases;software development,,6.0,,48.0,,10 Sep 2015,,,IEEE,IEEE Journals
1006,1007,The Impact of Irrelevant and Misleading Information on Software Development Effort Estimates: A Randomized Controlled Field Experiment,M. Jorgensen; S. Grimstad,"University of Oslo and Simula Research Laboratory, Lysaker; University of Oslo and Simula Research Laboratory, Lysaker",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,695,707,"Studies in laboratory settings report that software development effort estimates can be strongly affected by effort-irrelevant and misleading information. To increase our knowledge about the importance of these effects in field settings, we paid 46 outsourcing companies from various countries to estimate the required effort of the same five software development projects. The companies were allocated randomly to either the original requirement specification or a manipulated version of the original requirement specification. The manipulations were as follows: 1) reduced length of requirement specification with no change of content, 2) information about the low effort spent on the development of the old system to be replaced, 3) information about the client's unrealistic expectations about low cost, and 4) a restriction of a short development period with start up a few months ahead. We found that the effect sizes in the field settings were much smaller than those found for similar manipulations in laboratory settings. Our findings suggest that we should be careful about generalizing to field settings the effect sizes found in laboratory settings. While laboratory settings can be useful to demonstrate the existence of an effect and better understand it, field studies may be needed to study the size and importance of these effects.",1939-3520,,10.1109/TSE.2010.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551161,Cost estimation;software psychology;requirements/specifications.,Estimation;Software;Companies;Laboratories;Programming;Materials;Project management,formal specification;software cost estimation,irrelevant information impact;misleading information impact;software development effort estimates;randomized controlled field experiment;software development projects;original requirement specification;laboratory settings;software psychology,,31.0,,31.0,,19 Aug 2010,,,IEEE,IEEE Journals
1007,1008,PerLa: A Language and Middleware Architecture for Data Management and Integration in Pervasive Information Systems,F. A. Schreiber; R. Camplani; M. Fortunato; M. Marelli; G. Rota,"Politecnico di Milano, Milano; Politecnico di Milano, Milano; Politecnico di Milano, Milano; Politecnico di Milano, Milano; Politecnico di Milano, Milano",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,478,496,"A declarative SQL-like language and a middleware infrastructure are presented for collecting data from different nodes of a pervasive system. Data management is performed by hiding the complexity due to the large underlying heterogeneity of devices, which can span from passive RFID(s) to ad hoc sensor boards to portable computers. An important feature of the presented middleware is to make the integration of new device types in the system easy through the use of device self-description. Two case studies are described for PerLa usage, and a survey is made for comparing our approach with other projects in the area.",1939-3520,,10.1109/TSE.2011.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5728831,Declarative language;device heterogeneity;functionality proxy;middleware infrastructure;pervasive system;SQL;wireless sensor networks.,Middleware;Monitoring;Software;Context;Wireless sensor networks;Databases;Hardware,data integration;information systems;middleware;software architecture;SQL;ubiquitous computing,PerLa;language architecture;middleware architecture;data management;data integration;pervasive information systems;declarative SQL-like language;data collection;passive RFID;ad hoc sensor boards;portable computers;device self-description,,31.0,2.0,53.0,,10 Mar 2011,,,IEEE,IEEE Journals
1008,1009,Embedding Polychrony into Synchrony,J. Brandt; M. Gemünde; K. Schneider; S. K. Shukla; J. Talpin,"University of Kaiserslautern, Kaiserslautern; University of Kaiserslautern, Kaiserslautern; University of Kaiserslautern, Kaiserslautern; Virginia Polytechnic and State University, Blacksburg; INRIA Rennes-Bretagne-Atlantique, Rennes",IEEE Transactions on Software Engineering,26 Jun 2013,2013,39,7,917,929,"This paper presents an embedding of polychronous programs into synchronous ones. Due to this embedding, it is not only possible to deepen the understanding of these different models of computation, but, more importantly, it is possible to transfer compilation techniques that were developed for synchronous programs to polychronous programs. This transfer is nontrivial because the underlying paradigms differ more than their names suggest: Since synchronous systems react deterministically to given inputs in discrete steps, they are typically used to describe reactive systems with a totally ordered notion of time. In contrast, polychronous system models entail a partially ordered notion of time, and are most suited to interface a system with an asynchronous environment by specifying input/output constraints from which a deterministic controller may eventually be refined and synthesized. As particular examples for the mentioned cross fertilization, we show how a simulator and a verification backend for synchronous programs can be made available to polychronous specifications, which is a first step toward integrating heterogeneous models of computation.",1939-3520,,10.1109/TSE.2012.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6381420,Model-driven embedded software;synchronous programming;polychronous programming;programming models;synchrony hypothesis;synchronous guarded commands,Clocks;Computational modeling;Synchronization;Embedded systems;Hardware;Unified modeling language,embedded systems;program compilers;program verification,polychronous program specification;compilation techniques;reactive systems;polychronous system model;asynchronous environment;input-output constraints;deterministic controller;synchronous program verification;heterogeneous model,,5.0,,42.0,,13 Dec 2012,,,IEEE,IEEE Journals
1009,1010,Automated Checking of Conformance to Requirements Templates Using Natural Language Processing,C. Arora; M. Sabetzadeh; L. Briand; F. Zimmer,"SnT Centre for Security, Reliability, and Trust, Luxembourg; SnT Centre for Security, Reliability, and Trust, Luxembourg; SnT Centre for Security, Reliability, and Trust, Luxembourg; SES TechCom, Luxembourg",IEEE Transactions on Software Engineering,13 Oct 2015,2015,41,10,944,968,"Templates are effective tools for increasing the precision of natural language requirements and for avoiding ambiguities that may arise from the use of unrestricted natural language. When templates are applied, it is important to verify that the requirements are indeed written according to the templates. If done manually, checking conformance to templates is laborious, presenting a particular challenge when the task has to be repeated multiple times in response to changes in the requirements. In this article, using techniques from natural language processing (NLP), we develop an automated approach for checking conformance to templates. Specifically, we present a generalizable method for casting templates into NLP pattern matchers and reflect on our practical experience implementing automated checkers for two well-known templates in the requirements engineering community. We report on the application of our approach to four case studies. Our results indicate that: (1) our approach provides a robust and accurate basis for checking conformance to templates; and (2) the effectiveness of our approach is not compromised even when the requirements glossary terms are unknown. This makes our work particularly relevant to practice, as many industrial requirements documents have incomplete glossaries.",1939-3520,,10.1109/TSE.2015.2428709,National Research Fund-Luxembourg; Validation Laboratory and AFR; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7100933,Requirements Templates;Natural Language Processing (NLP);Case Study Research;Requirements templates;natural language processing (NLP);case study research,Terminology;Natural language processing;Ear;Safety;Pipelines;Pattern matching,formal specification;natural language processing;pattern matching,conformance automated checking;requirements templates;natural language processing;generalizable method;NLP pattern matcher;requirements engineering community,,51.0,,71.0,,1 May 2015,,,IEEE,IEEE Journals
1010,1011,Formulating Cost-Effective Monitoring Strategies for Service-Based Systems,Q. He; J. Han; Y. Yang; H. Jin; J. Schneider; S. Versteeg,"School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia 3122; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia 3122; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia 3122; Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan 430074, China; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Australia 3122; CA Technologies, Melbourne, Australia 3004",IEEE Transactions on Software Engineering,14 May 2014,2014,40,5,461,482,"When operating in volatile environments, service-based systems (SBSs) that are dynamically composed from component services must be monitored in order to guarantee timely and successful delivery of outcomes in response to user requests. However, monitoring consumes resources and very often impacts on the quality of the SBSs being monitored. Such resource and system costs need to be considered in formulating monitoring strategies for SBSs. The critical path of a composite SBS, i.e., the execution path in the service composition with the maximum execution time, is of particular importance in cost-effective monitoring as it determines the response time of the entire SBS. In volatile operating environments, the critical path of an SBS is probabilistic, as every execution path can be critical with a certain probability, i.e., its criticality. As such, it is important to estimate the criticalities of different execution paths when deciding which parts of the SBS to monitor. Furthermore, cost-effective monitoring also requires management of the trade-off between the benefit and cost of monitoring. In this paper, we propose CriMon, a novel approach to formulating and evaluating monitoring strategies for SBSs. CriMon first calculates the criticalities of the execution paths and the component services of an SBS and then, based on those criticalities, generates the optimal monitoring strategy considering both the benefit and cost of monitoring. CriMon has two monitoring strategy formulation methods, namely local optimisation and global optimisation. In-lab experimental results demonstrate that the response time of an SBS can be managed cost-effectively through CriMon-based monitoring. The effectiveness and efficiency of the two monitoring strategy formulation methods are also evaluated and compared.",1939-3520,,10.1109/TSE.2013.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6642029,Service-based system;web service;QoS;response time;monitoring;criticality;cost of monitoring;value of monitoring,Monitoring;Scattering;Probability;Time factors;Runtime;Probabilistic logic;Quality of service,service-oriented architecture;system monitoring;Web services,cost-effective monitoring strategy;service-based systems;SBSs;component services;system costs;service composition;global optimisation;local optimisation;CriMon-based monitoring approach;monitoring strategy formulation methods;service-oriented computing;Web service,,21.0,,65.0,,21 Oct 2013,,,IEEE,IEEE Journals
1011,1012,Inner Source in Platform-Based Product Engineering,D. Riehle; M. Capraro; D. Kips; L. Horn,"Computer Science Department, Friedrich-Alexander University Erlangen-Nürnberg, Erlangen, Germany; Computer Science Department, Friedrich-Alexander University Erlangen-Nürnberg, Erlangen, Germany; Develop Group, Erlangen, Germany; e-solutions, Erlangen, Germany",IEEE Transactions on Software Engineering,8 Dec 2016,2016,42,12,1162,1177,"Inner source is an approach to collaboration across intra-organizational boundaries for the creation of shared reusable assets. Prior project reports on inner source suggest improved code reuse and better knowledge sharing. Using a multiple-case case study research approach, we analyze the problems that three major software development organizations were facing in their product line engineering efforts. We find that a root cause, the separation of product units as profit centers from a platform organization as a cost center, leads to delayed deliveries, increased defect rates, and redundant software components. All three organizations assume that inner source can help solve these problems. The article analyzes the expectations that these companies were having towards inner source and the problems they were experiencing in its adoption. Finally, the article presents our conclusions on how these organizations should adapt their existing engineering efforts.",1939-3520,,10.1109/TSE.2016.2554553,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7452676,Inner source;product line engineering;product families;platform-based product engineering;open source;open collaboration;case study research,Collaboration;Product design;Software product lines;Best practices;Open source software,asset management;public domain software;software product lines,inner source;platform-based product line engineering;shared reusable asset creation;software development organization;product unit separation;profit center,,3.0,,73.0,,14 Apr 2016,,,IEEE,IEEE Journals
1012,1013,A Risk Management Methodology for Project Risk Dependencies,T. W. Kwan; H. K. N. Leung,"The Hong Kong Polytechnic University, Hong Kong; The Hong Kong Polytechnic University, Hong Kong",IEEE Transactions on Software Engineering,29 Sep 2011,2011,37,5,635,648,"Project risks are not always independent, yet current risk management practices do not clearly manage dependencies between risks. If dependencies can be explicitly identified and analyzed, project managers will be able to develop better risk management strategies and make more effective risk planning decisions. This paper proposes a management methodology to address risk dependency issues. Through the study of three IT projects, we confirm that risk dependencies do exist in projects and can be identified and systematically managed. We also observed that, as project teams needed to deal with risk dependency issues, communications between projects were improved, and there were synergetic effects in managing risks and risk dependencies among projects.",1939-3520,,10.1109/TSE.2010.108,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5696725,Project risk management;risk dependencies;risk assessment;metrics.,Risk management;Delta modulation;Analytical models;Monitoring;Measurement;Lead;Fault trees,project management;risk analysis,project risk management;risk planning decisions;IT projects;risk dependencies,,53.0,,33.0,,20 Jan 2011,,,IEEE,IEEE Journals
1013,1014,Bypassing the Combinatorial Explosion: Using Similarity to Generate and Prioritize T-Wise Test Configurations for Software Product Lines,C. Henard; M. Papadakis; G. Perrouin; J. Klein; P. Heymans; Y. Le Traon,"Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg",IEEE Transactions on Software Engineering,8 Jul 2014,2014,40,7,650,670,"Large Software Product Lines (SPLs) are common in industry, thus introducing the need of practical solutions to test them. To this end, t-wise can help to drastically reduce the number of product configurations to test. Current t-wise approaches for SPLs are restricted to small values of t. In addition, these techniques fail at providing means to finely control the configuration process. In view of this, means for automatically generating and prioritizing product configurations for large SPLs are required. This paper proposes (a) a search-based approach capable of generating product configurations for large SPLs, forming a scalable and flexible alternative to current techniques and (b) prioritization algorithms for any set of product configurations. Both these techniques employ a similarity heuristic. The ability of the proposed techniques is assessed in an empirical study through a comparison with state of the art tools. The comparison focuses on both the product configuration generation and the prioritization aspects. The results demonstrate that existing t-wise tools and prioritization techniques fail to handle large SPLs. On the contrary, the proposed techniques are both effective and scalable. Additionally, the experiments show that the similarity heuristic can be used as a viable alternative to t-wise.",1939-3520,,10.1109/TSE.2014.2327020,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6823132,Software product lines;testing;T-wise Interactions;search-based approaches;prioritization;similarity,Testing;Frequency modulation;Context;Scalability;Software;Linux;Arrays,combinatorial mathematics;program testing;software product lines,combinatorial explosion;test configurations;software product lines;SPL;product configurations;configuration process;search based approach;similarity heuristic;product configuration generation,,82.0,,64.0,,29 May 2014,,,IEEE,IEEE Journals
1014,1015,Static Analysis for Extracting Permission Checks of a Large Scale Framework: The Challenges and Solutions for Analyzing Android,A. Bartel; J. Klein; M. Monperrus; Y. Le Traon,"Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, 4, rue Alphonse Weicker, Luxembourg, Kirchberg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, 4, rue Alphonse Weicker, Luxembourg, Kirchberg; University of Lille and Inria, Villeneuve d'Ascq, France; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, 4, rue Alphonse Weicker, Luxembourg, Kirchberg",IEEE Transactions on Software Engineering,16 Jun 2014,2014,40,6,617,632,"A common security architecture is based on the protection of certain resources by permission checks (used e.g., in Android and Blackberry). It has some limitations, for instance, when applications are granted more permissions than they actually need, which facilitates all kinds of malicious usage (e.g., through code injection). The analysis of permission-based framework requires a precise mapping between API methods of the framework and the permissions they require. In this paper, we show that naive static analysis fails miserably when applied with off-the-shelf components on the Android framework. We then present an advanced class-hierarchy and field-sensitive set of analyses to extract this mapping. Those static analyses are capable of analyzing the Android framework. They use novel domain specific optimizations dedicated to Android.",1939-3520,,10.1109/TSE.2014.2322867,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6813664,Large scale framework;permissions;call-graph;Android;security;Soot;Java;static analysis,Androids;Humanoid robots;Sparks;Cameras;Java;Servers;Security,Android (operating system);optimisation;program diagnostics;security of data,static analysis;permission checks;large scale framework;common security architecture;permission-based framework;API methods;Android framework;novel domain specific optimizations;advanced class-hierarchy analysis;field-sensitive set analysis,,42.0,,32.0,,9 May 2014,,,IEEE,IEEE Journals
1015,1016,REPENT: Analyzing the Nature of Identifier Renamings,V. Arnaoudova; L. M. Eshkevari; M. D. Penta; R. Oliveto; G. Antoniol; Y. Guéhéneuc,"Polytechnique Montréal, Québec, Canada; Polytechnique Montréal, Québec, Canada; University of Sannio, Benevento, Italy; University of Molise, Pesche (IS), Italy; Polytechnique Montréal, Québec, Canada; Polytechnique Montréal, Québec, Canada",IEEE Transactions on Software Engineering,14 May 2014,2014,40,5,502,532,"Source code lexicon plays a paramount role in software quality: poor lexicon can lead to poor comprehensibility and even increase software fault-proneness. For this reason, renaming a program entity, i.e., altering the entity identifier, is an important activity during software evolution. Developers rename when they feel that the name of an entity is not (anymore) consistent with its functionality, or when such a name may be misleading. A survey that we performed with 71 developers suggests that 39 percent perform renaming from a few times per week to almost every day and that 92 percent of the participants consider that renaming is not straightforward. However, despite the cost that is associated with renaming, renamings are seldom if ever documented-for example, less than 1 percent of the renamings in the five programs that we studied. This explains why participants largely agree on the usefulness of automatically documenting renamings. In this paper we propose REanaming Program ENTities (REPENT), an approach to automatically document-detect and classify-identifier renamings in source code. REPENT detects renamings based on a combination of source code differencing and data flow analyses. Using a set of natural language tools, REPENT classifies renamings into the different dimensions of a taxonomy that we defined. Using the documented renamings, developers will be able to, for example, look up methods that are part of the public API (as they impact client applications), or look for inconsistencies between the name and the implementation of an entity that underwent a high risk renaming (e.g., towards the opposite meaning). We evaluate the accuracy and completeness of REPENT on the evolution history of five open-source Java programs. The study indicates a precision of 88 percent and a recall of 92 percent. In addition, we report an exploratory study investigating and discussing how identifiers are renamed in the five programs, according to our taxonomy.",1939-3520,,10.1109/TSE.2014.2312942,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6776542,Identifier renaming;refactoring;program comprehension;mining software repositories;empirical study,Taxonomy;Semantics;Java;Grammar;Software;History;Documentation,data flow analysis;pattern classification;software fault tolerance;software quality;source code (software),identifier renaming analysis;REPENT;source code lexicon;software quality;software fault-proneness;program entity renaming;entity identifier;software evolution;reanaming program entities;data flow analysis;natural language tools;taxonomy dimensions;public API;open-source Java programs,,41.0,,58.0,,20 Mar 2014,,,IEEE,IEEE Journals
1016,1017,When and Why Your Code Starts to Smell Bad (and Whether the Smells Go Away),M. Tufano; F. Palomba; G. Bavota; R. Oliveto; M. D. Penta; A. De Lucia; D. Poshyvanyk,"College of William and Mary, Williamsburg, VA; University of Salerno, Fisciano, SA, Italy; Università della Svizzera italiana (USI), Lugano, Switzerland; University of Molise, Pesche, (IS), Italy; University of Sannio, Benevento, BN, Italy; University of Salerno, Fisciano, SA, Italy; College of William and Mary, Williamsburg, VA",IEEE Transactions on Software Engineering,10 Nov 2017,2017,43,11,1063,1088,"Technical debt is a metaphor introduced by Cunningham to indicate “not quite right code which we postpone making it right”. One noticeable symptom of technical debt is represented by code smells, defined as symptoms of poor design and implementation choices. Previous studies showed the negative impact of code smells on the comprehensibility and maintainability of code. While the repercussions of smells on code quality have been empirically assessed, there is still only anecdotal evidence on when and why bad smells are introduced, what is their survivability, and how they are removed by developers. To empirically corroborate such anecdotal evidence, we conducted a large empirical study over the change history of 200 open source projects. This study required the development of a strategy to identify smell-introducing commits, the mining of over half a million of commits, and the manual analysis and classification of over 10K of them. Our findings mostly contradict common wisdom, showing that most of the smell instances are introduced when an artifact is created and not as a result of its evolution. At the same time, 80 percent of smells survive in the system. Also, among the 20 percent of removed instances, only 9 percent are removed as a direct consequence of refactoring operations.",1939-3520,,10.1109/TSE.2017.2653105,NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7817894,Code smells;empirical study;mining software repositories,Ecosystems;History;Androids;Humanoid robots;Software systems;Maintenance engineering,data mining;public domain software;software maintenance;software quality;source code (software),open source projects;code smells;code comprehensibility;code maintainability;commits mining;smell instances;smell-introducing commits;code quality;technical debt,,30.0,,91.0,Traditional,16 Jan 2017,,,IEEE,IEEE Journals
1017,1018,Development with Off-the-Shelf Components: 10 Facts,J. Li; R. Conradi; C. Bunse; M. Torchiano; O. P. N. Slyngstad; M. Morisio,Norwegian University of Science and Technology; Norwegian University of Science and Technology; International University; Politecnico di Torino; Norwegian University of Science and Technology; Politecnico di Torino,IEEE Software,24 Feb 2009,2009,26,2,80,87,Empirical studies have revealed a discrepancy between academic theory and industrial practices regarding the selection and integration of commercial off-the-shelf and open source software components in software system development.,1937-4194,,10.1109/MS.2009.33,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786958,COTS-based development;OSS-based development;empirical studies,Open source software;Software quality;Risk management;Computer industry;Programming;Costs;Software systems;Electronic switching systems;Software libraries;Quality management,object-oriented programming;public domain software;software engineering,commercial off-the-shelf components;academic theory;industrial practices;open source software components;software system development,,58.0,,12.0,,24 Feb 2009,,,IEEE,IEEE Magazines
1018,1019,The 10-Minute Test Plan,J. A. Whittaker,Google,IEEE Software,22 Oct 2012,2012,29,6,70,77,"The lowly test plan is perhaps the least appreciated of all supporting (read: noncode) software development artifacts. All projects need one, but few engineers appreciate their existence. So it's important to spend no more time than is absolutely necessary in the creation, care, and feeding of the test plan. Ten minutes, to be precise.",1937-4194,,10.1109/MS.2012.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6148203,software testing,Software testing,program testing;software engineering,software testing;test plan;software development artifacts,,,,7.0,,7 Feb 2012,,,IEEE,IEEE Magazines
1019,1020,A More Agile Approach to Embedded System Development,M. Smith; J. Miller; L. Huang; A. Tran,University of Calgary; University of Alberta; NovATel; DirectVoxx,IEEE Software,17 Apr 2009,2009,26,3,50,57,"Given the plethora of advantages attributed to agile methodologies, why are there only infrequent reports of their application in the embedded systems world? We believe this has two principal causes. First, embedded applications go through a life cycle that differs from desktop life cycles, so that desktop application production processes must be significantly altered to meet the demands of this new domain. Second, without providing for full life-cycle tool support, no change to embedded production processes will ever succeed, and again desktop tools must be adapted to meet the new environment's constraints. Here, the authors discuss their thoughts on an XP-inspired embedded life cycle and their successes in developing, extending, and using embedded test-driven development frameworks for customers (Matlab-Fit and Embedded-FitNesse) and developers (MUnit and Embedded-Unit).",1937-4194,,10.1109/MS.2009.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814958,embedded systems;agile methods;test-driven development;tool support,Embedded system;System testing;Registers;Hardware;Life testing;Embedded software;Production;Silicon;Instruments;Health and safety,embedded systems;software engineering,embedded system development;agile methodologies;desktop application production process;full life-cycle tool support;XP-inspired embedded life cycle,,6.0,,14.0,,17 Apr 2009,,,IEEE,IEEE Magazines
1020,1021,Strategies Facilitating Software Product Transfers,D. Smite; C. Wohlin,Blekinge Institute of Technology; Blekinge Institute of Technology,IEEE Software,18 Aug 2011,2011,28,5,60,66,"Globalization of software work has become common in today's market. As part of cost-reduction strategies, many product-focused software companies started shipping their product development to insourcing and outsourcing offshore locations. Unfortunately, moving software products from one site to another isn't always a good business strategy for either the organization or the product. In this article, the authors discuss findings from studying software insourcing transfers at Ericsson, a large software product development company headquartered in Sweden. Their findings suggest that certain product, personnel, and process characteristics can facilitate the execution of an offshore insourcing transfer. On the basis of research conducted together with the company, they share a list of critical factors alleviating transfer difficulties and seven strategies facilitating transition of software work across sites.",1937-4194,,10.1109/MS.2010.112,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5499459,organizational management and coordination;planning;offshore software development,Globalization;Outsourcing;Product development;Process planning;Investments;Collaborative work;Software development,globalisation;outsourcing;software engineering,software product transfers;cost-reduction strategies;product-focused software companies;software product development company;offshore location insourcing;offshore location outsourcing;Ericsson;Sweden,,13.0,,10.0,,1 Jul 2010,,,IEEE,IEEE Magazines
1021,1022,Magic Potion: Incorporating New Development Paradigms through Metaprogramming,D. Djuric; V. Devedzic,"University of Belgrade, Serbia; University of Belgrade, Belgrade",IEEE Software,19 Aug 2010,2010,27,5,38,44,"Software environments are typically based on a single programming paradigm, such as ontologies, functions, objects, or concurrency. This can limit what developers can represent and how elegant their solutions can be, so today's applications usually involve mixing and matching languages, platforms, and paradigms. However, cross-mapping multiple paradigms and platforms generates an impedance mismatch that increases a solution's complexity. Metaprogramming supports a lightweight process to incorporate different programming paradigms in a single development environment that's suitable for small development teams.",1937-4194,,10.1109/MS.2010.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473201,programming paradigms;multiparadigm languages;ontology languages;metaprogramming;domain-specific languages;programming languages;domain engineering;programming techniques,Functional programming;Ontologies;Concurrent computing;Application software;Impedance,multiprogramming;object-oriented methods;software engineering,Magic Potion;metaprogramming;ontologies;software development,,3.0,,10.0,,27 May 2010,,,IEEE,IEEE Magazines
1022,1023,Tools for Continuously Evaluating Distributed System Qualities,J. Hill; D. Schmidt; J. Edmondson; A. Gokhale,"Indiana University/Purdue University at Indianapolis, Indianapolis; Vanderbilt University, Nashville; Vanderbilt University, Nashville; Vanderbilt Univresity, Nashville",IEEE Software,14 Jun 2010,2010,27,4,65,71,"Developers are increasingly using service-oriented middleware to develop distributed systems. This middleware raises the abstraction level for software so that distributed-system developers can focus more on application-level concerns (for instance, business logic) rather than wrestle with infrastructure-level concerns (such as software adaptation, context-awareness, and life-cycle management). Service-oriented middleware also promotes reuse of business logic and services across heterogeneous application domains, thus facilitating the development of larger, more complex systems.",1937-4194,,10.1109/MS.2009.197,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5306061,agile techniques;continuous system integration;distributed systems;domain-specific modeling languages;model-driven engineering;system execution modeling tools,System testing;Performance analysis;Life testing;Software testing;Databases;Automatic testing;World Wide Web;Computer languages;Operating systems;Middleware,middleware;software engineering,distributed-system qualities;service-oriented middleware;software development;application-level concern;business logic;heterogeneous application domain;complex system,,15.0,,11.0,,30 Oct 2009,,,IEEE,IEEE Magazines
1023,1024,Streamlining Development for Networked Embedded Systems Using Multiple Paradigms,C. Huygens; D. Hughes; B. Lagaisse; W. Joosen,Katholieke Universiteit Leuven; Xi'an Jiaotong-Liverpool University; Katholieke Universiteit Leuven; Katholieke Universiteit Leuven,IEEE Software,19 Aug 2010,2010,27,5,45,52,"In networked embedded systems, multiparadigm programming enables an integrated approach for developing complementary artifacts that are essential but can't be programmed using a single paradigm.",1937-4194,,10.1109/MS.2010.93,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473203,embedded systems;programming paradigms;system integration and implementation;wireless sensor networks;computing equipment management;software,Embedded system;Computer science;Application software;Hardware;Embedded software;Software maintenance;Logic programming;Runtime;Wireless sensor networks;Computer networks,embedded systems;multiprogramming;software engineering,streamlining development;networked embedded systems;multipαrαdigm programming,,10.0,,6.0,,27 May 2010,,,IEEE,IEEE Magazines
1024,1025,Agile Collaborative Research: Action Principles for Industry-Academia Collaboration,A. Sandberg; L. Pareto; T. Arts,Ericsson; Chalmers University of Technology; Chalmers University of Technology,IEEE Software,23 Jun 2011,2011,28,4,74,83,"Both the software industry and academia promote collaboration to solve challenges together that neither can solve alone. Collaboration brings opportunities to understand and improve in ways not possible when working apart, but it succeeds only if both parties are contributing. A collaboration model developed from eight years' experience setting up and managing a research center explicitly focused on industry needs is based on five success factors enabling research results (need orientation, industry goal alignment, deployment impact, industry benefit, and innovativeness), five success factors enabling research activities (management engagement, network access, collaborator match, communication ability, and continuity), and 10 action principles for industry-academia collaboration management.",1937-4194,,10.1109/MS.2011.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5733335,research and development management;collaborative practice research;industry–academia collaboration,Collaboration;Management;Product development;Business;Adaptation model;Modeling;Training,groupware;software engineering;software management;software prototyping,agile collaborative research;industry-academia collaboration;software industry;research center;management engagement;network access;collaborator match;communication ability;continuity,,34.0,,14.0,,17 Mar 2011,,,IEEE,IEEE Magazines
1025,1026,Analytics-Driven Dashboards Enable Leading Indicators for Requirements and Designs of Large-Scale Systems,R. W. Selby,Northrop Grumman Space Technology,IEEE Software,22 Dec 2008,2009,26,1,41,49,"Mining software repositories using analytics-driven dashboards provides a unifying mechanism for understanding, evaluating, and predicting the development, management, and economics of large-scale systems and processes. Dashboards enable measurement and interactive graphical displays of complex information and support flexible analytic capabilities for user customizability and extensibility. Dashboards commonly include system requirements and design metrics because they provide leading indicators for project size, growth, and volatility. This article focuses on dashboards that have been used on actual large-scale software projects as well as example empirical relationships revealed by the dashboards. The empirical results focus on leading indicators for requirements and designs of large-scale software systems based on insights from two sets of software projects containing 14 systems and 23 systems.",1937-4194,,10.1109/MS.2009.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721182,leading indicators;requirements;designs;defects;empirical analysis;metrics,Large-scale systems;Project management;Risk management;Displays;Technology management;Software development management;Large scale integration;Economic forecasting;Software performance;Information analysis,data mining;software engineering,analytics-driven dashboards;large-scale systems;software repositories mining;interactive graphical displays,,5.0,,16.0,,22 Dec 2008,,,IEEE,IEEE Magazines
1026,1027,What Next? Advances in Software-Driven Industries,C. Ebert; G. Hoefner; V. S. Mani,Vector Consulting Services; Siemens Technology and Services; Siemens Technology and Services,IEEE Software,4 Feb 2015,2015,32,1,22,28,"Software-driven industries are advancing in five dimensions: collaboration, comprehension, connectivity, cloud, and convergence. However, companies often can get stuck in an overly narrow technology focus. To avoid this, they should connect architecture and functionality, master the entire software development life cycle, strengthen globally distributed teams, and streamline development.",1937-4194,,10.1109/MS.2015.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030204,software complexity;software architecture;model-driven development;software development life cycle;distributed software development;software development,Software architecture;Complexity theory;Software development;Modeling;Computer architecture,cloud computing;DP industry;groupware;software engineering,software-driven industries;collaboration;comprehension;connectivity;cloud;convergence;software development life cycle;globally distributed teams;streamline development,,5.0,,3.0,,4 Feb 2015,,,IEEE,IEEE Magazines
1027,1028,A Refactoring Approach to Parallelism,D. Dig,University of Illinois at Urbana-Champaign,IEEE Software,20 Dec 2010,2011,28,1,17,22,"In the multicore era, a major programming task will be to make programs more parallel. This is tedious because it requires changing many lines of code; it's also error-prone and nontrivial because programmers need to ensure noninterference of parallel operations. Fortunately, interactive refactoring tools can help reduce the analysis and transformation burden. The author describes how refactoring tools can improve programmer productivity, program performance, and program portability. The article also describes a toolset that supports several refactorings for making programs thread-safe, threading sequential programs for throughput, and improving scalability of parallel programs.",1937-4194,,10.1109/MS.2011.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672516,refactoring;parallelism;concurrency,Parallel processing;Instruction sets;Arrays;Computer threading,interactive systems;parallel programming;software engineering;software tools,refactoring approach;multicore era;major programming task;interactive refactoring tools;program performance;program portability;sequential programs threading;parallel programs,,41.0,,15.0,,20 Dec 2010,,,IEEE,IEEE Magazines
1028,1029,"Social Networking Meets Software Development: Perspectives from GitHub, MSDN, Stack Exchange, and TopCoder",A. Begel; J. Bosch; M. Storey,Microsoft; Chalmers University of Technology; University of Victoria,IEEE Software,3 Jan 2013,2013,30,1,52,66,"Many successful software companies use social networking as a way to improve the services or products they provide. To gain an understanding of the role social networking plays in today's software development world, the guest editors of the January/February 2013 issue conducted semistructured interviews with leaders from four successful companies: Brian Doll, an engineer who manages GitHub's marketing; Doug Laundry, a principal group program manager at Microsoft; David Fullerton, vice president of engineering at Stack Exchange; and Robert Hughes, the president and chief operating officer of TopCoder. The first Web extra at http://try.github.com is a video of Joel Spolsky discussing the structure, software, technology, and culture of Stack Exchange. The second Web extra at http://blip.tv/play/gvUBgqLbRgI.html is a video of Matthew McCullough and Tim Berglund demonstrating how Git not only incorporates the best features of existing source control systems but also includes unique distributed capabilities that make version control commands available without connectivity, allowing you to choose when to interact with a network. The third Web extra at http://blip.tv/play/gvUBgqLbRgI.html is a video of Matthew McCullough and Tim Berglund demonstrating how to leverage Git's powerful yet underused advanced features. The last Web extra at http://youtu.be/SK6TBI1bNLI is a video of Thomas Baden, Chief Information Officer, State of Minnesota, Department of Human Services, describing the experience of working on the TopCoder Platform and with the members of the TopCoder Community.",1937-4194,,10.1109/MS.2013.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401114,social networking;software;community;Microsoft;Github;Stack Exchange;TopCoder,Social network services;Software development;Human factors,configuration management;Internet;marketing;social networking (online);software engineering,social networking;MSDN;stack exchange;software companies;today software development world;GitHub marketing;principal group program manager;Microsoft;second Web extra;source control systems;unique distributed capabilities;third Web extra;TopCoder platform;TopCoder community,,36.0,,,,3 Jan 2013,,,IEEE,IEEE Magazines
1029,1030,Financial Pricing of Software Development Risk Factors,M. Benaroch; A. Appari,Syracuse University; Dartmouth College,IEEE Software,19 Aug 2010,2010,27,5,65,73,"The ability to price (monetize) software development risks can benefit various aspects of software development. Cost estimators predict project cost by adjusting a project's nominal cost on the basis of risk factors' (cost drivers') expected values, but the predicted cost is often inaccurate because risk factors' actual values normally deviate from expectations. Because variability is a widely used risk measure in finance, this risk-pricing method relates risk factor variability to project cost variability. The method estimates two parameters for each risk factor: extra cost incurred per unit exposure and project sensitivity. Several areas can benefit from the benchmark risk-pricing parameters obtained when applying this method with a cost estimator such as Cocomo.",1937-4194,,10.1109/MS.2010.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5396317,risk management;economics;software development;risk factors;financial pricing;Cocomo;project sensitivity;extra cost per unit exposure,Pricing;Programming;Portfolios;Risk management;Finance;Project management;Cost function;Economic forecasting;Financial management;Software development management,pricing;project management;risk analysis;software engineering;software management,software development risk;cost estimation;project cost;risk factors;risk pricing;Cocomo,,4.0,,16.0,,22 Jan 2010,,,IEEE,IEEE Magazines
1030,1031,The State of Practice in Model-Driven Engineering,J. Whittle; J. Hutchinson; M. Rouncefield,Lancaster University; Lancaster University; Lancaster University,IEEE Software,21 Apr 2014,2014,31,3,79,85,"Despite lively debate over the past decade on the benefits and drawbacks of model-driven engineering (MDE), there have been few industry-wide studies of MDE in practice. A new study that surveyed 450 MDE practitioners and performed in-depth interviews with 22 more suggests that although MDE might be more widespread than commonly believed, developers rarely use it to generate whole systems. Rather, they apply MDE to develop key parts of a system.",1937-4194,,10.1109/MS.2013.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6507223,software design methodologies;model driven engineering practice;software design;MDE,Companies;Unified modeling language;Software;Interviews;Computer architecture;DSL;Industries,software engineering,MDE;model-driven engineering,,149.0,,11.0,,23 Apr 2013,,,IEEE,IEEE Magazines
1031,1032,"Leveraging the Crowd: How 48,000 Users Helped Improve Lync Performance",R. Musson; J. Richards; D. Fisher; C. Bird; B. Bussone; S. Ganguly,Microsoft; Microsoft; Microsoft Research; Microsoft Research; Microsoft; Microsoft,IEEE Software,26 Jun 2013,2013,30,4,38,45,"Performance is a critical component of customer satisfaction with network-based applications. Unfortunately, accurately evaluating the performance of collaborative software that operates in extremely heterogeneous environments is difficult with traditional techniques such as modeling workloads or testing in controlled environments. To evaluate performance of an application in the wild during development, the authors deployed early versions of the software, collecting performance data from application users for key usage scenarios. The analysis package they used produces visualizations to help development teams identify and prioritize performance issues by focusing on performance early in the development cycle, evaluating progress, identifying defects, and estimating timelines.",1937-4194,,10.1109/MS.2013.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6509371,software performance;data collection;data analysis;performance monitoring;software analytics;software data visualization,Software development;Performance evaluation;Customer satisfaction;Software quality;Analytical models,groupware;software engineering,Lync performance;customer satisfaction;collaborative software;software development;data visualization,,25.0,,2.0,,26 Apr 2013,,,IEEE,IEEE Magazines
1032,1033,Introducing an Iterative Life-Cycle Model at Credit Suisse IT Switzerland,K. Sägesser; B. Joseph; R. Grau,"Credit Suisse, Switzerland; Wipro Technologies; Zuhlke",IEEE Software,25 Feb 2013,2013,30,2,68,73,"Credit Suisse IT Switzerland decided to introduce an iterative life-cycle model (ILCM) based on the Rational Unified Process (RUP), a de facto industry standard, in addition to the well-established waterfall life-cycle model (WLCM). Such a large-scale change management initiative involves risks, challenges, and an organizational mindset shift. The Credit Suisse project carefully considered issues such as the gap between RUP and CMMI, process vocabulary, best practices, development and maintenance effort, training, and company culture as a precursor to the change. The activities to deploy the model throughout the organization were coordinated in collaboration with actual practitioners toward creating awareness, managing knowledge, and managing resistance factors to effect the required mindset change.",1937-4194,,10.1109/MS.2012.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6216346,Rational Unified Process;RUP;iterative software development;software development life cycle;software development process management,Banking;Standards organizations;Training;Collaboration;Iterative methods;Product life cycle management;Software development;Process management,information technology;software engineering,iterative life cycle model;credit suisse IT Switzerland;ILCM;rational unified process;RUP;de facto industry standard;WLCM;waterfall life-cycle model;credit suisse project,,2.0,,12.0,,12 Jun 2012,,,IEEE,IEEE Magazines
1033,1034,Software Design for Empowering Scientists,D. De Roure; C. Goble,University of Southampton; University of Manchester,IEEE Software,22 Dec 2008,2009,26,1,88,95,"Scientific research is increasingly digital. Some activities, such as data analysis, search, and simulation, can be accelerated by letting scientists write workflows and scripts that automate routine activities. These capture pieces of the scientific method that scientists can share. The Taverna Workbench, a widely deployed scientific-workflow-management system, together with the myExperiment social Web site for sharing scientific experiments, follow six principles of designing software for adoption by scientists and six principles of user engagement.",1937-4194,,10.1109/MS.2009.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721191,scientific workflow management systems;Taverna workflow workbench;myExperiment social Web site;agile software development,Software design;Laboratories;Data analysis;Data processing;Software tools;Computational modeling;Analytical models;Application software;Proteins;Automation,scientific information systems;software engineering,software design;scientific research;scientific method;scientists;Taverna Workbench;scientific workflow management system;social Web site,,48.0,,9.0,,22 Dec 2008,,,IEEE,IEEE Magazines
1034,1035,Technical Debt: Where Are the Shareholders' Interests?,P. Conroy,University of British Columbia,IEEE Software,22 Oct 2012,2012,29,6,88,88,"Technical debt is more than a metaphor: applying finance and accounting practices typical of other business obligations to technical debt can, in addition to meeting ethical and legal governance requirements, generate real, sustained financial benefits.",1937-4194,,10.1109/MS.2012.166,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6336729,technical debt;shareholder value;governance,Investments;Finance;Law;Ethics,DP industry;software process improvement,technical debt;ethical governance requirement;legal governance requirement;financial benefit;accounting;software engineering,,2.0,,,,22 Oct 2012,,,IEEE,IEEE Magazines
1035,1036,Refactoring-a Shot in the Dark?,M. Leppänen; S. Mäkinen; S. Lahtinen; O. Sievi-Korte; A. Tuovinen; T. Männistö,Tampere University of Technology; University of Helsinki; Tampere University of Technology; Tampere University of Technology; University of Helsinki; University of Helsinki,IEEE Software,28 Oct 2015,2015,32,6,62,70,"A study performed semistructured interviews of 12 seasoned software architects and developers at nine Finnish companies. Its main goals were to find out how the practitioners viewed the role and importance of refactoring, and how and when they refactored. Another goal was to see whether shortened cycle times and, especially, continuous-deployment practices affected how and when refactoring was done. The results paint a multifaceted picture with some common patterns. The respondents considered refactoring to be valuable but had difficulty explaining and justifying it to management and customers. Refactoring often occurred in conjunction with the development of new features because it seemed to require a clear business need. The respondents didn't use measurements to quantify the need for or impact of refactoring. This article is part of a special issue on Refactoring.",1937-4194,,10.1109/MS.2015.132,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310989,software architecture;refactoring;metrics;software development;software engineering,Code refractoring;Web services;Agile software development;Software development;Frequency-domain analysis;Software architecture,software architecture;software maintenance,software refactoring;semistructured interviews;software architecture;software development;Finnish companies;continuous-deployment practices,,11.0,,7.0,,28 Oct 2015,,,IEEE,IEEE Magazines
1036,1037,SCEPYLT: An Information System for Fighting Terrorism,J. Cano; R. Hernández,Universidad Nacional de Educacion a Distancia; Universidad Nacional de Educacion a Distancia,IEEE Software,18 Apr 2013,2013,30,3,73,79,"A safety-critical software system called SCEPYLT provides an information solution for a field traditionally not computerized: explosives and their associated risks in handling, storage, transport, and use. SCEPYLT is a model for cooperative distributed systems engineering projects, synchronized over multiple databases.",1937-4194,,10.1109/MS.2013.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6461871,eGovernment;public security;critical software engineering;explosives control;safety-critical;service-oriented architecture;distributed system;cooperative system;terrorism;SCEPYLT,Explosives;Security;Distributed databases;Computers;Mesh networks;Web services;Software reliability;Terrorism,,,,1.0,,15.0,,14 Feb 2013,,,IEEE,IEEE Magazines
1037,1038,Earned Business Value: See That You Deliver Value to Your Customer,J. E. Hannay; H. C. Benestad; K. Strand,Simula Research Laboratory; Expertware; PROMIS,IEEE Software,11 Jul 2017,2017,34,4,58,70,"The order in which you send your backlog items into construction determines when stakeholders can reap benefits from each piece of functionality. This can substantially impact market timing, enterprise earnings, and the project manager survival rate. There are several ways to order a backlog, and sophisticated methods and tools exist to do so-for example, during release planning. But no matter what backlog-ordering scheme you use, you ought to be explicit on the order in which you realize potential business value. To that end, researchers have developed methods to express business value relative to cost in your backlog. They also have devised methods to monitor how much potential business value you're realizing along the way-in addition to the cost expended.",1937-4194,,10.1109/MS.2017.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974676,earned business value;earned value management;benefit points;story points;agile management;software development;software engineering,Schedules;Monitoring;Stakeholders;Business;Cost benefit analysis;Project management,business data processing,backlog items;backlog-ordering scheme;release planning,,2.0,,21.0,,11 Jul 2017,,,IEEE,IEEE Magazines
1038,1039,Adaptive Virtual Gestures for GUI Testing on Smartphones,C. Hsu; S. Lee; S. Winston Shieh,National Chiao Tung University; Chunghwa Telecom; National Chiao Tung University,IEEE Software,22 Sep 2017,2017,34,5,22,29,"Software testing is vital for software developers to launch mobile applications running on various software developer's kit versions and device models. Conventional in-depth testing isn't optimal for mobile apps because they're updated frequently in response to bugs and security concerns. Also, the wide variety of smartphones might diminish app quality owing to insufficient testing. To complement in-depth testing, a proposed breadth-first approach employs fast, automated GUI testing for adaptive virtual gestures on various mobile devices.",1937-4194,,10.1109/MS.2017.3641115,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048624,software testing;mobile application;GUI testing;software development;software engineering;automated GUI testing,Software testing;Graphical user interfaces;Smart phones;Androids;Humanoid robots,gesture recognition;graphical user interfaces;program testing;smart phones;software quality;tree searching,adaptive virtual gestures;smartphones;software testing;software development;mobile applications;software developer kit versions;device model;bugs;security concerns;application quality;breadth-first approach;automated GUI testing;mobile devices,,,,7.0,,22 Sep 2017,,,IEEE,IEEE Magazines
1039,1040,MobiGUITAR: Automated Model-Based Testing of Mobile Apps,D. Amalfitano; A. R. Fasolino; P. Tramontana; B. D. Ta; A. M. Memon,"University of Naples Federico II; University of Naples Federico II; University of Naples Federico II; University of Maryland, College Park; University of Maryland, College Park",IEEE Software,21 Aug 2015,2015,32,5,53,59,"As mobile devices become increasingly smarter and more powerful, so too must the engineering of their software. User-interface-driven system testing of these devices is gaining popularity, with each vendor releasing some automation tool. However, these tools are inappropriate for amateur programmers, an increasing portion of app developers. MobiGUITAR (Mobile GUI Testing Framework) provides automated GUI-driven testing of Android apps. It's based on observation, extraction, and abstraction of GUI widgets' run-time state. The abstraction is a scalable state machine model that, together with test coverage criteria, provides a way to automatically generate test cases. When applied to four open-source Android apps, MobiGUITAR automatically generated and executed 7,711 test cases and reported 10 new bugs. Some bugs were Android-specific, stemming from the event- and activity-driven nature of Android.",1937-4194,,10.1109/MS.2014.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6786194,software testing;GUI testing;android testing;software engineering;mobile apps;Android apps;MobiGUITAR,Software testing;Graphical user interfaces;Androids;Humanoid robots;Mobile communication;Computer bugs,Android (operating system);finite state machines;graphical user interfaces;mobile computing;program testing;public domain software,open-source Android apps;scalable state machine model;automated GUI-driven testing;mobile GUI testing framework;user-interface-driven system testing;mobile apps;automated model-based testing;MobiGUITAR,,129.0,2.0,14.0,,10 Apr 2014,,,IEEE,IEEE Magazines
1040,1041,Requirements-Driven Design of Service-Oriented Interactions,A. Mahfouz; L. Barroca; R. Laney; B. Nuseibeh,"Webalo, Inc., Los Angeles; The Open University, Walton Hall; The Open University, Walton Hall; Lero, Limerick",IEEE Software,14 Oct 2010,2010,27,6,25,32,"Service-oriented architecture (SOA) enables interenterprise service interactions. Services provide platform-independent abstractions around software systems, thereby enabling interoperability between heterogeneous systems. It is supported by a tool, Chreq(Choreograpy requirements) that automatically generates messaging protocols from requirements models. Chreq also generates comments, interleaved with the protocol, to indicate points at which physical activities should execute. Several languages are emerging as standards for describing interfaces and interaction protocols that specify service-oriented systems.",1937-4194,,10.1109/MS.2010.113,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5510236,software engineering,Protocols;Collaboration;Process design,business data processing;formal specification;formal verification;high level languages;open systems;software architecture;Web services,requirement driven design;service oriented architecture;interenterprise service interaction;platform independent abstraction;interoperability;heterogeneous system;interface protocol;interaction protocol;messaging protocol;choreography requirement;Web service description language,,1.0,,8.0,,15 Jul 2010,,,IEEE,IEEE Magazines
1041,1042,"Coping with Quality Requirements in Large, Contract-Based Projects",M. Daneva; A. Herrmann; L. Buglione,University of Twente; Herrmann & Ehrlich; Engineering Ingegneria Informatica,IEEE Software,28 Oct 2015,2015,32,6,84,91,"A typical contract for delivering a large software system must address a variety of related issues such as system quality, timelines, delivery cost and effort, and service-level agreements. Interviews with 20 software architects revealed how they coped with quality requirements in this context.",1937-4194,,10.1109/MS.2014.134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915592,quality requirements;software architecture design;exploratory study;contract-based software development;software engineering;software development,Contracts;Project management;Software systems;Software architecture;Software quality;Software development,contracts;software architecture;software quality;systems analysis,quality requirements;contract-based projects;large software system;system quality;timelines;delivery cost;service-level agreements;software architecture,,4.0,,10.0,,2 Oct 2014,,,IEEE,IEEE Magazines
1042,1043,Toward Compositional Software Product Lines,J. Bosch,"Intuit, Mountain View",IEEE Software,19 Apr 2010,2010,27,3,29,34,"Software product lines (SPLs) were introduced over the last two decades as a mechanism for dealing with the complexities of software systems' ever-increasing size by exploiting the commonalities among the company's different products or systems. By standardizing the software components sourced from the outside and sharing domain specific software assets the company develops among different product teams, you can significantly reduce the per-product R&D cost, which improves the company's competitive position. This can be achieved through a richer product portfolio, a harmonized look-and-feel across the product portfolio, or a significantly higher degree of customer configurability. Companies that successfully deploy SPL technology can achieve order-of magnitude growth over a decade and reach major business milestones.",1937-4194,,10.1109/MS.2010.32,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406498,software product lines;software engineering;reuse;compositional software product lines,Companies;Portfolios;Software systems;Costs,business data processing;product development;software reusability,software product lines;software systems;domain specific software;R & D cost,,11.0,,7.0,,5 Feb 2010,,,IEEE,IEEE Magazines
1043,1044,Agile Architecture Interactions,J. Madison,,IEEE Software,25 Feb 2010,2010,27,2,41,48,"Agile development starts to build before the outcome is fully understood, adjusts designs and plans as empirical knowledge is gained while building, trusts the judgment of those closest to the problem, and encourages continual collaboration with the ultimate consumers. Architecture establishes a technology stack, creates design patterns, enhances quality attributes, and communicates to all interested parties. The combination of these two spaces is agile architecture-an approach that uses agile techniques to drive towards good architecture. Agility and architecture aren't at odds. Agile development gives the architect repeated opportunities to work closely with the business and technical teams to continually guide systems in the direction of good architecture.",1937-4194,,10.1109/MS.2010.35,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420794,agile development;enterprise architecture;software engineering;project management;team organization,Space technology;Buildings;Collaboration,software architecture;software prototyping,agile architecture;architectural priority;agile development;software architecture;software development,,35.0,,16.0,,25 Feb 2010,,,IEEE,IEEE Magazines
1044,1045,The Connected Car in the Cloud: A Platform for Prototyping Telematics Services,T. Häberle; L. Charissis; C. Fehling; J. Nahm; F. Leymann,Daimler TSS; Daimler TSS; University of Stuttgart; Daimler TSS; University of Stuttgart,IEEE Software,28 Oct 2015,2015,32,6,11,17,"The Connected-Car Prototyping Platform provides both a back end for applications interacting with connected cars and an abstraction of such connected devices for developers. It also provides services such as identity management and data storage. Its main purposes are experimentation, prototyping, evaluation of ideas, and reduction of time-to-market for successful applications.",1937-4194,,10.1109/MS.2015.137,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310999,Connected-Car Prototyping Platform;prototyping platform;application templates;Maven;connected cars;automotive software;telematics;cloud computing;software engineering;software development,Telematics;Intelligent vehicles;Automotive electronics;Computer architecture;Java;Cloud computing;User interfaces,automobiles;automotive engineering;cloud computing;software prototyping,connected-car prototyping platform;cloud platform;telematics service;identity management;data storage,,20.0,,12.0,,28 Oct 2015,,,IEEE,IEEE Magazines
1045,1046,Up in the Air: Moving Your Applications to the Cloud,P. Louridas,consultant,IEEE Software,14 Jun 2010,2010,27,4,6,11,"An overview of cloud computing helps developers get beyond the hype by characterizing its unique requirements, the ways to implement cloud services, and the ways to operate the cloud infrastructure. A comparison of major products is included.",1937-4194,,10.1109/MS.2010.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484106,networking and communications;software engineering;systems engineering,Cloud computing,Internet;Web services,cloud computing;cloud infrastructure,,14.0,,,,14 Jun 2010,,,IEEE,IEEE Magazines
1046,1047,Software Adaptation: Classification and a Case Study with State Chart XML,F. Barbier; E. Cariou; O. L. Goaer; S. Pierre,University of Pau; University of Pau; University of Pau; University of Pau,IEEE Software,21 Aug 2015,2015,32,5,68,76,"Software adaptation has become prominent owing to the proliferation of software in everyday devices. In particular, computing with the Internet of Things requires adaptability. Traditional software maintenance, which involves long, energy-consuming cycles, is no longer satisfactory. Adaptation is a lightweight software evolution that provides more transparent maintenance for users. This article classifies types of adaptation and describes an implementation of it.",1937-4194,,10.1109/MS.2014.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6894482,software;model-driven development;model execution;software adaptation;software maintenance;software development;software engineering,Adaptation models;Unified modeling language;Java;Maintenance engineering;XML;Software maintenance,Internet of Things;software maintenance;XML,software adaptation;state chart XML;software proliferation;Internet of Things;software maintenance;energy-consuming cycles;lightweight software evolution,,3.0,,11.0,,9 Sep 2014,,,IEEE,IEEE Magazines
1047,1048,Impact of Ad Libraries on Ratings of Android Mobile Apps,I. J. Mojica Ruiz; M. Nagappan; B. Adams; T. Berger; S. Dienst; A. E. Hassan,McAfee; Rochester Institute of Technology; École Polytechnique de Montréal; University of Waterloo; University of Leipzig; Queen's University,IEEE Software,7 Nov 2014,2014,31,6,86,92,"One of the most popular ways to monetize a free app is by including advertisements in the app. Several advertising (ad) companies provide these ads to app developers through ad libraries that need to be integrated in the app. However, the demand for ads far exceeds the supply. This obstacle may lead app developers to integrate several ad libraries from different ad companies in their app to ensure they receive an ad with each request. However, no study has explored how many ad libraries are commonly integrated into apps. Additionally, no research to date has examined whether integrating many different ad libraries impacts an app's ratings. This article examines these two issues by empirically examining thousands of Android apps. The authors find that there are apps with as many as 28 ad libraries, but they find no evidence that the number of ad libraries in an app is related to its possible rating in the app store. However, integrating certain ad libraries can negatively impact an app's rating.",1937-4194,,10.1109/MS.2014.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6811104,software;mobile apps;ad libraries;Android;software economics;ad maintenance;software engineering,Advertisements;Companies;Androids;Humanoid robots;Mobile communication;Software development;Computer applications,advertising;Android (operating system);mobile computing;software libraries,ad libraries;Android mobile app ratings;free app monetization;advertisements;advertising companies;app store,,29.0,,13.0,,7 May 2014,,,IEEE,IEEE Magazines
1048,1049,Evaluating High-Performance Computing on Google App Engine,R. Prodan; M. Sperk; S. Ostermann,University of Innsbruck; University of Innsbruck; University of Innsbruck,IEEE Software,20 Feb 2012,2012,29,2,52,58,"An experimental approach employs the Google App Engine (GAE) for high-performance parallel computing. A generic master-slave framework enables fast prototyping and integration of parallel algorithms that are transparently scheduled and executed on the Google cloud infrastructure. Compared to Amazon Elastic Compute Cloud (EC2), GAE offers lower resource-provisioning overhead and is cheaper for jobs shorter than one hour. Experiments demonstrated good scalability of a Monte Carlo simulation algorithm. Although this approach produced important speedup, two main obstacles limited its performance: middleware overhead and resource quotas.",1937-4194,,10.1109/MS.2011.131,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6051415,cloud computing;high-performance computing;performance analysis;Google App Engine;GAE;Amazon Elastic Compute Cloud;Amazon EC2;software engineering,Google;Servers;Computer applications;Computational modeling;Parallel processing;Computer performance,cloud computing;middleware;Monte Carlo methods;parallel algorithms,Google App Engine;high-performance parallel computing;generic master-slave framework;parallel algorithm;Google cloud infrastructure;Amazon Elastic Compute Cloud;resource-provisioning overhead;Monte Carlo simulation algorithm;middleware overhead;resource quotas;GAE,,18.0,,12.0,,18 Oct 2011,,,IEEE,IEEE Magazines
1049,1050,The Risks of Agile Software Development: Learning from Adopters,A. Elbanna; S. Sarker,"Royal Holloway, University of London; University of Virginia",IEEE Software,24 Aug 2016,2016,33,5,72,79,"Agile software development (ASD) resulted from widespread professional discontent with traditional approaches; development projects' high failure rates; and, most important, the need for speedy, responsive delivery of software for Internet businesses. Many practitioners have embraced ASD, which commentators often extol as a faster, better, and cheaper development approach. However, a recent high-profile failure of an ASD project and the discontinued use of ASD in a software company have drawn attention to ASD's possible risks. Before we can manage such risks, we must identify them and understand why they arise. Researchers conducted interviews with 112 people in 28 organizations and with 25 ASD contractors and consultants. The interviews revealed key ASD risks that require careful management to achieve the desired project outcomes.",1937-4194,,10.1109/MS.2015.150,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325176,agile software development;agile risks;software development risks;software risk management;software development;software engineering,Software development;Risk management;Agile software development;Software engineeirng,risk management;software prototyping,agile software development;development project high failure rates;ASD risk management;Internet business software,,10.0,,14.0,,11 Nov 2015,,,IEEE,IEEE Magazines
1050,1051,Multicore Desktop Programming with Intel Threading Building Blocks,W. Kim; M. Voss,Intel; Intel,IEEE Software,20 Dec 2010,2011,28,1,23,31,The paper mentions that the Intel Threading Building Blocks is a key component of Intel Parallel Building Blocks. This widely used C++ template library helps developers achieve well-performing modular parallel programs in multiprogrammed environments.,1937-4194,,10.1109/MS.2011.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672517,multicore programming;threading libraries;parallel-programming models;software engineering;programming;parallel programming,Computer threading;Instruction sets;Parallel processing;Arrays;Programming;Concurrent computing,C++ language;multiprocessing systems;parallel programming,multicore desktop programming;Intel threading building blocks;C++ template library;parallel programs;multiprogrammed environment,,26.0,,15.0,,20 Dec 2010,,,IEEE,IEEE Magazines
1051,1052,Community Collaboration for ERP Implementation,H. Wu; L. Cao,Old Dominion University; Old Dominion University,IEEE Software,16 Oct 2009,2009,26,6,48,55,"The paper discusses the enterprise resource planning (ERP).ERP implementation solves business problems by customizing and integrating off-the-shelf enterprise software packages. A successful ERP implementation involves extensive collaboration and communication among the customer, implementation consultancy, and software vendor. Collaboration allows implementation personnel from different organizations to utilize each other's experiences. An example of this is the Web 2.0. A Web 2.0 knowledge repository system can reduce costs, improve quality, and lower the risks of ERP implementations.Through the case study, the key desired features for Web 2.0 knowledge repository system to support ERP implementations were defined. Epics was designed to fulfill these requirements and developed a prototype. Epics can be used by software vendors, ERP consulting firms, and ERP users. Human aspects play a critical role in ERP implementation. ERP implementation quality depends largely on how the implementation personnel's knowledge and past experiences are reused and communicated. Although knowledge reuse, collaboration, and communication are important for all software projects, they're particularly critical in ERP implementation owing to its unique challenges.",1937-4194,,10.1109/MS.2009.171,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287009,Web 2.0;ERP implementation;software engineering;software implementation;packaged software;enterprise resource planning;ERP,Collaboration;Enterprise resource planning;Collaborative software;Personnel;Software packages;Costs;Software prototyping;Prototypes;Humans,data mining;enterprise resource planning;groupware;Internet;software reusability;software tools,ERP implementation;community collaboration;enterprise software packages;software vendor;Web 2.0 knowledge repository system;Epics software;ERP consulting firms;ERP users;knowledge reuse;communication,,12.0,1.0,12.0,,16 Oct 2009,,,IEEE,IEEE Magazines
1052,1053,PriView: Personalized Media Consumption Meets Privacy against Inference Attacks,S. Bhamidipati; N. Fawaz; B. Kveton; A. Zhang,Technicolor; Technicolor; Adobe Research; SET Media,IEEE Software,30 Jun 2015,2015,32,4,53,59,"PriView is an interactive personalized video consumption system that protects user privacy while recommending relevant content. It provides transparency of privacy risk, control of privacy risk, and personalized recommendations. It implements an information-theoretic framework to enable a utility-aware privacy mapping that distorts a user's video ratings to prevent attackers from inferring users' personal attributes (such as age, gender, or political views), while maintaining the distorted ratings' usefulness for recommendations. PriView uses convex optimization to create a probability mapping from actual ratings to distorted ratings that minimizes the distortion, subject to a privacy constraint. One practical challenge is scalability, when data comes from a large alphabet. Quantization combined with low-rank approximation of the rating matrix helps reduce the number of optimization variables. Evaluations showed that PriView can achieve perfect privacy with little change in recommendation quality. This article is part of a special issue on Security and Privacy on the Web.",1937-4194,,10.1109/MS.2015.100,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140690,inference attack;video personalization;privacy;privacy risk;privacy-utility tradeoff;video recommendations;transparency;video on demand;PriView;software engineering;software development,Computer security;Data privacy;TV;Distortion;Quantization (signal);Video on demand;Databases,convex programming;data protection;interactive video;quantisation (signal);recommender systems,PriView;personalized media consumption;inference attacks;interactive personalized video consumption system;user privacy protection;personalized content recommendation;privacy risk control;utility-aware privacy mapping;user video ratings;user personal attributes;user age;user gender;user political views;convex optimization;probability mapping;distortion minimization;quantization;low-rank approximation;rating matrix;optimization variables,,5.0,,6.0,,30 Jun 2015,,,IEEE,IEEE Magazines
1053,1054,"Software Security, Privacy, and Dependability: Metrics and Measurement",G. Hatzivasilis; I. Papaefstathiou; C. Manifavas,Technical University of Crete; Technical University of Crete; Rochester Institute of Technology Dubai,IEEE Software,23 Jun 2016,2016,33,4,46,54,"Measurement of software security is an ongoing research field. Privacy is also becoming an imperative target as social networking and ubiquitous computing evolve and users exchange high volumes of personal information. However, security and privacy alone don't guarantee proper data protection; software must also be dependable. Several standards typify the main concepts and protection mechanisms for these three properties, and measurement methodologies can quantify the provided protection level. However, security, privacy, and dependability are usually dealt with in isolation. To solve this problem, researchers have proposed a practical, easy-to-use methodology that measures a software system's overall security, privacy, and dependability (SPD) on the basis of the standards for each property. The nSHIELD (New Embedded Systems Architecture for Multi-layer Dependable Solutions) project is applying the SPD methodology to evaluate configurable embedded software in a social-mobility scenario.",1937-4194,,10.1109/MS.2016.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436657,metrics;measurement;risk management;software quality assurance;verification and validation;security;privacy;software reliability;software dependability;nSHIELD;software engineering;software development,Privacy;Software security;Software measurement;Computer security;Process control,data privacy;security of data;software metrics;software quality,software security;privacy;dependability;metrics;social networking;ubiquitous computing;personal information;data protection;protection mechanisms;measurement methodologies;protection level;isolation;software system;nSHIELD project;SPD methodology;embedded software;social mobility scenario,,19.0,,11.0,,18 Mar 2016,,,IEEE,IEEE Magazines
1054,1055,Evolution of Software Systems with Extensible Languages and DSLs,S. Erdweg; S. Fehrenbach; K. Ostermann,"Technische Universität Darmstadt, Germany; University of Marburg, Germany; University of Marburg, Germany",IEEE Software,15 Sep 2014,2014,31,5,68,75,"Domain-specific languages (DSLs) provide various advantages regarding the maintainability of software systems. Unfortunately, existing software systems don't exploit DSLs and their maintenance benefits. Based on the extensible programming language SugarJ, the authors present a process for gradually integrating DSLs into existing software systems, report on their experience in integrating three DSLs into two existing software systems, and outline a roadmap for the development of tool support for the integration of DSLs.",1937-4194,,10.1109/MS.2014.99,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6840824,domain-specific languages;extensible programming languages;language embedding;software evolution;software maintenance;legacy applications;SugarJ;software engineering,DSL;Java;Software systems;Syntactics;Maintenance engineering;Programming;Domain specific languages;Embedded systems,high level languages;software maintenance,software system evolution;extensible languages;DSL;domain-specific languages;software system maintainability;SugarJ programming language,,,,16.0,,20 Jun 2014,,,IEEE,IEEE Magazines
1055,1056,Microservices Architecture Enables DevOps: Migration to a Cloud-Native Architecture,A. Balalaie; A. Heydarnoori; P. Jamshidi,Sharif University of Technology; Sharif University of Technology; Imperial College London,IEEE Software,25 Apr 2016,2016,33,3,42,52,This article reports on experiences and lessons learned during incremental migration and architectural refactoring of a commercial mobile back end as a service to microservices architecture. It explains how the researchers adopted DevOps and how this facilitated a smooth migration.,1937-4194,,10.1109/MS.2016.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7436659,DevOps;microservices;cloud computing;migration pattern;architectural refactoring;software engineering;software development;mobile back end as a service,Computer architecture;Servers;Cloud computing;Microservices;Scalability;Mobile communication;Software architecture;Refractoring,cloud computing;software architecture;software maintenance,microservices architecture;DevOps;incremental migration;architectural refactoring;cloud-native architecture,,245.0,1.0,17.0,,18 Mar 2016,,,IEEE,IEEE Magazines
1056,1057,Using the Agile Unified Process in Banking,I. Christou; S. Ponis; E. Palaiologou,"Athens Information Technology, Paiania; National Technical University of Athens, Athens; Athens Information Technology, Paiania",IEEE Software,19 Apr 2010,2010,27,3,72,79,"The banking sector is well known for using large, sometimes monolithic, legacy systems. Now, banks find themselves having to catch up with rapid advancements in software development that call for new service-oriented computing paradigms. Unfortunately, this task is nontrivial and often requires huge projects that are costly, time consuming, and risky. The safe choice for a development methodology is a process framework such as the Rational Unified Process (RUP), which is customizable enough to fit any project. However, customizing RUP isn't trivial, so it's often used in its full-blown out-of-the-box form, which entails significant sacrifices of time, cost, and flexibility. The Agile Unified Process (AUP)-a hybrid approach designed by Scott Ambler combining RUP with agile methods to a successful project in the banking sector. The project achieved on-time delivery within budget, integrating heavy legacy back-end application systems with newly reengineered client user-interface applications on a modern service-oriented architecture (SOA) platform.",1937-4194,,10.1109/MS.2009.156,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232801,software engineering;enterprise systems;systems design and analysis;methodologies;process;project management,Banking;Service oriented architecture;Programming;Costs,banking;software architecture;software maintenance;software prototyping;user interfaces,agile unified process;banking sector;software development;rational unified process;client user-interface application;service-oriented architecture;SOA;monolithic systems;legacy systems,,4.0,,12.0,,4 Sep 2009,,,IEEE,IEEE Magazines
1057,1058,Mining Task-Based Social Networks to Explore Collaboration in Software Teams,T. Wolf; A. Schröter; D. Damian; L. D. Panjer; T. H. D. Nguyen,University of Victoria; University of Victoria; University of Victoria; University of Victoria; University of Victoria,IEEE Software,22 Dec 2008,2009,26,1,58,66,"Suppose you're a software team manager who's responsible for delivering a software product by a specific date, and your team uses a code integration system (referred to as a build in IBM Rational Jazz and in this article) to integrate its work before delivery. When the build fails, your team needs to spend extra time diagnosing the integration issue and reworking code. As the manager, you suspect that your team failed to communicate about a code dependency, which broke the build. Your team needs to quickly disseminate information about its interdependent work to achieve a successful integration build. How can you understand your team's communication? Social-network analysis can give you insight into the team's communication patterns that might have caused the build's failure.",1937-4194,,10.1109/MS.2009.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721184,computer-supported collaborative work;organizational Impacts;software engineering;data mining,Social network services;Collaboration;Software;Graphical user interfaces;Data mining;Presses;Filtering,groupware;project management;social networking (online);software development management;team working,task-based social networks;collaboration;software teams;repository-independent approach;task-based communication,,58.0,,7.0,,22 Dec 2008,,,IEEE,IEEE Magazines
1058,1059,CodeBender: Remote Software Protection Using Orthogonal Replacement,M. Ceccato; P. Tonella,Fondazione Bruno Kessler; Fondazione Bruno Kessler,IEEE Software,28 Feb 2011,2011,28,2,28,34,"CodeBender implements a novel client replacement strategy to counter the malicious host problem and address the problem of guaranteeing client-code security. CodeBender is a tool that implements a novel client-replacement strategy to counter the malicious host problem. It works by limiting the client code's validity and, when the code expires, by having the server provide a new client that replaces the former one. The complexity of analyzing frequently changing, always different (orthogonal) program code deters an adversary's reverse engineering efforts. We've implemented CodeBender and tested its practicability in two case studies.",1937-4194,,10.1109/MS.2010.158,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661761,hardware/software protection;development tools;software/software engineering;program transformation;security and protection,OFDM;Remote monitoring;Data structures;Encoding;Synchronization;Layout;Computer security,industrial property;program testing;reverse engineering,CodeBender;remote software protection;orthogonal replacement;client replacement strategy;malicious host problem;client code security;malicious host problem;client code validity;program code;reverse engineering,,6.0,,4.0,,10 Dec 2010,,,IEEE,IEEE Magazines
1059,1060,Developing a Scheduler with Difference-Bound Matrices and the Floyd-Warshall Algorithm,L. Ridi; J. Torrini; E. Vicario,Universita di Firenze; Universita di Firenze; Universita di Firenze,IEEE Software,22 Dec 2011,2012,29,1,76,83,A study of difference-bound matrices and the Floyd-Warshall algorithm in the development of an online scheduler provides the backdrop for a comparison of software practice and algorithmic theory.,1937-4194,,10.1109/MS.2011.128,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111367,sequencing and scheduling;graph algorithms;Floyd-Warshall algorithm;difference-bound matrix;model checking;software engineering,Software algorithms;Scheduling;Difference equations;Algorithm design and analysis,graph theory;matrix algebra;scheduling,difference-bound matrices;Floyd-Warshall algorithm;online scheduler;software practice;algorithmic theory,,4.0,,12.0,,22 Dec 2011,,,IEEE,IEEE Magazines
1060,1061,Feminine Expertise in Architecting Teams,M. Razavian; P. Lago,VU University Amsterdam; VU University Amsterdam,IEEE Software,23 Jun 2016,2016,33,4,64,71,"A well-known adage is ""diversity brings innovation."" Diversity can be in culture, thinking, discipline, gender, and many more aspects. The result is the same: the chances for creating innovation in a given context increase when diversity is involved. To some extent, this principle should also hold for gender diversity in software teams. Achieving gender diversity in IT-related fields has been a goal for decades, but still, too few women choose such a career. But what skills or traits assigned to the feminine role bring concrete advantages to software teams? Researchers addressed this important and, strangely enough, mostly unexplored problem, specifically for software-architecting teams. They interviewed male and female software architects at four major IT companies in the Netherlands and then interviewed a panel of experts. They identified seven feminine expertise ""flavors""--traits and skills linked to the feminine role in architecting teams. Much of such expertise relates to the skills required to successfully deal with software architecting's human aspects.",1937-4194,,10.1109/MS.2015.84,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7155435,software engineering;software development;software architecting;gender diversity;feminine expertise;gender studies;human factors,Interviews;Gender issues;Cultural differences;Technological innovation,gender issues;software architecture;team working,feminine expertise;innovation;gender diversity;software teams;IT-related fields;feminine role;software-architecting teams;female software architects;major IT companies,,6.0,,14.0,,13 Jul 2015,,,IEEE,IEEE Magazines
1061,1062,Software Architecture Design Reasoning: A Case for Improved Methodology Support,A. Tang; J. Han; R. Vasa,Swinburne University of Technology; Swinburne University of Technology; Swinburne University of Technology,IEEE Software,24 Feb 2009,2009,26,2,43,49,This paper presents the capturing and recording of reasoning behind software architecture design to encourage architects to more carefully consider design decisions and better support future maintenance.,1937-4194,,10.1109/MS.2009.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786951,software architecture;design reasoning;software engineering;service interactions;speech acts,Software architecture;Software design;Process design;Design methodology;Computer architecture;Decision making;Context;Productivity,software architecture;software maintenance,software architecture design reasoning;improved methodology support;design decisions,,21.0,,12.0,,24 Feb 2009,,,IEEE,IEEE Magazines
1062,1063,Scrapheap Software Development: Lessons from an Experiment on Opportunistic Reuse,G. Kotonya; S. Lock; J. Mariani,Lancaster University; Lancaster University; Lancaster University,IEEE Software,28 Feb 2011,2011,28,2,68,74,In this paper a set of 10 guidelines for opportunistic software reuse is discussed. These guidelines are based on observations of nine systems developed entirely with scraps of functionality scavenged from abandoned projects.,1937-4194,,10.1109/MS.2010.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5432144,Software engineering;opportunistic reuse;scrapheap development;component-based development,Programming;Software systems;Software reusability;Investments;Application software;Software tools;Software prototyping;Prototypes,project management;software development management;software reusability,scrapheap software development:;opportunistic software reuse;abandoned project,,2.0,,3.0,,18 Mar 2010,,,IEEE,IEEE Magazines
1063,1064,Database Refactoring: Lessons from the Trenches,G. Vial,HEC Montreal,IEEE Software,28 Oct 2015,2015,32,6,71,79,"Although database refactoring has been advocated as an important area of database development, little research has studied its implications. A small software development firm refactored a database related to an application that lets clients optimize their logistics processes. This project was based on the design of clear database development conventions and the need to package documentation in the database itself. The experience led to five key lessons learned: refactoring should be automated whenever possible, the database catalog is crucial, refactoring is easier when it's done progressively, refactoring can help optimize an application and streamline its code base, and refactoring related to application development requires a complex skill set and must be applied sensibly. This article is part of a special issue on Refactoring.",1937-4194,,10.1109/MS.2015.131,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310988,database management;database design;data manipulation languages;data description languages;relational databases;transaction processing;database evolution;database refactoring;software engineering;software development;refactoring,Software development;Data models;Code refractoring;Servers;Maintenance engineering,database management systems;software maintenance,database refactoring;database development;software development,,6.0,,12.0,,28 Oct 2015,,,IEEE,IEEE Magazines
1064,1065,A Comprehensive Evaluation of Common Python Implementations,J. M. Redondo; F. Ortin,University of Oviedo; University of Oviedo,IEEE Software,30 Jun 2015,2015,32,4,76,84,"Python is a widely used general-purpose dynamic language. Owing to its popularity, many implementations exist for the two distinct Python 2 and Python 3 language versions. Researchers evaluated seven implementations of both language versions to facilitate the selection of one of them. For this purpose, they carefully selected 523 programs to execute in each implementation. They evaluated run-time performance and memory consumption and investigated each implementation's important qualitative characteristics.",1937-4194,,10.1109/MS.2014.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6879048,dynamic languages;Python;run-time performance;memory consumption;benchmark suite;performance analysis;JIT compilation;just-in-time compilation;software engineering;software development,Runtime;Benchmark testing;Java;Memory management;Visual BASIC;Dynamic programming,high level languages;storage management,Python implementations;general-purpose dynamic language;Python 2 language versions;Python 3 language version;run-time performance;memory consumption,,12.0,,14.0,,15 Aug 2014,,,IEEE,IEEE Magazines
1065,1066,Open Collaboration within Corporations Using Software Forges,D. Riehle; J. Ellenberger; T. Menahem; B. Mikhailovski; Y. Natchetoi; B. Naveh; T. Odenwald,SAP Labs; SAP Research; SAP Labs; SAP Labs; SAP; Moblica; ICW Technology Labs,IEEE Software,24 Feb 2009,2009,26,2,52,58,"This article describes our experiences using open source software development practices at SAP. SAP is a major software developer and leader in business applications. We've found that open source practices can complement traditional top-down software development with bottom-up collective intelligence. Software forges offer a mechanism for advancing the adoption of open source best practices within corporations. We illustrate our experiences using SAP's own internal software forge, called SAP Forge, and compare our experiences with those from other large software companies.",1937-4194,,10.1109/MS.2009.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786953,Software Engineering;Programming Environments;Management;Information Interfaces and Presentations;User/Machine Systems;Group and Organization Interfaces;Management of Computing and Information Systems;Project and People Management;Software Management;software forge;collaborative software development;open source;open source best practices;open collaboration,Collaborative software;Open source software;Programming;Software tools;Software development management;Collaboration;Internet;Navigation;Project management;Switches,business data processing;DP industry;public domain software;software development management,SAP Forge;open source software development;business applications;collective intelligence;internal software forge;software companies,,28.0,,13.0,,24 Feb 2009,,,IEEE,IEEE Magazines
1066,1067,Characterizing Architecturally Significant Requirements,L. Chen; M. Ali Babar; B. Nuseibeh,University of Limerick and Paddy Power PLC; Lancaster University and IT University of Copenhagen; University of Limerick and The Open University,IEEE Software,25 Feb 2013,2013,30,2,38,45,"This article presents a framework for characterizing architecturally significant requirements (ASRs) on the basis of an empirical study using grounded theory. The study involved interviews with 90 practitioners with an accumulated 1,448 years of software development experiences in more than 500 organizations of various sizes and domains. These findings could provide researchers with a framework for discussing and conducting further research on ASRs and can inform researchers' development of technologies for dealing with ASRs. The findings also enrich understanding of requirements and architecture interactions, allowing the twin peaks to move from aspiration to reality.",1937-4194,,10.1109/MS.2012.174,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6365165,requirements;specifications;software engineering;software architectures;architecturally significant requirements;nonfunctional requirements;quality attributes;grounded theory;empirical study;ASR,Software devlopment;Computer architecture;Software architecture;Contracts,software architecture,architecturally significant requirements;ASR;empirical study;grounded theory;software development experiences;architecture interactions,,64.0,,10.0,,29 Nov 2012,,,IEEE,IEEE Magazines
1067,1068,Software Testing and Verification in Climate Model Development,T. Clune; R. Rood,NASA/Goddard Space Flight Center; University of Michigan,IEEE Software,20 Oct 2011,2011,28,6,49,55,"Over the past 30 years, most climate models have grown from relatively simple representations of a few atmospheric processes to complex multidisciplinary systems. Computer infrastructure over that period has gone from punchcard mainframes to modern parallel clusters. Model implementations have become complex, brittle, and increasingly difficult to extend and maintain. Verification processes for model implementations rely almost exclusively on some combination of detailed analyses of output from full climate simulations and system-level regression tests. Besides being costly in terms of developer time and computing resources, these testing methodologies are limited in the types of defects they can detect, isolate, and diagnose. Mitigating these weaknesses of coarse-grained testing with finer-grained unit tests has been perceived as cumbersome and counterproductive. Recent advances in commercial software tools and methodologies have led to a renaissance of systematic fine-grained testing. This opens new possibilities for testing climate-modeling-software methodologies.",1937-4194,,10.1109/MS.2011.117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999647,software engineering;program verification;testing strategies;testing and debugging,Atmospheric measurements;Meteorology;Software development;Computational modeling;Atmospheric modeling;Numerical models;Global warming,climatology;digital simulation;geophysics computing;program diagnostics;program testing;program verification,software testing;software verification;climate model development;atmospheric process;computer infrastructure;parallel clusters;verification process;climate simulation;system-level regression test;computing resources;defect detection;defect isolation;defect diagnosis,,21.0,,16.0,,25 Aug 2011,,,IEEE,IEEE Magazines
1068,1069,Capturing Compliance Requirements: A Pattern-Based Approach,O. Turetken; A. Elgammal; W. van den Heuvel; M. P. Papazoglou,Tilburg University; Tilburg University; Tilburg University; Tilburg University,IEEE Software,20 Apr 2012,2012,29,3,28,36,"In today's IT-centric business environment, managing compliance with regulations, laws, and other imperatives has become critical for success. Directives govern almost every aspect of running a business, requiring organizations to provide assurances to regulators, stakeholders, customers, and business partners. Assuring compliance across an enterprise necessitates a holistic, tractable, and disciplined approach for defining an integrated, consistent set of process and system-level internal controls. A new pattern-based framework captures and manages business process compliance requirements by acting as a springboard to fully automate and continuously audit business processes.",1937-4194,,10.1109/MS.2012.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6158632,business process management;representations;business process compliance;business process;software engineering,Process control;Monitoring;Optimization;Runtime;Risk management;Object recognition,auditing;business data processing;formal verification;legislation,pattern-based framework;business process compliance requirement management;business process auditing;assurance;organizational objective;business partners,,30.0,1.0,11.0,,27 Feb 2012,,,IEEE,IEEE Magazines
1069,1070,The Runtime Performance of invokedynamic: An Evaluation with a Java Library,F. Ortin; P. Conde; D. Fernandez-Lanvin; R. Izquierdo,University of Oviedo; University of Oviedo; University of Oviedo; University of Oviedo,IEEE Software,13 Jun 2014,2014,31,4,82,90,"The Java 7 platform includes the invokedynamic opcode in its virtual machine, a feature that lets programmers define-and dynamically change-the linkage of method call sites, thereby maintaining platform optimizations. A comprehensive evaluation of a new library's performance includes a description of how to optimize real Java applications.",1937-4194,,10.1109/MS.2013.46,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6493308,invokedynamic;Java Virtual Machine;runtime performance;dynamic languages;reflection;software engineering,Java;Runtime;Programming;Benchmark testing;Performance evaluation,Java;software libraries;source code (software);virtual machines,runtime performance;Java library performance;Java 7 platform;invokedynamic opcode;virtual machine;method call sites;platform optimizations;source code,,12.0,,9.0,,3 Apr 2013,,,IEEE,IEEE Magazines
1070,1071,The Architect's Role in Practice: From Decision Maker to Knowledge Manager?,R. Weinreich; I. Groher,Johannes Kepler University Linz; Johannes Kepler University Linz,IEEE Software,28 Oct 2016,2016,33,6,63,69,"Interviews with European and US software architects show not only a diverse practice of architecting but also the architect's transformation from primary decision maker to coordinator, advisor, and knowledge manager.",1937-4194,,10.1109/MS.2016.143,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725227,software architecture;architectural decision making;software architecture knowledge management;industrial interview study;software development;software engineering,Software architecture;Computer architecture;Interviews,personnel;software architecture;software development management,European software architects;US software architects;decision maker;knowledge manager;United States;coordinator;advisor,,3.0,,12.0,,28 Oct 2016,,,IEEE,IEEE Magazines
1071,1072,Safety Analysis of Safety-Critical Systems Using State-Space Models,V. Kumar; L. K. Singh; A. K. Tripathi; P. Singh,Indian Institute of Technology (Banaras Hindu University); Indian Institute of Technology (Banaras Hindu University); Indian Institute of Technology (Banaras Hindu University); Indian Institute of Technology (Banaras Hindu University),IEEE Software,11 Jul 2017,2017,34,4,38,47,"State-space modeling is useful for prognostics of safety-critical systems. However, building such a model that embeds all the system requirements is a challenge. Furthermore, it requires expertise and hence isn't easily understood by all the stakeholders. UML can handle these challenges. A proposed approach converts a UML model into a state-space model. Researchers validated this approach on 13 safety-critical systems for nuclear power plants, focusing on the emergency core cooling system.",1937-4194,,10.1109/MS.2017.93,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974681,Petri nets;statecharts;state-space modeling;UML;software development;software engineering;nuclear power plants;emergency core cooling system;safety-critical systems,Unified modeling language;Reliability engineering;State-space methods;Safety;Mission critical systems,nuclear power stations;safety-critical software;Unified Modeling Language,safety-critical systems;state-space models;UML model;nuclear power plants;emergency core cooling system,,2.0,,15.0,,11 Jul 2017,,,IEEE,IEEE Magazines
1072,1074,Combining Service-Orientation with Product Line Engineering,J. Lee; G. Kotonya,"Lancaster University, Lancaster; Lancaster University , Lancaster",IEEE Software,19 Apr 2010,2010,27,3,35,41,"Software product line engineering (SPLE) is a paradigm of software reuse for developing a family of products with reduced time to market and improved quality. Most SPLE approaches, however, have focused on developing statically configured products using core assets. That is, all variations are instantiated before a product is delivered to the customers, making it difficult for them to make any changes to the product. However, various application areas are increasing the demand for dynamic product reconfiguration. A service-oriented product line (SOPL) is a DSPL application domain that's built on services and a service-oriented architecture. An example of an application area for an SOPL approach is a virtual office (VO). A VO includes many business peripherals with various services that interact with one another and that respond to their various environments to assist office workers.",1937-4194,,10.1109/MS.2010.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5406497,software;service-oriented product line;feature-oriented product line method;dynamic product line;service orientation;service-oriented architecture;QoS-aware framework;software engineering,Software quality;Time to market;Service oriented architecture;Teleworking,product development;software architecture;software reusability;virtual reality,service-orientation;software product line engineering;software reuse;core assets;dynamic product reconfiguration;service-oriented product line;service-oriented architecture;virtual office,,34.0,,15.0,,5 Feb 2010,,,IEEE,IEEE Magazines
1073,1075,Approximating Data with the Count-Min Sketch,G. Cormode; M. Muthukrishnan,AT&TLabs-Research; Rutgers University,IEEE Software,22 Dec 2011,2012,29,1,64,69,"Faced with handling multiple large data sets in modern data-processing settings, researchers have proposed sketch data structures that capture salient properties while occupying little memory and that update or probe quickly. In particular, the Count-Min sketch has proven effective for a variety of applications. It concurrently tracks many item counts with surprisingly strong accuracy.",1937-4194,,10.1109/MS.2011.127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6042851,Count-Min sketch;massive data;streaming algorithms;software engineering,Software algorithms;Data processing;Data structures;Large-scale systems,data handling,Count-Min sketch;data approximation;data-processing setting;data set handling,,22.0,,8.0,,13 Oct 2011,,,IEEE,IEEE Magazines
1074,1076,Improving Domain-Specific Language Reuse with Software Product Line Techniques,J. White; J. H. Hill; J. Gray; S. Tambe; A. S. Gokhale; D. C. Schmidt,Vanderbilt University; Vanderbilt University; University of Alabama; Vanderbilt University; Vanderbilt University; Vanderbilt University,IEEE Software,19 Jun 2009,2009,26,4,47,53,"Complex software systems, such as traffic management systems and shipboard computing environments, raise several concerns (such as performance, reliability, and fault tolerance) that developers must manage throughout the software life cycle. Domain-specific languages (DSLs) have emerged as a powerful mechanism for capturing and reasoning about these diverse concerns. For each system concern, you can design a DSL to precisely capture key domain-level information while shielding developers and users from the technical solution's implementation-level details.",1937-4194,,10.1109/MS.2009.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076458,feature models;domain-specific languages;reuse;software product lines;domain analysis;domain hierarchy;software engineering,Domain specific languages;DSL;Light scattering;Hardware;System testing;Context modeling;Embedded software;Application software;Programming;Traffic control,software reusability;specification languages,domain-specific language reuse;software product line techniques;complex software systems;software life cycle,,39.0,,4.0,,19 Jun 2009,,,IEEE,IEEE Magazines
1075,1077,Node.DPWS: Efficient Web Services for the Internet of Things,K. Fysarakis; D. Mylonakis; C. Manifavas; I. Papaefstathiou,Technical University of Crete; freelance software developer; Technological Educational Institute of Crete; Technical University of Crete,IEEE Software,25 Apr 2016,2016,33,3,60,67,"Node.DPWS is an implementation of the Devices Profile for Web Services (DPWS). It comprises the first set of DPWS libraries available to Node.js developers and can be used to deploy lightweight, efficient, and scalable Web services over heterogeneous nodes.",1937-4194,,10.1109/MS.2015.155,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325198,Web services;development tools;software libraries;software development;standards;ubiquitous computing;software engineering;DPWS;Devices Profile for Web Services;Node.DPWS;Node.js,Libraries;Java;Performance evaluation;Context awareness;Interoperability;Service-oriented architecture;Internet of things;Web services;Software development;Ubiquitous computing,Internet of Things;Web services,Node.DPWS;devices profile for Web services;DPWS libraries;Internet of Things,,8.0,,16.0,,11 Nov 2015,,,IEEE,IEEE Magazines
1076,1078,Clear Climate Code: Rewriting Legacy Science Software for Clarity,N. Barnes; D. Jones,Climate Code Foundation; Climate Code Foundation,IEEE Software,20 Oct 2011,2011,28,6,36,42,"The Clear Climate Code project rewrote GISTEMP, a legacy software system used to produce an important global surface temperature dataset. The focus of the project is on clarity: making the source code as clear as possible to interested people, to improve public understanding. The result is a Python package that's easy to understand, run, and change, which allows any interested person to pose and answer novel research questions. In the process, the project's founders also discovered and fixed some inconsequential bugs and hopefully improved online discussion of global warming.",1937-4194,,10.1109/MS.2011.113,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5999649,Earth and atmospheric sciences;physical sciences and engineering;computer applications;software psychology;software engineering;software;climate change;restructuring;reverse engineering;reengineering distribution;maintenance;enhancement;documentation;portability,Software development;Meteorology;Temperature measurement;Computer bugs;Ocean temperature;Legacy systems;Atmospheric measurements;Global warming,climatology;environmental science computing;meteorology;software maintenance,legacy science software rewriting;clear climate code project;GISTEMP;legacy software system;global surface temperature dataset;Python package;global warming,,3.0,,9.0,,25 Aug 2011,,,IEEE,IEEE Magazines
1077,1079,Requirements Engineering for Safety-Critical Systems: Overview and Challenges,L. E. G. Martins; T. Gorschek,Federal University of São Paulo; Blekinge Institute of Technology,IEEE Software,11 Jul 2017,2017,34,4,49,57,"In a world that depends increasingly on complex, critical, and intertwined systems, requirements engineering is crucial to developing and maintaining safety-critical systems (SCSs). Researchers studied the state of the art (through the literature) and the state of the practice (through in-depth interviews with practitioners) to discover what approaches are available for capturing, specifying, and communicating safety requirements throughout the SCS lifecycle and to determine the remaining challenges.",1937-4194,,10.1109/MS.2017.94,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974683,requirements engineering;safety-critical systems;embedded systems;systems engineering;software engineering;software development,Safety;Reliability engineering;Mission critical systems;Industries;Aerospace control,formal specification;safety-critical software,requirements engineering;safety-critical systems;SCS,,6.0,,17.0,,11 Jul 2017,,,IEEE,IEEE Magazines
1078,1080,From Software Development to Software Assembly,H. M. Sneed; C. Verhoef,Technische Universität Dresden; Vrije Universiteit Amsterdam,IEEE Software,24 Aug 2016,2016,33,5,80,85,"The lack of skilled programming personnel and the growing burden of maintaining customized software are forcing organizations to quit producing their own software. It's high time they turned to ready-made, standard components to fulfill their business requirements. Cloud services might be one way to achieve that goal.",1937-4194,,10.1109/MS.2015.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7106411,IT labor shortage;maintenance costs;legacy systems;software reuse;Web services;software engineering;software development,Software development;Maintenance engineering;Personnel;Employments;Standards,cloud computing;software development management,software development;software assembly;cloud services,,1.0,,21.0,,13 May 2015,,,IEEE,IEEE Magazines
1079,1081,Stigmergy-Based Construction of Internetware Artifacts,W. Zhang; H. Zhao; Y. Jiang; Z. Jin,Peking University; Peking University; Nanjing University of Aeronautics and Astronautics; Peking University,IEEE Software,4 Feb 2015,2015,32,1,58,66,"A proposed approach supports the continual construction and evolution of model-based Internetware artifacts by a collective of Internet-connected stakeholders. The key mechanism is incremental graph superimposition (IGS), a refinement of stigmergy, the process that produces collective intelligence in social insects. Employing IGS, a collective of individuals collaboratively and continually construct a collective-level graph by incrementally aggregating the individuals' working results. Each individual can work independently without direct interaction with others, facilitating mass collaboration among a large number of individuals. A conceptual model illustrates the effects of IGS. A Web environment supports IGS-based conceptual-model construction and ongoing case studies.",1937-4194,,10.1109/MS.2014.133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6914466,software artifacts;stigmergy;incremental graph superimposition;evolution;software engineering,Software;Internet;Educational institutions;Market research;Buildings;Context;Insects,graph theory;groupware;Internet,stigmergy-based construction;model-based Internetware artifacts;Internet-connected stakeholders;incremental graph superimposition;collective intelligence;social insects;collective-level graph;mass collaboration;Web environment;IGS-based conceptual-model construction,,4.0,,14.0,,1 Oct 2014,,,IEEE,IEEE Magazines
1080,1082,Debugging the Internet of Things: The Case of Wireless Sensor Networks,P. Eugster; V. Sundaram; X. Zhang,SensorHound; SensorHound; Purdue University,IEEE Software,4 Feb 2015,2015,32,1,38,49,"The Internet of Things (IoT) has the strong potential to support a human society interacting more symbiotically with its physical environment. Indeed, the emergence of tiny devices that sense environmental cues and trigger actuators after consulting logic and human preferences promises a more environmentally aware and less wasteful society. However, the IoT inherently challenges software development processes, particularly techniques for ensuring software reliability. Researchers have developed debugging tools for wireless sensor networks (WSNs), which can be viewed as the enablers of perception in the IoT. These tools gather run-time information on individual sensor node executions and node interactions and then compress that information.",1937-4194,,10.1109/MS.2014.132,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6914470,Internet of Things;wireless sensor networks;debugging;tracing;replay;software engineering,Internet of things;Debugging;Wireless sensor networks;Computers;Wireless communication;Peer-to-peer computing;Runtime,Internet of Things;program debugging;software reliability;wireless sensor networks,Internet of Things;wireless sensor networks;software development process;debugging tools;IoT;sensor node executions;node interactions;software reliability,,16.0,,11.0,,1 Oct 2014,,,IEEE,IEEE Magazines
1081,1083,"KLOVER: Automatic Test Generation for C and C++ Programs, Using Symbolic Execution",H. Yoshida; G. Li; T. Kamiya; I. Ghosh; S. Rajan; S. Tokumoto; K. Munakata; T. Uehara,Fujitsu Laboratories of America; Fujitsu Laboratories of America; Fujitsu Laboratories of America; Fujitsu Laboratories of America; Fujitsu Laboratories of America; Fujitsu Laboratories Limited; Fujitsu Laboratories Limited; Fujitsu Laboratories Limited,IEEE Software,22 Sep 2017,2017,34,5,30,37,"Fujitsu researchers have developed a methodology to automate testing of industrial-strength embedded software implemented in C or C++. The methodology's core is a program analysis technique called symbolic execution, which the researchers have customized to automate testing. The methodology generates unit-level tests, greatly reducing test generation time and cost while providing excellent test coverage.",1937-4194,,10.1109/MS.2017.3571576,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048666,automatic test generation;symbolic execution;embedded software;KLOVER;software engineering;software development,C++ languages;Embedded software;Payloads;Software testing;Automatic testing,C++ language;program diagnostics;program testing,KLOVER;automatic test generation;C programs;C++ programs;symbolic execution;software testing;program analysis technique,,3.0,,14.0,,22 Sep 2017,,,IEEE,IEEE Magazines
1082,1084,Automated System-Level Regression Test Prioritization in a Nutshell,P. Erik Strandberg; W. Afzal; T. J. Ostrand; E. J. Weyuker; D. Sundmark,Westermo Research and Development; Mälardalen University; Mälardalen University; Mälardalen University; Mälardalen University,IEEE Software,11 Jul 2017,2017,34,4,30,37,"Westermo Research and Development has developed SuiteBuilder, an automated tool to determine an effective ordering of regression test cases. The ordering is based on factors such as fault detection success, the interval since the last execution, and code modifications. SuiteBuilder has enabled Westermo to overcome numerous regression-testing problems, including lack of time to run a complete regression suite, failure to detect bugs in a timely manner, and repeatedly omitted tests. In the tool's first two years of use, reordered test suites finished in the available time, most fault-detecting test cases were located in the first third of suites, no important test case was omitted, and the necessity for manual work on the suites decreased greatly.",1937-4194,,10.1109/MS.2017.92,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974685,regression testing;software testing;testing strategies;test execution;testing tools;test levels;validation;SuiteBuilder;Westermo;software engineering;software development,Software testing;Software development;Databases;Reliability engineering;Computer bugs;Regression analysis,program testing,automated system-level regression test prioritization;SuiteBuilder;complete regression suite;fault-detecting test cases,,1.0,,9.0,,11 Jul 2017,,,IEEE,IEEE Magazines
1083,1085,Measuring Architecture Sustainability,H. Koziolek; D. Domis; T. Goldschmidt; P. Vorst,ABB Corporate Research Germany; ABB Corporate Research Germany; ABB Corporate Research Germany; ABB Corporate Research Germany,IEEE Software,28 Oct 2013,2013,30,6,54,62,"It's difficult to express a software architecture's sustainability in a single metric: relevant information is spread across requirements, architecture design documents, technology choices, source code, system context, and software architects' implicit knowledge. Many aspects influence economic sustainability, including design decisions facilitating evolutionary changes, adherence to good modularization practices, and technology choices. An approach that focuses on a single artifact or perspective is likely to neglect important factors. ABB Corporate Research is tracking the architecture sustainability of a large-scale industrial control system currently under development. A former version of the system grew to several million LOC and suffered from architecture erosion and high maintenance costs. A multiperspective approach called Morphosis will help avoid such a situation in the future by focusing on requirements, architecture design, and source code. It includes evolution scenario analysis, scoring of technology choices, architecture compliance checks, and tracking of architecture-level code metrics.",1937-4194,,10.1109/MS.2013.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6576748,software architecture;software engineering;maintenance measurement;product metrics;metrics;measurement;Morphosis;architecture sustainability,Computer architecture;Software architecture;Sustainable development;Software systems;Best practices,software architecture;software metrics;sustainable development,architecture sustainability measurment;software architecture sustainability;architecture design documents;source code;system context;economic sustainability;design decisions;ABB Corporate Research;large-scale industrial control system;architecture erosion;multiperspective approach;Morphosis;architecture compliance checks;architecture-level code metrics,,10.0,,13.0,,8 Aug 2013,,,IEEE,IEEE Magazines
1084,1086,Natural Language Requirements Processing: A 4D Vision,A. Ferrari; F. Dell’Orletta; A. Esuli; V. Gervasi; S. Gnesi,CNR-ISTI; CNR-ILC; CNR-ISTI; University of Pisa; CNR-ISTI,IEEE Software,13 Nov 2017,2017,34,6,28,35,"The future evolution of the application of natural language processing technologies in requirements engineering can be viewed from four dimensions: discipline, dynamism, domain knowledge, and datasets.",1937-4194,,10.1109/MS.2017.4121207,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106888,natural language processing;NLP;requirements engineering;RE;requirements specification;software engineering;software development,Natural language processing;Software development;Terminology;Requirements engineering,data analysis;formal specification;formal verification;natural language processing,datasets;domain knowledge;dynamism;discipline;natural language processing technologies;requirements engineering;4D vision;natural language requirements processing,,5.0,,21.0,,13 Nov 2017,,,IEEE,IEEE Magazines
1085,1087,Developing Cloud Business Models: A Case Study on Cloud Gaming,A. Ojala; P. Tyrvainen,University of Jyväskylä; University of Jyväskylä,IEEE Software,23 Jun 2011,2011,28,4,42,47,"Cloud computing offers new ways for firms to operate in the global market so that even small firms can compete in markets traditionally dominated by multinational corporations. A case study considers how, over ten years, a small firm developed a successful business model to compete in computer gaming.",1937-4194,,10.1109/MS.2011.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5741005,cloud computing;business models;cloud gaming;value chain;platform;SaaS;software engineering,Cloud computing;Strategic planning;Business;Modeling;Competitive intelligence;Marketing and sales;Globalization,business data processing;cloud computing;computer games;small-to-medium enterprises,cloud business model;cloud gaming;cloud computing;small firm,,43.0,,12.0,,5 Apr 2011,,,IEEE,IEEE Magazines
1086,1088,People over Process: Key Challenges in Agile Development,K. Conboy; S. Coyle; X. Wang; M. Pikkarainen,"National University of Ireland, Galway; National University of Ireland, Galway; Lero; VTT Technical Research Centre of Finland",IEEE Software,23 Jun 2011,2011,28,4,48,57,"Case studies of 17 organizations that have used agile methods for more than three years uncovered many serious ""people"" challenges including recruitment, training, motivation, and performance evaluation.",1937-4194,,10.1109/MS.2010.132,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5560625,agile;agile software development;adoption;methodologies;people factors;developers;software development;software engineering,Agile manufacturing;Business;Object oriented modeling;Strategic planning;Business;Management,organisational aspects;recruitment;training,agile development;recruitment;training;motivation;performance evaluation;organisations,,80.0,,7.0,,2 Sep 2010,,,IEEE,IEEE Magazines
1087,1089,Scale and Responsiveness in Large-Scale Software Development,H. Olsson; A. Sandberg; J. Bosch; H. Alahyari,"Malmö University; Ericsson AB , Gothenburg; Chalmers University of Technology, Gothenburg; Chalmers University of Technology, Gothenburg",IEEE Software,15 Sep 2014,2014,31,5,87,93,"In large-scale software development, there is typically a conflict between being responsive to individual customers, while at the same time achieving scale in terms of delivering a high number of features to a large customer base. Most often, organizations focus on scale and individual customer requests are viewed as problematic since they add complexity to product variation and version control. Here, we explore the use of customer-specific teams as a means to address this conflict. First, we verify the use of customer-specific teams as successful for improving customer responsiveness, customer satisfaction and feature quality through a case study at Ericsson. Second, we identify three approaches for how to organize feature development, and recommendations on how software development companies can efficiently use these to improve their practices. Third, we observe new business opportunities that arise when using customer-specific teams.",1937-4194,,10.1109/MS.2013.139,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6656805,large-scale software development;customer-specific teams;customer responsiveness;software engineering,Software development;Companies;Feedback loop;Interviews;Customer satisfaction,customer satisfaction;software development management,large-scale software development;scale customer requests;individual customer requests;product variation;version control;customer-specific teams;customer responsiveness;customer satisfaction;feature quality;business opportunities,,8.0,,15.0,,6 Nov 2013,,,IEEE,IEEE Magazines
1088,1090,Visual Tools for Software Architecture Understanding: A Stakeholder Perspective,A. Telea; L. Voinea; H. Sassenburg,"University of Groningen, Groningen; SolidSource BV, Eindhoven; SE-CURE, Lenk",IEEE Software,14 Oct 2010,2010,27,6,46,53,"This paper is talking about visual tools for understanding software architecture.Software visualisation tool operates as a pipeline.They mine data from various sources and then analyse the data using various techniques like static analyzers, text miners, repository access clients, and database clients. A refined-fact database stores the analysis results, using an entity-relationship.",1937-4194,,10.1109/MS.2010.115,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5518754,software engineering;software tools;visualization,Software architecture,data analysis;data mining;software architecture;software tools,software architecture;software visualisation tool;data mining;refined fact database;entity relationship;data analysis,,9.0,,12.0,,23 Jul 2010,,,IEEE,IEEE Magazines
1089,1091,Handshaking with Implementation Proposals: Negotiating Requirements Understanding,S. Fricker; T. Gorschek; C. Byman; A. Schmidle,University of Zurich and Fuchs-Informatik AG; Blekinge Institute of Technology; ABB; ABB Switzerland,IEEE Software,25 Feb 2010,2010,27,2,72,80,A bidirectional process for agreeing on product requirements proves effective in overcoming misunderstandings that arise in the traditional handoff of requirements specifications to development teams.,1937-4194,,10.1109/MS.2010.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420800,software engineering;requirements specification;software design;software methodologies,Proposals,formal specification;systems analysis,handshaking;implementation proposals;requirements understanding;bidirectional process;product requirements;requirements specifications,,43.0,,12.0,,25 Feb 2010,,,IEEE,IEEE Magazines
1090,1092,Model-Based Development and Formal Methods in the Railway Industry,A. Ferrari; A. Fantechi; S. Gnesi; G. Magnani,"CNR-ISTI; Università di Firenze; CNR-ISTI; General Electric Transportation Systems, Florence",IEEE Software,18 Apr 2013,2013,30,3,28,34,"The transition from a code-based process to a model-based process isn't easy. This is particularly true for a company that operates in a safety-critical sector, where the products must be developed according to international standards, with certified tools and controlled processes. The authors summarize the experience of a railway signaling manufacturer that decided to adopt general-purpose, model-based tools—namely, Simulink/Stateflow and SysML—for product development. The company faced challenges primarily concerning the verification of the software and the integration of the tools within the existing process. Structured development solutions and formal/semiformal approaches were adopted to tackle the challenges.",1937-4194,,10.1109/MS.2013.44,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6475930,software engineering process;formal methods;software and system safety;programming paradigms,Modeling;Software packages;Encoding;Rail transportation;Standards;System analysis and design;Safety,,,,18.0,,10.0,,7 Mar 2013,,,IEEE,IEEE Magazines
1091,1093,Scripting Multiple CPUs with Safe Data Sharing,A. Skyrme; N. Rodriguez; R. Ierusalimschy,"Pontifical Catholic University of Rio de Janeiro, RJ; Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro; Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro",IEEE Software,15 Sep 2014,2014,31,5,44,51,"Scripting languages are very popular and are being used to implement a wide range of applications. Meanwhile, multi-core processors are everywhere, from dektop computers to mobile devices, and concurrency has become the only means to improve performance. However, concurrent programming remains difficult and despite some interest in researching new concurrency models for compiled languages, the conventional concurrency support in scripting languages is still lacking. In this paper we are interested in \emph{safe data sharing for scripting languages}. We explore the landscape of conventional concurrency support in popular scripting languages and discuss some of its limitations. Then, we identify some emerging concurrency patterns in scripting languages, namely: no-default sharing, data ownership, futures and data immutability. Finally, we analyze some limitations in existing mechanisms and discuss how the patterns we identified can be used to provide safe data sharing in scripting languages.",1937-4194,,10.1109/MS.2014.102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898741,software;software engineering;concurrent programming;scripting;languages programming languages;data sharing,Concurrent computing;Message systems;Multithreading;Synchronization;Programming;Software development;Information sharing,authoring languages;multiprocessing systems,scripting languages;multi-core processors;data sharing;dekstop computers;mobile devices;concurrent programming;concurrency models;no-default sharing pattern;data ownership pattern;futures pattern;data immutability pattern,,,,14.0,,15 Sep 2014,,,IEEE,IEEE Magazines
1092,1094,People as a Service: A Mobile-centric Model for Providing Collective Sociological Profiles,J. Guillén; J. Miranda; J. Berrocal; J. García-Alonso; J. M. Murillo; C. Canal,Gloin; Gloin; University of Extremadura; University of Extremadura; University of Extremadura; University of Málaga,IEEE Software,17 Mar 2014,2014,31,2,48,53,"Researchers from sociological disciplines could greatly benefit from collective information from the many people who use mobile devices to communicate via various social apps and services. However, processing that information is difficult because it's scattered among numerous social platforms. Furthermore, users are becoming increasingly concerned about how and by whom their information is being accessed. A new mobile-centric computing model allows sociological profiles of people to be generated, kept, and securely provided to third parties as a service. With this model, device owners can be fully aware and in control of how their information is accessed, while still contributing to collective sociological information.",1937-4194,,10.1109/MS.2013.140,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6662347,mobile applications;data sharing;nomadic computing;pervasive computing;human-centered computing;distributed systems;human information processing;privacy;people as a service;PeaaS;software engineering;mobile computing,Mobile handsets;Computational modeling;Computer architecture;Next generation networking;Mobile communication;Mobile computing;Sociology,mobile computing;social networking (online);social sciences computing,people as a service;collective sociological profiles;sociological disciplines;mobile devices;social apps;social platforms;mobile-centric computing model;collective sociological information,,48.0,,6.0,,12 Nov 2013,,,IEEE,IEEE Magazines
1093,1095,"Reverse Engineering on the Mainframe: Lessons Learned from ""In Vivo"" Research",J. Van Geet; S. Demeyer,"University of Antwerp, Antwerp; University of Antwerp University of Antwerp, Antwerp Antwerpen",IEEE Software,14 Jun 2010,2010,27,4,30,36,"Despite growth in the popularity of desktop systems, Web applications, and mobile computing, mainframe systems remain the dominant force in large-scale enterprise computing. Although they're sometimes referred to as ""the dinosaurs of computing,"" even mainframe systems must adapt to changing circumstances to survive. Although reverse-engineering and reengineering techniques can help identify and achieve these adaptations, current techniques are mainly geared mainly toward more modern environments, languages, and platforms. It remains to be seen whether successful techniques can be easily transferred to a mainframe context. This article reports on the application of two proven reverse-engineering techniques (software visualization and feature location) in the context of mainframe systems. The authors conclude that these techniques remain viable but become very labor intensive when implemented on a per-project basis.",1937-4194,,10.1109/MS.2010.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5440167,feature location;software visualization;industrial experience;software engineering;software,Reverse engineering;In vivo;Mobile computing;Computer applications;Large-scale systems;Dinosaurs;Application software;Visualization,business data processing;program visualisation;reverse engineering,reverse engineering;mainframe systems;large-scale enterprise computing;software visualization;feature location,,8.0,,13.0,,29 Mar 2010,,,IEEE,IEEE Magazines
1094,1096,Requirements Engineering Tools,J. M. Carrillo de Gea; J. Nicolás; J. L. F. Alemán; A. Toval; C. Ebert; A. Vizcaíno,"Software Eng. Res. Group, Univ. of Murcia, Murcia, Spain; Software Eng. Res. Group, Univ. of Murcia, Murcia, Spain; Software Eng. Res. Group, Univ. of Murcia, Murcia, Spain; Software Eng. Res. Group, Univ. of Murcia, Murcia, Spain; NA; Alarcos Res. Group, Univ. of Castilla-La Mancha, Ciudad Real, Spain",IEEE Software,23 Jun 2011,2011,28,4,86,91,"Requirements engineering (RE) tools are increasingly used to ease the RE processes and allow for more systematic and formalized handling of requirements, change management and traceability. For developers and companies evaluating the use of RE tools it is thus essential to know which RE processes are supported by tools and how they fit to their own priorities. The answer isn't easy because many sales prospects highlight numerous features-yet leave out to which degree they're supported and whether all features really matter. To gain insight into how current RE tools adapt to RE activities, we ran a 146-item survey based on the features covered by the ISO/IEC TR 24766:2009, a new framework for assessing RE tool capabilities. We received responses from 37 participants, covering all relevant tools. In addition to the tools' score in each activity, we assessed their performance in three concrete use scenarios. Our findings can help practitioners select an RE tool as well as provide areas for improvement for RE tools developers.",1937-4194,,10.1109/MS.2011.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929527,requirements engineering tools;survey;ISO/IEC TR 24766:2009;software;software engineering,Design methodology;Software development management;Change detection algorithms;Business process re-engineering;System analysis and design,formal specification;formal verification;software tools;systems analysis,requirements engineering tools;RE processes;requirements handling;change management;change traceability;ISO-IEC TR 24766:2009 standard,,36.0,,2.0,,23 Jun 2011,,,IEEE,IEEE Magazines
1095,1097,Self-Adaptation Using Multiagent Systems,D. Weyns; M. Georgeff,Katholieke Universiteit Leuven; Monash University,IEEE Software,31 Dec 2009,2010,27,1,86,91,"Each decade has its key software technology to advance artificial intelligence, and each technology is highlighted in a novel that sells much better than the underlying technology. Who hasn't read Michael Crichton's Prey and wondered how far multiagent systems might evolve and how they might affect humankind? Our technology column digs into this topic in this issue. Danny Weyns and Michael Georgeff provide a short introduction and show how multiagent systems help master the complexity of self-adaptive systems. They contrast multiagent systems with other current technologies and provide links and hints for practitioners who want to get started with this emerging field.",1937-4194,,10.1109/MS.2010.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370765,software engineering;multiagent systems,Multiagent systems;Artificial intelligence,multi-agent systems;self-adjusting systems;systems analysis,systems self-adaptation;multiagent system;artificial intelligence,,12.0,,,,31 Dec 2009,,,IEEE,IEEE Magazines
1096,1098,Sharing Source Code with Clients: A Hybrid Business and Development Model,M. Riepula,Aalto University,IEEE Software,23 Jun 2011,2011,28,4,36,41,"Open innovation and the recent emphasis on client involvement imply the emergence of hybrid software licensing models combining the limited openness of source code with traditional value appropriation logic. A practical hybrid licensing model responds to the needs of both business-to-business software vendors in vertical domains and consultancies that must maintain separate quasi-products. The central idea is that the vendor of commoditized products also licenses source code to select clients, who become participants in and subscribers to an ongoing closed development community. The tools and techniques are readily available from open source development, but the motivations and relationship management work differently than in a pure open source context.",1937-4194,,10.1109/MS.2011.53,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5750002,client-shared source;shared source;gated source;open source;hybrid OSS;OSS 2.0;software licensing;client innovation;client coproduction;distributed development;inner source;corporate source;software business model;software commoditization;software commodification;software development;software engineering,Open source software;Licenses;Technological innovation;Business;Modeling;Marketing and sales;Strategic planning;Technological innovation,business data processing;consultancies;innovation management;public domain software;software development management,source code sharing;business-and-development model;open innovation;value appropriation logic;hybrid licensing model;business-to-business software vendors;commoditized products;open source development;consultancies,,3.0,,14.0,,15 Apr 2011,,,IEEE,IEEE Magazines
1097,1099,Object-Oriented Analysis: Is It Just Theory?,R. Gelbard; D. Te'eni; M. Sade,"Bar-Ilan University , Ramat-Gan; Tel-Aviv Univ., Tel-Aviv, Israel; Tel-Aviv University, Tel-Aviv",IEEE Software,31 Dec 2009,2010,27,1,64,71,"Research and commercial surveys suggest that the object-oriented (OO) approach strongly supports the technical design and coding phases of software development but poorly supports the functional analysis phase. In other words, ""the design is good, the analysis is poor."" The source of this weakness is often attributed to the fact that ""UML representations have not been effective in large-scale projects for context and communication.""",1937-4194,,10.1109/MS.2009.151,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232797,object oriented analysis;uml;cost-benefit;software;software engineering,Programming;Functional analysis;Unified modeling language;Large-scale systems;Context,object-oriented methods;Unified Modeling Language,object-oriented analysis;software development technical design;software development coding phase;functional analysis phase;UML representation,,7.0,,19.0,,4 Sep 2009,,,IEEE,IEEE Magazines
1098,1100,Enabling IoT Ecosystems through Platform Interoperability,A. Bröring; S. Schmid; C. -K. Schindhelm; A. Khelil; S. Käbisch; D. Kramer; D. Le Phuoc; J. Mitic; D. Anicic; E. Teniente,Siemens; Bosch Corporate Research; Siemens; Landshut University of Applied Sciences; Siemens; Bosch Software Innovations; Technical University of Berlin; Siemens; Siemens; Universitat Politècnica de Catalunya,IEEE Software,16 Jan 2017,2017,34,1,54,61,"Today, the Internet of Things (IoT) comprises vertically oriented platforms for things. Developers who want to use them need to negotiate access individually and adapt to the platform-specific API and information models. Having to perform these actions for each platform often outweighs the possible gains from adapting applications to multiple platforms. This fragmentation of the IoT and the missing interoperability result in high entry barriers for developers and prevent the emergence of broadly accepted IoT ecosystems. The BIG IoT (Bridging the Interoperability Gap of the IoT) project aims to ignite an IoT ecosystem as part of the European Platforms Initiative. As part of the project, researchers have devised an IoT ecosystem architecture. It employs five interoperability patterns that enable cross-platform interoperability and can help establish successful IoT ecosystems.",1937-4194,,10.1109/MS.2017.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819420,interoperability;software architecture;software patterns;semantics;Internet of Things;IoT;BIG IoT;Bridging the Interoperability Gap of the IoT;software engineering;software development;IoT ecosystems,Internet of things;Software development;Ecosystems;Interoperability,application program interfaces;Internet of Things;open systems,Internet of Things;vertically oriented platforms;platform-specific API;information models;BIG IoT;IoT ecosystems;bridging the interoperability gap of the IoT,,135.0,,9.0,,16 Jan 2017,,,IEEE,IEEE Magazines
1099,1101,Making Architecture Visible to Improve Flow Management in Lean Software Development,R. L. Nord; I. Ozkaya; R. S. Sangwan,Carnegie Mellon University; Carnegie Mellon University; Pennsylvania State University,IEEE Software,21 Aug 2012,2012,29,5,33,39,"Lean practices use the principle of Little's law to improve the flow of value to the end user by eliminating sources of waste from a software development process. Little's law defines throughput as a ratio of work in process and cycle time. Increasing throughput (or productivity) requires continuously improving (that is, decreasing) cycle time while ensuring that the work-in-process limit doesn't exceed the capacity available to process the work. This article shares experiences regarding the role architecture plays in lean software management practices. Release plans that give as much emphasis to architecturally significant tasks as to feature-based high-priority functionality can achieve better outcomes by avoiding conditions that lead to wasted time and effort. The application of lean software development practices can improve with better practical guidance on how to manage architecture flow as well as feature flow.",1937-4194,,10.1109/MS.2012.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6226344,software engineering management;lean software management;flow management;release planning;software architecture;waste,Computer architecture;Product life cycle management;Programming;Productivity;Agile manufacturing;Software management;Software architecture,software architecture;software development management;workflow management software,flow management;software development;software architecture;work in process;cycle time;lean software management;release plan;feature-based high priority functionality,,16.0,,12.0,,26 Jun 2012,,,IEEE,IEEE Magazines
1100,1102,Understanding How Companies Interact with Free Software Communities,J. M. Gonzalez-Barahona; D. Izquierdo-Cortazar; S. Maffulli; G. Robles,Universidad Rey Juan Carlos; Bitergia; OpenStack; Universidad Rey Juan Carlos,IEEE Software,3 Sep 2013,2013,30,5,38,45,"When free, open source software development communities work with companies that use their output, it's especially important for both parties to understand how this collaboration is performing. The use of data analytics techniques on software development repositories can improve factual knowledge about performance metrics.",1937-4194,,10.1109/MS.2013.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6560081,Software analytics;Software measurement;Electronic mail;Open source software;Statistics;computing milieu;software analytics;process metrics;measurement;software engineering;statistics,Software analytics;Software measurement;Electronic mail;Open source software;Statistics,data analysis;public domain software;software metrics,free software communities;open source software development communities;data analytics techniques;software development repositories;software performance metrics,,22.0,,9.0,,16 Jul 2013,,,IEEE,IEEE Magazines
1101,1103,Agile Practices: The Impact on Trust in Software Project Teams,O. McHugh; K. Conboy; M. Lang,"National University of Ireland Galway; Australian School of Business, Sydney; National University of Ireland Galway",IEEE Software,20 Apr 2012,2012,29,3,71,76,Agile software development involves self-managing teams that are empowered and responsible for meeting project goals in whatever way they deem suitable. Managers must place more trust in such teams than they do in teams following more traditional development methodologies. The authors highlight how the use of agile practices can enhance trust amongst agile team members. They also present challenges that agile teams can face as a result of using agile practices. Their results are based on the findings from three case studies of agile software development teams.,1937-4194,,10.1109/MS.2011.118,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6007124,agile methodology;agile practice;daily stand-up;planning;retrospective;trust;culture;distributed software engineering,Planning;Software;Programming;Interviews;Business;Delay;Cultural differences,project management;software management;software prototyping;team working,agile software development;self-managing team;agile team member;software project team;agile practice;trust impact,,44.0,,13.0,,1 Sep 2011,,,IEEE,IEEE Magazines
1102,1104,SASSY: A Framework for Self-Architecting Service-Oriented Systems,D. Menasce; H. Gomaa; s. Malek; J. Sousa,George Mason University; George Mason University; George Mason University; George Mason University,IEEE Software,20 Oct 2011,2011,28,6,78,85,"Making architectural decisions manually in the presence of quality-of-service trade-offs can be complicated. The SASSY (Self-architecting Software Systems) framework automatically generates candidate software architectures and selects the one that best serves stakeholder-defined, scenario-based quality-of-service (QoS) goals. This lets domain experts concentrate on functional and QoS requirements. SASSY reduces the effort of composing service-oriented systems by automatically generating the QoS-optimized architecture and rapidly reconfiguring it at runtime. Self-architecting occurs during initial system deployment and at runtime, thus making systems self-adaptive, self-healing, self-managing, and self-optimizing.",1937-4194,,10.1109/MS.2011.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5696721,software architectures;QoS;quality of service;service-oriented systems;software engineering,Computer architecture;Quality of service;Service oriented architecture;Software systems;Adaptation model,quality of service;service-oriented architecture,SASSY;self-architecting software systems;self-architecting service-oriented systems;architectural decisions;quality-of-service trade-offs,,70.0,,13.0,,20 Jan 2011,,,IEEE,IEEE Magazines
1103,1105,Refactoring for Asynchronous Execution on Mobile Devices,D. Dig,Oregon State University,IEEE Software,28 Oct 2015,2015,32,6,52,61,"To improve responsiveness, developers often use asynchronous programming. In the post-PC era, asynchronous programming is even more in demand because mobile and wearable devices have limited resources and access the network excessively. One current development task is refactoring long-running, blocking synchronous code (for example, accessing the Web, a cloud, a database, or a file system) into nonblocking asynchronous code. This article describes the refactorings that improve responsiveness, along with the obstacles of using asynchrony. It also discusses the challenges of retrofitting asynchrony and presents program analyses and transformations and a growing, practical toolset and resources for retrofitting asynchrony. This article is part of a special issue on Refactoring.",1937-4194,,10.1109/MS.2015.133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310985,refactoring;asynchronous programming;program analysis and transformation;Asynchronizer;AsyncFixer;AsyncDroid;Asyncifier;software engineering;software development,Reactive power;Graphical user interfaces;Mobile communication;Programming profession;Androids;Humanoid robots;Code refractoring,mobile computing;wearable computers,asynchronous execution refactoring;mobile devices;asynchronous programming;post-PC era;wearable devices;synchronous code blocking;Web access;nonblocking asynchronous code;retrofitting asynchrony;program analyses,,6.0,1.0,14.0,,28 Oct 2015,,,IEEE,IEEE Magazines
1104,1106,Improving Digital Game Development with Software Product Lines,A. W. B. Furtado; A. L. M. Santos; G. L. Ramalho; E. S. de Almeida,Federal University of Pernambuco; Federal University of Pernambuco; Federal University of Pernambuco; Federal University of Bahia,IEEE Software,18 Aug 2011,2011,28,5,30,37,"Introducing reuse and software product line (SPL) concepts into digital game-development processes isn't a straightforward task. This work presents a systematic process for bridging SPLs to game development, culminating with domain-specific languages and generators streamlined for game subdomains. The authors present a game SPL for arcade games as a case study to illustrate and evaluate their proposed guidelines. This article is part of a special issue on games.",1937-4194,,10.1109/MS.2011.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984795,digital games development;domain-specific languages;software product lines;software;software engineering,Software development;Product development;Software design;Computer architecture;Unified modeling language;Feature extraction;Games,computer games;software development management;software reusability;specification languages,digital game development;software product lines;software reusability;domain-specific languages;arcade games,,12.0,,13.0,,18 Aug 2011,,,IEEE,IEEE Magazines
1105,1107,The Architect's Role in Community Shepherding,D. A. Tamburri; R. Kazman; H. Fahimi,Politecnico di Milano; University of Hawaii; CGI,IEEE Software,28 Oct 2016,2016,33,6,70,79,"Software architects don't just design architecture components or champion architecture qualities; they often must guide and harmonize the entire community of project stakeholders. The community-shepherding aspects of the architect's role have been gaining attention, given the increasing importance of complex ""organizational rewiring"" scenarios such as DevOps, open source strategies, transitions to agile development, and corporate acquisitions. In these scenarios, architects would benefit by having effective models to align communities with architectures. This article discusses the ""smells"" indicating that a community isn't functioning efficiently, offers a set of mitigations for those smells, and provides an overview of community types.",1937-4194,,10.1109/MS.2016.144,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725222,software architecture shepherds;software organizational structure;software communities;software community smells;software social debt;social debt management;architectural social debt;software engineering;software development,Computer architecture;Software architecture;Cultural differences;Professional aspects,organisational aspects;software architecture;software quality,community shepherding;software architects;architecture component design;architecture qualities;project stakeholders;organizational rewiring,,23.0,,16.0,,28 Oct 2016,,,IEEE,IEEE Magazines
1106,1108,The rise and fall of the Chaos report figures,J. Eveleens; C. Verhoef,"VU University, Amsterdam; VU University, Amsterdam",IEEE Software,31 Dec 2009,2010,27,1,30,36,"This paper presents the chaos report figures that are often used to indicate problems in application software development project management, the reports contain major flaws.",1937-4194,,10.1109/MS.2009.154,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5232804,chaos report;standish group;forecasting;project success;software;software engineering,Chaos;Application software;Project management,chaos;project management;software management,chaos report figures;application software development management;project management,,117.0,,16.0,,4 Sep 2009,,,IEEE,IEEE Magazines
1107,1109,Is It Worth Responding to Reviews? Studying the Top Free Apps in Google Play,S. McIlroy; W. Shang; N. Ali; A. E. Hassan,"Queen's University, Canada; Concordia University, Montreal; Queen's University, Canada; Queen's University, Canada",IEEE Software,15 May 2017,2017,34,3,64,71,"Up to this point, researchers have not explored the value of responding to user reviews of mobile apps. An analysis of reviews and responses for 10,713 of the top apps in Google Play showed that few developers responded to reviews. However, responding can have positive effects. Users changed their ratings 38.7 percent of the time following a response, with a median rating increase of 20 percent.",1937-4194,,10.1109/MS.2015.149,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7325189,mobile apps;Google Play;software development;software engineering;user reviews,Google;Mobile communication;Crawlers;Data mining;Social network services;Computer crashes,information analysis;mobile computing;public domain software,free apps;Google Play;mobile apps;mobile app developer response;mobile app reviews,,10.0,,21.0,,11 Nov 2015,,,IEEE,IEEE Magazines
1108,1110,Mutation Testing Cost Reduction Techniques: A Survey,M. P. Usaola; P. R. Mateo,University of Castilla-La Mancha; University of Castilla-La Mancha,IEEE Software,19 Apr 2010,2010,27,3,80,86,"From the research perspective, mutation is a mature testing technique that has often shown its value for evaluating both software and software testing techniques. However, to the best of our knowledge, there's an important gap between its current research status and the possibilities of adopting it for the industrial world, owing to its high costs.",1937-4194,,10.1109/MS.2010.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452149,testing and debugging;testing strategies;testing tools;software engineering,Genetic mutations;Costs;Software testing,cost reduction;program testing,mutation testing cost reduction techniques;mature testing technique;testing techniques,,44.0,,30.0,,19 Apr 2010,,,IEEE,IEEE Magazines
1109,1111,Environmental Modeling for Automated Cloud Application Testing,L. Zhang; X. Ma; J. Lu; T. Xie; N. Tillmann; P. de Halleux,Nanjing University; Nanjing University; Nanjing University; North Carolina State University; Microsoft Research; Microsoft Research,IEEE Software,20 Feb 2012,2012,29,2,30,35,"Platforms such as Windows Azure let applications conduct data-intensive cloud computing. Unit testing can help ensure high-quality development of such applications, but the results depend on test inputs and the cloud environment's state. Manually providing various test inputs and cloud states is laborious and time-consuming. However, automated test generation must simulate various cloud states to achieve effective testing. To address this challenge, a proposed approach models the cloud environment and applies dynamic symbolic execution to generate test inputs and cloud states. Applying this approach to open-source Azure cloud applications shows that it can achieve high structural coverage.",1937-4194,,10.1109/MS.2011.158,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095493,cloud computing;software testing;dynamic symbolic execution;cloud environment model;software engineering,Testing;Cloud computing;Open source software;Computational modeling;Computer applications,cloud computing;program testing,environmental modeling;automated cloud application testing;data-intensive cloud computing;automated test generation;dynamic symbolic execution;open-source Azure cloud application,,17.0,1.0,1.0,,6 Dec 2011,,,IEEE,IEEE Magazines
1110,1112,Examining the Relationship between FindBugs Warnings and App Ratings,H. Khalid; M. Nagappan; A. E. Hassan,Shopify; Rochester Institute of Technology; Queen's University,IEEE Software,23 Jun 2016,2016,33,4,34,39,"In the mobile-app ecosystem, user ratings of apps (a measure of user perception) are extremely important because they correlate strongly with downloads and hence revenue. A case study examined the relationship between ratings (and the associated review comments) and static-analysis warnings (collected using FindBugs) for 10,000 free-to-download Android apps. Three warning categories - bad practice, internationalization, and performance - were more frequent in low-rated apps and corresponded to the review comment complaints. Thus, these categories were closely related to the user experience. These results suggest that app developers could use static-analysis tools to identify the bugs behind the issues that users complain about, before releasing an app.",1937-4194,,10.1109/MS.2015.29,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7006337,mobile apps;static analysis;user ratings;software quality assurance;FindBugs;Android;software engineering;software development,Ecosystems;Androids;Humanoid robots;Computer bugs;Software development;Mobile communication;Computer applications,mobile computing;program diagnostics,FindBugs warnings;app ratings;mobile-app ecosystem;static-analysis warnings;free-to-download Android apps;warning categories;low-rated apps;user experience;static-analysis tools,,20.0,,10.0,,12 Jan 2015,,,IEEE,IEEE Magazines
1111,1113,Decision-Centric Architecture Reviews,U. van Heesch; V. Eloranta; P. Avgeriou; K. Koskimies; N. Harrison,University of Groningen; Tampere University of Technology; University of Groningen; Tampere University of Technology; Utah Valley University,IEEE Software,28 Feb 2014,2014,31,1,69,76,"Architecture evaluation is an important activity in the software engineering life cycle that ensures that the architecture satisfies stakeholders' expectations. Additionally, risks and issues can be uncovered before they cause tremendous costs later in the life cycle. Unfortunately, architecture evaluation isn't regularly practiced in industry. This article presents DCAR (decision-centric architecture review), an architecture evaluation method that uses architecture decisions as first-class entities. DCAR uncovers and evaluates the rationale behind the most important architecture decisions, considering the entire context in which the decisions were made. Furthermore, it's lightweight and can be performed during or after the design is finalized. Experiences in large industrial projects have shown that full-scale DCAR evaluations, including reporting, can be conducted in fewer than five person-days, while producing satisfying results for the stakeholders.",1937-4194,,10.1109/MS.2013.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6449237,software architecture;software quality;knowledge representation,Computer architecture;Software architecture;Context awareness;Documentation;Databases;Product life cycle management,software architecture,decision-centric architecture reviews;software engineering life cycle;architecture evaluation method;architecture decisions;industrial projects;full-scale DCAR evaluations,,23.0,,9.0,,4 Feb 2013,,,IEEE,IEEE Magazines
1112,1114,A Large-Scale Empirical Study on Software Reuse in Mobile Apps,I. J. Mojica; B. Adams; M. Nagappan; S. Dienst; T. Berger; A. E. Hassan,McAfee; École Polytechnique de Montréal; Queen's University; University of Leipzig; University of Waterloo; Queen's University,IEEE Software,17 Mar 2014,2014,31,2,78,86,"In less than five years, the number of mobile apps has grown exponentially, with more than 1 million available in the largest mobile app stores. One explanation for this growth could be the adoption of well-proven software engineering practices--in particular, software reuse despite the often conjectured lack of training among mobile app developers. A study of hundreds of thousands of Android apps across 30 different categories found substantial software reuse, indicating that while these apps benefit from increased productivity, they're also more dependent on the quality of the apps and libraries that they reuse.",1937-4194,,10.1109/MS.2013.142,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6663589,software reuse;mobile apps;Android,Mobile communication;Smart phones;Software reusability;Large-scale systems;Androids;Humanoid robots;Next generation networking;Mobile computing;Computer applications,Android (operating system);mobile computing;software libraries;software quality;software reusability,software reuse;mobile app stores;software engineering practices;mobile app developers;Android apps;app quality;library quality,,54.0,,17.0,,13 Nov 2013,,,IEEE,IEEE Magazines
1113,1115,Assisted Assignment of Automotive Safety Requirements,L. d. S. Azevedo; D. Parker; M. Walker; Y. Papadopoulos; R. E. Araújo,University of Hull; University of Hull; University of Hull; University of Hull; University of Porto,IEEE Software,28 Feb 2014,2014,31,1,62,68,"ISO 26262, a functional-safety standard, uses Automotive Safety Integrity Levels (ASILs) to assign safety requirements to automotive-system elements. System designers initially assign ASILs to system-level hazards and then allocate them to elements of the refined system architecture. Through ASIL decomposition, designers can divide a function's safety requirements among multiple components. However, in practice, manual ASIL decomposition is difficult and produces varying results. To overcome this problem, a new tool automates ASIL allocation and decomposition. It supports the system and software engineering life cycle by enabling users to efficiently allocate safety requirements regarding systematic failures in the design of critical embedded computer systems. The tool is applicable to industries with a similar concept of safety integrity levels.",1937-4194,,10.1109/MS.2013.118,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6594996,functional safety;ISO 26262;ASIL decomposition;ASIL automation;ASIL;Automotive Safety Integrity Levels;HiP-HOPS,Hazards;Resource management;ISO standards;Automotive engineering;Batteries;Software quality,automobiles;embedded systems;ISO standards;road safety;safety systems;safety-critical software;traffic engineering computing,automotive safety requirements;ISO 26262;functional-safety standard;automotive safety integrity levels;assisted assignment;automotive-system elements;system-level hazards;system architecture;manual ASIL decomposition;software engineering life cycle;critical embedded computer system design;safety integrity levels;systematic failures,,26.0,,11.0,,10 Sep 2013,,,IEEE,IEEE Magazines
1114,1116,Experiences in Improving Flight Software Development Processes,R. K. Kandt,Jet Propulsion Laboratory,IEEE Software,17 Apr 2009,2009,26,3,58,64,"In 2001, the Jet Propulsion Laboratory (JPL) initiated a software process improvement effort. In 2004, JPL began the Multimission System Architecture Platform (MSAP) project and designated it as part of this effort. In 2007, JPL's Engineering and Science Directorate, which controls the MSAP project's technical development, achieved CMMI Staged Maturity Level 3.1 This article describes the impacts of the CMMI rating and the JPL process improvement effort on the MSAP project's software engineering and assurance organizations.",1937-4194,,10.1109/MS.2009.66,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814959,software process improvement;software quality assurance,Programming;Software testing;System testing;Embedded software;Aerospace engineering;Systems engineering and theory;Design engineering;Hardware;Failure analysis;Documentation,aerospace computing;software process improvement,flight software development processes;Jet Propulsion Laboratory;software process improvement;software engineering,,7.0,,8.0,,17 Apr 2009,,,IEEE,IEEE Magazines
1115,1117,Sharing Satellite Observations with the Climate-Modeling Community: Software and Architecture,D. J. Crichton; C. A. Mattmann; L. Cinquini; A. Braverman; D. Waliser; M. Gunson; A. F. Hart; C. E. Goodale; P. Lean; J. Kim,"NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory; NASA Jet Propulsion Laboratory; University of Reading; University of California, Los Angeles",IEEE Software,21 Aug 2012,2012,29,5,73,81,"The disparate communities of climate modeling and remote sensing are finding economic, political, and societal benefit from the direct comparisons of climate model outputs to satellite observations, using these comparisons to help tune models and to provide ground truth in understanding the Earth's climate processes. In the context of the Intergovernmental Panel on Climate Change (IPCC) and its upcoming 5th Assessment Report (AR5), the authors have been working with principals in both communities to build a software infrastructure that enables these comparisons. This infrastructure must overcome several software engineering challenges, including bridging heterogeneous data file formats and metadata formats, transforming swath-based remotely sensed data into globally gridded datasets, and navigating and aggregating information from the largely distributed ecosystem of organizations that house these climate model outputs and satellite data. The authors' focus in this article is on the description of software tools and services that meet these stringent challenges, and on informing the broader communities of climate modelers, remote sensing experts, and software engineers on the lessons learned from their experience so that future systems can benefit and improve upon their existing results.",1937-4194,,10.1109/MS.2012.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6133265,distributed applications;evolving Internet applications;domain-specific architectures,Meteorology;Distributed databases;Software development;Data models;Remote sensing;Computational modeling;Internet;Satellite communication,artificial satellites;climate mitigation;ecology;environmental science computing;meta data;remote sensing;satellite navigation;service-oriented architecture;software tools,satellite observations sharing;climate-modeling community;remote sensing experts;societal benefit;economic benefit;political benefit;Earth climate processes;intergovernmental panel on climate change;IPCC;5th assessment report;AR5;software infrastructure;software engineering challenges;heterogeneous data file formats;metadata formats;swath-based remotely sensed data;globally gridded datasets;information aggregation;information navigation;distributed ecosystem;climate model;satellite data;software tools;software services,,10.0,,9.0,,17 Jan 2012,,,IEEE,IEEE Magazines
1116,1118,The Dimension Architecture: A New Approach to Resource Access,W. Kern; C. Silberbauer; C. Wolff,Landesamt für Finanzen; Competence Center Software Engineering; University of Regensburg,IEEE Software,19 Aug 2010,2010,27,5,74,81,"An important task for almost every software application is I/O. For instance, database applications and even simple applications supporting configuration files-all use I/O. Consequently, accessing and manipulating resources is essential to most software systems. A new resource access approach separates various aspects such as address, content format, and location type to enable their flexible and configurable combination.",1937-4194,,10.1109/MS.2010.128,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551017,software architecture;I/O;resource acquisition;resource access;dimension architecture,Production facilities;Resource management;Software architecture;Cryptography,object-oriented methods;software architecture,dimension architecture;resource access;content format;software application;software systems,,,,14.0,,19 Aug 2010,,,IEEE,IEEE Magazines
1117,1119,The Business Goals Viewpoint,P. Clements; L. Bass,"Carnegie Mellon University, Pittsburgh; Carnegie Mellon University, Pittsburgh",IEEE Software,14 Oct 2010,2010,27,6,38,45,"A business goals viewpoint can help capture precise, unambiguous business goals, which in turn helps architects design systems that are more responsive to organizational needs. There are reasons other than cost reduction for improving business processes. A business goal expresses why a system is being developed at all, and what stakeholders in the developing organization, the customer organization, and beyond aspire to achieve through its production and use.",1937-4194,,10.1109/MS.2010.116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5518755,business goals;business goals viewpoint;software architecture;business goals scenario,Databases;Computer architecture;Production systems;Software engineering;Feedback;Documentation;Costs;Remuneration;Thermostats,business data processing;cost reduction;organisational aspects;software architecture,business goal;system design;organizational need;cost reduction;business process;stakeholder;customer organization,,6.0,,10.0,,23 Jul 2010,,,IEEE,IEEE Magazines
1118,1120,How to Avoid Selecting Bids Based on Overoptimistic Cost Estimates,M. Jorgensen,"Simula Res. Lab., Oslo",IEEE Software,17 Apr 2009,2009,26,3,79,84,"This article documents important connections between cost overruns and bidding. It also recommends how clients should design their bidding process to avoid selecting bids based on overoptimistic cost estimates. The recommendations provided reduce the risk of initiating projects that have unrealistic plans, time overruns, low software quality, high maintenance costs, and inflexible providers. Although this article aims to improve the clients' bidding processes, the authos believes that it also has important implications for software providers. They could use the reported results to identify bidding rounds that they're likely to win only if they provide a bid based on strongly overoptimistic cost estimates. Software providers should consider carefully whether it's worthwhile to participate in bidding rounds in which this is the case.",1937-4194,,10.1109/MS.2009.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814964,cost estimation;bidding processes;provider selection;software acquisition,Uncertainty;Programming;Cost function;Context awareness;Writing;Proposals;Software engineering;Project management,software cost estimation;software maintenance,overoptimistic cost estimates;bidding;software quality;maintenance costs;software providers,,7.0,,15.0,,17 Apr 2009,,,IEEE,IEEE Magazines
1119,1121,Specification Inference Using Systematic Reverse-Engineering Methodologies: An Automotive Industry Application,M. Shahbaz; K. C. Shashidhar; R. Eschbach,University of Sheffield; Max Planck Institute for Software Systems; ITK Engineering AG,IEEE Software,22 Oct 2012,2012,29,6,62,69,"Lack of precise specification is a well-known problem in the software industry. This article covers some peculiar aspects of the problem and its causes in the automotive software industry. The authors describe how the situation motivates engineers to grasp reverse-engineering methodologies to comprehend third-party components. They developed a novel approach for reverse-engineering components, which they applied to a recent project on testing embedded systems of a modern vehicle.",1937-4194,,10.1109/MS.2011.159,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6112742,software reverse engineering;system analysis;model inference;system integration;system specification,Software engineering;Automotive engineering;Embedded systems;Reverse engineering;System analysis and design;Modeling,automobile industry;DP industry;formal specification;inference mechanisms;program testing;reverse engineering;road vehicles,specification inference;systematic reverse-engineering methodology;automotive software industry application;third-party components;modern vehicle embedded system testing,,2.0,,11.0,,27 Dec 2011,,,IEEE,IEEE Magazines
1120,1122,Contemporary Peer Review in Action: Lessons from Open Source Development,P. Rigby; B. Cleary; F. Painchaud; M. Storey; D. German,"Concordia University, Montreal, Canada; University of Victoria, Canada; Department of National Defence, Canada; University of Victoria, Canada; University of Victoria, Canada",IEEE Software,22 Oct 2012,2012,29,6,56,61,"Do you use software peer reviews? Are you happy with your current code review practices? Even though formal inspection is recognized as one of the most effective ways to improve software quality, many software organizations struggle to effectively implement a formal inspection regime. Open source projects use an agile peer review process-based on asynchronous, frequent, incremental reviews that are carried out by invested codevelopers-that contrasts with heavyweight inspection processes. The authors describe lessons from the OSS process that transfer to proprietary software development. They also present a selection of popular tools that support lightweight, collaborative, code review processes and nonintrusive metric collection.",1937-4194,,10.1109/MS.2012.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6148202,software quality;software peer review;inspection;agile development;open source software development,Software quality;Agile manufacturing;Programming;Electronic mail;Software engineering;Software development,DP industry;formal verification;inspection;public domain software;software quality;software reviews,contemporary peer review;open source development;software peer reviews;code review practices;software quality;software organizations;formal inspection regime;open source projects;agile peer review process;invested codevelopers;heavyweight inspection processes;OSS process;proprietary software development;lightweight review process;collaborative review process;code review process;nonintrusive metric collection,,57.0,,15.0,,7 Feb 2012,,,IEEE,IEEE Magazines
1121,1123,iUCP: Estimating Interactive-Software Project Size with Enhanced Use-Case Points,N. Nunes; L. Constantine; R. Kazman,University of Madeira; University of Madeira; University of Hawaii,IEEE Software,23 Jun 2011,2011,28,4,64,73,An empirical study shows that estimations based on a modified use-case-point method exhibit less interestimator variance than those based on the original method.,1937-4194,,10.1109/MS.2010.111,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5499458,design tools and techniques. distribution;maintenance;enhancement. usability testing,Software engineering;Unified modeling language;Life estimation;Human computer interaction;User centered design;Interactive systems;Cost benefit analysis;Feedback;Data mining,project management;software development management;statistical analysis;user centred design;user interfaces,use-case-point method;interestimator variance;interactive-software project size;project size estimation;iUCP;interactive use-case point,,6.0,,12.0,,1 Jul 2010,,,IEEE,IEEE Magazines
1122,1124,Safety-Critical Software [Guest editors' introduction],X. Larrucea; A. Combelles; J. Favaro,Tecnalia; inspearit Group; Intecs SpA,IEEE Software,18 Apr 2013,2013,30,3,25,27,"We live in a world in which our safety depends on software-intensive systems. This is the case for the aeronautic, automotive, medical, nuclear, and railway sectors as well as many more. Organizations everywhere are struggling to find cost-effective methods to deal with the enormous increase in size and complexity of these systems, while simultaneously respecting the need to ensure their safety. Consequently, we're witnessing the ad hoc emergence of a renewed discipline of safety-critical software systems development as a broad range of software engineering methods, tools, and frameworks are revisited from a safety-related perspective. The rise of these complex, critical systems has spawned several recent initiatives to promote reuse, both of the technical artifacts and the artifacts and procedures that certify their suitability for use in safety-related contexts. One unmistakable trend is a strong interest in applying model-driven engineering techniques to safety-critical systems development over the entire life cycle.",1937-4194,,10.1109/MS.2013.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6504883,safety critical;model based;certification;security,Special issues and sections;Software development;Certification;Computer security;Product life cycle management;Safety;Software reliabiilty,,,,6.0,,,,18 Apr 2013,,,IEEE,IEEE Magazines
1123,1125,You Are What You Read,P. Kruchten,University of British Columbia,IEEE Software,24 Feb 2009,2009,26,2,10,11,"Given that useful knowledge in software engineering has a half-life of about five years, reading remains an excellent way to replenish this vanishing resource for the diligent software engineer.",1937-4194,,10.1109/MS.2009.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786944,software literacy;reading;book;magazine;journal;fieldstone;dormouse,Books;Materials;Software;Probability density function;Feeds;Data mining;Unified modeling language,,,,,,1.0,,24 Feb 2009,,,IEEE,IEEE Magazines
1124,1126,The Business Rules Approach and Its Effect on Software Testing,T. O. Meservy; C. Zhang; E. T. Lee; J. Dhaliwal,University of Memphis; University of Memphis; University of Memphis; University of Memphis,IEEE Software,10 Aug 2012,2012,29,4,60,66,Codification and testing of business rules in application programs has historically been a challenge in software engineering. Many organizations have adopted the business rules approach to formalize and compartmentalize business rules as a separate component from application code. This article investigates and presents the effects of the business rules approach on testing activities in the software development life cycle at a Fortune 500 corporation. The findings suggest that the business rules approach has the potential to engage testing personnel early in the development process and to improve the efficiency and effectiveness of testing activities.,1937-4194,,10.1109/MS.2011.120,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6030868,middleware/business logic;representations;rule-based processing;testing strategies,Programming;Software testing;Software development;Encoding;Testing;Best practices,,,,4.0,,11.0,,29 Sep 2011,,,IEEE,IEEE Magazines
1125,1127,Software is Driving Software Engineering?,G. Hurlburt; J. Voas,STEMCorp; National Institute of Standards and Technology,IEEE Software,29 Dec 2015,2016,33,1,101,104,"We're living in a physical world that's moving at the speed of software. This means that software's trajectory will drive software engineering, not vice versa. However, software engineering is also driven by visionary corporate leaders, backed by skilled software developers. This article is part of a special issue on the Future of Software Engineering.",1937-4194,,10.1109/MS.2016.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367983,software engineering;software development;SWEBOK;Software Engineering Body of Knowledge;SWEBOK Guide;Guide to the Software Engineering Body of Knowledge;software engineers,Software engineering;Professional aspects;Software development,professional aspects;software engineering,software engineering;physical world;software trajectory,,,,9.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1126,1128,How Best to Teach Global Software Engineering? Educators Are Divided,S. Beecham; T. Clear; D. Damian; J. Barr; J. Noll; W. Scacchi,"Lero; Auckland University of Technology; University of Victoria; Ithaca College; Lero; University of California, Irvine",IEEE Software,16 Jan 2017,2017,34,1,16,19,Pioneering educators discuss how they inject realism into global-software-engineering education.,1937-4194,,10.1109/MS.2017.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819407,global software engineering;GSE;global-software-engineering education;GSE-Ed;global software development;GSD;software education;software development;software engineering,Computer science education;Education courses;Software engineering,computer science education;software engineering,global-software-engineering education,,16.0,,3.0,,16 Jan 2017,,,IEEE,IEEE Magazines
1127,1129,Brazil and the Emerging Future of Software Engineering,C. d. O. Melo; R. Ferraz; R. J. Parsons,ThoughtWorks Latin America; ThoughtWorks; ThoughtWorks,IEEE Software,29 Dec 2015,2016,33,1,45,47,"Claudia Melo, Ronaldo Ferraz, and Rebecca Parsons from ThoughtWorks share their views of software engineering's future from a Brazilian perspective. This invited essay is part of a special issue on the Future of Software Engineering.",1937-4194,,10.1109/MS.2016.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368013,software engineering;software development;ThoughtWorks;Brazil,Software engineering;Brazil;Software development;Market opportunties,software engineering,Brazil;ThoughtWorks;software engineering future,,2.0,,2.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1128,1130,Putting the Engineering into Software Engineering Education,J. Offutt,George Mason University,IEEE Software,3 Jan 2013,2013,30,1,96,96,"Based on over 20 years of teaching and research experience, the author provides his assessment of software engineering education. He then builds on the analysis to provide recommendations on how we need to diverge from computer science to increase our impact, gain credibility, and ultimately ensure the success and recognition of our young discipline. A key behind the author's message is that we need to become a true engineering discipline.",1937-4194,,10.1109/MS.2013.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401119,teaching paradigm;scientific discipline;software engineering education,Computer engineering education;Software engineering;Engineering education,computer science education;software engineering;teaching,software engineering education;teaching;research experience;computer science;gain credibility;engineering discipline,,7.0,,4.0,,3 Jan 2013,,,IEEE,IEEE Magazines
1129,1131,The Future of Software Engineering,F. Shull; A. Carleton; J. Carriere; R. Prikladnicki; D. Zhang,Software Engineering Institute; Software Engineering Institute; Google; Pontificia Universidade Catolica do Rio Grande do Sul; Microsoft Research,IEEE Software,29 Dec 2015,2016,33,1,32,35,"This special issue offers a range of perspectives on software engineering's future from professionals working around the world in diverse areas of software. The content ranges from detailed technical articles about the research areas behind today's trends to shorter essays and opinion pieces from folks working to sharpen the focus of their own visions of that future. The Web extra at https://youtu.be/LnSHGDl9O7U is an audio recording of st Shull and Anita Carleton of the Software Engineering Institute and Rafael Prikladnicki of Pontificia Universidade Catolica do Rio Grande do Sul talking about the authors, articles, and discussions that went into the IEEE Software January/February 2016 theme issue on the future of software engineering.",1937-4194,,10.1109/MS.2016.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367988,software engineering;software development;China;Brazil;requirements engineering;crowdsourcing;sustainability;technical debt;app stores;big data;massive systems,Special issues and sections;Software engineering;Software architecture;Software development,,,,1.0,,4.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1130,1132,The Case for Context-Driven Software Engineering Research: Generalizability Is Overrated,L. Briand; D. Bianculli; S. Nejati; F. Pastore; M. Sabetzadeh,University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg,IEEE Software,22 Sep 2017,2017,34,5,72,75,"For software engineering research to increase its impact and steer our community toward a more successful future, it must foster context-driven research. Such research focuses on problems defined in collaboration with industrial partners and is driven by concrete needs in specific domains and development projects.",1937-4194,,10.1109/MS.2017.3571562,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048656,context-driven software engineering;context-driven research;software engineering;software development,,groupware;software engineering,context-driven software engineering;industrial partner collaboration,,13.0,,1.0,,22 Sep 2017,,,IEEE,IEEE Magazines
1131,1133,Software Engineering for Internet Computing: Internetware and Beyond [Guest editors' introduction],A. Bertolino; M. B. Blake; P. Mehra; H. Mei; T. Xie,Italian National Research Council; University of Miami; SanDisk; Peking University; University of Illinois at Urbana-Champaign,IEEE Software,4 Feb 2015,2015,32,1,35,37,"Software engineering for Internet computing involves the architecting, development, deployment, management, and quality assurance of software supporting Internet-based systems. It also addresses global-development issues such as communication complexity, distributed control, governance policies, and cultural differences. This issue presents a selection of exciting and representative research on this topic. The Web extra at http://youtu.be/UA7rLAwFbwY is an audio recording in which author IEEE Software Multimedia Editor Davide Falessi interviews Antonia Bertolino, Hong Mei, and Tao Xie, guest editors of the magazine's January/February 2015 issue on Software Engineering for Internet Computing: Internetware and Beyond.",1937-4194,,10.1109/MS.2015.16,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030224,software engineering;Internet computing;Internetware;Internet of Things;wireless sensor networks;service choreographies;smartphone applications;cloud APIs;software diversification;cloud computing,Special issues and sections;Software engineering;Internet computing;Cloud computing;Smart phones;Software engineering;Wireless sensor networks;Computer applications,Internet;software architecture;software management;software quality,software engineering;Internet computing;Internetware;software architecture;software development;software deployment;software management;software quality assurance;Internet-based systems;global-development issues,,7.0,,11.0,,4 Feb 2015,,,IEEE,IEEE Magazines
1132,1134,Four Thought Leaders on Where the Industry Is Headed,A. Moore; T. O'Reilly; P. D. Nielsen; K. Fall,Carnegie Mellon University; O'Reilly Media; Software Engineering Institute (SEI); Carnegie Mellon University,IEEE Software,29 Dec 2015,2016,33,1,36,39,"Four software engineering thought leaders offer challenging, thought-provoking ideas about where our industry is headed. They discuss challenges for software engineers to keep their skill set current and tout the promise of new technologies to advance our field. These invited essays are part of a special issue on the Future of Software Engineering.",1937-4194,,10.1109/MS.2016.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368019,software development;software engineering;formal methods;new technologies;Code for America;e-government;agile development;autonomous systems,Interviews;Software development;Autonomous systems;Software engineering;Technological innovation,software engineering,software engineering,,4.0,,2.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1133,1135,Bringing the Human Factor to Software Engineering,L. Fernando Capretz,Western University,IEEE Software,17 Mar 2014,2014,31,2,104,104,"The human aspects involved in the software development process are vital to a successful completion of a software project. The author advocates for human factor topics to be part of mainstream software engineering education in order to elevate job satisfaction, improve performance, and increase productivity of software engineers. Emphasis should be on providing a practical overview of software engineering processes from a human perspective, offering alternative viewpoints within technically saturated curricula.",1937-4194,,10.1109/MS.2014.30,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774355,human factors;soft skills;software psychology,Software development;Human factors;Software engineering,computer science education;human factors;software engineering,human factor;software development process;software project completion;mainstream software engineering education;software engineers productivity;human perspective;job satisfaction;performance improvement,,6.0,,,,17 Mar 2014,,,IEEE,IEEE Magazines
1134,1136,Déjà Vu: The Life of Software Engineering Ideas,H. Erdogmus,Kalemun Research,IEEE Software,31 Dec 2009,2010,27,1,2,5,"The story of software engineering since the label came into use is thus a story of compromise among generality and specificity, heuristics and formalism, procedures and data, sequence and cycle. The practical response was combination and accommodation-covering all bases or splitting the difference, synthesizing complementary approaches or accommodating inescapable trade-offs. Pragmatists argued for mixed strategies of testing and proving, the use of tailored reliability models and development environments, the use of a full set of metrics, and the synthesis of life-cycle models. But while seizing the middle ground appeared to be a practical way to cope with difficulties, it seemed unlikely to produce a revolution. If software technologists are nowadays devoting more effort to engaging in a pragmatic fashion with the complexity of their problems, it is to their credit. That is symptomatic of maturity and of real engineering.",1937-4194,,10.1109/MS.2010.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370754,software engineering;maturation;innovation;adoption,Software engineering;Life testing,software metrics;software reliability,software engineering idea;tailored reliability model;software life-cycle model;software technologist;software metrics,,2.0,,,,31 Dec 2009,,,IEEE,IEEE Magazines
1135,1137,Software Engineering for the Internet of Things,X. Larrucea; A. Combelles; J. Favaro; K. Taneja,Tecnalia; inspearit; Intecs; Google,IEEE Software,16 Jan 2017,2017,34,1,24,28,"No consolidated set of software engineering best practices for the Internet of Things (IoT) has yet emerged. Too often, the landscape resembles the Wild West, with unprepared programmers putting together IoT systems in ad hoc fashion and throwing them out into the market, often poorly tested. In addition, the academic sector is in danger of fragmenting into specialized, often unrelated research areas. This IEEE Software theme issue aims to help provide the basis for a set of best practices that will guide the industry through the challenges of software engineering for the IoT",1937-4194,,10.1109/MS.2017.28,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819384,Internet of Things;IoT;cyber-physical systems;software engineering;software development;model-based software engineering;scalability,Special issues and sections;Software engineering;Internet of things;Best practices;Cyber-physical systems;Software development;Scalability,,,,20.0,,16.0,,16 Jan 2017,,,IEEE,IEEE Magazines
1136,1138,Search Based Software Engineering: Introduction to the Special Issue of the IEEE Transactions on Software Engineering,M. Harman; A. Mansouri,NA; NA,IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,737,741,,1939-3520,,10.1109/TSE.2010.106,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5644735,,Special issues and sections;Search engines;Search problems;Search methods,,,,21.0,,22.0,,29 Nov 2010,,,IEEE,IEEE Journals
1137,1139,"The Tragedy of Defect Prediction, Prince of Empirical Software Engineering Research",M. Lanza; A. Mocci; L. Ponzanelli,Università della Svizzera italiana; Università della Svizzera italiana; Università della Svizzera italiana,IEEE Software,28 Oct 2016,2016,33,6,102,105,"If measured by the number of published papers, defect prediction has become an important research field over the past decade, with many researchers continuously proposing novel approaches to predict defects in software systems. However, most of these approaches have had a noticeable lack of impact on industrial practice. This lack of impact is because something is intrinsically wrong in how defect prediction approaches are evaluated.",1937-4194,,10.1109/MS.2016.156,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725218,defect prediction;empirical software engineering research;software engineering research;software engineering;software development;software defects;software bugs,,software fault tolerance,empirical software engineering research;software system defect prediction,,16.0,,5.0,,28 Oct 2016,,,IEEE,IEEE Magazines
1138,1140,Guest Editor's Introduction: International Conference on Software Engineering,J. M. Atlee; P. Inverardi,NA; NA,IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,3,4,"The papers in this special section contain extended versions of selected papers from the 31st ACM/IEEE International Conference on Software Engineering (ICSE), held 20-22 May 2009 in Vancouver, British Columbia, Canada.",1939-3520,,10.1109/TSE.2012.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6141071,,Special issues and sections;Meetings;Software engineering,,,,,,,,30 Jan 2012,,,IEEE,IEEE Journals
1139,1141,Guest Editors' Introduction: 2008 Conference on the Foundations of Software Engineering,G. C. Murphy; W. Schafer,NA; NA,IEEE Transactions on Software Engineering,30 Sep 2010,2010,36,5,591,592,"The four papers in this special section are extended versions of selected papers from the 16th ACM International Symposium on the Foundations of Software Engineering, held in Atlanta, Georgia, 11-13 November 2008.",1939-3520,,10.1109/TSE.2010.88,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5593044,,Special issues and sections;Meetings;Software engineering,,,,,,45.0,,30 Sep 2010,,,IEEE,IEEE Journals
1140,1142,Guest Editors' Introduction: Software Engineering for Compliance,U. Zdun; A. Bener; E. L. Olalia-Carin,University of Vienna; Ryerson University; KPMG Canada,IEEE Software,20 Apr 2012,2012,29,3,24,27,"This special issue of IEEE Software explores the challenges in developing compliant software systems. Typically, organizations face conflicting objectives, with compliance policies possibly hindering innovation, slowing down the product development process, or making the whole process most costly. The goal of software engineering for compliance is to bridge the gap between the software engineering community and the compliance community. The articles in this special issue explain the nature and extent of this domain from different viewpoints, the technical challenges it poses, novel software engineering methods for supporting compliance, and the current state of the art.",1937-4194,,10.1109/MS.2012.63,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188599,software engineering;compliance;regulations;laws;business,Special issues and sections;Software engineering,,,,3.0,,13.0,,20 Apr 2012,,,IEEE,IEEE Magazines
1141,1143,Embracing the Engineering Side of Software Engineering,L. Briand,University of Luxembourg,IEEE Software,10 Aug 2012,2012,29,4,96,96,"The author provides, based on 20 years of research and industrial experience, his assessment of software engineering research. He then builds on such analysis to provide recommendations on how we need to change as a research community to increase our impact, gain credibility, and ultimately ensure the success and recognition of our young discipline. The gist of the author's message is that we need to become a true engineering discipline.",1937-4194,,10.1109/MS.2012.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6265086,software engineering research;research paradigm;scientific discipline,Software engineering;Research and development,,,,22.0,,,,10 Aug 2012,,,IEEE,IEEE Magazines
1142,1144,Guest Editors' Introduction: End-User Software Engineering,A. J. Ko; R. Abraham; M. M. Burnett; B. A. Myers,University of Washington; Microsoft; Oregon State University; Carnegie Mellon University,IEEE Software,25 Aug 2009,2009,26,5,16,17,"Millions of people program to support their work but don't call themselves programmers. The field of end-user software engineering is concerned with helping these people create reliable, dependable, and reusable programs, without distracting them from their primary tasks. This special issue of IEEE Software presents a selection of research from this field, providing a glimpse of some of the exciting advances made in past 10 years of research and development.",1937-4194,,10.1109/MS.2009.129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222788,software engineering;reliability;end-user programming,Software engineering;Enterprise resource planning;Computer science;Debugging;Software design;Computer languages;Contacts;Programming profession;Management training;Risk management,,,,6.0,,1.0,,25 Aug 2009,,,IEEE,IEEE Magazines
1143,1145,Docker [Software engineering],C. Anderson,,IEEE Software,23 Apr 2015,2015,32,3,102,c3,"In episode 217 of Software Engineering Radio, host Charles Anderson talks with James Turnbull, a software developer and security specialist who's vice president of services at Docker. Lightweight Docker containers are rapidly becoming a tool for deploying microservice-based architectures.",1937-4194,,10.1109/MS.2015.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093032,Docker;SE Radio;Software Engineering Radio;James Turnbull;microservices;Docker containers,Interviews;Virtual machining;Software engineering;Software development,,,,56.0,,,,23 Apr 2015,,,IEEE,IEEE Magazines
1144,1146,Guest Editors' Introduction: Software Engineering for the Cloud,J. Grundy; G. Kaefer; J. Keung; A. Liu,Swinburne University of Technology; Siemens AG; Hong Kong Polytechnic University; National ICT Australia,IEEE Software,20 Feb 2012,2012,29,2,26,29,"Cloud computing is a new paradigm for software systems where applications are divided into sets of composite services hosted on leased, highly distributed platforms. There are many new software engineering challenges in building effective cloud-based software applications. This special issue provides a set of practical contributions to the engineering of cloud computing applications and includes software processes, architecture and design approaches, testing, scalability engineering, security engineering, and applications of highly parallel cloud-based systems.",1937-4194,,10.1109/MS.2012.31,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155142,software engineering for cloud computing;software testing;software architecture;scalability;parallel processing,Special issues and sections;Cloud computing;Software engineering;Computer architecture,,,,6.0,,,,20 Feb 2012,,,IEEE,IEEE Magazines
1145,1147,Guest Editors' Introduction: Cooperative and Human Aspects of Software Engineering,C. R. B. de Souza; H. Sharp; J. Singer; L. Cheng; G. Venolia,"Federal University of Pará, Brazil; The Open University, UK; National Research Council of Canada; IBM Center for Social Software; Microsoft Research",IEEE Software,16 Oct 2009,2009,26,6,17,19,"Software is developed by people, used by people, and supports interaction among people. As such, human characteristics and cooperation are central to modern practical software construction. While human aspects were recognized as important over 30 years ago, recent changes in the software domain have made cooperative and human aspects of software engineering even more significant. This special issue of IEEE Software presents a sample of current research in this field illustrating the wide variety of approaches, software domains and activities in which human and cooperative aspects are being investigated.",1937-4194,,10.1109/MS.2009.176,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5287004,human aspects;cooperative aspects;social aspects;cooperation;coordination;collaborative software engineering.,Humans;Software engineering,,,,16.0,,5.0,,16 Oct 2009,,,IEEE,IEEE Magazines
1146,1148,"Responses to ""Software Engineering: An Idea Whose Time Has Come and Gone?""",,,IEEE Software,25 Aug 2009,2009,26,5,5,5,"The section features excerpts of letters responding to Tom DeMarco's article ""Software Engineering: An Idea Whose Time Has Come and Gone?"" (July/Aug., pp. 96, 95).",1937-4194,,10.1109/MS.2009.136,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222783,software engineering;Tom DeMarco;software metrics,Software engineering;Biomedical imaging;DICOM;Standardization;Medical diagnostic imaging;Computer industry;Open source software;Software tools;Surgery;Manufacturing,,,,,,,,25 Aug 2009,,,IEEE,IEEE Magazines
1147,1149,Crowdsourcing for Software Engineering,K. Stol; T. D. LaToza; C. Bird,Lero-the Irish Software Research Centre; George Mason University; Microsoft Research,IEEE Software,28 Mar 2017,2017,34,2,30,36,"Crowdsourcing, which leverages the intelligence and contributions of a large group of people to achieve a specific goal, is disrupting business models and work practices. Because crowdsourcing approaches could have a far-reaching impact on future software development, this theme issue explores various ways developers and managers can benefit from these new opportunities. The Web Extra https://youtu.be/Z_8vWQjU7iY is an audio podcast of the introduction to the theme issue on crowdsourcing for software engineering.",1937-4194,,10.1109/MS.2017.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888402,crowdsourcing;software development;software engineering;requirements engineering;requirements elicitation;Stack Overflow;GitHub;crowdsourced software testing;CrowdSummarizer;code summaries;Java;App Store 2.0;mobile apps,Special issues and sections;Crowdsourcing;Software engineering;Business;Information analysis,crowdsourcing;software engineering,crowdsourcing;software engineering;business models;work practices;software development;audio podcast,,12.0,,19.0,,28 Mar 2017,,,IEEE,IEEE Magazines
1148,1150,How Abundance Changes Software Engineering,D. Spinellis,Athens University of Economics and Business,IEEE Software,15 May 2017,2017,34,3,4,7,"The abundance of processing power is changing the nature of software engineering. By reducing the cost of failure, abundance changes how developers use computing technologies. Also, abundance changes the developer's role by moving the focus from technology to management. This article also contains an erratum. In ""App Store 2.0: From Crowdsourced Information to Actionable Feedback in Mobile Ecosystems"" (DOI: 10.1109/MS.2017.46) from the Mar./Apr. 2017 issue, in the fifth line of the second column on p. 83, ""see sia"" should be ""see Figure 2a.""",1937-4194,,10.1109/MS.2017.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927929,processing power;software engineering;software development,,software development management;software reliability,software engineering;software failure;computing technologies;software management,,,,,,15 May 2017,,,IEEE,IEEE Magazines
1149,1151,Leaders of Tomorrow on the Future of Software Engineering: A Roundtable,F. Hermans; J. Siegmund; T. Fritz; G. Bavota; M. Nagappan; A. Hindle; Y. Kamei; A. Mesbah; B. Adams,Delft University of Technology; University of Passau; University of Zurich; Free University of Bozen-Bolzano; Rochester Institute of Technology; University of Alberta; Kyushu University; University of British Columbia; Polytechnique Montréal,IEEE Software,26 Feb 2016,2016,33,2,99,104,"Nine rising stars in software engineering describe how software engineering research will evolve, highlighting emerging opportunities and groundbreaking solutions. They predict the rise of end-user programming, the monitoring of developers through neuroimaging and biometrics sensors, analysis of data from unstructured documents, the mining of mobile marketplaces, and changes to how we create and release software.",1937-4194,,10.1109/MS.2016.55,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420475,end-user programming;neuroimaging;biometrics;unstructured documents;mobile marketplaces;software engineering;software development,,software engineering,software engineering;end-user programming;neuroimaging;biometrics sensors;data analysis;unstructured documents;mobile marketplace mining,,3.0,,9.0,,26 Feb 2016,,,IEEE,IEEE Magazines
1150,1152,Improving Timeliness and Visibility in Publishing Software Engineering Research,M. B. Dwyer,,IEEE Transactions on Software Engineering,13 Mar 2017,2017,43,3,205,206,Reports on initiatives to improve and enhance the IEEE Transactions on Software Engineering. ,1939-3520,,10.1109/TSE.2017.2663918,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876880,,,,,,,,,,13 Mar 2017,,,IEEE,IEEE Journals
1151,1153,Getting an Intuition for Big Data,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,26 Jun 2013,2013,30,4,3,6,"IEEE Software Editor-in-Chief Forrest Shull discusses the importance of building reliable systems to interpret big data. In addition, he discusses the IBM Impact 2013 Unconference; the Software Engineering Institute's SATURN 2013 conference in which the IEEE Software Architecture in Practice Award went to Simon Brown of Coding the Architecture, for his presentation titled ""The Conflict between Agile and Architecture: Myth or Reality"" and the IEEE Software New Directions Award went to Darryl Nelson of Raytheon for his presentation titled, ""Next-Gen Web Architecture for the Cloud Era."" He also welcomes Professor Rafael Prikladnicki of the Computer Science School at PUCRS, Brazil, and Chief Software Economist Walker Royce of IBM's Software Group to the IEEE Software Advisory Board. The first Web extra at http://youtu.be/JrQorWS5m6w is a video interview in which IEEE Software editor in chief Forrest Shull speaks with Paul Zikopoulos, Director--IBM Information Management Technical Professionals, Competitive Database, and Big Data at IBM, about the potentials of mining big data. Zikopoulos will deliver a keynote at Software Experts Summit 2013 on 17 July in Redmond, Washington. The second Web extra at http://youtu.be/NHHThAeONv8 is a video interview in which IEEE Software editor in chief Forrest Shull speaks with Catherine Plaisant and Megan Monroe of the University of Maryland Human-Computer Interaction Laboratory about big data information visualization and its applications to software development. The third Web extra at http://youtu.be/NqXE0ewoTKA is a video overview of the IBM Impact 2013 Unconference, sponsored by IEEE Software magazine, an event specifically designed for developers that featured Grady Booch and Tim O'Reilly as keynote speakers.",1937-4194,,10.1109/MS.2013.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547604,big data;smart data;reliability;software;interpret;interpretation;intuition;IBM;Impact;Unconference;Software Engineering Institute;SEI;Saturn;conference;Rafael Prikladnicki;Walker Royce;application;research;practice;practical;software engineering;software development,,data mining,big data interpretation;IEEE software;IBM Impact 2013 Unconference;IEEE Software Architecture in Practice Award;Software Engineering Institute;big data mining,,3.0,,,,26 Jun 2013,,,IEEE,IEEE Magazines
1152,1154,The Future of Chinese Software Development,Z. Tang; M. Yang; J. Xiang; J. Liu,Tuniu.com; Tujia.com; Secoo.com; Gridsum Technology,IEEE Software,29 Dec 2015,2016,33,1,40,44,Four chief technology officers from Chinese software companies share their thoughts of their industry's fast growth and their experiences dealing with the technical challenges of software development for massive-scale systems and services. These invited essays are part of a special issue on the Future of Software Engineering.,1937-4194,,10.1109/MS.2016.19,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368024,China;software development;software engineering;Tunio.com;Tujia.com;Secoo.com;Gridsum Technology;massive-scale systems;big data;Internet;e-commerce,Interviews;China;Software development;Big data;E-commerce,software engineering,Chinese software development;Chinese software companies;massive-scale systems;massive-scale services;Future of Software Engineering,,,,4.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1153,1155,The Only Constant Is Change,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,3 Sep 2013,2013,30,5,4,9,"IEEE Software editor-in-chief Forrest Shull discusses the magazine's recent editorial board meeting and some of the discussions the group had about where software development is headed, including refactoring and reengineering, technical debt, measurement, cloud computing, user experiences, and effective project management. In addition, he describes the recent Software Experts Summit 2013, which focused on smart data science and the International Conference on Software Engineering's Software Engineering in Practice award, selected by IEEE Software. The first Web extra at http://youtu.be/BRioqQenavA is a video interview in which John Howie of the Cloud Security Alliance expands on his talk at Software Experts Summit 2013 ""Big Data: Answering Questions and Solving Society's Problems, but at What Cost?"" The second Web extra at http://youtu.be/6jm8mZTQsnw is a video interview in which Microsoft's James Whittaker expands on his talk at Software Experts Summit 2013 (SES13) about the future of the Web and search. The third Web extra at http://youtu.be/aCypdSuCDQs is a video interview in which IEEE Software editor in chief Forrest Shull speaks with Jane Cleland-Huang of DePaul University about the Software Engineering in Practice Award at the International Conference on Software Engineering 2013, presented by IEEE Software.",1937-4194,,10.1109/MS.2013.115,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6588533,refactoring;reengineering;technical debt;measurement;cloud computing;user experience;project management;software experts summit;ses;international conference on software engineering;ses;software engineering in practice award;ieee software;software;research;practice;practical;software engineering;software development,,,,,,,,,3 Sep 2013,,,IEEE,IEEE Magazines
1154,1156,Three Experts on Big Data Engineering,C. Szyperski; M. Petitclerc; R. Barga,Microsoft; IBM Canada; Amazon Web Services,IEEE Software,26 Feb 2016,2016,33,2,68,72,"Clemens Szyperski (Microsoft), Martin Petitclerc (IBM), and Roger Barga (Amazon Web Services) answer three questions: What major challenges do you face when building scalable, big data systems? How do you address these challenges? Where should the research community focus its efforts to create tools and approaches for building highly reliable, scalable, big data systems? This article is part of a special issue on Software Engineering for Big Data Systems.",1937-4194,,10.1109/MS.2016.58,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420462,big data;software engineering;software development;Clemens Szyperski;Martin Petitclerc;Roger Barga,,Big Data;software engineering,Big Data engineering;Microsoft;IBM;Amazon Web services;scalable Big Data systems;research community;software engineering,,2.0,,,,26 Feb 2016,,,IEEE,IEEE Magazines
1155,1157,Editorial: Journal-First Publication for the Software Engineering Community,M. B. Dwyer; D. S. Rosenblum,NA; NA,IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,1,1,Presents the introductory editorial for this issue of the publication.,1939-3520,,10.1109/TSE.2015.2500318,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7374796,,,,,,,,,,7 Jan 2016,,,IEEE,IEEE Journals
1156,1158,Connecting and Serving the Software Engineering Community,M. B. Dwyer; E. Bodden; B. Fitzgerald; M. Kim; S. Kim; A. J. Ko; E. Mendes; R. Mirandola; A. Moreira; F. Shull; S. Siegel; T. Xie; C. Zhang,NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA; NA,IEEE Transactions on Software Engineering,11 Mar 2016,2016,42,3,203,280,Presents an editorial discusses the current status and activities supported by this publication.,1939-3520,,10.1109/TSE.2016.2532379,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7432058,,,,,,,,,,11 Mar 2016,,,IEEE,IEEE Journals
1157,1159,When Software Crosses a Line,L. Hatton; M. van Genuchten,Oakwood Computing Associates; VitalHealth,IEEE Software,29 Dec 2015,2016,33,1,29,31,"The debacle with the VW ""defeat device"" raises some unsettling questions. Are any other companies doing this, or-if we take a more cynical standpoint-how many are doing this? If they aren't, are they still using software practices almost as dubious? How do we decide what's reasonable, given software's extraordinary ability to give hardware its character?",1937-4194,,10.1109/MS.2016.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368030,software engineering;software development;VW;defeat device;VW diesel engine,Software engineering;Software development;Companies;Design methodology;Automobile industry;Diesel engines;Maintenance engineering,software engineering,VW defeat device;software practices;software ability,,5.0,,7.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1158,1160,Then a Miracle Occurs,G. Booch,IBM,IEEE Software,30 Jun 2015,2015,32,4,12,14,"Developing software-intensive systems is like many other things, but it's also like no other thing. For the general public, how software is made remains a mystery. The Web extra at https://youtu.be/yVYDwatEpQc is an audio podcast of Grady Booch's On Computing column, in which he discusses how developing software-intensive systems is like many other things, but it's also like no other thing. And for the general public, how software is made remains a mystery.",1937-4194,,10.1109/MS.2015.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140683,software engineering;computing;history,Software development;Software engineering,Internet;software engineering,computing column;Web;software-intensive system,,,,7.0,,30 Jun 2015,,,IEEE,IEEE Magazines
1159,1161,Software-Engineering the Internet of Things,D. Spinellis,,IEEE Software,16 Jan 2017,2017,34,1,4,6,New wiring transformed ENIAC into a versatile stored-program computer. Rewiring Internet of Things infrastructures into a general-purpose computing fabric can similarly change how modern computation interfaces with our environment.,1937-4194,,10.1109/MS.2017.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819398,Internet of Things;IoT;ENIAC;software engineering;software development,,,,,4.0,,,,16 Jan 2017,,,IEEE,IEEE Magazines
1160,1162,The Practice and Future of Release Engineering: A Roundtable with Three Release Engineers,B. Adams; S. Bellomo; C. Bird; T. Marshall-Keim; F. Khomh; K. Moir,Polytechnique Montréal; Software Engineering Institute; Microsoft Research; Software Engineering Institute; Polytechnique Montréal; Mozilla,IEEE Software,10 Mar 2015,2015,32,2,42,49,"Three release engineers share their perspectives on quality metrics for releases and on continuous delivery's benefits and limitations. They also discuss release-engineering job skills, the required mind-set, the role of education, and cultural change, and they recommend future research areas. The Web extra at http://youtu.be/O3cJQTZXAI8 is an audio recording of Davide Falessi speaking with Guest Editors Bram Adams and Foutse Khomh about release engineering and its value to the software industry.",1937-4194,,10.1109/MS.2015.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057611,release engineering;software engineering;continuous delivery;software development,Special issues and sections;Interviews;Software development;Continuous production;Software engineering,,,,9.0,,,,10 Mar 2015,,,IEEE,IEEE Magazines
1161,1163,Jürgen Laartz and Alexander Budzier on Why Large IT Projects Fail,R. Blumen,SalesForce Desk.com,IEEE Software,23 Jun 2016,2016,33,4,117,120,Software Engineering Radio host Robert Blumen speaks to Jürgen Laartz and Alexander Budzier about their joint research on large-IT-project failures.,1937-4194,,10.1109/MS.2016.102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498545,Software Engineering Radio;IT;project failures;black swan;software engineering;software development,Interviews;Software engineering;Software development;Information technology;Project management;Failure analysis,,,,,,,,23 Jun 2016,,,IEEE,IEEE Magazines
1162,1164,Technical Debt,E. Wolff; S. Johann,innoQ; Trifork Amsterdam,IEEE Software,30 Jun 2015,2015,32,4,94,c3,"In Episode 224 of Software Engineering Radio, Eberhard Wolff and Sven Johann discuss technical debt and how to handle it.",1937-4194,,10.1109/MS.2015.95,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140698,SE radio;Software Engineering Radio;Eberhard Wolff;Sven Johann;technical debt;software engineering,Software development;Software engineering;Software reliability,,,,,,,,30 Jun 2015,,,IEEE,IEEE Magazines
1163,1165,The Modern Cloud-Based Platform,S. Tilkov,innoQ,IEEE Software,10 Mar 2015,2015,32,2,116,116,"In this excerpt from Software Engineering Radio, Stefan Tilkov talks with Adrian Cockcroft about architecture, development, and operations that make the most out of cloud-based offerings, with Cockcroft sharing his experience at Netflix.",1937-4194,,10.1109/MS.2015.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057614,continuous delivery;DevOps;cloud;PaaS;platform as a service;infrastructure;windows;software engineering;SE Radio;Software Engineering Radio;Adrian Cockcroft,Software engineering;Continuous production;Software development,,,,4.0,,,,10 Mar 2015,,,IEEE,IEEE Magazines
1164,1166,"Software Quality, Energy Awareness, and More",J. C. Carver; A. Yamashita; L. Minku; M. Habayeb; S. A. Kocak,University of Alabama; Yamashita Research; University of Leicester; Ryerson University; Ryerson University,IEEE Software,28 Oct 2015,2015,32,6,98,100,"This article discusses six papers presented at events connected with the 2015 International Conference on Software Engineering. The papers cover organizational factors and software quality, microclones, big data platforms, energy-aware commits, open source software architecture, and requirements engineering.",1937-4194,,10.1109/MS.2015.127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7311003,software engineering;ICSE;2015 International Conference on Software Engineering;organizational factors;software quality;microclones;big data;energy-aware commits;open source software architecture;requirements engineering;last-line effect;PVS-Studio;Requirements Engineering for Sustainability;RE4S;software development,Software quality;Software engineering;Organizational aspects;Software architecture,,,,,,,,28 Oct 2015,,,IEEE,IEEE Magazines
1165,1167,Software Engineering for the Internet of Things,,,IEEE Software,26 Feb 2016,2016,33,2,c3,c3,Advertisement. IEEE.,1937-4194,,10.1109/MS.2016.50,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420463,,,,,,,,,,26 Feb 2016,,,IEEE,IEEE Magazines
1166,1168,Lightweight and Flexible: Emerging Trends in Software Architecture from the SATURN Conferences,M. Keeling,IBM,IEEE Software,23 Apr 2015,2015,32,3,7,11,"Over its 10-year history, the annual Software Engineering Institute (SEI) Architecture Technology User Network (SATURN) conference has become a barometer for the ever-evolving software architecture climate. This article summarizes some software architecture trends that emerged during SATURN 2014 and gives a glimpse of the future based on the current SATURN 2015 technical program.",1937-4194,,10.1109/MS.2015.65,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093052,SATURN;Software Engineering Institute (SEI) Architecture Technology User Network Conference;software architecture;software development;software engineering,,software architecture,SATURN conferences;Software Engineering Institute Architecture Technology User Network;software architecture climate;SATURN 2014;SATURN 2015 technical program,,3.0,,8.0,,23 Apr 2015,,,IEEE,IEEE Magazines
1167,1169,The Clock Is Ticking,F. Shull,Software Engineering Institute of Carnegie Mellon University,IEEE Software,21 Apr 2014,2014,31,3,4,8,IEEE Software Editor-in-Chief Forrest Shull discusses his tenure and looks at the initiatives during this time. He also welcomes Robert Blumen as department editor for Software Engineering Radio and puts out a call for more hosts to contribute to the Software Engineering Radio podcast interviews.,1937-4194,,10.1109/MS.2014.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802990,editor in chief;IEEE software;podcast;new media;digital edition;initiatives;mission;experience reports;comments;volunteer;objective;software;development;software engineering;radio;se radio,,,,,,,1.0,,21 Apr 2014,,,IEEE,IEEE Magazines
1168,1170,Keeping Ahead of Our Adversaries,J. Cleland-Huang; T. Denning; T. Kohno; F. Shull; S. Weber,DePaul University; University of Utah; University of Washington; Software Engineering Institute; Software Engineering Institute,IEEE Software,25 Apr 2016,2016,33,3,24,28,"Every software system is potentially vulnerable in ways that aren't always imagined during development. White-collar crime involving data breaches are rampant, and governments are investigating the potential for terrorist attacks on power grids, airplanes, and other public services. Technology is a double-edged blade: although computers let us pursue ever-more-impressive innovations, we're likewise subjected to growing possibilities for abuse. So, how do we build secure products that are hardened against adversarial attacks? The article provides a look at this topic.",1937-4194,,10.1109/MS.2016.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458755,threat analysis;software requirements;software security;Security Cards;implantable cardioverter-defibrillator;ICD;software development;software engineering,,security of data,software security;software development;white-collar crime;adversarial attacks,,3.0,,7.0,,25 Apr 2016,,,IEEE,IEEE Magazines
1169,1171,The True Cost of Mobility?,F. Shull,Software Engineering Institute of Carnegie Mellon University,IEEE Software,17 Mar 2014,2014,31,2,5,9,"IEEE Software Editor-in-Chief Forrest Shull discusses privacy implications for mobile and cloud computing with the John Howie, chief operating officer of the Cloud Security Alliance. He also looks at the upcoming Software Experts Summit scheduled for 30 May 2014 in Bangalore, India, and discusses the 200th episode of Software Engineering Radio. The Web extra at http://youtu.be/12w2q6BirV8 is an audio interview in which IEEE Software editor-in-chief Forrest Shull discusses the privacy implications of mobile and cloud computing with John Howie, chief operating officer of the Cloud Security Alliance.",1937-4194,,10.1109/MS.2014.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774335,smart phones;mobile computing;privacy;cloud;cloud computing;software experts summit;ses;software engineering;radio;se radio,,,,,1.0,,,,17 Mar 2014,,,IEEE,IEEE Magazines
1170,1172,Engineering Values: From Architecture Games to Agile Requirements,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,25 Feb 2013,2013,30,2,2,6,"IEEE Software Editor-in-Chief Forrest Shull discusses the importance of having and applying professional principles in all facets of software development while also keeping them in perspective. He cites work by Philippe Kruchten, Ellen Gottesdiener and Mary Gorman to support his position. In addition, he welcomes Dr. Adam Welc to the IEEE Software Editorial Board and discusses the 2012 African Conference on Software Engineering and Applied Computing. The first Web extra at http://youtu.be/R5zUHUFEB7k is an audio interview of IEEE Software editor-in-chief Forrest Shull speaking with Ellen Gottesdiener and Mary Gorman about requirements management in an agile context. The second Web extra at http://youtu.be/SSO6td0xzkI is an audio interview of IEEE Software editor-in-chief Forrest Shull speaking with Philippe Kruchten about how software engineers can be misled by their own cognitive biases, falacial reasoning, and the games architects and requirements managers play.",1937-4194,,10.1109/MS.2013.27,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6470583,engineering values;principles;values;bias;Philippe Kruchten;Ellen Gottesdiener;Mary Gorman;Adam Welc;ASEAC;African Conference on Software Engineering and Applied Computing,,game theory;professional aspects;software architecture;software prototyping,engineering values;architecture games;agile requirements;professional principles;software development;cognitive biases;falacial reasoning,,,,,,25 Feb 2013,,,IEEE,IEEE Magazines
1171,1173,I Believe!,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,22 Dec 2011,2012,29,1,4,7,"Many studies have shown that important factors and key relationships often don't hold up well when transferred from one project to another. To deal with this seeming lack of global truisms in software engineering, it helps to develop a healthy skepticism and find ways to test our beliefs in key development practices against measures collected within the project context.",1937-4194,,10.1109/MS.2012.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111358,effort prediction;defect prediction;empirical software engineering,,,,,1.0,,4.0,,22 Dec 2011,,,IEEE,IEEE Magazines
1172,1174,Perspectives [The changing nature of software evolution; The inevitability of evolution],B. Boehm; K. Beck,University of Southern California; Three Rivers Institute,IEEE Software,14 Jun 2010,2010,27,4,26,29,"Summary form only given. Traditionally, software evolution took place after software development put a system in place. However, the pace of change in technology and competition has changed the nature of software evolution to a continuous process, in which there's no neat boundary between development and evolution. Many traditional software development assumptions and practices haven't recognized this changing nature and increasingly find themselves in deep trouble as a result. Minimizing development costs by adopting numerous off-the-shelf products often leads to unaffordable evolution costs as vendors ship new releases and stop supporting the old ones. Assuming that a single form of evolutionary development covers all situations often leads to unrealistic commitments and dead-end systems as situations change.",1937-4194,,10.1109/MS.2010.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5484112,software evolution;software engineering;software change;development,Programming;Costs;Lead;Marine vehicles,software engineering,software evolution;software development;off-the-shelf software products;evolutionary development,,8.0,,14.0,,14 Jun 2010,,,IEEE,IEEE Magazines
1173,1175,Looking into the Future,C. Ebert,Vector Consulting Services,IEEE Software,28 Oct 2015,2015,32,6,92,97,"Surveys of and interviews with software business leaders around the world point to success factors that will advance the software business over the next 30 years. However, the responses left unaddressed whether we evolve to Humanity 2.0-or a posthuman society.",1937-4194,,10.1109/MS.2015.142,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310986,software engineering;software development;software business,Software development;Market opportunities;Market research,social aspects of automation;software engineering,software business leaders;success factors;humanity 2.0;posthuman society,,7.0,,5.0,,28 Oct 2015,,,IEEE,IEEE Magazines
1174,1176,Lifelong Learning for Lifelong Employment,P. Kruchten,University of British Columbia,IEEE Software,30 Jun 2015,2015,32,4,85,87,"Software engineers today must be lifelong learners or risk finding themselves out of a job, with totally obsolete skills to sell. Here are a few hints on how to tackle continuous professional development in our field.",1937-4194,,10.1109/MS.2015.97,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140693,software development;software engineering;lifelong learning;professional development,Career development;Employment;Training;Engineering education,computer science education;continuing professional development;software engineering,lifelong learning;lifelong employment;software engineers;continuous professional development in our field,,5.0,,3.0,,30 Jun 2015,,,IEEE,IEEE Magazines
1175,1177,Barry O'Reilly on Lean Enterprises,J. Thönes,ThoughtWorks,IEEE Software,28 Oct 2015,2015,32,6,101,104,"Software Engineering Radio host Johannes Thönes and Barry O'Reilly, coauthor of Lean Enterprise: How High Performance Organizations Innovate at Scale, discuss lean enterprises. A lean enterprise is a large organization that manages to innovate while keeping its existing products in the market. The Web extra at http://www.se-radio.net/2015/08/se-radio-episode-234-barry-oreilly-on-lean-enterprise is an audio recording of Johannes Thönes talking to Barry O'Reilly, principal consultant at ThoughtWorks, about his recent book Lean Enterprise. A lean enterprise is a large organization that manages to keep innovating while keeping its existing products in the market.",1937-4194,,10.1109/MS.2015.140,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310997,lean enterprise;lean startups;three-horizons model;software development;software engineering,Interviews;Software engineering,,,,,,,,28 Oct 2015,,,IEEE,IEEE Magazines
1176,1178,The Mobile Software App Takeover,J. Voas; J. B. Michael; M. van Genuchten,NA; Naval Postgraduate School; Open Digital Dentistry,IEEE Software,10 Aug 2012,2012,29,4,25,27,"Smartphones aren't very “smart” without the software apps that give them their usability and versatility. Apps, like all software, need some degree of guidance, regulation, and measurement to ensure a user is receiving proper functionality and quality of service. This problem has existed in software engineering and software development from Day 1, and apps are no different. The void has led to a recent clamor for some way to vet apps and the app stores in which they will reside and be licensed. The guest editors of this special issue contend that this will be a huge problem for the mobile app market as it continues to grow; the articles they feature here attempt to address the challenges to come.",1937-4194,,10.1109/MS.2012.104,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6265078,software engineering;mobile devices;mobile apps,Special issues and sections;Mobile communication;Computer applications;Smart phones;Handheld devices;Cloud computing;Software engineering,,,,6.0,,2.0,,10 Aug 2012,,,IEEE,IEEE Magazines
1177,1179,Ben Hindman on Apache Mesos,J. Meyerson,,IEEE Software,29 Dec 2015,2016,33,1,117,120,"Software Engineering Radio host Jeff Meyerson talks to Ben Hindman about Apache Mesos, a kernel that abstracts away many of the hassles of managing a distributed system.",1937-4194,,10.1109/MS.2016.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367989,distributed system;abstraction;Apache Mesos;software engineering;software development,Software engineering;Distributed processing;Software development,,,,2.0,,,,29 Dec 2015,,,IEEE,IEEE Magazines
1178,1180,Microservices,J. Thönes,,IEEE Software,4 Feb 2015,2015,32,1,116,116,"In this excerpt from Software Engineering Radio, Johannes Thönes talks with James Lewis, principal consultant at ThoughtWorks, about microservices. They discuss microservices' recent popularity, architectural styles, deployment, size, technical decisions, and consumer-driven contracts. They also compare microservices to service-oriented architecture and wrap up the episode by talking about key figures in the microservice community and standing on the shoulders of giants. The Web extra at http://www.se-radio.net/2014/10/episode-213-james-lewis-on-microservices is an audio recording of Tobias Kaatz speaking with James Lewis, principal consultant at ThoughtWorks, about microservices. They discuss microservices' recent popularity, architectural styles, deployment, size, technical decisions, and consumer-driven contracts. They also compare microservices to service-oriented architecture and wrap up the episode by talking about key figures in the microservice community and standing on the shoulders of giants.",1937-4194,,10.1109/MS.2015.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030212,architecture;enterprise service bus;http;microservice;service-oriented architecture;software engineering;SE Radio,Interviews;Software architecture;Service oriented architecture;Software engineering,,,,95.0,2.0,,,4 Feb 2015,,,IEEE,IEEE Magazines
1179,1182,The Wonder Years,G. Booch,IBM,IEEE Software,26 Jun 2013,2013,30,4,16,17,"For those on the outside of the curtain of computing, there is much mystery behind the matter of software-intensive systems. To some, it looks like magic; to most, its inner workings are irrelevant in so far that it simply works. To those of us behind the curtain, however, we know that such systems are filled with chaos, regularity, and beauty. The first Web extra at http://youtu.be/HfGVE3kt8Og is an audio podcast of author Grady Booch reading his On Computing column, in which he peers behind the curtain of computing into the mystery behind software-intensive systems. To some, such systems look like magic; to most, the inner workings are irrelevant insofar that they simply work. To those of us behind the curtain, however, we know that such systems are filled with chaos, regularity, and beauty. The second Web extra at http://youtu.be/52ztwEAcmAA is a video in which Tim O'Reilly, CEO and founder of O'Reilly Media, and Grady Booch, IBM Fellow, IBM Chief Scientist for Software Engineering, and author of On Computing in IEEE Software magazine, speak with James Governor about the next stage of development of mobile apps and the focus on development practitioners prior to the IBM Impact 2013 Unconference, sponsored by IEEE Software magazine.",1937-4194,,10.1109/MS.2013.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547632,software-intensive system;mystery;education;discovery;fundamentals,,mobile computing;software engineering,software-intensive systems;software engineering;IEEE Software magazine;mobile apps development;IBM Impact 2013 Unconference,,,,,,26 Jun 2013,,,IEEE,IEEE Magazines
1180,1183,Bridging Software Communities through Social Networking,A. Begel; J. Bosch; M. Storey,Microsoft Research; Chalmers University of Technology; University of Victoria,IEEE Software,3 Jan 2013,2013,30,1,26,28,"Over the past decade, the advent of social networking has fundamentally altered the landscape of how software is used, designed, and developed. It has expanded how communities of software stakeholders communicate, collaborate, learn from, and coordinate with one another. The guest editors of this special issue describe both the field and the articles they selected for it.",1937-4194,,10.1109/MS.2013.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401112,social networking;software;communities;stakeholders;communication,Special issues and sections;Software engineering;Social network services;Software development,social networking (online);software engineering,software communities;social networking;software stakeholders,,9.0,,5.0,,3 Jan 2013,,,IEEE,IEEE Magazines
1181,1184,Hiring in the Software Industry,T. Kaatz,"CSC, Germany",IEEE Software,7 Nov 2014,2014,31,6,96,96,"With this episode, Software Engineering Radio begins a series of interviews on the social or nontechnical aspects of working as a software engineer. Tobias Kaatz talks to Randy Shoup, who is the former CTO at Kixeye and before that served as Google's director of engineering for its Cloud Computing Group, about hiring in the software industry. The Web extra at http://www.se-radio.net/2014/08/episode-208-randy-shoup-on-hiring-in-the-software-industry is an audio recording of Tobias Kaatz speaking with Randy Shoup, former CTO at KIXEYE, about hiring in the software industry.",1937-4194,,10.1109/MS.2014.140,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949527,Google;hiring;job interviews;Kixeye;Randy Shoup;software engineering;SE Radio,Employment;Career development;Engineering profession,DP industry;employment;software radio,hiring;software industry;software engineering radio;social aspects;nontechnical aspects;Randy Shoup;CTO;Kixeye;Cloud Computing Group;Tobias Kaatz,,,,,,7 Nov 2014,,,IEEE,IEEE Magazines
1182,1185,Sustainability and Requirements: A Manifesto,B. Penzenstadler,"California State University, Long Beach",IEEE Software,21 Aug 2015,2015,32,5,90,92,"""The Karlskrona Manifesto on Sustainability Design"" is a call for discussion and action on the challenge of sustainability and its relation to software engineering. The manifesto aims to create common ground and develop a reference point for the global community of research and practice in software and sustainability. The Web extra at http://youtu.be/PXhFgswJPco is an audio podcast in which author Birgit Penzenstadler provides an audio recording of this column.",1937-4194,,10.1109/MS.2015.114,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217768,sustainability;software requirements;Karlskrona Manifesto;software design;software engineering;software development,,formal specification;sustainable development,requirements;Karlskrona Manifesto;sustainability design;software engineering,,2.0,,5.0,,21 Aug 2015,,,IEEE,IEEE Magazines
1183,1186,Our Best Hope,F. Shull,Software Engineering Institute of Carnegie Mellon University,IEEE Software,13 Jun 2014,2014,31,4,4,8,IEEE Software editor in chief Forrest Shull talks with author and consultant Linda Rising about the power of retrospectives for software teams. The Web extra at http://youtu.be/2Tgui-qr2AQ is an audio recording of IEEE Software editor in chief Forrest Shull talking with author and consultant Linda Rising about the power of retrospectives for software teams. The second Web extra at http://www.se-radio.net/2014/01/episode-200-markus-volter-on-language-design-and-domain-specific-languages/ is an audio recording of Markus Voelter talking to Linda Rising about retrospectives and the logistics of making them work for software projects.,1937-4194,,10.1109/MS.2014.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834710,software engineering;Linda Rising;retrospective;agile;practices;change;projects;Norman Keith,,,,,,,,,13 Jun 2014,,,IEEE,IEEE Magazines
1184,1187,The Human Element in Social Networking,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,3 Jan 2013,2013,30,1,2,6,"IEEE Software Editor in Chief Forrest Shull discusses his interviews with Ben Schneiderman on the social networking site the Nation of Neighbors and with Anne Rose on the International Children's Digital Library and lessons learned from both websites on how developers can best design social networks to award volunteer appreciation, thus ensuring continued success. The first Web extra at http://youtu.be/yFG3lL6HJ38 is an audio interview of IEEE Software editor-in-chief Forrest Shull speaking with Ben Shneiderman about the Nation of Neighbors Project and lessons learned about software that supports effective social networks. The Nation of Neighbors is an ambitious program that facilitates real-time collaboration in more than 400 neighborhood communities across the United States. The second Web extra at http://youtu.be/M3R4-XLBRyE is an audio interview of IEEE Software editor-in-chief Forrest Shull speaking with Anne Rose about the International Childrens Digital Library and lessons learned about supporting effective social networks. The ICDL is visited by up to 130,000 unique users per month and relies on the efforts of an impassioned network of more than 4,000 volunteers worldwide.",1937-4194,,10.1109/MS.2013.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401105,social networks;development;software;nation of neighbors;international children's digital library;software engineering,,digital libraries;social networking (online),human element;social networking;Nation of Neighbors;digital library;Web sites,,,,2.0,,3 Jan 2013,,,IEEE,IEEE Magazines
1185,1188,Looking Forward,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,21 Aug 2012,2012,29,5,2,5,Editor in chief Forrest Shull describes the decisions made at the magazine's most recent editorial board meeting and the exciting changes to come for this publication's digital edition. He also highlights winners of recent IEEE Software-sponsored awards.,1937-4194,,10.1109/MS.2012.117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6276290,software engineering;editorial board;awards;digital publication,,,,,,,,,21 Aug 2012,,,IEEE,IEEE Magazines
1186,1189,Designing a World at Your Fingertips: A Look at Mobile User Interfaces,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,10 Aug 2012,2012,29,4,4,7,"Smart mobile devices have had a huge impact on the world today with new apps being produced at a prodigious rate. How we got to this point has a lot to do with the ease of use that manufacturers and app developers have achieved, which includes aspects such as quick response time, intuitive interfaces, and well-designed functionality. To explore how this came about, IEEE Software Editor-in-Chief Forrest Shull recently spoke with Ben Shneiderman and Ben Bederson, both of whom are former directors of the University of Maryland's Human-Computer Interaction Lab (HCIL), the oldest center in the US focusing on research in HCI.",1937-4194,,10.1109/MS.2012.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6265071,software;engineering;smart phones;mobile devices;apps;functionality;interfaces;hci;human-computer interaction;lab;HCIL,,,,,1.0,,,,10 Aug 2012,,,IEEE,IEEE Magazines
1187,1190,A Lifetime Guarantee,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,28 Oct 2013,2013,30,6,4,8,"IEEE Software editor-in-chief Forrest Shull discusses the software sustainability and his interview with Girish Seshagiri, the CEO of AIS, an organization that offers ""firm fixed-price contracting with performance guarantees, including a lifetime warranty on software defects"" in government contracts. In addition, he discusses the best paper award at the 21st Annual IEEE International Requirements Engineering Conference and the best research paper award at the Agile Conference. The first Web extra at http://youtu.be/L1XN0R4koRk is an audio interview highlighting IEEE Software editor in chief Forrest Shull's discussion with Girish Seshagiri, the CEO of AIS, about the organization's philosophy of offering ""firm fixed-price contracting with performance guarantees, including a lifetime warranty on software defects"" in government contracts. The second Web extra at http://youtu.be/iFsZlrhSM9E is the complete audio interview in which IEEE Software editor in chief Forrest Shull's speaks with Girish Seshagiri, the CEO of AIS, about the organization's philosophy of offering ""firm fixed-price contracting with performance guarantees, including a lifetime warranty on software defects"" in government contracts.",1937-4194,,10.1109/MS.2013.119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648577,sustainability;ais;Girish Seshagiri;software quality;defects;government contracts;requirements engineering;agile;best paper ieee software;software;research;practice;practical;software engineering;software development,,,,,1.0,,,,28 Oct 2013,,,IEEE,IEEE Magazines
1188,1191,The Road Ahead,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,20 Dec 2010,2011,28,1,2,4,"The new editor in chief of IEEE Software magazine briefly outlines his vision for the future, including items regarding new digital content and possibilities for reader-author interaction. This EIC message also contains an erratum to the Nov./Dec. 2010 article, ""Visual Tools for Software Architecture Understanding: A Stakeholder Perspective,"" by Alexandru Telea, Lucian Voinea, SolidSource BV, and Hans Sassenburg. The erratum corrects a URL in Figure 1.",1937-4194,,10.1109/MS.2011.18,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672510,software;software engineering;EIC;editorial,,,,,,,,,20 Dec 2010,,,IEEE,IEEE Magazines
1189,1192,Refactoring Tools are Trustworthy Enough and Trust Must be Earned,J. Brant; F. Steimann,"FernUniv. in Hagen, Hagen, Germany; Fernuniversität in Hagen",IEEE Software,28 Oct 2015,2015,32,6,80,83,"In his Point essay, ""Refactoring Tools Are Trustworthy Enough,"" John Brant argues that refactoring tools that help developers work more efficiently is more important than tools that preserve behavior. In his Counterpoint essay, ""Trust Must Be Earned,"" Friedrich Steimann argues that current refactoring tools are unreliable and that developers should give their best to create refactoring tools that are correct. This article is part of a special issue on Refactoring.",1937-4194,,10.1109/MS.2015.145,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310993,refactoring;software development;software engineering,Code refractoring;Software development;Software engineering,software tools,refactoring tools;imperfect tools,,2.0,,,,28 Oct 2015,,,IEEE,IEEE Magazines
1190,1193,The Persistence of Memory,G. Booch,IBM,IEEE Software,7 Nov 2014,2014,31,6,38,40,"Each generation remakes itself. In the context of the historical, economic, technological, and cultural forces around it, each generation must confront, adapt, and evolve--or die; this is the nature of humankind. Still, some common threads exist that shape that evolution--threads that define our very humanity. Even in the face of the tumultuous changes brought about by computing, these threads persist and bring a poignant texture to a fully digital life. The Web extra at http://youtu.be/nsInmRVIlv0 is an audio podcast of author Grady Booch reading his On Computing column, in which he discusses how even in the face of the tumultuous changes brought about by computing, the threads that define our very humanity still persist and bring a poignant texture to a fully digital life.",1937-4194,,10.1109/MS.2014.148,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949575,software engineering;computing;commerce;architecture;history,Software engineering;Software architecture;History;Technology forecasting,,,,,,,,7 Nov 2014,,,IEEE,IEEE Magazines
1191,1194,Remembrance of Things Past,G. Booch,,IEEE Software,29 Dec 2015,2016,33,1,10,12,"We live in a world of unprecedented complexity and astonishing possibility. We should never forget our past, for those who came before us in computing enabled those possibilities. The Web extra at https://youtu.be/-ovLxiHmbr0 is an audio podcast of this column.",1937-4194,,10.1109/MS.2016.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7367979,history;Alan Turing;Bletchley Park;Tommy Flowers;Grace Hopper;history of computing;women in computing;software engineering;software development,"History;Computer industry;Software engineering;Turing, Alan;Codes",,,,,,7.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1192,1195,All Watched Over by Machines of Loving Grace,G. Booch,IBM,IEEE Software,10 Mar 2015,2015,32,2,19,21,"There was a time we could only dream of machines that served as companions, as helpmates, as servants. Now, we build them. As we slowly and inevitably and irreversibly surrender to these machines of our own creation, we must come to grips with a number of practical, ethical conundrums. The Web extra at http://youtu.be/17MsuJY4Xmo is an audio podcast of author Grady Booch reading his On Computing column, in which he discusses how we must come to grips with a number of practical and ethical conundrums as machines of our own creation become our companions, helpmates, and servants.",1937-4194,,10.1109/MS.2015.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057613,software engineering;computing;ethics of computing;morality,Software engineering;Ethics,ethical aspects,ethical conundrums;Web extra;audio podcast;On Computing column;practical conundrums,,3.0,,7.0,,10 Mar 2015,,,IEEE,IEEE Magazines
1193,1196,The Top 10 Burning Research Questions from Practitioners,S. Freudenberg; H. Sharp,"independent agile coach; Open University, Milton Keynes, UK",IEEE Software,19 Aug 2010,2010,27,5,8,9,"A common and frequent complaint from software practitioners is that academic research doesn't meet their requirements or expectations. During XP 2010 in Trondheim this year, practitioners were asked to suggest research topics that they'd like to see addressed. Around 60 different suggestions were made. They were collected and displayed so that attendees at the conference could vote for their favorite topic, and from this we developed a prioritized backlog of research issues. This article presents the top ten issues according to the voting, discusses the range of themes across the complete set of suggestions, and poses several questions that need answering for this backlog to be processed. The Web extra is an erratum to the acknowledgments.",1937-4194,,10.1109/MS.2010.129,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551011,agile;XP 2010;research;distributed;scaling agile;software engineering;general interest and relevance,Research and development;Software engineering;Distributed processing;Technological innovation;Technology,,,,14.0,,,,19 Aug 2010,,,IEEE,IEEE Magazines
1194,1197,Harnessing UML for Architectural Description--the Context View,E. Woods,Artechra,IEEE Software,7 Nov 2014,2014,31,6,30,33,This column discusses architectural descriptions and the process of representing and communicating designs and how UML is useful when creating architectural descriptions.,1937-4194,,10.1109/MS.2014.139,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949558,software engineering;UML;architecture;modeling,Unified modeling language;Context modeling;Software architecture;Software engineering;Modeling,software architecture;Unified Modeling Language,UML;architectural descriptions,,4.0,,3.0,,7 Nov 2014,,,IEEE,IEEE Magazines
1195,1198,Code Ownership Perspectives,S. Eldh; B. Murphy,Ericsson; Microsoft Research,IEEE Software,28 Oct 2015,2015,32,6,18,19,"In the essay ""Code Ownership-a Quality Issue,"" Sigrid Eldh argues for adapting code ownership to specific situations, focusing on quality, and taking into account ownership of the test code. In the essay ""Code Ownership-More Complex to Understand Than Research Implies,"" Brendan Murphy argues for a broader and deeper analysis of code ownership.",1937-4194,,10.1109/MS.2015.141,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310992,code ownership;code quality;software quality;software development;software engineering,Code refractoring;Encoding;Software engineering;Software development,computer software;copyright,code ownership perspectives,,,,,,28 Oct 2015,,,IEEE,IEEE Magazines
1196,1199,"Developer, Debug Thyself",D. Spinellis,,IEEE Software,29 Dec 2015,2016,33,1,3,5,"The risks of misbehaving software have been with us for decades but are now becoming too ubiquitous to casually brush under the carpet. We must act now; otherwise, the next software scandal might take down software development as we know it.",1937-4194,,10.1109/MS.2016.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368033,Volkswagen;VW;software development;software engineering;open source;government regulation;professional ethics;diesel engines;VW diesel engine;defeat device,Software development;Companies;Software engineering;Automobile industry;Diesel engines;Maintenance engineering,,,,1.0,,1.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1197,1201,Editorial,B. Nuseibeh,,IEEE Transactions on Software Engineering,28 Aug 2013,2013,39,9,1187,1189,"IT is my pleasure to introduce a number of distinguished researchers to the Editorial Board of IEEE Transactions on Software Engineering (TSE) this month. Their expertise covers a range of of areas that have seen consistently large numbers of submissions in recent times, and each new associate editor (AE) brings a track record of significant contributions to their field. Their short biographies are provided. Additionally, I am happy to report in the meantime that the latest journal Impact Factors have recently been published, and TSE's has risen to 2.6. It continues to be the highest of all software engineering and related journals.",1939-3520,,10.1109/TSE.2013.41,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6587460,,,,,,,,,,28 Aug 2013,,,IEEE,IEEE Journals
1198,1202,Editorial [new associate editors],B. Nuseibeh,,IEEE Transactions on Software Engineering,29 Apr 2013,2013,39,5,588,590,"It is the Editor-in-Chief's (EiC's) pleasure to welcome a number of new associate editors to the editorial board of the IEEE Transactions on Software Engineering. They are: Luciano Baresi, Daniela Damian, Robert DeLine, Audris Mockus, Gail Murphy, Mauro Pezze, Gian Pietro Pico, Helen Sharp, and Paolo Tonella. They bring a wealth of expertise in a broad range of research areas within software engineering, consolidating traditional strengths in areas such as software testing, and strengthening areas such as empirical studies of software development, mobile computing, and adaptive systems. Short professional biographies are included. At the same time, the EiC would like to bid farewell to those associate editors whose terms of service have ended: Martin Robillard, Peggy Storey, and Tetsuo Tamai. He thanks them for their distinguished contributions over a number of years, and for continuing to handle submitted manuscripts already on their editorial stack.",1939-3520,,10.1109/TSE.2013.22,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6509892,,,,,,,,,,29 Apr 2013,,,IEEE,IEEE Journals
1199,1203,Collaborations and Code Reviews,J. C. Carver; B. Caglayan; M. Habayeb; B. Penzenstadler; A. Yamashita,"University of Alabama; Ryerson University; Ryerson University; California State University, Long Beach; Yamashita Research",IEEE Software,21 Aug 2015,2015,32,5,27,29,This article discusses five papers presented at events connected with the 2015 International Conference on Software Engineering. The papers cover topics related to industry-academic collaborations and modern code review.,1937-4194,,10.1109/MS.2015.113,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217781,software engineering;industry-academic collaboration;code review;ICSE;2015 International Conference on Software Engineering;feedback cycles;changesets;ClusterChanges;software bugs,,,,,,,,,21 Aug 2015,,,IEEE,IEEE Magazines
1200,1204,James Phillips on Service Discovery,C. Anderson,,IEEE Software,28 Oct 2016,2016,33,6,117,120,"In this excerpt from a Software Engineering Radio podcast, James Phillips, who works on the open source service discovery tool Consul at HashiCorp, explains what service discovery is, provides use cases, and discusses available tools. You can listen to the entire interview at <url>www.se-radio.net</url>.",1937-4194,,10.1109/MS.2016.150,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725237,James Phillips;service discovery;Consul;software engineering;software development;Software Engineering Radio,Servers;IP networks;Databases;Interviews;Computer architecture;Internet,,,,,,,,28 Oct 2016,,,IEEE,IEEE Magazines
1201,1205,Software Architecture for Developers,S. Johann,Trifork Amsterdam,IEEE Software,21 Aug 2015,2015,32,5,93,96,"In Episode 228 of Software Engineering Radio, Sven Johann and Simon Brown discuss using sketches to create and communicate software architecture.",1937-4194,,10.1109/MS.2015.125,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217764,SE radio;Software Engineering Radio;Simon Brown;Sven Johann;software architecture;C4;Software Architecture for Developers;UML;software engineering;software development,,,,,,,,,21 Aug 2015,,,IEEE,IEEE Magazines
1202,1206,"Requirements, Human Values, and the Development Technology Landscape",J. C. Carver; L. L. Minku; B. Penzenstadler,"University of Alabama; University of Leicester; California State University, Long Beach",IEEE Software,16 Jan 2017,2017,34,1,13,15,"This issue's column reports on papers from the 24th International Requirements Engineering Conference, 38th International Conference on Software Engineering, and the 10th International Symposium on Empirical Software Engineering and Measurement. Topics include performance and security requirements, injecting human values into software engineering, and mapping the software development technology landscape.",1937-4194,,10.1109/MS.2017.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819412,software requirements;security requirements;social engineering;sentence patterns;serious games;human values;software engineering;software development;Stack Overflow;association rule mining;natural-language processing,,,,,,,,,16 Jan 2017,,,IEEE,IEEE Magazines
1203,1207,In Memoriam: Robin Milner and Amir Pnueli,B. Nuseibeh,,IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,305,305,"Provides the biographies for two members of the computing community, Robin Milner and Amir Pnueli, who recently passed away. Both were Turing Award winners and both contributed in fundamental ways to the foundations of software engineering.",1939-3520,,10.1109/TSE.2010.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473899,,Obituary;Robin Milner and Amir Pnueli,,,,,,,,27 May 2010,,,IEEE,IEEE Journals
1204,1208,elytS edoC detisiveR,,,IEEE Software,23 Jun 2011,2011,28,4,7,8,"Phillip G. Armour responds to a Tools of the Trade column by Diomidis Spinellis called ""elytS edoC"" in the March/April 2011 issue of IEEE Software, discussing the coding styles of software engineering. In another letter, Stefan Braun responds to a Letter from the Editor column by Forrest Shull called ""Perfectionists in a World of Finite Resources,"" in the March/April 2011 issue of IEEE Software, discussing the concept of technical debt in the world of software engineering.",1937-4194,,10.1109/MS.2011.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929520,software engineering;coding;technical debt;letters;IEEE Software,,,,,,,,,23 Jun 2011,,,IEEE,IEEE Magazines
1205,1209,Guest Editors' Introduction to the Special Section on Software Language Engineering,J. Favre; D. Gasević; R. Lammel; A. Winter,NA; NA; NA; NA,IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,737,741,The six articles in this special section are devoted to software language engineering.,1939-3520,,10.1109/TSE.2009.78,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5353438,,History;Natural languages;Writing;Humans;Production;Food technology;Information technology;Systems engineering and theory;Software engineering;Domain specific languages,,,,3.0,,8.0,,15 Dec 2009,,,IEEE,IEEE Journals
1206,1210,Stakeholders on the Prowl,J. Cleland-Huang,DePaul University,IEEE Software,26 Feb 2016,2016,33,2,29,31,Working with diverse stakeholders is a fact of life for any requirements engineer. And learning to bring out the best in each of them is an art acquired over time. This article shares effective stakeholder interaction techniques for solving three common problems. The Web extra at https://youtu.be/1df3HmRTbBk is an audio podcast in which author Jane Cleland-Huang provides an audio recording of the Requirements column.,1937-4194,,10.1109/MS.2016.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420494,software requirements;software engineering;agile software engineering;software development;requirements engineering;requirements elicitation,,formal specification,stakeholder interaction techniques;Web extra;requirements column,,4.0,,7.0,,26 Feb 2016,,,IEEE,IEEE Magazines
1207,1211,On Target,,,IEEE Software,15 Sep 2014,2014,31,5,8,8,"Ivan Sanchez, a student from Guayaquil, Ecuador, writes a letter thanking the editor for the continued publication of Grady Booch's columns, first On Architecture and now On Computing.",1937-4194,,10.1109/MS.2014.117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898683,software engineering;grady booch;computing;architecture,,,,,,,,,15 Sep 2014,,,IEEE,IEEE Magazines
1208,1212,Vaughn Vernon on Reactive Programming with the Actor Model,S. Tilkov,innoQ,IEEE Software,25 Apr 2016,2016,33,3,109,112,"Host Stefan Tilkov speaks with Vaughn Vernon, a consultant and mentor with more than 25 years' experience in software design, development, and architecture, about reactive programming and the actor model.",1937-4194,,10.1109/MS.2016.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458769,Vaughn Vernon;software development;software engineering;reactive programming;actor model;Software Engineering Radio,,,,,1.0,,,,25 Apr 2016,,,IEEE,IEEE Magazines
1209,1213,Software Analytics: So What?,T. Menzies; T. Zimmermann,West Virginia University; Microsoft Research,IEEE Software,26 Jun 2013,2013,30,4,31,37,"The guest editors of this special issue of IEEE Software invited submissions that reflected the benefits (and drawbacks) of software analytics, an area of explosive growth. They had so many excellent submissions that they had to split this special issue into two volumes--you'll see even more content in the September/October issue. They divided the articles on conceptual grounds, so both volumes will feature equally excellent work. The Web extra at http://youtu.be/nO6X0azR0nw is a video interview in which IEEE Software editor in chief Forrest Shull speaks with Tim Menzies about the growing importance of software analytics.",1937-4194,,10.1109/MS.2013.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547619,software analytics;big data;analysis;metrics;measurement,Special issues and sections;Data analysis;Decision making;Data models;Software development;Software algorithms;Software engineering,program diagnostics;software engineering,software analytics;IEEE Software;explosive software growth,,68.0,,10.0,,26 Jun 2013,,,IEEE,IEEE Magazines
1210,1214,Diversity and Software Development,H. Erdogmus,National Research Council Canada,IEEE Software,17 Apr 2009,2009,26,3,2,4,"Scott E. Page's diversity framework provides useful insights regarding software engineering research, practice, and education. This editorial discusses the concepts and implications of diversity in this context.",1937-4194,,10.1109/MS.2009.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814948,diversity;software engineering;problem solving;software estimation;regression models,Programming;Problem-solving;Predictive models;Software safety;Decision making;Economic forecasting,,,,,,,,17 Apr 2009,,,IEEE,IEEE Magazines
1211,1215,The Elusiveness of Smart Healthcare,D. Spinellis,Athens University of Economics and Business,IEEE Software,13 Nov 2017,2017,34,6,4,6,"To realize smart healthcare’s many benefits, researchers and practitioners must overcome significant hurdles. The problems they face mirror the challenges of the field of software engineering in a world gradually eaten up by software.",1937-4194,,10.1109/MS.2017.4121206,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106889,smart healthcare;software development;software engineering;From the Editor,,,,,,,,,13 Nov 2017,,,IEEE,IEEE Magazines
1212,1216,IEEE Software and Professional Development,I. Sommerville,,IEEE Software,26 Feb 2016,2016,33,2,90,92,"To become more relevant to both researchers and practitioners, IEEE Software should refocus and become the first place software engineers turn to for professional development in software engineering and related areas.",1937-4194,,10.1109/MS.2016.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420501,IEEE Software;software development;software engineering;professional development,,,,,,,4.0,,26 Feb 2016,,,IEEE,IEEE Magazines
1213,1217,Reliability Engineering,X. Larrucea; F. Belmonte; A. Welc; T. Xie,Tecnalia; Alstom Transport; Huawei; University of Illinois at Urbana-Champaign,IEEE Software,11 Jul 2017,2017,34,4,26,29,"Reliability engineering dates back to reliability studies in the 20th century; since then, various models have been defined and used. Software engineering plays a key role from several viewpoints, but the main concern is that we're moving toward a more connected world, including enterprises and mobile devices. The three articles in this special issue illustrate current trends in this domain.",1937-4194,,10.1109/MS.2017.89,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974694,reliability engineering;software reliability;software reliability growth models;regression testing;safety-critical systems;state-space models;requirements engineering;fault tree analysis;failure mode and effects analysis;software engineering;software development,Special issues and sections;Reliability engineering;Safety;Mission critical systems,,,,2.0,,17.0,,11 Jul 2017,,,IEEE,IEEE Magazines
1214,1218,"Managing Montezuma: Handling All the Usual Challenges of Software Development, and Making It Fun: An Interview with Ed Beach",F. Shull,Fraunhofer Center for Experimental Software,IEEE Software,18 Aug 2011,2011,28,5,4,7,EIC Forrest Shull interviews AI lead programmer Ed Beach to investigate the software engineering practices employed to create computer gaming software that is both high quality and fun. This interview focuses on the context of the best-selling Civilization series of games created by Firaxis Inc.,1937-4194,,10.1109/MS.2011.103,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984786,software engineering;artificial intelligence;computer gaming,,,,,,,,,18 Aug 2011,,,IEEE,IEEE Magazines
1215,1219,Did 32% Waterfall Surprise You?,,,IEEE Software,16 Jan 2017,2017,34,1,7,7,This issue's letter discusses the proper use of sampling in software engineering research surveys.,1937-4194,,10.1109/MS.2017.10,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819417,waterfall model;software development;software engineering;convenience sampling,,,,,,,,,16 Jan 2017,,,IEEE,IEEE Magazines
1216,1220,How Do You Keep Up to Date?,F. Shull,Fraunhofer Center for Experimental Software,IEEE Software,25 Apr 2011,2011,28,3,2,5,"Keeping up to date with new software engineering methods, practices, and tools is challenging in the best of times, and made even more urgent by today's tough economic climate. This article discusses a survey of software developers and describes high-level themes related to the types of media that were deemed useful for staying up to date. Based on these themes, some important thrusts for IEEE Software digital content are described.",1937-4194,,10.1109/MS.2011.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5756287,software engineering;survey;professional development,,,,,,,,,25 Apr 2011,,,IEEE,IEEE Magazines
1217,1221,Trends in Systems and Software Variability [Guest editors' introduction],J. Bosch; R. Capilla; R. Hilliard,Chalmers University of Technology; Rey Juan Carlos University; consulting software systems architect,IEEE Software,23 Apr 2015,2015,32,3,44,51,"The two articles in this special section address the topic of systems and software vaiability. Variability management involves two key challenges. First, industrial reality shows that for successful platforms, the number of variation points, variants (alternatives that can be selected for a variation point), and dependencies between variation points and variants easily reaches staggering levels.",1937-4194,,10.1109/MS.2015.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093024,software variability;systems variability;software engineering;software development;software product lines;FODA;Feature-Oriented Domain Analysis;binding time;software requirements;software architecture,Special issues and sections;Software architecture;Software engineering;Software development;Analytical models;Software variability,,,,23.0,,28.0,,23 Apr 2015,,,IEEE,IEEE Magazines
1218,1222,A Decade of Enterprise Integration Patterns: A Conversation with the Authors,O. Zimmermann; C. Pautasso; G. Hohpe; B. Woolf,"University of Applied Sciences of Eastern Switzerland, Rapperswil; University of Lugano; Allianz; IBM",IEEE Software,29 Dec 2015,2016,33,1,13,19,"Department editors Olaf Zimmerman and Cesare Pautasso interview Gregor Hohpe and Bobby Woolf, authors of Enterprise Integration Patterns. They discuss the book's impact, pattern language design, message-oriented middleware, integration technology's evolution, and the authors' future plans.",1937-4194,,10.1109/MS.2016.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368007,Enterprise Integration Patterns;software patterns;Gregor Hohpe;Bobby Woolf;Martin Fowler;pattern languages;message-oriented middleware;integration technology;software engineering;software development,Software engineering;Software development;Middleware;Message systems;Pattern recognition,,,,4.0,,12.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1219,1223,Guest Editors' Introduction to the Special Section on Evaluation and Improvement of Software Dependability,K. Goseva-Popstojanova; K. Kanoun,"Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, WV; LAAS-CNRS, 31077 Toulouse, France",IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,306,308,The four papers in this special section present new findings on different aspects of software dependability.,1939-3520,,10.1109/TSE.2010.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473900,,Software systems;Information security;Safety;Software testing;Medical control systems;Control systems;Humans;Software quality;Availability;Airplanes,,,,1.0,,51.0,,27 May 2010,,,IEEE,IEEE Journals
1220,1226,[Back cover],,,IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,c4,c4,Provides a listing of current committee members and society officers.,1939-3520,,10.1109/TSE.2012.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363460,,,,,,,,,,29 Nov 2012,,,IEEE,IEEE Journals
1221,1231,Introduction: The Best Papers of ISSTA,B. G. Ryder; A. Zeller,NA; NA,IEEE Transactions on Software Engineering,29 Jul 2010,2010,36,4,451,452,We present the best papers of the International Symposium on Software Testing and Analysis (ISSTA) 2008.,1939-3520,,10.1109/TSE.2010.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5532338,,Software testing;System testing;Sections;Electronic equipment testing;Electronic voting;Humans;Computer science;Computer industry;Security;Electronic voting systems,,,,,,,,29 Jul 2010,,,IEEE,IEEE Journals
1222,1233,State of the Journal Editorial,M. B. Dwyer,,IEEE Transactions on Software Engineering,7 Jan 2015,2015,41,1,1,2,Reports on the state of the journal.,1939-3520,,10.1109/TSE.2014.2380479,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7004121,,,,,,,,,,7 Jan 2015,,,IEEE,IEEE Journals
1223,1234,Guest Editors' Introduction to the Special Issue on Quantitative Evaluation of Computer Systems,J. Hillston; M. Kwiatkowska; M. Telek,NA; NA; NA,IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,145,147,The 10 items in this special issue focus on quantitative evaluation of computer systems.,1939-3520,,10.1109/TSE.2009.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809711,,Stochastic processes;Performance analysis;Petri nets;Queueing analysis;Stochastic systems;Discrete event simulation;Protocols;Performance evaluation;Air traffic control;Computational modeling,,,,,,,,3 Apr 2009,,,IEEE,IEEE Journals
1224,1235,[Front inside cover],,,IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,c2,c2,Provides a listing of current society officers.,1939-3520,,10.1109/TSE.2012.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6141069,,,,,,,,,,30 Jan 2012,,,IEEE,IEEE Journals
1225,1237,Guest Editors' Introduction to the Special Section from the International Conference on Software Maintenance,G. Canfora; L. Tahvildari; H. A. Muller,NA; NA; NA,IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,450,451,"The two papers in this special section are extended and enhanced versions of ones presented at the International Conference on Software Maintenance (ICSM), held in Paris, France, on 2-5 October 2007.",1939-3520,,10.1109/TSE.2009.49,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5186362,,Software maintenance;Computer Society;Conferences;Computer science;Software testing;Tagging;Programming profession;Navigation;Cities and towns;Sections,,,,,,,,31 Jul 2009,,,IEEE,IEEE Journals
1226,1240,Guest Editorial: Special Section on the International Symposium on Software Testing and Analysis 2010,A. Orso; P. Tonella,"Georgia Institute of Technology, 266 Ferst Drive, Atlanta, GA 30332-0765; Fondazione Bruno Kessler, Via Sommarive, 18, 38123 Povo, Trento, Italy",IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,241,242,The articles in this special section contain selected papers from the International Symposium on Software Testing and Analysis 2010.,1939-3520,,10.1109/TSE.2012.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173077,,Special issues and section;Meetings;Software testing,,,,,,,,3 Apr 2012,,,IEEE,IEEE Journals
1227,1241,Guest Editors' Introduction: Algorithms and Today's Practitioner,G. Prencipe; C. Zavattari; A. Tommasi; J. Favaro,"University of Pisa; CrowdEngineering, Pisa; CrowdEngineering, Pisa; Intecs SpA",IEEE Software,22 Dec 2011,2012,29,1,61,63,"Enormous advances in computing power and programming environments have obscured the importance of algorithms, one of the foundational pillars of software engineering. Today, even university curricula too often pay only lip service to the teaching of algorithmic fundamentals, reinforcing the popular belief that their place at the core of a software engineer's education is past. Yet even today, the importance of algorithms in software engineering has not diminished, and the effects of neglect are evident everywhere in needlessly inefficient industrial applications. The study of algorithms must regain its rightful place of central importance in the everyday work of today's practitioner.",1937-4194,,10.1109/MS.2012.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6111366,algorithm;software;efficiency;complexity,Special issues and sections;Software algorithms;Internet;Software engineering;Data structures,,,,,,,,22 Dec 2011,,,IEEE,IEEE Magazines
1228,1242,Code Inflation,G. J. Holzmann,NASA/JPL,IEEE Software,10 Mar 2015,2015,32,2,10,13,Much of the increase in the size of software applications is unnecessary. The history of the tiny Unix /bin/true command illustrates this growth.,1937-4194,,10.1109/MS.2015.40,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057573,software development;true command;code size;Unix,Encoding;Software development;Unix;Codes,software engineering;Unix,code inflation;software applications;Unix /bin/true command,,1.0,,,,10 Mar 2015,,,IEEE,IEEE Magazines
1229,1243,Guest Editor's Introduction: How Open Source Tools Can Benefit Industry,C. Ebert,Vector Consulting Services,IEEE Software,24 Feb 2009,2009,26,2,50,51,"The software industry has evolved toward complex supplier-user networks that cooperate and collaborate in many ways. We hardly see any longer the traditional way of software development in which one company handles design, production, sales, delivery, and service. Business models, engineering life cycles, distribution channels, and services have changed dramatically. A key driver in these new value networks is open source software (OSS). Open source refers to software that we may freely use, modify, or distribute, provided we observe certain restrictions with respect to copyright and protection of its open source status. OSS is not freeware and generally has a copyright. IEEE Software, through this paper, has assembled this minitheme to provide a glimpse of where OSS is heading.",1937-4194,,10.1109/MS.2009.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4786952,open source;open source software;software forge;community source;OSS project management tools;CMMI;dotProject,Open source software;Project management;Collaborative software;Software tools;Software quality;Employment;Engineering management;Computer industry;Ecosystems;Open source hardware,public domain software;software engineering,software industry;complex supplier-user networks;software development;open source software,,5.0,,6.0,,24 Feb 2009,,,IEEE,IEEE Magazines
1230,1244,Looking for the Holy Grail of Software Development,P. Ghazi; A. M. Moreno; L. Peters,Universidad Politécnica de Madrid; Universidad Politécnica de Madrid; NA,IEEE Software,28 Feb 2014,2014,31,1,96,96,"The history of software engineering has been marked by many famous project failures documented in papers, articles, and books. This pattern of lack of success has prompted the creation of dozens of software analysis, requirements definition, design methods, programming languages, software development environments, and software development processes all promoted as solving ""the software problem."" What we hear less about are software projects that were successful. This article reports on the findings of an extensive analysis of successful software projects that have been reported in the literature. It discusses the different interpretations of success and extracts the characteristics that successful projects have in common. These characteristics provide software project managers with an agenda of topics to be addressed that will help ensure, not guarantee, that their software project will be successful.",1937-4194,,10.1109/MS.2014.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6750443,successful project;success factors;software project management,Software development;Software engineering;Software reliability,,,,7.0,,14.0,,28 Feb 2014,,,IEEE,IEEE Magazines
1231,1245,The Strategic Importance of Release Engineering,D. Spinellis,Athens University of Economics and Business,IEEE Software,10 Mar 2015,2015,32,2,3,5,"Release engineering affects the software we build, how we build it, and how we can make money out of it. It also presents many challenges that will take time to overcome.",1937-4194,,10.1109/MS.2015.54,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057563,release engineering;software engineering;agile methods,,,,,1.0,,,,10 Mar 2015,,,IEEE,IEEE Magazines
1232,1246,The Gender Gap,,,IEEE Software,10 Aug 2012,2012,29,4,8,8,Linda Rising responds to an article by Robert Glass in the Sounding Board column (“The Gender Gap: Is It a Computing Problem or Simply a Computer Science Problem?”) in the March/April 2012 issue of IEEE Software.,1937-4194,,10.1109/MS.2012.102,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6265072,software;engineering;computer;gender gap;computer science;affirmative action;competitiveness;competition;gap,,,,,,,,,10 Aug 2012,,,IEEE,IEEE Magazines
1233,1247,Automotive Software,C. Ebert; J. Favaro,Vector Consulting Services; Intecs,IEEE Software,15 May 2017,2017,34,3,33,39,"This theme issue addresses automotive IT and software development. What technologies and principles deliver value, and how can you introduce them at a fast pace?",1937-4194,,10.1109/MS.2017.82,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927926,automotive software;IT;safety;cybersecurity;software engineering;software development,Special issues and sections;Automotive engineering;Software development,,,,28.0,,4.0,,15 May 2017,,,IEEE,IEEE Magazines
1234,1248,Disseminating the Best Material to Practitioners,P. Laplante; S. Counsell; G. Antoniol,Pennsylvania State University; Brunel University; Polytechnique Montréal,IEEE Software,15 May 2017,2017,34,3,111,113,"As this department celebrates its second year, its editors restate its mission and scope of interest, invite appropriate articles, and look at some previous contributions.",1937-4194,,10.1109/MS.2017.72,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927894,software practitioners;software development;software engineering;IEEE CS 2022 Report,,,,,,,6.0,,15 May 2017,,,IEEE,IEEE Magazines
1235,1249,Virtual Teams [Guest editors' introduction],D. Smite; M. Kuhrmann; P. Keil,Blekinge Institute of Technology; University of Southern Denmark; Keil KTM GmbH,IEEE Software,7 Nov 2014,2014,31,6,41,46,"Over the past decades, today, and in the future, business contexts in software organizations and the common ways of developing software are changing dramatically. Formation of teams in distributed environments, virtual or not, calls for new ways of working across geographic, temporal, and cultural boundaries. This, however, also requires effective leadership approaches enabled through systems, processes, technology, and people. The authors pulled together this special issue to provide some ideas and strategies for practitioners and open questions for researchers. The Web extra at http://youtu.be/YxE6S6MM3Ws is an audio recording in which author IEEE Software Multimedia Editor Davide Falessi interviews Laurence Tratt and Adam Welc, guest editors of the magazine's September/October 2014 issue, about the field of programming languages.",1937-4194,,10.1109/MS.2014.149,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949534,virtual teams;distributed teams;outsourcing;insourcing;software engineering,Special issues and sections;Software development;Virtual groups;Research and development;Project management;Computer languages;Programming,human resource management;software development management;team working,software development;virtual teams;team formation;leadership approach,,2.0,,10.0,,7 Nov 2014,,,IEEE,IEEE Magazines
1236,1250,Recent Advances in Healthcare Software: Toward Context-Aware and Smart Solutions,A. Solanas; J. H. Weber; A. B. Bener; F. van der Linden; R. Capilla,Rovira i Virgili University; University of Victoria; Ryerson University; Philips; Rey Juan Carlos University,IEEE Software,13 Nov 2017,2017,34,6,36,40,"This theme issue presents some of the most recent advances in and applications of software for context-aware and smart healthcare, so as to provide a view of the state of the technology.",1937-4194,,10.1109/MS.2017.4121202,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106887,smart health;s-health;electronic health;e-health;mobile health;m-health;contextaware computing;healthcare;healthcare software;recommender systems;hygge;SafeNeighborhood;software development;software engineering;context-aware and smart healthcare,Special issues and sections;Contect awareness;Medical services;Smart devices,,,,4.0,,7.0,,13 Nov 2017,,,IEEE,IEEE Magazines
1237,1251,Architecture Meets Agility,H. Erdogmus,National Research Council Canada,IEEE Software,25 Aug 2009,2009,26,5,2,4,The concept of architecture has a major role to play in expanding the traditional scope of agile software development.,1937-4194,,10.1109/MS.2009.121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222782,software engineering;agile software development;software architecture,Computer architecture;Software architecture;Documentation;Programming;Vehicles;Risk management;Costs;Communication system control;Stability,,,,7.0,,,,25 Aug 2009,,,IEEE,IEEE Magazines
1238,1252,Recruiting a Star Team,D. Spinellis,Athens University of Economics and Business,IEEE Software,23 Apr 2015,2015,32,3,3,5,Editor in chief Diomidis Spinellis explains how IEEE Software recruited volunteers for the magazine.,1937-4194,,10.1109/MS.2015.68,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7093014,IEEE Software;editorial board;advisory board;volunteer recruitment;software engineering,,human resource management;personnel,star team recruiting;Diomidis Spinellis;IEEE software;volunteer recruit;magazine,,2.0,,1.0,,23 Apr 2015,,,IEEE,IEEE Magazines
1239,1253,Kudos to Bob Glass and Rebecca Wirfs-Brock,,,IEEE Software,31 Dec 2009,2010,27,1,7,9,"These letters deal with the retirement of Rebecca Wirfs-Brock and Bob Glass, systems architecture, domain-specific languages, the certification of requirements analysts, measurement, and reading classics.",1937-4194,,10.1109/MS.2010.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370756,General interest;software engineering;standards and best practices,Glass;Retirement;Domain specific languages;Certification,,,,,,,,31 Dec 2009,,,IEEE,IEEE Magazines
1240,1254,Twenty Years of Patterns' Impact,G. Hohpe; R. Wirfs-Brock; J. W. Yoder; O. Zimmermann,"Allianz SE; Wirfs-Brock Associates; The Refactory, Inc.; Institute for Software at the University of Applied Sciences of Eastern Switzerland, Rapperswil (HSR FHO)",IEEE Software,28 Oct 2013,2013,30,6,88,88,"This column celebrates 20 years of software patterns. IEEE Software advisory board members teamed up with members of the Hillside Group, a nonprofit organization that promotes the use of patterns and pattern languages, to reflect on the state of the practice and impact of patterns.",1937-4194,,10.1109/MS.2013.135,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648592,impact;patterns;pattern writing;software engineering enterprise service bus;enterprise application integration;messaging;architectural knowledge,,,,,4.0,,15.0,,28 Oct 2013,,,IEEE,IEEE Magazines
1241,1255,The Social Responsibility of Software Development,D. Spinellis,,IEEE Software,28 Mar 2017,2017,34,2,4,6,"For better or worse, software developers are building the fabric of tomorrow's world. So, they need to realize that many of the things they do have ethical, social, and political implications.",1937-4194,,10.1109/MS.2017.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888390,software engineering;ethics;software development;social responsibility,,,,,4.0,,1.0,,28 Mar 2017,,,IEEE,IEEE Magazines
1242,1256,My Must-Reads,,,IEEE Software,22 Dec 2008,2009,26,1,8,8,Two readers offer high praise for IEEE Software 's contributions to their careers.,1937-4194,,10.1109/MS.2009.17,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721172,software engineering;professional development,Engineering profession,,,,,,,,22 Dec 2008,,,IEEE,IEEE Magazines
1243,1257,State-of-the-Art Software Testing,D. Spinellis,Athens University of Economics and Business,IEEE Software,22 Sep 2017,2017,34,5,4,6,"Best practices for software testing include unit testing, test-driven development, using a test pyramid, test automation, continuous integration, test coverage analysis, A/B testing, and employing the appropriate metrics.",1937-4194,,10.1109/MS.2017.3571564,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048644,software testing;unit testing;test-driven development;test pyramids;test automation;continuous integration;test coverage analysis;A/B testing;software development;software engineering;Mik Kersten;DevOps,,program testing;software metrics,software testing;unit testing;test-driven development;test pyramid;test automation;continuous integration;test coverage analysis;A/B testing,,2.0,,4.0,,22 Sep 2017,,,IEEE,IEEE Magazines
1244,1258,The Changing Role of the Software Architect,D. Spinellis,,IEEE Software,28 Oct 2016,2016,33,6,4,6,"Being a good software architect has never been easy. Changes in the software industry are making the job even more challenging. The key drivers are the rising role of software in systems and their operation; more emphasis on reuse, agility, and testability during software development; and several quality elements increasingly affected by architectural choices.",1937-4194,,10.1109/MS.2016.133,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725213,software architecture;software architect;software development;software engineering,,software architecture;software quality;software reusability,software architect;software industry;software development;quality elements;software reuse;software agility;software testability,,3.0,,1.0,,28 Oct 2016,,,IEEE,IEEE Magazines
1245,1259,"Of Boilers, Bit, and Bots",G. Booch,IBM,IEEE Software,4 Feb 2015,2015,32,1,11,13,"Parallels exist between the Industrial Revolution and our current computing revolution regarding risk, transparency, and responsibility. This article examines some of these parallels, the implications for society, and the individual developer's responsibility. The Web extra at http://youtu.be/9qfm9DDzLCc is an audio podcast of author Grady Booch reading his On Computing column, in which he discusses how parallels exist between the Industrial Revolution and our current computing revolution regarding risk, transparency, and responsibility. Grady then examines some of these parallels, their implications for society, and individual developer's responsibilities.",1937-4194,,10.1109/MS.2015.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030158,software engineering;computing;history;society;professional development,Social factors;Technology social factors;Social implications of technology;Philosophical considerations,,,,,,,,4 Feb 2015,,,IEEE,IEEE Magazines
1246,1260,A Brave New World of Testing? An Interview with Google's James Whittaker,F. Shull,,IEEE Software,20 Feb 2012,2012,29,2,4,7,"The increasing pervasiveness of cloud computing is changing the state of the practice in software testing. In an interview with James Whittaker, an engineering director at Google, editor in chief Forrest Shull explores some of the important trends in cloud computing and their implications. The conversation covers key technology changes, such as more pervasive access to monitoring frameworks, the ability to aggregate and act on feedback directly from massive user communities (the ""crowdsourcing"" of quality assurance), and the ability to know the exact machine configuration when bugs are discovered. All of these changes are having concrete impacts on which skills are important—and which no longer so—for software testers. An accompanying audio interview provides a complete recording of the conversation and more details on points such as privacy testing.",1937-4194,,10.1109/MS.2012.23,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6155134,cloud computing;software testing;quality assurance;functional testing;software engineering training;privacy,,,,,1.0,1.0,,,20 Feb 2012,,,IEEE,IEEE Magazines
1247,1261,Seeking Your Insights,C. Pautasso; O. Zimmermann,"University of Lugano; University of Applied Sciences of Eastern Switzerland in Rapperswil, Switzerland",IEEE Software,10 Mar 2015,2015,32,2,7,9,"The column's new editors ask readers to participate, and they give guidelines for the type of articles they seek.",1937-4194,,10.1109/MS.2015.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7057623,IEEE Software;Insights column;software engineering;software development;software development lifecycle;software architectures,,,,,,,6.0,,10 Mar 2015,,,IEEE,IEEE Magazines
1248,1262,Point/Counterpoint,R. Kolb; F. van der Linden,Honeywell; Philips Healthcare,IEEE Software,19 Apr 2010,2010,27,3,56,59,"Ronny Kolb and Frank van der Linden discuss the pros and cons of software product lines. Kolb writes about the competitive advantages software product lines can deliver in reducing time-to-market in his article, ""The Need for Speed: Releasing Products Earlier Using Software Product Lines."" Whereas, in ""Why Do We Do Product Lines?"" van der Linden cautions that different stakeholders and organizations have different goals that might or might not fit with software product lines.",1937-4194,,10.1109/MS.2010.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452146,software product lines;software engineering;product line engineering,Time to market,,,,1.0,,3.0,,19 Apr 2010,,,IEEE,IEEE Magazines
1249,1263,Extending Our Field's Reach,D. Spinellis,Athens University of Economics and Business,IEEE Software,28 Oct 2015,2015,32,6,4,6,"The techniques and processes software engineers have perfected to manage complex projects, version control, and international collaboration could benefit other fields and industries.",1937-4194,,10.1109/MS.2015.138,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7311002,software engineering;change management;Git;GitHub;version control;configuration management,,,,,,,,,28 Oct 2015,,,IEEE,IEEE Magazines
1250,1264,"Sigil, BlueGriffon, and the Evolving Software Market",T. DeMarco,,IEEE Software,13 Jun 2014,2014,31,4,100,100,Changes in the applications software market promise increased opportunities for individual players.,1937-4194,,10.1109/MS.2014.93,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834686,software market;freelance development;software brokerage;niche software;software engineering,,,,,,,,,13 Jun 2014,,,IEEE,IEEE Magazines
1251,1265,Refactoring [Guest editors' introduction],E. Murphy-Hill; D. Roberts; P. Sommerlad; W. F. Opdyke,North Carolina State University; University of Evansville; FHO/Hochschule für Technik Rapperswil; JPMorgan Chase,IEEE Software,28 Oct 2015,2015,32,6,27,29,"Refactoring changes a program's source code without changing its external behavior, typically to improve the software's design The articles selected for this issue range from historical, exploring refactoring research's origins, to practical, exploring software developers' experiences with refactoring, to theoretical, exploring new refactoring techniques that haven't yet appeared in the wild. The Web extra at https://youtu.be/f2IK3V9wwa8 is an audio recording of Davide Falessi speaking with guest editors Emerson Murphy-Hill of North Carolina State University, Don Roberts of the University of Evansville, and Peter Sommerlad of Fachhochschule Ostschweiz / Hochschule für Technik Rapperswil about past, present, and future approaches to refactoring.",1937-4194,,10.1109/MS.2015.136,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310990,refactoring;software engineering;software development;mobile computing,Special issues and sections;Code refractoring;Software architecture;Programming;Software development,,,,1.0,,1.0,,28 Oct 2015,,,IEEE,IEEE Magazines
1252,1266,"Fewer Dead Trees, More Engagement",D. Spinellis,Athens University of Economics and Business,IEEE Software,4 Feb 2015,2015,32,1,4,6,New IEEE Software editor in chief Diomidis Spinellis discusses the IEEE Computer Society's switch to digital as the primary delivery option for its publication. He also outlines his vision for Software's future and calls for volunteer help.,1937-4194,,10.1109/MS.2015.5,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030241,software engineering;digital edition;IEEE Computer Society;publications,,,,,1.0,,,,4 Feb 2015,,,IEEE,IEEE Magazines
1253,1267,RE@40: Midlife Crisis or Graceful Maturity?,S. Gregory,Intel Corporation,IEEE Software,13 Nov 2017,2017,34,6,14,17,"The RE@40 seminar offered a diagnosis of the state of RE as it enters its 40s. At 40, RE has grown up a bit and should have a clear sense of who it is as it moves deeper into its most productive years. Of course, many 40-somethings also begin to experience a midlife crisis and suddenly change direction, perhaps not attending well to their current responsibilities. Where does RE sit at this juncture?",1937-4194,,10.1109/MS.2017.4121215,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106880,RE@40;requirements engineering;software requirements;software development;software engineering;Requirements,,,,,1.0,,2.0,,13 Nov 2017,,,IEEE,IEEE Magazines
1254,1268,"Data, Data Everywhere...",F. Shull,Carnegie Mellon University,IEEE Software,15 Sep 2014,2014,31,5,4,7,Editor-in-chief Forrest Shull talks about the practical application of software analytics.,1937-4194,,10.1109/MS.2014.110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898721,software engineering;software analytics;software measurement;software management,,,,,,,4.0,,15 Sep 2014,,,IEEE,IEEE Magazines
1255,1269,How Well Do You Know Your Personae Non Gratae?,J. Cleland-Huang,DePaul University,IEEE Software,13 Jun 2014,2014,31,4,28,31,"Imagine that you're building a software system that collects healthcare data and financial information from its users. It might seem obvious that this personal information should be protected from prying eyes through access control mechanisms, audit trails, transaction controls, transmission encryption, and so on--in fact, perhaps so obvious that in many cases people perform only a cursory security analysis and produce rather generic security requirements. But is this the right way to build secure software? Are security requirements so similar across projects that we simply don't need to invest the time to explore product-level needs or to document requirements at an individual level for each project? The Web extra at http://youtu.be/qoocRI-7yRQ is an audio podcast in which author Jane Cleland-Huang discusses the importance of making informed decisions about how much time and effort to invest in analyzing security needs and specifying product-level security requirements.",1937-4194,,10.1109/MS.2014.85,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834694,requirements;software engineering;cybersecurity;attackers;security,Network security;Software development;Productivity;Medical services;Information services,,,,3.0,,4.0,,13 Jun 2014,,,IEEE,IEEE Magazines
1256,1270,Architecture from a Developer's Perspective,D. Spinellis,Athens University of Economics,IEEE Software,21 Aug 2015,2015,32,5,4,7,Editor in Chief Diomidis Spinellis discusses the importance of architectural considerations for developers.,1937-4194,,10.1109/MS.2015.110,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217777,IEEE Software;software engineering;architecture,,,,,,,,,21 Aug 2015,,,IEEE,IEEE Magazines
1257,1271,Being a DevOps Developer,D. Spinellis,,IEEE Software,25 Apr 2016,2016,33,3,4,5,"In many IT sectors, DevOps is here to stay, helping deliver higher-quality services more efficiently. Thinking like a DevOps developer is an essential trait of an enlightened software professional. This article is part of a theme issue on DevOps.",1937-4194,,10.1109/MS.2016.76,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458759,DevOps;software development;software engineering;agile development;software developers;IT operations,,,,,2.0,,,,25 Apr 2016,,,IEEE,IEEE Magazines
1258,1272,"To Code or Not to Code, That Is the Question",G. Booch,IBM,IEEE Software,15 Sep 2014,2014,31,5,9,11,"There have been many periods in the unfolding of human history when we have asserted that it was possible to catalog all that was known or that could be known. Ignoring the pragmatic reality of trying to catalog an ever-expanding corpus, one must understand that such a task is further complicated by cultural and situational bias: what is important to know at one place and time is not necessary important in another. So it is with our present day; this raises the question, what must a functioning member of society know about computing? The Web extra at http://youtu.be/PjR6GqobTBo is an audio podcast of author Grady Booch reading his On Computing column, in which he discusses how much a functioning member of society today should know about computing.",1937-4194,,10.1109/MS.2014.128,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898799,computational thinking;programming;knowledge;information;history;software engineering,,computer science education;encoding;programming,code;computing;Internet;programming;coding teaching,,,,,,15 Sep 2014,,,IEEE,IEEE Magazines
1259,1273,Introductions,D. Spinellis,Athens University of Economics and Business,IEEE Software,30 Jun 2015,2015,32,4,3,5,"Editor in Chief Diomidis Spinellis introduces 12 editorial board members, four advisory board members, the initiatives team, and two magazine departments.",1937-4194,,10.1109/MS.2015.101,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140675,IEEE Software;software engineering,,,,,1.0,,1.0,,30 Jun 2015,,,IEEE,IEEE Magazines
1260,1274,Differential Debugging,,,IEEE Software,28 Oct 2013,2013,30,6,9,10,"Phillip G. Armour responds to ""Differential Debugging"" in the Tools of the Trade column September/October issue of IEEE Software to discuss the process of predicting defects.",1937-4194,,10.1109/MS.2013.123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648591,defects;debugging;bugs;software;engineering;development;testing;tools;defect masking;existential defects,,,,,,,,,28 Oct 2013,,,IEEE,IEEE Magazines
1261,1275,Protection from Wishful Thinking,F. Shull,,IEEE Software,23 Jun 2011,2011,28,4,3,6,"One of the problems of software development is accurately assessing progress and the cost remaining to completion. Without a good sense of where the project is and how far it still has to go, it's just not possible to consistently manage people and resources well. And miscommunicating progress to stakeholders is among the surest ways to lose trust and buy-in. Even with the best of intentions and good processes in place, it's possible for projects to end up in serious trouble as a result of misassessing or miscomunicating progress. The paper mentions that optimism is a virtue in many cases, but there is a fine distinction between optimism and wishful thinking.",1937-4194,,10.1109/MS.2011.80,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929519,Software engineering;survey;professional development,,project management;software development management,project sense;people management;resource management;software development management,,,,,,23 Jun 2011,,,IEEE,IEEE Magazines
1262,1276,Passing the Baton,F. Shull,Carnegie Mellon University,IEEE Software,7 Nov 2014,2014,31,6,4,8,"Forrest Shull writes his final column as IEEE Software editor in chief; outlining the magazine's accomplishments during his four-year tenure; introducing his successor, Diomidis Spinellis; and discussing the success of Software Experts Summit 2014 in Bangalore, India. The Web extra at http://youtu.be/yhBsX8OHqhY is a video overview of the multimedia content from past issues of IEEE Software and Computer magazines showing the endless possibilites that IEEE Computer Society multimedia affords.",1937-4194,,10.1109/MS.2014.143,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6949506,software engineering;computing;Forrest Shull;Diomidis Spinellis;SES14;Software Experts Summit,,,,,,,,,7 Nov 2014,,,IEEE,IEEE Magazines
1263,1277,Security and Privacy on the Web [Guest editors' introduction],T. Grandison; L. Koved,Proficiency Labs; IBM Research,IEEE Software,30 Jun 2015,2015,32,4,36,39,"Software enables every aspect of the Web. Everything from device communication to online social networks is achievable only because of multiple lines of code. For various reasons, designing and building security and privacy into Web software is often an afterthought for most developers. This results in easily compromised systems that pose significant privacy and security risks to users. The Web extra at https://youtu.be/juxM-mJERxc is an audio recording of Davide Falessi speaking with Guest Editors Tyrone Grandison, CEO of Proficiency Labs, and Larry Koved, Principal Research Staff Member at IBM Research, about why, at a bare minimum, Web software developers must ensure that their code is sufficiently hardened to protect against URL interpretation attacks, input validation attacks, SQL injection attacks, impersonation attacks, basic inference attacks, buffer overflow attacks, and inadvertent data disclosure attacks.",1937-4194,,10.1109/MS.2015.86,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140679,software development;security;privacy;Web;software engineering;Web software,Special issues and sections;Social network services;Computer security;Privacy;Software development,,,,1.0,,,,30 Jun 2015,,,IEEE,IEEE Magazines
1264,1278,The Computational Human,G. Booch,IBM,IEEE Software,26 Feb 2016,2016,33,2,8,10,"Different ages of humanity have required different modes of thinking. These modes aren't only reflections of the particular circumstances of life in each age; they're also projections of the forces that propel us to the next. The Web extra at https://youtu.be/0_kwid5kUAU is an audio podcast of Grady Booch's On Computing column, in which he discusses how we have progressed from the Cognitive Revolution to the Agricultural Revolution to the Industrial Revolution and now find ourselves in the Computational Revolution.",1937-4194,,10.1109/MS.2016.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420499,computational thinking;history;science;software engineering,,social aspects of automation,cognitive revolution;agricultural revolution;industrial revolution;computational revolution;computational human,,1.0,,4.0,,26 Feb 2016,,,IEEE,IEEE Magazines
1265,1279,Architecting in the Gaps: A Metaphor for Architecture Work,E. Woods,Endava,IEEE Software,30 Jun 2015,2015,32,4,33,35,"The metaphor ""architecting in the gaps"" can help software development teams clearly understand the software architect's role and how architecture contributes to a system's overall efficiency.",1937-4194,,10.1109/MS.2015.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140650,software architecture;software engineering;software development;software design,Software development;Software architecture,software architecture,software development teams;software architect role;system overall efficiency,,2.0,,2.0,,30 Jun 2015,,,IEEE,IEEE Magazines
1266,1280,Time Pressure,F. Dzerzhinskiy,"Promsvyazbank, Moscow, Russia",IEEE Software,25 Apr 2016,2016,33,3,6,6,The article is a letter discussing the aspect of time in software development. It states that time pressure has its positive aspects but can also hinder software developers.,1937-4194,,10.1109/MS.2016.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458773,time pressure;software development;software engineering;human factors,,software development management,time pressure;software development,,,,,,25 Apr 2016,,,IEEE,IEEE Magazines
1267,1281,Dave Thomas on Innovating Legacy Systems,S. Johann,innoQ,IEEE Software,26 Feb 2016,2016,33,2,105,108,"Host Sven Johann speaks with Dave Thomas, ACM Distinguished Member, entrepreneur, and researcher, about the tradeoffs and constraints facing developers as they work with legacy systems.",1937-4194,,10.1109/MS.2016.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420466,Dave Thomas;legacy systems;software development;software engineering,,software maintenance,legacy system innovation,,2.0,,,,26 Feb 2016,,,IEEE,IEEE Magazines
1268,1282,Playing Nice,,,IEEE Software,3 Jan 2013,2013,30,1,7,8,"Dale Gaumer responds to Linda Rising's column in the September/October 2012 issue of IEEE Software titled ""Why Can't We All Play Nice?"" and gives examples of how the competence and talent of one's management and coworkers can impact the success of a project. Chris Morris responds to Rising's column to clarify her statements on human genetics.",1937-4194,,10.1109/MS.2013.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6401106,software;engineering;projects;management;competition;genes;genetics,,,,,,,,,3 Jan 2013,,,IEEE,IEEE Magazines
1269,1283,Reflecting on Quality,D. Spinellis,Athens University of Economics and Business,IEEE Software,23 Jun 2016,2016,33,4,4,5,"The production of quality software requires data-driven quality management. Fortunately, developers can use a plethora of tools and techniques for this.",1937-4194,,10.1109/MS.2016.90,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7498538,software quality;data-driven management;software engineering,,,,,,,,,23 Jun 2016,,,IEEE,IEEE Magazines
1270,1284,I Believe,,,IEEE Software,20 Apr 2012,2012,29,3,7,7,"Magdin Stoica discusses the difference between beliefs, intuition and principles in a letter responding to Forrest Shull's From the Editor column ""I Believe"" in the January/February 2012 issue of IEEE Software.",1937-4194,,10.1109/MS.2012.64,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188593,software;engineering;belief;intuition;principles;test-driven development;tdd,,,,,2.0,,,,20 Apr 2012,,,IEEE,IEEE Magazines
1271,1285,Software Process versus Design Quality: Tug of War?,G. Suryanarayana; T. Sharma; G. Samarthyam,"Corporate Research and Technologies Center, Siemens Technology and Services Private Ltd., India; Corporate Research and Technologies Center, Siemens Technology and Services Private Ltd., India; Corp. Res. & Technol. Center, Siemens Technol. & Services Private Ltd., India",IEEE Software,30 Jun 2015,2015,32,4,7,11,"Software processes and design quality are inextricably intertwined. So, developers must consider their impact on each other to ensure a high-quality design.",1937-4194,,10.1109/MS.2015.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7140652,software design smells;refactoring;software process;software engineering;software development;software design;software quality;duplicate abstraction;insufficient modularization;multipath hierarchy,Software development;Product life cycle management,software quality,software process;software design quality;high-quality design,,6.0,,10.0,,30 Jun 2015,,,IEEE,IEEE Magazines
1272,1286,Perfectionists in a World of Finite Resources,F. Shull,Fraunhofer Center for Experimental Software,IEEE Software,28 Feb 2011,2011,28,2,4,6,"The metaphor of technical debt, originally coined by Ward Cunninghamhas helped me recently get a handle on this type of issue. Almost invariably in software projects, developers can be so focused on accomplishing the needed functionality that the software itself grows less understandable, more complex, and harder to modify. Since this system deterioration usually reflects a lack of activity spent in refactoring, documentation, and other aspects of the project infrastructure, we can view it as a kind of debt that developers owe the system. Ward Cunningham's metaphor helps make clear an important trade-off: although a little debt can speed up software development in the short run, this benefit is achieved at the cost of extra work in the future, as if paying interest on the debt. Technical debt gives us a frame work for thinking about the fact that not doing some good things today, no matter how valuable they seem on their own merits, allows us to invest in other good things. In short, there are always trade-offs in life.",1937-4194,,10.1109/MS.2011.38,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5720703,technical debt;code decay;code smells;software maintainability;software engineering,,software maintenance,technical debt;software projects;system deterioration;software development;software refactoring,,2.0,,,,28 Feb 2011,,,IEEE,IEEE Magazines
1273,1287,Software Reliability Redux,D. Spinellis,Athens University of Economics and Business,IEEE Software,11 Jul 2017,2017,34,4,4,7,"The requirement for high reliability is no longer restricted to a few specialized and proven domains. Instead, ever more functions whose failure can hurt humans and damage property are cropping up in new areas. Avoiding problems and catastrophes in the new software reliability landscape is possible but won't be easy.",1937-4194,,10.1109/MS.2017.98,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974699,software reliability;software development;software engineering,,,,,,,3.0,,11 Jul 2017,,,IEEE,IEEE Magazines
1274,1288,Sweet Spot for User Involvement,,,IEEE Software,21 Apr 2014,2014,31,3,9,9,"Chris Morris writes a letter to the editor in response to the Voice of Evidence column ""Does Involving Users in Software Development Really Influence System Success?"" from the Nov./Dec. 2013 issue of IEEE Software in which he discusses the correlation between user and involvement and project success.",1937-4194,,10.1109/MS.2014.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802988,letter to the editor;Chris Morris;user involvement;voice of evidence;software;engineering;development;IEEE,,,,,,,,,21 Apr 2014,,,IEEE,IEEE Magazines
1275,1289,View from the Bridge,,,IEEE Software,17 Mar 2014,2014,31,2,10,13,"Stuart Jobbins writes a letter to the editor in response to the column ""Progression, Regression, or Stasis?"" from the Jan./Feb. 2014 issue of IEEE Software in which he states that software engineers need to inspire youngsters enter our intellectually stimulating and challenging career world, where technology evolution means constant learning and growth in an industry that now pervades nearly every product. Stan Rifkin also writes a letter regarding the same column in which he states that a commitment to software quality is of utmost importance.",1937-4194,,10.1109/MS.2014.48,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774317,letter to the editor;letters;Stuart Jobbins;careers;software;engineering;Stan Rifkin;quality;development;IEEE,,,,,,,,,17 Mar 2014,,,IEEE,IEEE Magazines
1276,1290,"I, for One, Welcome Our New Computer Overlords",G. Booch,,IEEE Software,28 Oct 2015,2015,32,6,8,10,"Many fear the rise of superintelligent AIs. Such fears are at best unfounded and at worst misleading. The Web extra at https://youtu.be/geSb5Zp4qbM is an audio podcast of Grady Booch's On Computing column, in which he discusses why he rejects fears that machines with superintelligent computing powers will eventually spell the end of humanity.",1937-4194,,10.1109/MS.2015.134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7310991,software engineering;computing;artificial intelligence;future;singularity,,artificial intelligence;Internet,computer overlords;superintelligent AIs;Web extra;audio podcast;Grady Booch On Computing column;superintelligent computing powers,,3.0,,13.0,,28 Oct 2015,,,IEEE,IEEE Magazines
1277,1291,Serving Professionals,D. Spinellis,Athens University of Economics and Business,IEEE Software,26 Feb 2016,2016,33,2,4,6,Editor in Chief Diomidis Spinellis discusses what IEEE Software is doing to provide more practitioner-focused material.,1937-4194,,10.1109/MS.2016.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420484,IEEE Software;software engineering;software development,,,,,,,,,26 Feb 2016,,,IEEE,IEEE Magazines
1278,1292,Next-Generation Mobile Computing,J. Edmondson; W. Anderson; J. Gray; J. P. Loyall; K. Schmid; J. White,Carnegie Mellon University; Carnegie Mellon University; University of Alabama; Raytheon BBN Technologies; University of Hildesheim; Vanderbilt University,IEEE Software,17 Mar 2014,2014,31,2,44,47,"This issue of IEEE Software discusses where the mobile computing has brought us today and where it could be taking us in the future. It provides a glimpse into the near future of mobile computing by focusing on proximate software challenges coupled with promising techniques, infrastructure, and research from academia, government, and industry. The first Web extra at http://youtu.be/iLnNHwp-H8E is a video demonstration of the Group Autonomy for Mobile Systems (GAMS) project, which is an extension of a research project called Self-governing Mobile Adhocs with Sensors and Handhelds (SMASH) that investigated human-in-the-loop autonomy at Carnegie Mellon University. The project created Android interfaces to a drone swarm that tried to autonomously search for survivors in a disaster scenario using the Parrot AR.Drone and custom GPS and thermal sensors. The second Web extra at http://youtu.be/lW1dqsrdRHU is a video demonstration of HD4AR mobile augmented reality technology that was commercialized through PAR Works. The third Web extra at http://youtu.be/M4w5oPqrMRo is an audio interview in which James Edmondson talks with Suzanne Miller about autonomous systems, specifically as they relate to robotic systems. In particular, Edmondson's research focuses on partial autonomy with an aim of complementing human users and extending their reach and capabilities in mission-critical environments. From the SEI Podcast Series ""Conversations in Software Engineering.""",1937-4194,,10.1109/MS.2014.39,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774331,mobile computing;mobile;smartphones,Special issues and sections;Next generation networking;Mobile computing;Mobile communication;Computer applications;Software development,augmented reality;disasters;Global Positioning System;mobile computing;robots;user interfaces,next-generation mobile computing;IEEE software;Group Autonomy for Mobile Systems;GAMS;Self-governing Mobile Adhocs with Sensors and Handhelds;SMASH;human-in-the-loop autonomy;Carnegie Mellon University;Android interfaces;disaster scenario;Parrot AR.Drone;custom GPS;thermal sensors;HD4AR mobile augmented reality technology;PAR Works;autonomous systems;robotic systems;mission-critical environments;SEI Podcast Series Conversations in Software Engineering,,7.0,,6.0,,17 Mar 2014,,,IEEE,IEEE Magazines
1279,1293,"Progression, Regression, or Stasis?",F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,28 Feb 2014,2014,31,1,4,8,"IEEE Software Editor in Chief Forrest Shull discusses the challenges of delivering quality software systems on time and on schedule, while considering the many challenges faced by the Health Insurance Marketplace system. He also introduces new Editorial Board and Advisory Board members Jeromy Carriere, Davide Falessi, Evelyn Tian, and Grigori Melnik.",1937-4194,,10.1109/MS.2014.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6750467,healthcare.gov;health insurance marketplace;Jeromy Carriere;Davide Falessi;Evelyn Tian;Grigori Melnik,,,,,,,11.0,,28 Feb 2014,,,IEEE,IEEE Magazines
1280,1294,"Guest Editors' Introduction: Developing Scientific Software, Part 2",J. Segal; C. Morris,Open University; Daresbury Lab,IEEE Software,22 Dec 2008,2009,26,1,79,79,"This guest editors' introduction introduces a special issue on scientific software development. This issue is a sequel to the July/August 2008 issue, whose 6 articles provided some flavor of the variety of such software. Part 2 of this theme focuses on practices for improving the relationships between users, developers, and software.",1937-4194,,10.1109/MS.2009.8,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4721189,scientific computing;high-performance computing;simulation;data visualization,Programming;Councils;Risk management;Software development management;Software testing;Software engineering;Usability;User centered design;Microscopy;Publishing,,,,3.0,,1.0,,22 Dec 2008,,,IEEE,IEEE Magazines
1281,1295,Requirements That Reflect Social Responsibility,J. Cleland-Huang,DePaul University,IEEE Software,29 Dec 2015,2016,33,1,109,111,"A few simple steps can help app developers think through potential harm, identify mitigating requirements, and ensure that the products they develop maximize good and minimize harm. The Web extra at https://youtu.be/UI-itpTr6Jw is an audio podcast of this column.",1937-4194,,10.1109/MS.2016.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368038,software requirements;software development;social responsibility;social networking;Peeple;SketchFactor;software design,Software engineering;Requirements engineering;Social network services;Software design,formal specification,software requirements;social responsibility,,,,4.0,,29 Dec 2015,,,IEEE,IEEE Magazines
1282,1296,Lean Software Development,C. Ebert; P. Abrahamsson; N. Oza,Vector Consulting Services; Free University of Bozen-Bolzano; University of Helsinki,IEEE Software,21 Aug 2012,2012,29,5,22,25,"This special issue addresses lean software development. What principles deliver value, and how are they introduced to best manage change?",1937-4194,,10.1109/MS.2012.116,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6276296,lean software development;agile;life cycle,Special issues and sections;Software engineering;Product life cycle management;Software development;Agile manufacturing,,,,33.0,,5.0,,21 Aug 2012,,,IEEE,IEEE Magazines
1283,1297,The Many Faces of Software Analytics,T. Menzies; T. Zimmermann,West Virginia University; Microsoft Research,IEEE Software,3 Sep 2013,2013,30,5,28,29,"Articles regarding the many faces of software analytics highlight the power of analytics for different types of organizations: large organizations and open source projects, as well as small- to medium-sized projects.",1937-4194,,10.1109/MS.2013.114,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6588525,software analytics;analytics;analysis,Special issues and sections;Software analytics;Software engineering,,,,2.0,,,,3 Sep 2013,,,IEEE,IEEE Magazines
1284,1298,Don't Fire the Architect! Where Were the Requirements?,J. Cleland-Huang,DePaul University,IEEE Software,17 Mar 2014,2014,31,2,27,29,"The Healthcare.gov debacle of 2013 leads many to wonder if a better understanding of the project's requirements could have lessened the impact of the failed launch. The Web extra at http://youtu.be/qyQldlPz1ws is an audio podcast of author Jane Cleland-Huang reading her Requirements column, in which she discusses the Healthcare.gov debacle of 2013 and how it led many to wonder if a better understanding of the projec's requirements could have lessened the impact of the failed launch.",1937-4194,,10.1109/MS.2014.34,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6774318,requirements;architecture;Healthcare.gov,Software engineering;Medical services;Insurance;Performance evaluation;Computer architecture,medical information systems;social aspects of automation;Web sites,healthcare.gov debacle;project requirements;failed launch;Web extra;audio podcast,,2.0,,5.0,,17 Mar 2014,,,IEEE,IEEE Magazines
1285,1299,A Balancing Act: What Software Practitioners Have to Say about Technical Debt,E. Lim; N. Taksande; C. Seaman,"Aquatic Informatics; Novasom; University of Maryland, Baltimore County",IEEE Software,22 Oct 2012,2012,29,6,22,27,"An interview study involving 35 practitioners from a variety of domains aimed to characterize technical debt at the ground level to find out how software practitioners perceive it. The study also aimed to understand the context in which technical debt occurs, including its causes, symptoms, and effects. In addition, the study focused on how practitioners currently deal with technical debt. This analysis paints a picture of a large, complex balancing act of various short- and long-term concerns. The Web Extra gives the interview questions used by Erin Lim, Nitin Taksande, and Carolyn Seaman.",1937-4194,,10.1109/MS.2012.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6280547,maintenance management;software maintenance;technical debt;software engineering,Interviews;Risk management;Investments;Software testing;Documentation;Software quality,DP industry;project management;software development management;software quality,software practitioner;technical debt;software quality;project management,,83.0,,10.0,,23 Aug 2012,,,IEEE,IEEE Magazines
1286,1300,New Perspectives on Software Quality [Guest editors' introduction],R. Breu; A. Kuntzmann-Combelles; M. Felderer,University of Innsbruck; inspearit; University of Innsbruck,IEEE Software,28 Feb 2014,2014,31,1,32,38,"This special issue, owing to its fundamental software quality focus, comprises a collection of diverse articles that address the challenges and directions for software quality research. The Web extra at http://youtu.be/T7V4RSr1KEE is an audio interview in which Davide Falessi speaks with guest editors Annie Kuntzmann-Combelles, Michael Felderer, and Ruth Breu about methods for improving software quality management, testing, and security on intelligent and interconnected devices.",1937-4194,,10.1109/MS.2014.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6750444,software quality;quality engineering;software,Special issues and sections;Software testing;Collaboration;Quality management;Software engineering;Data analysis;Software quality,,,,9.0,,15.0,,28 Feb 2014,,,IEEE,IEEE Magazines
1287,1301,Mars Rover,,,IEEE Software,26 Jun 2013,2013,30,4,8,8,"Iowa State University Lanh & Oanh Nguyen Professor of Software Engineering David Weiss compliments the ""Landing a Spacecraft on Mars"" article in the Impact column from the March/April 2013 issue of IEEE Software.",1937-4194,,10.1109/MS.2013.79,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547628,engineering;Curiosity;rover;Mars;spacecraft;software;development;process critical systems,,,,,1.0,,,,26 Jun 2013,,,IEEE,IEEE Magazines
1288,1302,The Go Programming Language,J. Meyerson,,IEEE Software,15 Sep 2014,2014,31,5,104,104,"Andrew Gerrand, who works on the Go programming language at Google, speaks with Jeff Meyerson in this excerpt from Software Engineering Radio. His conversation with Jeff begins with a history of the language, including the details behind how Go was conceived and how the open source community contributes to it. Andrew explains how Go intends to simplify problems which have been motifs as Google has scaled. The Web extra at http://www.se-radio.net/2014/03/episode-202-andrew-gerrand/ is an audio recording of Jeff Meyerson speaking with Andrew Gerrand about the Go programming language.",1937-4194,,10.1109/MS.2014.127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898707,Andrew Gerrand;arrays;build times;C;compilers;garbage collection;Go;golang;Google;imports;interfaces;open source;readability;scalability;slices;standard library;syntax,,,,,3.0,,,,15 Sep 2014,,,IEEE,IEEE Magazines
1289,1303,Assuring the Future? A Look at Validating Climate Model Software,F. Shull,,IEEE Software,20 Oct 2011,2011,28,6,4,8,"The scientific community studying climate change uses a variety of strategies to assess the correctness of their models. These software systems represent large, sophisticated, fine-grained scientific tools. The validation practices described are thus tailored to a domain in which software and software engineering practices are useful but cannot be allowed to get in the way of the science. In audio interviews, two scientists--Robert Jacob, a computational climate scientist at Argonne National Laboratory, and Gavin Schmidt, a climatologist and climate modeler at the NASA Goddard Institute for Space Studies--discuss what it means to develop and communicate ground-breaking results.",1937-4194,,10.1109/MS.2011.135,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6055655,Software validation;modeling and simulation;climate studies;Robert Jacob;Gavin Schmidt;Argonne National Laboratory and NASA Goddard Institute for Space Studies,Special issues and sections;Software development;Metrology;Global warming;Atmospheric modeling;Atmosphere measurements,,,,1.0,,1.0,,20 Oct 2011,,,IEEE,IEEE Magazines
1290,1304,Sharing Your Story,F. Shull,Fraunhofer Center for Experimental Software,IEEE Software,18 Apr 2013,2013,30,3,4,7,"IEEE Software Editor-in-Chief Forrest Shull discusses the value of experience reports and how they can bring practical advice and perspective that simple metrics are not always able to provide. In addition, he discusses Software Experts Summit 2013 and announces that the magazine is seeking a new multimedia editor. The first Web extra at http://youtu.be/KTUHr-1S_wo is a video preview of Software Experts Summit 2013, which will focus on Smart Data Science: Harnessing Data for Intelligent Decision Making. Scheduled for 17 July at the Microsoft Campus in Redmond, Washington, speakers include James Whittaker of Microsoft, Paul Zikopoulos of IBM, Wolfram Schulte of Microsoft Research, Ayse Bener of Ryerson University, and Forrest Shull of the Fraunhofer Center for Experimental Software Engineering.",1937-4194,,10.1109/MS.2013.56,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6504876,experience report;software;technology;engineering;multimedia;edit;editing;author;guidelines;application;research;practice;practical,,,,,1.0,,3.0,,18 Apr 2013,,,IEEE,IEEE Magazines
1291,1305,Roundtable: The Future of Software Engineering for Internet Computing,J. Lü; D. S. Rosenblum; T. Bultan; V. Issarny; S. Dustdar; M. Storey; D. Zhang,"Nanjing University; National University of Singapore; University of California, Santa Barbara; Inria Paris-Rocquencourt; Vienna University of Technology; University of Victoria; Microsoft Research, China",IEEE Software,4 Feb 2015,2015,32,1,91,97,"Seven research leaders in software engineering for Internet computing present their viewpoints on important issues that will shape this field's future. They discuss opportunities and challenges for the shifting software paradigm; stepping outside the comfort zone to revisit issues such as software correctness; improving Internet software dependability and programmability; addressing software engineering issues for the Internet of Things; exploring relationships among the Internet of Things, people, and software services; supporting a participatory culture of software development; and rethinking logging in online services.",1937-4194,,10.1109/MS.2015.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030178,software engineering;Internetware;Internet computing;Internet of Things,Interviews;Software engineering;Internet computing;Internet of things,,,,4.0,,18.0,,4 Feb 2015,,,IEEE,IEEE Magazines
1292,1306,2014 Index IEEE Transactions on Software Engineering Vol. 40,,,IEEE Transactions on Software Engineering,19 Jan 2015,2015,41,1,104,112,"This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.",1939-3520,,10.1109/TSE.2014.2382474,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7014339,,Indexes,,,,,,,,19 Jan 2015,,,IEEE,IEEE Journals
1293,1308,Kief Morris on Infrastructure as Code,S. Johann,,IEEE Software,16 Jan 2017,2017,34,1,117,120,"Cloud specialist Kief Morris joins Software Engineering Radio host Sven Johann to discuss the benefits of infrastructure as code, including security, auditability, testing, documentation, and traceability.",1937-4194,,10.1109/MS.2017.13,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7819402,Kief Morris;infrastructure as code;infrastructure automation;Software Engineering Radio;software engineering;software development,Servers;Software engineering;Automation;Software testing;Computer security,,,,2.0,,,,16 Jan 2017,,,IEEE,IEEE Magazines
1294,1309,Jay Fields on Working with Unit Tests,S. Tilkov,innoQ,IEEE Software,24 Aug 2016,2016,33,5,117,120,"Host Stefan Tilkov explores issues surrounding unit testing with software engineer Jay Fields, author of Working Effectively with Unit Tests.",1937-4194,,10.1109/MS.2016.121,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7548912,Software Engineering Radio;unit tests;software engineering;Jay Fields;software testing;software development,Testing;Writing;Databases;Software engineering;Navigation;Interviews;Production,,,,1.0,,,,24 Aug 2016,,,IEEE,IEEE Magazines
1295,1310,Software Engineering for Big Data Systems,I. Gorton; A. B. Bener; A. Mockus,"Northeastern University; Ryerson University; University of Tennessee, Knoxville",IEEE Software,26 Feb 2016,2016,33,2,32,35,"Software engineering for big data systems is complex and faces challenges including pervasive distribution, write-heavy workloads, variable request loads, computation-intensive analytics, and high availability. The articles in this theme issue examine several facets of this complicated puzzle. The Web extra at https://youtu.be/YKBGf9EOBUo is an audio recording of Davide Falessi speaking with Ayse Basar Bener and Audris Mockus about the authors, articles, and discussions that went into the IEEE Software March/April 2016 theme issue on software engineering for big data systems.",1937-4194,,10.1109/MS.2016.47,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7420514,strategic prototyping;online video processing;operational-log analysis;data analytics;big data;software engineering;software development,,,,,15.0,,5.0,,26 Feb 2016,,,IEEE,IEEE Magazines
1296,1311,"How Important Is Evidence, Really?",H. Erdogmus,Kalemun Research,IEEE Software,19 Apr 2010,2010,27,3,2,5,"The utility of evidence in the adoption of software engineering ideas depends on several factors. The type of evidence, the adoption context, the attitudes of decision makers, and the size of the idea and its bundle all play a role in the adoption decision. Feasibility check might suffice for small, viral ideas, whereas systematic evidence might be warranted for medium-scale ideas considered for limited-scale but rapid adoption.",1937-4194,,10.1109/MS.2010.75,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452140,software engineering;empirical software engineering;evidence-based software engineering,Software engineering,,,,5.0,,18.0,,19 Apr 2010,,,IEEE,IEEE Magazines
1297,1312,Josh Doody on Salary Negotiation for Software Engineers,M. Blankenship,,IEEE Software,28 Mar 2017,2017,34,2,117,120,"Host Marcus Blankenship talks about the importance of salary negotiation for software engineers with Josh Doody, author of Fearless Salary Negotiation.",1937-4194,,10.1109/MS.2017.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888381,Josh Doody;software engineering;salary negotiation;SE Radio;software development,Remuneration;Companies;Software engineering;Software;Interviews;Digital audio broadcasting;Blogs,,,,,,,,28 Mar 2017,,,IEEE,IEEE Magazines
1298,1313,The Future of Software Engineering,,,IEEE Software,21 Aug 2015,2015,32,5,c2,c2,Describes the above-named upcoming special issue or section. May include topics to be covered or calls for papers.,1937-4194,,10.1109/MS.2015.123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7217778,,,,,,,,,,21 Aug 2015,,,IEEE,IEEE Magazines
1299,1314,International Conference on Software Engineering,,,IEEE Software,22 Sep 2017,2017,34,5,c3,c3,Describes the above-named upcoming conference event. May include topics to be covered or calls for papers.,1937-4194,,10.1109/MS.2017.3571566,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048632,,,,,,,,,,22 Sep 2017,,,IEEE,IEEE Magazines
1300,1315,Software Engineering for the 21st Century [Advertisement],,,IEEE Software,21 Apr 2014,2014,31,3,c2,c2,Advertisement.,1937-4194,,10.1109/MS.2014.71,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802983,,,,,,,,,,21 Apr 2014,,,IEEE,IEEE Magazines
1301,1317,Guest Editors' Introduction to the Special Section on Exception Handling: From Requirements to Software Maintenance,A. Garcia; A. Romanovsky; V. Issarny,NA; NA; NA,IEEE Transactions on Software Engineering,29 Mar 2010,2010,36,2,147,149,The four papers in this special section focus on topics related to exception handling.,1939-3520,,10.1109/TSE.2010.45,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5439569,,Software maintenance;Application software;Software systems;Computer languages;Programming;Software quality;Software engineering;Protection;Pressing;Reflection,,,,,,70.0,,29 Mar 2010,,,IEEE,IEEE Journals
1302,1318,The Software Architect's Role in the Digital Age,G. Hohpe; I. Ozkaya; U. Zdun; O. Zimmermann,"Allianz SE; Carnegie Mellon Software Engineering Institute; University of Vienna; University of Applied Sciences of Eastern Switzerland, Rapperswil",IEEE Software,28 Oct 2016,2016,33,6,30,39,"Internet scale, the increasing rate of technology evolution, and the broad adoption of lean and agile methods have triggered a profound change in not only application and infrastructure architectures but also the software architect's roles and responsibilities. This article reviews the field's state of the art, identifies the skills of the connected architect, and gives an overview of related education programs and knowledge sources.",1937-4194,,10.1109/MS.2016.137,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7725214,software architect;software architecture;software development;software engineering;software engineering education;architecture as a service;connected vehicles;Ericsson;embedded software;decision making,,,,,13.0,,21.0,,28 Oct 2016,,,IEEE,IEEE Magazines
1303,1319,2011 Reviewers List,,,IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,236,238,Lists the reviewers who contributed to IEEE Transactions on Software Engineering in 2011.,1939-3520,,10.1109/TSE.2012.3,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6141072,,IEEE publishing,,,,,,,,30 Jan 2012,,,IEEE,IEEE Journals
1304,1320,2010 Reviewers List,,,IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,142,144,Lists the reviewers who contributed to IEEE Transactions on Software Engineering in 2010.,1939-3520,,10.1109/TSE.2011.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704238,,IEEE publishing,,,,,,,,28 Jan 2011,,,IEEE,IEEE Journals
1305,1321,2008 Reviewers List,,,IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,138,141,Lists the reviewers who contributed to the IEEE Transactions on Software Engineering from 09 January 2008 through 13 January 2009.,1939-3520,,10.1109/TSE.2009.6,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4771849,,IEEE,,,,,,,,2 Feb 2009,,,IEEE,IEEE Journals
1306,1322,2009 Reviewers List,,,IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,141,143,Lists the reviewers who contributed to the IEEE Transactions on Software Engineering from 14 January 09 through 07 January 2010.,1939-3520,,10.1109/TSE.2010.14,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401366,,IEEE publications,,,,,,,,29 Jan 2010,,,IEEE,IEEE Journals
1307,1323,Toward Meaningful Industrial--Academic Partnerships,J. Cleland-Huang,DePaul University,IEEE Software,4 Feb 2015,2015,32,1,18,21,"At the Ready-Set-Transfer panel at the 2014 IEEE International Requirements Engineering Conference, researchers presented their projects to a team of industrial judges, explaining the industrial motivation and describing how they had evaluated their idea's adoption readiness. The projects included FlexiSketch, a collaborative-whiteboard sketching tool; the Collaborative Creativity Canvas, which replaces requirements negotiation with a lively cocreation process; and Archie, which detects and visualizes architectural decisions in code. The Web extra at http://youtu.be/6RNYVVWrJAQ is an audio podcast in which author Jane Cleland-Huang provides an audio recording of the Requirements column,in which she discusses the Ready-Set-Transfer panel at the 2014 IEEE International Requirements Engineering Conference.",1937-4194,,10.1109/MS.2015.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7030230,technology transfer;requirements engineering;software engineering;Ready-Set-Transfer;FlexiSketch;Collaborative Creativity Canvas;Archie,Technology transfer;Requirements engineering;Software engineering;Interviews,,,,1.0,,4.0,,4 Feb 2015,,,IEEE,IEEE Magazines
1308,1324,Front Cover,,,IEEE Software,25 Aug 2009,2009,26,5,c1,c1,September/October 2009 IEEE Software: End-User Software Engineering,1937-4194,,10.1109/MS.2009.128,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222780,IEEE Software;End-User Software Engineering,,,,,,,,,25 Aug 2009,,,IEEE,IEEE Magazines
1309,1325,Front Cover,,,IEEE Software,16 Oct 2009,2009,26,6,c1,c1,November/December 2009 IEEE Software: Human Aspects of Software Engineering,1937-4194,,10.1109/MS.2009.174,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5286994,IEEE Software;End-User Software Engineering,,,,,,,,,16 Oct 2009,,,IEEE,IEEE Magazines
1310,1326,Front Cover,,,IEEE Software,20 Apr 2012,2012,29,3,c1,c1,May/June 2012 IEEE Software: Software Engineering for Compliance,1937-4194,,10.1109/MS.2012.60,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188589,Software Engineering for Compliance,,,,,,,,,20 Apr 2012,,,IEEE,IEEE Magazines
1311,1328,[Front cover],,,IEEE Transactions on Software Engineering,27 May 2010,2010,36,3,c1,c1,Presents the front cover/table of contents for this issue of the periodical.,1939-3520,,10.1109/TSE.2010.52,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5473897,,,,,,,,,,27 May 2010,,,IEEE,IEEE Journals
1312,1329,TSE information for authors [inside back cover],,,IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,c3,c3,Provides instructions and guidelines to prospective authors who wish to submit manuscripts.,1939-3520,,10.1109/TSE.2012.59,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311393,,,,,,,,,,24 Sep 2012,,,IEEE,IEEE Journals
1313,1331,[Back cover],,,IEEE Transactions on Software Engineering,3 Apr 2012,2012,38,2,c4,c4,"Provides a listing of current staff, committee members and society officers.",1939-3520,,10.1109/TSE.2012.24,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6173079,,,,,,,,,,3 Apr 2012,,,IEEE,IEEE Journals
1314,1332,7 Great Reasons for Joining the IEEE Computer Society [advertisement],,,IEEE Transactions on Software Engineering,29 Jan 2010,2010,36,1,144,144,Advertisement: 7 Great Reasons for Joining the IEEE Computer Society.,1939-3520,,10.1109/TSE.2010.15,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5401367,,,,,,,,,,29 Jan 2010,,,IEEE,IEEE Journals
1315,1335,Call for Papers for New IEEE Transactions on Affective Computing,,,IEEE Transactions on Software Engineering,15 Dec 2009,2009,35,6,879,879,"The new IEEE Transactions on Affective Computing seeks original manuscripts for publication. This new online only journal will publish cross disciplinary and international archival results of research on the design of systems that can recognize, interpret, and simulate human emotions and related affective phenomena. The journal will publish original research on the principles and theories explaining why and how affective factors condition interaction between humans and technology, on how affective sensing and simulation techniques can inform our understanding of human affective processes, and on the design, implementation and evaluation of systems that carefully consider affect among the factors that influence their usability. Surveys of existing work will be considered for publication when they propose a new viewpoint on the history and the perspective on this domain.",1939-3520,,10.1109/TSE.2009.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5353440,,,,,,,,,,15 Dec 2009,,,IEEE,IEEE Journals
1316,1344,2013 Reviewers List,,,IEEE Transactions on Software Engineering,4 Mar 2014,2014,40,1,103,106,"The publication offers a note of thanks and lists its reviewers. Reviewers' comments are an essential part of the process of creating a well written article capable of expressing theoretical content well with effective illustrations, tables and graphs.",1939-3520,,10.1109/TSE.2014.2298173,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6755631,,IEEE publishing,,,,,,,,4 Mar 2014,,,IEEE,IEEE Journals
1317,1345,Introduction to OnlinePlus Video [advertisement],,,IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,239,239,Advertisement: Now available: A video introducing the IEEE Computer Society's new OnlinePius publication model for Transactions. Viewers will see an overview of the great features and benefits included with an OnlinePlus subscription and will take a tour of the user-friendly interface included on the accompanying disc. Go to www.computer.org/onlineplus to view the video and learn all about it today.,1939-3520,,10.1109/TSE.2012.9,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6141074,,,,,,,,,,30 Jan 2012,,,IEEE,IEEE Journals
1318,1350,2015 reviewers list,,,IEEE Transactions on Software Engineering,7 Jan 2016,2016,42,1,100,102,The conference offers a note of thanks and lists its reviewers.,1939-3520,,10.1109/TSE.2015.2507218,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7374786,,IEEE publishing,,,,,,,,7 Jan 2016,,,IEEE,IEEE Journals
1319,1353,Call for Papers for Special Issue on Software Services and Service-Based Systems,,,IEEE Transactions on Software Engineering,31 Jul 2009,2009,35,4,592,592,"Prospective authors are requested to submit new, unpublished manuscripts for inclusion in the upcoming event described in this call for papers.",1939-3520,,10.1109/TSE.2009.43,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5186363,,,,,,,,,,31 Jul 2009,,,IEEE,IEEE Journals
1320,1357,[Table of contents - Front cover],,,IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,c1,c1,Presents the cover/table of contents for this issue of the periodical.,1939-3520,,10.1109/TSE.2012.57,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311484,,,,,,,,,,24 Sep 2012,,,IEEE,IEEE Journals
1321,1366,New Transactions Newsletter [advertisement],,,IEEE Transactions on Software Engineering,26 Jul 2012,2012,38,4,992,992,Advertisement: Stay connected with the IEEE Computer Society Transactions by signing up for our new Transactions Connection newsletter. It is free and contains valuable information.,1939-3520,,10.1109/TSE.2012.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6249695,,,,,,,,,,26 Jul 2012,,,IEEE,IEEE Journals
1322,1367,2012 Reviewers List,,,IEEE Transactions on Software Engineering,28 Dec 2012,2013,39,1,141,144,The publication offers a note of thanks and lists its reviewers.,1939-3520,,10.1109/TSE.2013.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6397559,,IEEE publishing,,,,,,,,28 Dec 2012,,,IEEE,IEEE Journals
1323,1378,IEEE Computer Society CSDP [advertisement],,,IEEE Transactions on Software Engineering,29 Nov 2010,2010,36,6,878,878,Advertisement: The IEEE Computer Society Certified Software Development Professional (CSDP) credential.,1939-3520,,10.1109/TSE.2010.105,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5644736,,,,,,,,,,29 Nov 2010,,,IEEE,IEEE Journals
1324,1382,[Front cover],,,IEEE Transactions on Software Engineering,3 Apr 2009,2009,35,2,c1,c1,Presents the table of contents for this issue of the periodical.,1939-3520,,10.1109/TSE.2009.20,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4809709,,,,,,,,,,3 Apr 2009,,,IEEE,IEEE Journals
1325,1386,IEEE Computer Society Magazines and Transactions available in ePUB format [advertisement],,,IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,878,878,Advertisement: IEEE Computer Society Magazines and Transactions in ePUB format.,1939-3520,,10.1109/TSE.2011.117,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095282,,,,,,,,,,5 Dec 2011,,,IEEE,IEEE Journals
1326,1392,What's new in Transactions [advertisement],,,IEEE Transactions on Software Engineering,5 Dec 2011,2011,37,6,880,880,Advertisement: IEEE periodicals.,1939-3520,,10.1109/TSE.2011.119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6095284,,,,,,,,,,5 Dec 2011,,,IEEE,IEEE Journals
1327,1397,IEEE Open Access Publishing [advertisement],,,IEEE Transactions on Software Engineering,24 Sep 2012,2012,38,5,1232,1232,Advertisement: What does IEEE Open Access mean to an author? Top quality publishing with established impact factors; Increased exposure and recognition as a thought leader; A consistent IEEE peer-review standard of excellence; Unrestricted access for readers to discover your publications; and Great way to fulfill a requirement to publish open access.,1939-3520,,10.1109/TSE.2012.61,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6311396,,,,,,,,,,24 Sep 2012,,,IEEE,IEEE Journals
1328,1400,2011 Annual Index,,,IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,Online Only,,"This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the coauthors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under he primary entry in the Author Index.",1939-3520,,10.1109/TSE.2012.2,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6141073,,Indexes,,,,,,,,30 Jan 2012,,,IEEE,IEEE Journals
1329,1406,What's new in Transactions [advertisement],,,IEEE Transactions on Software Engineering,30 Jan 2012,2012,38,1,240,240,"Advertisement: Our new ""What's New in Transactions"" webpage provides an overview of our 14 peer-reviewed scholarly journals. Visit http://www.computer.org/whats-new today.",1939-3520,,10.1109/TSE.2012.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6141075,,,,,,,,,,30 Jan 2012,,,IEEE,IEEE Journals
1330,1409,OnlinePlus Coming Soon to TSE [advertisement],,,IEEE Transactions on Software Engineering,29 Nov 2012,2012,38,6,1488,1488,"Advertisement: Recognizing the need for quicker access to research, TSE will transition to the new OnlinePlus publication model beginning in 2013.",1939-3520,,10.1109/TSE.2012.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6363463,,,,,,,,,,29 Nov 2012,,,IEEE,IEEE Journals
1331,1433,IEEE Computer Society 2009 Membership Application,,,IEEE Transactions on Software Engineering,2 Feb 2009,2009,35,1,142,144,Advertisement: IEEE Computer Society 2009 Membership Application.,1939-3520,,10.1109/TSE.2009.12,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4771850,,,,,,,,,,2 Feb 2009,,,IEEE,IEEE Journals
1332,1436,2010 Annual Index,,,IEEE Transactions on Software Engineering,28 Jan 2011,2011,37,1,Online-only content,,"This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the coauthors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.",1939-3520,,10.1109/TSE.2011.11,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5704239,,,,,,,,,,28 Jan 2011,,,IEEE,IEEE Journals
1333,1446,In Memoriam - David Notkin (1953-2013),B. Nuseibeh,,IEEE Transactions on Software Engineering,23 May 2013,2013,39,6,742,743,"David Samuel Notkin, whose technical, educational, and social contributions to computer science and software engineering research made him a major figure in the field, died on 22 April 2013, at his home in Seattle, Washington. He was 58 years old. The cause of his death was cancer. David is best known for his research, with his many graduate students, on software evolution. He asked why software is often so hard and expensive to change, and he worked to reduce the difficulty of software evolution to an essential minimum. This focus came from his belief that the ability to change software - its softness - is where its true but under-realized potential resides. He asked questions such as whether we can identify and close the gap between Brooks' notions of accidental and essential software complexity? How much should rather than does it cost to develop, test, and evolve software? Can we make the cost of change proportionate rather than disproportionate to the apparent complexity of changes to be made? Can we design software analysis methods that realize the best properties of both static and dynamic analysis techniques? Beyond technical contributions, David is widely recognized and admired for his exceptional skill as a research mentor for graduate students and as a powerful and unwavering advocate for improving gender diversity in computer science. A brief biography is given highlighting Notkin's professional achievements.",1939-3520,,10.1109/TSE.2013.25,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6519247,,"Obituaries;Notkin, David",,,,,,,,23 May 2013,,,IEEE,IEEE Journals
1334,1447,Front Cover,,,IEEE Software,11 Jul 2017,2017,34,4,c1,c1,"The theme articles in this issue address reliability engineering. Other topics in the issue include agile development, requirements engineering, and technical debt.",1937-4194,,10.1109/MS.2017.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7974714,IEEE Software;July/Aug. 2017;reliability engineering;agile development;requirements engineering;technical debt;software engineering;software development,,,,,,,,,11 Jul 2017,,,IEEE,IEEE Magazines
1335,1448,An Interview with Gilad Bracha,L. Tratt; A. Welc,King's College London; Oracle Labs,IEEE Software,15 Sep 2014,2014,31,5,76,79,The guest editors of IEEE Software's special issue on programming languages recently met with Gilad Bracha to talk about his experiences in the field.,1937-4194,,10.1109/MS.2014.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898742,software engineering;programming languages,Programming;Software;Security;Java;Interviews;Educational institutions,,,,,,,,15 Sep 2014,,,IEEE,IEEE Magazines
1336,1449,2015 Reviewers,,,IEEE Software,29 Dec 2015,2016,33,1,6,8,The articles in IEEE Software are the result of hard work by many people. We deeply appreciate the efforts of everyone who reviewed the many articles submitted to Software last year. The peer review process helps maintain the magazine's revered quality. All of us in the software development community owe gratitude to people who participate in this crucial service.,1937-4194,,10.1109/MS.2016.4,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7368003,IEEE Software;peer review;reviewers;software engineering;software development,IEEE publishing,,,,,,,,29 Dec 2015,,,IEEE,IEEE Magazines
1337,1450,2009 Reviewers,,,IEEE Software,31 Dec 2009,2010,27,1,92,94,The editorial board and staff of IEEE Software thanks the 337 reviewers who contributed to the continuous excellence of the magazine in 2009 through the peer review process.,1937-4194,,10.1109/MS.2010.1,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5370766,peer review;reviewers;software;software engineering,IEEE publications,,,,,,,,31 Dec 2009,,,IEEE,IEEE Magazines
1338,1451,Front Cover,,,IEEE Software,22 Sep 2017,2017,34,5,c1,c1,Presents the front cover for this issue of the publication.,1937-4194,,10.1109/MS.2017.3571579,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048654,IEEE Software;Sept./Oct. 2017;software testing;DevOps;DevSecOps;gamification;requirements;software engineering;software development,,,,,,,,,22 Sep 2017,,,IEEE,IEEE Magazines
1339,1452,Front Cover,,,IEEE Software,15 May 2017,2017,34,3,c1,c1,"The theme articles in this issue address automotive IT and software development. Other topics in the issue include software for inland shipping, software startups, and energy-aware software.",1937-4194,,10.1109/MS.2017.73,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7927927,IEEE Software;May/June 2017;automotive software;software engineering;software development;inland shipping;software startups;energy-aware software,,,,,,,,,15 May 2017,,,IEEE,IEEE Magazines
1340,1453,Table of Contents,,,IEEE Software,20 Apr 2012,2012,29,3,1,2,IEEE Software May/June 2012 Table of Contents,1937-4194,,10.1109/MS.2012.67,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6188591,IEEE Software;software engineering for compliance,,,,,,,,,20 Apr 2012,,,IEEE,IEEE Magazines
1341,1454,Table of Contents,,,IEEE Software,18 Aug 2011,2011,28,5,2,3,IEEE Software September/October Table of Contents,1937-4194,,10.1109/MS.2011.109,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984785,IEEE Software;Engineering Fun,,,,,,,,,18 Aug 2011,,,IEEE,IEEE Magazines
1342,1455,Certified Software Architects,P. Clements,Carnegie Mellon University,IEEE Software,14 Oct 2010,2010,27,6,6,8,"Are software architecture certifications worthwhile? At a recent Software Engineering Institute architecture conference, certification programs from Boeing, Raytheon, Siemens, the International Association of Software Architects, and the SEI were presented and compared. This article captures the comparison, and offers some advice about engaging in certification activities and (if you're an organizational manager) setting up your own program.",1937-4194,,10.1109/MS.2010.137,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604355,software architecture;software architect;architecture certification;software architecture training;software engineering,Software architecture;Certification;Training;Career development,,,,1.0,,,,14 Oct 2010,,,IEEE,IEEE Magazines
1343,1458,In Memoriam: Mary Jean Harrold (1947-2013),B. Nuseibeh,,IEEE Transactions on Software Engineering,28 Oct 2013,2013,39,11,1466,1466,Recounts the career and contributions of Mary Jean Harrold.,1939-3520,,10.1109/TSE.2013.51,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6648565,,"Obituaries;Harrold,  Mary Jean",,,,,,,,28 Oct 2013,,,IEEE,IEEE Journals
1344,1460,Watts Humphrey: 4 July 1927 - 28 October 2010,F. Shull,Fraunhofer Center for Experimental Software Engineering,IEEE Software,20 Dec 2010,2011,28,1,5,5,"Watts Humphrey, one of the true pioneers of the software engineering discipline, passed away this past October. Watts Humphrey had a truly remarkable career, during which he developed or contributed to the Personal Software Process, Team Software Process, and Capability Maturity Model Integration (CMMI) framework, among many other contributions. Many colleagues (including IEEE Software board members and authors) who knew Watts have documented some of their memories here and on our website (www.computer.org/software/watts). Readers are invited to reminisce with them and contribute your own thoughts on the website.",1937-4194,,10.1109/MS.2011.21,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5672511,software engineeringWatts Humphreyhistory of computingsoftware development processPersonal Software ProcessTeam Software ProcessCapability Maturity Model IntegrationCMMI,"Obituaries;Humphrey, Watts",,,,,,,,20 Dec 2010,,,IEEE,IEEE Magazines
1345,1461,Guest Editors' Introduction: Software as a Business,J. Favaro; S. L. Pfleeger,Intecs; Dartmouth University,IEEE Software,23 Jun 2011,2011,28,4,22,25,"Software plays an increasingly important role in most aspects of business. Many new business models for software-intensive enterprises have arisen in the last decade, ranging from selling software as a service to off shoring and crowd sourcing. Governments and standards bodies have also intervened to influence business models for stimulating growth in the industry. The software business has also had ancillary effects including the creation of new sectors such as innovation management. The management of intellectual property rights has become a more critical issue as software is embedded in more and more products. The debate about whether the software business is fundamentally different from others will continue, even as the software business continues to transform itself.",1937-4194,,10.1109/MS.2011.77,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5929525,software;business model;open source;service;embedded systems,Special issues and sections;Software;Business;Marketing and sales;Strategic planning;Enterprise resource planning;Modeling;Product development;Productivity,business data processing;cloud computing;industrial property;innovation management;software engineering,software business;business model;software intensive enterprise;innovation management;intellectual property right;software as a service,,1.0,,5.0,,23 Jun 2011,,,IEEE,IEEE Magazines
1346,1462,Programming Languages,L. Tratt; A. Welc,King's College London; Oracle Labs,IEEE Software,15 Sep 2014,2014,31,5,33,34,"The guest editors of IEEE Software magazine's September/October issue describe the field of programming languages and why they selected the articles highlighted here. The Web extra at http://youtu.be/SmIc0Chc9Y0 is an audio recording in which author IEEE Software Multimedia Editor Davide Falessi interviews Laurence Tratt and Adam Welc, guest editors of IEEE Software magazine's September/October 2014 issue, about the field of programming languages.",1937-4194,,10.1109/MS.2014.119,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6898781,programming languages;software engineering,,,,,,,,,15 Sep 2014,,,IEEE,IEEE Magazines
1347,1463,John D. Musa,W. Everett; J. Cusick; L. Williams,SPRE (Software Process and Reliability Engineering); Walters Kluwer; North Carolina State University,IEEE Software,25 Aug 2009,2009,26,5,102,102,"This article looks back at the life of John Musa, known for his work in software reliability engineering.",1937-4194,,10.1109/MS.2009.132,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222805,John Musa;software engineering;software reliability engineering;software reliability,Software reliability;Reliability engineering,,,,,,,,25 Aug 2009,,,IEEE,IEEE Magazines
1348,1464,DevOps and Its Practices,L. Zhu; L. Bass; G. Champlin-Scharff,Data61 | CSIRO; Professional Education Consortium; IBM,IEEE Software,25 Apr 2016,2016,33,3,32,34,"DevOps aims to reduce the time between committing a system change and placing the change into normal production, while ensuring high quality. The article topics in this theme issue include using DevOps to migrate to microservices, adopting DevOps, and DevOps tools. The Web extra at https://youtu.be/NzX6JmwDS0s is an audio recording of Davide Falessi speaking with Len Bass and George Champlin-Scharff about the IEEE Software May/June 2016 theme issue on DevOps and its practices.",1937-4194,,10.1109/MS.2016.81,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7458765,DevOps;microservices;continuous deployment;continuous delivery;software development;software engineering,,,,,40.0,,4.0,,25 Apr 2016,,,IEEE,IEEE Magazines
1349,1465,The Reflective Software Engineer: Reflective Practice,T. Dybå; N. Maiden; R. Glass,SINTEF; City University London; Computing Trends,IEEE Software,13 Jun 2014,2014,31,4,32,36,"The capacity to reflect on past practice is important for continuous learning in software development. Reflection often takes place in cycles of experience followed by conscious application of learning from that experience, during which a software developer might explore comparisons, ponder alternatives, take diverse perspectives, and draw inferences, especially in new and/or complex situations. Such reflective practice has been shown in different disciplines to be an effective developmental practice for organizations, for teams, and for individuals. The guest editors of this special issue on reflection describe the concept in general and the selected articles in particular.",1937-4194,,10.1109/MS.2014.97,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6834681,reflection;software development;software engineering;practitioners,,,,,11.0,,12.0,,13 Jun 2014,,,IEEE,IEEE Magazines
1350,1466,Tracking Progress through Earned Value,H. Erdogmus,Kalemun Research,IEEE Software,19 Aug 2010,2010,27,5,2,7,"Considered a gross misnomer by some, earned value for progress tracking in software development projects is still little known in the software industry. But the concept shouldn't be so unfamiliar: tracking progress by earned value is similar to tracking progress through burndown charts-the ubiquitous, simple and powerful visuals that are so popular in agile software development. The two techniques, although developed independently in very different contexts, are similar in terms of their information content. This isn't a new discovery: Alistair Cockburn talked about the relationship between earned value and burndown charts as early as 2004 in Chapter 3 of his book Crystal Clear (Addison-Wesley, 2004). Section 7.3 of Gngori Melnik's and Gerard Meszaros' volume 1 of Acceptance Test Engineering Guide also discusses the same relationship.",1937-4194,,10.1109/MS.2010.130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5551010,software engineering;project management;performance measurement;earned value;earned value management;burndown charts;schedule variance;cost variance,,DP industry;project management;software development management;software prototyping,progress tracking;software development projects;software industry;agile software development;burndown charts;earned value,,,,,,19 Aug 2010,,,IEEE,IEEE Magazines
1351,1467,Modeling and Managing Context-Aware Systems’ Variability,K. Mens; R. Capilla; H. Hartmann; T. Kropf,Université catholique de Louvain; Rey Juan Carlos University; NXP Semiconductors; Robert Bosch GmbH,IEEE Software,13 Nov 2017,2017,34,6,58,63,"This theme issue provides an updated perspective on techniques to manage software system variability at runtime, to make software systems smarter and less dependent on human intervention.",1937-4194,,10.1109/MS.2017.4121225,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8106877,context awareness;context-aware systems;system variability;runtime variability;connected cars;context analysis;context-oriented programming;feature-oriented programming;object-oriented systems;software engineering;software development;contextual-variability modeling,,,,,2.0,,16.0,,13 Nov 2017,,,IEEE,IEEE Magazines
1352,1468,Guest Editors' Introduction: Successful Software Product Line Practices,J. D. McGregor; D. Muthig; K. Yoshimura; P. Jensen,Clemson University; Lufthansa Systems; Hitachi; OverWatch Textron,IEEE Software,19 Apr 2010,2010,27,3,16,21,"A software product line is a set of software-intensive systems sharing a common, managed set of features that satisfy the specific needs of a particular market segment or mission and that are developed from a common set of core assets in a prescribed way in place. Organizations adopting product development strategies that include a software product line have achieved impressive results, reducing product cycle time and increasing productivity by an order of magnitude. The software product line strategy is a blend of business and technical actions that lets an organization satisfy a wide range of customers, gain leverage with suppliers, meet the threats of substitute products, and deter other companies seeking to enter the market. The strategy is robust over a wide range of technologies, domains, and organizations of different structures, cultures, and goals. Service-oriented architectures, agile development methods, and open source business models have all played roles in successful product line organizations.",1937-4194,,10.1109/MS.2010.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5452144,software architecture;software product lines;software engineering,Asset management;Software development management;Product development;Productivity;Companies;Robustness;Service oriented architecture,business data processing;product development;software architecture;software reusability,software product line strategy;software-intensive systems;market segment;product development strategies;product cycle time reduction;service-oriented architectures;agile development methods;open source business models,,22.0,,18.0,,19 Apr 2010,,,IEEE,IEEE Magazines
1353,1469,Agility and Architecture: Can They Coexist?,P. Abrahamsson; M. A. Babar; P. Kruchten,University of Helsinki; IT University of Copenhagen; University of British Columbia,IEEE Software,25 Feb 2010,2010,27,2,16,22,"Agile development has significantly impacted industrial software development practices. However, despite its wide popularity, there's an increasing perplexity about software architecture's role and importance in agile approaches. Advocates of architecture's vital role in achieving quality goals for large software-intensive systems doubt the scalability of any development approach that doesn't pay sufficient attention to architecture. This article talks about software architecture being relevant to the basis of aspects such as communication among team members, inputs to subsequent design decisions, documenting design assumptions, and evaluating design alternatives. In a large software organization, implementing agile approaches isn't a straightforward adoption problem. Most likely, it will take several years to shorten the feedback cycles to benefit from the adaptability and earlier value-creation opportunities. Failure is a natural part of process improvement.",1937-4194,,10.1109/MS.2010.36,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420791,software architecture;agile development methods;software engineering,Computer architecture;Software architecture;Computer industry;Programming;Scalability;Feedback,software architecture;software development management,agile development;industrial software development practices;software intensive systems;software architecture;design decisions;design assumptions,,79.0,,32.0,,25 Feb 2010,,,IEEE,IEEE Magazines
1354,1470,Front Cover,,,IEEE Software,18 Aug 2011,2011,28,5,c1,c1,September/October IEEE Software: Engineering Fun cover,1937-4194,,10.1109/MS.2011.96,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5984782,Engineering Fun;IEEE Software,,,,,,,,,18 Aug 2011,,,IEEE,IEEE Magazines
1355,1471,Table of Contents,,,IEEE Software,16 Oct 2009,2009,26,6,2,3,November/December 2009 IEEE Software Table of Contents. Theme: Human Aspects of Software Engineering,1937-4194,,10.1109/MS.2009.189,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5286997,,,,,,,,,,16 Oct 2009,,,IEEE,IEEE Magazines
1356,1472,Software Experts Summit Advertisement,,,IEEE Software,26 Jun 2013,2013,30,4,c4,c4,"Software Experts Summit Advertisement. The first Web extra at http://youtu.be/KTUHr-1S_wo is a video preview of Software Experts Summit 2013, which wiwill focus on Smart Data Science: Harnessing Data for Intelligent Decision Making. Scheduled for 17 July at the Microsoft Campus in Redmond, Washington, speakers include James Whittaker of Microsoft, Paul Zikopoulos of IBM, Wolfram Schulte of Microsoft Research, Jeromy Carriere of Google, John Howie of Cloud Security Alliance, Ayse Bener of Ryerson University, and Forrest Shull of the Fraunhofer Center for Experimental Software Engineering.",1937-4194,,10.1109/MS.2013.87,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547635,Software Experts Summit Advertisement,,,,,,,,,26 Jun 2013,,,IEEE,IEEE Magazines
1357,1473,Table of Contents,,,IEEE Software,25 Aug 2009,2009,26,5,c2,1,IEEE Software September/October 2009 issue on End-User Software Engineering.,1937-4194,,10.1109/MS.2009.142,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5222781,,,,,,,,,,25 Aug 2009,,,IEEE,IEEE Magazines
1358,1474,Green Software,A. B. Bener; M. Morisio; A. Miranskyy,Ryerson University; Politecnico di Torino; Ryerson University,IEEE Software,21 Apr 2014,2014,31,3,36,39,"Most studies and regulatory controls focus on hardware-related measurement, analysis, and control for energy consumption. However, all forms of hardware include significant software components. Although software systems don't consume energy directly, they affect hardware utilization, leading to indirect energy consumption. Therefore, it's important to engineer software to optimize its energy consumption. The software engineering research domain has recently been paying attention to sustainability, as the increased number of publications, empirical studies, and conferences on the topic demonstrate. The guest editors of this special issue explain the articles they selected to highlight this important research area. The Web extra at http://youtu.be/h0tQoOH9_aM is an audio interview in which IEEE Software multimedia editor Davide Falessi interviews guest editor Ayse Basar Bener about how green software can help minimize the negative effects of software products and their development.",1937-4194,,10.1109/MS.2014.62,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6802987,green software;green IT;energy efficiency;power usage;datacenter;cloud,,,,,3.0,,1.0,,21 Apr 2014,,,IEEE,IEEE Magazines
1359,1475,David Notkin: 1955-2013,,,IEEE Software,26 Jun 2013,2013,30,4,7,7,"Members of the software research community, including IEEE Software Editor in Chief Forrest Shull, IEEE Software Advisory Board Chair Emerita Frances Paulisch, IEEE Software Editor in Chief Emeritus Hakan Erdogmus, and IEEE Transactions on Software Engineering Editor in Chief Bashar Nuseibeh remember David Notkin, who recently passed away.",1937-4194,,10.1109/MS.2013.74,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6547599,David Notkin,"Obituaries;Notkin, David",,,,,,,,26 Jun 2013,,,IEEE,IEEE Magazines
1360,1476,Guest Editors' Introduction: Software Architecture: Framing Stakeholders' Concerns,P. Lago; P. Avgeriou; R. Hilliard,VU University Amsterdam; University of Groningen; Freelance Software Architect,IEEE Software,14 Oct 2010,2010,27,6,20,24,"As noted earlier, some stakeholder concerns are well-served today by available architecture viewpoints, frameworks, or ADLs, while others aren't expressible with available, off-the-shelf approaches. Hence the theme of this special issue: exploring the space of architecting in the face of multiple stakeholder concerns and looking for solutions that help the architect in that space. The articles in this issue all demonstrate techniques for framing one or more stakeholder concerns. Some have confronted the topic within software architecture; others are included because they offer insights on concerns and viewpoints from other branches of software engineering.",1937-4194,,10.1109/MS.2010.142,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5604359,stakeholder concerns;architecture;framework;viewpoints;software development;software life cycle,Special issues and sections;Software development;Product life cycle management;Investments;Software architecture,,,,13.0,,5.0,,14 Oct 2010,,,IEEE,IEEE Magazines
1361,0,"A Progression Model of Software Engineering Goals, Challenges, and Practices in Start-Ups",E. Klotins; M. Unterkalmsteiner; P. Chatzipetrou; T. Gorschek; R. Prikladnicki; N. Tripathi; L. B. Pompermaier,"Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Informatics, CERIS, Örebro University School of Business, Örebro, Sweden; Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Sweden; M3S Research Unit, University of Oulu, Oulu, Finland; School of Technology, Pontifical Catholic University of Rio Grande do Sul, Porto Alegre, Brazil",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,498,521,"Context: Software start-ups are emerging as suppliers of innovation and software-intensive products. However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups. As a result, there is insufficient support for software engineering in the start-up context. Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups. Such data allows researchers to understand better how goals and challenges are related to practices. This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges. Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice. Method: We use a case survey method to gather first-hand, in-depth experiences from a large sample of software start-ups. We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis. Results: We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups. We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity). Thus, creating the progression model guiding software engineering efforts in start-ups. Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies. However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors.",1939-3520,,10.1109/TSE.2019.2900213,CNpq and FAPERGS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643804,Software start-up;software engineering practices;progression model,Software;Software engineering;Companies;Market opportunities;Requirements engineering;Analytical models,innovation management;organisational aspects;project management;software development management;software engineering;statistical analysis,start-up cases;primary software engineering challenge;software engineering efforts;engineering practices;start-up companies;traditional software engineering practices;software start-ups;software engineering goals,,1.0,,96.0,IEEE,17 Feb 2019,,,IEEE,IEEE Journals
1362,1,A Comparison of Natural Language Understanding Platforms for Chatbots in Software Engineering,A. Abdellatif; K. Badran; D. Costa; E. Shihab,"Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: ahmad.abdellatif87@gmail.com); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: badrankhaled97@gmail.com); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: diegoelias1@gmail.com); Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, H3G 1M8 (e-mail: emadshihab@gmail.com)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Chatbots are envisioned to dramatically change the future of Software Engineering, allowing practitioners to chat and inquire about their software projects and interact with different services using natural language. At the heart of every chatbot is a Natural Language Understanding (NLU) component that enables the chatbot to understand natural language input. Recently, many NLU platforms were provided to serve as an off-the-shelf NLU component for chatbots, however, selecting the best NLU for Software Engineering chatbots remains an open challenge. Therefore, in this paper, we evaluate four of the most commonly used NLUs, namely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on which NLU should be used in Software Engineering based chatbots. Specifically, we examine the NLUs' performance in classifying intents, confidence scores stability, and extracting entities. To evaluate the NLUs, we use two datasets that reflect two common tasks performed by Software Engineering practitioners, 1) the task of chatting with the chatbot to ask questions about software repositories 2) the task of asking development questions on Q&A forums (e.g., Stack Overflow). According to our findings, IBM Watson is the best performing NLU when considering the three aspects (intents classification, confidence scores, and entity extraction). However, the results from each individual aspect show that, in intents classification, IBM Watson performs the best with an F1-measure>84%, but in confidence scores, Rasa comes on top with a median confidence score higher than 0.91. Our results also show that all NLUs, except for Dialogflow, generally provide trustable confidence scores. For entity extraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE tasks. Our results provide guidance to software engineering practitioners when deciding which NLU to use in their chatbots.",1939-3520,,10.1109/TSE.2021.3078384,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426404,Software Chatbots;Natural Language Understanding Platforms;Empirical Software Engineering,Chatbot;Task analysis;Software engineering;Software;Feature extraction;XML;Java,,,,,,,IEEE,7 May 2021,,,IEEE,IEEE Early Access Articles
1363,2,A Method to Assess and Argue for Practical Significance in Software Engineering,R. Torkar; C. A. Furia; R. Feldt; F. Gomes de Oliveira Neto; L. Gren; P. Lenberg; N. A. Ernst,"Software Engineering, University of Gothenburg, 3570 Goteborg, n7a, Sweden, (e-mail: richard.torkar@cse.gu.se); Informatics, USI, 27216 Lugano, Ticino, Switzerland, 6900 (e-mail: furiac@usi.ch); Software Engineering division, Chalmers University of Technology Department of Computer Science and Engineering, 541960 Goteborg, V'stra Gtaland, Sweden, (e-mail: robert.feldt@chalmers.se); Software Engineering, University of Gothenburg, 3570 Goteborg, n/a, Sweden, (e-mail: gomesf@chalmers.se); Software Engineering, Computer Science and Engineering, Gothenburg, Gothenburg, Sweden, SE-412 96 (e-mail: lucas.gren@cse.gu.se); Department of Computer Science of Engineering, Chalmers University, Gothenburg, V'stra Gtaland, Sweden, 42163 (e-mail: perle@chalmers.se); Computer Science, University of Victoria, 8205 Victoria, British Columbia, Canada, (e-mail: nernst@uvic.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"A key goal of empirical research in software engineering is to assess practical significance, which answers whether the observed effects of some compared treatments show a relevant difference in practice in realistic scenarios. Even though plenty of standard techniques exist to assess statistical significance, connecting it to practical significance is not straightforward or routinely done; indeed, only a few empirical studies in software engineering assess practical significance in a principled and systematic way. In this paper, we argue that Bayesian data analysis provides suitable tools to assess practical significance rigorously. We demonstrate our claims in a case study comparing different test techniques. The case study's data was previously analyzed (Afzal et al., 2015) using standard techniques focusing on statistical significance. Here, we build a multilevel model of the same data, which we fit and validate using Bayesian techniques. Our method is to apply cumulative prospect theory on top of the statistical model to quantitatively connect our statistical analysis output to a practically meaningful context. This is then the basis both for assessing and arguing for practical significance. Our study demonstrates that Bayesian analysis provides a technically rigorous yet practical framework for empirical software engineering. A substantial side effect is that any uncertainty in the underlying data will be propagated through the statistical model, and its effects on practical significance are made clear. Thus, in combination with cumulative prospect theory, Bayesian analysis supports seamlessly assessing practical significance in an empirical software engineering context, thus potentially clarifying and extending the relevance of research for practitioners.",1939-3520,,10.1109/TSE.2020.3048991,Marianne and Marcus Wallenberg Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314270,practical significance;statistical significance;Bayesian analysis;empirical software engineering,Bayes methods;Data models;Software engineering;Statistical analysis;Analytical models;Testing;Decision making,,,,,,,CCBY,5 Jan 2021,,,IEEE,IEEE Early Access Articles
1364,3,Software Engineering for Machine-Learning Applications: The Road Ahead,F. Khomh; B. Adams; J. Cheng; M. Fokaefs; G. Antoniol,Polytechnique Montréal; Polytechnique Montréal; Polytechnique Montréal; Polytechnique Montréal; Polytechnique Montréal,IEEE Software,27 Sep 2018,2018,35,5,81,84,"The First Symposium on Software Engineering for Machine Learning Applications (SEMLA) aimed to create a space in which machine learning (ML) and software engineering (SE) experts could come together to discuss challenges, new insights, and practical ideas regarding the engineering of ML and AI-based systems. Key challenges discussed included the accuracy of systems built using ML and AI models, the testing of those systems, industrial applications of AI, and the rift between the ML and SE communities. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.3571224,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474484,First Symposium on Software Engineering for Machine Learning Applications;SEMLA;machine learning;artificial intelligence;AI;software engineering;SE;software development;Invited Content,Learning systems;Software engineering;Software systems;Software development;Machine learning;Artificial intelligence,artificial intelligence;learning (artificial intelligence);software engineering,AI-based systems;ML model;software engineering for machine learning applications;SEMLA;industrial applications,,7.0,,0.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1365,4,"Yesterday, Today, and Tomorrow: 50 Years of Software Engineering",M. Broy,Technische Universität München and Zentrum Digitalisierung.Bayern,IEEE Software,27 Sep 2018,2018,35,5,38,43,"In 2018, we're now 50 years after the famous groundbreaking conference on software engineering in Garmisch, organized by its chairman F.L. Bauer and his cochairs L. Bolliet and H.J. Helms. This conference introduced the notion and discipline of software engineering. This is a moment to look back at what we've achieved, what we haven't achieved, where we are today, and what challenges lie ahead. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290111138,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409912,software engineering;software development;history of software engineering,Software engineering;Programming;Computer architecture;Computer languages;Software systems,software engineering,software engineering;software crisis;computer hardware;software production,,,,11.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1366,5,Closing the Gap Between Software Engineering Education and Industrial Needs,V. Garousi; G. Giray; E. Tuzun; C. Catal; M. Felderer,"Software Engineering, Queen’s University Belfast, United Kingdom; NA; Bilkent University, Ankara, Turkey; Wageningen University; University of Innsbruck, Austria",IEEE Software,12 Feb 2020,2020,37,2,68,77,"Many recent software engineering graduates often face difficulties when beginning their professional careers, due to misalignment of the skills learned in their university education with what is needed in industry. In this article, we report a literature review of the studies that have been done to make improvements on this issue.",1937-4194,,10.1109/MS.2018.2880823,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664487,Software engineering education;industry needs;important skills;knowledge gap;software engineering curriculum,Software engineering;Computer science education;Software engineering;Education courses;Knowledge engineering;Computer science;Information systems,computer science education;educational courses;educational institutions;engineering education;software engineering,university education;software engineering education;software engineering graduates;professional careers;industrial needs,,2.0,,14.0,,10 Mar 2019,,,IEEE,IEEE Magazines
1367,6,"Software Engineering’s Top Topics, Trends, and Researchers",G. Mathew; T. Menzies,North Carolina State University; North Carolina State University,IEEE Software,27 Sep 2018,2018,35,5,88,93,"For this theme issue on the 50th anniversary of software engineering (SE), Redirections offers an overview of the twists, turns, and numerous redirections seen over the years in the SE research literature. Nearly a dozen topics have dominated the past few decades of SE research-and these have been redirected many times. Some are gaining popularity, whereas others are becoming increasingly rare. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.3571230,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474491,latent Dirichlet allocation;text mining;software engineering research;software engineering;software development;redirections,Text mining;Object oriented modeling;Market research;Software measurement;Software engineering,research and development;software engineering,SE research literature;software engineering,,1.0,,11.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1368,7,Half a Century of Software Engineering Education: The CMU Exemplar,N. R. Mead; D. Garlan; M. Shaw,Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,IEEE Software,27 Sep 2018,2018,35,5,25,31,"From the aspirational title of the 1968 NATO conference, software engineering has evolved to a well-defined engineering discipline with strong educational underpinnings. The supporting educational foundation has grown from a few courses in programming languages and data structures, evolving through structured programming, correctness formalisms, and state machine abstractions to full curricula and degree programs. With this context in mind, the authors discuss the evolution of software engineering education and pedagogy, software engineering principles, and future needs, drawing specifically on their experience at Carnegie Mellon University. Reflecting on the software development profession today, they believe that formal software engineering education is needed at least as much as it was in earlier decades. However, it must address the increasing diversity of the developer community, and it must be an education based on the enduring principles that will last a lifetime. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290110743,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409913,software engineering education;software engineering history;software engineering practice;Carnegie Mellon University;Software Engineering Institute;software development;software engineering,Software engineering;History;Technology forecasting;Computer science,computer science education;data structures;educational courses;educational institutions;software engineering,degree programs;formal software engineering education;educational foundation;CMU exemplar;data structure;state machine abstraction;Carnegie Mellon University;programming languages course,,1.0,,16.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1369,8,Software Engineering Research and Industry: A Symbiotic Relationship to Foster Impact,V. Basili; L. Briand; D. Bianculli; S. Nejati; F. Pastore; M. Sabetzadeh,"University of Maryland, College Park; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg",IEEE Software,27 Sep 2018,2018,35,5,44,49,"Software engineering is not only an increasingly challenging endeavor that goes beyond the intellectual capabilities of any single individual engineer but also an intensely human one. Tools and methods to develop software are employed by engineers of varied backgrounds within a large variety of organizations and application domains. As a result, the variation in challenges and practices in system requirements, architecture, and quality assurance is staggering. Human, domain, and organizational factors define the context within which software engineering methodologies and technologies are to be applied and therefore the context that research needs to account for, if it is to be impactful. This article provides an assessment of the current challenges faced by software engineering research in achieving its potential, a description of the root causes of such challenges, and a proposal for the field to move forward and become more impactful through collaborative research and innovation between public research and industry. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290110216,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409904,software engineering research;empirical software engineering;collaborative research;context-driven research;software engineering;software development,Software engineering;Collaboration;Software development;Context modeling,DP industry;innovation management;organisational aspects;quality assurance;software engineering,software engineering methodologies;collaborative research;quality assurance;organizational factors;software engineering technologies;innovation;system requirements;software engineering industry,,1.0,,8.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1370,9,Software Engineering for Internet of Things,M. Fahmideh; A. A. Abbasi; A. Behnaz; J. Grundy; W. Susilo,"UTS, University of Technology Sydney Faculty of Engineering and Information Technology, 120558 Sydney, New South Wales, Australia, 2007 (e-mail: mehdi.fahmideh@gmail.com); Computer Science and Engineering, University of Hail, 48138 Hail, Hail, Saudi Arabia, (e-mail: ahmad.aakash@gmail.com); Computer science, University of New South Wales, 7800 Sydney, New South Wales, Australia, (e-mail: ali.behnaz@unsw.edu.au); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); School of Computing and IT, University of Wollongong, 8691 Wollongong, New South Wales, Australia, 2522 (e-mail: wsusilo@uow.edu.au)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Internet of Things based systems (IoT systems for short) are becoming increasingly popular across different industrial domains and their development is rapidly increasing to provide value-added services to end-users and citizens. Little research to date uncovers the core development process lifecycle needed for IoT systems, and thus software engineers find themselves unprepared and unfamiliar with this new genre of system development. To ameliorate this gap, we conducted a mixed quantitative and qualitative research study where we derived a conceptual process framework from the extant literature on IoT, through which 27 key tasks for incorporation into the development processes of IoT systems were identified. The framework was then validated by means of a survey of 127 IoT practitioners from 35 countries across 6 continents with 15 different industry backgrounds. Our research provides an understanding of the most important development process tasks and informs both software engineering practitioners and researchers of the challenges and recommendations related to the development of next-generation of IoT systems.",1939-3520,,10.1109/TSE.2021.3070692,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9398558,software engineering;software management;software development process;empirical software engineering;Internet of Things (IoT),Software engineering;Task analysis;Software;Internet of Things;Systematics;Information technology;Hardware,,,,,,,IEEE,7 Apr 2021,,,IEEE,IEEE Early Access Articles
1371,10,Industry–Academia Collaboration in Software Engineering,J. C. Carver; R. Prikladnicki,University of Alabama; Pontifical Catholic University,IEEE Software,27 Sep 2018,2018,35,5,120,124,"This article aims to encourage more industry-academia collaborations by highlighting examples of successful collaborations. Through these examples, the authors hope to help practitioners and researchers understand the breadth of options available for such interactions. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.3571250,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474518,software architecture;automatic bug assignment;software quality;requirements-based testing;industry–academia collaboration;software development;software engineering;Practitioners’ Digest,Software engineering;Computer science education;Collaboration,software engineering,software engineering;industry-academia collaboration,,1.0,,,,27 Sep 2018,,,IEEE,IEEE Magazines
1372,11,Trends and Challenges for Software Engineering in the Mobile Domain,L. Baresi; W. G. Griswold; G. A. Lewis; M. Autili; I. Malavolta; C. Julien,"Politecnico di Milano, Milano, Italy; Computer Science and Engineering, University of California, San Diego, La Jolla, California United States; Software Engineering Institute, Carnegie Mellon, Pittsburgh, Pennsylvania United States; University of L'Aquila, L'Aquila, Italy, Italy; Computer Science, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands; Software Engineering, University of Texas at Austin, Austin, Texas United States",IEEE Software,23 Dec 2020,2021,38,1,88,96,"Mobile computing is becoming a key aspect of our lives. This article builds on conversations held during the 2018 IEEE/ACM International Conference on Mobile Software Engineering and Systems, highlighting mobile computing's impact on software engineering practices, the transition from research to industry, and related areas.",1937-4194,,10.1109/MS.2020.2994306,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091517,Mobile computing;Software engineering;Android and beyond;Research and Industry,Software engineering;Smart phones;Software;Software tools;Mobile computing;Sensors,computer science education;mobile computing;software engineering,Mobile domain;Mobile Software Engineering;highlighting mobile computing;software engineering practices,,1.0,,20.0,IEEE,13 May 2020,,,IEEE,IEEE Magazines
1373,12,Cognitive Biases in Software Engineering: A Systematic Mapping Study,R. Mohanani; I. Salman; B. Turhan; P. Rodríguez; P. Ralph,"M3S Group, University of Oulu, Oulu, Finland; M3S Group, University of Oulu, Oulu, Finland; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; M3S Group, University of Oulu, Oulu, Finland; Department of Computer Science, University of Auckland, Auckland, New Zealand",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1318,1339,"One source of software project challenges and failures is the systematic errors introduced by human cognitive biases. Although extensively explored in cognitive psychology, investigations concerning cognitive biases have only recently gained popularity in software engineering research. This paper therefore systematically maps, aggregates and synthesizes the literature on cognitive biases in software engineering to generate a comprehensive body of knowledge, understand state-of-the-art research and provide guidelines for future research and practise. Focusing on bias antecedents, effects and mitigation techniques, we identified 65 articles (published between 1990 and 2016), which investigate 37 cognitive biases. Despite strong and increasing interest, the results reveal a scarcity of research on mitigation techniques and poor theoretical foundations in understanding and interpreting cognitive biases. Although bias-related research has generated many new insights in the software engineering community, specific bias mitigation techniques are still needed for software professionals to overcome the deleterious effects of cognitive biases on their work.",1939-3520,,10.1109/TSE.2018.2877759,Oulun Yliopisto; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8506423,Antecedents of cognitive bias;cognitive bias;debiasing;effects of cognitive bias;software engineering;systematic mapping,Cognition;Software engineering;Software project management,cognition;psychology;software engineering,systematic mapping study;software project challenges;human cognitive biases;cognitive psychology;software engineering research;bias antecedents;software engineering community;specific bias mitigation techniques;systematic errors,,1.0,,109.0,IEEE,24 Oct 2018,,,IEEE,IEEE Journals
1374,13,A Systematic Review of Interaction in Search-Based Software Engineering,A. Ramírez; J. R. Romero; C. L. Simons,"Department of Computer Science and Numerical Analysis, University of Córdoba, Córdoba, Spain; Department of Computer Science and Numerical Analysis, University of Córdoba, Córdoba, Spain; Department of Computer Science and Creative Technologies, University of the West of England, Bristol, United Kingdom",IEEE Transactions on Software Engineering,26 Aug 2019,2019,45,8,760,781,"Search-Based Software Engineering (SBSE) has been successfully applied to automate a wide range of software development activities. Nevertheless, in those software engineering problems where human evaluation and preference are crucial, such insights have proved difficult to characterize in search, and solutions might not look natural when that is the expectation. In an attempt to address this, an increasing number of researchers have reported the incorporation of the 'human-in-the-loop' during search and interactive SBSE has attracted significant attention recently. However, reported results are fragmented over different development phases, and a great variety of novel interactive approaches and algorithmic techniques have emerged. To better integrate these results, we have performed a systematic literature review of interactive SBSE. From a total of 669 papers, 26 primary studies were identified. To enable their analysis, we formulated a classification scheme focused on four crucial aspects of interactive search, i.e., the problem formulation, search technique, interactive approach, and the empirical framework. Our intention is that the classification scheme affords a methodological approach for interactive SBSE. Lastly, as well as providing a detailed cross analysis, we identify and discuss some open issues and potential future trends for the research community.",1939-3520,,10.1109/TSE.2018.2803055,Spanish Ministry of Economy and Competitiveness; Spanish Ministry of Education; FEDER; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283568,Search-based software engineering;interaction;systematic literature review;optimization,Software;Software engineering;Search problems;Optimization;Systematics;Market research;Software metrics,interactive systems;reviews;search problems;software engineering,search-based software engineering;development phases;search technique;interactive search;systematic literature review;interactive approach;interactive SBSE;human evaluation;software engineering problems;software development activities,,12.0,,100.0,,6 Feb 2018,,,IEEE,IEEE Journals
1375,14,A Survey on the Use of Computer Vision to Improve Software Engineering Tasks,M. Bajammal; A. Stocco; D. Mazinanian; A. Mesbah,"Electrical and Computer Engineering, The University of British Columbia, 8166 Vancouver, British Columbia, Canada, (e-mail: bajammal@ece.ubc.ca); Department of Electrical and Computer Engineering, U. British Columbia, Vancouver, British Columbia, Canada, V6T 1Z4 (e-mail: andrea.stocco@usi.ch); Electrical and Computer Engineering, University of British Columbia Faculty of Applied Science, Vancouver, British Columbia, Canada, (e-mail: dmazinanian@ece.ubc.ca); Electrical and Computer Engineering, University of British Columbia, VANCOUVER, British Columbia, Canada, V6T1Z4 (e-mail: amesbah@ece.ubc.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software engineering (SE) research has traditionally revolved around engineering the source code. However, novel approaches that analyze software through computer vision have been increasingly adopted in SE. These approaches allow analyzing the software from a different complementary perspective other than the source code, and they are used to either complement existing source code-based methods, or to overcome their limitations. The goal of this manuscript is to survey the use of computer vision techniques in SE with the aim of assessing their potential in advancing the field of SE research. We examined an extensive body of literature from top-tier SE venues, as well as venues from closely related fields (machine learning, computer vision, and human-computer interaction). Our inclusion criteria targeted papers applying computer vision techniques that address problems related to any area of SE. We collected an initial pool of 2,716 papers, from which we obtained 66 final relevant papers covering a variety of SE areas. We analyzed what computer vision techniques have been adopted or designed, for what reasons, how they are used, what benefits they provide, and how they are evaluated. Our findings highlight that visual approaches have been adopted in a wide variety of SE tasks, predominantly for effectively tackling software analysis and testing challenges in the web and mobile domains. The results also show a rapid growth trend of the use of computer vision techniques in SE research.",1939-3520,,10.1109/TSE.2020.3032986,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237151,Computer Vision;Software Engineering;Survey,Testing;Visualization;Software engineering;Computer vision;Software;Task analysis;Graphical user interfaces,,,,1.0,,,,22 Oct 2020,,,IEEE,IEEE Early Access Articles
1376,15,App Store Effects on Software Engineering Practices,A. A. Al-Subaihin; F. Sarro; S. Black; L. Capra; M. Harman,"University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,300,319,"In this paper, we study the app store as a phenomenon from the developers' perspective to investigate the extent to which app stores affect software engineering tasks. Through developer interviews and questionnaires, we uncover findings that highlight and quantify the effects of three high-level app store themes: bridging the gap between developers and users, increasing market transparency and affecting mobile release management. Our findings have implications for testing, requirements engineering and mining software repositories research fields. These findings can help guide future research in supporting mobile app developers through a deeper understanding of the app store-developer interaction.",1939-3520,,10.1109/TSE.2019.2891715,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606261,Empirical software engineering;mobile app development;app store analysis,Software engineering;Software;Interviews;Data mining;Testing;Data collection;Business,data mining;formal specification;mobile computing;software engineering,app store effects;software engineering practices;software engineering tasks;developer interviews;high-level app store themes;market transparency;affecting mobile release management;requirements engineering;mining software repositories research fields;mobile app developers;app store-developer interaction,,5.0,,100.0,IEEE,9 Jan 2019,,,IEEE,IEEE Journals
1377,16,A Procedure and Guidelines for Analyzing Groups of Software Engineering Replications,A. Santos; S. Vegas; M. Oivo; N. Juristo,"M-Group, University of Oulu, Oulu, Oulu Finland (e-mail: Adrian.Santos.Parrilla@oulu.fi); Languajes, computer systems and software engineering, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: svegas@fi.upm.es); Department of Information Processing Science, University of Oulu, Oulu, Oulu Finland 90014 (e-mail: Markku.Oivo@oulu.fi); Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: natalia@fi.upm.es)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Context: Researchers from different groups and institutions are collaborating on building groups of experiments by means of replication (i.e., conducting groups of replications). Disparate aggregation techniques are being applied to analyze groups of replications. The application of unsuitable techniques to aggregate replication results may undermine the potential of groups of replications to provide in-depth insights from experiment results. Objectives: Provide an analysis procedure with a set of embedded guidelines to aggregate software engineering (SE) replication results. Method: We compare the characteristics of groups of replications for SE and other mature experimental disciplines such as medicine and pharmacology. In view of their differences, the limitations with regard to the joint data analysis of groups of SE replications and the guidelines provided in mature experimental disciplines to analyze groups of replications, we build an analysis procedure with a set of embedded guidelines specifically tailored to the analysis of groups of SE replications. We apply the proposed analysis procedure to a representative group of SE replications to illustrate its use. Results: All the information contained within the raw data should be leveraged during the aggregation of replication results. The analysis procedure that we propose encourages the use of stratified individual participant data and aggregated data in tandem to analyze groups of SE replications. Conclusion: The aggregation techniques used to analyze groups of replications should be justified in research articles. This will increase the reliability and transparency of joint results. The proposed guidelines should ease this endeavor.",1939-3520,,10.1109/TSE.2019.2935720,"Ministerio de Ciencia, Innovación y Universidades; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805425,Replication;Statistical Analysis;Aggregated Data;Individual Participant Data;Narrative Synthesis,Guidelines;Reliability;Aggregates;Buildings;Data analysis;Biological system modeling;Software engineering,,,,,,,,19 Aug 2019,,,IEEE,IEEE Early Access Articles
1378,17,Software Engineering for Data Analytics,M. Kim,"Computer Science, UCLA, Los Angeles, California United States",IEEE Software,19 Jun 2020,2020,37,4,36,42,"We are at an inflection point where software engineering meets the data-centric world of big data, machine learning, and artificial intelligence. In this article, I summarize findings from studies of professional data scientists and discuss my perspectives on open research problems to improve data-centric software development.",1937-4194,,10.1109/MS.2020.2985775,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9056482,,Big Data;Software engineering;Data analysis;Debugging;Artificial intelligence;Software engineering;Software testing,Big Data;data analysis;learning (artificial intelligence);software engineering,inflection point;data analytics;software engineering;data-centric software development;professional data scientists;artificial intelligence;machine learning;Big Data,,1.0,,14.0,,3 Apr 2020,,,IEEE,IEEE Magazines
1379,18,Applying Software Engineering Standards in Very Small Entities: From Startups to Grownups,C. Y. Laporte; M. Munoz; J. Mejia Miranda; R. V. O’Connor,École de technologie supérieure; Centro de Investigación en Matemáticas; Centro de Investigación en Matemáticas; Dublin City University,IEEE Software,25 Dec 2017,2018,35,1,99,103,"Very small entities (VSEs) are organizations with up to 25 people. The ISO/IEC 29110 series of standards and guides target VSEs with little or no experience or expertise in selecting the appropriate processes from lifecycle standards and tailoring them to a project's needs. This article gives an overview of ISO/IEC 29110, some examples of VSEs that have implemented it, and those implementations' results.",1937-4194,,10.1109/MS.2017.4541041,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239934,software engineering standards;ISO/IEC 29110;very small entities;software engineering;software development;Invited Content,IEC Standards;ISO Standards;Software engineering;Software development;Standards organizations,IEC standards;ISO standards;software development management;software process improvement;software standards,startups;grownups;VSEs;organizations;experience;appropriate processes;lifecycle standards;software engineering standards;very small entities;ISO-IEC 29110 series,,6.0,,9.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1380,19,Impact of Affirmative Action on Female Computer Science/Software Engineering Undergraduate Enrollment,J. Simmonds; M. C. Bastarrica; N. Hitschfeld-Kahler,"Computer Science, University of Chile, Santiago, 8370456, Chile; Computer Science, University of Chile, Santiago, 8370456, Chile; Computer Science, University of Chile, Santiago, 8370456, Chile",IEEE Software,15 Feb 2021,2021,38,2,32,37,"Affirmative action in college admissions has been touted as a way to close the gender gap in science, technology, engineering, and mathematics programs. We report a study of one such program, where we discovered a positive effect on female enrollment and a smaller effect on a combined computer science and software engineering degree.",1937-4194,,10.1109/MS.2020.3044841,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293108,,Software engineering;Market research;Conferences;STEM;Programming;Organizations,computer science education;educational courses;educational institutions;engineering education;further education;gender issues;software engineering,affirmative action;college admissions;gender gap;mathematics programs;female enrollment;combined computer science;software engineering degree,,,,15.0,IEEE,14 Dec 2020,,,IEEE,IEEE Magazines
1381,20,Mining Treatment-Outcome Constructs from Sequential Software Engineering Data,M. Nayebi; G. Ruhe; T. Zimmermann,"Ecole Polytechnique of Montreal, Montreal, QC, Canada; Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,393,411,"Many investigations in empirical software engineering look at sequences of data resulting from development or management processes. In this paper, we propose an analytical approach called the Gandhi-Washington Method (GWM) to investigate the impact of recurring events in software projects. GWM takes an encoding of events and activities provided by a software analyst as input. It uses regular expressions to automatically condense and summarize information and infer treatments. Relating the treatments to the outcome through statistical tests, treatment-outcome constructs are automatically mined from the data. The output of GWM is a set of treatment-outcome constructs. Each treatment in the set of mined constructs is significantly different from the other treatments considering the impact on the outcome and/or is structurally different from other treatments considering the sequence of events. We describe GWM and classes of problems to which GWM can be applied. We demonstrate the applicability of this method for empirical studies on sequences of file editing, code ownership, and release cycle time.",1939-3520,,10.1109/TSE.2019.2892956,Natural Sciences and Engineering Research Council of Canada; Alberta Innovates - Technology Futures; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620369,Pattern mining;mining software repositories;regular expressions;analytics;release cycle time patterns;code ownership,Software;Computer bugs;Encoding;Data mining;Software engineering;Testing;Itemsets,data mining;software engineering;statistical testing,sequential software engineering data;GWM;software projects;software analyst;Gandhi-Washington method;treatment-outcome constructs,,,,54.0,IEEE,20 Jan 2019,,,IEEE,IEEE Journals
1382,21,Five Predictions for the Coming Decades of Software,M. Kersten,Tasktop,IEEE Software,27 Sep 2018,2018,35,5,7,9,"To help celebrate software engineering's 50th anniversary, department editor Mik Kersten considers how software engineering will evolve over the coming 50 years. His five predictions aren't intended to be precise; they aim to provide discussion topics for the shape of software engineering trends to come. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.3571232,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474514,Carlota Perez;artificial intelligence;AI;software engineering;software development;On DevOps,Technology forecasting;Software engineering,software engineering,software engineering trends;software engineering's 50th anniversary,,,,3.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1383,22,"Empirical Software Engineering, Predictive Models, and Product Lines",J. C. Carver; E. Santana de Almeida; R. Capilla; L. Minku; M. Torchiano; A. Valdezate,University of Alabama; Federal University of Bahia; Rey Juan Carlos University of Madrid; University of Leicester; Politecnico di Torino; Ibermatica,IEEE Software,4 May 2018,2018,35,3,8,11,"This issue’s column reports on presentations at the 11th International Symposium on Empirical Software Engineering and Measurement, 13th International Conference on Predictive Models and Data Analytics in Software Engineering, and 21st International Systems and Software Product Line Conference.",1937-4194,,10.1109/MS.2018.2141018,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354421,11th International Symposium on Empirical Software Engineering and Measurement;13th International Conference on Predictive Models and Data Analytics in Software Engineering;21st International Systems and Software Product Line Conference;empirical software engineering;predictive models;data analytics;software product lines;product line engineering;developer productivity;issue resolution;agile development;microservices;software engineering;software development;Practitioners’ Digest,,,,,,,,,4 May 2018,,,IEEE,IEEE Magazines
1384,23,Software Engineering Antipatterns in Start-Ups,E. Klotins; M. Unterkalmsteiner; T. Gorschek,"Software Engineering, Blekinge Institute of Technology; Free University of Bozen-Bolzano; Blekinge Institute of Technology",IEEE Software,21 Feb 2019,2019,36,2,118,126,"Software start-up failures are often explained with poor business models, market issues, or insufficient funding. Inadequacies in software engineering could be a significant contributing factor to the high start-up failure rate and precede any marketing or business related challenges. We reveal three antipatterns associated with start-up progression phases.",1937-4194,,10.1109/MS.2018.227105530,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356173,Software;Software Engineering;Requirements;specifications;Software quality;SQA;management;programming teams,Software engineering;Software development;Companies;Business;Investment,DP industry;electronic commerce;marketing;software engineering;uninterruptible power supplies,marketing;start-up progression phases;software engineering antipatterns;start-ups;poor business models;market issues;insufficient funding;significant contributing factor;high start-up failure rate,,2.0,,15.0,,8 May 2018,,,IEEE,IEEE Magazines
1385,24,Does Distance Still Matter? Revisiting Collaborative Distributed Software Design,R. Jolak; A. Wortmann; M. Chaudron; B. Rumpe,Chalmers University of Technology and Gothenburg University; RWTH Aachen University; Chalmers University of Technology and Gothenburg University; RWTH Aachen University,IEEE Software,29 Nov 2018,2018,35,6,40,47,"Global software engineering requires supporting distributed collaboration for most software development activities. However, geographical distance challenges effective collaboration. Nowadays, we're witnessing significant advances in communication and collaboration technologies. So, researchers explored whether these advances enable effective remote collaboration. To that end, they studied the design activities of both colocated and distributed professional software designers. The findings are based on analysis of video recordings of design sessions and questionnaires. The researchers found that despite comprehensive technological improvements, distance still matters. To ensure effective distributed software design, designers must consider extra (nontechnical) details. This article is part of a theme issue on collaborative modeling.",1937-4194,,10.1109/MS.2018.290100920,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409905,global software engineering;GSE;collaborative software design;collaborative software modeling;distributed software design;software design communication;software design decisions;software design reasoning;software models;interactive whiteboards;computer-supported cooperative work;CSCW;software engineering;software development,Collaborative software;Software design;Software engineering;Software development,groupware;software engineering,distributed software design;collaborative modeling;comprehensive technological improvements;questionnaires;design sessions;colocated distributed professional software designers;design activities;effective remote collaboration;geographical distance;software development activities;global software engineering;collaborative distributed software design,,2.0,,15.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1386,25,Belief and Evidence: How Software Engineers Form Their Opinions,P. Devanbu; T. Zimmermann; C. Bird,"University of California, Davis; Microsoft Research; Microsoft Research",IEEE Software,29 Nov 2018,2018,35,6,72,76,A study at Microsoft revealed how developers' opinions about software engineering truths can be subjectively based.,1937-4194,,10.1109/MS.2018.4321246,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552655,evidence-based software engineering;software engineering;software development;Redirections,Software development;Software engineering,computer science education;software engineering,software engineers;opinions;Microsoft;developers;software engineering truths,,3.0,,8.0,,29 Nov 2018,,,IEEE,IEEE Magazines
1387,26,A Conversation with Barry Boehm: Recollections from 50 Years of Software Engineering,H. Erdogmus; N. Medvidović,Carnegie Mellon University; University of Southern California,IEEE Software,27 Sep 2018,2018,35,5,14,19,Barry Boehm speaks with IEEE Software about his experiences throughout the history of software engineering. This article is part of a theme issue on software engineerings 50th anniversary.,1937-4194,,10.1109/MS.2018.3571249,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474492,history of software engineering;Barry Boehm;software development;software engineering,Software engineering;History,,,,,,6.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1388,27,Toward Methodological Guidelines for Process Theories and Taxonomies in Software Engineering,P. Ralph,"Department of Computer Science, University of Auckland, Auckland, New Zealand",IEEE Transactions on Software Engineering,16 Jul 2019,2019,45,7,712,735,"Software engineering is increasingly concerned with theory because the foundational knowledge comprising theories provides a crucial counterpoint to the practical knowledge expressed through methods and techniques. Fortunately, much guidance is available for generating and evaluating theories for explaining why things happen (variance theories). Unfortunately, little guidance is available concerning theories for explaining how things happen (process theories), or theories for analyzing and understanding situations (taxonomies). This paper therefore attempts to clarify the nature and functions of process theories and taxonomies in software engineering research, and to synthesize methodological guidelines for their generation and evaluation. It further advances the key insight that most process theories are taxonomies with additional propositions, which helps inform their evaluation. The proposed methodological guidance has many benefits: it provides a concise summary of existing guidance from reference disciplines, it adapts techniques from reference disciplines to the software engineering context, and it promotes approaches that better facilitate scientific consensus.",1939-3520,,10.1109/TSE.2018.2796554,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267085,Research methodology;process theory;taxonomy;theory for analysis;theory for understanding;model;framework;guidelines;case study;grounded theory;questionnaire;experiment;action research,Taxonomy;Software;Software engineering;Guidelines;Measurement;Knowledge engineering;Organisms,software engineering,process theories;taxonomies;variance theories;software engineering context,,4.0,,146.0,,23 Jan 2018,,,IEEE,IEEE Journals
1389,28,PerfJIT: Test-level Just-in-time Prediction for Performance Regression Introducing Commits,J. Chen; W. Shang; E. Shihab,"Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 1M8 (e-mail: fu_chen@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: shang@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: eshihab@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Performance issues may compromise user experiences, increase the cost resources, and cause field failures. One of the most prevalent performance issues is performance regression. Due to the importance and challenges in performance regression detection, prior research proposes various automated approaches that detect performance regressions. However, performance regression detection is conducted after the system is built and deployed. Hence, large amounts of resources are still required to locate and fix performance regressions. In our paper, we propose an approach that automatically predicts whether a test would manifest performance regressions given a code commit. In particular, we extract both traditional metrics and performance-related metrics from the code changes that are associated with each test. For each commit, we build random forest classifiers that are trained from all prior commits to predict in this commit whether each test would manifest performance regression. We conduct case studies on three open-source systems (Hadoop, Cassandra and OpenJPA). Our results show that our approach can predict tests that manifest performance regressions in a commit with high AUC values (on average 0.86). Our approach can drastically reduce the testing time needed to detect performance regressions. In addition, we find that our approach could be used to detect the introduction of six out of nine real-life performance issues from the subject systems during our studied period. Finally, we find that traditional metrics that are associated with size and code change histories are the most important factors in our models. Our approach and the study results can be leveraged by practitioners to effectively cope with performance regressions in a timely and proactive manner.",1939-3520,,10.1109/TSE.2020.3023955,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197704,performance regression;software performance;software quality;mining software repositories;empirical software engineering,Measurement;Predictive models;Software;Task analysis;Benchmark testing;Logistics,,,,,,,,15 Sep 2020,,,IEEE,IEEE Early Access Articles
1390,29,Impact of Discretization Noise of the Dependent variable on Machine Learning Classifiers in Software Engineering,G. K. Rajbahadur; S. Wang; Y. Kamei; A. E. Hassan,"School of Computing, Queen's University, 4257 Kingston, Ontario Canada K7L 2N8 (e-mail: krishnan@cs.queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: shaowei@cs.queensu.ca); Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Fukuoka Japan 819-0395 (e-mail: kamei@ait.kyushu-u.ac.jp); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Researchers usually discretize a continuous dependent variable into two target classes by introducing an artificial discretization threshold (e.g., median). However, such discretization may introduce noise (i.e., discretization noise) due to ambiguous class loyalty of data points that are close to the artificial threshold. Previous studies do not provide a clear directive on the impact of discretization noise on the classifiers and how to handle such noise. In this paper, we propose a framework to help researchers and practitioners systematically estimate the impact of discretization noise on classifiers in terms of its impact on various performance measures and the interpretation of classifiers. Through a case study of 7 software engineering datasets, we find that: 1) discretization noise affects the different performance measures of a classifier differently for different datasets; 2) Though the interpretation of the classifiers are impacted by the discretization noise on the whole, the top 3 most important features are not affected by the discretization noise. Therefore, we suggest that practitioners and researchers use our framework to understand the impact of discretization noise on the performance of their built classifiers and estimate the exact amount of discretization noise to be discarded from the dataset to avoid the negative impact of such noise.",1939-3520,,10.1109/TSE.2019.2924371,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744330,Discretization noise;Discretization;Classifiers;Feature Importance Analysis;Performance;Random Forest;Logistic Regression;Decision Trees;KNN,Software engineering;Computer bugs;Noise measurement;Software;Machine learning;Regression tree analysis;Logistics,,,,,,,,24 Jun 2019,,,IEEE,IEEE Early Access Articles
1391,30,Software Maintenance and Evolution and Automated Software Engineering,J. C. Carver; A. Serebrenik,University of Alabama; Eindhoven University of Technology,IEEE Software,12 Mar 2018,2018,35,2,102,104,"This issue’s column reports on the 33rd International Conference on Software Maintenance and Evolution and 32nd International Conference on Automated Software Engineering. Topics include flaky tests, technical debt, QA bots, and regular expressions.",1937-4194,,10.1109/MS.2018.1661318,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314151,33rd International Conference on Software Maintenance and Evolution;ICSME 17;32nd International Conference on Automated Software Engineering;ASE 17;software maintenance;software evolution;automated software engineering;flaky tests;technical debt;self-admitted technical debt;SATD;QA bots;regular expressions;regexes;software engineering;software development;Practitioners’ Digest,,,,,,,,,12 Mar 2018,,,IEEE,IEEE Magazines
1392,31,Broken External Links on Stack Overflow,J. Liu; X. Xia; D. Lo; H. Zhang; Y. Zou; A. E. Hassan; S. Li,"College of Computer Science and Technology, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: jkliu@zju.edu.cn); Software Engineering Application Technology Lab, Huawei Technologies Co Ltd, 115371 Shenzhen, Guangdong, China, (e-mail: xin.xia@acm.org); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); School of Computing, Queen's University, Kingston, Ontario, Canada, K7M1B5 (e-mail: haoxiang.zhang@huawei.com); Electrical and Computer Enginereing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ying.zou@queensu.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: shan@zju.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Stack Overflow hosts 11,926,354 links that reference to the programming-related knowledge in third-party websites. The links that reference to the resources hosted outside the Stack Overflow websites extend the Stack Overflow knowledge base substantially. However, with the rapid development of programming-related knowledge, many resources hosted on the Internet are not available anymore. Based on our analysis of the Stack Overflow data that was released on Jun. 2, 2019, 14.2% of the links on Stack Overflow are broken links. The broken links on Stack Overflow can obstruct viewers from obtaining desired programming-related knowledge, and potentially damage the reputation of the Stack Overflow as viewers might regard the posts with broken links as obsolete. In this paper, we characterize the broken links on Stack Overflow. 63% of the broken links in questions are used to show examples, e.g., code examples. 80% of the broken links in answers are used to provide supporting information, e.g., explaining a certain concept and describing a step to solve a problem. Only 1.67% of the posts with broken links are highlighted as such by viewers in the posts' comments. Only 5.8% of the posts with broken links removed the broken links. Viewers cannot fully rely on the vote scores to detect broken links, as broken links are common across posts with different vote scores. The websites that host resources that can be maintained by their users are referenced by broken links the most on Stack Overflow -- a prominent example of such websites is GitHub. The posts and comments related to the web technologies, i.e., JavaScript, HTML, CSS, and jQuery, are associated with more broken links. Based on our findings, we shed lights for future directions and provide recommendations for practitioners and researchers.",1939-3520,,10.1109/TSE.2021.3086494,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447188,Empirical Software Engineering;Stack Overflow;Broken Link,Internet;Software engineering;Software;Knowledge engineering;Web search;Computer bugs;Tools,,,,,,,IEEE,4 Jun 2021,,,IEEE,IEEE Early Access Articles
1393,32,The History of Software Engineering,G. Booch,,IEEE Software,27 Sep 2018,2018,35,5,108,114,"Grady Booch, one of UML's original authors, offers his perspective on the history of software engineering. This article is part of a theme issue on software engineering's 50th anniversary. The Web Extra, a version of the article with an expanded bibliography, is at https://extras.computer.org/extra/mso2018050108s1.pdf.",1937-4194,,10.1109/MS.2018.3571234,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474489,history of software engineering;software development;Grady Booch,Computers;Software engineering;Software development;Programming;History,history;Internet;software engineering;Unified Modeling Language,software engineering;Grady Booch;Web extra;bibliography;history;UML original authors,,5.0,,10.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1394,33,What the Errors Tell Us,M. H. Hamilton,Hamilton Technologies,IEEE Software,27 Sep 2018,2018,35,5,32,37,"Margaret Hamilton talks about her experiences over the last 60 years and how a “theory of errors” was derived from the errors made along the way. Its axioms of control led to the Universal Systems Language (USL) together with its automation and preventative paradigm, development-before-the-fact. The pressing issues haven't gone away, largely because the traditional paradigm continues in force. With a preventative paradigm, most errors aren't allowed into a system in the first place, just by the way the system is defined. Unlike a traditional approach, with a preventative approach the more reliable the system, the higher the productivity in its lifecycle. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290110447,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409915,preventative paradigm;ultrareliable software;nonprocedural languages;programming languages;dataflow languages;software engineering;operating systems;software development,Software engineering;Error analysis;Software development;Programming;Computer languages,software engineering;specification languages;systems engineering,Universal Systems Language;USL;preventative paradigm;preventative approach;productivity;software engineering,,,,12.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1395,34,Software Analytics: What’s Next?,T. Menzies; T. Zimmermann,North Carolina State University; Microsoft Research,IEEE Software,27 Sep 2018,2018,35,5,64,70,"Knowing what factors control software projects is very useful because humans might not understand those factors. Developers sometimes develop their own ideas about good and bad software, on the basis of just a few past projects. Using software analytics, we can correct those misconceptions. Software analytics lets software engineers learn about AI techniques. Once they learn those techniques, they can build and ship innovative AI tools. That is, software analytics is the training ground for the next generation of AI-literate software engineers. This article is part of a special issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290111035,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409908,software;software analytics;data mining;software development;software engineering,Software development;Artificial intelligence;5G mobile communication;Computer bugs;Software engineering;Data mining,artificial intelligence;project management;software engineering,software analytics;software projects;AI-literate software engineers;software engineering;AI techniques,,2.0,,41.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1396,35,Collaborative Model-Driven Software Engineering: A Classification Framework and a Research Map,M. Franzago; D. D. Ruscio; I. Malavolta; H. Muccini,"Department of Information Engineering, Computer Science and Mathematics (DISIM), University of L'Aquila, L'Aquila, AQ, Italy; Department of Information Engineering, Computer Science and Mathematics (DISIM), University of L'Aquila, L'Aquila, AQ, Italy; Department of Computer Science, Vrije Universiteit Amsterdam, Amsterdam, North Holland, HV, The Netherlands; Department of Information Engineering, Computer Science and Mathematics (DISIM), University of L'Aquila, L'Aquila, AQ, Italy",IEEE Transactions on Software Engineering,9 Dec 2018,2018,44,12,1146,1175,"Context: Collaborative Model-Driven Software Engineering (MDSE) consists of methods and techniques where multiple stakeholders manage, collaborate, and are aware of each others' work on shared models. Objective: Collaborative MDSE is attracting research efforts from different areas, resulting in a variegated scientific body of knowledge. This study aims at identifying, classifying, and understanding existing collaborative MDSE approaches. Method: We designed and conducted a systematic mapping study. Starting from over 3,000 potentially relevant studies, we applied a rigorous selection procedure resulting in 106 selected papers, further clustered into 48 primary studies along a time span of 19 years. We rigorously defined and applied a classification framework and extracted key information from each selected study for subsequent analysis. Results: Our analysis revealed the following main fidings: (i) there is a growing scientific interest on collaborative MDSE in the last years; (ii) multi-view modeling, validation support, reuse, and branching are more rarely covered with respect to other aspects about collaborative MDSE; (iii) different primary studies focus differently on individual dimensions of collaborative MDSE (i.e., model management, collaboration, and communication); (iv) most approaches are language-specific, with a prominence of UML-based approaches; (v) few approaches support the interplay between synchronous and asynchronous collaboration. Conclusion: This study gives a solid foundation for classifying existing and future approaches for collaborative MDSE. Researchers and practitioners can use our results for identifying existing research/technical gaps to attack, better scoping their own contributions, or understanding existing ones.",1939-3520,,10.1109/TSE.2017.2755039,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8047991,Collaborative MDSE;CoMDSE;C-MDSE;model-driven engineering;collaborative software engineering;CoSE;systematic mapping study,Collaboration;Analytical models;Software engineering;Stakeholders;Systematics,formal specification;groupware;Unified Modeling Language,asynchronous collaboration;Collaborative Model-Driven Software Engineering;classification framework;systematic mapping study;synchronous collaboration;primary studies;collaborative MDSE approaches;time 19.0 year,,5.0,,119.0,,21 Sep 2017,,,IEEE,IEEE Journals
1397,36,Exploring Community Smells in Open-Source: An Automated Approach,D. A. Tamburri; F. Palomba; R. Kazman,"Eindhoven University of Technology, Eindhoven, The Netherlands; University of Zurich, Zurich, Switzerland; University of Hawaii & SEI/CMU, Honolulu, Hawaii, USA",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,630,652,"Software engineering is now more than ever a community effort. Its success often weighs on balancing distance, culture, global engineering practices and more. In this scenario many unforeseen socio-technical events may result into additional project cost or “social” debt, e.g., sudden, collective employee turnover. With industrial research we discovered community smells, that is, sub-optimal patterns across the organisational and social structure in a software development community that are precursors of such nasty socio-technical events. To understand the impact of community smells at large, in this paper we first introduce CodeFace4Smells, an automated approach able to identify four community smell types that reflect socio-technical issues that have been shown to be detrimental both the software engineering and organisational research fields. Then, we perform a large-scale empirical study involving over 100 years worth of releases and communication structures data of 60 open-source communities: we evaluate (i) their diffuseness, i.e., how much are they distributed in open-source, (ii) how developers perceive them, to understand whether practitioners recognize their presence and their negative effects in practice, and (iii) how community smells relate to existing socio-technical factors, with the aim of assessing the inter-relations between them. The key findings of our study highlight that community smells are highly diffused in open-source and are perceived by developers as relevant problems for the evolution of software communities. Moreover, a number of state-of-the-art socio-technical indicators (e.g., socio-technical congruence) can be used to monitor how healthy a community is and possibly avoid the emergence of social debt.",1939-3520,,10.1109/TSE.2019.2901490,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651329,Software organisational structures;software community smells;human aspects in software engineering;social software engineering;empirical software engineering;,Software engineering;Open source software;Organizational aspects;Social networking (online);Tools;Microstructure,project management;public domain software;socio-economic effects;software development management;team working,socio-technical factors;community smells;software communities;socio-technical congruence;automated approach;software engineering;global engineering practices;organisational structure;social structure;software development community;CodeFace4Smells;open-source communities;socio-technical issues;community smell types,,7.0,,84.0,IEEE,24 Feb 2019,,,IEEE,IEEE Journals
1398,37,Grey Literature Versus Academic Literature in Software Engineering: A Call for Epistemological Analysis,V. Garousi; A. Rainer,"Computer Science, Queen's University Belfast, Belfast, Belfast, United Kingdom of Great Britain and Northern Ireland; School of Electronics, Electrical Engineering and Computer Science (EEECS), Queen's University Belfast, Belfast, Belfast, United Kingdom of Great Britain and Northern Ireland",IEEE Software,,2020,PP,99,0,0,"To learn about novel software engineering (SE) trends, where do you refer to? In order to document and disseminate their experience / knowledge, many SE practitioners prepare technical materials and share them online as blog posts, white papers and videos. Such materials are often called “grey literature” because they are not formally peer reviewed. By contrast, SE researchers write technical papers that are peer-reviewed and published as academic literature. We observe that, in general, these two communities mostly read literature that is only written by and published within their respective communities. This situation has led to a form of “knowledge divide” between the two communities that, we believe, hurts both communities. By characterizing and contrasting the two types of literature, grey and academic, we discuss how each literature can complement the other and can lead to a richer and more integrated knowledge exchange and dissemination in SE.",1937-4194,,10.1109/MS.2020.3022931,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190027,Grey literature;academic literature;information needs;evidence-based software engineering,Software testing;Industries;Software engineering;Software;Decision making;Collaboration,,,,,,,,9 Sep 2020,,,IEEE,IEEE Early Access Articles
1399,38,The End to the Myth of Individual Programmer Productivity,W. R. Nichols,"Software Engineering, Carnegie Mellon University",IEEE Software,16 Aug 2019,2019,36,5,71,75,"One often-quoted truism in software engineering is that good programmers are ""much much better"" than bad programmers. The size of ""much much better"" is widely debated, but ranges such as 10 times more productive are often cited as conservative estimates. This article argues that such statements are misleading and miss numerous important effects. Based on the studies described later, it would appear that some programmers are not inherently exceedingly better than others.",1937-4194,,10.1109/MS.2019.2908576,Department of Defense; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804291,,Productivity;Software engineering;Security;Programming profession,software engineering,individual programmer productivity;software engineering,,1.0,,14.0,,16 Aug 2019,,,IEEE,IEEE Magazines
1400,39,The Importance of the Correlation in Crossover Experiments,B. A. Kitchenham; L. Madeyski; G. Scanniello; C. Gravino,"School of Computing and Mathematics, Keele University, Newcastle-under-Lyme, Staffordshire, United Kingdom of Great Britain and Northern Ireland, (e-mail: b.a.kitchenham@keele.ac.uk); Department of Applied Informatics, Wroclaw University of Science and Technology, 49567 Wroclaw, Dolnoslaskie, Poland, (e-mail: lech.madeyski@pwr.edu.pl); Giuseppe Scanniello, Universita degli Studi della Basilicata, 19006 Potenza, PZ, Italy, 85100 (e-mail: giuseppe.scanniello@unibas.it); Department of Computer Science, University of Salerno, Salerno, Fisciano, Italy, 84084 (e-mail: gravino@unisa.it)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Context: In empirical software engineering, crossover designs are popular for experiments comparing software engineering techniques that must be undertaken by human participants. However, their value depends on the correlation (r) between the outcome measures on the same participants. Software engineering theory emphasizes the importance of individual skill differences, so we would expect the values of r to be relatively high. However, few researchers have reported the values of r. Goal: To investigate the values of r found in software engineering experiments. Method: We undertook simulation studies to investigate the theoretical and empirical properties of r. Then we investigated the values of r observed in 35 software engineering crossover experiments. Results: The level of r obtained by analysing our 35 crossover experiments was small. Estimates based on means, medians, and random effect analysis disagreed but were all between 0.2 and 0.3. As expected, our analyses found large variability among the individual r estimates for small sample sizes, but no indication that r estimates were larger for the experiments with larger sample sizes that exhibited smaller variability. Conclusions: Low observed r values cast doubts on the validity of crossover designs for software engineering experiments. However, if the cause of low r values relates to training limitations or toy tasks, this affects all Software Engineering (SE) experiments involving human participants. For all human-intensive SE experiments, we recommend more intensive training and then tracking the improvement of participants as they practice using specific techniques, before formally testing the effectiveness of the techniques.",1939-3520,,10.1109/TSE.2021.3070480,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395223,empirical software engineering;experiments;crossover experiments;crossover design;repeated measures correlation,Particle measurements;Atmospheric measurements;Correlation;Size measurement;Mathematical model;Time measurement;Software engineering,,,,,,,CCBY,5 Apr 2021,,,IEEE,IEEE Early Access Articles
1401,40,What Makes a Great Manager of Software Engineers?,E. Kalliamvakou; C. Bird; T. Zimmermann; A. Begel; R. DeLine; D. M. German,"Department of Computer Science, University of Victoria, Victoria, BC, Canada; Microsoft Corportation, Redmond, WA; Microsoft Corportation, Redmond, WA; Microsoft Corportation, Redmond, WA; Microsoft Corportation, Redmond, WA; Department of Computer Science, University of Victoria, Victoria, BC, Canada",IEEE Transactions on Software Engineering,8 Jan 2019,2019,45,1,87,106,"Having great managers is as critical to success as having a good team or organization. In general, a great manager is seen as fuelling the team they manage, enabling it to use its full potential. Though software engineering research studies factors that may affect the performance and productivity of software engineers and teams (like tools and skills), it has overlooked the software engineering manager. The software industry's growth and change in the last decades is creating a need for a domain-specific view of management. On the one hand, experts are questioning how the abundant work in management applies to software engineering. On the other hand, practitioners are looking to researchers for evidence-based guidance on how to manage software teams. We conducted a mixed methods empirical study of software engineering management at Microsoft to investigate what manager attributes developers and engineering managers perceive important and why. We present a conceptual framework of manager attributes, and find that technical skills are not the sign of greatness for an engineering manager. Through statistical analysis we identify how engineers and managers relate in their views, and how software engineering differs from other knowledge work groups in its perceptions about what makes great managers. We present strategies for putting the attributes to use, discuss implications for research and practice, and offer avenues for further work.",1939-3520,,10.1109/TSE.2017.2768368,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094304,software engineering management;empirical studies;software companies,Software engineering;Software;Organizations;Knowledge engineering;Productivity;Interviews;Psychology,software development management;software engineering;statistical analysis,software industry;software teams;software engineering management;manager attributes;evidence-based guidance;statistical analysis,,3.0,,108.0,,2 Nov 2017,,,IEEE,IEEE Journals
1402,41,Successful Engagement of Practitioners and Software Engineering Researchers: Evidence From 26 International Industry–Academia Collaborative Projects,V. Garousi; D. C. Shepherd; K. Herkiloglu,"Software Engineering, Queen’s University Belfast, Ireland; Virginia Commonwealth University, Virginia United States; HAVELSAN, Ankara, Turkey",IEEE Software,23 Oct 2020,2020,37,6,65,75,"There has been a push to increase the practical relevance and impact of software engineering research. Although many practitioners and researchers agree that this change is desirable, thus far, only a few concrete actions have been taken by the community. In this article, we present our experiences with a large number of collaborative research projects that have had a practical (industrial) impact.",1937-4194,,10.1109/MS.2019.2914663,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704922,Industry-academia collaborations;experience report;lessons learned;applied research,Industries;Collaboration;Software engineering;Companies;Software;Testing;Reflection,groupware;research and development;software engineering;software management,international industry-academia collaborative projects;software engineering researchers;collaborative research projects,,,,27.0,,2 May 2019,,,IEEE,IEEE Magazines
1403,42,Software Engineering for Sustainability: Find the Leverage Points!,B. Penzenstadler; L. Duboc; C. C. Venters; S. Betz; N. Seyff; K. Wnuk; R. Chitchyan; S. M. Easterbrook; C. Becker,"California State University, Long Beach; La Salle—University Ramon Llull; University of Huddersfield; Furtwangen University; University of Applied Sciences and Arts Northwestern Switzerland; Blekinge Institute of Technology; University of Bristol; University of Toronto; University of Toronto",IEEE Software,6 Jul 2018,2018,35,4,22,33,"We as software engineers are responsible for the long-term consequences of the systems we design-including impacts on the wider environmental and societal sustainability. However, the field lacks analytical tools for understanding these potential impacts while designing a system or for identifying opportunities for using software to bring about broader societal transformations. This article explores how the concept of leverage points can be used to make sustainability issues more tangible in system design. The example of software for transportation systems illustrates how leverage points can help software engineers map out and investigate the wider system in which the software resides, such that we can use software as an effective tool for engineering a more sustainable world. This article is part of a theme issue on Process Improvement.",1937-4194,,10.1109/MS.2018.110154908,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254307,sustainability;leverage points;software engineering;software development,Sustainable development;Feedback loop;Software engineering;System analysis and design;Social implications of technology,software engineering;sustainable development,environmental sustainability;societal transformations;process improvement;sustainable world;wider system;transportation systems;system design;sustainability issues;societal sustainability;long-term consequences;software engineers;leverage points;software engineering,,7.0,,25.0,,11 Jan 2018,,,IEEE,IEEE Magazines
1404,43,Bayesian Data Analysis in Empirical Software Engineering Research,C. A. Furia; R. Feldt; R. Torkar,"Faculty of Informatics, USI, 27216 Lugano, TI Switzerland (e-mail: furiac@usi.ch); Department of Computer Science of Engineering, Chalmers University, Gothenburg, Västra Götaland Sweden (e-mail: robert.feldt@bth.se); Computer Science and Engineering, Chalmers tekniska hogskola, 11248 Goteborg, Vastra Gotaland Sweden (e-mail: richard.torkar@gmail.com)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics have traditionally dominated empirical data analysis, and certainly remain prevalent in empirical software engineering. This situation is unfortunate because frequentist statistics suffer from a number of shortcomings---such as lack of flexibility and results that are unintuitive and hard to interpret---that curtail their effectiveness when dealing with the heterogeneous data that is increasingly available for empirical analysis of software engineering practice. In this paper, we pinpoint these shortcomings, and present Bayesian data analysis techniques that provide tangible benefits---as they can provide clearer results that are simultaneously robust and nuanced. After a short, high-level introduction to the basic tools of Bayesian statistics, we present the reanalysis of two empirical studies on the effectiveness of automatically generated tests and the performance of programming languages, respectively. By contrasting the original frequentist analyses with our new Bayesian analyses, we demonstrate the concrete advantages of the latter. To conclude we advocate a more prominent role for Bayesian statistical techniques in empirical software engineering research and practice.",1939-3520,,10.1109/TSE.2019.2935974,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807222,Bayesian data analysis;statistical analysis;statistical hypothesis testing;empirical software engineering,Bayes methods;Software engineering;Testing;Data analysis;Machine learning;Statistical analysis;Software,,,,2.0,,,,20 Aug 2019,,,IEEE,IEEE Early Access Articles
1405,44,Search-Based Crash Reproduction and Its Impact on Debugging,M. Soltani; A. Panichella; A. van Deursen,"Software Engineering Research Group, Delft University of Technology, Delft, Netherlands; Software Engineering Research Group, Delft University of Technology, Delft, Netherlands; Software Engineering Research Group, Delft University of Technology, Delft, Netherlands",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1294,1317,"Software systems fail. These failures are often reported to issue tracking systems, where they are prioritized and assigned to responsible developers to be investigated. When developers debug software, they need to reproduce the reported failure in order to verify whether their fix actually prevents the failure from happening again. Since manually reproducing each failure could be a complex task, several automated techniques have been proposed to tackle this problem. Despite showing advancements in this area, the proposed techniques showed various types of limitations. In this paper, we present EvoCrash, a new approach to automated crash reproduction based on a novel evolutionary algorithm, called Guided Genetic Algorithm (GGA). We report on our empirical study on using EvoCrash to reproduce 54 real-world crashes, as well as the results of a controlled experiment, involving human participants, to assess the impact of EvoCrash tests in debugging. Based on our results, EvoCrash outperforms state-of-the-art techniques in crash reproduction and uncovers failures that are undetected by classical coverage-based unit test generation tools. In addition, we observed that using EvoCrash helps developers provide fixes more often and take less time when debugging, compared to developers debugging and fixing code without using EvoCrash tests.",1939-3520,,10.1109/TSE.2018.2877664,EU; Fonds National de la Recherche Luxembourg; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502801,Search-based software testing;genetic algorithms;automated crash reproduction;empirical software engineering,Debugging;Genetic algorithms;Software testing;Software engineering;Computer bugs,genetic algorithms;program debugging;program testing;public domain software;system recovery,software systems;responsible developers;reported failure;automated techniques;automated crash reproduction;evolutionary algorithm;real-world crashes;guided genetic algorithm;EvoCrash tests;classical coverage-based unit test generation tools;fixing code;developer debug software;developer debugging;tracking systems;GGA;human participants,,4.0,,85.0,IEEE,23 Oct 2018,,,IEEE,IEEE Journals
1406,45,Human Values in Software Engineering: Contrasting Case Studies of Practice,W. Hussain; H. Perera; J. Whittle; A. Nurwidyantoro; R. Hoda; R. A. Shams; G. Oliver,"Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: waqar.hussain@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: harsha.perera@monash.edu); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: jon.whittle@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: arif.nurwidyantoro@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail:rashina.hoda@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: rifat.shams@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: Gillian.Oliver@monash.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The growing diffusion of software in society and its influence on people demands from its creators that their work carefully considers human values such as transparency, social responsibility, and equality. But how do software practitioners address human values in software engineering practice’ We interviewed 31 software practitioners from two organizations, each having a strong values framework, with the aim to understand: (a) practitioners’ perceptions of human values and their role in software engineering; (b)practices that practitioners use to address human values in software; and (c) challenges they face during this process. We report our findings from two contrasting case studies on how practitioners “engineer” values in their unique organizational settings. We found evidence that organizational culture significantly contributes to how values are addressed in software. We summarize recommendations from the practitioners to support proactive engineering of values-conscious software.",1939-3520,,10.1109/TSE.2020.3038802,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261980,Engineering Human Values;Software Engineering;Human Values in Software Practice;Challenges in Human Values;Case Studies of Practice;Ethics;Responsible Innovations;Non-functional Requirements,Software;Software engineering;Privacy;Security;Companies;Human factors;Artificial intelligence,,,,,,,IEEE,17 Nov 2020,,,IEEE,IEEE Early Access Articles
1407,46,Bridging the Gap: From Research to Practical Advice,C. L. Goues; C. Jaspan; I. Ozkaya; M. Shaw; K. T. Stolee,Carnegie Mellon University; Google; Carnegie Mellon University; Carnegie Mellon University; North Carolina State University,IEEE Software,27 Sep 2018,2018,35,5,50,57,"Software engineers must solve practical problems under deadline pressure. They rely on the best-codified knowledge available, turning to weaker results and their expert judgment when sound science is unavailable. Meanwhile, software engineering researchers seek fully validated results, resulting in a lag to practical guidance. To bridge this gap, research results should be systematically distilled into actionable guidance in a way that respects differences in strength and scope among the results. Starting with the practitioners' need for actionable guidance, this article reviews the evolution of software engineering research expectations, identifies types of results and their strengths, and draws on evidence-based medicine for a concrete example of deriving pragmatic guidance from mixed-strength research results. It advances a levels-of-evidence framework to allow researchers to clearly identify the strengths of their claims and the supporting evidence for their results and to work with practitioners to synthesize actionable recommendations from diverse types of evidence. This article is part of a special issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.3571235,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474493,levels of evidence;evidence-based software engineering;evidence-based medicine;software engineering;computing profession;software development,Systematics;Decision making;Software engineering;Static analysis;Computer bugs,software engineering,software engineering research expectations;evidence-based medicine;pragmatic guidance;levels-of-evidence framework;actionable recommendations,,6.0,,17.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1408,47,Code Vault,G. J. Holzmann,Nimble Research,IEEE Software,27 Sep 2018,2018,35,5,85,87,"So, what has changed since that first NATO software engineering conference in 1968? Depending on your point of view, nothing much has changed, or everything has changed. The part that didn't change much is that we still struggle with writing code that's robust enough to trust. The part that has changed dramatically is the performance of the hardware that runs our code. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.3571225,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474479,software errors;software technology;history of software engineering;software engineering;software development;Reliable Code,Error analysis;Software development;Software reliability;Random access memory;Computer bugs,software engineering,code vault;NATO software engineering conference;hardware performance,,,,3.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1409,48,A Wizard of Oz Study Simulating API Usage Dialogues with a Virtual Assistant,Z. Eberhart; A. Bansal; C. Mcmillan,"Computer Science, University of Notre Dame, 6111 Notre Dame, Indiana, United States, (e-mail: zacharyeberhart@gmail.com); Computer Science, University of Notre Dame, 6111 Notre Dame, Indiana, United States, (e-mail: abansal1@nd.edu); Computer Science, University of Notre Dame, 6111 Notre Dame, Indiana, United States, (e-mail: cmc@nd.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Virtual Assistant technology is rapidly proliferating to improve productivity in a variety of tasks. While several virtual assistants for everyday tasks are well-known (e.g., Siri, Cortana, Alexa), assistants for specialty tasks such as software engineering are rarer. One key reason software engineering assistants are rare is that very few experimental datasets are available and suitable for training the AI that is the bedrock of current virtual assistants. In this paper, we present a set of Wizard of Oz experiments that we designed to build a dataset for creating a virtual assistant. Our target is a hypothetical virtual assistant for helping programmers use APIs. In our experiments, we recruited 30 professional programmers to complete programming tasks using two APIs. The programmers interacted with a simulated virtual assistant for help the programmers were not aware that the assistant was actually operated by human experts. We then annotated the dialogue acts in the corpus along four dimensions: illocutionary intent, API information type(s), backward-facing function, and traceability to specific API components. We observed a diverse range of interactions that will facilitate the development of dialogue strategies for virtual assistants for API usage.",1939-3520,,10.1109/TSE.2020.3040935,Division of Computing and Communication Foundations; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272865,Intelligent agents;Discourse;Software/Software Engineering;Wizard of Oz (WoZ);Virtual Assistants,Task analysis;Software engineering;Training data;Annotations;Programming profession;Documentation;Navigation,,,,,,,IEEE,27 Nov 2020,,,IEEE,IEEE Early Access Articles
1410,49,On Accelerating Source Code Analysis at Massive Scale,G. Upadhyaya; H. Rajan,"Department of Computer Science, Iowa State University, Ames, IA; Department of Computer Science, Iowa State University, Ames, IA",IEEE Transactions on Software Engineering,17 Jul 2018,2018,44,7,669,688,"Encouraged by the success of data-driven software engineering (SE) techniques that have found numerous applications e.g., in defect prediction, specification inference, the demand for mining and analyzing source code repositories at scale has significantly increased. However, analyzing source code at scale remains expensive to the extent that data-driven solutions to certain SE problems are beyond our reach today. Extant techniques have focused on leveraging distributed computing to solve this problem, but with a concomitant increase in computational resource needs. This work proposes a technique that reduces the amount of computation performed by the ultra-large-scale source code mining task, especially those that make use of control and data flow analyses. Our key idea is to analyze the mining task to identify and remove the irrelevant portions of the source code, prior to running the mining task. We show a realization of our insight for mining and analyzing massive collections of control flow graphs of source codes. Our evaluation using 16 classical control-/data-flow analyses that are typical components of mining tasks and 7 Million CFGs shows that our technique can achieve on average a 40 percent reduction in the task computation time. Our case studies demonstrates the applicability of our technique to massive scale source code mining tasks.",1939-3520,,10.1109/TSE.2018.2828848,US National Science Foundation (NSF); US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344505,Source code analysis;mining software repositories;ultra-large-scale mining;data-driven software engineering,Task analysis;Data mining;Acceleration;Static analysis;Software engineering;Distributed computing;Software,data flow analysis;data mining;software engineering;source code (software),control-flow analyses;ultralarge-scale source code mining task;source code repository analysis;massive scale source code mining tasks;task computation time;control flow graphs;data flow analyses;specification inference;defect prediction;data-driven software engineering techniques,,3.0,,34.0,,20 Apr 2018,,,IEEE,IEEE Journals
1411,50,Does Reviewer Recommendation Help Developers?,V. Kovalenko; N. Tintarev; E. Pasynkov; C. Bird; A. Bacchelli,"Software Engineering Research Group, Delft University of Technology, Delft, CD, The Netherlands; Web Information Systems Group, Delft University of Technology, Delft, CD, The Netherlands; JetBrains GmbH, Munich, Germany; Microsoft Research, Microsoft, Redmond, WA, USA; ZEST, University of Zürich, Zürich, Zürich, Switzerland",IEEE Transactions on Software Engineering,15 Jul 2020,2020,46,7,710,731,"Selecting reviewers for code changes is a critical step for an efficient code review process. Recent studies propose automated reviewer recommendation algorithms to support developers in this task. However, the evaluation of recommendation algorithms, when done apart from their target systems and users (i.e., code review tools and change authors), leaves out important aspects: perception of recommendations, influence of recommendations on human choices, and their effect on user experience. This study is the first to evaluate a reviewer recommender in vivo. We compare historical reviewers and recommendations for over 21,000 code reviews performed with a deployed recommender in a company environment and set out to measure the influence of recommendations on users' choices, along with other performance metrics. Having found no evidence of influence, we turn to the users of the recommender. Through interviews and a survey we find that, though perceived as relevant, reviewer recommendations rarely provide additional value for the respondents. We confirm this finding with a larger study at another company. The confirmation of this finding brings up a case for more user-centric approaches to designing and evaluating the recommenders. Finally, we investigate information needs of developers during reviewer selection and discuss promising directions for the next generation of reviewer recommendation tools. Preprint: https://doi.org/10.5281/zenodo.1404814.",1939-3520,,10.1109/TSE.2018.2868367,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453850,Code review;reviewer recommendation;empirical software engineering,Tools;Recommender systems;Companies;Measurement;Software;In vivo;Software engineering,recommender systems;review sites;software engineering;source code (software),code review tools;user experience;historical reviewers;user-centric approaches;reviewer selection;reviewer recommendation tools;code review process;automated reviewer recommendation algorithms,,4.0,,74.0,IEEE,2 Sep 2018,,,IEEE,IEEE Journals
1412,51,Which Commits Can Be CI Skipped?,R. Abdalkareem; S. Mujahid; E. Shihab; J. Rilling,"Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,448,463,"Continuous Integration (CI) frameworks such as Travis CI, automatically build and run tests whenever a new commit is submitted/pushed. Although there are many advantages in using CI, e.g., speeding up the release cycle and automating the test execution process, it has been noted that the CI process can take a very long time to complete. One of the possible reasons for such delays is the fact that some commits (e.g., changes to readme files) unnecessarily kick off the CI process. Therefore, the goal of this paper is to automate the process of determining which commits can be CI skipped. We start by examining the commits of 58 Java projects and identify commits that were explicitly CI skipped by developers. Based on the manual investigation of 1,813 explicitly CI skipped commits, we first devise an initial model of a CI skipped commit and use this model to propose a rule-based technique that automatically identifies commits that should be CI skipped. To evaluate the rule-based technique, we perform a study on unseen datasets extracted from ten projects and show that the devised rule-based technique is able to detect and label CI skip commits, achieving Areas Under the Curve (AUC) values between 0.56 and 0.98 (average of 0.73). Additionally, we show that, on average, our technique can reduce the number of commits that need to trigger the CI process by 18.16 percent. We also qualitatively triangulated our analysis on the importance of skipping the CI process through a survey with 40 developers. The survey results showed that 75 percent of the surveyed developers consider it to be nice, important or very important to have a technique that automatically flags CI skip commits. To operationalize our technique, we develop a publicly available prototype tool, called CI-Skipper, that can be integrated with any git repository and automatically mark commits that can be CI skipped.",1939-3520,,10.1109/TSE.2019.2897300,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8633335,Continuous integration;travis CI;build status;mining software repository,Java;Software;Prototypes;Tools;Virtual machining;Data collection;Manuals,Java;program testing;project management;public domain software;software engineering,AUC values;area under the curve;CI-Skipper;automatically flagged CI skip commits;Travis CI;continuous integration frameworks;rule-based technique,,4.0,,41.0,IEEE,3 Feb 2019,,,IEEE,IEEE Journals
1413,52,A Theory of Value for Value-based Feature Selection in Software Engineering,P. Rodriguez; C. Urquhart; E. Mendes,"Department of Information Processing Sciences, University of Oulu, Oulu, Oulu Finland 90014 (e-mail: pilar.rodriguez@oulu.fi); Business School, Manchester Metropolitan University, 5289 Manchester, Greater Manchester United Kingdom of Great Britain and Northern Ireland (e-mail: c.urquhart@mmu.ac.uk); Computer Science, Blekinge Tekniska Hogskola, 4206 Karlskrona, Blekinge Sweden 371 79 (e-mail: emilia.mendes@bth.se)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Value-Based Software Engineering stresses the role of value in software related decisions. In the context of feature selection, software features judged to provide higher value take priority in the development process. This paper focuses on what value means when selecting software features. Using grounded theory, we conducted and analyzed semi-structured interviews with 21 key stakeholders (decision-makers) from three software/software-intensive companies, within a context where value-based decision-making was already established. Our analysis led to the building of a theory of value for value-based feature selection that identifies the nature of value propositions considered by key stakeholders when selecting software features (i.e. decision-making criteria for deciding upon software features, as suggested by Boehm (2003)). We found that some value propositions were common to all three company cases (core value propositions), whereas others were dependent upon the context in which a company operates, and the characteristics of the product under development (specific value propositions). Moreover, value propositions vary according to the stakeholder group and the type of feature being assessed. Our study provides significant insight into value in the context of feature selection, and generates new concepts around value-based feature selection such as new value propositions.",1939-3520,,10.1109/TSE.2020.2989666,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088281,Value-based Software Engineering (VBSE);Value Proposition;Decision-making Criteria;Grounded-theory;Theory Development;Feature Selection;Release Planning;Requirements Engineering;Decision-making;Decision-making Theory;Software Value;Software Products;Software-intensive Systems,Software;Feature extraction;Stakeholders;Companies;Decision making;Software engineering;Planning,,,,,,,,6 May 2020,,,IEEE,IEEE Early Access Articles
1414,53,How to Evaluate Solutions in Pareto-based Search-Based Software Engineering? A Critical Review and Methodological Guidance,M. Li; T. Chen; X. Yao,"School of Computer Science, University of Birmingham, 1724 Birmingham, Birmingham United Kingdom of Great Britain and Northern Ireland (e-mail: M.Li.8@cs.bham.ac.uk); Department of Computer Science, Loughborough University, 5156 Loughborough, UK United Kingdom of Great Britain and Northern Ireland (e-mail: t.t.chen@lboro.ac.uk); Department of Computer Science and Engnieering, Southern University of Science and Technology, 255310 Shenzhen, Guangdong China (e-mail: xiny@sustc.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"With modern requirements, there is an increasing tendency of considering multiple objectives/criteria simultaneously in many Software Engineering (SE) scenarios. Such a multi-objective optimization scenario comes with an important issue - how to evaluate the outcome of optimization algorithms, which typically is a set of incomparable solutions (i.e., being Pareto nondominated to each other). This issue can be challenging for the SE community, particularly for practitioners of Search-Based SE (SBSE). On one hand, multi-objective optimization could still be relatively new to SE/SBSE researchers, who may not be able to identify the right evaluation methods for their problems. On the other hand, simply following the evaluation methods for general multi-objective optimization problems may not be appropriate for specific SBSE problems, especially when the problem nature or decision maker's preferences are explicitly/implicitly known. This has been well echoed in the literature by various inappropriate/inadequate selection and inaccurate/misleading use of evaluation methods. In this paper, we first carry out a systematic and critical review of quality evaluation for multi-objective optimization in SBSE. We survey 717 papers published between 2009 and 2019 from 36 venues in seven repositories, and select 95 prominent studies, through which we identify five important but overlooked issues in the area. We then conduct an in-depth analysis of quality evaluation indicators/methods and general situations in SBSE, which, together with the identified issues, enables us to codify a methodological guidance for selecting and using evaluation methods in different SBSE scenarios.",1939-3520,,10.1109/TSE.2020.3036108,University Key Laboratory of Guangdong Province; Guangdong Introducing Innovative and Enterpreneurial Teams; Guangdong Provincial Key Laboratory; Shenzhen Science and Technology Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252185,Search-based software engineering;multi-objective optimization;Pareto optimization;quality evaluation;quality indicators;preferences,Software engineering;Pareto optimization;Computer science;Systematics;Indexes;Licenses,,,,1.0,,,CCBY,9 Nov 2020,,,IEEE,IEEE Early Access Articles
1415,54,50 Years of Software Engineering: Progress and Perils,C. Ebert,Vector Consulting Services,IEEE Software,27 Sep 2018,2018,35,5,94,101,"A survey of software professionals worldwide suggests the past, present, and future challenges of software engineering. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.3571228,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474504,software complexity;magic triangle;software crisis;agile development;digital transformation;software engineering;software development;software technology,Agile software development;Software development;Computer security;Complexity theory,software engineering,software engineering;software professionals;future challenges,,4.0,,5.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1416,55,Breaking Type-Safety in Go: An Empirical Study on the Usage of the unsafe Package,D. E. Costa; S. Mujahid; R. Abdalkareem; E. Shihab,"Department of Computer Science and Software Engineering (CSSE), Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: diego.costa@concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: s_mujahi@encs.concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 1M8 (e-mail: rab_abdu@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: eshihab@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"A decade after its first release, the Go programming language has become a major programming language in the development landscape. While praised for its clean syntax and C-like performance, Go also contains a strong static type-system that prevents arbitrary type casting and arbitrary memory access, making the language type-safe by design. However, to give developers the possibility of implementing low-level code, Go ships with a special package called unsafe that offers developers a way around the type-safety of Go programs. The package gives greater flexibility to developers but comes at a higher risk of runtime errors, chances of non-portability, and the loss of compatibility guarantees for future versions of Go. In this paper, we present the first large-scale study on the usage of the unsafe package in 2,438 popular Go projects. Our investigation shows that unsafe is used in 24% of Go projects, motivated primarily by communicating with operating systems and C code but is also commonly used as a source of performance optimization. Developers are willing to use unsafe to break language specifications (e.g., string immutability) for better performance and 6% of analyzed projects that use unsafe perform risky pointer conversions that can lead to program crashes and unexpected behavior. Furthermore, we report a series of real issues faced by projects that use unsafe, from crashing errors and non-deterministic behavior to having their deployment restricted from certain popular environments. Our findings can be used to understand how and why developers break type-safety in Go and help motivate further tools and language development that could make the usage of unsafe in Go even safer.",1939-3520,,10.1109/TSE.2021.3057720,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350178,Go language;unsafe;type safety;software packages;Empirical Study,Safety;Computer languages;Documentation;Computer crashes;Operating systems;Runtime;Java,,,,,,,IEEE,8 Feb 2021,,,IEEE,IEEE Early Access Articles
1417,56,Looking For Novelty in Search-based Software Product Line Testing,Y. Xiang; H. Huang; M. Li; S. Li; X. Yang,"School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: gzhuxiang_yi@163.com); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: hhan@scut.edu.cn); School of Computer Science, University of Birmingham, 1724 Birmingham, Birmingham, United Kingdom of Great Britain and Northern Ireland, (e-mail: M.Li.8@cs.bham.ac.uk); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: chickl@qq.com); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: xwyang@scut.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Testing software product lines (SPLs) is difficult due to a huge number of possible products to be tested. Recently, there has been a growing interest in similarity-based testing of SPLs, where similarity is used as a surrogate metric for the t-wise coverage. In this context, one of the primary goals is to sample, by optimizing similarity metrics using search-based algorithms, a small subset of test cases (i.e., products) as dissimilar as possible, thus potentially making more t-wise combinations covered. Prior work has shown, by means of empirical studies, the great potential of current similarity-based testing approaches. However, the rationale of this testing technique deserves a more rigorous exploration. To this end, we perform correlation analyses to investigate how similarity metrics are correlated with the t-wise coverage. We find that similarity metrics generally have significantly positive correlations with the t-wise coverage. This well explains why similarity-based testing works, as the improvement on similarity metrics will potentially increase the t-wise coverage. Moreover, we explore, for the first time, the use of the novelty search (NS) algorithm for similarity-based SPL testing. The algorithm rewards “novel” individuals, i.e., those being different from individuals discovered previously, and this well matches the goal of similarity-based SPL testing. We find that the novelty score used in NS has (much) stronger positive correlations with the t-wise overage than previous approaches relying on a genetic algorithm (GA) with a similarity-based fitness function. Experimental results on 31 software product lines validate the superiority of NS over GA, as well as other state-of-the-art approaches, concerning both t-wise coverage and fault detection capacity. Finally, we investigate whether it is useful to combine two satisfiability solvers when generating new individuals in NS, and how the performance of NS is affected by its key parameters. In summary, looking for novelty provides a promising way of sampling diverse test cases for SPLs.",1939-3520,,10.1109/TSE.2021.3057853,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350184,Software product line testing;product sampling;novelty search;similarity-based testing;t-wise coverage;correlation analysis,Testing;Frequency modulation;Measurement;Software;Correlation;Software product lines;Fault detection,,,,,,,IEEE,8 Feb 2021,,,IEEE,IEEE Early Access Articles
1418,57,Studying Duplicate Logging Statements and Their Relationships with Code Clones,Z. Li; T. -H. P. Chen; J. Yang; W. Shang,"Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: l_zhenha@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: jinqiuy@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Developers rely on software logs for a variety of tasks, such as debugging, testing, program comprehension, verification, and performance analysis. Despite the importance of logs, prior studies show that there is no industrial standard on how to write logging statements. In this paper, we focus on studying duplicate logging statements, which are logging statements that have the same static text message. Such duplications in the text message are potential indications of logging code smells, which may affect developers understanding of the dynamic view of the system. We manually studied over 4K duplicate logging statements and their surrounding code in five large-scale open source systems: Hadoop, CloudStack, Elasticsearch, Cassandra, and Flink. We uncovered five patterns of duplicate logging code smells. For each instance of the duplicate logging code smell, we further manually identify the potentially problematic (i.e., require fixes) and justifiable (i.e., do not require fixes) cases. Then, we contact developers to verify our manual study result. We integrated our manual study result and developers feedback into our automated static analysis tool, DLFinder, which automatically detects problematic duplicate logging code smells. We evaluated DLFinder on the five manually studied systems and three additional systems: Camel, Kafka and Wicket. In total, combining the results of DLFinder and our manual analysis, we reported 91 problematic duplicate logging code smell instances to developers and all of them have been fixed. We further study the relationship between duplicate logging statements, including the problematic instances of duplicate logging code smells, and code clones. We find that 83% of the duplicate logging code smell instances reside in cloned code, but 17% of them reside in micro-clones that are difficult to detect using automated clone detection tools. We also find that more than half of the duplicate logging statements reside in cloned code snippets, and a large portion of them reside in very short code blocks which may not be effectively detected by existing code clone detection tools. Our study shows that, in addition to general source code that implements the business logic, code clones may also result in bad logging practices that could increase maintenance difficulties.",1939-3520,,10.1109/TSE.2021.3060918,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9360483,log;code smell;duplicate log;code clone;static analysis;empirical study,Cloning;Manuals;Tools;Static analysis;Maintenance engineering;Java;Cloud computing,,,,,,,IEEE,22 Feb 2021,,,IEEE,IEEE Early Access Articles
1419,58,Logram: Efficient Log Parsing Using n-Gram Dictionaries,H. Dai; H. Li; C. S. Chen; W. Shang; T. Chen,"Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: he_da@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, (e-mail: hengli@cs.queensu.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: c_chesha@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software systems usually record important runtime information in their logs. Logs help practitioners understand system runtime behaviors and diagnose field failures. As logs are usually very large in size, automated log analysis is needed to assist practitioners in their software operation and maintenance efforts. Typically, the first step of automated log analysis is log parsing, i.e.,converting unstructured raw logs into structured data. However, log parsing is challenging, because logs are produced by static templates in the source code (i.e., logging statements) yet the templates are usually inaccessible when parsing logs. Prior work proposed automated log parsing approaches that have achieved high accuracy. However, as the volume of logs grows rapidly in the era of cloud computing, efficiency becomes a major concern in log parsing. In this work, we propose an automated log parsing approach, Logram, which leverages-gram dictionaries to achieve efficient log parsing. We evaluated Logram on 16 public log datasets and compared Logram with five state-of-the-art log parsing approaches. We found that Logram achieves a higher parsing accuracy than the best existing approaches (i.e., at least 10% higher, on average) and also outperforms these approaches in efficiency (i.e., 1.8 to 5.1 times faster than the second-fastest approaches in terms of end-to-end parsing time). Furthermore, we deployed Logram on Spark and we found that Logram scales out efficiently with the number of Spark nodes (e.g., with near-linear scalability for some logs) without sacrificing parsing accuracy. In addition, we demonstrated that Logram can support effective online parsing of logs, achieving similar parsing results and efficiency to the offline mode.",1939-3520,,10.1109/TSE.2020.3007554,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134790,Log parsing;Log analysis;N-gram,Dictionaries;Runtime;Data mining;Cows;Sparks;Software systems;Moon,,,,3.0,,,,7 Jul 2020,,,IEEE,IEEE Early Access Articles
1420,59,“Sampling” as a Baseline Optimizer for Search-Based Software Engineering,J. Chen; V. Nair; R. Krishna; T. Menzies,"Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,597,614,"Increasingly, Software Engineering (SE) researchers use search-based optimization techniques to solve SE problems with multiple conflicting objectives. These techniques often apply CPU-intensive evolutionary algorithms to explore generations of mutations to a population of candidate solutions. An alternative approach, proposed in this paper, is to start with a very large population and sample down to just the better solutions. We call this method “Sway”, short for “the sampling way”. This paper compares Sway versus state-of-the-art search-based SE tools using seven models: five software product line models; and two other software process control models (concerned with project management, effort estimation, and selection of requirements) during incremental agile development. For these models, the experiments of this paper show that Sway is competitive with corresponding state-of-the-art evolutionary algorithms while requiring orders of magnitude fewer evaluations. Considering the simplicity and effectiveness of Sway, we, therefore, propose this approach as a baseline method for search-based software engineering models, especially for models that are very slow to execute.",1939-3520,,10.1109/TSE.2018.2790925,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249828,Search-based SE;sampling;evolutionary algorithms,Software engineering;Optimization;Software;Numerical models;Evolutionary computation;Estimation;Sociology,evolutionary computation;process control;search problems;software prototyping,baseline optimizer;CPU-intensive evolutionary algorithms;software product line models;software process control models;baseline method;search-based software engineering models;search-based optimization;evolutionary algorithms;SWAY;the sampling way;agile development,,2.0,,78.0,,8 Jan 2018,,,IEEE,IEEE Journals
1421,60,How does Machine Learning Change Software Development Practices?,Z. Wan; X. Xia; D. Lo; G. C. Murphy,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: wanzhiyuan@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Adding an ability for a system to learn inherently adds non-determinism into the system. Given the rising popularity of incorporating machine learning into systems, we wondered how the addition alters software development practices. We performed a mixture of qualitative and quantitative studies with 14 interviewees and 342 survey respondents from 26 countries across four continents to elicit significant differences between the development of machine learning systems and the development of non-machine-learning systems. Our study uncovers significant differences in various aspects of software engineering (e.g., requirements, design, testing, and process) and work features (e.g., skill variety, problem solving and task identity). Based on our findings, we highlight future research directions and provide recommendations for practitioners.",1939-3520,,10.1109/TSE.2019.2937083,National Basic Research Program of China (973 Program); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812912,Software engineering;machine learning;practitioner;empirical study,Software;Interviews;Data models;Machine learning;Testing;Task analysis;Software engineering,,,,2.0,,,,26 Aug 2019,,,IEEE,IEEE Early Access Articles
1422,61,Gender Differences in Personality Traits of Software Engineers,D. Russo; K. Stol,"Department of Computer Science, Aalborg Universitet, 1004 Aalborg, Aalborg Denmark (e-mail: daniel.russo@cs.aau.dk); Computer Science, University College Cork, 8795 Cork, Cork Ireland (e-mail: klaas-jan.stol@lero.ie)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"There is a growing body of gender studies in software engineering to understand diversity and inclusion issues, as diversity is recognized to be a key issue to healthy teams and communities. A second factor often linked to team performance is personality, which has received far more attention. Very few studies, however, have focused on the intersection of these two fields. Hence, we set out to study gender differences in personality traits of software engineers. Through a survey study we collected personality data, using the HEXACO model, of 483 software engineers. The data were analyzed using a Bayesian independent sample t-test and network analysis. The results suggest that women score significantly higher in Openness to Experience, Honesty-Humility, and Emotionality than men. Further, men show higher psychopathic traits than women. Based on these findings, we develop a number of propositions that can guide future research.",1939-3520,,10.1109/TSE.2020.3003413,Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120355,Personality traits;Gender;Empirical software engineering;Bayesian statistics;Network analysis,Software;Software engineering;Instruments;Bayes methods;Sea measurements;Data models;Face,,,,1.0,,,,18 Jun 2020,,,IEEE,IEEE Early Access Articles
1423,62,Towards a Theory of Software Developer Job Satisfaction and Perceived Productivity,M. Storey; T. Zimmermann; C. Bird; J. Czerwonka; B. Murphy; E. Kalliamvakou,"Computer Science, University of Victoria, Victoria, British Columbia Canada (e-mail: mstorey@uvic.ca); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Research, Microsoft Corporation, Redmond, Washington United States (e-mail: cabird@microsoft.com); TSE, Microsoft Corp, 6834 Redmond, Washington United States (e-mail: jacekcz@microsoft.com); Research, Microsoft, Cambridge, Cambridgeshire United Kingdom of Great Britain and Northern Ireland cb30fb (e-mail: bmurphy@microsoft.com); Computer Science, University of Victoria, Victoria, British Columbia Canada V8W 2Y2 (e-mail: ikaliam@uvic.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Developer satisfaction and work productivity are important considerations for software companies. Enhanced developer satisfaction may improve the attraction, retention and health of employees, while higher productivity should reduce costs and increase customer satis- faction through faster software improvements. Many researchers and companies assume that perceived productivity and job satisfaction are related and may be used as proxies for one another, but these claims are a current topic of debate. There are also many social and technical factors that may impact satisfaction and productivity, but which factors have the most impact is not clear, especially for specific development contexts. Through our research, we developed a theory articulating a bi-directional relationship between software developer job satisfaction and perceived productivity, and identified what additional social and technical factors, challenges and work context variables influence this relationship. The constructs and relationships in our theory were derived in part from related literature in software engineering and knowledge work, and we validated and extended these concepts through a rigorously designed survey instrument. We instantiate our theory with a large software company, which suggests a number of propositions about the relative impact of various factors and challenges on developer satisfaction and perceived productivity. Our survey instrument and analysis approach can be applied to other development settings, while our findings lead to concrete recommendations for practitioners and researchers.",1939-3520,,10.1109/TSE.2019.2944354,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851296,software engineering management;empirical studies;software companies;theory,Productivity;Software;Companies;Software engineering;Complexity theory;Psychology;Measurement,,,,1.0,,,,27 Sep 2019,,,IEEE,IEEE Early Access Articles
1424,63,Motivation and Satisfaction of Software Engineers,C. França; F. Q. B. da Silva; H. Sharp,"Departamento de Computação of the Universidade Federal Rural de Pernambuco—UFRPE, Rua Dom Manoel de Medeiros, s/n, Dois Irmãos, Recife, PE, Brazil; Centro de Informática, Universidade Federal de Pernambuco–UFPE. Cidade Universitária, Recife, PE, Brazil; Centre for Research in Computing, The Open University, UK, Milton Keynes, Buckinghamshire, United Kingdom",IEEE Transactions on Software Engineering,12 Feb 2020,2020,46,2,118,140,"Context: The proper management of people can help software organisations to achieve higher levels of success. However, the limited attention paid to the appropriate use of theories to underpin the research in this area leaves it unclear how to deal with human aspects of software engineers, such as motivation and satisfaction. Objectives: This article aims to expose what drives the motivation and satisfaction of software engineers at work. Methods: A multiple case study was conducted at four software organisations in Brazil. For 11 months, data was collected using semi-structured interviews, diary studies, and document analyses. Results: The Theory of Motivation and Satisfaction of Software Engineers (TMS-SE), presented in this article, combines elements from well established theories with new findings, and translates them into the software engineering context. Conclusion: The TMS-SE advances the understanding of people management in the software engineering field and presents a strong conceptual framework for future investigations in this area.",1939-3520,,10.1109/TSE.2018.2842201,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370133,Work motivation;job satisfaction;human resource management;software engineering,Software development management;Software engineering;Productivity;Organizational aspects;Human resource management;Human factors,human factors;human resource management;organisational aspects;software development management,software organisations;software engineers;software engineering context;software engineering field;theory of motivation and satisfaction of software engineers;people management,,2.0,,106.0,IEEE,31 May 2018,,,IEEE,IEEE Journals
1425,64,"Engineering Security Vulnerability Prevention, Detection, and Response",L. Williams; G. McGraw; S. Migues,North Carolina State University; Synopsys; Synopsys,IEEE Software,27 Sep 2018,2018,35,5,76,80,"Around the turn of the 21st century, practices began to emerge to guide teams toward engineering software to stop attackers and users from utilizing unintended functionality by violating the system designer's assumptions to cause a security breach. Yet, breaches are reported daily in the news in all domains-from the casual to the critical. The goal of this article is to help software engineers, software engineering educators, and security researchers understand opportunities for education and research through an analysis of current software security practices. The analysis is conducted on data on the use of a subset of 113 software security practices by 109 firms over 42 months, as reported in the Building Security In Maturity Model (BSIMM) Version 8 report. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290110854,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409917,Building Security In Maturity Model;BSIMM;software security;cybersecurity;software engineering;software security practices;software development,Computer bugs;Software engineering;Computer security;Software development,security of data;software engineering,security breach;software security practices;Building Security In Maturity Model Version 8 report;engineering security vulnerability prevention,,4.0,,10.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1426,65,In Search of Socio-Technical Congruence: A Large-Scale Longitudinal Study,W. Mauerer; M. Joblin; D. A. A. Tamburri; C. Paradis; R. Kazman; S. Apel,"Computer Science and Mathematics, Technical University of Applied Sciences Regensburg, Regensburg, Bavaria, Germany, 93058 (e-mail: wolfgang.mauerer@oth-regensburg.de); Corporate Research, Siemens AG, Munich, Bavaria, Germany, (e-mail: mitchell.joblin@siemens.com); Computer Science, Eindhoven University of Technology School of Innovation Sciences, 200734 Eindhoven, Noord-Brabant, Netherlands, (e-mail: dtamburri@acm.org); Department of Information and Computer Sciences, University of Hawaii, Honolulu, Hawaii, United States, (e-mail: cvas@hawaii.edu); Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii, United States, 96822 (e-mail: kazman@hawaii.edu); Saarland Informatics Campus, Saarland University, 9379 Saarbrcken, Saarland, Germany, (e-mail: apel@cs.uni-saarland.de)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"This paper describes a large-scale empirical study investigating the relevance of socio-technical congruence over key basic software quality metrics, namely, bugs and churn. That is, we explore whether alignment or misalignment of social communication structures and technical dependencies in large software projects influences software quality. To this end, we have defined a quantitative and operational notion of socio-technical congruence, which we call /socio-technical motif congruence/ (STMC). STMC is a measure of the degree to which developers working on the same file or on two related files, need to communicate. As socio-technical congruence is a complex and multi-faceted phenomenon, the interpretability of the results is one of our main concerns, so we have employed a careful mixed-methods statistical analysis. In particular, we provide analyses with similar techniques as employed by seminal work in the field to ensure comparability of our results with the existing body of work. The major result of our study, based on an analysis of 25 large open-source projects, is that STMC is /not/ related to project quality measures---software bugs and churn---in any temporal scenario. That is, we find no statistical relationship between the alignment of developer tasks and developer communications on one hand, and project outcomes on the other hand. We conclude that, wherefore congruence does matter as literature shows, then its measurable effect lies elsewhere.",1939-3520,,10.1109/TSE.2021.3082074,ECSEL; Deutsche Forschungsgemeinschaft; NSF; BayIntAn; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9436025,Socio-Technical Congruence;Human Factors in Software Engineering;Graph Analysis;Empirical Software Engineering;Socio-Technical Analysis;Quantitative Software Engineering;Mixed-Methods Research,Open source software;Computer bugs;Software quality;Measurement;Software architecture;Data models;Task analysis,,,,,,,CCBY,19 May 2021,,,IEEE,IEEE Early Access Articles
1427,66,Empirically Evaluating the Effect of the Physics of Notations on Model Construction,M. El-Attar,"Software Engineering Department, Alfaisal University, 101686 Riyadh, Riyadh, Saudi Arabia, 11533 (e-mail: melattar@alfaisal.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"In 2009, Moody introduced nine principles for evaluating, improving and designing cognitively effective notations called the Physics of Notations [49] motivating many research works ever since, being cited more than 1250 times at the time of writing this paper. Many research works have adopted the nine principles of the Physics of Notations to improve existing notations or devise new notations. Modeling is a two-step process that has the goal of communicating a mental concept by a model constructor (step one) to a model reader (step two). A subset of the research works utilizing the Physics of Notations have empirically validated the cognitive effectiveness of the new notations by their readers. However, there lacks any empirical evidence that investigates the effect of using Physics of Notations-enabled notations in model construction. This is a serious matter to be investigated as naturally model construction preludes model comprehension. Poorly constructed models can at best be poorly comprehended by its readers having dire consequences in downstream development activities. This paper reports on three different experiments that use software engineering professionals as subjects. The experiments investigate the effect of using notations that adhere to the Physics if Notations principles on model construction efforts. The results do not indicate an outright advantage for model constructors who utilize Physics of Notations-enabled notations in comparison to using their original versions of these notations.",1939-3520,,10.1109/TSE.2021.3060344,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357929,Physics of notations;feature diagrams;misuse case diagrams;UML statechart diagrams;subject-based experiment,Unified modeling language;Visualization;Physics;Semantics;Syntactics;Software;Software engineering,,,,,,,IEEE,18 Feb 2021,,,IEEE,IEEE Early Access Articles
1428,67,Software Module Clustering: An In-Depth Literature Analysis,Q. Alsarhan; B. S. Ahmed; M. Bures; K. Z. Zamli,"Computer Science, University of Duhok, 113404 Duhok City, Duhok, Iraq, (e-mail: qusay.sarhan@uod.ac); Computer Science and Engineering, Ceske Vysoke Uceni Technicke v Praze, 48220 Praha, Prague, Czech Republic, 12135 (e-mail: bestoon82@gmail.com); Computer Science and Engineering, Ceske Vysoke Uceni Technicke v Praze, 48220 Praha, Prague, Czech Republic, (e-mail: buresm3@fel.cvut.cz); Faculty of Computer Systems & Software Engineering, Universiti Malaysia Pahang, 65240 Kuantan, Pahang, Malaysia, (e-mail: kamalz@ump.edu.my)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software module clustering is an unsupervised learning method used to cluster software entities (e.g., classes, modules, or files) of similar features. The obtained clusters may be used to study, analyze, and understand the structure and behavior of the software entities. Implementing software module clustering with optimal results is challenging. Accordingly, researchers have addressed many aspects of software module clustering in the last decade. Thus, it is essential to present research evidence that has been published in this area. In this study, 143 research papers that examined software module clustering from well-known literature databases were extensively reviewed to extract useful data. The obtained data were then used to answer several research questions regarding state-of-the-art clustering approaches, applications of clustering in software engineering, clustering process, clustering algorithms, and evaluation methods. Several research gaps and challenges in software module clustering are discussed in this paper to provide a useful reference for researchers in this field.",1939-3520,,10.1109/TSE.2020.3042553,Stiftelsen för Kunskaps- och Kompetensutveckling; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282200,Systematic literature study;software module clustering;clustering applications;clustering algorithms;clustering evaluation;clustering challenges,Software;Search problems;Data mining;Software engineering;Software algorithms;Clustering algorithms;Systematics,,,,,,,IEEE,4 Dec 2020,,,IEEE,IEEE Early Access Articles
1429,68,Hybrid Labels Are the New Measure!,M. Nayebi; S. J. Kabeer; G. Ruhe; C. Carlson; F. Chew,University of Calgary; University of Calgary; University of Calgary; Brightsquid Secure Communication; Brightsquid Secure Communication,IEEE Software,25 Dec 2017,2018,35,1,54,57,"Developing minimum viable products (MVPs) is critical for start-up companies to hit the market fast with an accepted level of performance. The US Food and Drug Administration mandates additional nonfunctional requirements in healthcare systems, meaning that the MVP should provide the best availability, privacy, and security. This critical demand is motivating companies to further rely on analytics to optimize the development process. In a collaborative project with Brightsquid, the authors provided a decision-support system based on analogical reasoning to assist in effort estimation, scoping, and assignment of change requests. This experience report proposes a new metric, change request labels, for better prediction. Using different methods for textual-similarity analysis, the authors found that the combination of machine-learning techniques with experts' manually added labels has the highest prediction accuracy. Better prediction of change impacts allows a company to optimize its resources and provide proper timing of releases to target MVPs. This article is part of a special issue on Actionable Analytics for Software Engineering.",1937-4194,,10.1109/MS.2017.4541048,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239937,software analytics;digital health;digital care;change impact analysis;software engineering;software development,Software engineering;Software development;Medical services;Digital systems;Resource management,case-based reasoning;decision support systems;health care;learning (artificial intelligence);medical computing;software engineering,hybrid labels;minimum viable products;MVP;healthcare systems;Brightsquid;decision-support system;analogical reasoning;change requests;metric change request labels;textual-similarity analysis;machine-learning techniques;change impacts;nonfunctional requirements;US Food and Drug Administration,,,,9.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1430,69,Identifying Self-Admitted Technical Debts with Jitterbug: A Two-Step Approach,Z. Yu; F. M. Fahid; H. Tu; T. Menzies,"Software Engineering, Rochester Institute of Technology, 6925 Rochester, New York United States (e-mail: zyu9@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: ffahid@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27606 (e-mail: hqtu@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Keeping track of and managing Self-Admitted Technical Debts (SATDs) are important to maintaining a healthy software project. This requires much time and effort from human experts to identify the SATDs manually. The current automated solutions do not have satisfactory precision and recall in identifying SATDs to fully automate the process. To solve the above problems, we propose a two-step framework called Jitterbug for identifying SATDs. Jitterbug first identifies the ""easy to find"" SATDs automatically with close to 100% precision using a novel pattern recognition technique. Subsequently, machine learning techniques are applied to assist human experts in manually identifying the remaining ""hard to find"" SATDs with reduced human effort. Our simulation studies on ten software projects show that Jitterbug can identify SATDs more efficiently (with less human effort) than the prior state-of-the-art methods.",1939-3520,,10.1109/TSE.2020.3031401,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226105,Technical debt;software engineering;machine learning;pattern recognition,Software;Machine learning;Pattern recognition;Training;Computer hacking;Machine learning algorithms;Estimation,,,,,,,,15 Oct 2020,,,IEEE,IEEE Early Access Articles
1431,70,A Study of C/C++ Code Weaknesses on Stack Overflow,H. Zhang; S. Wang; H. Li; T. -H. P. Chen; A. E. Hassan,"Centre for Software Excellence, Huawei Technologies Co Ltd Canada, 538302 Markham, Ontario, Canada, (e-mail: hzhang@cs.queensu.ca); Computer Science, University of Manitoba, 8664 Winnipeg, Manitoba, Canada, (e-mail: shaoweiwang.2010@hotmail.com); School of Computing, Queen's University, Kingston, Ontario, Canada, (e-mail: heng.li@polymtl.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Stack Overflow hosts millions of solutions that aim to solve developers' programming issues. Stack Overflow becomes a code hosting website where developers actively share its code. However, code snippets on Stack Overflow may contain security vulnerabilities, and if shared carelessly, such snippets can introduce security problems in software systems. In this paper, we empirically study the prevalence of the <i>Common Weakness Enumeration</i> -- CWE, in code snippets of C/C++ related answers. We explore the characteristics of Code<sub>w</sub>, i.e., code snippets that have CWE instances, in terms of the types of weaknesses, the evolution of Code<sub>w</sub>, and who contributed such code snippets. We find that: 1) 36% (i.e., 32 out of 89) CWE types occurred in Code<sub>w</sub> on Stack Overflow. Particularly, CWE-119, i.e.,<i> improper restriction of operations within the bounds of a memory buffer</i>, is common in both answer code snippets and real-world software systems. Furthermore, the proportion of Code<sub>w</sub>, doubled from 2008 to 2018 after normalizing by the total number of C/C++ snippets in each year. 2) In general, code revisions are associated with a reduction in the number of code weaknesses. However, the majority of Code<sub>w</sub> had weaknesses introduced in the first version of the code, and these Code<sub>w</sub> were never revised since then. Only 7.5% of users who contributed C/C++ code snippets posted or edited code with weaknesses. Users contributed fewer code with CWE weakness when they were more active -- either revised more code snippets or had a higher reputation. We also find that some users tended to have the same CWE type repeatedly in their various code snippets. Our empirical study provides insights to users who share code snippets on Stack Overflow so that they are aware of the potential security issues. To understand the community feedback about improving code weaknesses by answer revisions, we also conduct a pilot user study and 62.5% of our suggested revisions are adopted by the community. Stack Overflow can perform CWE scanning for all the code that is hosted on its platform. Further research is needed to improve the quality of the crowdsourced knowledge on Stack Overflow.",1939-3520,,10.1109/TSE.2021.3058985,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359361,Code Security;C/C++;Empirical Software Engineering;Crowdsourced Knowledge Sharing and Management;Stack Overflow,Security;Programming;Software systems;History;Electronic mail;C++ languages;Indexes,,,,,,,IEEE,19 Feb 2021,,,IEEE,IEEE Early Access Articles
1432,71,The Four Pillars of Research Software Engineering,J. Cohen; D. S. Katz; M. Barker; N. Chue Hong; R. Haines; C. Jay,"Computing, Imperial College London, London, United Kingdom; National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign, Urbana, Illinois United States; Research Software Alliance, Cairns, Queensland, Australia; University of Edinburgh, Edinburgh, United Kingdom; Computer Science, The University of Manchester, Manchester, United Kingdom; Computer Science, University of Manchester, Manchester, United Kingdom",IEEE Software,23 Dec 2020,2021,38,1,97,105,"We present four elements we believe are key to providing a comprehensive and sustainable support for research software engineering: software development, community, training, and policy. We also show how the wider developer community can learn from, and engage with, these activities.",1937-4194,,10.1109/MS.2020.2973362,Engineering and Physical Sciences Research Council; Division of Advanced Cyberinfrastructure; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994167,,Software engineering;Engineering profession;Sustainable development;Training;Software reliability,software engineering,research software engineering;comprehensive support;sustainable support;software development,,,,18.0,IEEE,11 Feb 2020,,,IEEE,IEEE Magazines
1433,72,A Case for Human Values in Software Engineering,J. Whittle; M. A. Ferrario; W. Simm; W. Hussain,"Data61, Monash University, Clayton, Victoria, Australia; Computing and Communications, Lancaster University, Lancaster, United Kingdom; Computng and Communications, Lancaster University, Lancaster, United Kingdom; Software, Monash University, Melbourne, Victoria, Australia",IEEE Software,23 Dec 2020,2021,38,1,106,113,"This article argues that human values-such as responsibility, transparency, creativity, and equality-are heavily underrepresented in software engineering methods. Using experience with projects involving notfor-protorganizations, we explored how human values can be integrated into existing participatory agile practices.",1937-4194,,10.1109/MS.2019.2956701,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917668,D.2.14 Human Factors in Software Design;H.1.2.b Human-centered computing;D.2.1 Requirements/Specifications,Software engineering;Stakeholders;Ethics;Software systems;Design methodology;Taxonomy,object-oriented programming;software engineering,human values;software engineering methods;responsibility value;transparency value;creativity value;equality value,,3.0,,12.0,IEEE,28 Nov 2019,,,IEEE,IEEE Magazines
1434,73,Sentinel: A Hyper-Heuristic for the Generation of Mutant Reduction Strategies,G. Guizzo; F. Sarro; J. Krinke; S. R. Vergilio,"Department of Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland WC1E 6BT (e-mail: g.guizzo@ucl.ac.uk); Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: j.krinke@ucl.ac.uk); Computer Science Department, Federal University of Parana, 28122 Curitiba, PR Brazil (e-mail: silvia@inf.ufpr.br)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Mutation testing is an effective approach to evaluate and strengthen software test suites, but its adoption is currently limited by the mutants' execution computational cost. Several strategies have been proposed to reduce this cost (a.k.a. mutation cost reduction strategies), however none of them has proven to be effective for all scenarios since they often need an ad-hoc manual selection and configuration depending on the software under test (SUT). In this paper, we propose a novel multi-objective evolutionary hyper-heuristic approach, dubbed Sentinel, to automate the generation of optimal cost reduction strategies for every new SUT. We evaluate Sentinel by carrying out a thorough empirical study involving 40 releases of 10 open-source real-world software systems and both baseline and state-of-the-art strategies as a benchmark for a total of 4,800 experiments, which results are evaluated with both quality indicators and statistical significance tests, following the most recent best practice in the literature. The results show that strategies generated by Sentinel outperform the baseline strategies in 95% of the cases always with large effect sizes, and they also obtain statistically significantly better results than state-of-the-art strategies in 88% of the cases with large effect sizes for 95% of them. Also, our study reveals that the mutation strategies generated by Sentinel for a given software version can be used without any loss in quality for subsequently developed versions in 95% of the cases. These results show that Sentinel is able to automatically generate mutation strategies that reduce mutation testing cost without affecting its testing effectiveness (i.e. mutation score), thus taking off from the tester's shoulders the burden of manually selecting and configuring strategies for each SUT.",1939-3520,,10.1109/TSE.2020.3002496,Coordenao de Aperfeioamento de Pessoal de Nvel Superior; European Research Council; Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9117067,Mutation Testing;Mutant Reduction;Software Testing;Grammatical Evolution;Hyper-Heuristic;Search Based Software Testing;Search Based Software Engineering,Testing;Maintenance engineering;Computational efficiency;Open source software;Software engineering;Search problems,,,,,,,,15 Jun 2020,,,IEEE,IEEE Early Access Articles
1435,74,Gender in Software Engineering,J. C. Carver; A. Serebrenik,"Computer Science, University of Alabama, United States; Mathematics and Computer Science, Eindhoven University of Technology",IEEE Software,22 Oct 2019,2019,36,6,76,78,"The topic of gender in software engineering received significant attention during the most recent International Conference on Software Engineering (ICSE). Papers related to gender appeared in the main research track, the Software Engineering in Society (SEIS) track, and the second Gender Equity (GE) workshop (https://sites.google.com/view/ge-icse2019). Three of the papers summarized in this column are coauthored by the column authors.",1937-4194,,10.1109/MS.2019.2934584,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880051,,Engineering profession;Software engineering;Gender issues,,,,,,6.0,,22 Oct 2019,,,IEEE,IEEE Magazines
1436,75,Revisiting Test Impact Analysis in Continuous Testing From the Perspective of Code Dependencies,Z. Peng; T. -H. Chen; J. Yang,"Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: zi_peng@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: jinqiuy@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"In continuous testing, developers execute automated test cases once or even several times per day to ensure the quality of the integrated code. Although continuous testing helps ensure the quality of the code and reduces maintenance effort, it also significantly increases test execution overhead. In this paper, we empirically evaluate the effectiveness of test impact analysis from the perspective of code dependencies in the continuous testing setting. We first applied test impact analysis to one year of software development history in 11 large-scale open-source systems. We found that even though the number of changed files is small in daily commits (median ranges from 3 to 28 files), around 50% or more of the test cases are still impacted and need to be executed. Motivated by our finding, we further studied the code dependencies between source code files and test cases, and among test cases. We found that 1) test cases often focus on testing the integrated behaviour of the systems and 15% of the test cases have dependencies with more than 20 source code files; 2) 18\% of the test cases have dependencies with other test cases, and test case inheritance is the most common cause of test case dependencies; and 3) we documented four dependency-related test smells that we uncovered in our manual study. Our study provides the first step towards studying and understanding the effectiveness of test impact analysis in the continuous testing setting and provides insights on improving test design and execution.",1939-3520,,10.1109/TSE.2020.3045914,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303402,empirical study;test smells;continuous testing;test impact analysis,Testing;Software;Maintenance engineering;Manuals;Computer bugs;Automation;Tools,,,,,,,IEEE,22 Dec 2020,,,IEEE,IEEE Early Access Articles
1437,76,On the Untriviality of Trivial Packages: An Empirical Study of npm JavaScript Packages,M. A. R. Chowdhury; R. Abdalkareem; E. Shihab; B. Adams,"Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: m_wdhu@encs.concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 1M8 (e-mail: rab_abdu@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: eshihab@encs.concordia.ca); Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, Quebec, Canada, H3T 1J4 (e-mail: bram.adams@polymtl.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Nowadays, developing software would be unthinkable without the use of third-party packages. Although such code reuse helps to achieve rapid continuous delivery of software to end-users, blindly reusing code has its pitfalls. For example, prior work has investigated the rationale for using packages that implement simple functionalities, known as trivial packages (i.e., in terms of the code size and complexity). This prior work showed that although these trivial packages were simple, they were popular and prevalent in the npm ecosystem. This popularity and prevalence of trivial packages peaked our interest in questioning the ‘triviality of trivial packages’. To better understand and examine the triviality of trivial packages, we mine a large set of JavaScript projects that use trivial npm packages and evaluate their relative centrality. Specifically, we evaluate the triviality from two complementary points of view: based on project usage and ecosystem usage of these trivial packages. Our result shows that trivial packages are being used in central JavaScript files of a software project. Additionally, by analyzing all external package API calls in these JavaScript files, we found that a high percentage of these API calls are attributed to trivial packages. Therefore, these packages play a significant role in JavaScript files. Furthermore, in the package dependency network, we observed that 16.8% packages are trivial and in some cases removing a trivial package can impact approximately 29% of the ecosystem. Overall, our finding indicates that although smaller in size and complexity, trivial packages are highly depended on packages by JavaScript projects. Additionally, our study shows that although they might be called trivial, nothing about trivial packages is trivial.",1939-3520,,10.1109/TSE.2021.3068901,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387131,Trivial Packages;npm ecosystem;Mining Software Repository,Ecosystems;Software development management;Complexity theory;Tools;Data mining;Software packages;Electronic mail,,,,,,,IEEE,25 Mar 2021,,,IEEE,IEEE Early Access Articles
1438,77,A3: Assisting Android API Migrations Using Code Examples,M. Lamothe; W. Shang; T. P. Chen,"Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: lamothe.max@gmail.com); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: shang@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 2W1 (e-mail: peterc@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The fast-paced evolution of Android APIs has posed a challenging task for Android app developers. To leverage Androids frequently released APIs, developers must often spend considerable effort on API migrations. Prior research and Android official documentation typically provide enough information to guide developers in identifying the API calls that must be migrated and the corresponding API calls in an updated version of Android (what to migrate). However, API migration remains a challenging task since developers lack the knowledge of  $how$  to migrate the API calls. There exist code examples, such as Google Samples, that illustrate the usage of APIs. We posit that by analyzing the changes of API usage in code examples, we can learn API migration patterns to assist developers with API Migrations. In this paper, we propose an approach that learns API migration patterns from code examples, applies these patterns to the source code of Android apps for API migration, and presents the results to users as potential migration solutions. To evaluate our approach, we migrate API calls in open source Android apps by learning API migration patterns from code examples. We find that our approach can successfully learn API migration patterns and provide API migration assistance in 71 out of 80 cases. Our approach can either migrate API calls with little to no extra modifications needed or provide guidance to assist with the migrations. Through a user study, we find that adopting our approach can reduce the time spent on migrating APIs, on average, by 29%. Moreover, our interviews with app developers highlight the benefits of our approach when seeking API migrations. Our approach demonstrates the value of leveraging the knowledge contained in software repositories to facilitate API migrations.",1939-3520,,10.1109/TSE.2020.2988396,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079197,API;software quality;mining software repositories;empirical software engineering,Task analysis;Documentation;Google;Software maintenance;Interviews;Indexes,,,,1.0,,,,27 Apr 2020,,,IEEE,IEEE Early Access Articles
1439,78,Nautilus: An Interactive Plug and Play Search Based Software Engineering Framework,T. Ferreira; S. R. Vergilio; M. Kessentini,"DInf - Federal University of Paraná, UFPR, Curitiba, 80060-000 Parana, Brazil; Computer Science Department, Federal University of Parana - UFPR, Curitiba, 81531-970 Parana, Brazil; Computer Science, Missouri University of Science and Technology, Rolla, Missouri 65401 United States",IEEE Software,,2020,PP,99,0,0,"Several Software Engineering problems are complex and encompass a great number of objectives to be handled. However, practitioners may face several challenges to adopt existing metaheuristic search for their problems due to the lack of background, or some difficult choices such as the change operators, and parameters tuning. Nautilus Framework allows practitioners developing and experimenting several multi- and many-objectives evolutionary algorithms guided (or not) by human participation in few steps with a minimum required background in coding and search-based algorithms. A case study illustrates its benefits, which can also be used to support the construction of AI solutions guided by human decisions.",1937-4194,,10.1109/MS.2020.3039694,Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior; Conselho Nacional de Desenvolvimento Científico e Tecnologico; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264666,preference and search based software engineering;many-objective optimization;plugin and play framework,Optimization;Software algorithms;Search problems;Software;Linear programming;Encoding;Visualization,,,,,,,,19 Nov 2020,,,IEEE,IEEE Early Access Articles
1440,79,Graph Based Mining of Code Change Patterns from Version Control Commits,M. Janke; P. Mader,"Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: mario.janke@tu-ilmenau.de); Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thoringen Germany (e-mail: patrick.maeder@tu-ilmenau.de)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Detailed knowledge of frequently recurring code changes can be beneficial for a variety of software engineering activities. For example, it is a key step to understand the process of software evolution, but is also necessary when developing more sophisticated code completion features predicting likely changes. Previous attempts on automatically finding such code change patterns were mainly based on frequent itemset mining, which essentially finds sets of edits occurring in close proximity. However, these approaches do not analyze the interplay among code elements, e.g., two code objects being named similarly, and thereby neglect great potential in identifying a number of meaningful patterns. We present a novel method for the automated mining of code change patterns from Git repositories that captures these context relations between individual edits. Our approach relies on a transformation of source code into a graph representation, while keeping relevant relations present. We then apply graph mining techniques to extract frequent subgraphs, which can be used for further analysis of development projects. We suggest multiple usage scenarios for the resulting pattern type. Additionally, we propose a transformation into CEP rules which allows for easier application, especially for event-based auto-completion recommenders or similar tools. For evaluation, we mined seven open-source code repositories. We present ten frequent change patterns occurring across these projects. We found these patterns to be meaningful, easy to interpret and mostly persistent across project borders. These ten patterns already cover about 13% of all file changes in the analyzed projects.",1939-3520,,10.1109/TSE.2020.3004892,Deutsche Forschungsgemeinschaft; German Ministry of Education and Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9129812,Code Changes;Data Mining;Frequent Graph Mining;Auto-completion,Data mining;Pipelines;Itemsets;Tools;Optimization;Open source software,,,,,,,,30 Jun 2020,,,IEEE,IEEE Early Access Articles
1441,80,Is Your Software Valueless?,J. Whittle,"Information Technology, Monash University",IEEE Software,16 Apr 2019,2019,36,3,112,115,"Software development ignores human values. As a society, we rely on software systems that neither align with nor respect our core values, such as transparency, gender diversity, social justice, and personal integrity. The past 50 years of software engineering have focused on functionality, cost, safety, availability, and security. But what about broader human values (Figure 1) such as compassion, social responsibility, and justice? The way we design software fundamentally influences society, yet human values-which we would all claim to care about-have been a side concern in software engineering. (See ""Where Are the Values in Software?"").",1937-4194,,10.1109/MS.2019.2897397,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693084,,Software development management;Software engineering;Computer security;Ethics;Human computer interaction,ethical aspects;gender issues;human factors;organisational aspects;software engineering,software systems;core values;gender diversity;social justice;personal integrity;software engineering;broader human values;social responsibility;design software;software development;human values;valueless software;transparency;compassion;time 50.0 year,,4.0,,12.0,,16 Apr 2019,,,IEEE,IEEE Magazines
1442,81,Secure Views for Collaborative Modeling,C. Debreceni; G. Bergmann; I. Ráth; D. Varró,MTA-BME Lendület Cyber-Physical Systems Research Group; MTA-BME Lendület Cyber-Physical Systems Research Group; Budapest University of Technology and Economics; McGill University,IEEE Software,29 Nov 2018,2018,35,6,32,38,"Model-based systems engineering necessitates effective collaboration between different collaborators, teams, and stakeholders. Traditional approaches used for managing concurrent code-based development don't naturally extend to collaborative modeling, which implies novel challenges. This article presents a collaborative-modeling framework that provides secure views with precisely defined model access to each collaborator, using rule-based access control policies. This article is part of a theme issue on collaborative modeling.",1937-4194,,10.1109/MS.2018.290101728,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409907,MONDO;system architectures;integration and modeling;access controls;inter-enterprise collaboration;intra-enterprise collaboration;software engineering;software development,Access control;Software engineering;Software architecture;Load modeling;Collaborative software;Software development,authorisation;groupware;knowledge based systems;software engineering;systems engineering,model access;rule-based access control policies;secure views;collaborative-modeling framework;model-based systems engineering,,,,12.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1443,82,Mythical Unit Test Coverage,V. Antinyan; J. Derehag; A. Sandberg; M. Staron,University of Gothenburg; Ericsson; Ericsson; University of Gothenburg,IEEE Software,4 May 2018,2018,35,3,73,79,"It is a continuous struggle to understand how much a product should be tested before its delivery to the market. Ericsson, as a global software development company, decided to evaluate the adequacy of the unit-test-coverage criterion that it had employed for years as a guide for sufficiency of testing. Naturally, one can think that if increasing coverage decreases the number of defects significantly, then coverage can be considered a criterion for test sufficiency. To test this hypothesis in practice, we investigated the relationship of unit-test-coverage measures and post-unit-test defects in a large commercial product of Ericsson. The results indicate that high unit-test coverage did not seem to be any tangible help in producing defect-free software.",1937-4194,,10.1109/MS.2017.3281318,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354427,software development;unit test;test coverage;code complexity;software metrics;software testing;software engineering,Encoding;Complexity theory;Software engineering;Software metrics;Software testing,program testing;software engineering,Ericsson;global software development company;unit-test-coverage criterion;test sufficiency;unit-test-coverage measures;post-unit-test defects;commercial product;high unit-test coverage;defect-free software;mythical unit test coverage,,2.0,,13.0,,4 May 2018,,,IEEE,IEEE Magazines
1444,83,"User Involvement in Software Development: The Good, the Bad, and the Ugly",M. Bano; D. Zowghi; F. da Rimini,Swinburne University of Technology; University of Technology Sydney; University of Technology Sydney,IEEE Software,29 Nov 2018,2018,35,6,8,11,"Merely involving the users in software development won't guarantee system success. User involvement is a complex, multifaceted phenomenon with a good side, a bad side, and an ugly side. A better, deeper understanding of those sides can help project managers develop responsive strategies for increasing user involvement's effectiveness.",1937-4194,,10.1109/MS.2018.4321252,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552628,user involvement;user satisfaction;requirements analysis;software development;software engineering;software requirements,Software development;Software engineering;Quality of service;User interfaces,project management;software engineering,user involvement;software development;complex phenomenon;multifaceted phenomenon;bad side;ugly side;good side;project managers,,1.0,,10.0,,29 Nov 2018,,,IEEE,IEEE Magazines
1445,84,The Unreasonable Effectiveness of Software Analytics,T. Menzies,North Carolina State University,IEEE Software,12 Mar 2018,2018,35,2,96,98,"In theory, software analytics shouldn't work because software project behavior shouldn't be predictable. However, it does. Why?",1937-4194,,10.1109/MS.2018.1661323,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314156,software analytics;software engineering;software development;Redirections,Software;Complexity theory;Software engineering;Scrum (Software development);Frequency selective surfaces;Task analysis;Software tools,software engineering,unreasonable effectiveness;software analytics;software project behavior,,4.0,,9.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1446,85,Collaborative Modeling and Group Decision Making Using Chatbots in Social Networks,S. Pérez-Soler; E. Guerra; J. de Lara,Universidad Autónoma de Madrid; Universidad Autónoma de Madrid; Universidad Autónoma de Madrid,IEEE Software,29 Nov 2018,2018,35,6,48,54,"Modeling is used in the early phases of software and system development to discuss and explore problems, understand domains, and evaluate alternatives and comprehend their implications. In this setting, modeling is inherently collaborative because it involves stakeholders with different backgrounds and expertise, who cooperate to build solutions based on consensus. However, modeling tools typically provide unwieldy diagrammatic editors that might hamper the active involvement of domain experts and lack mechanisms to ease decision making. To tackle these issues, the proposed approach embeds modeling in social networks, so that the modeling interface is natural language that a chatbot interprets to derive an appropriate domain model. Social networks have intuitive built-in discussion mechanisms, while the use of natural language lowers the entry barrier to modeling for domain experts. Moreover, this approach facilitates choosing among modeling alternatives, using soft-consensus decision making. This approach is supported by the SOCIO tool, which works on social networks such as Telegram. This article is part of a theme issue on collaborative modeling.",1937-4194,,10.1109/MS.2018.290101511,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409918,collaborative modeling;social networks;chatbots;decision making;SOCIO;collaborative modeling;software engineering;software development,Collaborative software;Social network services;Biological system modeling;Decision making;Software engineering,decision making;groupware;natural language processing;social networking (online);software engineering,natural language;domain experts;modeling alternatives;soft-consensus decision making;social networks;collaborative modeling;chatbot;system development;modeling tools;active involvement;modeling interface;discussion mechanisms;group decision making;software development;domain model;embeds modeling;diagrammatic editors;Telegram;theme issue,,10.0,,11.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1447,86,"""Lessons Must Be Learned""-But Are They?",L. Hatton; A. Rutkowski,"Forensic Software Engineering, Kingston University; Management, Tilburg University",IEEE Software,17 Jun 2019,2019,36,4,91,95,"Despite all the software systems we have seen, both in <;italic>IEEE Software's<;/italic> columns and through our professional experience, periodically, something happens in the world of software engineering that really takes us by surprise. The last time we were in this position was after the revelation of software ""cheats,"" that is, algorithms deliberately introduced into a system with the specific purpose of misleading the general public and certification agencies on the nature of system emissions.8 This time, we feel that we must comment on the equally startling revelations emerging about the interactions among software, management, and requirements in the sad case of the two Boeing 737 MAX crashes.",1937-4194,,10.1109/MS.2019.2909330,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738154,,Aircraft;Safety;Software systems;Cetification;Training,software engineering,professional experience;software engineering;software cheats;certification agencies;system emissions;software systems;IEEE Software,,2.0,,19.0,,17 Jun 2019,,,IEEE,IEEE Magazines
1448,87,The Rise and Evolution of Agile Software Development,R. Hoda; N. Salleh; J. Grundy,University of Auckland; International Islamic University Malaysia; Monash University,IEEE Software,27 Sep 2018,2018,35,5,58,63,"Agile software development has dominated the second half of the past 50 years of software engineering. Retrospectives, one of the most common agile practices, enables reflection on past performance, discussion of current progress, and charting forth directions for future improvement. Because of agile's burgeoning popularity as the software development model of choice and a significant research subdomain of software engineering, it demands a retrospective of its own. This article provides a historical overview of agile's main focus areas and a holistic synthesis of its trends, their evolution over the past two decades, agile's current status, and, forecast from these, agile's likely future. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290111318,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409911,agile;agile software development;software engineering;software development,Software engineering;Agile software development;Market research;Planning,software prototyping,agile software development;software engineering;common agile practices,,11.0,,8.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1449,88,The Five Laws of SE for AI,T. Menzies,"RAISE, North Carolina State University, North Carolina United States",IEEE Software,20 Dec 2019,2020,37,1,81,85,"It is time to talk about software engineering (SE) for artificial intelligence (AI). As shown in Figure 1, industry is becoming increasingly dependent on AI software. Clearly, AI is useful for SE. But what about the other way around? How important is SE for AI? Many thought leaders in the AI industry are asking how to better develop and maintain AI software (see Figure 2).",1937-4194,,10.1109/MS.2019.2954841,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938116,,Software engineering;Artificial intelligence;Software development management,artificial intelligence;software engineering,software engineering;artificial intelligence;AI software;AI industry,,4.0,,16.0,,20 Dec 2019,,,IEEE,IEEE Magazines
1450,89,Data Science: Technologies for Better Software,C. Ebert; J. Heidrich; S. Martinez-Fernandez; A. Trendowicz,"Vector Consulting Services; Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany; Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany; Data Engineering, Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany",IEEE Software,22 Oct 2019,2019,36,6,66,72,"Data science is mandatory in today's business to capitalize on achievements and assets. This specifically holds for modern software development, where data science facilitates analyzing product, process, and usage and thus managing evolution and performance. With the convergence of embedded and IT domains, such as the Internet of Things (IoT) and automotive systems, software systems are becoming more complex. Complexity has two faces. On one hand it means more functionality and fluid delivery models, thus offering markets more value, such as the ability to deliver a single-customer focus. Complexity, however, also means the growth of technical debt, which slows productivity and lowers quality. As software engineering generates ever larger and more varied data sets, such as feature usage, code analysis, test coverage, error logs, and maintenance data, companies face the challenge of unlocking the value of that data.",1937-4194,,10.1109/MS.2019.2933681,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880036,,Software tools;Data science;Software measurement;Complexity theory;Analytical models,data handling;software engineering,modern software development;data science;software systems;fluid delivery models;software engineering,,1.0,,8.0,,22 Oct 2019,,,IEEE,IEEE Magazines
1451,90,Healthy Code Reveals the Problem and Solution,G. Fairbanks,"Software Engineering, Google",IEEE Software,15 Aug 2019,2019,36,5,76,79,"Source code reveals abstractions from two places: the problem and the solution. It's easier to design and evolve a system when you understand each of them separately before you combine them in code. With skill, it's possible to separate those concerns in the code. Declarative understanding of the abstractions is the most useful and easy to convey. However, current software development processes rarely guide developers to do this.",1937-4194,,10.1109/MS.2019.2923860,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802316,,Source coding;Software engineering;Data structures;Programming;Software development management,software engineering;source code (software),abstractions;healthy code;source code;software development processes;declarative understanding,,,,4.0,,15 Aug 2019,,,IEEE,IEEE Magazines
1452,91,Deploying Software Team Analytics in a Multinational Organization,V. Augustine; J. Hudepohl; P. Marcinczak; W. Snipes,ABB; ABB; ABB; ABB,IEEE Software,25 Dec 2017,2018,35,1,72,76,"Implementing a software engineering analytics solution poses challenges and offers significant value for the globally distributed software development organization at ABB. Because software development activities in agile methodologies revolve around the team, ABB decided to implement an analytics solution focused on team metrics as part of its Software Development Improvement Program. Using key indicators focused around team improvement, researchers found that teams could manage their activities with metrics such as cycle time. Key lessons learned include paying attention to visual design and navigation and providing drill-down capabilities for the user. This article is part of a special issue on Actionable Analytics for Software Engineering.",1937-4194,,10.1109/MS.2017.4541044,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239945,software metrics;software quality;ABB;software engineering;software development management;software development,Software engineering;Software measurement;Data visualization;Software development,distributed processing;project management;software development management;software prototyping,actionable analytics;analytics solution;drill-down capabilities;navigation;visual design;key lessons;team improvement;key indicators;Software Development Improvement Program;team metrics;agile methodologies;software development activities;ABB;globally distributed software development organization;offers significant value;software engineering analytics solution;multinational organization;software team analytics,,,,13.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1453,92,Competition-Based Crowdsourcing Software Development: A Multi-Method Study from a Customer Perspective,K. Stol; B. Caglayan; B. Fitzgerald,"Department of Computer Science, University College Cork, Cork, Ireland; IBM Ireland, Dublin 4, Ireland; University of Limerick, Limerick, Ireland",IEEE Transactions on Software Engineering,13 Mar 2019,2019,45,3,237,260,"Crowdsourcing is emerging as an alternative outsourcing strategy which is gaining increasing attention in the software engineering community. However, crowdsourcing software development involves complex tasks which differ significantly from the micro-tasks that can be found on crowdsourcing platforms such as Amazon Mechanical Turk which are much shorter in duration, are typically very simple, and do not involve any task interdependencies. To achieve the potential benefits of crowdsourcing in the software development context, companies need to understand how this strategy works, and what factors might affect crowd participation. We present a multi-method qualitative and quantitative theory-building research study. First, we derive a set of key concerns from the crowdsourcing literature as an initial analytical framework for an exploratory case study in a Fortune 500 company. We complement the case study findings with an analysis of 13,602 crowdsourcing competitions over a ten-year period on the very popular Topcoder crowdsourcing platform. Drawing from our empirical findings and the crowdsourcing literature, we propose a theoretical model of crowd interest and actual participation in crowdsourcing competitions. We evaluate this model using Structural Equation Modeling. Among the findings are that the level of prize and duration of competitions do not significantly increase crowd interest in competitions.",1939-3520,,10.1109/TSE.2017.2774297,Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119867,Crowdsourcing;software engineering;multi-method study;case study;sample study,Crowdsourcing;Software;Outsourcing;Mathematical model;Companies,crowdsourcing;public domain software;software engineering;statistical analysis;ubiquitous computing,case study findings;popular Topcoder crowdsourcing platform;crowdsourcing literature;crowd interest;competition-based crowdsourcing software development;multimethod study;customer perspective;alternative outsourcing strategy;software engineering community;complex tasks;microtasks;crowdsourcing platforms;Amazon Mechanical Turk;task interdependencies;software development context;multimethod qualitative;quantitative theory-building research study;exploratory case study;crowdsourcing competitions,,7.0,,157.0,,24 Nov 2017,,,IEEE,IEEE Journals
1454,93,Data Scientists in Software Teams: State of the Art and Challenges,M. Kim; T. Zimmermann; R. DeLine; A. Begel,"University of California, Los Angeles, CA; One Microsoft Way, Redmond, WA; One Microsoft Way, Redmond, WA; One Microsoft Way, Redmond, WA",IEEE Transactions on Software Engineering,11 Nov 2018,2018,44,11,1024,1038,"The demand for analyzing large scale telemetry, machine, and quality data is rapidly increasing in software industry. Data scientists are becoming popular within software teams, e.g., Facebook, LinkedIn and Microsoft are creating a new career path for data scientists. In this paper, we present a large-scale survey with 793 professional data scientists at Microsoft to understand their educational background, problem topics that they work on, tool usages, and activities. We cluster these data scientists based on the time spent for various activities and identify 9 distinct clusters of data scientists, and their corresponding characteristics. We also discuss the challenges that they face and the best practices they share with other data scientists. Our study finds several trends about data scientists in the software engineering context at Microsoft, and should inform managers on how to leverage data science capability effectively within their teams.",1939-3520,,10.1109/TSE.2017.2754374,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8046093,Data science;development roles;software engineering;industry,Data science;Tools;Sociology;Statistics;Software;Best practices;Interviews,information management;software engineering,professional data scientists;software teams;Microsoft;software engineering context,,15.0,,33.0,,19 Sep 2017,,,IEEE,IEEE Journals
1455,94,SEthesaurus: WordNet in Software Engineering,X. Chen; C. Chen; D. Zhang; Z. Xing,"School of Information Science and Technology, Nantong University, 66479 Nantong, Jiangsu China (e-mail: xchencs@ntu.edu.cn); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: chunyang.chen@monash.edu); School of Information Science and Technology, Nantong University, Nantong, jiangsu China (e-mail: dunnzhang0@gmail.com); College of Engineering and Computer Science, Australian National University, Canberra, Australian Capital Territory Australia (e-mail: zhenchang.xing@anu.edu.au)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Informal discussions on social platforms (e.g., Stack Overflow, CodeProject) have accumulated a large body of programming knowledge in the form of natural language text. Natural language process (NLP) techniques can be utilized to harvest this knowledge base for software engineering tasks. However, consistent vocabulary for a concept is essential to make an effective use of these NLP techniques. Unfortunately, the same concepts are often intentionally or accidentally mentioned in many different morphological forms (such as abbreviations, synonyms and misspellings) in informal discussions. Existing techniques to deal with such morphological forms are either designed for general English or mainly resort to domain-specific lexical rules. A thesaurus, which contains software-specific terms and commonly-used morphological forms, is desirable to perform normalization for software engineering text. However, constructing this thesaurus in a manual way is a challenge task. In this paper, we propose an automatic unsupervised approach to build such a thesaurus. In particular, we first identify software-specific terms by utilizing a software-specific corpus (e.g., Stack Overflow) and a general corpus (e.g., Wikipedia). Then we infer morphological forms of software-specific terms by combining distributed word semantics, domain-specific lexical rules and transformations. Finally, we perform graph analysis on morphological relations. We evaluate the coverage and accuracy of our constructed thesaurus against community-cumulated lists of software-specific terms, abbreviations and synonyms. We also manually examine the correctness of the identified abbreviations and synonyms in our thesaurus. We demonstrate the usefulness of our constructed thesaurus by developing three applications and also verify the generality of our approach in constructing thesauruses from data sources in other domains.",1939-3520,,10.1109/TSE.2019.2940439,the seed grant from Monash University; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827962,Software-specific Thesaurus;Natural Language Processing;Morphological Form;Word Embedding,Thesauri;Software engineering;Encyclopedias;Electronic publishing;Internet;Natural language processing,,,,5.0,,,,10 Sep 2019,,,IEEE,IEEE Early Access Articles
1456,95,Key Stakeholders’ Value Propositions for Feature Selection in Software-Intensive Products: An Industrial Case Study,P. Rodríguez; E. Mendes; B. Turhan,"University of Oulu, Oulu, Finland; Blekinge Institute of Technology, Sweden; Monash University, Melbourne, VIC, Australia",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1340,1363,"Numerous software companies are adopting value-based decision making. However, what does value mean for key stakeholders making decisions? How do different stakeholder groups understand value? Without an explicit understanding of what value means, decisions are subject to ambiguity and vagueness, which are likely to bias them. This case study provides an in-depth analysis of key stakeholders' value propositions when selecting features for a large telecommunications company's software-intensive product. Stakeholders' value propositions were elicited via interviews, which were analyzed using Grounded Theory coding techniques (open and selective coding). Thirty-six value propositions were identified and classified into six dimensions: customer value, market competitiveness, economic value/profitability, cost efficiency, technology & architecture, and company strategy. Our results show that although propositions in the customer value dimension were those mentioned the most, the concept of value for feature selection encompasses a wide range of value propositions. Moreover, stakeholder groups focused on different and complementary value dimensions, calling to the importance of involving all key stakeholders in the decision making process. Although our results are particularly relevant to companies similar to the one described herein, they aim to generate a learning process on value-based feature selection for practitioners and researchers in general.",1939-3520,,10.1109/TSE.2018.2878031,Finnish Funding Agency for Technology and Innovation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509148,Value-based software engineering (VBSE);feature selection;release planning;decision-making;value proposition;stakeholder analysis;key stakeholders;software-intensive systems;case study;grounded theory,Stakeholders;Software engineering;Feature extraction;Decision making;Economics,decision making;feature selection;profitability;software engineering,value-based decision making;stakeholder groups;open coding;selective coding;customer value dimension;complementary value dimensions;decision making process;value-based feature selection;key stakeholder value propositions;grounded theory coding techniques;telecommunications company software-intensive product;learning process,,4.0,,70.0,IEEE,25 Oct 2018,,,IEEE,IEEE Journals
1457,96,The Pragmatic Architect Evolves,E. Woods; G. Fairbanks,Endava; Google,IEEE Software,29 Nov 2018,2018,35,6,12,15,"The software architect's role has changed in response to the changing demands of software engineering practice. Now, the Pragmatic Architect department is changing too. This installment looks back over the department's history to see how it has changed and considers the topics it should cover in the future.",1937-4194,,10.1109/MS.2018.4321235,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552622,software architecture;software development;software engineering;The Pragmatic Architect,Software architecture;Software development;Software engineering,software architecture,software architecture;Pragmatic Architect department;software engineering practice,,,,3.0,,29 Nov 2018,,,IEEE,IEEE Magazines
1458,97,The Path to DevOps,E. Dörnenburg,ThoughtWorks,IEEE Software,27 Sep 2018,2018,35,5,71,75,"IT's role in the business world has changed dramatically over the past decades. New technologies and techniques let enterprises get much more out of IT, while increasingly sophisticated business models have pushed IT to investigate and deliver novel solutions. Agile development led the way, and now the DevOps and DesignOps movements are hitting the mainstream. IT in businesses is now entirely a team activity. While we still need experts with deep technical knowledge, we must focus on how to get people from all disciplines working together effectively. This article is part of a theme issue on software engineering's 50th anniversary.",1937-4194,,10.1109/MS.2018.290110337,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409919,DevOps;DesignOps;CycleTime;agile;agile development;software development;software engineering,5G mobile communication;Software engineering;Software development;Agile software development,commerce;software prototyping,DevOps;deep technical knowledge;business world;enterprises;agile development;DesignOps;software engineering,,4.0,,15.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1459,98,The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring,M. Aniche; E. Maziero; R. Durelli; V. Durelli,"Software Engineering Research Group, Technische Universiteit Delft, 2860 Delft, South Holland, Netherlands, 2628CD (e-mail: mauricioaniche@gmail.com); -, Federal University of Lavras, 67739 Lavras, MG, Brazil, (e-mail: Erick.Maziero@ufla.br); -, Federal University of Lavras, 67739 Lavras, MG, Brazil, (e-mail: Rafael.Durelli@ufla.br); -, Federal University of So Joo del-Rei, 74383 Sao Joao del-Rei, MG, Brazil, (e-mail: durelli@ufsj.edu.br)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Refactoring is the process of changing the internal structure of software to improve its quality without modifying its external behavior. Empirical studies have repeatedly shown that refactoring has a positive impact on the understandability and maintainability of software systems. However, before carrying out refactoring activities, developers need to identify refactoring opportunities. Currently, refactoring opportunity identification heavily relies on developers' expertise and intuition. In this paper, we investigate the effectiveness of machine learning algorithms in predicting software refactorings. More specifically, we train six different machine learning algorithms (i.e., Logistic Regression, Naive Bayes, Support Vector Machine, Decision Trees, Random Forest, and Neural Network) with a dataset comprising over two million refactorings from 11,149 real-world projects from the Apache, F-Droid, and GitHub ecosystems. The resulting models predict 20 different refactorings at class, method, and variable-levels with an accuracy often higher than 90%. Our results show that (i) Random Forests are the best models for predicting software refactoring, (ii) process and ownership metrics seem to play a crucial role in the creation of better models, and (iii) models generalize well in different contexts.",1939-3520,,10.1109/TSE.2020.3021736,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186715,software engineering;software refactoring;machine learning for software engineering,Biological system modeling;Measurement;Tools;Software;Predictive models;Context modeling;Prediction algorithms,,,,,,,,4 Sep 2020,,,IEEE,IEEE Early Access Articles
1460,99,Managing Technical Debt in Database Normalization,M. Albarak; R. Bahsoon; I. Ozkaya; R. L. Nord,"School of Computer Science, University of Birmingham, 1724 Birmingham, Birmingham United Kingdom of Great Britain and Northern Ireland (e-mail: mesh55@gmail.com); School of Computer Science, University of Birmingham, Birmingham, BIRMINGHAM United Kingdom of Great Britain and Northern Ireland b15 2TT (e-mail: r.bahsoon@cs.bham.ac.uk); Product Line Systems, Software Architecture Technology Initiative, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: ozkaya@sei.cmu.edu); n/a, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: rn@sei.cmu.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Database normalization is one of the main principles for designing relational databases, which is the most popular database model, with the objective of improving data and system qualities, such as performance. Refactoring the database for normalization can be costly, if the benefits of the exercise are not justified. Developers often ignore the normalization process due to the time and expertise it requires, introducing technical debt into the system. Technical debt is a metaphor that describes trade-offs between short-term goals and applying optimal design and development practices. We consider database normalization debts are likely to be incurred for tables below the fourth normal form. To manage the debt, we propose a multi-attribute analysis framework that makes a novel use of the Portfolio Theory and the TOPSIS method (Technique for Order of Preference by Similarity to Ideal Solution) to rank the candidate tables for normalization to the fourth normal form. The ranking is based on the tables estimated impact on data quality, performance, maintainability, and cost. The techniques are evaluated using an industrial case study of a database-backed web application for human resource management. The results show that the debt-aware approach can provide an informed justification for the inclusion of critical tables to be normalized, while reducing the effort and cost of normalization.",1939-3520,,10.1109/TSE.2020.3001339,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113328,Database Normalization;Multi-attribute analysis;Software Design;Technical Debt,Data integrity;Data models;Relational databases;Redundancy;Portfolios,,,,,,,,10 Jun 2020,,,IEEE,IEEE Early Access Articles
1461,100,"Optimization of Software Release Planning Considering Architectural Dependencies, Cost, and Value",R. S. Sangwan; A. Negahban; R. L. Nord; I. Ozkaya,"Engineering, Pennsylvania State University, 8082 Malvern, Pennsylvania United States (e-mail: rsangwan@psu.edu); Engineering, Pennsylvania State University, 8082 Malvern, Pennsylvania United States (e-mail: aun85@psu.edu); n/a, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: rn@sei.cmu.edu); Product Line Systems, Software Architecture Technology Initiative, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: ozkaya@sei.cmu.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Within any incremental development paradigm, there exists a tension between the desire to deliver value to the customer early and the desire to reduce cost by avoiding architectural refactoring and rework in subsequent releases. What is lacking is an analytical framework that quantifies opportunities and risks of choosing one or the other of these strategies or a blend of the two. This paper demonstrates the use of design structure and domain mapping matrices for analyzing architectural dependencies and proposes an optimization-based decision-making technique to support effective release planning. The optimization models recommend the order in which architectural elements and features should be implemented across different releases so as to: (a) minimize rework cost; (b) maximize early value delivery; or, (c) optimize an integrated measure of cost and value. These analytic models can be applied earlier in the life cycle and, hence, provide timely information about the progress and changes that occur at each iteration.",1939-3520,,10.1109/TSE.2020.3020013,U.S. Department of Defense; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178988,software release management and delivery;software architecture;nonlinear programming,Planning;Software;Computer architecture;Optimization;Electronic mail;Analytical models;Matrix decomposition,,,,,,,,27 Aug 2020,,,IEEE,IEEE Early Access Articles
1462,101,MoMIT: Porting a JavaScript Interpreter on a Quarter Coin,R. Morales; R. Saborido; Y. Guéhéneuc,"Departement of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: moar820326@gmail.com); Department of Computer Science, University of Malaga, Malaga, Andalucia Spain (e-mail: rsain@uma.es); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: yann-gael.gueheneuc@concordia.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The Internet of Things (IoT) is a network of physical, connected devices providing services through private networks and the Internet. The devices connect through the Internet to Web servers and other devices. One of the popular programming languages for communicating Web pages and Web apps is JavaScript (JS). Hence, the devices would benefit from JS apps. However, porting JS apps to the many IoT devices, e.g., System-on-a-Chip (SoCs) devices (e.g., Arduino Uno), is challenging because of their limited memory, storage, and CPU capabilities. Also, some devices may lack hardware/software capabilities for running JS apps ""as is"". Thus, we propose MoMIT, a multiobjective optimization approach to miniaturize JS apps to run on IoT devices. We implement MoMIT using three different search algorithms. We miniaturize a JS interpreter and measure the characteristics of 23 apps before/after applying MoMIT. We find reductions of code size, memory usage, and CPU time of 31%, 56%, and 36%, respectively (medians). We show that MoMIT allows apps to run on up to two additional devices in comparison to the original JS interpreter.",1939-3520,,10.1109/TSE.2020.2968061,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966499,Internet of Things;Software Miniaturization;Multiobjective optimization;embedded devices;JavaScript;Evolutionary algorithms,Optimization;Software;Internet of Things;Computer languages;Tools;Companies;Hardware,,,,1.0,,,,22 Jan 2020,,,IEEE,IEEE Early Access Articles
1463,102,Real World Scrum A Grounded Theory of Variations in Practice,Z. Masood; R. Hoda; K. Blincoe,"Electrical, Computer, and Software Engineering, The University of Auckland, 1415 Auckland, Auckland New Zealand (e-mail: zmas690@aucklanduni.ac.nz); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: rashina@gmail.com); Electrical, Computer, and Software Engineering, University of Auckland, 1415 Auckland, Auckland New Zealand 1142 (e-mail: kelly.blincoe@gmail.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Scrum, the most popular agile method and project management framework, is widely reported to be used, adapted, misused, and abused in practice. However, not much is known about how Scrum actually works in practice, and critically, where, when, how and why it diverges from Scrum by the book. Through a Grounded Theory study involving semi-structured interviews of 45 participants from 30 companies and observations of five teams, we present our findings on how Scrum works in practice as compared to how it is presented in its formative books. We identify significant variations in these practices such as work breakdown, estimation, prioritization, assignment, the associated roles and artefacts, and discuss the underlying rationales driving the variations. Critically, we claim that not all variations are process misuse/abuse and propose a nuanced classification approach to understanding variations as standard, necessary, contextual, and clear deviations for successful use and adaptation of Scrum by the book in practice.",1939-3520,,10.1109/TSE.2020.3025317,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201058,Scrum;agile;Scrum by the book;Scrum In practice;variations;grounded theory,Scrum (Software development);Lead;Software;Project management;Interviews;Electric breakdown;Estimation,,,,1.0,,,,21 Sep 2020,,,IEEE,IEEE Early Access Articles
1464,103,How Practitioners Perceive Automated Bug Report Management Techniques,W. Zou; D. Lo; Z. Chen; X. Xia; Y. Feng; B. Xu,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing Shi, Jiangsu Sheng, China; School of Information Systems, Singapore Management University, Singapore; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing Shi, Jiangsu Sheng, China; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Department of Informatics, University of California, Irvine, Irvine, CA, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing Shi, Jiangsu Sheng, China",IEEE Transactions on Software Engineering,13 Aug 2020,2020,46,8,836,862,"Bug reports play an important role in the process of debugging and fixing bugs. To reduce the burden of bug report managers and facilitate the process of bug fixing, a great amount of software engineering research has been invested toward automated bug report management techniques. However, the verdict is still open whether such techniques are actually required and applicable outside the domain of theoretical research. To fill this gap, we conducted a survey among 327 practitioners to gain their insights into various categories of automated bug report management techniques. Specifically, we asked the respondents to rate the importance of such techniques and provide the rationale. To get deeper insights into practitioners' perspective, we conducted follow-up interviews with 25 interviewees selected from the survey respondents. Through the survey and the interviews, we gained a better understanding of the perceived usefulness (or its lack) of different categories of automated bug report management techniques. Based on our findings, we summarized some potential research directions in developing techniques to help developers better manage bug reports.",1939-3520,,10.1109/TSE.2018.2870414,National Natural Science Foundation of China; China Scholarship Council Scholarship; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466000,Bug report;developer perception,Computer bugs;Software;Software engineering;Bibliographies;Conferences;Interviews;Maintenance engineering,program debugging;software engineering,practitioner perspective;automated bug report management techniques;software engineering research;debugging;bug fixing,,3.0,,93.0,IEEE,14 Sep 2018,,,IEEE,IEEE Journals
1465,104,Understanding Diverse Usage Patterns from Large-Scale Appstore-Service Profiles,X. Liu; H. Li; X. Lu; T. Xie; Q. Mei; F. Feng; H. Mei,"Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; University of Illinois Urbana-Champaign, Champaign, IL; University of Michigan, Ann Arbor, MI; Wandoujia, Beijing, China; Beijing Institute of Technology",IEEE Transactions on Software Engineering,16 Apr 2018,2018,44,4,384,411,"The prevalence of smart mobile devices has promoted the popularity of mobile applications (a.k.a. apps). Supporting mobility has become a promising trend in software engineering research. This article presents an empirical study of behavioral service profiles collected from millions of users whose devices are deployed with Wandoujia, a leading Android app-store service in China. The dataset of Wandoujia service profiles consists of two kinds of user behavioral data from using 0.28 million free Android apps, including (1) app management activities (i.e., downloading, updating, and uninstalling apps) from over 17 million unique users and (2) app network usage from over 6 million unique users. We explore multiple aspects of such behavioral data and present patterns of app usage. Based on the findings as well as derived knowledge, we also suggest some new open opportunities and challenges that can be explored by the research community, including app development, deployment, delivery, revenue, etc.",1939-3520,,10.1109/TSE.2017.2685387,National Basic Research Program (973) of China; Natural Science Foundation of China; National Science Foundation; National Science Foundation; MCubed; University of Michigan; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883939,Mobile apps;app store;user behavior analysis,Androids;Humanoid robots;Software;Biological system modeling;Mobile communication;Electronic mail;Software engineering,Android (operating system);mobile computing;public domain software;software engineering,Wandoujia service profiles;user behavioral data;app usage;app development;diverse usage patterns;large-scale appstore-service profiles;smart mobile devices;mobile applications;software engineering research;behavioral service profiles;leading Android app-store service;free Android apps;app management activities;app network usage,,4.0,,68.0,,21 Mar 2017,,,IEEE,IEEE Journals
1466,105,Stability in Software Engineering: Survey of the State-of-the-Art and Research Directions,M. Salama; R. Bahsoon; P. Lago,"School of Computer Science, University of Birmingham, Birmingham, West Middlands United Kingdom of Great Britain and Northern Ireland (e-mail: m.salama@cs.bham.ac.uk); School of Computer Science, University of Birmingham, Birmingham, West Middlands United Kingdom of Great Britain and Northern Ireland (e-mail: r.bahsoon@cs.bham.ac.uk); Department of Computer Science, VU University Amsterdam, Amsterdam, NL Netherlands 1081HV (e-mail: p.lago@vu.nl)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"With the increasing dependence on software systems, their longevity is becoming a pressing need. Stability is envisioned as a primary property to achieve longevity. Stability has been defined and treated in many different ways in the literature. We conduct a systematic literature review to analyse the state-of-the-art related to stability as a software property. We formulate a taxonomy for characterising the notion, analyse the definitions found in the literature, and present research studies dealing with stability. Also, as architecture is one of the software artefacts with profound effects throughout the software lifecycle, we focus on software engineering practices for realising architectural stability. The analysis results show a wide variation in dimensions when dealing with stability. The state-of-the-art indicates the need for a shift towards a multi-dimensional concept that could cope with runtime dynamics and emerging software paradigms. More research efforts should be directed toward the identified gaps. The presented taxonomy and analysis of the literature aim to help the research community in consolidating the existing research efforts and deriving future developments.",1939-3520,,10.1109/TSE.2019.2925616,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747478,software architecture;longevity;quality;stability;architecture design;architecture evaluation;architectural stability,Stability criteria;Software engineering;Computer architecture;Software systems;Taxonomy,,,,1.0,,,,27 Jun 2019,,,IEEE,IEEE Early Access Articles
1467,106,On Scheduling Constraint Abstraction for Multi-Threaded Program Verification,L. Yin; W. Dong; W. Liu; J. Wang,"Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, Hunan, China; Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, Hunan, China; Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, Hunan, China; Laboratory of Software Engineering for Complex Systems, State Key Laboratory of High Performance Computing, School of Computer, National University of Defense Technology, Changsha, Hunan, China",IEEE Transactions on Software Engineering,14 May 2020,2020,46,5,549,565,"Bounded model checking is among the most efficient techniques for the automated verification of concurrent programs. However, due to the nondeterministic thread interleavings, a large and complex formula is usually required to give an exact encoding of all possible behaviors, which significantly limits the scalability. Observing that the large formula is usually dominated by the exact encoding of the scheduling constraint, this paper proposes a novel scheduling constraint based abstraction refinement method for multi-threaded C program verification. Our method is both efficient in practice and complete in theory, which is challenging for existing techniques. To achieve this, we first proposed an effective and powerful technique which works well for nearly all benchmarks we evaluated. We have proposed the notion of Event Order Graph (EOG), and have devised two graph-based algorithms over EOG for counterexample validation and refinement generation, which can often obtain a small yet effective refinement constraint. Then, to ensure completeness, our method was enhanced with two constraint-based algorithms for counterexample validation and refinement generation. Experimental results on SV-COMP 2017 benchmarks and two real-world server systems indicate that our method is promising and significantly outperforms the state-of-the-art tools.",1939-3520,,10.1109/TSE.2018.2864122,National Natural Science Foundation of China; National Key R&D program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428438,Multi-threaded program;bounded model checking;scheduling constraint;event order graph,Instruction sets;Electrooculography;Encoding;Concurrent computing;Programming;Model checking;Tools,graph theory;multi-threading;program diagnostics;program verification;scheduling,multithreaded program verification;bounded model checking;automated verification;concurrent programs;nondeterministic thread interleavings;complex formula;exact encoding;multithreaded C program verification;event order graph;EOG;graph-based algorithms;refinement generation;constraint-based algorithms;refinement constraint;scheduling constraint based abstraction refinement,,3.0,,45.0,IEEE,7 Aug 2018,,,IEEE,IEEE Journals
1468,107,Inputs from Hell Learning Input Distributions for Grammar-Based Test Generation,E. Soremekun; E. Pavese; N. Havrikov; L. Grunske; A. Zeller,"Software Engineering Chair, CISPA - Helmholtz Center for Information Security, 535167 Saarbrucken, Saarland Germany (e-mail: ezekiel.soremekun@cispa.saarland); Software Engineering, Humboldt-Universitat zu Berlin, 9373 Berlin, Berlin Germany (e-mail: epavese@gmail.com); Software Engineering Chair, CISPA - Helmholtz Center for Information Security, 535167 Saarbrucken, Saarland Germany (e-mail: nikolas.havrikov@cispa.saarland); Software Engineering, Humboldt-Universitat zu Berlin, 9373 Berlin, Berlin Germany 10099 (e-mail: grunske@informatik.hu-berlin.de); Software Engineering Chair, CISPA - Helmholtz Center for Information Security, 535167 Saarbrucken, Saarland Germany (e-mail: zeller@cispa.saarland)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Grammars can serve as producers for structured test inputs that are syntactically correct by construction. A probabilistic grammar assigns probabilities to individual productions, thus controlling the distribution of input elements. Using the grammars as input parsers, we show how to learn input distributions from input samples, allowing to create inputs that are similar to the sample; by inverting the probabilities, we can create inputs that are dissimilar to the sample. This allows for three test generation strategies: 1) Common inputs by learning from common inputs, we can create inputs that are similar to the sample; this is useful for regression testing. 2) Uncommon inputs learning from common inputs and inverting probabilities yields inputs that are strongly dissimilar to the sample; this is useful for completing a test suite with inputs from hell that test uncommon features, yet are syntactically valid. 3) Failure-inducing inputs learning from inputs that caused failures in the past gives us inputs that share similar features and thus also have a high chance of triggering bugs; this is useful for testing the completeness of fixes. Our evaluation on three common input formats (JSON, JavaScript, CSS) shows the effectiveness of these approaches. Results show that common inputs reproduced 96% of the methods induced by the samples. In contrast, for almost all subjects (95%), the uncommon inputs covered significantly different methods from the samples. Learning from failure-inducing samples reproduced all exceptions (100%) triggered by the failure-inducing samples and discovered new exceptions not found in any of the samples learned from.",1939-3520,,10.1109/TSE.2020.3013716,Deutsche Forschungsgemeinschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154602,test case generation;probabilistic grammars;input samples,Grammar;Production;Probabilistic logic;Computer bugs;Software;Test pattern generators,,,,,,,,3 Aug 2020,,,IEEE,IEEE Early Access Articles
1469,108,LogAssist: Assisting Log Analysis Through Log Summarization,S. Locke; H. Li; T. -H. P. Chen; W. Shang; W. Liu,"Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: s_loc@encs.concordia.ca); Computer Engineering and Software Engineering, Polytechnique Montreal, 5596 Montreal, Quebec, Canada, H3T 1J4 (e-mail: heng.li@polymtl.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: w_liu201@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Logs contain valuable information about the runtime behaviors of software systems. Thus, practitioners rely on logs for various tasks such as debugging, system comprehension, and anomaly detection. However, due to the unstructured nature and large size of logs, there are several challenges that practitioners face with log analysis. In this paper, we propose a novel approach called LogAssist that tackles these challenges and assists practitioners with log analysis. LogAssist provides an organized and concise view of logs by first grouping logs into event sequences (i.e., workflows), which better illustrate the system runtime execution paths. Then, LogAssist compresses the log events in workflows by hiding consecutive events and applying n-gram modeling to identify common event sequences. We evaluated LogAssist on the logs that are generated by two open-source and one enterprise system. We find that LogAssist can reduce the number of log events that practitioners need to investigate by up to 99%. Through a user study with 19 participants, we also find that LogAssist can assist practitioners by reducing the needed time on log analysis tasks by an average of 40%. The participants also rated LogAssist an average of 4.53 out of 5 for improving their experiences of performing log analysis. Finally, we document our experiences and lessons learned from developing and adopting LogAssist in practice. We believe that LogAssist and our reported experiences may lay the basis for future analysis and interactive exploration on logs.",1939-3520,,10.1109/TSE.2021.3083715,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442364,Log analysis;log compression;n-gram modeling;log abstraction;workflow characterization;log reduction,Task analysis;Runtime;Tools;Testing;Faces;Anomaly detection;Software systems,,,,,,,IEEE,26 May 2021,,,IEEE,IEEE Early Access Articles
1470,109,The Offshoring Elephant in the Room: Turnover,D. Smite; R. van Solingen; P. Chatzipetrou,"Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; Global Software Engineering, Delft University of Technology, Delft, The Netherlands; Informatics, Orebro University, Sweden",IEEE Software,15 Apr 2020,2020,37,3,54,62,"Staffing software projects with engineers from inexpensive locations has become commonplace. However, distributed development remains practically challenging because of recurring problems, e.g., decreased productivity, low quality, and high, unforeseen costs. Although it is often overlooked, one of the main underlying reasons for these challenges is high employee turnover. This might be especially noticeable in developing countries with strong economic growth such as India. This article examines turnover of Indian software engineers and introduces strategies to address it.",1937-4194,,10.1109/MS.2018.2886179,Stiftelsen for Kunskaps- och Kompetensutveckling; Stiftelsen for Kunskaps- och Kompetensutveckling; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664169,Offshoring;Global software engineering;Global software development;Turnover;Attrition;Hidden costs,Project management;Software development management;Productivity;Collaboration;Economics;Employment;Personnel,DP industry;labour resources;personnel;planning;recruitment;software engineering,high employee turnover;strong economic growth;Indian software engineers;unforeseen costs;decreased productivity;distributed development;inexpensive locations;staffing software projects;offshoring elephant,,,,15.0,,10 Mar 2019,,,IEEE,IEEE Magazines
1471,110,Software Bots,C. Lebeuf; M. Storey; A. Zagalsky,University of Victoria; University of Victoria; University of Victoria,IEEE Software,25 Dec 2017,2018,35,1,18,23,"Although the development and widespread adoption of software bots has occurred in just a few years, bots have taken on many diverse tasks and roles. This article discusses current bot technology and presents a practical case study on how to use bots in software engineering.",1937-4194,,10.1109/MS.2017.4541027,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239928,software bots;bots;chatbots;Slack;software engineering;software development;Software Technology,Software development;Graphical user interfaces;Bot (Internet);Software engineering,software agents;software engineering,current bot technology;software engineering;software bots,,20.0,,11.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1472,111,Dealing with Non-Functional Requirements in Model-Driven Development: A Survey,D. Ameller; X. Franch; C. Gómez; S. Martínez-Fernández; J. Araújo; S. Biffl; J. Cabot; V. Cortellessa; D. M. Fernández; A. Moreira; H. Muccini; A. Vallecillo; M. Wimmer; V. Amaral; W. Böhm; H. Bruneliere; L. Burgueño; M. Goulão; S. Teufl; L. Berardinelli,"Universitat Politècnica de Catalunya, Barcelona, Spain; Departament de Enginyeria de Serveis i Sistemes de Informació, Universitat Politècnica de Catalunya, Barcelona, Spain; Service and Information System Engineering, Universitat Politècnica de Catalunya, Barcelona, Spain; Data Engineering, Fraunhofer IESE, Kaiserslautern, Germany; Department of Informatics, Universidade Nova de Lisboa, Caparica, Portugal; Department of Software Engineering, Technische Universitat Wien, Vienna, Austria; IN3-UOC, Institucio Catalana de Recerca i Estudis Avancats, Barcelona, Spain; Dipartimento di Informatica, Universita’ dell’Aquila, L’Aquila, Italy; Technische Universität München, Garching, Gemany; Department of Informatics, Universidade Nova de Lisboa, Caparica, Portugal; DISIM, University of L’Aquila, L’Aquila, Italy; Lenguajes y Ciencias de la Computación, Universidad de Malaga, Malaga, Spain; Computer Science, Vienna University of Technology, Vienna, Austria; Department of Informatics, Universidade Nova de Lisboa, Caparica, Portugal; Technische Universität München, Garching, Gemany; NaoMod Team, IMT Atlantique Bretagne - Pays de Loire, Brest, Nantes-France; Lenguajes y Ciencias de la Computación, Universidad de Malaga, Malaga, Spain; Faculdade de Ciencias e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal; Technische Universität München, Garching, Gemany; Department of Software Engineering, Technische Universitat Wien, Vienna, Austria",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,818,835,"Context: Managing Non-Functional Requirements (NFRs) in software projects is challenging, and projects that adopt Model-Driven Development (MDD) are no exception. Although several methods and techniques have been proposed to face this challenge, there is still little evidence on how NFRs are handled in MDD by practitioners. Knowing more about the state of the practice may help researchers to steer their research and practitioners to improve their daily work. Objective: In this paper, we present our findings from an interview-based survey conducted with practitioners working in 18 different companies from 6 European countries. From a practitioner's point of view, the paper shows what barriers and benefits the management of NFRs as part of the MDD process can bring to companies, how NFRs are supported by MDD approaches, and which strategies are followed when (some) types of NFRs are not supported by MDD approaches. Results: Our study shows that practitioners perceive MDD adoption as a complex process with little to no tool support for NFRs, reporting productivity and maintainability as the types of NFRs expected to be supported when MDD is adopted. But in general, companies adapt MDD to deal with NFRs. When NFRs are not supported, the generated code is sometimes changed manually, thus compromising the maintainability of the software developed. However, the interviewed practitioners claim that the benefits of using MDD outweight the extra effort required by these manual adaptations. Conclusion: Overall, the results indicate that it is important for practitioners to handle `NFRs in MDD, but further research is necessary in order to lower the barrier for supporting a broad spectrum of NFRs with MDD. Still, much conceptual and tool implementation work seems to be necessary to lower the barrier of integrating the broad spectrum of NFRs in practice.",1939-3520,,10.1109/TSE.2019.2904476,"NOVA LINCS Research Laboratory; Spanish projects; Austrian Federal Ministry for Digital, Business and Enterprise; Österreichische Nationalstiftung für Forschung, Technologie und Entwicklung; ECSEL (Electronic Component Systems for European Leadership Joint Undertaking) project named MegaM@Rt2; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8665968,Model-driven development;non-functional requirements;quality requirements;requirements engineering;survey,Unified modeling language;Software;Companies;Productivity;Software engineering;Security;Analytical models,,,,7.0,,72.0,IEEE,12 Mar 2019,,,IEEE,IEEE Journals
1473,112,Asymmetric Release Planning: Compromising Satisfaction against Dissatisfaction,M. Nayebi; G. Ruhe,"Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada; Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada",IEEE Transactions on Software Engineering,17 Sep 2019,2019,45,9,839,857,"Maximizing satisfaction from offering features as part of the upcoming release(s) is different from minimizing dissatisfaction gained from not offering features. This asymmetric behavior has never been utilized for product release planning. We study Asymmetric Release Planning (ARP) by accommodating asymmetric feature evaluation. We formulated and solved ARP as a bi-criteria optimization problem. In its essence, it is the search for optimized trade-offs between maximum stakeholder satisfaction and minimum dissatisfaction. Different techniques including a continuous variant of Kano analysis are available to predict the impact on satisfaction and dissatisfaction with a product release from offering or not offering a feature. As a proof of concept,we validated the proposed solution approach called Satisfaction-Dissatisfaction Optimizer (SDO) via a real-world case study project. From running three replications with varying effort capacities, we demonstrate that SDO generates optimized trade-off solutions being (i) of a different value profile and different structure, (ii) superior to the application of random search and heuristics in terms of quality and completeness, and (iii) superior to the usage of manually generated solutions generated from managers of the case study company. A survey with 20 stakeholders evaluated the applicability and usefulness of the generated results.",1939-3520,,10.1109/TSE.2018.2810895,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307259,Release planning;bi-objective optimization;stakeholder satisfaction;stakeholder dissatisfaction;case study;empirical evaluation,Planning;Stakeholders;Software engineering;Software;Streaming media;Mathematical model;Optimization,optimisation;pattern classification,offering features;asymmetric behavior;product release planning;ARP;asymmetric feature evaluation;maximum stakeholder satisfaction;minimum dissatisfaction;optimized trade-off solutions;different value profile;upcoming release;asymmetric release planning;bicriteria optimization problem;satisfaction-dissatisfaction optimizer;random search,,1.0,,79.0,,6 Mar 2018,,,IEEE,IEEE Journals
1474,113,AI in Software Engineering at Facebook,J. Bader; S. Kim; F. Luan; S. Chandra; E. Meijer,"Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States",IEEE Software,,2021,PP,99,0,0,"We address the question: How can AI help software engineers better do their jobs and advance the state of the practice? Our perspective comes from building and integrating AI-based techniques in Facebook’s developer infrastructure over the past two years. In this article, we describe three productivity tools that we have built that learn patterns from software artifacts: code search using natural language, code recommendation, and automatic bug fixing. We also present a broader picture of how machine learning can bring insights to virtually all stages of the software lifecycle.",1937-4194,,10.1109/MS.2021.3061664,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9360852,,Social networking (online);Tools;Training;Licenses;Data mining;Software engineering;Software development management,,,,,,,CCBYNCND,23 Feb 2021,,,IEEE,IEEE Early Access Articles
1475,114,The Diversity Crisis of Software Engineering for Artificial Intelligence,B. Adams; F. Khomh,"Maintenance, Construction, and Intelligence of Software, Polytechnique Montreal, Canada; Software Analytics and Technology, Polytechnique Montreal, Canada",IEEE Software,21 Aug 2020,2020,37,5,104,108,"Artificial Intelligence (AI) is experiencing a ""diversity crisis.""1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (""given enough eyeballs, all bugs are shallow"") but applied to the development process of AI products.",1937-4194,,10.1109/MS.2020.2975075,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173624,,Companies;Software engineering;Machine learning;Artificial intelligence;Google;Industries,,,,,,16.0,,21 Aug 2020,,,IEEE,IEEE Magazines
1476,115,Designing Corporate Hackathons With a Purpose: The Future of Software Development,E. P. P. Pe-Than; A. Nolte; A. Filippova; C. Bird; S. Scallen; J. D. Herbsleb,"Software Research, Carnegie Mellon University, Pittsburg, Pennsylvania United States; Computer Science, University of Tartu; GitHub; Empirical Software Engineering, Microsoft Research; Principal Design, Microsoft Garage; Software Research, Carnegie Mellon University, Pittsburg, Pennsylvania United States",IEEE Software,14 Jan 2019,2019,36,1,15,22,"Based on our empirical studies of 10 hackathons held by scientific communities, a corporation, and universities as well as the review of published literature, we discuss that hackathons can be organized around goals such as enriching social networks, facilitating collaborative learning, and workforce development. We also discuss design choices that can scaffold the organization of hackathons and their tradeoffs. Design choices include identifying a suitable mixture of attendee skills, the selection process for projects and teams, and whether to hold a competitive or collaborative event. Hackathons can achieve multiple goals if designed carefully.",1937-4194,,10.1109/MS.2018.290110547,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409916,computing milieux;Computers and Society;organizational impacts;computer-supported collaborative work;Software;Software Engineering;human factors in software design;Information Technology and Systems;Information Interfaces and Representation (HCI);group and organization interfaces;collaborative computing;management of computing and information systems;software management;software development;services computing;services lifecycle;key factors in services lifecycle;innovation and technology,Software development management;Social netwowrk services;Agile software development;Collaborative work;Software engineering;Information and communication technology,computer crime;hobby computing;social aspects of automation;social networking (online);software engineering,corporate hackathons;software development;empirical studies;scientific communities;published literature;social networks;collaborative learning;workforce development;design choices;attendee skills,,4.0,,14.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1477,116,Effects of Mindfulness on Conceptual Modeling Performance: a Series of Experiments,B. Bernardez; A. Duran Toro; J. A. Parejo Maestre; N. Juristo; A. Ruiz-Cortes,"Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: beat@us.es); Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: amador@us.es); Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: japarejo@us.es); Escuela Tcnica Superior de Ingenieros Informticos, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: natalia@fi.upm.es); Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: aruiz@us.es)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Context. Mindfulness is a meditation technique whose main goal is keeping the mind calm and educating attention by focusing only on one thing at a time, usually breathing. The reported benefits of its continued practice can be of interest for Software Engineering students and practitioners, especially in tasks like conceptual modeling, in which concentration and clearness of mind are crucial. Goal. In order to evaluate whether Software Engineering students enhance their conceptual modeling performance after several weeks of mindfulness practice, a series of three controlled experiments were carried out at the University of Seville during three consecutive academic years (2013—2016) involving 130 students. Method. In all the experiments, the subjects were divided into two groups. While the experimental group practiced mindfulness, the control group was trained in public speaking as a placebo treatment. All the subjects developed two conceptual models based on a transcript of an interview, one before and another one after the treatment. The results were compared in terms of conceptual modeling quality (measured as effectiveness, i.e. the percentage of model elements correctly identified) and productivity (measured as efficiency, i.e. the number of model elements correctly identified per unit of time). Results. The statistically significant results of the series of experiments revealed that the subjects who practiced mindfulness developed slightly better conceptual models (their quality was 8.16% higher) and they did it faster (they were 46.67% more productive) than the control group, even if they did not have a previous interest in meditation. Conclusions. The practice of mindfulness improves the performance of Software Engineering students in conceptual modeling, especially their productivity. Nevertheless, more experimentation is needed in order to confirm the outcomes in other Software Engineering tasks and populations.",1939-3520,,10.1109/TSE.2020.2991699,European Commission FEDER and the Spanish Government; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084263,Mindfulness;Conceptual Modeling;Experiment Replication;Family of Experiments;Software Engineering Education,Software engineering;Education;Task analysis;Productivity;Stress;Focusing;Public speaking,,,,,,,,1 May 2020,,,IEEE,IEEE Early Access Articles
1478,117,$\mathcal K$K-Branching UIO Sequences for Partially Specified Observable Non-Deterministic FSMs,K. El-Fakih; R. M. Hierons; U. C. Türker,"Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Computer Science, The University of Sheffield, Sheffield, United Kingdom; Computer Engineering, Gebze Technical University, Kocaeli, Turkey",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,1029,1040,"In black-box testing, test sequences may be constructed from systems modelled as deterministic finite-state machines (DFSMs) or, more generally, observable non-deterministic finite state machines (ONFSMs). Test sequences usually contain state identification sequences, with unique input output sequences (UIOs) often being used with DFSMs. This paper extends the notion of UIOs to ONFSMs. One challenge is that, as a result of non-determinism, the application of an input sequence can lead to exponentially many expected output sequences. To address this scalability problem, we introduce ${\mathcal K}$K-UIOs: UIOs that lead to at most ${\mathcal K}$K output sequences from states of $M$M. We show that checking ${\mathcal K}$K-UIO existence is PSPACE-Complete if the problem is suitably bounded; otherwise it is in EXPSPACE and PSPACE-Hard. We provide a massively parallel algorithm for constructing ${\mathcal K}$K-UIOs and the results of experiments on randomly generated and real FSM specifications. The proposed algorithm was able to construct UIOs in cases where the existing UIO generation algorithm could not and was able to construct UIOs from FSMs with 38K states and 400K transitions.",1939-3520,,10.1109/TSE.2019.2911076,AUS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691615,Software engineering/software/program verification;software engineering/testing and debugging;software engineering/test design;finite state machine;unique input output sequence generation;general purpose graphics processing units,Testing;Object oriented modeling;Software algorithms;Software;Integrated circuit modeling;Scalability;Parallel algorithms,,,,,,47.0,IEEE,14 Apr 2019,,,IEEE,IEEE Journals
1479,118,Reactive Auto-completion of Modeling Activities,P. Mäder; T. Kuschke; M. Janke,"Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: patrick.maeder@tu-ilmenau.de); Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: tobias.kuschke@tu-ilmenau.de); Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: mario.janke@tu-ilmenau.de)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Assisting and automating software engineering tasks is a state-of-the-art way to support stakeholders of development projects. A common assistance function of IDEs is the auto-completion of source code. Assistance functions, such as auto-completion, are almost entirely missing in modeling tools though auto-completion in general gains continuously more importance in software development. We analyze a user's performed editing operations in order to anticipate modeling activities and to recommend appropriate auto-completions for them. Editing operations are captured as events and modeling activities are defined as complex event patterns, facilitating the matching by complex-event-processing. The approach provides adapted auto-completions reactively upon each editing operation of the user. We implemented the RapMOD prototype as add-in for the modeling tool Sparx Enterprise ArchitectTM . A controlled user experiment with 37 participants performing modeling tasks demonstrated the approach's potential to reduce modeling effort significantly. Users having auto-completions available for a modeling scenario performed the task 27% faster, needed to perform 56% less actions, and perceived the task 29% less difficult.",1939-3520,,10.1109/TSE.2019.2924886,Thuringer Aufbaubank; Bundesministerium fur Bildung und Forschung; Deutsche Forschungsgemeinschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745532,Auto-completion;modeling activity;complex-event-processing;CEP;activity recognition;pattern matching;recommender,Unified modeling language;Tools;Task analysis;Computational modeling;Adaptation models;Analytical models;Engines,,,,,,,,25 Jun 2019,,,IEEE,IEEE Early Access Articles
1480,119,An Empirical Study on Heterogeneous Defect Prediction Approaches,H. Chen; X. Jing; Z. Li; D. Wu; Y. Peng; Z. Huang,"School of Computer, Wuhan University, Wuhan City, Hubei Province China (e-mail: hwc_zzu@126.com); State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan City, Hubei Province China 430072 (e-mail: jingxy_2000@126.com); State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, Hubei China (e-mail: lzq115@163.com); State Key Laboratory of Software Engineering, School of Computer, Wuhan University, 12390 Wuhan, Hubei China (e-mail: htuwudi@sina.com); School of Computer, Wuhan University, Wuhan City, Hubei Province China (e-mail: hbyspy2008@qq.com); School of Computer, Wuhan University, 12390 Wuhan, Hubei China (e-mail: huang_906@126.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software defect prediction has always been a hot research topic in the field of software engineering owing to its capability of allocating limited resources reasonably. Compared with cross-project defect prediction (CPDP), heterogeneous defect prediction (HDP) further relaxes the limitation of defect data used for prediction, permitting different metric sets to be contained in the source and target projects. However, there is still a lack of a holistic understanding of existing HDP studies due to different evaluation strategies and experimental settings. In this paper, we provide an empirical study on HDP approaches. We review the research status systematically and compare the HDP approaches proposed from 2014 to June 2018. Furthermore, we also investigate the feasibility of HDP approaches in CPDP. Through extensive experiments on 30 projects from five datasets, we have the following findings: (1) metric transformation-based HDP approaches usually result in better prediction effects, while metric selection-based approaches have better interpretability. Overall, the HDP approach proposed by Li et al. (CTKCCA) currently has the best performance. (2) Handling class imbalance problems can boost the prediction effects, but the improvements are usually limited. In addition, utilizing mixed project data cannot improve the performance of HDP approaches consistently since the label information in the target project is not used effectively. (3) HDP approaches are feasible for cross-project defect prediction in which the source and target projects have the same metric set.",1939-3520,,10.1109/TSE.2020.2968520,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964460,Heterogeneous defect prediction;cross-project;empirical study;metric selection;metric transformation,Measurement;NASA;Predictive models;Data models;Software;Libraries;Buildings,,,,1.0,,,,22 Jan 2020,,,IEEE,IEEE Early Access Articles
1481,120,Utilizing Automatic Query Reformulations as Genetic Operations to Improve Feature Location in Software Models,F. Pérez; T. Ziadi; C. Cetina,"SVIT Research Group, Universidad San Jorge, Zaragoza, Zaragoza Spain (e-mail: mfperez@usj.es); LIP6, Sorbonne Université, 27063 Paris, Île-de-France France (e-mail: tewfik.ziadi@lip6.fr); SVIT Research Group, Universidad San Jorge, Zaragoza, Zaragoza Spain (e-mail: ccetina@usj.es)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"In the combination of Model-Driven Engineering (MDE) and Search-Based Software Engineering (SBSE), genetic operations are one of the key ingredients. Our work proposes a novel adaptation of automatic query reformulations as genetic operations that leverage the latent semantics of software models (the cornerstone artefact of MDE). We analyze the impact of these reformulation operations in a real-world industrial case study of feature location in models. As baselines, we use: 1) the widespread single-point crossover plus random mutation; and 2) mask crossover plus random mutation, which is the best performer for feature location in models. We also perform a statistical analysis to provide quantitative evidence of the impact of the results and to show that this impact is significant. Our reformulation operations improve the results of the best baseline by 37.73% in recall and 14.08% in precision. These results are relevant for the task of feature location in models (one of the main activities performed during software maintenance and evolution). Furthermore, given that the only requirement to apply our approach is term availability in models, our work opens a new research direction to improve more tasks in MDE such as bug location or requirements traceability.",1939-3520,,10.1109/TSE.2020.3000520,Ministerio de Economa y Competitividad; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110751,Model-Driven Engineering;Search-Based Software Engineering;Automatic Query Reformulations,Genetics;Adaptation models;Task analysis;Software;Semantics;Evolutionary computation;Analytical models,,,,,,,,8 Jun 2020,,,IEEE,IEEE Early Access Articles
1482,121,Software Development Analytics for Xen: Why and How,D. Izquierdo; J. M. Gonzalez-Barahona; L. Kurth; G. Robles,Bitergia; Universidad Rey Juan Carlos; Citrix; Universidad Rey Juan Carlos,IEEE Software,16 Apr 2019,2019,36,3,28,32,"Xen is one of the most popular virtualization technologies. Several IT companies collect and publish metrics, helping the ecosystem to be more self-aware of their development processes. Thus, ecosystem participants make informed decisions, monitor their effects, and improve their coordination.",1937-4194,,10.1109/MS.2018.290101357,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409914,Software;Software Engineering;Software maintenance;Software management;Management of Computing and Information Systems;computing Mil;Software Engineering;metrics;measurement;process metrics,Software development management;Ecosystems;Virtualization;Software measurement;Object recognition;Ecosystems,software engineering;virtual machines;virtualisation,software development analytics;xen;virtualization technologies;IT companies,,,,6.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1483,122,Interacto: A Modern User Interaction Processing Model,A. Blouin; J. -M. Jezequel,"DiverSE, IRISA/Inria, Rennes, ile et vilaine, France, (e-mail: Arnaud.Blouin@irisa.fr); DiverSE, IRISA-University of Rennes, Rennes, France, France, (e-mail: jezequel@irisa.fr)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Since most software systems provide their users with interactive features, building user interfaces (UI) is one of the core software engineering tasks. It consists in designing, implementing and testing ever more sophisticated and versatile ways for users to interact with software systems, and safely connecting these interactions with commands querying or modifying their state. However, most UI frameworks still rely on a low level model, the bare bone UI event processing model. This model was suitable for the rather simple UIs of the early 80s (menus, buttons, keyboards, mouse clicks), but now exhibits major software engineering flaws for modern, highly interactive UIs. These flaws include lack of separation of concerns, weak modularity and thus low reusability of code for advanced interactions, as well as low testability. To mitigate these flaws, we propose Interacto as a high level user interaction processing model. By reifying the concept of user interaction, Interacto makes it easy to design, implement and test modular and reusable advanced user interactions, and to connect them to commands with built-in undo/redo support. To demonstrate its applicability and generality, we briefly present two open source implementations of Interacto for Java/JavaFX and TypeScript/Angular. We evaluate Interacto interest (1) on a real world case study, where it has been used since 2013, and with (2) a controlled experiment with 44 master students, comparing it with traditionnal UI frameworks.",1939-3520,,10.1109/TSE.2021.3083321,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440800,user interface;user interaction;UI event processing;separation of concerns;undo/redo,Mice;Software systems;Object oriented modeling;Encoding;Standards;Software engineering;Process control,,,,,,,IEEE,25 May 2021,,,IEEE,IEEE Early Access Articles
1484,123,On the Introduction of Automatic Program Repair in Bloomberg,S. Kirbas; E. Windels; O. McBello; K. Kells; M. Pagano; R. Szalanski; V. Nowack; E. Winter; S. Counsell; D. Bowes; T. Hall; S. Haraldsson; J. Woodward,"Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Software Engineering, Bloomberg LP, New York, New York United States; Software Engineering, Bloomberg LP, New York, New York United States; Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Computer Science, Queen Mary University of London, London, London, United Kingdom of Great Britain and Northern Ireland; School of Computng and Communications, Lancaster University, Lancaster, Lancashire, United Kingdom of Great Britain and Northern Ireland; Computer Science, Brunel University, Greater London, UB8 3PH London, United Kingdom of Great Britain and Northern Ireland; School of Computing and Communication, Lancaster University School of Computing and Communications, Lancaster, Lancashire, United Kingdom of Great Britain and Northern Ireland; Computing & Communications, Lancaster University, Lancaster, LA1 4WA Lancashire, United Kingdom of Great Britain and Northern Ireland; Computer Science, University of Stirling, Stirling, Stirling, United Kingdom of Great Britain and Northern Ireland; Computer Science, Queen Mary University of London, London, London, United Kingdom of Great Britain and Northern Ireland",IEEE Software,,2021,PP,99,0,0,"A key to the success of Automatic Program Repair techniques is how easily they can be used in an industrial setting. In this article, we describe a collaboration by a team from four UK-based universities with Bloomberg (London) in implementing automatic, high-quality ﬁxes to its code base. We explain the motivation for adopting APR, the mechanics of the prototype tool that was built, and the practicalities of integrating APR into existing systems.",1937-4194,,10.1109/MS.2021.3071086,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395171,,Software;Tools;Computer bugs;Maintenance engineering;Industries;Computer architecture;Social networking (online),,,,,,,IEEE,5 Apr 2021,,,IEEE,IEEE Early Access Articles
1485,124,Continuously Managing NFRs: Opportunities and Challenges in Practice,C. Werner; Z. S. Li; D. Lowlind; O. Elazhary; N. A. Ernst; D. Damian,"Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: colinwerner@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: zanelib1@gmail.com); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: dereklowlind@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: omazhary@uvic.ca); Computer Science, University of Victoria, 8205 Victoria, British Columbia, Canada, (e-mail: nernst@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8W 3P6 (e-mail: damian.daniela@gmail.com)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Non-functional requirements (NFR), which include performance, availability, and maintainability, are vitally important to overall software quality. However, research has shown NFRs are, in practice, poorly defined and difficult to verify. Continuous software engineering practices, which extend agile practices, emphasize fast paced, automated, and rapid release of software that poses additional challenges to handling NFRs. In this multi-case study we empirically investigated how three organizations, for which NFRs are paramount to their business survival, manage NFRs in their continuous practices. We describe four practices these companies use to manage NFRs, such as offloading NFRs to cloud providers or the use of metrics and continuous monitoring, both of which enable almost real-time feedback on managing the NFRs. However, managing NFRs comes at a costas we also identified a number of challenges these organizations face while managing NFRs in their continuous software engineering practices. For example, the organizations in our study were able to realize an NFR by strategically and heavily investing in configuration management and infrastructure as code, in order to offload the responsibility of NFRs; however, this offloading implied potential loss of control. Our discussion and key research implications show the opportunities, trade-offs, and importance of the unique give-and-take relationship between continuous software engineering and NFRs.",1939-3520,,10.1109/TSE.2021.3066330,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380710,non-functional requirements;continuous software engineering,Organizations;Software;Software engineering;Testing;Tools;Requirements engineering;Interviews,,,,1.0,,,IEEE,17 Mar 2021,,,IEEE,IEEE Early Access Articles
1486,125,What Leads to a Confirmatory or Disconfirmatory Behaviour of Software Testers?,I. Salman; P. Rodriguez; B. Turhan; A. Tosun; A. Gureller,"M3S, Oulun Yliopisto Teknillinen Tiedekunta, 101225 Oulu, Northern Ostrobothnia Finland 90014 (e-mail: iflaah.salman@oulu.fi); Department of Languages, Computer Systems and Software Engineering, Universidad Politecnica de Madrid, 16771 Madrid, Comunidad de Madrid Spain (e-mail: pilar.rodriguez@upm.es); FIT, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: turhanb@computer.org); Faculty of Computer and Informatics Engineering, Istanbul Technical University, Istanbul, Istanbul Turkey (e-mail: tosunay@itu.edu.tr); Research NAP, Ericsson, Istanbul, Istanbul Turkey (e-mail: arda.gureller@ericsson.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Background: The existing literature in software engineering reports adverse effects of confirmation bias on software testing. Confirmation bias among software testers leads to confirmatory behaviour, which is designing or executing relatively more specification consistent test cases (confirmatory behaviour) than specification inconsistent test cases (disconfirmatory behaviour). Objective: We aim to explore the antecedents to confirmatory and disconfirmatory behaviour of software testers. Furthermore, we aim to understand why and how those antecedents lead to (dis)confirmatory behaviour. Method: We follow grounded theory method for the analyses of the data collected through semi-structured interviews with twelve software testers. Results: We identified twenty antecedents to (dis)confirmatory behaviour, and classified them in nine categories. Experience and Time are the two major categories. Experience is a disconfirmatory category, which also determines which behaviour (confirmatory or disconfirmatory) occurs first among software testers, as an effect of other antecedents. Time Pressure is a confirmatory antecedent of the Time category. It also contributes to the confirmatory effects of antecedents of other categories. Conclusion: The disconfirmatory antecedents, especially that belong to the testing process, e.g., test suite reviews by project team members, may help circumvent the deleterious effects of confirmation bias in software testing. If a team's resources permit, the designing and execution of a test suite could be divided among the test team members, as different perspectives of testers may help to detect more errors. The results of our study are based on a single context where dedicated testing teams focus on higher levels of testing. The study's scope does not account for the testing performed by developers. Future work includes exploring other contexts to extend our results.",1939-3520,,10.1109/TSE.2020.3019892,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9179007,Software Testing;Cognitive Biases;Confirmation Bias;Grounded Theory;Interviews,Software;Software testing;Interviews;Electronic mail;Companies;Decision making,,,,,,,,27 Aug 2020,,,IEEE,IEEE Early Access Articles
1487,126,Ubiquitous Requirements Engineering: A Paradigm Shift That Affects Everyone,K. Villela; E. C. Groen; J. Doerr,"Fraunhofer Institute for Experimental Software Engineering IESE; Fraunhofer Institute for Experimental Software Engineering IESE; Information Systems, Fraunhofer Institute for Experimental Software Engineering IESE",IEEE Software,21 Feb 2019,2019,36,2,8,12,"In recent years, we have witnessed profound changes in business and society. The use of digital technologies has brought about disruptive changes in every domain, changes that are widely known as the ""digital transformation."" Systems are growing increasingly interconnected and complex with cyberphysical systems even sensing and actuating in the physical world. Typical computer, tablet, and smartphone users include anyone from children to the elderly. A single software product can now easily reach audiences of millions with unprecedented opportunities to obtain feedback.",1937-4194,,10.1109/MS.2018.2883876,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648266,,Ecosystems;Software;Companies;Stakeholders;Requirements engineering;Software engineering,formal specification;language translation;smart phones,cyberphysical systems;physical world;typical computer;smartphone users;single software product;ubiquitous requirements engineering;paradigm shift;profound changes;digital technologies;disruptive changes;digital transformation,,,,7.0,,21 Feb 2019,,,IEEE,IEEE Magazines
1488,127,Finding Trends in Software Research,G. Mathew; A. Agrawal; T. Menzies,"Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: george.meg91@gmail.com); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: aagrawa8@ncsu.edu); Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, West Virginia United States 26501 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2018,PP,99,1,1,"This paper explores the structure of research papers in software engineering. Using text mining, we study 35,391 software engineering (SE) papers from 34 leading SE venues over the last 25 years. These venues were divided, nearly evenly, between conferences and journals. An important aspect of this analysis is that it is fully automated and repeatable. To achieve that automation, we used topic modeling (with LDA) to mine 10 topics that represent much of the structure of contemporary SE. The 10 topics presented here should not be ""set in stone"" as the only topics worthy of study in SE. Rather our goal is to report that (a) text mining methods can detect large scale trends within our community; (b) those topic change with time; so (c) it is important to have automatic agents that can update our understanding of our community whenever new data arrives.",1939-3520,,10.1109/TSE.2018.2870388,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465996,Software Engineering;Bibliometrics;Topic Modeling;Text Mining,Software engineering;Conferences;Software;Analytical models;Data models;Predictive models;Testing,,,,,,,,14 Sep 2018,,,IEEE,IEEE Early Access Articles
1489,128,Behavioral Science and Diversity in Software Engineering,J. C. Carver; H. Muccini; B. Penzenstadler; R. Prikladnicki; A. Serebrenik; T. Zimmermann,"Computer Science, University of Alabama, Tuscaloosa, Alabama 35487 United States; Information Engineering, University of L’Aquila, L’Aquila, 67100, Italy; Chalmers University of Technology, Gothenburg, 412 96, Sweden; Technology and Innovation, University of Rio Grande do Sul, Porto Alegre, RS 90619-900, Brazil; Eindhoven University of Technology, Eindhoven, 5600MB, The Netherlands; Microsoft, Redmond, Washington 98052 United States",IEEE Software,15 Feb 2021,2021,38,2,107,112,"The “Practioners' Digest” department in this issue of IEEE Software covers two topics: the behavioral science of software engineering and diversity in software engineering (this issue’s theme) and includes papers from the 42nd International Conference on Software Engineering (ICSE20), 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME19), 13th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE20), Empirical Software Engineering and Measurement 2020 (ESEM20), and Association for Computing Machinery Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE20). Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in this article, please send me and the authors of the paper(s) a note about your experiences.",1937-4194,,10.1109/MS.2020.3042683,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354400,,Software engineering;Meetings,,,,,,9.0,IEEE,15 Feb 2021,,,IEEE,IEEE Magazines
1490,129,A Machine Learning Approach to Improve the Detection of CI Skip Commits,R. Abdalkareem; S. Mujahid; E. Shihab,"Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 1M8 (e-mail: rab_abdu@encs.concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: suhaibmujahid@gmail.com); Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: eshihab@encs.concordia.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Continuous integration (CI) frameworks, such as Travis CI, are growing in popularity, encouraged by market trends towards speeding up the release cycle and building higher-quality software. A key facilitator of CI is to automatically build and run tests whenever a new commit is submitted/pushed. Despite the many advantages of using CI, it is known that the CI process can take a very long time to complete. One of the core causes for such delays is the fact that some commits (e.g., cosmetic changes) unnecessarily kick off the CI process. Therefore, the main goal of this paper is to automate the process of determining which commits can be CI skipped through the use of machine learning techniques. We first extracted 23 features from historical data of ten software repositories. Second, we conduct a study on the detection of CI skip commits using machine learning, where we built a decision tree classifier. We then examine the accuracy of using the decision tree in detecting CI skip commits. Our results show that the decision tree can identify CI skip commits with an average AUC equal to 0.89. Furthermore, the top node analysis shows that the number of developers who changed the modified files, the CI-Skip rules, and commit message are the most important features to detect CI skip commits. Finally, we investigate the generalizability of identifying CI skip commits through applying cross-project validation, and our results show that the general classifier achieves an average 0.74 of AUC values.",1939-3520,,10.1109/TSE.2020.2967380,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961089,Continuous Integration;Travis CI;Build Status;Machine Learning,Machine learning;Decision trees;Feature extraction;Software;Message systems;Documentation;Buildings,,,,3.0,,,,16 Jan 2020,,,IEEE,IEEE Early Access Articles
1491,130,CrySL: An Extensible Approach to Validating the Correct Usage of Cryptographic APIs,S. Krüger; J. Späth; K. Ali; E. Bodden; M. Mezini,"Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, North Rhine-Westphalia Germany (e-mail: stefan.krueger@uni-paderborn.de); Software Engineering and Security, Fraunhofer IEM, Paderborn, North Rhine-Westphalia Germany (e-mail: johannes.spaeth@iem.fraunhofer.de); Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada T6G 2R3 (e-mail: karim.ali@ualberta.ca); Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, NRW Germany (e-mail: eric.bodden@uni-paderborn.de); Computer Science, Darmstadt University of Technology, Darmstadt, Hessen Germany 64289 (e-mail: mezini@informatik.tu-darmstadt.de)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Various studies have empirically shown that the majority of Java and Android applications misuse cryptographic libraries, causing devastating breaches of data security. It is crucial to detect such misuses early in the development process. To detect cryptography misuses, one must define secure uses first, a process mastered primarily by cryptography experts but not by developers. In this paper, we present CrySL, a specification language for bridging the cognitive gap between cryptography experts and developers. CrySL enables cryptography experts to specify the secure usage of the cryptographic libraries they provide. We have implemented a compiler that translates such CrySL specification into a context-sensitive and flow-sensitive demand-driven static analysis. The analysis then helps developers by automatically checking a given Java or Android app for compliance with the CrySL-encoded rules. We have designed an extensive CrySL rule set for the Java Cryptography Architecture (JCA), and empirically evaluated it by analyzing 10,000 current Android apps and all 204,788 current Java software artefacts on Maven Central. Our results show that misuse of cryptographic APIs is still widespread, with 95% of apps and 63% of Maven artefacts containing at least one misuse. Our easily extensible CrySL rule set covers more violations than previous special-purpose tools that contain hard-coded rules, while still offering a more precise analysis.",1939-3520,,10.1109/TSE.2019.2948910,Oracle; Heinz-Nixdorf Foundation; Fraunhofer-Gesellschaft; Deutsche Forschungsgemeinschaft; Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880510,cryptography;domain-specific language;static analysis,Java;Encryption;Static analysis;Tools;Ciphers;Semantics,,,,1.0,,,,23 Oct 2019,,,IEEE,IEEE Early Access Articles
1492,131,Taking the Middle Path: Learning About Security Through Online Social Interaction,T. Lopez; T. T. Tun; A. K. Bandara; M. Levine; B. Nuseibeh; H. Sharp,"The Open University, Milton Keynes, United Kingdom; The Open University, Milton Keynes, United Kingdom; Software Engineering, The Open University, Milton Keynes, United Kingdom; Psychology, Lancaster University, Lancashire, United Kingdom; Computing, The Open University, Milton Keynes, United Kingdom; Software Engineering, The Open University, Milton Keynes, United Kingdom",IEEE Software,20 Dec 2019,2020,37,1,25,30,"Integrating security into software development involves more than learning principles or applying techniques. Security can be integrated into software development practice by following a middle path, through which developers draw together knowledge received through training and software development techniques.",1937-4194,,10.1109/MS.2019.2945300,National Cyber Security Centre; Engineering and Physical Sciences Research Council; Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854988,Social learning techniques;support for security;software construction,Security;Software development management;Task analysis;Encoding;Best practices;Programming;Social networking (online),computer aided instruction;computer science education;security of data;social networking (online);software engineering,online social interaction;learning principles;software development;training;cybersecurity,,,,16.0,,2 Oct 2019,,,IEEE,IEEE Magazines
1493,132,Is 40 the New 60? How Popular Media Portrays the Employability of Older Software Developers,S. Baltes; G. Park; A. Serebrenik,"QAware Gmb, Germany; Software Engineering, Itility B.V.; Software Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands",IEEE Software,23 Oct 2020,2020,37,6,26,31,"We studied the public discourse around age and software development, focusing on the United States. This work was designed to build awareness among decision makers in software projects to help them anticipate and mitigate challenges that their older employees may face.",1937-4194,,10.1109/MS.2020.3014178,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157881,,Software;Media;Computer hacking;Industries;Face;Engineering profession;Companies,decision making;organisational aspects;personnel;project management;software engineering,popular media portrays;employability;older software developers;software development;United States;software projects;older employees;decision making,,,,19.0,,4 Aug 2020,,,IEEE,IEEE Magazines
1494,133,On the Relationship Between the Developer's Perceptible Race and Ethnicity and the Evaluation of Contributions in OSS,R. Nadri; G. Rodriguezperez; M. Nagappan,"Computer Science, University of Waterloo Faculty of Mathematics, 153521 Waterloo, Ontario, Canada, (e-mail: rnadri@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: gema.rodriguez-perez@uwaterloo.ca); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: mei.nagappan@uwaterloo.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Context: Open Source Software (OSS) projects are typically the result of collective efforts performed by developers with different backgrounds. Although the quality of developers contributions should be the only factor influencing the evaluation of the contributions to OSS projects, recent studies have shown that diversity issues are correlated with the acceptance or rejection of developers contributions. Objective: This paper assists this emerging state-of-the-art body on diversity research with the first empirical study that analyzes how developers perceptible race and ethnicity relates to the evaluation of the contributions in OSS. We also want to create awareness of the racial and ethnic diversity in OSS projects. Methodology: We performed a large-scale quantitative study of OSS projects in GitHub. We extracted the developers perceptible race and ethnicity from their names in GitHub using the Name-Prism tool and applied regression modeling of contributions (i.e, pull requests) data from GHTorrent and GitHub. Results: We observed that (1) among the developers whose perceptible race and ethnicity was captured by the tool, only 16.56% were perceptible as Non-White developers; (2) contributions from perceptible White developers have about 6-10% higher odds of being accepted when compared to contributions from perceptible Non-White developers; and (3) submitters with perceptible non-white races and ethnicities are more likely to get their pull requests accepted when the integrator is estimated to be from their same race and ethnicity rather than when the integrator is estimated to be White. Conclusion: Our initial analysis shows a low number of Non-White developers participating in OSS. Furthermore, the results from our regression analysis lead us to believe that there may exist differences between the evaluation of the contributions from different perceptible races and ethnicities. Thus, our findings reinforce the need for further studies on racial and ethnic diversity in software engineering to foster healthier OSS communities.",1939-3520,,10.1109/TSE.2021.3073773,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406372,,Software development management;Cultural differences;Tools;Software engineering;Open source software;Psychology;Gender issues,,,,,,,IEEE,16 Apr 2021,,,IEEE,IEEE Early Access Articles
1495,134,Learning From Mistakes: Machine Learning Enhanced Human Expert Effort Estimates,F. Sarro; R. Moussa; A. Petrozziello; M. Harman,"Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: rebecca.moussa.18@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: a.petrozziello@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"In this paper, we introduce a novel approach to predictive modeling for software engineering, named Learning From Mistakes (LFM). The core idea underlying our proposal is to automatically learn from past estimation errors made by human experts, in order to predict the characteristics of their future misestimates, therefore resulting in improved future estimates. We show the feasibility of LFM by investigating whether it is possible to predict the type, severity and magnitude of errors made by human experts when estimating the development effort of software projects, and whether it is possible to use these predictions to enhance future estimations. To this end we conduct a thorough empirical study investigating 402 maintenance and new development industrial software projects. The results of our study reveal that the type, severity and magnitude of errors are all, indeed, predictable. Moreover, we find that by exploiting these predictions, we can obtain significantly better estimates than those provided by random guessing, human experts and traditional machine learners in 31 out of the 36 cases considered (86%), with large and very large effect sizes in the majority of these cases (81%). This empirical evidence opens the door to the development of techniques that use the power of machine learning, coupled with the observation that human errors are predictable, to support engineers in estimation tasks rather than replacing them with machine-provided estimates.",1939-3520,,10.1109/TSE.2020.3040793,European Research Council Advanced Fellowship Grant; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272884,Software Effort Estimation;Estimate errors;Human expert estimates;Human Bias;Human-competitive results,Software;Predictive models;Companies;Software engineering;Estimation error;Task analysis;Software measurement,,,,,,,IEEE,27 Nov 2020,,,IEEE,IEEE Early Access Articles
1496,135,The Effects of Human Aspects on the Requirements Engineering Process: A Systematic Literature Review,D. Hidellaarachchi; J. Grundy; R. Hoda; K. Madampe,"Software Systems and Cybersecurity, Monash University, 2541 Clayton, Victoria, Australia, 3800 (e-mail: dulajidinupama@gmail.com); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, 3800 (e-mail: rashina@gmail.com); Software Systems and Cybersecurity, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: kashumi.madampe@monash.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Requirements Engineering (RE) requires the collaboration of various roles in SE, such as requirements engineers, stakeholders and other developers, and it is thus a very highly human dependent process in software engineering (SE). Identifying how ""human aspects"" such as personality, motivation, emotions, communication, gender, culture and geographic distribution might impact on the RE process would assist us in better supporting successful RE. The main objective of this paper is to systematically review primary studies that have investigated the effects of various human aspects on the RE process. We wanted to identify if any critical human aspects have been found, and what might be the relationships between different human aspects impacting the RE process. A systematic literature review (SLR) was conducted and identified 474 initial primary research studies. These were eventually filtered down to 73 relevant, high-quality primary studies. No primary study to date was found to focus on identifying what are the most influential human aspects on the RE process. Among the studied human aspects, the effects of communication have been considered in many studies of RE. Other human aspects such as personality, motivation and gender have mainly been investigated to date in relation to more general SE studies that include RE as one phase. Findings show that studying more than one human aspect together is beneficial, as this reveals relationships between various human aspects and how they together impact the RE process. However, the majority of these studied combinations of human aspects are unique. From 56.2% of studies that identified the effects of human aspects on RE, 39% identified the positive impact, 32% negative, 27% identified both impacts whereas 2% mentioned that there was no impact. This implies that a variety of human aspects positively or negatively affects the RE process and a well-defined theoretical analysis on the effects of different human aspects on RE remains to be defined and practically evaluated. The findings of this SLR help researchers who are investigating the impact of various human aspects on the RE process by identifying well-studied research areas, and highlight new areas that should be focused on in future research.",1939-3520,,10.1109/TSE.2021.3051898,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325916,Systematic Literature Review;human aspects;human-centric issues;requirements engineering,Software;Systematics;Software engineering;Bibliographies;Stakeholders;Meteorology;Taxonomy,,,,,,,IEEE,15 Jan 2021,,,IEEE,IEEE Early Access Articles
1497,136,Need for Sleep: The Impact of a Night of Sleep Deprivation on Novice Developers’ Performance,D. Fucci; G. Scanniello; S. Romano; N. Juristo,"HITeC, University of Hamburg, Hamburg, Germany; DiMIE, University of Basilicata, Potenza, Italy; DiMIE, University of Basilicata, Potenza, Italy; Technical University of Madrid, Madrid, Spain",IEEE Transactions on Software Engineering,8 Jan 2020,2020,46,1,1,19,"We present a quasi-experiment to investigate whether, and to what extent, sleep deprivation impacts the performance of novice software developers using the agile practice of test-first development (TFD). We recruited 45 undergraduates, and asked them to tackle a programming task. Among the participants, 23 agreed to stay awake the night before carrying out the task, while 22 slept normally. We analyzed the quality (i.e., the functional correctness) of the implementations delivered by the participants in both groups, their engagement in writing source code (i.e., the amount of activities performed in the IDE while tackling the programming task) and ability to apply TFD (i.e., the extent to which a participant is able to apply this practice). By comparing the two groups of participants, we found that a single night of sleep deprivation leads to a reduction of 50 percent in the quality of the implementations. There is notable evidence that the developers' engagement and their prowess to apply TFD are negatively impacted. Our results also show that sleep-deprived developers make more fixes to syntactic mistakes in the source code. We conclude that sleep deprivation has possibly disruptive effects on software development activities. The results open opportunities for improving developers' performance by integrating the study of sleep with other psycho-physiological factors in which the software engineering research community has recently taken an interest in.",1939-3520,,10.1109/TSE.2018.2834900,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357494,Sleep deprivation;psycho-physiological factors;test-first development,Sleep;Software;Task analysis;Biomedical monitoring;Software engineering;Programming;Functional magnetic resonance imaging,computer aided instruction;computer science education;sleep;software engineering,source code;sleep deprivation;software development activities;novice software developers;TFD;programming task;sleep-deprived developers,,2.0,,103.0,IEEE,10 May 2018,,,IEEE,IEEE Journals
1498,137,Experimental evaluation of test-driven development with interns working on a real industrial project,B. K. Papis; K. Grochowski; K. Subzda; K. Sijko,"SWE, Google Inc, 93176 Warsaw, Mazowieckie, Poland, 00-113 (e-mail: bartoszkp@gmail.com); The Institute of Computer Science, Politechnika Warszawska, 49566 Warszawa, mazowieckie, Poland, (e-mail: Konrad.Grochowski@pw.edu.pl); Katedra Metrologii Elektronicznej i Fotonicznej, Politechnika Wroclawska Wydzial Elektroniki, 325847 Wroclaw, dolnolskie, Poland, (e-mail: kamil.subzda@gmail.com); R&D, Transition Technologies, Warsaw, mazowieckie, Poland, (e-mail: kamil@sijko.pl)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Context: There is still little evidence on differences between Test-Driven Development and Test-Last Development, especially for real-world projects, so their impact on code/test quality is an ongoing research trend. An empirical comparison is presented, with 19 participants working on an industrial project developed for an energy market software company, implementing real-world requirements for one of the company's customers. Objective: Examine the impact of TDD and TLD on quality of the code and the tests. The aim is to evaluate if there is a significant difference in external code quality and test quality between these techniques. Method: The experiment is based on a randomized within-subjects block design, with participants working for three months on the same requirements using different techniques, changed from week to week, within three different competence blocks: Intermediate, Novice and Mixed. The resulting code was verified for process conformance. The participants developed only business logic and were separated from infrastructural concerns. A separate group of code repositories was used to work without unit tests, to verify that the requirements were not too easy for the participants. Also, it was analysed if there is any difference between the code created by shared efforts of developers with different competences and the code created by participants isolated in the competence blocks. The resulting implementations had LOC order of magnitude of 10k. Results: Statistically significant advantage of TDD in terms of external code quality (1.8 fewer bugs) and test quality (5 percentage points higher) than TLD. Additionally, TDD narrows the gap in code coverage between developers from different competence blocks. At the same time, TDD proved to have a considerable entry barrier and was hard to follow strictly, especially by Novices. Still, no significant difference w.r.t. code coverage has been observed between the Intermediate and the Novice developers - as opposed to TLD, which was easier to follow. Lastly, isolating the Intermediate developers from the Novices had significant impact on the code quality. Conclusion:TDD is a recommended technique for software projects with a long horizon or when it is critical to minimize the number of bugs and achieve high code coverage.",1939-3520,,10.1109/TSE.2020.3027522,Transition Technologies S.A.; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207972,Empirical software engineering;Iterative test last development;Test driven development,Software;Companies;Testing;Writing;Programming;Market research,,,,,,,CCBY,28 Sep 2020,,,IEEE,IEEE Early Access Articles
1499,138,Measuring the Impact of Code Dependencies on Software Architecture Recovery Techniques,T. Lutellier; D. Chollak; J. Garcia; L. Tan; D. Rayside; N. Medvidović; R. Kroeger,"University of Waterloo, Waterloo, ON, Canada; University of Waterloo, Waterloo, ON, Canada; University of California, Irvine, CA; University of Waterloo, Waterloo, ON, Canada; University of Waterloo, Waterloo, ON, Canada; University of Southern California, Los Angeles, CA; Google Inc., Mountain View, CA",IEEE Transactions on Software Engineering,12 Feb 2018,2018,44,2,159,181,"Many techniques have been proposed to automatically recover software architectures from software implementations. A thorough comparison among the recovery techniques is needed to understand their effectiveness and applicability. This study improves on previous studies in two ways. First, we study the impact of leveraging accurate symbol dependencies on the accuracy of architecture recovery techniques. In addition, we evaluate other factors of the input dependencies such as the level of granularity and the dynamic-bindings graph construction. Second, we recovered the architecture of a large system, Chromium, that was not available previously. Obtaining the ground-truth architecture of Chromium involved two years of collaboration with its developers. As part of this work, we developed a new submodule-based technique to recover preliminary versions of ground-truth architectures. The results of our evaluation of nine architecture recovery techniques and their variants suggest that (1) using accurate symbol dependencies has a major influence on recovery quality, and (2) more accurate recovery techniques are needed. Our results show that some of the studied architecture recovery techniques scale to very large systems, whereas others do not.",1939-3520,,10.1109/TSE.2017.2671865,"Natural Sciences and Engineering Research Council of Canada; Google Faculty Research Award; Ontario Ministry of Research and Innovation; U.S. National Science Foundation; Infosys Technologies, Ltd.; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7859416,Software architecture;empirical software engineering;maintenance and evolution;program comprehension,Computer architecture;Software architecture;Software;Heuristic algorithms;Chromium;Software algorithms;Manuals,software architecture;software quality;system recovery,symbol dependencies;accurate recovery techniques;recovery quality;submodule-based technique;ground-truth architecture;input dependencies;software implementations;software architectures;software architecture recovery techniques;code dependencies,,11.0,,72.0,,20 Feb 2017,,,IEEE,IEEE Journals
1500,139,Enabling Decision and Objective Space Exploration for Interactive Multi-Objective Refactoring,S. Rebai; V. Alizadeh; M. Kessentini; H. Fehri; R. Kazman,"Computer and Information Science, Regents of the University of Michigan, 507697 Dearborn, Michigan United States (e-mail: srebal@umich.edu); CIS Department, University of Michigan, Dearborn, Michigan United States (e-mail: alizadeh@umich.edu); CIS, University of Michigan Dearborn, 14711 Dearborn, Michigan United States (e-mail: marouane@umich.edu); CIS, University of Michigan Dearborn, 14711 Dearborn, Michigan United States (e-mail: houcemf@umich.edu); Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii United States 96822 (e-mail: kazman@hawaii.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Due to the conflicting nature of quality measures, there are always multiple refactoring options to fix quality issues. Thus, interaction with developers is critical to inject their preferences. While several interactive techniques have been proposed, developers still need to examine large numbers of possible refactorings, which makes the interaction time-consuming. Furthermore, existing interactive tools are limited to the ""objective space"" to show developers the impacts of refactorings on quality attributes. However, the ""decision space"" is also important since developers may want to focus on specific code locations. In this paper, we propose an interactive approach that enables developers to pinpoint their preference simultaneously in the objective (quality metrics) and decision (code location) spaces. Developers may be interested in looking at refactoring strategies that can improve a specific quality attribute, such as extendibility (objective space), but they are related to different code locations (decision space). A plethora of solutions is generated at first using multi-objective search that tries to find the possible trade-offs between quality objectives. Then, an unsupervised learning algorithm clusters the trade-off solutions based on their quality metrics, and another clustering algorithm is applied to each cluster of the objective space to identify solutions related to different code locations. The objective and decision spaces can now be explored more efficiently by the developer, who can give feedback on a smaller number of solutions. This feedback is then used to generate constraints for the optimization process, to focus on the developer's regions of interest in both the decision and objective spaces. The manual validation of selected refactoring solutions by developers confirms that our approach outperforms state of the art refactoring techniques.",1939-3520,,10.1109/TSE.2020.3024814,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200705,Search based software engineering;refactoring;multi-objective search;clustering,Tools;Clustering algorithms;Measurement;Search problems;Manuals;Software;Space exploration,,,,,,,,18 Sep 2020,,,IEEE,IEEE Early Access Articles
1501,140,Approximate Oracles and Synergy in Software Energy Search Spaces,B. R. Bruce; J. Petke; M. Harman; E. T. Barr,"University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom",IEEE Transactions on Software Engineering,12 Nov 2019,2019,45,11,1150,1169,"Reducing the energy consumption of software systems through optimisation techniques such as genetic improvement is gaining interest. However, efficient and effective improvement of software systems requires a better understanding of the code-change search space. One important choice practitioners have is whether to preserve the system's original output or permit approximation, with each scenario having its own search space characteristics. When output preservation is a hard constraint, we report that the maximum energy reduction achievable by the modification operators is 2.69 percent (0.76 percent on average). By contrast, this figure increases dramatically to 95.60 percent (33.90 percent on average) when approximation is permitted, indicating the critical importance of approximate output quality assessment for code optimisation. We investigate synergy, a phenomenon that occurs when simultaneously applied source code modifications produce an effect greater than their individual sum. Our results reveal that 12.0 percent of all joint code modifications produced such a synergistic effect, though 38.5 percent produce an antagonistic interaction in which simultaneously applied modifications are less effective than when applied individually. This highlights the need for more advanced search-based techniques.",1939-3520,,10.1109/TSE.2018.2827066,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338061,Search-based software engineering;search space;energy consumption;genetic improvement;synergy;antagonism;oracle;approximation,Energy consumption;Energy measurement;Software systems;Optimization;Aggregates;Genetics,optimisation;power aware computing;search problems;software engineering,optimisation techniques;genetic improvement;software systems;code-change search space;search space characteristics;output preservation;hard constraint;maximum energy reduction;modification operators;approximate output quality assessment;code optimisation;source code modifications;joint code modifications;synergistic effect;advanced search-based techniques;approximate oracles;software energy search spaces;energy consumption,,4.0,,63.0,,16 Apr 2018,,,IEEE,IEEE Journals
1502,141,How Developers Diagnose Potential Security Vulnerabilities with a Static Analysis Tool,J. Smith; B. Johnson; E. Murphy-Hill; B. Chu; H. R. Lipford,"North Carolina State University, Raleigh, NC; University of Massachusetts Amherst, Amherst, MA; North Carolina State University, Raleigh, NC; University of North Carolina at Charlotte, Charlotte, NC; University of North Carolina at Charlotte, Charlotte, NC",IEEE Transactions on Software Engineering,18 Sep 2019,2019,45,9,877,897,"While using security tools to resolve security defects, software developers must apply considerable effort. Success depends on a developer's ability to interact with tools, ask the right questions, and make strategic decisions. To build better security tools and subsequently help developers resolve defects more accurately and efficiently, we studied the defect resolution process-from the questions developers ask to their strategies for answering them. In this paper, we report on an exploratory study with novice and experienced software developers. We equipped them with Find Security Bugs, a security-oriented static analysis tool, and observed their interactions with security vulnerabilities in an open-source system that they had previously contributed to. We found that they asked questions not only about security vulnerabilities, associated attacks, and fixes, but also questions about the software itself, the social ecosystem that built the software, and related resources and tools. We describe the strategic successes and failures we observed and how future tools can leverage our findings to encourage better strategies.",1939-3520,,10.1109/TSE.2018.2810116,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8303758,Software engineering;human factors;security;software tools;programming environments,Tools;Task analysis;Software;Static analysis;Computer bugs;SQL injection,program debugging;program diagnostics;security of data;software engineering;software maintenance,security tools;questions developers;experienced software developers;Security Bugs;security-oriented static analysis tool;security defects;potential Security vulnerabilities;defect resolution process;open-source system;social ecosystem,,4.0,,65.0,,27 Feb 2018,,,IEEE,IEEE Journals
1503,142,"Managing Programmers, with Ron Lichty",N. Black,Sleeperbot,IEEE Software,25 Dec 2017,2018,35,1,117,120,"Veteran software manager Ron Lichty joins Nate Black to share his insights on managing software engineers. Nate and Ron delve into what about this is hard, how to grow as a manager, and what makes highly performing teams.",1937-4194,,10.1109/MS.2017.4541030,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239929,programming managers;software teams;software development;Ron Lichty;Nate Black;software engineering;Software Engineering Radio,Collaboration;Software engineering;Engineering profession;Programming profession;Databases;Training,,,,,,,,25 Dec 2017,,,IEEE,IEEE Magazines
1504,143,Using K-core Decomposition on Class Dependency Networks to Improve Bug Prediction Model's Practical Performance,Y. Qu; Q. Zheng; J. Chi; Y. Jin; A. He; D. Cui; H. Zhang; T. Liu,"Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; School of Computer Science, Xi'an University of Posts and Telecommunications, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,348,366,"In recent years, Complex Network theory and graph algorithms have been proved to be effective in predicting software bugs. On the other hand, as a widely-used algorithm in Complex Network theory, k-core decomposition has been used in software engineering domain to identify key classes. Intuitively, key classes are more likely to be buggy since they participate in more functions or have more interactions and dependencies. However, there is no existing research uses k-core decomposition to analyze software bugs. To fill this gap, we first use k-core decomposition on Class Dependency Networks to analyze software bug distribution from a new perspective. An interesting and widely existed tendency is observed: for classes in k-cores with larger k values, there is a stronger possibility for them to be buggy. Based on this observation, we then propose a simple but effective equation named as top-core which improves the order of classes in the suspicious class list produced by effort-aware bug prediction models. Based on an empirical study on 18 open-source Java systems, we show that the bug prediction models' performances are significantly improved in 85.2 percent experiments in the cross-validation scenario and in 80.95 percent experiments in the forward-release scenario, after using top-core. The models' average performances are improved by 11.5 and 12.6 percent, respectively. It is concluded that the proposed top-core equation can help the testers or code reviewers locate the real bugs more quickly and easily in software bug prediction practices.",1939-3520,,10.1109/TSE.2019.2892959,National Key Research and Development Program of China; National Natural Science Foundation of China; Ministry of Education Innovation Research Team; Shaanxi Province postdoctoral research project funding; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611396,Bug prediction;software defects;complex network;class dependency network;effort-aware bug prediction,Computer bugs;Software;Mathematical model;Predictive models;Complex networks;Prediction algorithms;Software algorithms,complex networks;graph theory;Java;network theory (graphs);program debugging;public domain software;software engineering;software maintenance,class dependency networks;complex network theory;software bug distribution;software engineering domain;software bugs;bug prediction model;k-core decomposition;software bug prediction practices;top-core equation;effort-aware bug prediction models;suspicious class list;efficiency 85.2 percent;efficiency 80.95 percent;efficiency 12.6 percent;efficiency 11.5 percent,,,,66.0,IEEE,13 Jan 2019,,,IEEE,IEEE Journals
1505,144,A Templating System to Generate Provenance,L. Moreau; B. V. Batlajery; T. D. Huynh; D. Michaelides; H. Packer,"Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom",IEEE Transactions on Software Engineering,12 Feb 2018,2018,44,2,103,121,"PROV-TEMPLATEIS a declarative approach that enables designers and programmers to design and generate provenance compatible with the PROV standard of the World Wide Web Consortium. Designers specify the topology of the provenance to be generated by composing templates, which are provenance graphs containing variables, acting as placeholders for values. Programmers write programs that log values and package them up in sets of bindings, a data structure associating variables and values. An expansion algorithm generates instantiated provenance from templates and sets of bindings in any of the serialisation formats supported by PROV. A quantitative evaluation shows that sets of bindings have a size that is typically 40 percent of that of expanded provenance templates and that the expansion algorithm is suitably tractable, operating in fractions of milliseconds for the type of templates surveyed in the article. Furthermore, the approach shows four significant software engineering benefits: separation of responsibilities, provenance maintenance, potential runtime checks and static analysis, and provenance consumption. The article gathers quantitative data and qualitative benefits descriptions from four different applications making use of PROV-TEMPLATE. The system is implemented and released in the open-source library ProvToolbox for provenance processing.",1939-3520,,10.1109/TSE.2017.2659745,EPSRC SOCIAM; ORCHID; FP7 SmartSociety; ESRC eBook; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7909036,Provenance;prov;provenance generation;template,Electronic publishing;Instruments;Standards;Maintenance engineering;Runtime;Libraries;Automobiles,data structures;graph theory;Internet;software engineering;software maintenance,data structure;PROV-TEMPLATE;provenance generation;open-source library ProvToolbox;software engineering;templating system;provenance processing;quantitative data;provenance consumption;provenance maintenance;expanded provenance templates;expansion algorithm;provenance graphs;World Wide Web Consortium;PROV standard,,6.0,,64.0,CCBY,24 Apr 2017,,,IEEE,IEEE Journals
1506,145,What Predicts Software Developers’ Productivity?,E. Murphy-Hill; C. Jaspan; C. Sadowski; D. Shepherd; M. Phillips; C. Winter; A. Knight; E. Smith; M. Jorde,"Developer Infrastructure, Google Inc., Sunnyvale, CA, USA; Developer Infrastructure, Google Inc., Sunnyvale, CA, USA; Chrome, Google Inc., Mountain View, CA, USA; ISS SWE, ABB, Inc., Raleigh, NC, USA; Research & Development, National Instruments Corp., Austin, TX, USA; Waymo, Mountain View, CA, USA; Developer Infrastructure, Google Inc., Sunnyvale, CA, USA; Bloomberg, Bloomberg LP, New York, NY, USA; Developer Infrastructure, Google Inc., Sunnyvale, CA, USA",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,582,594,"Organizations have a variety of options to help their software developers become their most productive selves, from modifying office layouts, to investing in better tools, to cleaning up the source code. But which options will have the biggest impact? Drawing from the literature in software engineering and industrial/organizational psychology to identify factors that correlate with productivity, we designed a survey that asked 622 developers across 3 companies about these productivity factors and about self-rated productivity. Our results suggest that the factors that most strongly correlate with self-rated productivity were non-technical factors, such as job enthusiasm, peer support for new ideas, and receiving useful feedback about job performance. Compared to other knowledge workers, our results also suggest that software developers' self-rated productivity is more strongly related to task variety and ability to work remotely.",1939-3520,,10.1109/TSE.2019.2900308,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643844,Productivity factors;software engineers;knowledge workers,Productivity;Software;Companies;Google;Tools;Task analysis;Time measurement,DP industry;employee welfare;industrial psychology;organisational aspects;personnel;productivity;software engineering;teleworking,task variety;remote work;job performance feedback;peer support;job enthusiasm;organizational psychology;industrial psychology;software developer productivity prediction;software engineering;source code;office layouts;nontechnical factors;self-rated productivity;productivity factors,,1.0,,48.0,IEEE,19 Feb 2019,,,IEEE,IEEE Journals
1507,146,Automating Intention Mining,Q. Huang; X. Xia; D. Lo; G. C. Murphy,"College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Information Systems, Singapore Management University, Singapore; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,14 Oct 2020,2020,46,10,1098,1119,"Developers frequently discuss aspects of the systems they are developing online. The comments they post to discussions form a rich information source about the system. Intention mining, a process introduced by Di Sorbo et al., classifies sentences in developer discussions to enable further analysis. As one example of use, intention mining has been used to help build various recommenders for software developers. The technique introduced by Di Sorbo et al. to categorize sentences is based on linguistic patterns derived from two projects. The limited number of data sources used in this earlier work introduces questions about the comprehensiveness of intention categories and whether the linguistic patterns used to identify the categories are generalizable to developer discussion recorded in other kinds of software artifacts (e.g., issue reports). To assess the comprehensiveness of the previously identified intention categories and the generalizability of the linguistic patterns for category identification, we manually created a new dataset, categorizing 5,408 sentences from issue reports of four projects in GitHub. Based on this manual effort, we refined the previous categories. We assess Di Sorbo et al.'s patterns on this dataset, finding that the accuracy rate achieved is low (0.31). To address the deficiencies of Di Sorbo et al.'s patterns, we propose and investigate a convolution neural network (CNN)-based approach to automatically classify sentences into different categories of intentions. Our approach optimizes CNN by integrating batch normalization to accelerate the training speed, and an automatic hyperparameter tuning approach to tune appropriate hyperparameters of CNN. Our approach achieves an accuracy of 0.84 on the new dataset, improving Di Sorbo et al.'s approach by 171 percent. We also apply our approach to improve an automated software engineering task, in which we use our proposed approach to rectify misclassified issue reports, thus reducing the bias introduced by such data to other studies. A case study on four open source projects with 2,076 issue reports shows that our approach achieves an average AUC score of 0.687, which improves other baselines by at least 16 percent.",1939-3520,,10.1109/TSE.2018.2876340,National Key Research and Development Program of China; NSFC Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493285,Deep Learning;Intention;Issue Report;Empirical Study,Taxonomy;Linguistics;Data mining;Tuning;Computer bugs;Software;Training,computational linguistics;convolutional neural nets;data mining;pattern classification;software engineering,intention mining;software developers;linguistic patterns;software artifacts;category identification;CNN;automatic hyperparameter tuning;software engineering;convolution neural network;sentence classification,,6.0,,90.0,IEEE,16 Oct 2018,,,IEEE,IEEE Journals
1508,147,Analyzing Families of Experiments in SE: A Systematic Mapping Study,A. Santos; O. Gómez; N. Juristo,"M3S (M-Group), ITEE University of Oulu, Oulu, Finland; Escuela Superior Politécnica de Chimborazo Riobamba, Chimborazo, Ecuador; Escuela Técnica Superior de Ingenieros Informáticos, Campus Montegancedo, Universidad Politécnica de Madrid, Boadilla del Monte, Spain",IEEE Transactions on Software Engineering,14 May 2020,2020,46,5,566,583,"Context: Families of experiments (i.e., groups of experiments with the same goal) are on the rise in Software Engineering (SE). Selecting unsuitable aggregation techniques to analyze families may undermine their potential to provide in-depth insights from experiments' results. Objectives: Identifying the techniques used to aggregate experiments' results within families in SE. Raising awareness of the importance of applying suitable aggregation techniques to reach reliable conclusions within families. Method: We conduct a systematic mapping study (SMS) to identify the aggregation techniques used to analyze families of experiments in SE. We outline the advantages and disadvantages of each aggregation technique according to mature experimental disciplines such as medicine and pharmacology. We provide preliminary recommendations to analyze and report families of experiments in view of families' common limitations with regard to joint data analysis. Results: Several aggregation techniques have been used to analyze SE families of experiments, including Narrative synthesis, Aggregated Data (AD), Individual Participant Data (IPD) mega-trial or stratified, and Aggregation of p-values. The rationale used to select aggregation techniques is rarely discussed within families. Families of experiments are commonly analyzed with unsuitable aggregation techniques according to the literature of mature experimental disciplines. Conclusion: Data analysis' reporting practices should be improved to increase the reliability and transparency of joint results. AD and IPD stratified appear to be suitable to analyze SE families of experiments.",1939-3520,,10.1109/TSE.2018.2864633,Ministerio de Ciencia e Innovación; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430603,Family of experiments;meta-analysis;narrative synthesis;IPD;AD,Systematics;Data aggregation;Reliability;Data analysis,data analysis;software engineering,systematic mapping study;aggregation technique;SE families;software engineering;SMS;narrative synthesis;aggregated data;individual participant data;p-values,,2.0,,121.0,IEEE,9 Aug 2018,,,IEEE,IEEE Journals
1509,148,How Do Users Revise Answers on Technical Q&A Websites? A Case Study on Stack Overflow,S. Wang; T. -H. Chen; A. E. Hassan,"School of the Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; School of the Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,1024,1038,"To ensure the quality of its shared knowledge, Stack Overflow encourages users to revise answers through a badge system, which is based on quantitative measures (e.g., a badge is awarded after revising more than 500 answers). Prior studies show that badges can positively steer the user behavior on Stack Overflow (e.g., increasing user participation). However, little is known whether revision-related badges have a negative impact on the quality of revisions since some studies show that certain users may game incentive systems to gain rewards. In this study, we analyze 3,871,966 revision records that are collected from 2,377,692 Stack Overflow answers. We find that: 1) Users performed a much larger than usual revisions on the badge-awarding days compared to normal days; 25% of the users did not make any more revisions once they received their first revision-related badge. 2) Performing more revisions than usual in a single day increased the likelihood of such revisions being rolled back (e.g., due to undesired or incorrect revisions). 3) Users were more likely to perform text and small revisions if they performed many revisions in a single day. Our findings are concurred by the Stack Overflow community, and they highlight the need for changes to the current badge system in order to provide a better balance between the quality and quantity of revisions.",1939-3520,,10.1109/TSE.2018.2874470,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485395,Stack overflow;incentive system;badge;answer revision,Atmospheric measurements;Particle measurements;Games;Indexes;Knowledge engineering;Software;Computer science,question answering (information retrieval);software engineering;Web sites,user behavior;user participation;revision-related badge;Stack Overflow answers;usual revisions;badge-awarding days;undesired revisions;incorrect revisions;Stack Overflow community;current badge system;revision records,,4.0,,44.0,IEEE,7 Oct 2018,,,IEEE,IEEE Journals
1510,149,Metamorphic Relations for Enhancing System Understanding and Use,Z. Q. Zhou; L. Sun; T. Y. Chen; D. Towey,"Institute of Cybersecurity and Cryptology, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Institute of Cybersecurity and Cryptology, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, VIC, Australia; School of Computer Science, University of Nottingham Ningbo China, Ningbo, Zhejiang, China",IEEE Transactions on Software Engineering,14 Oct 2020,2020,46,10,1120,1154,"Modern information technology paradigms, such as online services and off-the-shelf products, often involve a wide variety of users with different or even conflicting objectives. Every software output may satisfy some users, but may also fail to satisfy others. Furthermore, users often do not know the internal working mechanisms of the systems. This situation is quite different from bespoke software, where developers and users typically know each other. This paper proposes an approach to help users to better understand the software that they use, and thereby more easily achieve their objectives-even when they do not fully understand how the system is implemented. Our approach borrows the concept of metamorphic relations from the field of metamorphic testing (MT), using it in an innovative way that extends beyond MT. We also propose a “symmetry” metamorphic relation pattern and a “change direction” metamorphic relation input pattern that can be used to derive multiple concrete metamorphic relations. Empirical studies reveal previously unknown failures in some of the most popular applications in the world, and show how our approach can help users to better understand and better use the systems. The empirical results provide strong evidence of the simplicity, applicability, and effectiveness of our methodology.",1939-3520,,10.1109/TSE.2018.2876433,Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493260,Metamorphic exploration;symmetry;metamorphic testing;metamorphic relation;metamorphic relation pattern;metamorphic relation input pattern;change direction;oracle problem;user experience;user countermeasure;software validation,Software testing;Information technology;Electronic mail;Software systems;Software maintenance,program testing;software engineering,system understanding;software output;metamorphic testing;MT;symmetry metamorphic relation pattern;change direction metamorphic relation input pattern;multiple concrete metamorphic relations;system usage,,10.0,,95.0,IEEE,16 Oct 2018,,,IEEE,IEEE Journals
1511,150,Harsh Sinha on Product Management,B. Reinero,MongoDB,IEEE Software,12 Mar 2018,2018,35,2,105,108,"Software Engineering Radio host Bryan Reinero talks with Harsh Sinha about product management, particularly for software engineers. http://www.se-radio.net/2017/10/se-radio-episode-307-harsh-sinha-on-product-management/ is an audio recording of this episode of Software Engineering Radio.",1937-4194,,10.1109/MS.2018.1661314,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314170,Harsh Sinha;product management;product managers;conversion funnel;software engineering;software development,Software engineering;Software development management;Software measurement;Interviews;Software product lines,,,,,,,,12 Mar 2018,,,IEEE,IEEE Magazines
1512,151,Automatic Feature Learning for Predicting Vulnerable Software Components,H. K. Dam; T. Tran; T. Pham; S. W. Ng; J. Grundy; A. Ghose,"Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; School of Information Technology, Deakin University, Waurn Ponds, Victoria, Australia; School of Information Technology, Deakin University, Waurn Ponds, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Faculty of Information Technology, Monash University, Clayton, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,67,85,"Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g., complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the Firefox application demonstrates that the prediction power obtained from our learned features is better than what is achieved by state of the art vulnerability prediction models, for both within-project prediction and cross-project prediction.",1939-3520,,10.1109/TSE.2018.2881961,Samsung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540022,Software vulnerability prediction;mining software engineering repositories;empirical software engineering,Semantics;Software systems;Predictive models;Security;Feature extraction;System recovery,data mining;feature extraction;learning (artificial intelligence);public domain software;security of data,prediction power;art vulnerability prediction models;within-project prediction;cross-project prediction;automatic feature learning;predicting vulnerable software components;software systems;information loss;system failure;code vulnerabilities;code bases;code features;complexity metrics;code tokens;potentially problematic code;semantic representation;syntactic representation;source code;important capability;accurate prediction models;powerful deep learning Long Short Term Memory model,,4.0,,61.0,IEEE,18 Nov 2018,,,IEEE,IEEE Journals
1513,152,Predicting Delivery Capability in Iterative Software Development,M. Choetkiertikul; H. K. Dam; T. Tran; A. Ghose; J. Grundy,"Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, NSW, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, NSW, Australia; School of Information Technology, Deakin University, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, NSW, Australia; School of Information Technology, Deakin University, Victoria, Australia",IEEE Transactions on Software Engineering,12 Jun 2018,2018,44,6,551,573,"Iterative software development has become widely practiced in industry. Since modern software projects require fast, incremental delivery for every iteration of software development, it is essential to monitor the execution of an iteration, and foresee a capability to deliver quality products as the iteration progresses. This paper presents a novel, data-driven approach to providing automated support for project managers and other decision makers in predicting delivery capability for an ongoing iteration. Our approach leverages a history of project iterations and associated issues, and in particular, we extract characteristics of previous iterations and their issues in the form of features. In addition, our approach characterizes an iteration using a novel combination of techniques including feature aggregation statistics, automatic feature learning using the Bag-of-Words approach, and graph-based complexity measures. An extensive evaluation of the technique on five large open source projects demonstrates that our predictive models outperform three common baseline methods in Normalized Mean Absolute Error and are highly accurate in predicting the outcome of an ongoing iteration.",1939-3520,,10.1109/TSE.2017.2693989,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898472,Mining software engineering repositories;empirical software engineering;iterative software development,Software;Feature extraction;Predictive models;Data mining;Complexity theory;Iterative methods;Agile software development,graph theory;learning (artificial intelligence);project management;software development management;software prototyping;software quality,iterative software development;incremental delivery;data-driven approach;project iterations;open source projects;delivery capability;software projects;feature aggregation statistics;automatic feature learning;Bag-of-Words;graph-based complexity;Normalized Mean Absolute Error,,5.0,,88.0,,12 Apr 2017,,,IEEE,IEEE Journals
1514,153,An Empirical Study of Obsolete Answers on Stack Overflow,H. Zhang; S. Wang; T. -H. Chen; Y. Zou; A. E. Hassan,"Software Analysis and Intelligence Lab (SAIL), Queen’s University, Kingston, ON, Canada; Software Analysis and Intelligence Lab (SAIL), Queen’s University, Kingston, ON, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada; Software Analysis and Intelligence Lab (SAIL), Queen’s University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,850,862,"Stack Overflow accumulates an enormous amount of software engineering knowledge. However, as time passes, certain knowledge in answers may become obsolete. Such obsolete answers, if not identified or documented clearly, may mislead answer seekers and cause unexpected problems (e.g., using an out-dated security protocol). In this paper, we investigate how the knowledge in answers becomes obsolete and identify the characteristics of such obsolete answers. We find that: 1) More than half of the obsolete answers (58.4 percent) were probably already obsolete when they were first posted. 2) When an obsolete answer is observed, only a small proportion (20.5 percent) of such answers are ever updated. 3) Answers to questions in certain tags (e.g., node.js, ajax, android, and objective-c) are more likely to become obsolete. Our findings suggest that Stack Overflow should develop mechanisms to encourage the whole community to maintain answers (to avoid obsolete answers) and answer seekers are encouraged to carefully go through all information (e.g., comments) in answer threads.",1939-3520,,10.1109/TSE.2019.2906315,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669958,Q&A website;stack overflow;obsolete knowledge;knowledge sharing,Aging;Knowledge engineering;Message systems;Google;Computer languages;Software engineering;Security,,,,6.0,,39.0,IEEE,19 Mar 2019,,,IEEE,IEEE Journals
1515,154,Explaining Static Analysis with Rule Graphs,L. Nguyen Quang Do; E. Bodden,"Computer Science, Universitat Paderborn, 26578 Paderborn, North Rhine-Westphalia Germany (e-mail: lisa.nqd@gmail.com); Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, NRW Germany 33102 (e-mail: eric.bodden@uni-paderborn.de)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"As static data-flow analysis becomes able to report increasingly complex bugs, using an evergrowing set of complex internal rules encoded into flow functions, the analysis tools themselves grow more and more complex. In result, for users to be able to effectively use those tools on specific codebases, they require special configurations—a task which in industry is typically performed by individual developers or dedicated teams. To efficiently use and configure static analysis tools, developers need to build a certain understanding of the analysis' rules, i.e., how the underlying analyses interpret the analyzed code and their reasoning for reporting certain warnings. In this article, we explore how to assist developers in understanding the analysis' warnings, and finding weaknesses in the analysis' rules. To this end, we introduce the concept of rule graphs that expose to the developer selected information about the internal rules of data-flow analyses. We have implemented rule graphs on top of a taint analysis, and show how the graphs can support the abovementioned tasks. Our user study and empirical evaluation show that using rule graphs helps developers understand analysis warnings more accurately than using simple warning traces, and that rule graphs can help developers identify causes for false positives in analysis rules.",1939-3520,,10.1109/TSE.2020.2999534,NRW Research Training Group on Human Centered Systems Security; Heinz Nixdorf Foundation; Bundesministerium fr Bildung und Forschung; Deutsche Forschungsgemeinschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106860,Program analysis;Data-flow analysis;Rule graphs;Analysis configuration;Explainability;Usability,Static analysis;Tools;SQL injection;Task analysis;Computer bugs;Cognition;Usability,,,,,,,,2 Jun 2020,,,IEEE,IEEE Early Access Articles
1516,155,Improving State-of-the-art Compression Techniques for Log Management Tools,K. Yao; M. Sayagh; W. Shang; A. E. Hassan,"School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: kundi@cs.queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: msayagh@cs.queensu.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Log data records important runtime information about the running of a software system for different purposes including performance assurance, capacity planning, and anomaly detection. Log management tools such as ELK Stack and Splunk are widely adopted to manage and leverage log data in order to assist DevOps in real-time log analytics and decision making. To enable fast queries and to save storage space, such tools split log data into small blocks (e.g., 16KB), then index and compress each block separately. Previous log compression studies focus on improving the compression of either large-sized log files or log streams, without considering improving the compression of small log blocks (the actual compression need by modern log management tools). The evaluation of four state-of-the-art compression approaches (e.g., Logzip, a variation of Logzip by pre-extracting log templates named Logzip-E, LogArchive and Cowic) indicates that these approaches do not perform well on small log blocks. In fact, the compressed blocks that are preprocessed using Logzip, Logzip-E, LogArchive or Cowic are even larger (on median 1.3 times, 1.5 times, 0.2 times or 6.6 times) than the compressed blocks without any preprocessing. Hence, we propose an approach named LogBlock to preprocess small log blocks before compressing them with a general compressor such as gzip, deflate and lz4, which are widely adopted by log management tools. Logblock reduces the repetitiveness of logs by preprocessing the log headers and rearranging the log content leading to an improved compression ratio for a log file. Our evaluation on 16 log files shows that, for 16KB to 128KB block sizes, the compressed blocks by LogBlock are on median 5% to 21% smaller than the same compressed blocks without preprocessing (outperforming the state-of-the-art compression approaches). LogBlock achieves both a higher compression ratio (a median of 1.7 to 8.4 times, 1.9 to 10.0 times, 1.3 to 1.9 times and 6.2 to 11.4 times) and a faster compression speed (a median of 30.8 to 49.7 times, 42.6 to 53.8 times, 4.5 to 6.0 times and 2.5 to 4.0 times) than Logzip, Logzip-E, LogArchive and Cowic. LogBlock can help improve the storage efficiency of log management tools.",1939-3520,,10.1109/TSE.2021.3069958,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392377,Software log compression;Software logging;Log management tools F,Tools;Indexes;IP networks;Software systems;Runtime;Monitoring;Message systems,,,,,,,IEEE,31 Mar 2021,,,IEEE,IEEE Early Access Articles
1517,156,How do Practitioners Perceive the Relevance of Requirements Engineering Research?,X. Franch; D. Mendez; A. Vogelsang; R. Heldal; E. Knauss; M. Oriol; G. Travassos; J. C. Carver; T. Zimmermann,"Departament de Enginyeria de Serveis i Sistemes de Informaci? (ESSI), Universitat Polit?cnica de Catalunya, 16767 Barcelona, Catalunya, Spain, (e-mail: franch@essi.upc.edu); Software Engineering Research Lab, Blekinge Institute of Technology, 4206 Karlskrona, Blekinge, Sweden, (e-mail: daniel.mendez@bth.se); Daimler Center for Automotive IT Innovations, Technische Universitat Berlin, 26524 Berlin, Berlin, Germany, (e-mail: vogelsang@cs.uni-koeln.de); Department of Computer science, Electrical engineering and Mathematical sciences, Western Norway University of Applied Sciences, 1657 Bergen, Hordaland, Norway, (e-mail: rohe@hvl.no); Computer Science and Engineering, Chalmers tekniska hogskola Campus Lindholmen, 101171 Goteborg, Sweden, Sweden, (e-mail: eric.knauss@cse.gu.se); ESSI, Universitat Polit?cnica de Catalunya, 16767 Barcelona, Catalunya, Spain, (e-mail: moriol@essi.upc.edu); Instituto Alberto Luiz Coimbra de P?s-Gradua??o e Pesquisa de Engenharia, Federal University of Rio de Janeiro, 28125 Rio de Janeiro, RJ, Brazil, (e-mail: bht@cos.ufjr.br); Computer Science, University of Alabama, Tuscaloosa, Alabama, United States, 35487 (e-mail: carver@cs.ua.edu); Research, Microsoft Corporation, Redmond, Washington, United States, 98052 (e-mail: tzimmer@microsoft.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Context: The relevance of Requirements Engineering (RE) research to practitioners is vital for a long-term dissemination of research results to everyday practice. Some authors have speculated about a mismatch between research and practice in the RE discipline. However, there is not much evidence to support or refute this perception. Objective: This paper presents the results of a study aimed at gathering evidence from practitioners about their perception of the relevance of RE research and at understanding the factors that influence that perception. Method: We conducted a questionnaire-based survey of industry practitioners with expertise in RE. The participants rated the perceived relevance of 435 scientific papers presented at five top RE-related conferences. Results: The 153 participants provided a total of 2,164 ratings. The practitioners rated RE research as essential or worthwhile in a majority of cases. However, the percentage of non-positive ratings is still higher than we would like. Among the factors that affect the perception of relevance are the paper?s links to industry, the research method used, and respondents? roles. The reasons for positive perceptions were primarily related to the relevance of the problem and the soundness of the solution, while the causes for negative perceptions were more varied. The respondents also provided suggestions for future research, including topics researchers have studied for decades, like elicitation or requirement quality criteria. Conclusions: The study is valuable for both researchers and practitioners. Researchers can use the reasons respondents gave for positive and negative perceptions and the suggested research topics to help make their research more appealing to practitioners and thus more prone to industry adoption. Practitioners can benefit from the overall view of contemporary RE research by learning about research topics that they may not be familiar with, and compare their perception with those of their colleagues to self-assess their positioning towards more academic research.",1939-3520,,10.1109/TSE.2020.3042747,Ministerio de Ciencia e Innovación; Conselho Nacional de Desenvolvimento Científico e Tecnológico; KKS Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282205,Requirements Engineering;Survey;Impact of Research;Practitioners' Perception,Industries;Protocols;Requirements engineering;Buildings;Tools;Testing;Task analysis,,,,,,,IEEE,4 Dec 2020,,,IEEE,IEEE Early Access Articles
1518,157,ModGuard: Identifying Integrity &Confidentiality Violations in Java Modules,A. Dann; B. Hermann; E. Bodden,"Heinz Nixdorf Institut, Universitat Paderborn, 26578 Paderborn, NRW Germany (e-mail: andreas.dann@uni-paderborn.de); Heinz Nixdorf Institut, Universitat Paderborn, 26578 Paderborn, NRW Germany (e-mail: ben.hermann@uni-paderborn.de); Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, NRW Germany 33102 (e-mail: eric.bodden@uni-paderborn.de)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"With version 9, Java has been given the new module system Jigsaw. Major goals were to simplify maintainability of the JDK and improve its security by encapsulating modules' internal types. While the module system successfully limits the visibility of internal types, it does not prevent sensitive data from escaping. Since the module system reasons about types only, objects are allowed to escape even if that module declares the type as internal. Finding such unintended escapes is important, as they may violate a module's integrity and confidentiality, but is a complex task as it requires one to reason about pointers and type hierarchy. We thus present ModGuard, a novel static analysis based on Doop which complements the Java module system with an analysis to automatically identify instances that escape their declaring module. Along with ModGuard we contribute a complete formal definition of a module's entrypoints, i.e., the method implementations that a module actually allows other modules to directly invoke. We further make available a novel micro-benchmark suite Mic9Bench to show the effectiveness but also current shortcomings of ModGuard, and to enable comparative studies in the future. Finally, we describe a case study that we conducted using Apache Tomcat, which shows that a migration of applications towards Jigsaw modules does not prevent sensitive instances from escaping, yet also shows that ModGuard is an effective aid in identifying integrity and confidentiality violations of sensitive instances.",1939-3520,,10.1109/TSE.2019.2931331,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778721,Java 9;Jigsaw;Module Systems;Security;Static Escape Analysis;Doop;Soot,Java;Security;Cognition;Static analysis;Encapsulation;Manuals;Benchmark testing,,,,,,,,29 Jul 2019,,,IEEE,IEEE Early Access Articles
1519,158,RefactoringMiner 2.0,N. Tsantalis; A. Ketkar; D. Dig,"Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada H3G 1M8 (e-mail: nikolaos.tsantalis@concordia.ca); Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: ketkara@oregonstate.edu); Computer Science, University of Colorado Boulder, 1877 Boulder, Colorado United States (e-mail: digd@eecs.oregonstate.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Refactoring detection is crucial for a variety of applications and tasks: (i) empirical studies about code evolution, (ii) tools for library API migration, (iii) code reviews and change comprehension. However, recent research has questioned the accuracy of the state-of-the-art refactoring mining tools, which poses threats to the reliability of the detected refactorings. Moreover, the majority of refactoring mining tools depend on code similarity thresholds. Finding universal threshold values that can work well for all projects, regardless of their architectural style, application domain, and development practices is extremely challenging. Therefore, in a previous work [1], we introduced the first refactoring mining tool that does not require any code similarity thresholds to operate. In this work, we extend our tool to support low-level refactorings that take place within the body of methods. To evaluate our tool, we created one of the most accurate, complete, and representative refactoring oracles to date, including 7,223 true instances for 40 different refactoring types detected by one (minimum) up to six (maximum) different tools, and validated by one up to four refactoring experts. Our evaluation showed that our approach achieves the highest average precision (99.6%) and recall (94%) among all competitive tools, and on median is 2.6 times faster than the second faster competitive tool.",1939-3520,,10.1109/TSE.2020.3007722,Division of Computing and Communication Foundations; Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136878,Refactoring Mining;Refactoring Oracle;Precision;Recall;Execution time;Git;Commit,Tools;Open source software;Software systems;Task analysis;Libraries;Syntactics;Maintenance engineering,,,,4.0,,,,8 Jul 2020,,,IEEE,IEEE Early Access Articles
1520,159,Efficient execution of ATL model transformations using static analysis and parallelism,J. Sanchez Cuadrado; L. Burgueno; M. Wimmer; A. Vallecillo,"Informtica y Sistemas, University of Murcia, Murcia, Murcia Spain 30100 (e-mail: jesusc@um.es); Lenguajes y Ciencias de la Computacin, Universidad de Mlaga, Mlaga, Mlaga Spain 29071 (e-mail: lburguenoc@uoc.edu); Software Engineering, Johannes Kepler Universitat Linz, 27266 Linz, n/a Austria (e-mail: manuel.wimmer@jku.at); Lenguajes y Ciencias de la Computacin, Universidad de Malaga, 16752 Spain, Malaga Spain 29071 (e-mail: av@lcc.uma.es)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Although model transformations are considered to be the heart and soul of Model Driven Engineering (MDE), there are still several challenges that need to be addressed to unleash their full potential in industrial settings. Among other shortcomings, their performance and scalability remain unsatisfactory for dealing with large models, making their wide adoption difficult in practice. This paper presents A2L, a compiler for the parallel execution of ATL model transformations, which produces efficient code that can use existing multicore computer architectures, and applies effective optimizations at the transformation level using static analysis. We have evaluated its performance in both sequential and multi-threaded modes obtaining significant speedups with respect to current ATL implementations. In particular, we obtain speedups between 2.32x and 38.28x for the A2L sequential version, and between 2.40x and 245.83x when A2L is executed in parallel, with expected average speedups of 8.59x and 22.42x, respectively.",1939-3520,,10.1109/TSE.2020.3011388,Ministerio de Ciencia e Innovacin; Austrian Federal Ministry for Digital and Economic Affairs National Foundation for Research Technology and Development FWF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146715,Model transformation;MDE;ATL;Performance;Scalability;Parallelization,Unified modeling language;Analytical models;Engines;Java;Scalability;Static analysis;Biological system modeling,,,,,,,,23 Jul 2020,,,IEEE,IEEE Early Access Articles
1521,160,Change-Patterns Mapping: A Boosting Way for Change Impact Analysis,Y. Huang; J. Jiang; X. Luo; X. Chen; Z. Zheng; N. Jia; G. Huang,"School of Software Engineering, Sun Yat-sen University, Guangzhou, GuangDong, China, (e-mail: huangyjn@gmail.com); School of Data and Computer Science, School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China., Guangzhou, Guangdong, China, (e-mail: exinpie@163.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); the School of Communication and Design, Sun Yat-sen University, Guangzhou, Guangdong, China, 510000 (e-mail: chenxp8@mail.sysu.edu.cn); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong, China, (e-mail: zibinzheng@yeah.net); School of Management Science and Engineering, Hebei GEO University, 12410 Shijiazhuang, Hebei, China, (e-mail: jianan_0101@163.com); Computer Science, School of EECS, Beijing, Beijing, China, 100871 (e-mail: hg@pku.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Change impact analysis (CIA) is a specialized process of program comprehension that investigates the ripple effects of a code change in a software system. In this paper, we present a boosting way for change impact analysis via mapping the historical change-patterns to current CIA task in a cross-project scenario. The change-patterns reflect the coupling dependencies between changed entities in a change set. A traditional CIA tool (such as ImpactMiner) outputs an initial impact set for a starting entity. To boost the traditional CIA tool, our approach retrieves an equivalent entity from various historical change sets for the starting entity. Then, the change-patterns between the equivalent entity and the rest of entities in the change set are mapped to the CIA task at hand. For current CIA task, if an entity in the initial impact set involves the similar change-pattern with the starting entity when comparing with the mapped change-pattern, we will reward the impacted confidence of the entity. Accuracy improvements are observed in the experiments when applying our boosting method to three famous CIA tools, i.e., ImpactMiner, JRipples and ROSE.",1939-3520,,10.1109/TSE.2021.3059481,China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; Guangdong Basic and Applied Basic Research Foundation; Key-Area Research and Development Program of Guangdong Province; Hong Kong RGC Project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354949,Change Impact Analysis;Change-Patterns;Coupling Dependency;Boosting Method,Software;Task analysis;Tools;Couplings;Boosting;Software systems;Licenses,,,,,,,CCBYNCND,16 Feb 2021,,,IEEE,IEEE Early Access Articles
1522,161,Enhancement of Mutation Testing via Fuzzy Clustering and Multi-population Genetic Algorithm,X. Dang; D. Gong; X. Yao; T. Tian; H. Liu,"School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu, China, (e-mail: dangpaper@163.com); School of Information and Electrical Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu, China, (e-mail: dwgong@vip.163.com); School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu, China, (e-mail: yaoxj@cumt.edu.cn); School of Computer Science and Technology, Shandong Jianzhu University, 105835 Jinan, Shandong, China, (e-mail: tian_tiantian@126.com); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria, Australia, (e-mail: hliu@swin.edu.au)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Mutation testing, a fundamental software testing technique, which is a typical way to evaluate the adequacy of test data. In mutation testing, a set of mutants are generated by seeding the different classes of faults into a program under test. Test data shall be generated in the way that as many mutants can be killed as possible. Thanks to numerous tools to implement mutation testing for different languages, a huge amount of mutants are normally generated even for small-sized programs. However, a large number of mutants not only leads to a high cost of mutation testing, but also make the corresponding test data generation a non-trivial task. In this paper, we make use of intelligent technologies to improve the effectiveness and efficiency of mutation testing from two perspectives. A machine learning technique, namely fuzzy clustering, is applied to categorize mutants into different clusters. Then, a multi-population genetic algorithm via individual sharing is employed to generate test data for killing the mutants in different clusters in parallel when the problem of test data generation as an optimization one. A comprehensive framework, termed as FUZGENMUT, is thus developed to implement the proposed techniques. The experiments based on nine programs of various sizes show that fuzzy clustering can help to reduce the cost of mutation testing effectively, and that the multi-population genetic algorithm improves the efficiency of test data generation while delivering the high mutant-killing capability. The results clearly indicate the huge potential of using intelligent technologies to enhance the efficacy and thus the practicality of mutation testing.",1939-3520,,10.1109/TSE.2021.3052987,National Natural Science Foundation of China; National Key Research and Development Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328619,mutation testing;fuzzy clustering;mutation clustering;test data generation;multi-population genetic algorithm (MGA),Testing;Genetic algorithms;Sorting;Clustering algorithms;Syntactics;Statistics;Sociology,,,,,,,IEEE,19 Jan 2021,,,IEEE,IEEE Early Access Articles
1523,162,DPWord2Vec: Better Representation of Design Patterns in Semantics,D. Liu; H. Jiang; X. Li; Z. Ren; L. Qiao; Z. Ding,"School of Software, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: dongliu@mail.dlut.edu.cn); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: jianghe@dlut.edu.cn); School of Software, Dalian university of technology Dalian, Dalian, Liaoning China 116621 (e-mail: li1989@mail.dlut.edu.cn); School of Software, Dalian university of technology, Dalian, Liaoning China (e-mail: zren@dlut.edu.cn); On-board Computer Center, Beijing Institute of Control Engineering, 154569 Beijing, Beijing China (e-mail: qosman@163.com); Center of Math Computing and Software Engineering, Zhejiang Sci-Tech University, Hangzhou, Zhejiang China (e-mail: zouhuading@hotmail.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"With the plain text descriptions of design patterns, developers could better learn and understand the definitions and usage scenarios of design patterns. To facilitate the automatic usage of these descriptions, e.g., recommending design patterns by free-text queries, design patterns and natural languages should be adequately associated. Existing studies usually use texts in design pattern books as the representations of design patterns to calculate similarities with the queries. However, this way is problematic. Lots of information of design patterns may be absent from design pattern books and many words would be out of vocabulary due to the content limitation of these books. To overcome these issues, a more comprehensive method should be constructed to estimate the relatedness between design patterns and natural language words. Motivated by Word2Vec, in this study, we propose DPWord2Vec that embeds design patterns and natural language words into vectors simultaneously. We first build a corpus containing more than 400 thousand documents extracted from design pattern books, Wikipedia, and Stack Overflow. Next, we redefine the concept of context window to associate design patterns with words. Then, the design pattern and word vector representations are learnt by leveraging an advanced word embedding method. The learnt design pattern and word vectors can be universally used in textual description based design pattern tasks. An evaluation shows that DPWord2Vec outperforms the baseline algorithms by 17.1%-96.5% in measuring the similarities between design patterns and words in terms of Spearman's rank correlation coefficient. Moreover, we adopt DPWord2Vec on two typical design pattern tasks. In the design pattern tag recommendation task, the DPWord2Vec based method outperforms two state-of-the-art algorithms by 6.6% and 32.7% respectively when considering Recall@10. In the design pattern selection task, DPWord2Vec improves the existing methods by 6.5%-70.7% in terms of MRR.",1939-3520,,10.1109/TSE.2020.3017336,National Natural Science Foundation of China; National Key Research and Development Plan of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170909,Design Pattern;Word Embedding;Word2Vec;Semantic Similarity;Tag Recommendation;Design Pattern Selection,Natural languages;Task analysis;Semantics;Windows;Vocabulary;Software design,,,,,,,,18 Aug 2020,,,IEEE,IEEE Early Access Articles
1524,163,Theoretical and Empirical Analyses of the Effectiveness of Metamorphic Relation Composition,K. Qiu; Z. Zheng; T. Chen; P. Poon,"School of Automation Science and Electrical Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: qiukun@buaa.edu.cn); School of Automation Science and Electrical Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: zhengz@buaa.edu.cn); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Melbourne, Victoria Australia (e-mail: tychen@swin.edu.au); School of Engineering and Technology, Central Queensland University, 6939 Melbourne, Victoria Australia (e-mail: p.poon@cqu.edu.au)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Metamorphic Relations (MRs) play a key role in determining the fault detection capability of Metamorphic Testing (MT). As human judgement is required for MR identification, systematic MR generation has long been an important research area in MT. Additionally, due to the extra program executions required for follow-up test cases, some concerns have been raised about MT cost-effectiveness. Consequently, the reduction in testing costs associated with MT has become another important issue to be addressed. MR composition can address both of these problems. This technique can automatically generate new MRs by composing existing ones, thereby reducing the number of follow-up test cases. Despite this advantage, previous studies on MR composition have empirically shown that some composite MRs have lower fault detection capability than their corresponding component MRs. To investigate this issue, we performed theoretical and empirical analyses to identify what characteristics component MRs should possess so that their corresponding composite MR has at least the same fault detection capability as the component MRs do. We have also derived a convenient, but effective guideline so that the fault detection capability of MT will most likely not be reduced after composition.",1939-3520,,10.1109/TSE.2020.3009698,Technical Foundation Project of Ministry of Industry and Information Technology of China; National Natural Science Foundation of China; Equipment Preliminary R and D Project of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144441,Metamorphic testing;metamorphic relation;metamorphic relation composition;test oracle;fault detection,Testing;Fault detection;Software;Guidelines;Systematics;Australia;Companies,,,,1.0,,,,20 Jul 2020,,,IEEE,IEEE Early Access Articles
1525,164,What Flows through a Software Value Stream?,M. Kersten,Tasktop,IEEE Software,6 Jul 2018,2018,35,4,8,11,"Most enterprise IT organizations don't have a well-defined productivity measure for what flows through their software production process. No clear consensus exists from academia or industry thought leaders on what constitutes software development productivity. Organizations know it when they see it-for example, through products that drive market adoption faster than others. But correlating development activities to those results has been more of an opaque art than a disciplined activity. To define productivity in a value stream, we must first define what flows.",1937-4194,,10.1109/MS.2018.2801538,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405621,software delivery value stream;software delivery;software value stream;lean software development;agile software development;DevOps;flow units;features;defects;technical debt;risk;Scaled Agile Framework;SAFe;Information Technology Infrastructure Library;ITIL;software development tools;software development;software engineering;On DevOps,Software product lines;Computer security;Production management;Production systems;Task analysis;Performance evaluation,organisational aspects;productivity;software engineering,software value stream;software production process;software development productivity;enterprise IT organizations;productivity measure,,1.0,,10.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1526,165,Recent Progress in Software Security,E. Amoroso,TAG Cyber,IEEE Software,12 Mar 2018,2018,35,2,11,13,"To reduce cybersecurity risk in software, the security community has widely adopted an approach involving a collage of techniques, tools, and methods, each addressing some aspect of the threat implications of bad code. This article briefly surveys recent progress in each element of this combined approach, including the pros and cons for reducing cybersecurity risk.",1937-4194,,10.1109/MS.2018.1661316,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314164,software security;malware;malware detection;software process maturity;software review;software scanning;DevOps;runtime application self-protection;RASP;software development;software engineering;Invited Content,Computer security;Malware;Software reliability;Runtime;Computer bugs,security of data;software engineering,software security;cybersecurity risk;security community;threat implications;bad code,,2.0,,1.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1527,166,A Theoretical and Empirical Study of Diversity-Aware Mutation Adequacy Criterion,D. Shin; S. Yoo; D. Bae,"KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea",IEEE Transactions on Software Engineering,14 Oct 2018,2018,44,10,914,931,"Diversity has been widely studied in software testing as a guidance towards effective sampling of test inputs in the vast space of possible program behaviors. However, diversity has received relatively little attention in mutation testing. The traditional mutation adequacy criterion is a one-dimensional measure of the total number of killed mutants. We propose a novel, diversity-aware mutation adequacy criterion called distinguishing mutation adequacy criterion, which is fully satisfied when each of the considered mutants can be identified by the set of tests that kill it, thereby encouraging inclusion of more diverse range of tests. This paper presents the formal definition of the distinguishing mutation adequacy and its score. Subsequently, an empirical study investigates the relationship among distinguishing mutation score, fault detection capability, and test suite size. The results show that the distinguishing mutation adequacy criterion detects 1.33 times more unseen faults than the traditional mutation adequacy criterion, at the cost of a 1.56 times increase in test suite size, for adequate test suites that fully satisfies the criteria. The results show a better picture for inadequate test suites; on average, 8.63 times more unseen faults are detected at the cost of a 3.14 times increase in test suite size.",1939-3520,,10.1109/TSE.2017.2732347,Information & communications Technology Promotion (IITP); Korea government (MSIP); Software R&D for Model-based Analysis and Verification of Higher-order Large Complex System; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7994647,Mutation testing;test adequacy criteria;diversity,Fault detection;Software engineering;Software testing;Correlation;Indexes;Subspace constraints,fault diagnosis;program testing;software engineering,empirical study;diversity-aware mutation adequacy criterion;software testing;test inputs;mutation testing;distinguishing mutation score;distinguishing mutation adequacy criterion;adequate test suites;inadequate test suites;theoretical study;program behaviors;killed mutants;fault detection capability,,3.0,,58.0,,27 Jul 2017,,,IEEE,IEEE Journals
1528,167,Expanding Queries for Code Search Using Semantically Related API Class-names,F. Zhang; H. Niu; I. Keivanloo; Y. Zou,"Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,11 Nov 2018,2018,44,11,1070,1082,"When encountering unfamiliar programming tasks (e.g., connecting to a database), there is a need to seek potential working code examples. Instead of using code search engines, software developers usually post related programming questions on online Q&A forums (e.g., Stack Overflow). One possible reason is that existing code search engines would return effective code examples only if a query contains identifiers (e.g., class or method names). In other words, existing code search engines do not handle natural-language queries well (e.g., a description of a programming task). However, developers may not know the appropriate identifiers at the time of the search. As the demand of searching code examples is increasing, it is of significant interest to enhance code search engines. We conjecture that expanding natural-language queries with their semantically related identifiers has a great potential to enhance code search engines. In this paper, we propose an automated approach to find identifiers (in particular API class-names) that are semantically related to a given natural-language query. We evaluate the effectiveness of our approach using 74 queries on a corpus of 23,677,216 code snippets that are extracted from 24,666 open source Java projects. The results show that our approach can effectively recommend semantically related API class-names to expand the original natural-language queries. For instance, our approach successfully retrieves relevant code examples in the top 10 retrieved results for 76 percent of 74 queries, while it is 36 percent when using the original natural-language query; and the median rank of the first relevant code example is increased from 22 to 7.",1939-3520,,10.1109/TSE.2017.2750682,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031055,Query expansion;code search;neural network language model;API class-name,Search engines;Programming;Java;Software engineering;IEEE transactions;Software;Joining processes,application program interfaces;Internet;natural language processing;query processing;search engines;software engineering,semantically related API class-names;natural-language query;code search engines;online Q&A forums;software developers,,5.0,,46.0,,11 Sep 2017,,,IEEE,IEEE Journals
1529,168,Automatically Exploring Tradeoffs Between Software Output Fidelity and Energy Costs,J. Dorn; J. Lacomis; W. Weimer; S. Forrest,"Department of Computer Science, University of Virginia, Charlottesville, VA; Department of Computer Science, University of Virginia, Charlottesville, VA; Department of Computer Science, University of Virginia, Charlottesville, VA; Arizona State University, Tempe, AZ",IEEE Transactions on Software Engineering,13 Mar 2019,2019,45,3,219,236,"Data centers account for a significant fraction of global energy consumption and represent a growing business cost. Most current approaches to reducing energy use in data centers treat it as a hardware, compiler, or scheduling problem. This article focuses instead on the software level, showing how to reduce the energy used by programs when they execute. By combining insights from search-based software engineering, mutational robustness, profile-guided optimization, and approximate computing, the Producing Green Applications Using Genetic Exploration (PowerGAUGE) algorithm finds variants of individual programs that use less energy than the original. We apply hardware, software, and statistical techniques to manage the complexity of accurately assigning physical energy measurements to particular processes. In addition, our approach allows, but does not require, relaxing output quality requirements to achieve greater non-functional improvements. PowerGAUGE optimizations are validated using physical performance measurements. Experimental results on PARSEC benchmarks and two larger programs show average energy reductions of 14% when requiring the preservation of original output quality and 41% when allowing for human-acceptable levels of error.",1939-3520,,10.1109/TSE.2017.2775634,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8118155,Power optimization;search-based software engineering;genetic algorithms;profile-guided optimization;optimizing noisy functions;accurate energy measurement,Energy consumption;Optimization;Hardware;Genetic algorithms;Software;Energy measurement,computer centres;energy conservation;energy consumption;genetic algorithms;optimisation;program compilers;scheduling;software quality;statistical analysis,tradeoffs;software output fidelity;data centers;global energy consumption;compiler;scheduling problem;software level;search-based software engineering;profile-guided optimization;approximate computing;statistical techniques;physical energy measurements;PowerGAUGE optimizations;physical performance measurements;business cost;energy reductions;genetic exploration;producing green applications;energy costs;PARSEC benchmarks,,1.0,,63.0,,22 Nov 2017,,,IEEE,IEEE Journals
1530,169,Reading Answers on Stack Overflow: Not Enough!,H. Zhang; S. Wang; T. Chen; A. E. Hassan,"School of Computing, Queen's University, Kingston, Ontario Canada K7M1B5 (e-mail: hzhang@cs.queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: wang@cse.msstate.edu); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 2W1 (e-mail: peterc@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Stack Overflow is one of the most active communities for developers to share their programming knowledge. Answers posted on Stack Overflow help developers solve issues during software development. In addition to posting answers, users can also post comments to further discuss their associated answers. As of Aug 2017, there are 32.3 million comments that are associated with answers, forming a large collection of crowdsourced repository of knowledge on top of the commonly-studied Stack Overflow answers. In this study, we wish to understand how the commenting activities contribute to the crowdsourced knowledge. We investigate what users discuss in comments, and analyze the characteristics of the commenting dynamics, (i.e., the timing of commenting activities and the roles of commenters). We find that: 1) the majority of comments are informative and thus can enhance their associated answers from a diverse range of perspectives. However, some comments contain content that is discouraged by Stack Overflow. 2) The majority of commenting activities occur after the acceptance of an answer. More than half of the comments are fast responses occurring within one day of the creation of an answer, while later comments tend to be more informative. Most comments are rarely integrated back into their associated answers, even though such comments are informative. 3) Insiders (i.e., users who posted questions/answers before posting a comment in a question thread) post the majority of comments within one month, and outsiders (i.e., users who never posted any question/answer before posting a comment) post the majority of comments after one month. Inexperienced users tend to raise limitations and concerns while experienced users tend to enhance the answer through commenting. Our study provides insights into the commenting activities in terms of their content, timing, and the individuals who perform the commenting. For the purpose of long-term knowledge maintenance and effective information retrieval for developers, we also provide actionable suggestions to encourage Stack Overflow users/engineers/moderators to leverage our insights for enhancing the current Stack Overflow commenting system for improving the maintenance and organization of the crowdsourced knowledge.",1939-3520,,10.1109/TSE.2019.2954319,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906075,Crowdsourced Knowledge Sharing and Management;Stack Overflow;Commenting;Empirical Software Engineering,Programming;Software;Guidelines;Maintenance engineering;Knowledge discovery;Timing,,,,1.0,,,,19 Nov 2019,,,IEEE,IEEE Early Access Articles
1531,170,What do package dependencies tell us about semantic versioning?,A. Decan; T. Mens,"Software Engineering Lab, University of Mons, Mons, Hainaut Belgium (e-mail: alexandre.decan@umons.ac.be); Institut d'Informatique, Université de Mons, Mons, Hainaut Belgium 7000 (e-mail: tom.mens@umons.ac.be)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The semantic versioning (semver) policy is commonly accepted by open source package management systems to inform whether new releases of software packages introduce possibly backward incompatible changes. Maintainers depending on such packages can use this information to avoid or reduce the risk of breaking changes in their own packages by specifying version constraints on their dependencies. Depending on the amount of control a package maintainer desires to have over her package dependencies, these constraints can range from very permissive to very restrictive. This article empirically compares semver compliance of four software packaging ecosystems (Cargo, npm, Packagist and Rubygems), and studies how this compliance evolves over time. We explore to what extent ecosystem-specific characteristics or policies influence the degree of compliance. We also propose an evaluation based on the ""wisdom of the crowds"" principle to help package maintainers decide which type of version constraints they should impose on their dependencies.",1939-3520,,10.1109/TSE.2019.2918315,FWO-Vlaanderen and F.R.S.-FNRS; FRQ-FNRS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721084,"D.2 Software Engineering;D.2.7 Distribution, Maintenance, and Enhancement;D.2.7.g Maintainability;D.2.7.n Version control;D.2.8 Metrics/Measurement;D.2.13 Reusable Software;D.2.13.b Reusable libraries;D.2.16 Configuration Management;D.2.16.f Software release management and delivery",Ecosystems;Software;Semantics;Packaging;Libraries;Java;Computer bugs,,,,5.0,,,,23 May 2019,,,IEEE,IEEE Early Access Articles
1532,171,From Voice of Evidence to Redirections,R. Prikladnicki; T. Menzies,Pontifícia Universidade Católica do Rio Grande do Sul; North Carolina State University,IEEE Software,25 Dec 2017,2018,35,1,11,13,"The Voice of Experience department is being relaunched as Redirections, which will focus on the surprises in software engineering.",1937-4194,,10.1109/MS.2017.4541053,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239930,Voice of Evidence;Redirections;software engineering;software development,Software engineering;Software development,,,,1.0,,6.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1533,172,Tammy Bütow on Chaos Engineering,E. Salinas,Microsoft,IEEE Software,27 Sep 2018,2018,35,5,125,128,"Software Engineering Radio host Edaena Salinas talks with Tammy Bütow of Gremlin on chaos engineering. The excerpt here covers Tammy’s background in failure testing, the nature of failure injection, what we can learn from chaos experiments, how to work through failure scenarios to harden your infrastructure, and their value in training operations staff. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2018.3571246,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474498,chaos engineering;Tammy Bütow;software engineering;software development,Chaos;Reliability engineering;Servers;Software engineering;Software development,,,,,,0.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1534,173,Natural Language Processing for Requirements Engineering: The Best Is Yet to Come,F. Dalpiaz; A. Ferrari; X. Franch; C. Palomares,Utrecht University; CNR-ISTI; Universitat Politècnica de Catalunya; Universitat Politècnica de Catalunya,IEEE Software,27 Sep 2018,2018,35,5,115,119,"As part of the growing interest in natural language processing for requirements engineering (RE), RE researchers, computational linguists, and industry practitioners met at the First Workshop on Natural Language Processing for Requirements Engineering (NLP4RE 18). This article summarizes the workshop and presents an overview of the discussion held on the field’s future. This article is part of a theme issue on software engineering’s 50th anniversary.",1937-4194,,10.1109/MS.2018.3571242,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474507,natural language processing;NLP;requirements engineering;NLP4RE;software requirements;software engineering;software development,Software development;Task analysis;Natural language processing;Software engineering;Requirements engineering,,,,8.0,,5.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1535,174,How Software Developers Mitigate their Errors when Developing Code,B. Nagaria; T. Hall,"Department of Computer Science, Brunel University London, 3890 London, Uxbridge, United Kingdom of Great Britain and Northern Ireland, UB8 3PH (e-mail: bhaveet.nagaria@brunel.ac.uk); School of Computing and Communication, Lancaster University, 4396 Bailrigg, Lancaster, United Kingdom of Great Britain and Northern Ireland, (e-mail: tracy.hall@lancaster.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Code remains largely hand-made by humans and, as such, writing code is prone to error. Many previous studies have focused on the technical reasons for these errors and provided developers with increasingly sophisticated tools. Few studies have looked in detail at why code errors have been made from a human perspective. We use Human Error Theory to frame our exploratory study and use semi-structured interviews to uncover a preliminary understanding of the errors developers make while coding. We look particularly at the Skill-Based (SB) errors reported by 27 professional software developers. We found that the complexity of the development environment is one of the most frequently reported reasons for errors. Maintaining concentration and focus on a particular task also underpins many developer errors. We found that developers struggle with effective mitigation strategies for their errors, reporting strategies largely based on improving their own willpower to concentrate better on coding tasks. We discuss how using Reason's Swiss Cheese model may help reduce errors during software development. This model ensures that layers of tool, process and management mitigation are in place to prevent developer errors from causing system failures.",1939-3520,,10.1109/TSE.2020.3040554,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9271926,Human error;human factors;software development,Software;Task analysis;Encoding;Psychology;Interviews;Software engineering;Footwear,,,,,,,IEEE,25 Nov 2020,,,IEEE,IEEE Early Access Articles
1536,175,The impact of feature importance methods on the interpretation of defect classifiers,G. K. Rajbahadur; S. Wang; G. Ansaldi; Y. Kamei; A. E. Hassan,"School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, K7L 2N8 (e-mail: krishnan@cs.queensu.ca); Computer Science, University of Manitoba, 8664 Winnipeg, Manitoba, Canada, (e-mail: shaoweiwang.2010@hotmail.com); School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: gustavo@cs.queensu.ca); Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Fukuoka, Japan, 819-0395 (e-mail: kamei@ait.kyushu-u.ac.jp); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Classifier specific (CS) and classifier agnostic (CA) feature importance methods are widely used (often interchangeably) by prior studies to derive feature importance ranks from a defect classifier. However, different feature importance methods are likely to compute different feature importance ranks even for the same dataset and classifier. Hence such interchangeable use of feature importance methods can lead to conclusion instabilities unless there is a strong agreement among different methods. Therefore, in this paper, we evaluate the agreement between the feature importance ranks associated with the studied classifiers through a case study of 18 software projects and six commonly used classifiers. We find that: 1) The computed feature importance ranks by CA and CS methods do not always strongly agree with each other. 2) The computed feature importance ranks by the studied CA methods exhibit a strong agreement including the features reported at top-1 and top-3 ranks for a given dataset and classifier, while even the commonly used CS methods yield vastly different feature importance ranks. Such findings raise concerns about the stability of conclusions across replicated studies. We further observe that the commonly used defect datasets are rife with feature interactions and these feature interactions impact the computed feature importance ranks of the CS methods (not the CA methods). We demonstrate that removing these feature interactions, even with simple methods like CFS improves agreement between the computed feature importance ranks of CA and CS methods. In light of our findings, we provide guidelines for stakeholders and practitioners when performing model interpretation and directions for future research, e.g., future research is needed to investigate the impact of advanced feature interaction removal methods on computed feature importance ranks of different CS methods.",1939-3520,,10.1109/TSE.2021.3056941,JSPS KAKENHI Japan; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347823,Model interpretation;Model Agnostic interpretation;Built-in interpretation;Feature Importance Analysis;Variable Importance 3,Software engineering;Computational modeling;Internet;Software quality;Predictive models;Neural networks;Logistics,,,,,,,IEEE,4 Feb 2021,,,IEEE,IEEE Early Access Articles
1537,176,Predicting Defective Lines Using a Model-Agnostic Technique,S. Wattanakriengkrai; P. Thongtanunam; C. Tantithamthavorn; H. Hata; K. Matsumoto,"Information Science, Nara Institute of Science and Technology, 12708 Ikoma, Nara Japan (e-mail: wattanakri.supatsara.ws3@is.naist.jp); School of Computing and Information System, The University of Melbourne, Melbourne, Victoria Australia (e-mail: patanamon.t@unimelb.edu.au); Information Technology, Monash University, 2541 Clayton, Victoria Australia 3800 (e-mail: chakkrit@monash.edu); Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara Japan 630-0192 (e-mail: hata@is.naist.jp); Information Systems, Nara Institute of Science and Technology, Information Systems, Ikomashi, Naraken Japan (e-mail: matumoto@is.naist.jp)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Defect prediction models are proposed to help a team prioritize source code areas files that need Software Quality Assurance (SQA) based on the likelihood of having defects. However, developers may waste their unnecessary effort on the whole file while only a small fraction of its source code lines are defective. Indeed, we find that as little as 1%-3% of lines of a file are defective. Hence, in this work, we propose a novel framework (called LINE-DP) to identify defective lines using a model-agnostic technique, i.e., an Explainable AI technique that provides information why the model makes such a prediction. Broadly speaking, our LINE-DP first builds a file-level defect model using code token features. Then, our LINE-DP uses a state-of-the-art model-agnostic technique (i.e., LIME) to identify risky tokens, i.e., code tokens that lead the file-level defect model to predict that the file will be defective. Then, the lines that contain risky tokens are predicted as defective lines. Through a case study of 32 releases of nine Java open source systems, our evaluation results show that our LINE-DP achieves an average recall of 0.61, a false alarm rate of 0.47, a top 20%LOC recall of 0.27, and an initial false alarm of 16, which are statistically better than six baseline approaches. Our evaluation shows that our LINE-DP requires an average computation time of 10 seconds including model construction and defective identification time. In addition, we find that 63% of defective lines that can be identified by our LINE-DP are related to common defects (e.g., argument change, condition change). These results suggest that our LINE-DP can effectively identify defective lines that contain common defects while requiring a smaller amount of inspection effort and a manageable computation cost. The contribution of this paper builds an important step towards line-level defect prediction by leveraging a model-agnostic technique.",1939-3520,,10.1109/TSE.2020.3023177,Australian Research Councils Discovery Early Career Researcher Award DECRA; Japan Society for the Promotion of Science; Monash-FIT Early Career Researcher Seed Grant; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9193975,Software Quality Assurance;Line-level Defect Prediction,Predictive models;Computational modeling;Software quality;Software systems;Pipelines;Software engineering,,,,2.0,,,CCBY,10 Sep 2020,,,IEEE,IEEE Early Access Articles
1538,177,Software Batch Testing to Save Build Test Resources and to Reduce Feedback Time,M. J. Beheshtian; A. Bavand; P. Rigby,"CSE, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: s_ehesht@encs.concordia.ca); CSE, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: amirhossein.bavand@gmail.com); CSE, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: peter.rigby@concordia.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Testing is expensive and batching tests has the potential to reduce test costs. The continuous integration strategy of testing each commit or change individually helps to quickly identify faults but leads to a maximal number of test executions. Large companies that have a massive number of commits, e.g., Google and Facebook, or have expensive test infrastructure, e.g., Ericsson, must batch changes together to reduce the number of total test runs. For example, if eight builds are batched together and there is no failure, then we have tested eight builds with one execution saving seven executions. However, when a failure occurs it is not immediately clear which build is the cause of the failure. A bisection is run to isolate the failing build, i.e. the culprit build. In our eight builds example, a failure will require an additional 6 executions, resulting in a saving of one execution. In this work, we re-evaluate batching approaches developed in industry on large open source projects using Travis CI. We also introduce novel batching approaches. In total, we evaluate six approaches. We find that compared to the TestAll baseline, on average, the approaches reduce the number of build test executions across projects by 46%, 48%, 50%, 44%, and 49% for BatchBisect, Batch4, BatchStop4, RiskTopN, and RiskBatch, respectively. The greatest reduction in executions is BatchStop4 at 50%. However, the simple approach of Batch4 does not require bisection and achieves a reduction of 48%. In a larger sample of projects, we find that a project's failure rate is strongly correlated with execution savings. Using Batch4, 85% of projects see savings. All projects that have build failures less than 40% of the time will benefit from batching. In terms of feedback time, compared to TestAll, we find that BatchBisect, Batch2, Batch4, BatchStop4 all reduce the average feedback time by 33%, 16%, 32%, and 37%. Simple batching saves not only resources but also reduces feedback time without introducing any slip-throughs and without changing the test run order. We release our scripts and data for replication [1] and the GitHub integration of the BatchBuilder tool for developers [2].",1939-3520,,10.1109/TSE.2021.3070269,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392370,Software Testing;Batch Testing;Continuous Integration and Deployment;Bisection;Pool Testing;Reducing Testing Cost;Risk Modelling,Testing;Internet;Software engineering;Tools;Resource management;Software development management;Social networking (online),,,,,,,IEEE,31 Mar 2021,,,IEEE,IEEE Early Access Articles
1539,178,Version Control Systems: An Information Foraging Perspective,S. Srinivasa Ragavan; M. Codoban; D. Piorkowski; D. Dig; M. Burnett,"School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: srinivas@eecs.oregonstate.edu); Tools for Software Engineers, Microsoft, Redmond, Washington United States (e-mail: micodoba@microsoft.com); AI, IBM Research, Yorktown Heights, New York United States (e-mail: david.piorkowski@ibm.com); School of EECS, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: digd@eecs.oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon United States 97331 (e-mail: burnett@eecs.oregonstate.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Version Control Systems (VCS) are an important source of information for developers. This calls for a principled understanding of developers' information seeking in VCS-both for improving existing tools and for understanding requirements for new tools. Our prior work investigated empirically how and why developers seek information in VCS: in this paper, we complement and enrich our prior findings by reanalyzing the data via a theory's lens. Using the lens of Information Foraging Theory (IFT), we present new insights not revealed by the prior empirical work. First, while looking for specific information, participants' foraging behaviors were consistent with other foraging situations in SE; therefore, prior research on IFT-based SE tool design can be leveraged for VCS. Second, in change awareness foraging, participants consumed similar diets, but in subtly different ways than in other situations; this calls for further investigations into change awareness foraging. Third, while committing changes, participants attempted to enable future foragers, but the competing needs of different foraging situations led to tensions that participants failed to balance: this opens up a new avenue for research at the intersection of IFT and SE, namely, creating forageable information. Finally, the results of using an IFT lens on these data provides some evidence as to IFT's scoping and utility for the version control domain.",1939-3520,,10.1109/TSE.2019.2931296,Division of Computing and Communication Foundations; National Science Foundation; Defense Advanced Research Projects Agency; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778723,Human factors in software desgin;Software engineering;Version control,Tools;Control systems;Software;Software engineering;Computer bugs;Animals;Lenses,,,,,,,,29 Jul 2019,,,IEEE,IEEE Early Access Articles
1540,179,Incentivizing Deep Fixes in Software Economies,M. Rao; D. F. Bacon; D. C. Parkes; M. I. Seltzer,"John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA; Google; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA",IEEE Transactions on Software Engineering,8 Jan 2020,2020,46,1,51,70,"An important question in a software economy is how to incentivize deep rather than shallow fixes. A deep fix corrects the root cause of a bug instead of suppressing the symptoms. This paper initiates the study of the problem of incentive design for open workflows in fixing code. We model the dynamics of the software ecosystem and introduce subsumption mechanisms. These mechanisms only make use of externally observable information in determining payments and promote competition between workers. We use a mean field equilibrium methodology to evaluate the performance of these mechanisms, demonstrating in simulation that subsumption mechanisms perform robustly across various environment configurations and satisfy important criteria for market design.",1939-3520,,10.1109/TSE.2018.2842188,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8384304,Market design;mean field equilibrium;software engineering;payment mechanisms,Computer bugs;Task analysis;Ecosystems;Open source software;Testing;Software engineering,game theory;socio-economic effects;software development management,mean field equilibrium methodology;subsumption mechanisms;software economy;open workflows;software ecosystem;externally observable information,,1.0,,63.0,IEEE,13 Jun 2018,,,IEEE,IEEE Journals
1541,180,The Effect of Work Environments on Productivity and Satisfaction of Software Engineers,B. Johnson; T. Zimmermann; C. Bird,"Massachusetts Amherst, Amherst, MA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,736,757,"The physical work environment of software engineers can have various effects on their satisfaction and the ability to get the work done. To better understand the factors of the environment that affect productivity and satisfaction of software engineers, we explored different work environments at Microsoft. We used a mixed-methods, multiple stage research design with a total of 1,159 participants: two surveys with 297 and 843 responses respectively and interviews with 19 employees. We found several factors that were considered as important for work environments: personalization, social norms and signals, room composition and atmosphere, work-related environment affordances, work area and furniture, and productivity strategies. We built statistical models for satisfaction with the work environment and perceived productivity of software engineers and compared them to models for employees in the Program Management, IT Operations, Marketing, and Business Program & Operations disciplines. In the satisfaction models, the ability to work privately with no interruptions and the ability to communicate with the team and leads were important factors among all disciplines. In the productivity models, the overall satisfaction with the work environment and the ability to work privately with no interruptions were important factors among all disciplines. For software engineers, another important factor for perceived productivity was the ability to communicate with the team and leads. We found that private offices were linked to higher perceived productivity across all disciplines.",1939-3520,,10.1109/TSE.2019.2903053,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658138,Productivity;satisfaction;physical environments;work environments;software engineering;program management;IT operations;marketing;business program & operations,Software;Productivity;Organizations;Software engineering;Interviews;Collaboration;Knowledge engineering,,,,2.0,,134.0,IEEE,4 Mar 2019,,,IEEE,IEEE Journals
1542,181,"Love, Joy, Anger, Sadness, Fear, and Surprise: SE Needs Special Kinds of AI: A Case Study on Text Mining and SE",N. Novielli; F. Calefato; F. Lanubile,"University of Bari, Italy; University of Bari, Italy; University of Bari, Italy",IEEE Software,15 Apr 2020,2020,37,3,86,91,"Artificial-intelligence (AI) tools are often applied to software engineering (SE) tasks using their “off-the-shelf” configurations. But is that wise? Perhaps not. In this column, researchers from the University of Bari show how AI gets much better when it is tuned to the particulars of SE.",1937-4194,,10.1109/MS.2020.2968557,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068371,,Software tools;Artificial intelligence;Sentiment analysis;Training data;Software development management;Data models,data mining;human factors;software engineering;text analysis,artificial-intelligence;software engineering tasks;SE;off-the-shelf configurations;AI;special kinds;text mining;University of Bari,,,,6.0,,15 Apr 2020,,,IEEE,IEEE Magazines
1543,182,OpenStack Gender Diversity Report,D. Izquierdo; N. Huesman; A. Serebrenik; G. Robles,"Bitergia; Diversity and Inclusion, Open Source Software Project; Software Evolution, Eindhoven University of Technology; Universidad Rey Juan Carlos, Spain",IEEE Software,14 Jan 2019,2019,36,1,28,33,"When it comes to gender, the field of software engineering is heavily skewed toward men; multiple studies show that the gender situation in the open source arena is even more lopsided.",1937-4194,,10.1109/MS.2018.2874322,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491276,gender diversity;open source software;openstack foundation;diversity and inclusion,Agile software development;Gender issues;Companies;Software development management;Cultural differences;Open source software,gender issues;public domain software;software engineering,OpenStack gender diversity report;software engineering;gender situation;open source arena,,5.0,,12.0,,14 Oct 2018,,,IEEE,IEEE Magazines
1544,183,METRIC+: A Metamorphic Relation Identification Technique Based on Input plus Output Domains,C. Sun; A. Fu; P. Poon; X. Xie; H. Liu; T. Y. Chen,"Department of Computer Science and Technology, University of Science and Technology Beijing, 12507 Beijing, Beijing China (e-mail: casun@ustb.edu.cn); Department of Computer Science and Technology, University of Science and Technology Beijing, 12507 Beijing, Beijing China (e-mail: anfu@xs.ustb.edu.cn); School of Engineering and Technology, Central Queensland University, 6939 Rockhampton, Queensland Australia (e-mail: p.poon@cqu.edu.au); School of Computer Science, Wuhan University, 12390 Wuhan, Hubei China (e-mail: xxie@whu.edu.cn); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: hliu@swin.edu.au); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: tychen@swin.edu.au)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Metamorphic testing is well known for its ability to alleviate the oracle problem in software testing. The main idea of metamorphic testing is to test a software system by checking whether each identified metamorphic relation (MR) holds among several executions. In this regard, identifying MRs is an essential task in metamorphic testing. In view of the importance of this identification task, METRIC (METamorphic Relation Identification based on Category-choice framework) was developed to help software testers identify MRs from a given set of complete test frames. However, during MR identification, METRIC primarily focuses on the input domain without sufficient attention given to the output domain, thereby hindering the effectiveness of METRIC. Inspired by this problem, we have extended METRIC into METRIC+ by incorporating the information derived from the output domain for MR identification. A tool implementing METRIC+ has also been developed. Two rounds of experiments, involving four real-life specifications, have been conducted to evaluate the effectiveness and efficiency of METRIC+. The results have confirmed that METRIC+ is highly effective and efficient in MR identification. Additional experiments have been performed to compare the fault detection capability of the MRs generated by METRIC+ and those by μMT (another MR identification technique). The comparison results have confirmed that the MRs generated by METRIC+ are highly effective in fault detection.",1939-3520,,10.1109/TSE.2019.2934848,National Natural Science Foundation of China; Chinese Aeronautical Establishment; Beijing Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807231,Metamorphic testing;metamorphic relation;category-choice framework;fault detection effectiveness,Measurement;Testing;Software systems;Fault detection;Task analysis;Tools,,,,3.0,,,CCBY,20 Aug 2019,,,IEEE,IEEE Early Access Articles
1545,184,Formulating Criticality-Based Cost-Effective Fault Tolerance Strategies for Multi-Tenant Service-Based Systems,Y. Wang; Q. He; D. Ye; Y. Yang,"State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Vic, Australia; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Vic, Australia",IEEE Transactions on Software Engineering,13 Mar 2018,2018,44,3,291,307,"The proliferation of cloud computing has fueled the rapid growth of multi-tenant service-based systems (SBSs), which serve multiple tenants simultaneously by composing existing services in the form of business processes. In a distributed and volatile operating environment, runtime anomalies may occur to the component services of an SBS and cause end-to-end quality violations. Engineering multi-tenant SBSs that can quickly handle runtime anomalies cost effectively has become a significant challenge. Different approaches have been proposed to formulate fault tolerance strategies for engineering SBSs. However, none of the existing approaches has sufficiently considered the service criticality based on multi-tenancy where multiple tenants share the same SBS instance with different multi-dimensional quality preferences. In this paper, we propose Criticality-based Fault Tolerance for Multi-Tenant SBSs (CFT4MTS), a novel approach that formulates cost-effective fault tolerance strategies for multi-tenant SBSs by providing redundancy for the critical component services. First, the criticality of each component service is evaluated based on its multi-dimensional quality and multiple tenants sharing the component service with differentiated quality preferences. Then, the fault tolerance problem is modelled as an Integer Programming problem to identify the optimal fault tolerance strategy. The experimental results show that, compared with three existing representative approaches, CFT4MTS can alleviate degradation in the quality of multi-tenant SBSs in a much more effective and efficient way.",1939-3520,,10.1109/TSE.2017.2681667,Australian Research Council Discovery; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876832,Cloud computing;criticality;fault tolerance;multi-tenancy;redundancy;service-based system,Fault tolerant systems;Streaming media;Runtime;Redundancy;Cloud computing;Business,cloud computing;integer programming;service-oriented architecture;software fault tolerance,optimal fault tolerance;criticality-based cost-effective fault tolerance;multi-tenant service-based systems;multidimensional quality preferences;cloud computing;Criticality-based Fault Tolerance for Multi-Tenant SBSs;CFT4MTS;end-to-end quality violations;runtime anomalies cost;service criticality;multitenancy;critical component services;Integer Programming problem,,7.0,,46.0,,13 Mar 2017,,,IEEE,IEEE Journals
1546,185,Spotify Guilds: How to Succeed With Knowledge Sharing in Large-Scale Agile Organizations,D. Smite; N. B. Moe; G. Levinta; M. Floryan,"Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; SINTEF, Trondheim, Norway; Spotify, Stockholm, Sweden; Spotify, Stockholm, Sweden",IEEE Software,21 Feb 2019,2019,36,2,51,57,"The new generation of software companies has revolutionized the way companies are designed. While bottom-up governance and team autonomy improve motivation, performance, and innovation, managing agile development at scale is a challenge. We describe how Spotify cultivates guilds to help the company share knowledge, align, and make collective decisions.",1937-4194,,10.1109/MS.2018.2886178,Swedish Knowledge Foundation; Research Council of Norway; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648260,,Information sharing;Agile software development;Standardization;Software development;Task analysis,knowledge management;project management;software development management;software engineering;software prototyping;team working,Spotify guilds;knowledge sharing;large-scale agile organizations;software companies;agile development;company share knowledge,,1.0,,5.0,,21 Feb 2019,,,IEEE,IEEE Magazines
1547,186,Reducing Software Developer Human Errors by Improving Situation Awareness,B. Nagaria; T. Hall,"Brunel University London, London, United Kingdom; Software Engineering, Lancaster University, Lancaster, United Kingdom",IEEE Software,23 Oct 2020,2020,37,6,32,37,"Software development is prone to errors, which are partially related to losing situation awareness. We recommend that developers know their own weaknesses, use cognitive training to manage those weaknesses, simplify their working environment, and communicate carefully with external stakeholders.",1937-4194,,10.1109/MS.2020.3014223,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157860,,Training;Software;Task analysis;Complexity theory;Syntactics;Stakeholders;Tools,cognition;risk analysis;software engineering,software developer human errors;software development;situation awareness;cognitive training;working environment;external stakeholders,,,,15.0,,4 Aug 2020,,,IEEE,IEEE Magazines
1548,187,Software-Intensive Product Engineering in Start-Ups: A Taxonomy,E. Klotins; M. Unterkalmsteiner; T. Gorschek,Blekinge Institute of Technology; Blekinge Institute of Technology; Blekinge Institute of Technology,IEEE Software,6 Jul 2018,2018,35,4,44,52,"Software start-ups are new companies aiming to launch an innovative product to mass markets fast with minimal resources. However, most start-ups fail before realizing their potential. Poor software engineering, among other factors, could be a significant contributor to the challenges that start-ups experience. Little is known about the engineering context in start-up companies. On the surface, start-ups are characterized by uncertainty, high risk, and minimal resources. However, such a characterization isn't granular enough to support identification of specific engineering challenges and to devise start-up-specific engineering practices. The first step toward an understanding of software engineering in start-ups is the definition of a Start-Up Context Map-a taxonomy of engineering practices, environment factors, and goals influencing the engineering process. This map aims to support further research on the field and serve as an engineering decision support tool for start-ups. This article is part of a theme issue on Process Improvement.",1937-4194,,10.1109/MS.2018.2801548,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405630,software-intensive product engineering;product engineering;Start-Up Context Map;start-ups;software engineering;software development,Software engineering;Market research;Context modeling;Market opportunities;Business;Software development management,decision support systems;DP industry;DP management;innovation management;project management;software development management;software process improvement,software-intensive product engineering;software start-ups;start-ups experience;start-up-specific engineering practices;software engineering;Start-Up Context Map;decision support tool;taxonomy;environmental factors;process improvement,,1.0,,26.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1549,188,An Empirical Study of Model-Agnostic Techniques for Defect Prediction Models,J. Jiarpakdee; C. Tantithamthavorn; H. K. Dam; J. Grundy,"Faculty of Information Technology, Monash University, Clayton, Victoria Australia 3800 (e-mail: jirayus.jiarpakdee@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: chakkrit@monash.edu); School of Computer Science and Software Engineering, University of Wollongong, Wollongong, New South Wales Australia 2522 (e-mail: hoa@uow.edu.au); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software analytics have empowered software organisations to support a wide range of improved decision-making and policy-making. However, such predictions made by software analytics to date have not been explained and justified. Specifically, current defect prediction models still fail to explain why models make such a prediction and fail to uphold the privacy laws in terms of the requirement to explain any decision made by an algorithm. In this paper, we empirically evaluate three model-agnostic techniques, i.e., two state-of-the-art Local Interpretability Model-agnostic Explanations technique (LIME) and BreakDown techniques, and our improvement of LIME with Hyper Parameter Optimisation (LIME-HPO). Through a case study of 32 highly-curated defect datasets that span across 9 open-source software systems, we conclude that (1) model-agnostic techniques are needed to explain individual predictions of defect models; (2) instance explanations generated by model-agnostic techniques are mostly overlapping (but not exactly the same) with the global explanation of defect models and reliable when they are re-generated; (3) model-agnostic techniques take less than a minute to generate instance explanations; and (4) more than half of the practitioners perceive that the contrastive explanations are necessary and useful to understand the predictions of defect models. Since the implementation of the studied model-agnostic techniques is available in both Python and R, we recommend model-agnostic techniques be used in the future.",1939-3520,,10.1109/TSE.2020.2982385,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9044387,Explainable Software Analytics;Software Quality Assurance;Defect Prediction Models;Model-Agnostic Techniques,Predictive models;Software;Analytical models;Software algorithms;Prediction algorithms;Electric breakdown;Software engineering,,,,5.0,,,,23 Mar 2020,,,IEEE,IEEE Early Access Articles
1550,189,LegacyPro—A DNA-Inspired Method for Identifying Process Legacies in Software Development Organizations,M. Ochodek; M. Staron; W. Meding; J. Bosch,"Poznan University of Technology, Poznan, Poland; Software Engineering, University of Gothenburg, Gothenburg, Sweden; Ericsson, Gothenburg, Sweden, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden",IEEE Software,26 Oct 2020,2020,37,6,76,85,This article presents a novel method for determining the factual adoption of new processes in software R&D organizations. We use a DNA-inspired analysis (motifs) to categorize parts and find similarities between projects using defect-inflow profiles.,1937-4194,,10.1109/MS.2020.2971894,Software Center www.software-center.se; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984294,Software metrics;process transformation;process improvement;SimSAX,Software;Time series analysis;Testing;Companies;DNA;Transforms,organisational aspects;research and development;software development management;software engineering;software maintenance,software development organizations;LegacyPro-A DNA-inspired method;software R&D organizations,,,,8.0,,5 Feb 2020,,,IEEE,IEEE Magazines
1551,190,Strategies for Competing in the Automotive Industry's Software Ecosystem: Standards and Bottlenecks,Y. Lichtenstein; S. Dujmovic; C. Baden-Fuller,"Cass Business School, University of London, United Kingdom; Robert Bosch GmbH; Cass Business School, University of London, United Kingdom",IEEE Software,16 Apr 2019,2019,36,3,45,49,"The automotive industry includes many actors engaged in software. This article focuses on the controlling position of car manufacturers in the automotive software ecosystem and suggests three strategies for software innovators: contesting, cooperating, and circumventing.",1937-4194,,10.1109/MS.2018.290105946,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409906,Computer Systems Organization;Communication;Networking and Information Technology;mobile computing;services computing;services lifecycle;service-oriented business models;application services and standards;industry-specific standards;general;case studies in industry,Software development management;Ecosystems;Automotive engineering;Software engineering;Ecosystems;Manufacturing processes,automobile industry;automobiles;automotive engineering;production engineering computing;software engineering,bottlenecks;car manufacturers;standards;automotive industry software ecosystem,,,,13.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1552,191,Who Can Maintain This Code?: Assessing the Effectiveness of Repository-Mining Techniques for Identifying Software Maintainers,G. Avelino; L. Passos; F. Petrillo; M. T. Valente,"Federal University of Piaui, Brazil; Software Engineering, Quantstamp Technologies, United States; Concordia University, United States; Computer Science, Federal University of Minas Gerais, Brazil",IEEE Software,22 Oct 2019,2019,36,6,34,42,"In large and complex systems, identifying developers capable of maintaining a piece of code is an essential task. Repository-mining techniques can help by providing some level of automation; however, whether such techniques effectively identify skilled software maintainers is still unclear.",1937-4194,,10.1109/MS.2018.185140155,Fundação de Amparo à Pesquisa do Estado de Minas Gerais; Conselho Nacional de Desenvolvimento Científico e Tecnológico; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328969,"Software;software engineering;management;programming teams;maintenance management;distribution, maintenance, and enhancement;software engineering",History;Object recognition;Open source software;Task analysis;Linear regression;Data mining,data mining;software maintenance,repository-mining techniques;skilled software maintainers,,1.0,,10.0,,30 Mar 2018,,,IEEE,IEEE Magazines
1553,192,Expert Perspectives on AI,A. D. Carleton; E. Harper; M. R. Lyu; S. Eldh; T. Xie; T. Menzies,"Software Engineering, Carnegie Mellon University; Software Engineering, Carnegie Mellon University; Computer Science and Engineering, The Chinese University of Hong Kong; Ericsson AB, Stockholm, Sweden; Computer Science and Technology, Peking University, China; North Carolina State University",IEEE Software,19 Jun 2020,2020,37,4,87,94,"IEEE Software: With the rapid changes occurring in the fields of artificial intelligence (AI) and machine learning (ML), what areas do you think are the most important to focus on right now, especially in relation to software engineering?",1937-4194,,10.1109/MS.2020.2987673,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121622,,Artificial intelligence;Software engineering;Industries;Task analysis;Magnetic heads;Software algorithms,,,,,,0.0,,19 Jun 2020,,,IEEE,IEEE Magazines
1554,193,Naming the Pain in Developing Scientific Software,I. Wiese; I. Polato; G. Pinto,"Computing, Federal University of Technology???Parana, Parana, Curitiba, Brazil; Computing, Federal University of Technology???Parana, Parana, Curitiba, Brazil; Computer Science, Federal University of Para, Para, Brazil",IEEE Software,19 Jun 2020,2020,37,4,75,82,"The scientific software community's lack of computer science background and software engineering training takes a toll on scientists who need to develop software. We built a taxonomy of 2,110 reported problems and grouped them into three major axes: technical-related, socialrelated, and scientific-related problems.",1937-4194,,10.1109/MS.2019.2899838,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664473,Scientific Software Developers;Pain points;Survey,Documentation;Programming;Software packages;Software engineering;Encoding,computer based training;computer science education;public domain software;software engineering,scientific software development;scientific software community;computer science;software engineering training;online learning platforms,,1.0,,12.0,,10 Mar 2019,,,IEEE,IEEE Magazines
1555,194,INTERO: An Interoperability Model for Large Systems,R. Spalazzese; P. Pelliccione; U. Eklund,"Computer Science and Media Technology, Malmo University; Computer Science and Engineering, Chalmers University of Technology; Computer Science, Malmo University",IEEE Software,15 Apr 2020,2020,37,3,38,45,"The INTERO (interoperability) model helps organizations manage and improve interoperability among their large, evolving software systems. They can analyze a specific interoperability problem, conceive strategies to enhance interoperability, and reevaluate the problem to determine whether interoperability has improved.",1937-4194,,10.1109/MS.2017.265100723,Software Center; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950888,D Software/Software Engineering;D.2 Software Engineering;D.2.12 Interoperability;D.2.2 Design Tools and Techniques;H Information Technology and Systems;H.1 Models and Principles,Interoperability;Large-scale systems;Software engineering;Standards;Protocols;Software development management,business data processing;open systems,evolving software systems;interoperability problem;interoperability model;INTERO model;large systems,,,,14.0,,16 Jun 2017,,,IEEE,IEEE Magazines
1556,195,AngularJS Performance: A Survey Study,M. Ramos; M. T. Valente; R. Terra,Federal University of Minas Gerais; Federal University of Minas Gerais; Federal University of Lavras,IEEE Software,12 Mar 2018,2018,35,2,72,79,"AngularJS is a popular JavaScript framework based on the model-view-controller pattern to construct single-page web apps. Researchers surveyed 95 professional developers regarding the performance problems of AngularJS applications. They determined the common practices the developers followed to avoid the problems (for example, using third-party or custom components), the problems' general causes (for example, inadequate application architectures), and the problems' technical causes (for example, unnecessary processing in the digest cycle, which is the internal computation that automatically updates the view with changes detected in the model).",1937-4194,,10.1109/MS.2017.265100610,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950843,AngularJS;development experience;software performance;software development;software engineering;web apps,Software reliability;Object recognition;Computer architecture;Performance evaluation;Mobile handsets;Software development management;Computer applications;Internet;Software engineering,Internet;Java;software performance evaluation,AngularJS performance;performance problems;AngularJS applications;custom components;JavaScript framework;model-view-controller pattern;single-page Web apps,,,,11.0,,16 Jun 2017,,,IEEE,IEEE Magazines
1557,196,"Correct, Efficient, and Tailored: The Future of Build Systems",G. Maudoux; K. Mens,Université catholique de Louvain; Université catholique de Louvain,IEEE Software,12 Mar 2018,2018,35,2,32,37,"Build systems are used in every nontrivial software project. They contain knowledge of how software is built and provide tools to get it built as fast as possible. While being central to day-to-day productivity, they sometimes fail to deliver their promise of being correct, efficient, and tailored. This situation gets aggravated with huge code bases and fast-paced continuous-integration pipelines. This article surveys state-of-the-art techniques and algorithms that relegate the occasional inconsistent build, slow execution times, and boilerplate makefiles to another age. This article is part of a special issue on release engineering.",1937-4194,,10.1109/MS.2018.111095025,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255774,build systems;release engineering;incremental builds;Bazel;Gradle;namespacing;sandboxing;DAG;directed acyclic graphs;software engineering;software development,Software tools;Object recognition;Software product lines;Product life cycle management;Software engineering,pipeline processing;software maintenance;software metrics,build systems;nontrivial software project;day-to-day productivity;huge code bases;occasional inconsistent build;fast-paced continuous-integration pipelines;boilerplate makefiles;release engineering,,1.0,,19.0,,12 Jan 2018,,,IEEE,IEEE Magazines
1558,197,Software Structures: A Careful Look,D. Lorge Parnas,McMaster University and the University of Limerick,IEEE Software,29 Nov 2018,2018,35,6,68,71,"In the half century since Edsger Dijkstra published “The Structure of the `THE'-Multiprogramming System,” it has become clear that the ability to design a software system's structure is at least as important as the ability to design efficient algorithms or write code in a particular programming language. Although the word “structure” appeared in the paper's title and was used seven more times, Dijkstra never defined the term. Closer examination revealed that he was discussing at least three distinct structures. His failure to define “structure,” or to clearly distinguish the structures that were important in his software, has led many to confuse those structures. This article aims to clarify what those structures are, their differences, and each one's importance.",1937-4194,,10.1109/MS.2018.4321239,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552620,module;program;component;process;software structures;uses;part-of;gives-work-to;Edsger Dijkstra;THE operating system;software engineering;software development;Reliable Code,Software engineering;Operating systems;Software development;Codes,multiprogramming;programming languages,software structures;Edsger Dijkstra;THE-Multiprogramming System;software system;particular programming language;word structure;closer examination;distinct structures,,2.0,,7.0,,29 Nov 2018,,,IEEE,IEEE Magazines
1559,198,Modular Architectures Make You Agile in the Long Run,D. Sturtevant,Silverthread,IEEE Software,25 Dec 2017,2018,35,1,104,108,"Researchers have developed ways to think about, visualize, and measure software modularity and its erosion objectively and quantifiably. Using these techniques, you'll be able to determine whether your software is modular and identify complexity hotspots in your code that warrant further investigation.",1937-4194,,10.1109/MS.2017.4541034,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239949,software architecture;agile programming;Design Structure Matrices;DevOps;software development;software engineering;On DevOps,Computer architecture;Complexity theory;Software engineering;Cognitive science;Visualization;Productivity,software architecture;software prototyping,software erosion;software modularity;modular architectures,,1.0,,8.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1560,199,What Do We (Really) Know about Test-Driven Development?,I. Karac; B. Turhan,University of Oulu; Brunel University,IEEE Software,6 Jul 2018,2018,35,4,81,85,Test-driven development (TDD) involves more than just testing before coding. This article examines how (and whether) TDD has lived up to its promises. Test-driven development (TDD) is one of the most controversial agile practices in terms of its impact on software quality and programmer productivity.,1937-4194,,10.1109/MS.2018.2801554,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405634,test-driven development;TDD;test-first;test-last;software development;software engineering,Productivity;Task analysis;Systematics;Software engineering;Testing;Software quality,program testing;software quality,test-driven development;TDD,,,,18.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1561,200,The Software Architect and DevOps,L. Bass,Carnegie Mellon University,IEEE Software,25 Dec 2017,2018,35,1,8,10,"DevOps practices deal with such things as the velocity of releases, how fast incidents are handled, and the enforcement of organizationally specified security practices. All these are critical for success in today's environment, and the architect is critical for success in adopting DevOps practices. This instalment of the Pragmatic Architect explains why.",1937-4194,,10.1109/MS.2017.4541051,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239924,software architect;software architecture;DevOps;continuous deployment;continuous delivery;traceability;software engineering;software development;The Pragmatic Architect,Software architecture;Software engineering;Software development;Computer security,security of data;software architecture;software development management;software quality,DevOps practices;fast incidents;software architect;Pragmatic Architect;organizationally specified security practices,,7.0,,4.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1562,201,"Agility, Risk, and Uncertainty, Part 1: Designing an Agile Architecture",M. Waterman,Specialised Architecture Services,IEEE Software,12 Mar 2018,2018,35,2,99,101,"Software architects in agile environments face the dilemma of determining how much effort goes into architecting up front, before development starts. This is an issue that agile methodologies and frameworks don't address and that's becoming more critical as agile development gets used for a wider range of problems. This article is the first of two that discuss findings of recent research based on the experiences of 44 agile practitioners, to help shed light on the problem.",1937-4194,,10.1109/MS.2018.1661335,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314169,agile development;agile architecture;software architecture;software development;software engineering;The Pragmatic Architect,Computer architecture;Agile software development;Decision making;Pragmatics;Software development management;Software engineering;Software architecture,software architecture;software prototyping,agile architecture;software architects;agile environments;agile methodologies;agile development,,2.0,,3.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1563,202,Software Refactoring for System Modernization,B. M. Santos; I. G. de Guzmán; V. V. de Camargo; M. Piattini; C. Ebert,Federal University of São Carlos; Universidad de Castilla-La Mancha; Federal University of São Carlos; Universidad de Castilla-La Mancha; Vector Consulting Services,IEEE Software,29 Nov 2018,2018,35,6,62,67,"Unlike their authors, software systems tend to live much longer than was ever intended or thought possible. Companies thus must modernize their software systems to keep them productive in new environments with new technology, within acceptable levels of costs. Refactoring tools can help with this process.",1937-4194,,10.1109/MS.2018.4321236,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552634,Architecture-Driven Modernization;ADM;legacy systems;Knowledge Discovery Metamodel;KDM;software tools;refactoring;refactoring tools;software engineering;software development;Software Technology,Software architecture;Software development;Software engineering;Knowledge discovery;Software tools,software maintenance;software tools,system modernization;software refactoring;refactoring tools;software systems,,,,5.0,,29 Nov 2018,,,IEEE,IEEE Magazines
1564,203,Ends and Means,G. J. Holzmann,Nimble Research,IEEE Software,25 Dec 2017,2018,35,1,14,17,"Even the smallest coding mistake can cause huge problems when it slips by testing. Finding it can be difficult, and retesting the fixed system can be expensive, but this certainly isn't true for every type of problem. A defect found and fixed during coding is a fairly routine occurrence and not costlier than a defect found and fixed during design. Quite the opposite is usually true.",1937-4194,,10.1109/MS.2017.4541029,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239938,software defects;root cause analysis;software development;software engineering;Reliable Code,Software engineering;Encoding;Software testing;Software reliability;Software measurement,program debugging;program testing,coding mistake;bug fixing;defect fixing;software testing,,,,3.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1565,204,Using Microservices for Legacy Software Modernization,H. Knoche; W. Hasselbring,Kiel University; Kiel University,IEEE Software,4 May 2018,2018,35,3,44,49,"Microservices are commonly known as an architecture for building scalable applications running in the cloud. However, they also promise high maintainability due to smaller code bases and strong component separation, making them an interesting option for software modernization. This article presents a migration process to decompose an existing application into microservices, and presents experiences from applying this process in an ongoing legacy modernization project.",1937-4194,,10.1109/MS.2018.2141035,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354422,microservices;web services;services modernization;software development;software engineering,Databases;Java;Software engineering;Computer architecture;Software development;Service computing;Web services,cloud computing;software maintenance,microservices;legacy software modernization;scalable applications;smaller code bases;migration process;legacy modernization project,,16.0,1.0,13.0,,4 May 2018,,,IEEE,IEEE Magazines
1566,205,"To Transform to Have Agility, Dont Do a Capital A, Capital T Agile Transformation",J. Smart,Barclays,IEEE Software,29 Nov 2018,2018,35,6,56,60,"This article presents antipatterns (and the corresponding patterns) based on the author's experience implementing agility at Barclays. In recent years, enterprise -wide DevOps and agile at scale have surged. Compared to nearly 30 years of ""lightweight methodologies"" for team -level software development, this is a new field. DevOps emerged as a term in 2009, with scaled agile frameworks coming out comparatively recently: SAFe (Scaled Agile Framework) in 2011, Disciplined Agile in 2012, and LeSS (Large Scale Scrum) in 2013. However, relatively little research is available about these frameworks' effectiveness in practice, especially on an enterprise scale.",1937-4194,,10.1109/MS.2018.4321245,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552621,agile transformation;agile development;agility;Barclays;DevOps;software engineering;software development;On DevOps,Software engineering;Software development;Agile software development,DP industry;project management;software development management;software prototyping;team working,agile transformation;enterprise-wide DevOps;team-level software development;agile frameworks;SAFe;Scaled Agile Framework;antipatterns,,1.0,,14.0,,29 Nov 2018,,,IEEE,IEEE Magazines
1567,206,Collaborative-Design Conflicts: Costs and Solutions,J. y. Bang; Y. Brun; N. Medvidović,Kakao Corporation; University of Massachusetts Amherst; University of Southern California,IEEE Software,29 Nov 2018,2018,35,6,25,31,"Collaborative design exposes software architects to the risk of making conflicting modeling changes that either can't be merged or, when merged, violate consistency rules, nonfunctional requirements, or other system constraints. Such design conflicts are common and incur a high cost, including having to redo and abandon work. Proactive conflict detection can alleviate this risk. This article motivates the need for design conflict detection, describes the benefits of such detection to practitioners, and identifies requirements for building detection tools. In particular, FLAME is a collaborative-design framework that efficiently and continuously detects design conflicts. This article is part of a theme issue on collaborative modeling.",1937-4194,,10.1109/MS.2018.290110057,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409920,proactive conflict detection;design;FLAME;Framework for Logging and Analyzing Modeling Events;software architecture;collaborative modeling;collaborative design;software development;software engineering,Collaboration;Analytical models;Software architecture;Collaborative software;Software development;Computational modeling;Software engineering,configuration management;groupware;product design;software architecture;source code (software),software architects;consistency rules;nonfunctional requirements;proactive conflict detection;design conflict detection;collaborative modeling;collaborative-design conflicts;FLAME,,,,13.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1568,207,Supporting Requirements-Engineering Research That Industry Needs: The NaPiRE Initiative,D. M. Fernández,Technical University of Munich,IEEE Software,25 Dec 2017,2018,35,1,112,116,The NaPiRE (Naming the Pain in Requirements Engineering) initiative aims to tackle the problem of conducting the requirements-engineering research that industry needs.,1937-4194,,10.1109/MS.2017.4541045,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239923,NaPiRE;Naming the Pain in Requirements Engineering;requirements engineering;software engineering;software development;agile software development,Software engineering;Software development;Requirements engineering;Information retrieval;Search problems,formal specification;formal verification,Naming the Pain in Requirements Engineering;NaPiRE Initiative;requirements-engineering research,,3.0,,8.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1569,208,Reconsidering Whether GOTO Is Harmful,M. Nagappan,University of Waterloo,IEEE Software,4 May 2018,2018,35,3,93,95,Is it always bad to use GOTO statements? An empirical analysis of open source C projects on GitHub suggests otherwise.,1937-4194,,10.1109/MS.2018.2141020,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354436,GOTO;GitHub;Edsger Dijkstra;software development;software engineering;Redirections,Open source software;Software engineering;Programming profession;Software reliability;Blogs,program control structures;public domain software,GOTO statements;empirical analysis;open source C projects;GitHub,,,,3.0,,4 May 2018,,,IEEE,IEEE Magazines
1570,209,Making Sense of Agile Methods,B. Meyer,Politecnico di Milano and Innopolis University,IEEE Software,12 Mar 2018,2018,35,2,91,94,"Bertrand Meyer runs agile methods and practices through his personal friend-or-foe test. He also offers his experiences and opinions about the hype, ugly, good, and even brilliant aspects of agile development.",1937-4194,,10.1109/MS.2018.1661325,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314168,agile development;Extreme Programming;XP;Scrum;pair programming;user stories;refactoring;branching;software development;software engineering;Insights,Software development management;Agile software development;Software engineering;Task analysis,cultural aspects;social aspects of automation;software prototyping,Bertrand Meyer;agile methods;opinions;ugly aspects;agile development;personal friend-or-foe test;good aspects;brilliant aspects,,3.0,,10.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1571,210,"Continuous Experimentation: Challenges, Implementation Techniques, and Current Research",G. Schermann; J. Cito; P. Leitner,University of Zurich; University of Zurich; Chalmers University of Technology,IEEE Software,12 Mar 2018,2018,35,2,26,31,"Continuous experimentation is an up-and-coming technique for requirements engineering and testing, particularly for web-based systems. On the basis of a practitioner survey, this article gives an overview of challenges, implementation techniques, and current research in the field. This article is part of a theme issue on release engineering.",1937-4194,,10.1109/MS.2018.111094748,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255793,release engineering;continuous experimentation;feature toggles;traffic routing;regression-driven experiments;business-driven experiments;software development;software engineering,Software engineering;Routing;Software testing;Data science;Computer architecture;Software product lines;Product life cycle management,formal specification;Internet;program testing;systems analysis,requirements engineering;Web-based systems,,8.0,,10.0,,12 Jan 2018,,,IEEE,IEEE Magazines
1572,211,The Interplay of Sampling and Machine Learning for Software Performance Prediction,C. Kaltenecker; A. Grebhahn; N. Siegmund; S. Apel,"Software Engineering, Saarland University, Saarbrucken, Saarland, Germany; Big Data Engineering, University of Passau, Berlin, Germany; Software Systems, Leipzig University, Germany; Software Engineering, Saarland University, Saarbrucken, Saarland, Germany",IEEE Software,19 Jun 2020,2020,37,4,58,66,"Artificial intelligence has gained considerable momentum in software engineering, but there are major challenges that make this domain special. We review recent advances, raise awareness of the distinctiveness of software configuration spaces, and provide practical guidelines for modeling, predicting, and optimizing performance.",1937-4194,,10.1109/MS.2020.2987024,Deutsche Forschungsgemeinschaft; Bundesministerium f??r Bildung und Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9062326,Configuration Management;Metrics/Measurement;Domain Engineering;Machine Learning;Modeling and Prediction,Machine learning;Software systems;Predictive models;Encryption;Computational modeling,learning (artificial intelligence);software performance evaluation,software performance prediction;artificial intelligence;software engineering;software configuration spaces;machine learning,,5.0,,19.0,,9 Apr 2020,,,IEEE,IEEE Magazines
1573,212,The Connection Between Burnout and Personality Types in Software Developers,E. Mellblom; I. Arason; L. Gren; R. Torkar,"Carmenta Geospatial Technologies, Gothenburg, Sweden; Software Engineering and Management, Gothenburg University, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden; Chalmers University of Technology, Gothenburg, Sweden",IEEE Software,15 Aug 2019,2019,36,5,57,64,This article examines the connection between the five-factor model personality traits and burnout in software developers and aims to validate generalizations of findings in other fields.,1937-4194,,10.1109/MS.2019.2924769,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745484,"Burnout;personality;five factor model,;software developers",Software development management;Stress;Software engineering;Sentiment analysis;Emotion recognition;Personnel,human factors;software development management,burnout;personality types;software developers;five-factor model personality traits,,1.0,,19.0,,25 Jun 2019,,,IEEE,IEEE Magazines
1574,213,DevOps and Organisational Performance: The Fallacy of Chasing Maturity,C. Marnewick; J. Langerman,"Applied Information Systems, University of Johannesburg College of Business and Economics, Auckland Park, Gauteng, South Africa; Academy of Computer Science and Software Engineering, University of Johannesburg, Auckland Park, Gauteng, South Africa",IEEE Software,,2020,PP,99,0,0,"Maturity models are perceived as aiding organizations to perform better. This is also true of DevOps maturity models. The question is whether DevOps maturity models also improve organisational performance. A case study approach was used to determine the impact of DevOps maturity on organisational performance. The results indicate that although maturity models improve DevOps processes, they in themselves do not improve organisational performance. Organisations need to use DevOps maturity models in association with other drivers such as scaling agile and a change in organisational culture to improve performance. This article contributes to the current debate on the value of DevOps maturity models and provides alternative insights.",1937-4194,,10.1109/MS.2020.3023298,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190017,,Stability analysis;Throughput;Software;Measurement;Business;Analytical models;Software engineering,,,,,,,,9 Sep 2020,,,IEEE,IEEE Early Access Articles
1575,214,Scale Your Team Horizontally,G. Fairbanks,"Software Engineering, Google",IEEE Software,17 Jun 2019,2019,36,4,88,90,"Not long ago, when your company became successful, you bought a bigger computer to run your software. We called this scaling vertically. Today, that is less common, in part because we have gotten quite good at scaling horizontally so when your company becomes successful, it buys more of the same-sized computers.",1937-4194,,10.1109/MS.2019.2909766,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738150,,Planning;Software engineering;Team working;Organizational aspects,team working,same-sized computers;vertical scaling;horizontal scaling,,,,4.0,,17 Jun 2019,,,IEEE,IEEE Magazines
1576,215,Software Components,G. J. Holzmann,Nimble Research,IEEE Software,4 May 2018,2018,35,3,80,82,Software components have come a long way since Doug McIlroy first called for them in 1968.,1937-4194,,10.1109/MS.2018.2141034,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354432,software components;Doug McIlroy;software development;software engineering;Reliable Code,Software development;Standards;Encoding;Software reliability;Computer bugs,software reusability,software components;software engineering;software design;mass-produced software parts,,,,4.0,,4 May 2018,,,IEEE,IEEE Magazines
1577,216,A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction,Q. Song; Y. Guo; M. Shepperd,"Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Department of Computer Science, Brunel University, Uxbridge, Middlesex, United Kingdom",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1253,1269,"Context: Software defect prediction (SDP) is an important challenge in the field of software engineering, hence much research work has been conducted, most notably through the use of machine learning algorithms. However, class-imbalance typified by few defective components and many non-defective ones is a common occurrence causing difficulties for these methods. Imbalanced learning aims to deal with this problem and has recently been deployed by some researchers, unfortunately with inconsistent results. Objective: We conduct a comprehensive experiment to explore (a) the basic characteristics of this problem; (b) the effect of imbalanced learning and its interactions with (i) data imbalance, (ii) type of classifier, (iii) input metrics and (iv) imbalanced learning method. Method: We systematically evaluate 27 data sets, 7 classifiers, 7 types of input metrics and 17 imbalanced learning methods (including doing nothing) using an experimental design that enables exploration of interactions between these factors and individual imbalanced learning algorithms. This yields 27 × 7 × 7 × 17 = 22491 results. The Matthews correlation coefficient (MCC) is used as an unbiased performance measure (unlike the more widely used F1 and AUC measures). Results: (a) we found a large majority (87 percent) of 106 public domain data sets exhibit moderate or low level of imbalance (imbalance ratio <; 10; median = 3.94); (b) anything other than low levels of imbalance clearly harm the performance of traditional learning for SDP; (c) imbalanced learning is more effective on the data sets with moderate or higher imbalance, however negative results are always possible; (d) type of classifier has most impact on the improvement in classification performance followed by the imbalanced learning method itself. Type of input metrics is not influential. (e) only 52% of the combinations of Imbalanced Learner and Classifier have a significant positive effect. Conclusion: This paper offers two practical guidelines. First, imbalanced learning should only be considered for moderate or highly imbalanced SDP data sets. Second, the appropriate combination of imbalanced method and classifier needs to be carefully chosen to ameliorate the imbalanced learning problem for SDP. In contrast, the indiscriminate application of imbalanced learning can be harmful.",1939-3520,,10.1109/TSE.2018.2836442,National Natural Science Foundation of China; Brunel University London; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359087,Software defect prediction;bug prediction;imbalanced learning;imbalance ratio;effect size,Software measurement;Boosting;Machine learning algorithms;Bagging;Computer bugs,learning (artificial intelligence);pattern classification;program diagnostics;sampling methods;software engineering,software defect prediction;machine learning algorithms;input metrics;imbalanced learning method;individual imbalanced learning algorithms;traditional learning;moderate imbalanced SDP data sets;highly imbalanced SDP data sets;imbalanced learning problem,,19.0,,92.0,IEEE,15 May 2018,,,IEEE,IEEE Journals
1578,217,"Fault Analysis and Debugging of Microservice Systems: Industrial Survey, Benchmark System, and Empirical Study",X. Zhou; X. Peng; T. Xie; J. Sun; C. Ji; W. Li; D. Ding,"School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; University of Illinois at Urbana-Champaign, Urbana, IL, USA; Singapore University of Technology and Design, Singapore; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,243,260,"The complexity and dynamism of microservice systems pose unique challenges to a variety of software engineering tasks such as fault analysis and debugging. In spite of the prevalence and importance of microservices in industry, there is limited research on the fault analysis and debugging of microservice systems. To fill this gap, we conduct an industrial survey to learn typical faults of microservice systems, current practice of debugging, and the challenges faced by developers in practice. We then develop a medium-size benchmark microservice system (being the largest and most complex open source microservice system within our knowledge) and replicate 22 industrial fault cases on it. Based on the benchmark system and the replicated fault cases, we conduct an empirical study to investigate the effectiveness of existing industrial debugging practices and whether they can be further improved by introducing the state-of-the-art tracing and visualization techniques for distributed systems. The results show that the current industrial practices of microservice debugging can be improved by employing proper tracing and visualization techniques and strategies. Our findings also suggest that there is a strong need for more intelligent trace analysis and visualization, e.g., by combining trace visualization and improved fault localization, and employing data-driven and learning-based recommendation for guided visual exploration and comparison of traces.",1939-3520,,10.1109/TSE.2018.2887384,National Key Research and Development Program of China; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580420,Microservices;fault localization;tracing;visualization;debugging,Debugging;Benchmark testing;Companies;Computer architecture;Visualization;Industries;Runtime,data visualisation;fault diagnosis;learning (artificial intelligence);program debugging;program testing;software architecture;software engineering;software fault tolerance,22 industrial fault cases;most complex open source microservice system;largest source microservice system;medium-size benchmark microservice system;typical faults;fault analysis;benchmark system;industrial survey;microservice systems;microservice debugging;current industrial practices;distributed systems;industrial debugging practices;replicated fault cases,,16.0,,67.0,IEEE,18 Dec 2018,,,IEEE,IEEE Journals
1579,218,Quotes from IEEE Software History,Ž. Obrenović,Software Improvement Group,IEEE Software,27 Sep 2018,2018,35,5,10,13,"This alternative view of IEEE Software history presents quotes organized in conversations. Each conversation pairs a quote from the magazine’s early days (1984–1990) with a more contemporary quote, with at least 20 years between the two. The aim is to illustrate that some key ideas and topics are classic and have value even decades later. Additional pairs of quotes are available in the Web Extra at https://extras.computer.org/extra/mso2018050010s1.pdf. This article is part of a theme issue on software engineering’s 50th anniversary.",1937-4194,,10.1109/MS.2018.3571243,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474517,IEEE Software;software engineering;software development;Conversations with the Past,IEEE publishing;History,,,,,,,,27 Sep 2018,,,IEEE,IEEE Magazines
1580,219,Nicolai Parlog on Java 9 Modules,N. Black,Sleeperbot,IEEE Software,4 May 2018,2018,35,3,101,104,"In this excerpt from a Software Engineering Radio episode, Nick Black talks with Nicolai Parlog about Java 9—specifically, the why and how of the module system.",1937-4194,,10.1109/MS.2018.2141025,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354430,Nicolai Parlog;Java 9;JAR;Java archives;Java Platform Module System;JPMS;Java modules;Software Engineering Radio;software engineering;software development,Java;Runtime;Interviews;Software development,,,,1.0,,,,4 May 2018,,,IEEE,IEEE Magazines
1581,220,Automatic Identification and Classification of Software Development Video Tutorial Fragments,L. Ponzanelli; G. Bavota; A. Mocci; R. Oliveto; M. D. Penta; S. Haiduc; B. Russo; M. Lanza,"Università della Svizzera italiana (USI), Lugano, 6900, Switzerland; Università della Svizzera italiana (USI), Lugano, 6900, Switzerland; Università della Svizzera italiana (USI), Lugano, 6900, Switzerland; University of Molise, Pesche (IS), Campobasso, Italy; University of Sannio, Benevento, Italy; Florida State University, Tallahassee, FL; Free University of Bozen-Bolzano, Bolzano, Italy; Università della Svizzera italiana (USI), Lugano, 6900, Switzerland",IEEE Transactions on Software Engineering,21 May 2019,2019,45,5,464,488,"Software development video tutorials have seen a steep increase in popularity in recent years. Their main advantage is that they thoroughly illustrate how certain technologies, programming languages, etc. are to be used. However, they come with a caveat: there is currently little support for searching and browsing their content. This makes it difficult to quickly find the useful parts in a longer video, as the only options are watching the entire video, leading to wasted time, or fast-forwarding through it, leading to missed information. We present an approach to mine video tutorials found on the web and enable developers to query their contents as opposed to just their metadata. The video tutorials are processed and split into coherent fragments, such that only relevant fragments are returned in response to a query. Moreover, fragments are automatically classified according to their purpose, such as introducing theoretical concepts, explaining code implementation steps, or dealing with errors. This allows developers to set filters in their search to target a specific type of video fragment they are interested in. In addition, the video fragments in CodeTube are complemented with information from other sources, such as Stack Overflow discussions, giving more context and useful information for understanding the concepts.",1939-3520,,10.1109/TSE.2017.2779479,Swiss National Science foundation; Swiss National Science foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128506,Recommender systems;mining unstructured data;video tutorials,Tutorials;Java;Software;YouTube;Indexes;Androids;Humanoid robots,computer aided instruction;data mining;Internet;meta data;pattern classification;query processing;software engineering;video signal processing,CodeTube;video tutorials mining;video fragment;software development video tutorials;automatic identification,,4.0,,77.0,,4 Dec 2017,,,IEEE,IEEE Journals
1582,221,Microtask Programming,T. D. LaToza; A. Di Lecce; F. Ricci; W. B. Towne; A. van der Hoek,"Department of Computer Science, George Mason University, Fairfax, VA; Cuebiq Srl, Milano, Italy; Bosch Rexroth, Milan, Italy; Carnegie Mellon University, Pittsburgh, PA; Department of Informatics, University of California, Irvine, Irvine, CA",IEEE Transactions on Software Engineering,13 Nov 2019,2019,45,11,1106,1124,"Traditional forms of Crowdsourcing such as open source software development harness crowd contributions to democratize the creation of software. However, potential contributors must first overcome joining barriers forcing casually committed contributors to spend days or weeks onboarding and thereby reducing participation. To more effectively harness potential contributions from the crowd, we propose a method for programming in which work occurs entirely through microtasks, offering contributors short, self-contained tasks such as implementing part of a function or updating a call site invoking a function to match a change made to the function. In microtask programming, microtasks involve changes to a single artifact, are automatically generated as necessary by the system, and nurture quality through iteration. A study examining the feasibility of microtask programming to create small programs found that developers were able to complete 1008 microtasks, onboard and submit their first microtask in less than 15 minutes, complete all types of microtasks in less than 5 minutes on average, and create 490 lines of code and 149 unit tests. The results demonstrate the potential feasibility as well as revealing a number of important challenges to address to successfully scale microtask programming to larger and more complex programs.",1939-3520,,10.1109/TSE.2018.2823327,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331909,Programming environments;management,Programming;Task analysis;Crowdsourcing;Programming environments;Public domain software;Collaborative software,groupware;public domain software;software engineering,open source software development;potential contributors;potential contributions;microtask programming;complex programs;crowd contributions,,2.0,,49.0,,5 Apr 2018,,,IEEE,IEEE Journals
1583,222,Mining Fix Patterns for FindBugs Violations,K. Liu; D. Kim; T. F. Bissyandé; S. Yoo; Y. Le Traon,"Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; School of Computing, KAIST, Daejeon, Republic of Korea; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,165,188,"Several static analysis tools, such as Splint or FindBugs, have been proposed to the software development community to help detect security vulnerabilities or bad programming practices. However, the adoption of these tools is hindered by their high false positive rates. If the false positive rate is too high, developers may get acclimated to violation reports from these tools, causing concrete and severe bugs being overlooked. Fortunately, some violations are actually addressed and resolved by developers. We claim that those violations that are recurrently fixed are likely to be true positives, and an automated approach can learn to repair similar unseen violations. However, there is lack of a systematic way to investigate the distributions on existing violations and fixed ones in the wild, that can provide insights into prioritizing violations for developers, and an effective way to mine code and fix patterns which can help developers easily understand the reasons of leading violations and how to fix them. In this paper, we first collect and track a large number of fixed and unfixed violations across revisions of software. The empirical analyses reveal that there are discrepancies in the distributions of violations that are detected and those that are fixed, in terms of occurrences, spread and categories, which can provide insights into prioritizing violations. To automatically identify patterns in violations and their fixes, we propose an approach that utilizes convolutional neural networks to learn features and clustering to regroup similar instances. We then evaluate the usefulness of the identified fix patterns by applying them to unfixed violations. The results show that developers will accept and merge a majority (69/116) of fixes generated from the inferred fix patterns. It is also noteworthy that the yielded patterns are applicable to four real bugs in the Defects4J major benchmark for software testing and automated repair.",1939-3520,,10.1109/TSE.2018.2884955,"Fonds National de la Recherche Luxembourg; National Research Foundation of Korea; Ministry of Science, ICT; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565907,Fix pattern;pattern mining;program repair;findbugs violation;unsupervised learning,Tools;Static analysis;Computer bugs;Maintenance engineering;Software;Java;Security,data mining;inference mechanisms;learning (artificial intelligence);neural nets;program debugging;program diagnostics;program testing;public domain software;security of data;software engineering;software maintenance;software quality,FindBugs violations;static analysis tools;software development community;high false positive rates;false positive rate;violation reports;similar unseen violations;prioritizing violations;leading violations;unfixed violations;fixes;identified fix patterns;inferred fix patterns;mining fix patterns,,3.0,,108.0,IEEE,6 Dec 2018,,,IEEE,IEEE Journals
1584,223,Control-Theoretical Software Adaptation: A Systematic Literature Review,S. Shevtsov; M. Berekmeri; D. Weyns; M. Maggio,"Linnaeus University, Växjö, Sweden; Grenoble Institute of Technology, Grenoble, France; Katholieke Universiteit Leuven, Leuven, Belgium; Lund University, Lund, Sweden",IEEE Transactions on Software Engineering,13 Aug 2018,2018,44,8,784,810,"Modern software applications are subject to uncertain operating conditions, such as dynamics in the availability of services and variations of system goals. Consequently, runtime changes cannot be ignored, but often cannot be predicted at design time. Control theory has been identified as a principled way of addressing runtime changes and it has been applied successfully to modify the structure and behavior of software applications. Most of the times, however, the adaptation targeted the resources that the software has available for execution (CPU, storage, etc.) more than the software application itself. This paper investigates the research efforts that have been conducted to make software adaptable by modifying the software rather than the resource allocated to its execution. This paper aims to identify: the focus of research on control-theoretical software adaptation; how software is modeled and what control mechanisms are used to adapt software; what software qualities and controller guarantees are considered. To that end, we performed a systematic literature review in which we extracted data from 42 primary studies selected from 1,512 papers that resulted from an automatic search. The results of our investigation show that even though the behavior of software is considered non-linear, research efforts use linear models to represent it, with some success. Also, the control strategies that are most often considered are classic control, mostly in the form of Proportional and Integral controllers, and Model Predictive Control. The paper also discusses sensing and actuating strategies that are prominent for software adaptation and the (often neglected) proof of formal properties. Finally, we distill open challenges for control-theoretical software adaptation.",1939-3520,,10.1109/TSE.2017.2704579,Assurances for Decentralized Self-Adaptive Systems Vetenskapsradet Sweden; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7929422,Self-adaptive software;control theory;software adaptation,Software;Control theory;Adaptation models;Runtime;Bibliographies;Mathematical model;Knowledge based systems,predictive control;resource allocation;reverse engineering;software engineering;software performance evaluation;software quality,control-theoretical software adaptation;systematic literature review;modern software applications;runtime changes;software application;software adaptable;software qualities;model predictive control,,5.0,,116.0,,16 May 2017,,,IEEE,IEEE Journals
1585,224,Predicting Future Developer Behavior in the IDE Using Topic Models,K. Damevski; H. Chen; D. C. Shepherd; N. A. Kraft; L. Pollock,"Department of Computer Science, Virginia Commonwealth University, Richmond, VA; Department of Computer and Information Science, University of New York, Brooklyn, NY; ABB Corporate Research, Raleigh, NC; ABB Corporate Research, Raleigh, NC; Department of Computer and Information Sciences, University of Delaware, Newark, DE",IEEE Transactions on Software Engineering,11 Nov 2018,2018,44,11,1100,1111,"While early software command recommender systems drew negative user reaction, recent studies show that users of unusually complex applications will accept and utilize command recommendations. Given this new interest, more than a decade after first attempts, both the recommendation generation (backend) and the user experience (frontend) should be revisited. In this work, we focus on recommendation generation. One shortcoming of existing command recommenders is that algorithms focus primarily on mirroring the short-term past,-i.e., assuming that a developer who is currently debugging will continue to debug endlessly. We propose an approach to improve on the state of the art by modeling future task context to make better recommendations to developers. That is, the approach can predict that a developer who is currently debugging may continue to debug OR may edit their program. To predict future development commands, we applied Temporal Latent Dirichlet Allocation, a topic model used primarily for natural language, to software development interaction data (i.e., command streams). We evaluated this approach on two large interaction datasets for two different IDEs, Microsoft Visual Studio and ABB Robot Studio. Our evaluation shows that this is a promising approach for both predicting future IDE commands and producing empirically-interpretable observations.",1939-3520,,10.1109/TSE.2017.2748134,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024001,Command recommendation systems;IDE interaction data,Natural languages;Data models;Analytical models;Predictive models;Visualization;Adaptation models;Data analysis,program debugging;recommender systems;software engineering,future developer behavior;early software command recommender systems;negative user reaction;unusually complex applications;command recommendations;recommendation generation;user experience;command recommenders;future task context;debug OR;future development commands;software development interaction data;predicting future IDE commands;empirically-interpretable observations,,6.0,,33.0,,1 Sep 2017,,,IEEE,IEEE Journals
1586,225,A Study of Bug Resolution Characteristics in Popular Programming Languages,J. Zhang; F. Li; D. Hao; M. Wang; H. Tang; L. Zhang; M. Harman,"Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: jie.zhang@ucl.ac.uk); Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: lifeng2014@pku.edu.cn); EECS,Peking University, Institute of Software, Beijing, Beijing China 100871 (e-mail: haodan@pku.edu.cn); Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: meng.wang@bristol.ac.uk); Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: tanghaoth90@pku.edu.cn); EECS,Peking University, Institute of Software, Beijing, Beijing China (e-mail: zhanglucs@pku.edu.cn); CS, Facebook London, 507852 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: mark.harman@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Bug resolution is an essential part of software development. The impact of programming language on bug resolution has been a topic of much debate. Taking Python as an example, some hold the view that bugs in the language are easy to handle because its code is easy to read and understand, while others believe that the absence of static typing leads to more bug-handling effort. This paper presents the first large-scale study that investigates the connection between programming language and bug resolution characteristics. It follows the recent trend of empirical scientific reformulation of long-standing, but hitherto anecdotal, `great debates' about the influence of programming language and paradigm on software engineering concerns. We analyse bug resolution data from over 70 million SLOC drawn from 3 million commits to 600 GitHub projects in 10 languages. The results suggest that statistically significant differences in resolution time and patch size exist between different languages and language categories. In particular, Java bug resolution consumes less elapsed time from raise to resolve, while Ruby consumes more. We also found that patches tend to touch significantly more files for strongly typed and for static languages (as one might expect given the need to maintain type annotations). However, despite this apparent extra effort, we found evidence for a significantly lower elapsed resolution time for bug resolution committed to projects constructed from statically typed languages. This finding sheds further empirical light on the debate about the importance of static typing. Indeed, more generally, we found no evidence for any correlation between bug-resolution time and size (lines or files touched), nor any evidence for correlation with other potential confounding factors, such as problem features (e.g., size, age, and commit number) and target domain.",1939-3520,,10.1109/TSE.2019.2961897,Royal Society IES; Newton Advanced Fellowships; National Natural Science Foundation of China; ERC advanced grant; the National Key Research and Development Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941305,program language;bug resolution;empirical study,Computer bugs;Software engineering;Java;Correlation;Software;Data mining,,,,,,,CCBY,24 Dec 2019,,,IEEE,IEEE Early Access Articles
1587,226,A Comparison of Program Comprehension Strategies by Blind and Sighted Programmers,A. Armaly; P. Rodeghero; C. McMillan,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN",IEEE Transactions on Software Engineering,13 Aug 2018,2018,44,8,712,724,"Programmers who are blind use a screen reader to speak source code one word at a time, as though the code were text. This process of reading is in stark contrast to sighted programmers, who skim source code rapidly with their eyes. At present, it is not known whether the difference in these processes has effects on the program comprehension gained from reading code. These effects are important because they could reduce both the usefulness of accessibility tools and the generalizability of software engineering studies to persons with low vision. In this paper, we present an empirical study comparing the program comprehension of blind and sighted programmers. We found that both blind and sighted programmers prioritize reading method signatures over other areas of code. Both groups obtained an equal and high degree of comprehension, despite the different reading processes.",1939-3520,,10.1109/TSE.2017.2729548,National Science Foundation Graduate Research Fellowship Program; US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987041,Program comprehension;accessibility technology;blindness,Tools;Software;Blindness;Navigation;Programming profession;Software engineering,programming environments;public domain software;software prototyping;source code (software),source code;sighted programmers;program comprehension strategies;reading processes;stark;program comprehension;reading method signature,,2.0,,46.0,,20 Jul 2017,,,IEEE,IEEE Journals
1588,227,Property Satisfiability Analysis for Product Lines of Modelling Languages,E. Guerra; J. de Lara; M. Chechik; R. Salay,"Computer Science, Universidad Autnoma de Madrid, Madrid, Madrid Spain (e-mail: esther.guerra@uam.es); Ingeniera Informtica, Universidad Autnoma de Madrid, Madrid, Madrid Spain 28049 (e-mail: juan.delara@uam.es); Department of Computer Science, University of Toronto, Toronto, Ontario Canada M5S2E4 (e-mail: chechik@cs.toronto.edu); Computer Science, University of Toronto, 7938 Toronto, Ontario Canada M5S 3G4 (e-mail: rsalay@cs.toronto.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software engineering uses models throughout most phases of the development process. Models are defined using modelling languages. To make these languages applicable to a wider set of scenarios and customizable to specific needs, researchers have proposed using product lines to specify modelling language variants. However, there is currently a lack of efficient techniques for ensuring correctness with respect to properties of the models accepted by a set of language variants. This may prevent detecting problematic combinations of language variants that produce undesired effects at the model level. To attack this problem, we first present a classification of instantiability properties for language product lines. Then, we propose a novel approach to lifting the satisfiability checking of model properties of individual language variants, to the product line level. Finally, we report on an implementation of our proposal in the Merlin tool, and demonstrate the efficiency gains of our lifted analysis method compared to an enumerative analysis of each individual language variant.",1939-3520,,10.1109/TSE.2020.2989506,Ministerio de Ciencia y Tecnologa; Consejera de Educacin Juventud y Deporte Comunidad de Madrid; Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076306,Model-Driven Engineering;Software Language Engineering;Product Lines;Meta-Modelling;OCL;Model Finding,Unified modeling language;Analytical models;Petri nets;Syntactics;Tools;Programmable logic arrays;Software engineering,,,,,,,,22 Apr 2020,,,IEEE,IEEE Early Access Articles
1589,228,A Multi-Study Investigation into Dead Code,S. Romano; C. Vendome; G. Scanniello; D. Poshyvanyk,"University of Basilicata, Potenza, PZ, Italy; College of William and Mary, Williamsburg, VA; University of Basilicata, Potenza, PZ, Italy; College of William and Mary, Williamsburg, VA",IEEE Transactions on Software Engineering,8 Jan 2020,2020,46,1,71,99,"Dead code is a bad smell and it appears to be widespread in open-source and commercial software systems. Surprisingly, dead code has received very little empirical attention from the software engineering research community. In this paper, we present a multi-study investigation with an overarching goal to study, from the perspective of researchers and developers, when and why developers introduce dead code, howthey perceive and cope with it, and whether dead code is harmful. To this end, we conducted semi-structured interviews with software professionals and four experiments at the University of Basilicata and the College of William & Mary. The results suggest that it is worth studying dead code not only in the maintenance and evolution phases, where our results suggest that dead code is harmful, but also in the design and implementation phases. Our results motivate future work to develop techniques for detecting and removing dead code and suggest that developers should avoid this smell.",1939-3520,,10.1109/TSE.2018.2842781,NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370748,Dead code;unreachable code;unused code;bad smell;empirical investigation;multi-study,Software systems;Maintenance engineering;Software engineering;Interviews;Tools;Open source software,software maintenance,dead code;multistudy investigation;bad smell;commercial software systems;open-source software systems,,4.0,,51.0,IEEE,1 Jun 2018,,,IEEE,IEEE Journals
1590,229,A Study of Call Graph Construction for JVM-Hosted Languages,K. Ali; X. Lai; Z. Luo; O. Lhotak; J. Dolby; F. Tip,"Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada T6G 2R3 (e-mail: karim.ali@ualberta.ca); N/A, Google, Waterloo, Ontario Canada (e-mail: xlai@google.com); N/A, Microsoft Corp, 6834 Redmond, Washington United States (e-mail: zhaoyi.luo@microsoft.com); David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario Canada (e-mail: olhotak@uwaterloo.ca); Software Technology, IBM T.J. Watson Research Center, Yorktown Heights, New York United States 10598 (e-mail: dolby@us.ibm.com); Khoury College of Computer Sciences, Northeastern University, Boston, Massachusetts United States (e-mail: f.tip@northeastern.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Call graphs have many applications in software engineering, including bug-finding, security analysis, and code navigation in IDEs. However, the construction of call graphs requires significant investment in program analysis infrastructure. An increasing number of programming languages compile to the Java Virtual Machine (JVM), and program analysis frameworks such as WALA and SOOT support a broad range of program analysis algorithms by analyzing JVM bytecode. This approach has been shown to work well when applied to bytecode produced from Java code. In this paper, we show that it also works well for diverse other JVM-hosted languages: dynamically-typed functional Scheme, statically-typed object-oriented Scala, and polymorphic functional OCaml. Effectively, we get call graph construction for these languages for free, using existing analysis infrastructure for Java, with only minor challenges to soundness. This, in turn, suggests that bytecode-based analysis could serve as an implementation vehicle for bug-finding, security analysis, and IDE features for these languages. We present qualitative and quantitative analyses of the soundness and precision of call graphs constructed from JVM bytecodes for these languages, and also for Groovy, Clojure, Python, and Ruby. However, we also show that implementation details matter greatly. In particular, the JVM-hosted implementations of Groovy, Clojure, Python, and Ruby produce very unsound call graphs, due to the pervasive use of reflection, invokedynamic instructions, and run-time code generation. Interestingly, the dynamic translation schemes employed by these languages, which result in unsound static call graphs, tend to be correlated with poor performance at run time.",1939-3520,,10.1109/TSE.2019.2956925,Natural Sciences and Engineering Research Council of Canada; Office of Naval Research; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944149,Call graphs;static analysis;JVM;compilation;Scheme;Scala;OCaml;Groovy;Clojure;Python;Ruby,Java;Static analysis;Python;Security;Vehicle dynamics;Software engineering,,,,2.0,,,CCBY,27 Dec 2019,,,IEEE,IEEE Early Access Articles
1591,230,"How to ""DODGE"" Complex Software Analytics",A. Agrawal; W. Fu; D. Chen; X. Shen; T. Menzies,"Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: aagrawa8@ncsu.edu); Department of Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: wfu@ncsu.edu); Computer Science, Facebook Inc, 342996 Menlo Park, California United States (e-mail: dchen20@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: xshen5@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Machine learning techniques applied to software engineering tasks can be improved by hyperparameter optimization, i.e., automatic tools that find good settings for a learner's control parameters. We show that such hyperparameter optimization can be unnecessarily slow, particularly when the optimizers waste time exploring ""redundant tunings"", i.e., pairs of tunings which lead to indistinguishable results. By ignoring redundant tunings, DODGE, a tuning tool, runs orders of magnitude faster, while also generating learners with more accurate predictions than seen in prior state-of-the-art approaches.",1939-3520,,10.1109/TSE.2019.2945020,Directorate for Computer and Information Science and Engineering; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854183,Software analytics;hyperparameter optimization;defect prediction;text mining,Tuning;Text mining;Software;Task analysis;Optimization;Software engineering;Tools,,,,5.0,,,,1 Oct 2019,,,IEEE,IEEE Early Access Articles
1592,231,"Requirements, Politics, or Individualism: What Drives the Success of COVID-19 Contact-Tracing Apps?",M. Bano; D. Zowghi; C. Arora,"Software Engineering, Deakin University, Australia; Software Engineering, University of Technology Sydney, Australia; Software Engineering, Deakin University, Australia",IEEE Software,23 Dec 2020,2021,38,1,7,12,"The year 2020 brought us the global pandemic of COVID-19, which is not just a health crisis but a disruption to the fabric of society around the world. With no vaccine yet approved, other measures have been taken all over the world related to lockdowns, social distancing, and contact tracing to quarantine the infected individuals and suppress community transmission. The numerous challenges presented by this novel coronavirus, such as the incubation period, various symptoms, and asymptomatic superspreaders, have exacerbated the challenges of manual contact tracing.",1937-4194,,10.1109/MS.2020.3029311,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305893,,COVID-19;Pandemics;Government,diseases;epidemics;medical information systems;microorganisms;politics,COVID-19 contact-tracing apps;global pandemic;health crisis;social distancing;infected individuals;manual contact tracing;politics;individualism;community transmission suppression;asymptomatic superspreaders,,1.0,,10.0,IEEE,23 Dec 2020,,,IEEE,IEEE Magazines
1593,232,Hybrid Software Development Approaches in Practice: A European Perspective,M. Kuhrmann; P. Diebold; J. Munch; P. Tell; K. Trektere; F. McCaffery; V. Garousi; M. Felderer; O. Linssen; E. Hanser; C. R. Prause,"Applied Software Systems Engineering, Clausthal University of Technology; Bagilstein GmbH; Software Engineering, Reutlingen University; Computer Science, IT University of Copenhagen; Regulated Software, Dundalk Institute of Technology; Regulated Software, Dundalk Institute of Technology; Software Engineering, Wageningen University; Computer Science, University of Innsbruck; FOM University of Applied Sciences for Economics and Management; Software Engineering, Baden-Wuerttemberg Cooperative State University; Software Quality Assurance, German Aerospace Center Space Administration",IEEE Software,17 Jun 2019,2019,36,4,20,31,The surveyed companies applied hybrid development approaches to specific projects even when company-wide policies for process usage existed. These approaches emerged from the evolution of different work practices and were consistently used regardless of company size or industry sector.,1937-4194,,10.1109/MS.2018.110161245,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254323,computing milieux;management of computing and information systems;software management;software process;software development method;software development practice;agile practices;traditional development approach;hybrid development approach,Software development;Software development management;Software process;Agile software development;Organizational aspects,organisational aspects;software development management,company-wide policies;process usage;hybrid software development approaches;hybrid development approaches;work practices;European perspective,,3.0,,15.0,,11 Jan 2018,,,IEEE,IEEE Magazines
1594,233,An Overview and Comparison of Technical Debt Measurement Tools,P. C. Avgeriou; D. Taibi; A. Ampatzoglou; F. Arcelli Fontana; T. Besker; A. Chatzigeorgiou; V. Lenarduzzi; A. Martini; A. Moschou; I. Pigazzini; N. Saarimaki; D. D. Sas; S. S. de Toledo; A. A. Tsintzira,"Department of Mathematics and Computing Science, University of Groningen, Groningen, 9747 AG groningen, Netherlands; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Pirkanmaa, Finland; Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece; DISCo, University of Milano Bicocca, Milano, 20126 Milano, Italy; Software Engineering , Computer Science and Engineering,, Göteborg, Göteborg, Sweden; Applied Informatics, University of Macedonia, Thessaloniki, 540 06 Thessaloniki, Greece; Department of Computing, Tampere University, Tampere, Pirkanmaa, Finland; Programming and Software Engineering, University of Oslo, Oslo, 0373 Oslo, Norway; Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece; Department of Informatics, Systems and Communications, University of Milan–Bicocca, Milano, Lombardia, Italy; Department of Computing, Tampere University, Tampere, Pirkanmaa, Finland; Bernoulli Instititute For Mathematics, Computer Science, and Artificial Intelligence, University of Groningen, Groningen, 9700 AB Groningen, Netherlands; Programming and Software Engineering, University of Oslo, Oslo, Oslo, Norway; Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece",IEEE Software,19 Apr 2021,2021,38,3,61,71,"Different tools adopt different terms, metrics, and ways to identify and measure technical debt. We attempt to clarify the situation by comparing the features and popularity of technical debt measurement tools and analyzing the existing empirical evidence on their validity.",1937-4194,,10.1109/MS.2020.3024958,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200792,Technical Debt;Tools;Source Code Analysis;Software Quality,Economics;Google;Software quality;Software measurement,,,,2.0,,12.0,IEEE,18 Sep 2020,,,IEEE,IEEE Magazines
1595,234,Metamorphic Testing: Testing the Untestable,S. Segura; D. Towey; Z. Q. Zhou; T. Y. Chen,"Software Engineering, University of Seville, Spain; Computer Science, University of Nottingham, Ningbo, China; Software Engineering, University of Wollongong, Australia; Software Engineering, Swinburne University of Technology, Australia",IEEE Software,15 Apr 2020,2020,37,3,46,53,"What if we could know that a program is buggy, even if we could not tell whether or not its observed output is correct? Metamorphic testing provides this ability. This article explains the basics of the technique.",1937-4194,,10.1109/MS.2018.2875968,Australian Research Council; Operational Programme FEDER Andalusia and the Spanish Government; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573811,Software testing;metamorphic testing;oracle problem;test case generation,Search engines;Programming;Australia;Program processors;Software testing,program debugging;program testing,metamorphic testing;observed output;buggy program,,8.0,,21.0,,12 Dec 2018,,,IEEE,IEEE Magazines
1596,235,Requirements Engineering Tools: An Evaluation,J. M. Carrillo de Gea; C. Ebert; M. Hosni; A. Vizcaíno; J. Nicolás; J. L. Fernández-Alemán,"Software Engineering Research Group, Faculty of Computer Science, University of Murcia, Spain; Vector Consulting Services; MOSI Research Team, High School of Arts and Crafts Meknes, Moulay Ismail University; Alarcos Research Group, Institute of Information Technologies & Systems, Escuela Superior de Inform, University of Castilla-La Mancha, Spain; Software Engineering Research Group, Faculty of Computer Science, University of Murcia, Spain; Software Engineering Research Group, Faculty of Computer Science, University of Murcia, Spain",IEEE Software,19 Apr 2021,2021,38,3,17,24,"""If you don't know where you are going, any road will get you there."" Alice from Alice in Wonderland was told this obvious piece of wisdom when she asked for directions. We all know this wisdom from navigating through the fog of insufficient requirements when working on projects. Clear goals can be achieved; unclear goals are sure to be missed. Requirements engineering (RE) is the disciplined and systematic approach (i.e., ""engineering"") for elicitation, documentation, analysis, agreement, verification, and management of requirements while considering market, technical, and economic goals. ""Disciplined"" is about culture, and ""systematic"" demands process and tools, which is our focus here.",1937-4194,,10.1109/MS.2021.3058394,Consejeria de Educacion Cultura y Deportes de la Junta de Comunidades de Castilla La Mancha y Fondo Europeo de Desarrollo Regional FEDER; Ministerio de Ciencia Innovacion y Universidades y Fondo Europeo de Desarrollo Regional FEDER; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408308,,Software tools;Collaboration;Distributed databases;Stakeholders;Software as a service;Scalability,,,,,,8.0,IEEE,19 Apr 2021,,,IEEE,IEEE Magazines
1597,236,Improving Vulnerability Inspection Efficiency Using Active Learning,Z. Yu; C. Theisen; L. Williams; T. Menzies,"Computer science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: zyu9@ncsu.edu); Security, Microsoft Research, 214606 Redmond, Washington United States (e-mail: crtheise@ncsu.edu); Computer Science, North Carolina State University, Raleigh, North Carolina United States 27695-8206 (e-mail: williams@csc.ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Software engineers can find vulnerabilities with less effort if they are directed towards code that might contain more vulnerabilities. HARMLESS is an incremental support vector machine tool that builds a vulnerability prediction model from the source code inspected to date, then suggests what source code files should be inspected next. In this way, HARMLESS can reduce the time and effort required to achieve some desired level of recall for finding vulnerabilities. The tool also provides feedback on when to stop (at that desired level of recall) while at the same time, correcting human errors by double-checking suspicious files. This paper evaluates HARMLESS on Mozilla Firefox vulnerability data. HARMLESS found 80, 90, 95, 99% of the vulnerabilities by inspecting 10, 16, 20, 34% of the source code files. When targeting 90, 95, 99% recall, HARMLESS could stop after inspecting 23, 30, 47% of the source code files. Even when human reviewers fail to identify half of the vulnerabilities (50% false negative rate), HARMLESS could detect 96% of the missing vulnerabilities by double-checking half of the inspected files. Our results serve to highlight the very steep cost of protecting software from vulnerabilities (in our case study that cost is, for example, the human effort of inspecting $28,750 \times 20\% = 5,750$ source code files to identify 95% of the vulnerabilities). While this result could benefit the mission-critical projects where human resources are available for inspecting thousands of source code files, the research challenge for future work is how to further reduce that cost. The conclusion of this paper discusses various ways that goal might be achieved.",1939-3520,,10.1109/TSE.2019.2949275,Division of Computing and Communication Foundations; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883076,Active learning;security;vulnerabilities;software engineering;error correction,Inspection;Software;Tools;Security;Predictive models;Error correction;NIST,,,,3.0,,,,25 Oct 2019,,,IEEE,IEEE Early Access Articles
1598,237,The Impact of Automated Parameter Optimization on Defect Prediction Models,C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto,"University of Adelaide, Adelaide, SA, Australia; Department of Electrical and Computer Engineering, McGill University, Montréal, Quebec, Canada; Queen's University, Kingston, Ontario, Canada; Nara Institute of Science and Technology, Ikoma, Takayamacho, Japa",IEEE Transactions on Software Engineering,16 Jul 2019,2019,45,7,683,711,"Defect prediction models-classifiers that identify defect-prone software modules-have configurable parameters that control their characteristics (e.g., the number of trees in a random forest). Recent studies show that these classifiers underperform when default settings are used. In this paper, we study the impact of automated parameter optimization on defect prediction models. Through a case study of 18 datasets, we find that automated parameter optimization: (1) improves AUC performance by up to 40 percentage points; (2) yields classifiers that are at least as stable as those trained using default settings; (3) substantially shifts the importance ranking of variables, with as few as 28 percent of the top-ranked variables in optimized classifiers also being top-ranked in non-optimized classifiers; (4) yields optimized settings for 17 of the 20 most sensitive parameters that transfer among datasets without a statistically significant drop in performance; and (5) adds less than 30 minutes of additional computation to 12 of the 26 studied classification techniques. While widely-used classification techniques like random forest and support vector machines are not optimization-sensitive, traditionally overlooked techniques like C5.0 and neural networks can actually outperform widely-used techniques after optimization is applied. This highlights the importance of exploring the parameter space when using parameter-sensitive classification techniques.",1939-3520,,10.1109/TSE.2018.2794977,JSPS Program for Advancing Strategic International Networks to Accelerate the Circulation of Talented Researchers; Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8263202,Software defect prediction;search-based software engineering;experimental design;classification techniques;parameter optimization;grid search;random search;genetic algorithm;differential evolution,Optimization;Predictive models;Computational modeling;Software;Neural networks;Computational efficiency;Power system stability,optimisation;pattern classification;random forests;software quality;support vector machines,automated parameter optimization;random forest;nonoptimized classifiers;optimized settings;20 most sensitive parameters;parameter space;parameter-sensitive classification techniques;defect prediction models;defect-prone software modules;support vector machines,,12.0,,154.0,,18 Jan 2018,,,IEEE,IEEE Journals
1599,238,Revisiting the Performance Evaluation of Automated Approaches for the Retrieval of Duplicate Issue Reports,M. S. Rakha; C. Bezemer; A. E. Hassan,"Queen's University, Kingston, ON, Canada; Queen's University, Kingston, ON, Canada; Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,9 Dec 2018,2018,44,12,1245,1268,"Issue tracking systems (ITSs), such as Bugzilla, are commonly used to track reported bugs, improvements and change requests for a software project. To avoid wasting developer resources on previously-reported (i.e., duplicate) issues, it is necessary to identify such duplicates as soon as they are reported. Several automated approaches have been proposed for retrieving duplicate reports, i.e., identifying the duplicate of a new issue report in a list of $n$  candidates. These approaches rely on leveraging the textual, categorical, and contextual information in previously-reported issues to decide whether a newly-reported issue has previously been reported. In general, these approaches are evaluated using data that spans a relatively short period of time (i.e., the classical evaluation). However, in this paper, we show that the classical evaluation tends to overestimate the performance of automated approaches for retrieving duplicate issue reports. Instead, we propose a realistic evaluation using all the reports that are available in the ITS of a software project. We conduct experiments in which we evaluate two popular approaches for retrieving duplicate issues (BM25F and REP) using the classical and realistic evaluations. We find that for the issue tracking data of the Mozilla foundation, the Eclipse foundation and OpenOffice, the realistic evaluation shows that previously proposed approaches perform considerably lower than previously reported using the classical evaluation. As a result, we conclude that the reported performance of approaches for retrieving duplicate issue reports is significantly overestimated in literature. In order to improve the performance of the automated retrieval of duplicate issue reports, we propose to leverage the resolution field of issue reports. Our experiments show that a relative improvement in the performance of a median of 7-21.5 percent and a maximum of 19-60 percent can be achieved by leveraging the resolution field of issue reports for the automated retrieval of duplicates.",1939-3520,,10.1109/TSE.2017.2755005,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048025,Text analysis;software engineering;performance evaluation,Text analysis;Computer bugs;Frequency measurement;Performance evaluation;Manuals;Ports (Computers),,,,9.0,,36.0,,21 Sep 2017,,,IEEE,IEEE Journals
1600,239,A Controlled Experiment with Novice Developers on the Impact of Task Description Granularity on Software Quality in Test-Driven Development,E. I. Karac; B. Turhan; N. Juristo,"M3S, Oulun Yliopisto, 6370 Oulu, N/A Finland (e-mail: itir.karac@oulu.fi); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: turhanb@computer.org); Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politecnica de Madrid Facultad de Informatica, 170631 Boadilla del Monte, Comunidad de Madrid Spain (e-mail: natalia@fi.upm.es)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Background: Test-Driven Development (TDD) is an iterative software development process characterized by test-code-refactor cycle. TDD recommends that developers work on small and manageable tasks at each iteration. However, the ability to break tasks into small work items effectively is a learned skill that improves with experience. In experimental studies of TDD, the granularity of task descriptions is an overlooked factor. In particular, providing a more granular task description in terms of a set of sub-tasks versus providing a coarser-grained, generic description. Objective: We aim to investigate the impact of task description granularity on the outcome of TDD, as implemented by novice developers, with respect to software quality, as measured by functional correctness and functional completeness. Method: We conducted a one-factor crossover experiment with 48 graduate students in an academic environment. Each participant applied TDD and implemented two tasks, where one of the tasks was presented using a more granular task description. Resulting artifacts were evaluated with acceptance tests to assess functional correctness and functional completeness. Linear mixed-effects models (LMM) were used for analysis. Results: Software quality improved significantly when participants applied TDD using more granular task descriptions. The effect of task description granularity is statistically significant and had a medium to large effect size. Moreover, the task was found to be a significant predictor of software quality which is an interesting result (because two tasks used in the experiment were considered to be of similar complexity). Conclusion: For novice TDD practitioners, the outcome of TDD is highly coupled with the ability to break down the task into smaller parts. For researchers, task selection and task description granularity requires more attention in the design of TDD experiments. Task description granularity should be taken into account in secondary studies. Further comparative studies are needed to investigate whether task descriptions affect other development processes similarly.",1939-3520,,10.1109/TSE.2019.2920377,Luonnontieteiden ja Tekniikan Tutkimuksen Toimikunta; Ministerio de Ciencia e Innovación; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8727972,Test-driven development;programming task description;controlled experiment;empirical software engineering;crossover experiment;software quality;requirement granularity,Task analysis;Software quality;Productivity;Process control;Atmospheric measurements;Particle measurements,,,,1.0,,,,3 Jun 2019,,,IEEE,IEEE Early Access Articles
1601,240,The Adoption of JavaScript Linters in Practice: A Case Study on ESLint,K. F. Tómasdóttir; M. Aniche; A. Van Deursen,"Delft University of Technology, Delft, CDThe Netherlands; Delft University of Technology, Delft, CDThe Netherlands; Delft University of Technology, Delft, CDThe Netherlands",IEEE Transactions on Software Engineering,13 Aug 2020,2020,46,8,863,891,"A linter is a static analysis tool that warns software developers about possible code errors or violations to coding standards. By using such a tool, errors can be surfaced early in the development process when they are cheaper to fix. For a linter to be successful, it is important to understand the needs and challenges of developers when using a linter. In this paper, we examine developers' perceptions on JavaScript linters. We study why and how developers use linters along with the challenges they face while using such tools. For this purpose we perform a case study on ESLint, the most popular JavaScript linter. We collect data with three different methods where we interviewed 15 developers from well-known open source projects, analyzed over 9,500 ESLint configuration files, and surveyed 337 developers from the JavaScript community. Our results provide practitioners with reasons for using linters in their JavaScript projects as well as several configuration strategies and their advantages. We also provide a list of linter rules that are often enabled and disabled, which can be interpreted as the most important rules to reason about when configuring linters. Finally, we propose several feature suggestions for tool makers and future work for researchers.",1939-3520,,10.1109/TSE.2018.2871058,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468105,Static analysis tools;linters;eslint;javascript linters;ASATs;empirical software engineering,Tools;Static analysis;Interviews;Encoding;Standards;Software;Face,authoring languages;program diagnostics,linter rules;static analysis tool;code errors;JavaScript linters;ESLint configuration files;coding standards,,3.0,,101.0,IEEE,19 Sep 2018,,,IEEE,IEEE Journals
1602,241,EARMO: An Energy-Aware Refactoring Approach for Mobile Apps,R. Morales; R. Saborido; F. Khomh; F. Chicano; G. Antoniol,"Polytechynique Montéal, Montreal, QC, Canada; Polytechynique Montéal, Montreal, QC, Canada; Polytechynique Montéal, Montreal, QC, Canada; University of Málaga, Málaga, Spain; Polytechynique Montéal, Montreal, QC, Canada",IEEE Transactions on Software Engineering,9 Dec 2018,2018,44,12,1176,1206,"The energy consumption of mobile apps is a trending topic and researchers are actively investigating the role of coding practices on energy consumption. Recent studies suggest that design choices can conflict with energy consumption. Therefore, it is important to take into account energy consumption when evolving the design of a mobile app. In this paper, we analyze the impact of eight type of anti-patterns on a testbed of 20 android apps extracted from F-Droid. We propose EARMO, a novel anti-pattern correction approach that accounts for energy consumption when refactoring mobile anti-patterns. We evaluate EARMO using three multiobjective search-based algorithms. The obtained results show that EARMO can generate refactoring recommendations in less than a minute, and remove a median of 84 percent of anti-patterns. Moreover, EARMO extended the battery life of a mobile phone by up to 29 minutes when running in isolation a refactored multimedia app with default settings (no Wi-Fi, no location services, and minimum screen brightness). Finally, we conducted a qualitative study with developers of our studied apps, to assess the refactoring recommendations made by EARMO. Developers found 68 percent of refactorings suggested by EARMO to be very relevant.",1939-3520,,10.1109/TSE.2017.2757486,"Natural Sciences and Engineering Research Council of Canada (NSERC); Consejo Nacional de Ciencia y Tecnología, México; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052533,Software maintenance;refactoring;anti-patterns;mobile apps;energy consumption;search-based software engineering,Mobile communication;Energy consumption;Software;Androids;Humanoid robots;Energy measurement;Software maintenance,Android (operating system);mobile computing;power aware computing;search problems;smart phones;software maintenance,EARMO;energy-aware refactoring approach;refactoring recommendations;mobile phone;energy consumption;mobile apps;Android apps;antipattern correction approach;mobile antipatterns;F-Droid;multiobjective search-based algorithms,,17.0,,96.0,,28 Sep 2017,,,IEEE,IEEE Journals
1603,242,"Relations Between Effort Estimates, Skill Indicators, and Measured Programming Skill",M. Jorgensen; G. R. Bergersen; K. Liestol,"Simula Metropolitan Center for Digital Engineering and Oslo Metropolitan University, Oslo Norway (e-mail: magnej@simula.no); University of Oslo, Norway (e-mail: gunnab@ifi.uio.no); University of Oslo, Norway (e-mail: knut@ifi.uio.no)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"There are large skill differences among software developers, and clients and managers will benefit from being able to identify those with better skill. This study examines the relations between low effort estimates, and other commonly used skill indicators, and measured programming skill. One hundred and four professional software developers were recruited. After skill-related information was collected, they were asked to estimate the effort for four larger and five smaller programming tasks. Finally, they completed a programming skill test. The lowest and most over-optimistic effort estimates for the larger tasks were given by those with the lowest programming skill, which is in accordance with the well-known Dunning-Kruger effect. For the smaller tasks, however, those with the lowest programming skill had the highest and most over-pessimistic estimates. The other programming skill indicators, such as length of experience, company assessed skill and self-assessed skill, were only moderately correlated with measured skill and not particularly useful in guiding developer skill identification. A practical implication is that for larger and more complex tasks, the use of low effort estimates and commonly used skill indicators as selection criteria leads to a substantial risk of selecting among the least skilled developers.",1939-3520,,10.1109/TSE.2020.2973638,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999628,D.2.9.b Cost estimation;D.2.1.d Management;D.2.0 Software engineering;D.2.0b Software psychology,Task analysis;Software;Companies;Programming profession;Estimation;Java,,,,,,,,14 Feb 2020,,,IEEE,IEEE Early Access Articles
1604,243,Requirements Engineering for Safety-Critical Systems: An Interview Study with Industry Practitioners,L. E. G. Martins; T. Gorschek,"Institute of Science and Technology, Federal University of São Paulo, São José dos Campos, Brazil; School of Computing, Blekinge Institute of Technology, Karlskrona, Sweden",IEEE Transactions on Software Engineering,16 Apr 2020,2020,46,4,346,361,"We have conducted in-depth interviews with experienced practitioners in the Safety-Critical Systems (SCS) domain in order to investigate several aspects related to requirements specification and safety analysis for SCS. We interviewed 19 practitioners from eleven SCS companies in different domains with the intention of verifying which approaches they use day-to-day, and what their perceptions are in relation to the approaches used to elicit, analyze, specify and validate safety requirements. The aim of this study is to obtain an in-depth understanding of how requirements engineering is carried out in companies that develop SCS.",1939-3520,,10.1109/TSE.2018.2854716,Federal University of São Paulo; Conselho Nacional de Desenvolvimento Científico e Tecnológico; The Knowledge Foundation in Sweden; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409284,Requirements;specification;software and system safety;requirements engineering;safety critical systems;software engineering;SCS,Safety;Companies;Requirements engineering;Software;Certification;Interviews;Unified modeling language,formal specification;safety;safety-critical software;systems analysis,requirements specification;safety-critical systems domain;experienced practitioners;in-depth interviews;industry practitioners;requirements engineering;safety requirements;day-to-day;safety analysis,,5.0,,52.0,IEEE,10 Jul 2018,,,IEEE,IEEE Journals
1605,244,Integrating Technical Debt Management and Software Quality Management Processes: A Normative Framework and Field Tests,N. Ramasubbu; C. F. Kemerer,"University of Pittsburgh, Pittsburgh, PA; University of Pittsburgh, Pittsburgh, PA",IEEE Transactions on Software Engineering,13 Mar 2019,2019,45,3,285,300,"Despite the increasing awareness of the importance of managing technical debt in software product development, systematic processes for implementing technical debt management in software production have not been readily available. In this paper we report on the development and field tests of a normative process framework that systematically incorporates steps for managing technical debt in commercial software production. The framework integrates processes required for technical debt management with existing software quality management processes prescribed by the project management body of knowledge (PMBOK), and it contributes to the further development of software-specific extensions to the PMBOK. We partnered with three commercial software product development organizations to implement the framework in real-world software production settings. All three organizations, irrespective of their varying software process maturity levels, were able to adopt the proposed framework and integrate the prescribed technical debt management processes with their existing software quality management processes. Our longitudinal observations and case-study interviews indicate that the organizations were able to accrue economic benefits from the adoption and use of the integrated framework.",1939-3520,,10.1109/TSE.2017.2774832,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114229,Technical debt;software quality;software maintenance;software engineering economics;cost of quality;software product development;software process;software extension to PMBOK;case study,Software quality;Business;Economics;Product development;Tools;Systematics,economics;product development;project management;quality management;software development management;software quality,field tests;normative process framework;commercial software production;software process maturity levels;software production settings;software quality management processes;technical debt management processes;project management body of knowledge;commercial software product development organizations;software-specific extensions,,6.0,,49.0,,17 Nov 2017,,,IEEE,IEEE Journals
1606,245,An Interactive and Dynamic Search-Based Approach to Software Refactoring Recommendations,V. Alizadeh; M. Kessentini; M. W. Mkaouer; M. Ocinneide; A. Ouni; Y. Cai,"University of Michigan, Dearborn, MI, USA; University of Michigan, Dearborn, MI, USA; Rochester Institute of Technology, Rochester, NY, USA; University College Dublin, Dublin 4, Ireland; ETS, Montreal, QC, Canada; Drexel University, Philadelphia, PA, USA",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,932,961,"Successful software products evolve through a process of continual change. However, this process may weaken the design of the software and make it unnecessarily complex, leading to significantly reduced productivity and increased fault-proneness. Refactoring improves the software design while preserving overall functionality and behavior, and is an important technique in managing the growing complexity of software systems. Most of the existing work on software refactoring uses either an entirely manual or a fully automated approach. Manual refactoring is time-consuming, error-prone and unsuitable for large-scale, radical refactoring. On the other hand, fully automated refactoring yields a static list of refactorings which, when applied, leads to a new and often hard to comprehend design. Furthermore, it is difficult to merge these refactorings with other changes performed in parallel by developers. In this paper, we propose a refactoring recommendation approach that dynamically adapts and interactively suggests refactorings to developers and takes their feedback into consideration. Our approach uses NSGA-II to find a set of good refactoring solutions that improve software quality while minimizing the deviation from the initial design. These refactoring solutions are then analyzed to extract interesting common features between them such as the frequently occurring refactorings in the best non-dominated solutions. Based on this analysis, the refactorings are ranked and suggested to the developer in an interactive fashion as a sequence of transformations. The developer can approve, modify or reject each of the recommended refactorings, and this feedback is then used to update the proposed rankings of recommended refactorings. After a number of introduced code changes and interactions with the developer, the interactive NSGA-II algorithm is executed again on the new modified system to repair the set of refactoring solutions based on the new changes and the feedback received from the developer. We evaluated our approach on a set of eight open source systems and two industrial projects provided by an industrial partner. Statistical analysis of our experiments shows that our dynamic interactive refactoring approach performed significantly better than four existing search-based refactoring techniques and one fully-automated refactoring tool not based on heuristic search.",1939-3520,,10.1109/TSE.2018.2872711,Ford Motor Company; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477161,Search-based software engineering;Refactoring;interactive optimization;software quality,Manuals;Tools;Software quality;Maintenance engineering;Optimization;Electronic mail,genetic algorithms;search problems;software maintenance;software quality;software tools;statistical analysis,software refactoring recommendations;software products;software design;software systems;manual refactoring;software quality;dynamic interactive refactoring approach;search-based refactoring;interactive search-based approach;dynamic search-based approach;interactive NSGA-II algorithm;statistical analysis,,1.0,,62.0,IEEE,30 Sep 2018,,,IEEE,IEEE Journals
1607,246,The Impact of Code Review on Architectural Changes,M. Paixao; J. Krinke; D. Han; C. Ragkhitwetsagul; M. Harman,"State University of Ceara, Fortaleza, CE, Brazil; Centre for Research in Search, Testing and Evolution (CREST), University College London, London, United Kingdom; Centre for Research in Search, Testing and Evolution (CREST), University College London, London, United Kingdom; Faculty of Information and Communication Technology, Mahidol University, Salaya, Nakhon Pathom, Thailand; Centre for Research in Search, Testing and Evolution (CREST), University College London, London, United Kingdom",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,1041,1059,"Although considered one of the most important decisions in the software development lifecycle, empirical evidence on how developers perform and perceive architectural changes remains scarce. Architectural decisions have far-reaching consequences yet, we know relatively little about the level of developers’ awareness of their changes’ impact on the software’s architecture. We also know little about whether architecture-related discussions between developers lead to better architectural changes. To provide a better understanding of these questions, we use the code review data from 7 open source systems to investigate developers’ intent and awareness when performing changes alongside the evolution of the changes during the reviewing process. We extracted the code base of 18,400 reviews and 51,889 revisions. 4,171 of the reviews have changes in their computed architectural metrics, and 731 present significant changes to the architecture. We manually inspected all reviews that caused significant changes and found that developers are discussing the impact of their changes on the architectural structure in only 31% of the cases, suggesting a lack of awareness. Moreover, we noticed that in 73% of the cases in which developers provided architectural feedback during code review, the comments were addressed, where the final merged revision tended to exhibit higher architectural improvement than reviews in which the system’s structure is not discussed.",1939-3520,,10.1109/TSE.2019.2912113,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8697147,Software architecture;code reviews;empirical software engineering,Computer architecture;Couplings;Software systems;Measurement;Software architecture;Agriculture;Java,,,,3.0,,59.0,IEEE,23 Apr 2019,,,IEEE,IEEE Journals
1608,247,Uncovering the Benefits and Challenges of Continuous Integration Practices,O. Elazhary; C. Werner; Z. S. Li; D. Lowlind; N. A. Ernst; M. -A. Storey,"Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8P 5C2 (e-mail: omazhary@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8P 5C2 (e-mail: colinwerner@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: zanelib1@gmail.com); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: dereklowlind@uvic.ca); Computer Science, University of Victoria, 8205 Victoria, British Columbia, Canada, (e-mail: nernst@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8P 3W6 (e-mail: mstorey@uvic.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"In 2006, Fowler and Foemmel defined ten core Continuous Integration (CI) practices that could increase the speed of software development feedback cycles and improve software quality. Since then, these practices have been widely adopted by industry and subsequent research has shown they improve software quality. However, there is poor understanding of how organizations implement these practices, of the benefits developers perceive they bring, and of the challenges developers and organizations experience in implementing them. In this paper, we discuss a multiple-case study of three small- to medium-sized companies using the recommended suite of ten CI practices. Using interviews and activity log mining, we learned that these practices are broadly implemented but how they are implemented varies depending on their perceived benefits, the context of the project, and the CI tools used by the organization. We also discovered that CI practices can create new constraints on the software process that hurt feedback cycle time. For researchers, we show that how CI is implemented varies, and thus studying CI (for example, using data mining) requires understanding these differences as important context for research studies. For practitioners, our findings reveal in-depth insights on the possible benefits and challenges from using the ten practices, and how project context matters.",1939-3520,,10.1109/TSE.2021.3064953,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9374092,Software engineering;automation;continuous integration;continuous software development,Tools;Software;Companies;Built-in self-test;Software quality;Complexity theory;Computer bugs,,,,1.0,,,IEEE,9 Mar 2021,,,IEEE,IEEE Early Access Articles
1609,248,An Integrated Approach for Effective Injection Vulnerability Analysis of Web Applications Through Security Slicing and Hybrid Constraint Solving,J. Thomé; L. K. Shar; D. Bianculli; L. Briand,"Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg",IEEE Transactions on Software Engineering,12 Feb 2020,2020,46,2,163,195,"Malicious users can attack Web applications by exploiting injection vulnerabilities in the source code. This work addresses the challenge of detecting injection vulnerabilities in the server-side code of Java Web applications in a scalable and effective way. We propose an integrated approach that seamlessly combines security slicing with hybrid constraint solving; the latter orchestrates automata-based solving with meta-heuristic search. We use static analysis to extract minimal program slices relevant to security from Web programs and to generate attack conditions. We then apply hybrid constraint solving to determine the satisfiability of attack conditions and thus detect vulnerabilities. The experimental results, using a benchmark comprising a set of diverse and representative Web applications/services as well as security benchmark applications, show that our approach (implemented in the JOACO tool) is significantly more effective at detecting injection vulnerabilities than state-of-the-art approaches, achieving 98 percent recall, without producing any false alarm. We also compared the constraint solving module of our approach with state-of-the-art constraint solvers, using six different benchmark suites; our approach correctly solved the highest number of constraints (665 out of 672), without producing any incorrect result, and was the one with the least number of time-out/failing cases. In both scenarios, the execution time was practically acceptable, given the offline nature of vulnerability detection.",1939-3520,,10.1109/TSE.2018.2844343,Qatar National Research Fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373739,Vulnerability detection;constraint solving;static analysis;search-based software engineering,Security;Benchmark testing;Tools;Explosions;Java;Static analysis;Reliability,constraint handling;Internet;Java;program slicing;search problems;security of data,security slicing;hybrid constraint solving;injection vulnerabilities;source code;Java Web applications;minimal program slices;Web programs;attack conditions;security benchmark applications;constraint solving module;constraint solvers;vulnerability detection;injection vulnerability analysis;efficiency 98.0 percent,,,,100.0,IEEE,6 Jun 2018,,,IEEE,IEEE Journals
1610,249,Engineering Trustworthy Self-Adaptive Software with Dynamic Assurance Cases,R. Calinescu; D. Weyns; S. Gerasimou; M. U. Iftikhar; I. Habli; T. Kelly,"Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, Linnaeus University, Växjö, Sweden; Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, University of York, York, United Kingdom",IEEE Transactions on Software Engineering,11 Nov 2018,2018,44,11,1039,1069,"Building on concepts drawn from control theory, self-adaptive software handles environmental and internal uncertainties by dynamically adjusting its architecture and parameters in response to events such as workload changes and component failures. Self-adaptive software is increasingly expected to meet strict functional and non-functional requirements in applications from areas as diverse as manufacturing, healthcare and finance. To address this need, we introduce a methodology for the systematic ENgineering of TRUstworthy Self-adaptive sofTware (ENTRUST). ENTRUST uses a combination of (1) design-time and runtime modelling and verification, and (2) industry-adopted assurance processes to develop trustworthy self-adaptive software and assurance cases arguing the suitability of the software for its intended application. To evaluate the effectiveness of our methodology, we present a tool-supported instance of ENTRUST and its use to develop proof-of-concept self-adaptive software for embedded and service-based systems from the oceanic monitoring and e-finance domains, respectively. The experimental results show that ENTRUST can be used to engineer self-adaptive software systems in different application domains and to generate dynamic assurance cases for these systems.",1939-3520,,10.1109/TSE.2017.2738640,Defence Science and Technology Laboratory; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008800,Self-adaptive software systems;software engineering methodology;assurance evidence;assurance cases,Software systems;Control systems;Runtime;Monitoring;Computer architecture;Adaptive systems,embedded systems;formal verification;software architecture;trusted computing,self-adaptive software handles;nonfunctional requirements;ENTRUST;industry-adopted assurance processes;engineering trustworthy;control theory;engineering of trustworthy self-adaptive software systems;service-based systems;oceanic monitoring;e-finance domains;embedded software;software architecture,,28.0,,132.0,,11 Aug 2017,,,IEEE,IEEE Journals
1611,250,Studying the Impact of Noises in Build Breakage Data,T. A. Ghaleb; D. Alencar da Costa; Y. Zou; A. E. Hassan,"School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: taher.a.ghaleb@gmail.com); Information Science, University of Otago, 2495 Dunedin, 9054 New Zealand (e-mail: daniel.calencar@gmail.com); Electrical and Computer Engineering, Queen's University, 4257 Kingston, Ontario Canada (e-mail: ying.zou@queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Much research has investigated the common reasons for build breakages. However, prior research has paid little attention to builds that may break due to reasons that are unlikely to be related to development activities. For example, Continuous Integration(CI) builds may break due to timeout or connection errors while generating the build. Such kinds of build breakages potentially introduce noises to build breakage data. Not considering such noises may lead to misleading results when studying CI builds. In this paper, we propose three criteria to identify build breakages that can potentially introduce noises to build breakage data. We apply these criteria to a dataset of 350,246 builds from153 GitHub projects that are linked with Travis CI. Our results reveal that 33% of the build breakages are due to environmental factors (e.g., errors in CI servers), 29% are due to (unfixed) errors in previous builds, and 9% are due to build jobs that were later deemed by developers as noisy (there is an overlap of 17% between these three types of breakages). We measure the impact of noises in build breakage data on modeling build breakages. We observe that models that use uncleaned build breakage data can lead to misleading associations between build breakages and development activities (e.g., the role of developer). However, such associations could not be observed after eliminating noisy build breakages. Moreover, we replicate a prior study that investigates the association between build breakages and development activities using data from 14 GitHub projects. We observe that some observations reported by the prior study (e.g., pull requests cause more breakages) do not hold after eliminating the noises from build breakage data.",1939-3520,,10.1109/TSE.2019.2941880,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839858,Continuous Integration;CI build breakages;Noisy data;Mining software repositories;Empirical software engineering,Noise measurement;Data models;Software;Environmental factors;Servers;Indexes,,,,,,,,16 Sep 2019,,,IEEE,IEEE Early Access Articles
1612,251,Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics,S. Dalla Palma; D. Di Nucci; F. Palomba; D. A. Tamburri,"Jheronimus Academy of Data Science, Tilburg University, 7899 's-Hertogenbosch, Noord-Brabant, Netherlands, (e-mail: s.dallapalma@uvt.nl); Jheronimus Academy of Data Science, Tilburg University, 7899 's-Hertogenbosch, Noord-Brabant, Netherlands, (e-mail: d.dinucci@uvt.nl); Department of Computer Science, Universita degli Studi di Salerno, 19028 Fisciano, Campania, Italy, (e-mail: fpalomba@unisa.it); Computer Science, University of Technology Eindhoven, 3169 Eindhoven, Noord-Brabant, Netherlands, (e-mail: d.a.tamburri@tue.nl)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Infrastructure-as-code (IaC) is the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files, hereinafter referred to as IaC scripts. Similarly to other source code artefacts, these files may contain defects that can preclude their correct functioning. In this paper, we aim at assessing the role of product and process metrics when predicting defective IaC scripts. We propose a fully integrated machine-learning framework for IaC Defect Prediction, that allows for repository crawling, metrics collection, model building, and evaluation. To evaluate it, we analyzed 104 projects and employed five machine-learning classifiers to compare their performance in flagging suspicious defective IaC scripts. The key results of the study report Random Forest as the best-performing model, with a median AUC-PR of 0.93 and MCC of 0.80. Furthermore, at least for the collected projects, product metrics identify defective IaC scripts more accurately than process metrics. Our findings put a baseline for investigating IaC Defect Prediction and the relationship between the product and process metrics, and IaC scripts' quality.",1939-3520,,10.1109/TSE.2021.3051492,Horizon 2020 Framework Programme; Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321740,Infrastructure-as-code;Defect Prediction;Empirical Software Engineering,Measurement;Software;Predictive models;Machine learning;Radon;Cloud computing;Task analysis,,,,,,,CCBY,13 Jan 2021,,,IEEE,IEEE Early Access Articles
1613,252,The Assessor's Dilemma: Improving Bug Repair via Empirical Game Theory,C. Gavidia-Calderon; F. Sarro; M. Harman; E. T. Barr,"Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: cgavidiac@gmail.com); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland WC1E 6B (e-mail: f.sarro@ucl.ac.uk); CS, Facebook London, 507852 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: mark.harman@ucl.ac.uk); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland WC1E 6BT (e-mail: e.barr@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Priority inflation occurs when a QA engineer or a project manager requesting a feature inflates the priority of their task so that developers deliver the fix or the new functionality faster. We survey developers and show that priority inflation occurs and misallocates developer time. We are the first to apply empirical game-theoretic analysis (EGTA) to a software engineering problem, specifically priority inflation. First, we extract prioritization strategies from 42,620 issues from Apache's JIRA, then use TaskAssessor, our EGTA-based modelling approach, to confirm conventional wisdom and show that the common process of a QA engineer assigning priority labels is susceptible to priority inflation. We then show that the common mitigation strategy of having a bug triage team assigning priorities does not resolve priority inflation and slows development. We then use mechanism design to devise assessor-throttling, a new, lightweight prioritization process, immune to priority inflation. We show that assessor-throttling resolves 97% of high priority tasks, 69% better than simply relying on those filing tasks to assign their priorities. Finally, we present TheFed, a browser extension for Chrome that supports assessor-throttling.",1939-3520,,10.1109/TSE.2019.2944608,Dynamic Adaptive Automated Software Engineering Programme Grant; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852726,Software Process;Game Theory;Bug Report;Priority Inflation,Task analysis;Computer bugs;Logic gates;Games;Nash equilibrium;Software,,,,,,,,30 Sep 2019,,,IEEE,IEEE Early Access Articles
1614,253,Watch out for Extrinsic Bugs! A Case Study of their Impact in Just-In-Time Bug Prediction Models on the OpenStack project,G. Rodriguezperez; M. Nagappan; G. Robles,"Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: gema.rodriguez-perez@uwaterloo.ca); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: mei.nagappan@uwaterloo.ca); Sistemas Telematicos y Computacion, Universidad Rey Juan Carlos, 16776 Madrid, Madrid, Spain, (e-mail: grex@gsyc.urjc.es)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Intrinsic bugs are bugs for which a bug-introducing change can be identified in the version control system of a software. In contrast, extrinsic bugs are caused by external changes to a software, such as errors in external APIs; thereby they do not have an explicit bug-introducing change in the version control system. Although most previous research literature has assumed that all bugs are of intrinsic nature, in a previous study, we show that not all bugs are intrinsic. This paper shows an example of how considering extrinsic bugs can affect software engineering research. Specifically, we study the impact of extrinsic bugs in Just-In-Time bug prediction by partially replicating a recent study by McIntosh and Kamei on JIT models. These models are trained using properties of earlier bug-introducing changes. Since extrinsic bugs do not have bug-introducing changes in the version control system, we manually curate McIntosh and Kamei's dataset to distinguish between intrinsic and extrinsic bugs. Then, we address their original research questions, this time removing extrinsic bugs, to study whether bug-introducing changes are a moving target in Just-In-Time bug prediction. Finally, we study whether characteristics of intrinsic and extrinsic bugs are different. Our results show that intrinsic and extrinsic bugs are of different nature. When removing extrinsic bugs the performance is different up to 16 % Area Under the Curve points. This indicates that our JIT models obtain a more accurate representation of the real world. We conclude that extrinsic bugs negatively impact Just-In-Time models. Furthermore, we offer evidence that extrinsic bugs should be further investigated, as they can significantly impact how software engineers understand bugs.",1939-3520,,10.1109/TSE.2020.3021380,Ministerio de Economa Industria y Competitividad Gobierno de Espaa; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185031,Bugs;Extrinsic Bugs;Intrinsic Bugs;Mislabeled Bugs;Bug-introducing changes;Just-In-Time;Bug Prediction,Computer bugs;Predictive models;Software;Data models;Control systems;Analytical models;Context modeling,,,,,,,,2 Sep 2020,,,IEEE,IEEE Early Access Articles
1615,254,Multi-Objective Software Effort Estimation: A Replication Study,V. Tawosi; F. Sarro; A. Petrozziello; M. Harman,"Computer Science, University College London, 4919 London, London,City of, United Kingdom of Great Britain and Northern Ireland, WC1E 6BT (e-mail: vali.tawosi@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: a.petrozziello@ucl.ac.uk); CS, Facebook London, 507852 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Replication studies increase our confidence in previous results when the findings are similar each time, and help mature our knowledge by addressing both internal and external validity aspects. However, these studies are still rare in certain software engineering fields. In this paper, we replicate and extend a previous study, which denotes the current state-of-the-art for multi-objective software effort estimation, namely CoGEE. We investigate the original research questions with an independent implementation and the inclusion of a more robust baseline (LP4EE), carried out by the first author, who was not involved in the original study. Through this replication, we strengthen both the internal and external validity of the original study. We also answer two new research questions investigating the effectiveness of CoGEE by using four additional evolutionary algorithms (i.e., IBEA, MOCell, NSGA-III, SPEA2) and a well-known Java framework for evolutionary computation, namely JMetal (rather than the previously used R software), which allows us to strengthen the external validity of the original study. The results of our replication confirm that: (1) CoGEE outperforms both baseline and state-of-the-art benchmarks statistically significantly (p < 0.001); (2) CoGEEs multi-objective nature makes it able to reach such a good performance; (3) CoGEEs estimation errors lie within claimed industrial human-expert-based thresholds. Moreover, our new results show that the effectiveness of CoGEE is generally not limited to nor dependent on the choice of the multi-objective algorithm. Using CoGEE with either NSGA-II, NSGA-III, or MOCell produces human competitive results in less than a minute. The Java version of CoGEE has decreased the running time by over 99.8% with respect to its R counterpart. We have made publicly available the Java code of CoGEE to ease its adoption, as well as, the data used in this study in order to allow for future replication and extension of our work.",1939-3520,,10.1109/TSE.2021.3083360,European Research Council Advanced Fellowship Grant; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440773,Software effort estimation;multi-objective evolutionary algorithm;confidence interval;estimates uncertainty,Estimation;Software;Predictive models;Prediction algorithms;Evolutionary computation;Java;Software measurement,,,,,,,IEEE,25 May 2021,,,IEEE,IEEE Early Access Articles
1616,255,DiffTech: Differencing Similar Technologies from Crowd-Scale Comparison Discussions,H. Wang; C. Chen; Z. Xing; J. Grundy,"Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: freddie.wanah@gmail.com); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: chunyang.chen@monash.edu); College of Engineering & Computer Science, Australian National University, 2219 Canberra, Australian Capital Territory, Australia, (e-mail: zhenchang.xing@anu.edu.au); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Developers use different technologies for many software development tasks. However, when faced with several technologies with comparable functionalities, it is not easy to select the most appropriate one, as trial and error comparisons among such technologies are time-consuming. Instead, developers can resort to expert articles, read official documents or ask questions in Q&A sites. However, it still remains difficult to get a comprehensive comparison as online information is often fragmented or contradictory. To overcome these limitations, we propose the DiffTech system that exploits crowdsourced discussions from Stack Overflow, and assists technology comparison with an informative summary of different aspects. We first build a large database of comparable technologies in software engineering by mining tags in Stack Overflow. We then locate comparative sentences about comparable technologies with natural language processing methods. We further mine prominent comparison aspects by clustering similar comparative sentences and representing each cluster with its keywords and aggregate the overall opinion towards the comparable technologies. Our evaluation demonstrates both the accuracy and usefulness of our model, and we have implemented our approach as a practical website for public use.",1939-3520,,10.1109/TSE.2021.3059885,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356217,comparing and differencing similar technology;Stack Overflow;natural language processing;NLP,Libraries;Tools;Natural language processing;Aggregates;Task analysis;Tagging;Data mining,,,,,,,IEEE,17 Feb 2021,,,IEEE,IEEE Early Access Articles
1617,256,Requirements of API Documentation: A Case Study into Computer Vision Services,A. Cummaudo; R. Vasa; J. Grundy; M. Abdelrazek,"Applied Artificial Intelligence Institute, Deakin University, 2104 Geelong, Victoria, Australia, (e-mail: ca@deakin.edu.au); Applied Artificial Intelligence Institute, Deakin University, 2104 Geelong, Victoria, Australia, (e-mail: rajesh.vasa@deakin.edu.au); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: john.grundy@monash.edu); School of Information Technology, Deakin University, 2104 Geelong, Victoria, Australia, (e-mail: mohamed.abdelrazek@deakin.edu.au)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Using cloud-based computer vision services is gaining traction, where developers access AI-powered components through familiar RESTful APIs, not needing to orchestrate large training and inference infrastructures or curate/label training datasets. However, while these APIs seem familiar to use, their non-deterministic run-time behaviour and evolution is not adequately communicated to developers. Therefore, improving these services' API documentation is paramount-more extensive documentation facilitates the development process of intelligent software. In a prior study, we extracted 34 API documentation artefacts from 21 seminal works, devising a taxonomy of five key requirements to produce quality API documentation. We extend this study in two ways. Firstly, by surveying 104 developers of varying experience to understand what API documentation artefacts are of most value to practitioners. Secondly, identifying which of these highly-valued artefacts are or are not well-documented through a case study in the emerging computer vision service domain. We identify: (i) several gaps in the software engineering literature, where aspects of API documentation understanding is/is not extensively investigated; and (ii) where industry vendors (in contrast) document artefacts to better serve their end-developers. We provide a set of recommendations to enhance intelligent software documentation for both vendors and the wider research community.",1939-3520,,10.1109/TSE.2020.3047088,Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307242,Intelligent Web Services and Semantic Web;Code Documentation;Computer Vision,Documentation;Taxonomy;Computer vision;Usability;Guidelines;Measurement;Tools,,,,,,,,24 Dec 2020,,,IEEE,IEEE Early Access Articles
1618,257,Measuring Program Comprehension: A Large-Scale Field Study with Professionals,X. Xia; L. Bao; D. Lo; Z. Xing; A. E. Hassan; S. Li,"Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Singapore Management University, Singapore; Australian National University, Canberra, ACT, Australia; Queen’s University, Kingston, ON, Canada; Zhejiang University, Hangzhou, China",IEEE Transactions on Software Engineering,14 Oct 2018,2018,44,10,951,976,"During software development and maintenance, developers spend a considerable amount of time on program comprehension activities. Previous studies show that program comprehension takes up as much as half of a developer's time. However, most of these studies are performed in a controlled setting, or with a small number of participants, and investigate the program comprehension activities only within the IDEs. However, developers' program comprehension activities go well beyond their IDE interactions. In this paper, we extend our ActivitySpace framework to collect and analyze Human-Computer Interaction (HCI) data across many applications (not just the IDEs). We follow Minelli et al.'s approach to assign developers' activities into four categories: navigation, editing, comprehension, and other. We then measure the comprehension time by calculating the time that developers spend on program comprehension, e.g., inspecting console and breakpoints in IDE, or reading and understanding tutorials in web browsers. Using this approach, we can perform a more realistic investigation of program comprehension activities, through a field study of program comprehension in practice across a total of seven real projects, on 78 professional developers, and amounting to 3,148 working hours. Our study leverages interaction data that is collected across many applications by the developers. Our study finds that on average developers spend ~58 percent of their time on program comprehension activities, and that they frequently use web browsers and document editors to perform program comprehension activities. We also investigate the impact of programming language, developers' experience, and project phase on the time that is spent on program comprehension, and we find senior developers spend significantly less percentages of time on program comprehension than junior developers. Our study also highlights the importance of several research directions needed to reduce program comprehension time, e.g., building automatic detection and improvement of low quality code and documentation, construction of software-engineering-specific search engines, designing better IDEs that help developers navigate code and browse information more efficiently, etc.",1939-3520,,10.1109/TSE.2017.2734091,National Natural Science Foundation of China; National Key Technology R&D Program; Ministry of Science and Technology of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7997917,Program comprehension;field study;inference model,Navigation;Software;Time measurement;Browsers;Maintenance engineering;Programming;Debugging,human computer interaction;Internet;program compilers;reverse engineering;search engines;software maintenance,program comprehension activities;program comprehension time;developers time;software development;software maintenance;IDE interactions;ActivitySpace framework;human computer interaction;Web browsers;programming language;project phase;software-engineering;search engines,,15.0,,63.0,,31 Jul 2017,,,IEEE,IEEE Journals
1619,258,"On the Understandability of Temporal Properties Formalized in Linear Temporal Logic, Property Specification Patterns and Event Processing Language",C. Czepa; U. Zdun,"Faculty of Computer Science, Research Group Software Architecture, University of Vienna, Vienna, Austria; Faculty of Computer Science, Research Group Software Architecture, University of Vienna, Vienna, Austria",IEEE Transactions on Software Engineering,8 Jan 2020,2020,46,1,100,112,"Temporal properties are important in a wide variety of domains for different purposes. For example, they can be used to avoid architectural drift in software engineering orto support the regulatory compliance of business processes. In this work, we study the understandability of three majortemporal property representations: (1) LinearTemporal Logic (LTL) is a formal and well-established logic that offers temporal operators to describe temporal properties; (2) Property Specification Patterns (PSP) are a collection of recurring temporal properties that abstract underlying formal and technical representations; (3) Event Processing Language (EPL) can be used for runtime monitoring of event streams using Complex Event Processing. We conducted two controlled experiments with 216 participants in total to study the understandability of those approaches using a completely randomized design with one alternative per experimental unit. We hypothesized that PSP, as a highly abstracting pattern language, is easier to understand than LTL and EPL, and that EPL, due to separation of concerns (as one or more queries can be used to explicitly define the truth value change that an observed event pattern causes), is easier to understand than LTL. We found evidence supporting our hypotheses which was statistically significant and reproducible.",1939-3520,,10.1109/TSE.2018.2859926,Austrian Research Promotion Agency; Austrian Science Fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419310,Controlled experiment;understandability;temporal property;linear temporal logic;property specification patterns;complex event processing;event processing language,Software;Computer science;Guidelines;Industries;Software architecture;Cognition,formal specification;formal verification;pattern recognition;temporal logic,temporal properties;linear temporal Logic;business processes;complex event processing;property specification patterns;event processing language;software engineering,,1.0,,71.0,IEEE,25 Jul 2018,,,IEEE,IEEE Journals
1620,259,Just-In-Time Defect Identification and Localization: A Two-Phase Framework,M. Yan; X. Xia; Y. Fan; A. E. Hassan; D. Lo; S. Li,"School of Big Data and Software Engineering, Chongqing University, 47913 Chongqing, Sichuan China (e-mail: mengy@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: yrfan@zju.edu.cn); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: shan@zju.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Defect localization aims to locate buggy program elements (e.g., buggy files, methods or lines of code) based on defect symptoms, e.g., bug reports or program spectrum. However, when we receive the defect symptoms, the defect has been exposed and negative impacts have been introduced. Thus, one challenging task is: whether we can locate buggy program prior to appearance of the defect symptom at an early time (e.g., when buggy program elements are being checked-in). We refer to this type of defect localization as “Just-In-Time (JIT) Defect localization”. Although many prior studies have proposed various JIT defect identification methods to identify whether a new change is buggy, these prior methods do not locate the suspicious positions. Thus, JIT defect localization is the next step of JIT defect identification (i.e., after a buggy change is identified, suspicious source code lines are located). To address this problem, we propose a two-phase framework, i.e., JIT defect identification and JIT defect localization. Given a new change, JIT defect identification will identify it as buggy change or clean change first. If a new change is identified as buggy, JIT defect localization will rank the source code lines introduced by the new change according to their suspiciousness scores. The source code lines ranked at the top of the list are estimated as the defect location. For JIT defect identification phase, we use 14 change-level features to build a classifier by following existing approach. For JIT defect localization phase, we propose a JIT defect localization approach that leverages software naturalness with the N-gram model. To evaluate the proposed framework, we conduct an empirical study on 14 open source projects with a total of 177,250 changes. The results show that software naturalness is effective for our JIT defect localization. Our model achieves a reasonable performance, and outperforms the two baselines (i.e., random guess and a static bug finder (i.e., PMD)) by a substantial margin in terms of four ranking measures.",1939-3520,,10.1109/TSE.2020.2978819,China Postdoctoral Science Foundation; Australian Research Councils Discovery Early Career Researcher Award; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9026802,Defect Localization;Just-in-Time;Defect Identification;Software Naturalness,Software;Computer bugs;Task analysis;History;Fans;Computer science,,,,2.0,,,,6 Mar 2020,,,IEEE,IEEE Early Access Articles
1621,260,"Automatically ‘Verifying’ Discrete-Time Complex Systems through Learning, Abstraction and Refinement",J. Wang; J. Sun; S. Qin; C. Jegourel,"College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Singapore University of Technology and Design, Singapore; School of Computing, Media and the Arts, Teesside University, Middlesbrough, United Kingdom; Singapore University of Technology and Design, Singapore",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,189,203,"Precisely modeling complex systems like cyber-physical systems is challenging, which often renders model-based system verification techniques like model checking infeasible. To overcome this challenge, we propose a method called LAR to automatically `verify' such complex systems through a combination of learning, abstraction and refinement from a set of system log traces. We assume that log traces and sampling frequency are adequate to capture `enough' behaviour of the system. Given a safety property and the concrete system log traces as input, LAR automatically learns and refines system models, and produces two kinds of outputs. One is a counterexample with a bounded probability of being spurious. The other is a probabilistic model based on which the given property is `verified'. The model can be viewed as a proof obligation, i.e., the property is verified if the model is correct. It can also be used for subsequent system analysis activities like runtime monitoring or model-based testing. Our method has been implemented as a self-contained software toolkit. The evaluation on multiple benchmark systems as well as a real-world water treatment system shows promising results.",1939-3520,,10.1109/TSE.2018.2886898,National Natural Science Foundation of China; Science and Technology Foundation of Shenzhen City; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576657,Verification;model learning;abstraction refinement;cyber-physical system,Probabilistic logic;Model checking;Analytical models;Safety;Complex systems;System analysis and design,computational complexity;distributed processing;formal verification;large-scale systems;learning (artificial intelligence);probability;program verification,real-world water treatment system;multiple benchmark systems;subsequent system analysis activities;given property;probabilistic model;system models;concrete system;safety property;log traces;abstraction;automatically verify such complex systems;LAR;model-based system verification techniques;cyber-physical systems;discrete-time complex systems,,1.0,,59.0,IEEE,14 Dec 2018,,,IEEE,IEEE Journals
1622,261,Quantitative Verification for Monitoring Event-Streaming Systems,G. Su; L. Liu; M. Zhang; D. Rosenblum,"School of Computing and Information Technology, University of Wollongong, 8691 Wollongong, New South Wales Australia (e-mail: guoxin@uow.edu.au); School of Software Engineering, Chongqing University, 47913 Chongqing, Chongqing China (e-mail: dcsliuli@cqu.edu.cn); School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: minjie@uow.edu.au); School of Computing, National University of Singapore, Singapore, Singapore Singapore (e-mail: david@comp.nus.edu.sg)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"High-performance data streaming technologies are increasingly adopted in IT companies to support the integration of heterogeneous and possibly distributed service systems and applications. Compared with the traditional message queuing middleware, a streaming platform enables the implementation of event-streaming systems (ESS) which include not only complex queues but also applications that transform and react to the streams of data. By analysing the centralised data streams, one can evaluate the Quality-of-Service for other systems and components that produce or consume the streams. We consider the exploitation of probabilistic model checking as a performance monitoring technique for ESS systems. Probabilistic model checking is a mature, powerful verification technique with successful application in performance analysis. However, an ESS system may contain quantitative parameters that are determined by event streams observed in a certain period of time. In this paper, we present a novel theoretical framework called QV4M (meaning “quantitative verification for monitoring”) for ESS system monitoring based on two recent methods of probabilistic model checking. Our framework QV4M assumes the parameters in a probabilistic system model as random variables and infers the statistical confidence of a probabilistic model checking output. We present two case studies as an empirical evaluation of QV4M.",1939-3520,,10.1109/TSE.2020.2996033,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097462,Discrete-time Markov chain;event stream;parametric model checking;performance monitoring;probabilistic model checking;statistical inference,Task analysis;Probabilistic logic;Model checking;Measurement;Monitoring;Pipelines;Computational modeling,,,,,,,,20 May 2020,,,IEEE,IEEE Early Access Articles
1623,262,Investigating the Impact of Development Task on External Quality in Test-Driven Development: An Industry Experiment,A. Tosun; O. Dieste; S. Vegas; D. Pfahl; K. Rungi; N. Juristo,"Computer Engineering, Istanbul Technical University, Istanbul, Istanbul Turkey 34469 (e-mail: tosunay@itu.edu.tr); Lenguajes y Sistemas Informaticos e Ingenieria de Software, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: odieste@fi.upm.es); Languajes, computer systems and software engineering, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: svegas@fi.upm.es); Institute of Computer Science, University of Tartu, Tartu, Tartu Estonia (e-mail: dietmar.pfahl@ut.ee); IT, Testlio, Oulu, Oulu Finland (e-mail: kerli.rungi@gmail.com); Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: natalia@fi.upm.es)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Reviews on test-driven development (TDD) studies suggest that the conflicting results reported in the literature are due to unobserved factors, such as the tasks used in the experiments, and highlight that there are very few industry experiments conducted with professionals. The goal of this study is to investigate the impact of a new factor, the chosen task, and the development approach on external quality in an industrial experiment setting with 17 professionals. The participants are junior to senior developers in programming with Java, beginner to novice in unit testing, JUnit, and they have no prior experience in TDD. The experimental design is a $2 \times 2$ cross-over, i.e., we use two tasks for each of the two approaches, namely TDD and incremental test-last development (ITLD). Our results reveal that both development approach and task are significant factors with regards to the external quality achieved by the participants. More specifically, the participants produce higher quality code during ITLD in which splitting user stories into subtasks, coding, and testing activities are followed, compared to TDD. The results also indicate that the participants produce higher quality code during the implementation of Bowling Score Keeper, compared to that of Mars Rover API, although they perceived both tasks as of similar complexity. An interaction between the development approach and task could not be observed in this experiment. We conclude that variables that have not been explored so often, such as the extent to which the task is specified in terms of smaller subtasks, and developers' unit testing experience might be critical factors in TDD experiments. The real-world appliance of TDD and its implications on external quality still remain to be challenging unless these uncontrolled and unconsidered factors are further investigated by researchers in both academic and industrial settings.",1939-3520,,10.1109/TSE.2019.2949811,Ministerio de Ciencia e Innovación; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884172,Test-driven development;industry experiment;experimental task;incremental test-last development;external quality,Task analysis;Industries;Bibliographies;Productivity;Programming profession;Organizations,,,,1.0,,,,28 Oct 2019,,,IEEE,IEEE Early Access Articles
1624,263,"Choosing Component Origins for Software Intensive Systems: In-House, COTS, OSS or Outsourcing?—A Case Survey",K. Petersen; D. Badampudi; S. M. A. Shah; K. Wnuk; T. Gorschek; E. Papatheocharous; J. Axelsson; S. Sentilles; I. Crnkovic; A. Cicchetti,"Department of Software Engineering, Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; SICS Swedish ICT AB, Kista, Sweden; Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; SICS Swedish ICT AB, Kista, Sweden; SICS Swedish ICT AB, Kista, Sweden; Mälardalen University, Västerås, Sweden; Chalmers, Gothenberg, Sweden; Mälardalen University, Västerås, Sweden",IEEE Transactions on Software Engineering,13 Mar 2018,2018,44,3,237,261,"The choice of which software component to use influences the success of a software system. Only a few empirical studies investigate how the choice of components is conducted in industrial practice. This is important to understand to tailor research solutions to the needs of the industry. Existing studies focus on the choice for off-the-shelf (OTS) components. It is, however, also important to understand the implications of the choice of alternative component sourcing options (CSOs), such as outsourcing versus the use of OTS. Previous research has shown that the choice has major implications on the development process as well as on the ability to evolve the system. The objective of this study is to explore how decision making took place in industry to choose among CSOs. Overall, 22 industrial cases have been studied through a case survey. The results show that the solutions specifically for CSO decisions are deterministic and based on optimization approaches. The non-deterministic solutions proposed for architectural group decision making appear to suit the CSO decision making in industry better. Interestingly, the final decision was perceived negatively in nine cases and positively in seven cases, while in the remaining cases it was perceived as neither positive nor negative.",1939-3520,,10.1109/TSE.2017.2677909,ORION project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870688,Decision making;in-house;COTS;OSS;outsourcing,Decision making;Outsourcing;Companies;Computer architecture;Software;Industries,decision making;object-oriented programming;outsourcing;software architecture,CSO decision making;software intensive systems;COTS;OSS;Outsourcing;software component;software system;tailor research solutions;off-the-shelf components;OTS;alternative component sourcing options;CSOs;CSO decisions;nondeterministic solutions;architectural group decision;component origins;architectural group decision making,,9.0,,67.0,,3 Mar 2017,,,IEEE,IEEE Journals
1625,264,Enabling Mutant Generation for Open- and Closed-Source Android Apps,C. Escobar-Velásquez; M. Linares-Vásquez; G. Bavota; M. Tufano; K. P. Moran; M. Di Penta; C. Vendome; C. Bernal-Cárdenas; D. Poshyvanyk,"Systems aned Computing Engineering, Universidad de los Andes Facultad de Ingenieria, 428452 Bogota, Bogot Colombia (e-mail: ca.escobar2434@uniandes.edu.co); Systems Engineering and Computing, Universidad de los Andes, 27991 Bogota, Bogota Colombia (e-mail: m.linaresv@uniandes.edu.co); Faculty of Informatics, Universita della Svizzera Italiana, 27216 Lugano, Lugano Switzerland 6904 (e-mail: gabriele.bavota@usi.ch); Computer Science, College of William and Mary, 8604 Williamsburg, Virginia United States (e-mail: mtufano@email.wm.edu); Computer Science, College of William & Mary, Williamsburg, Virginia United States 23185 (e-mail: kpmoran@cs.wm.edu); Dept. of Engineering, University of Sannio, Benevento, _ Italy 82100 (e-mail: dipenta@unisannio.it); Department of Computer Science & Software Engineering, Miami University, 6403 Oxford, Ohio United States (e-mail: vendomcg@miamioh.edu); Computer Science, College of William and Mary, 8604 Williamsburg, Virginia United States (e-mail: cebernal@cs.wm.edu); Computer Science, William and Mary, Williamsburg, Virginia United States 23188 (e-mail: denys@cs.wm.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Mutation testing has been widely used to assess the fault-detection effectiveness of a test suite, as well as to guide test case generation or prioritization. Empirical studies have shown that, while mutants are generally representative of real faults, an effective application of mutation testing requires “traditional” operators designed for programming languages to be augmented with operators specific to an application domain and/or technology. The case for Android apps is not an exception. Therefore, in this paper we describe the process we followed to create (i) a taxonomy of mutation operations and, (ii) two tools, MDroid+ and MutAPK for mutant generation of Android apps. To this end, we systematically devise a taxonomy of 262 types of Android faults grouped in 14 categories by manually analyzing 2,023 software artifacts from different sources (e.g., bug reports, commits). Then, we identified a set of 38 mutation operators, and implemented them in two tools, the first enabling mutant generation at the source code level, and the second designed to perform mutations at APK level. The rationale for having a dual-approach is based on the fact that source code is not always available when conducting mutation testing. Thus, mutation testing for APKs enables new scenarios in which researchers/practitioners only have access to APK files. The taxonomy, proposed operators, and tools have been evaluated in terms of the number of non-compilable, trivial, equivalent, and duplicate mutants generated and their capacity to represent real faults in Android apps as compared to other well-known mutation tools.",1939-3520,,10.1109/TSE.2020.2982638,National Science Foundation; Google Latin America; Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9052435,Mutation Testing;Fault taxonomy;Mutation Operators;Android,Testing;Tools;Taxonomy;Mobile applications;Computer bugs;Java;Software,,,,,,,,1 Apr 2020,,,IEEE,IEEE Early Access Articles
1626,265,Why My App Crashes Understanding and Benchmarking Framework-specific Exceptions of Android apps,T. Su; L. Fan; S. Chen; Y. Liu; L. Xu; G. Pu; Z. Su,"Department of Computer Science, ETH Zurich Department of Computer Science, 31018 Zurich, Zrich Switzerland 8092 (e-mail: krave_su@163.com); School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: ecnujanefan@gmail.com); School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: ecnuchensen@gmail.com); School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: yangliu@ntu.edu.sg); Computer Science, New York University Shanghai, 447103 Shanghai, Shanghai China (e-mail: lihua.xu@nyu.edu); School of Software Engineering, East China Normal University, Shanghai, Shanghai China (e-mail: ggpu@sei.ecnu.edu.cn); Computer Science, ETH Zurich Department of Computer Science, 31018 Zurich, ZH Switzerland (e-mail: su@cs.ucdavis.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Mobile apps have become ubiquitous. Ensuring their correctness and reliability is important. However, many apps still suffer from occasional to frequent crashes, weakening their competitive edge. Large-scale, deep analyses of the characteristics of real-world app crashes can provide useful insights to both developers and researchers. However, such studies are difficult and yet to be carried out --- this work fills this gap. We collected 16,245 and 8,760 unique exceptions from 2,486 open-source and 3,230 commercial Android apps, respectively, and observed that the exceptions thrown from Android framework (termed ""framework-specific exceptions"") account for the majority. With one-year effort, we (1) extensively investigated these framework-specific exceptions, and (2) further conducted an online survey of 135 professional app developers about how they analyze, test, reproduce and fix these exceptions. Specifically, we aim to understand the framework-specific exceptions from several perspectives: (i) their characteristics (e.g., manifestation locations, fault taxonomy), (ii) the developers' testing practices, (iii) existing bug detection techniques' effectiveness, (iv) their reproducibility and (v) bug fixes. To enable follow-up research (e.g., bug understanding, detection, localization and repairing), we further systematically constructed, DroidDefects, the first comprehensive and largest benchmark of Android app exception bugs. This benchmark contains 33 reproducible exceptions (with test cases, stack traces, faulty and fixed app versions, bug types, etc.), and 3,696 ground-truth exceptions (real faults manifested by automated testing tools), which cover the apps with different complexities and diverse exception types. Based on our findings, we also built two prototype tools: Stoat+, an optimized dynamic testing tool, which quickly uncovered three previously-unknown, fixed crashes in Gmail and Google+; ExLocator, an exception localization tool, which can locate the root causes of specific exception types. Our dataset, benchmark and tools are publicly available on https://github.com/tingsu/droiddefects.",1939-3520,,10.1109/TSE.2020.3013438,Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153947,Mobile applications;Android applications;empirical study;exception analysis;software testing;bug reproducibility,Computer bugs;Tools;Androids;Humanoid robots;Benchmark testing,,,,3.0,,,,31 Jul 2020,,,IEEE,IEEE Early Access Articles
1627,266,Automatic Detection and Update Suggestion for Outdated API Names in Documentation,S. Lee; R. Wu; S. -C. Cheung; S. Kang,"Department of Aerospace and Software Engineering and with the Department of Informatics, Gyeongsang National University, Jinju, Jinju-daero, Republic of Korea; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; School of Computing, KAIST, Daejeon, Republic of Korea",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,653,675,"Application programming interfaces (APIs) continually evolve to meet ever-changing user needs, and documentation provides an authoritative reference for their usage. However, API documentation is commonly outdated because nearly all of the associated updates are performed manually. Such outdated documentation, especially with regard to API names, causes major software development issues. In this paper, we propose a method for automatically updating outdated API names in API documentation. Our insight is that API updates in documentation can be derived from API implementation changes between code revisions. To evaluate the proposed method, we applied it to four open source projects. Our evaluation results show that our method, FreshDoc, detects outdated API names in API documentation with 48 percent higher accuracy than the existing state-of-the-art methods do. Moreover, when we checked the updates suggested by FreshDoc against the developers’ manual updates in the revised documentation, FreshDoc detected 82 percent of the outdated names. When we reported 40 outdated API names found by FreshDoc via issue tracking systems, developers accepted 75 percent of the suggestions. These evaluation results indicate that FreshDoc can be used as a practical method for the detection and updating of API names in the associated documentation.",1939-3520,,10.1109/TSE.2019.2901459,"National Research Foundation of Korea; Ministry of Science, ICT; Hong Kong RGC/GRF; MSRA Collaborative Research Award; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651318,Application programming interfaces;documentation;history;software maintenance,Documentation;Computer bugs;Tools;History;Libraries;Software systems,,,,1.0,,80.0,IEEE,24 Feb 2019,,,IEEE,IEEE Journals
1628,267,A Qualitative Study of the Benefits and Costs of Logging from Developers' Perspectives,H. Li; W. Shang; B. Adams; M. Sayagh; A. E. Hassan,"School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: hengli@cs.queensu.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: shang@encs.concordia.ca); Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, Quebec Canada H3T 1J4 (e-mail: bram.adams@polymtl.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: msayagh@cs.queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software developers insert logging statements in their source code to collect important runtime information of software systems. In practice, logging appropriately is a challenge for developers. Prior studies aimed to improve logging by proactively inserting logging statements in certain code snippets or by learning where to log from existing logging code. However, there exists no work that systematically studies developers' logging considerations, i.e., the benefits and costs of logging from developers' perspectives. Without understanding developers' logging considerations, automated approaches for logging decisions are based primarily on researchers' intuition which may not be convincing to developers. In order to fill the gap between developers' logging considerations and researchers' intuition, we performed a qualitative study that combines a survey of 66 developers and a case study of 223 logging-related issue reports. The findings of our qualitative study draw a comprehensive picture of the benefits and costs of logging from developers' perspectives. We observe that developers consider a wide range of logging benefits and costs, while most of the uncovered benefits and costs have never been observed nor discussed in prior work. We also observe that developers use ad hoc strategies to balance the benefits and costs of logging. Developers need to be fully aware of the benefits and costs of logging, in order to better benefit from logging (e.g., leveraging logging to enable users to solve problems by themselves) and avoid unnecessary negative impact (e.g., exposing users' sensitive information). Future research needs to consider such a wide range of logging benefits and costs when developing automated logging strategies. Our findings also inspire opportunities for researchers and logging library providers to help developers balance the benefits and costs of logging, for example, to support different log levels for different parts of a logging statement, or to help developers estimate and reduce the negative impact of logging statements.",1939-3520,,10.1109/TSE.2020.2970422,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8976297,software logging;issue reports;developer survey;qualitative analysis,Runtime;Libraries;Tools;Software systems;Standards;Computational modeling,,,,2.0,,,,30 Jan 2020,,,IEEE,IEEE Early Access Articles
1629,268,Empirical Effort and Schedule Estimation Models for Agile Processes in the US DoD,W. Rosa; B. K. Clark; R. Madachy; B. Boehm,"NCCA, Department of Navy, Arlington, Virginia, United States, (e-mail: wilymar04@cox.net); Software Metrics, Inc., Software Metrics, Inc., Haymarket, Virginia, United States, (e-mail: brad@software-metrics.com); Systems Engineering Department, Naval Postgraduate School, San Diego, California, United States, 92104 (e-mail: rjmadach@nps.edu); USC Center for Software Engineering, USC, Santa Monica, California, United States, (e-mail: boehm@usc.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Estimating the cost and schedule of agile software projects is critical at an early phase to establish baseline budgets and schedules for the selection of competitive bidders. The challenge is that common agile sizing measures such as story points and user stories are not practical for early estimation as these are often reported after contract award in DoD. This study provides a set of effort and schedule estimation models for agile projects using a sizing measure that is available before proposal evaluation based on data from 36 DoD agile projects. The results suggest that initial software requirements, defined as the sum of functions and external interfaces, is an effective sizing measure for early estimation of effort and schedule of agile projects. The models accuracy improves when application domain groups and peak staff are added as inputs.",1939-3520,,10.1109/TSE.2021.3080666,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432729,Agile software processes;Cost estimation;Requirements/Specification;Software acquisition;Software process;Time estimation,Software;US Department of Defense;Schedules;Estimation;Contracts;Unified modeling language;Agile software development,,,,,,,IEEE,17 May 2021,,,IEEE,IEEE Early Access Articles
1630,269,UniDoSA: The Unified Specification and Detection of Service Antipatterns,F. Palma; N. Moha; Y. Guéhéneuc,"Department of Computer Science and Media Technology, Linnaeus University, Kalmar, Sweden; Department of Computer Science, University of Québec in Montréal, Montréal, Quebec, Canada; Department of Computing and Software Engineering, Polytechnique Montréal, Montréal, Canada",IEEE Transactions on Software Engineering,16 Oct 2019,2019,45,10,1024,1053,"Service-based Systems (SBSs) are developed on top of diverse Service-Oriented Architecture (SOA) technologies or architectural styles. Like any other complex systems, SBSs face both functional and non-functional changes at the design or implementation-level. Such changes may degrade the design quality and quality of service (QoS) of the services in SBSs by introducing poor solutions-service antipatterns. The presence of service antipatterns in SBSs may hinder the future maintenance and evolution of SBSs. Assessing the quality of design and QoS of SBSs through the detection of service antipatterns may ease their maintenance and evolution. However, the current literature lacks a unified approach for modelling and evaluating the design of SBSs in term of design quality and QoS. To address this lack, this paper presents a meta-model unifying the three main service technologies: REST, SCA, and SOAP. Using the meta-model, it describes a unified approach, UniDoSA (Unified Specification and Detection of Service Antipatterns), supported by a framework, SOFA (Service Oriented Framework for Antipatterns), for modelling and evaluating the design quality and QoS of SBSs. We apply and validate UniDoSA on: (1) 18 RESTful APIs, (2) two SCA systems with more than 150 services, and (3) more than 120 SOAP Web services. With a high precision and recall, the detection results provide evidence of the presence of service antipatterns in SBSs, which calls for future studies of their impact on QoS.",1939-3520,,10.1109/TSE.2018.2819180,Natural Sciences and Engineering Research Council of Canada; Canada Chairs; FRQ-NT; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325321,Antipatterns;service-based systems;REST;SCA;SOAP;web services;specification;detection;quality of service;design;software maintenance and evolution,Simple object access protocol;Quality of service;Service-oriented architecture;Maintenance engineering;DSL,application program interfaces;formal specification;quality of service;service-oriented architecture;software maintenance;software quality;Web services,Unified Specification;SOAP Web services;Service-based Systems;service-oriented architecture;SBS;UniDoSA;service antipattern detection;service oriented framework for antipatterns;SOFA;SCA;quality of service;QoS;RESTful API,,1.0,,69.0,,26 Mar 2018,,,IEEE,IEEE Journals
1631,270,"The Art, Science, and Engineering of Fuzzing: A Survey",V. J. M. Manès; H. Han; C. Han; S. K. Cha; M. Egele; E. J. Schwartz; M. Woo,"Computer Science, KAIST, 34968 Daejeon, Yuseong-gu Korea (the Republic of) (e-mail: valentinmanes@outlook.fr); Computer Science, KAIST, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: yungseok.han@kaist.ac.kr); N/A, Naver, Daejeon, Daejeon Korea (the Republic of) (e-mail: cwhan.tunz@navercorp.com); Computer Scienece, KAIST, Daejeon, Yusung-gu Korea (the Republic of) 34141 (e-mail: sangkilc@kaist.ac.kr); Electrical & Computer Engineering, Boston University, Boston, Massachusetts United States (e-mail: megele@bu.edu); Software Engineering Institute, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: edmcman@cmu.edu); Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: pooh@cmu.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Among the many software testing techniques available today, fuzzing has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities. At a high level, fuzzing refers to a process of repeatedly running a program with generated inputs that may be syntactically or semantically malformed. While researchers and practitioners alike have invested a large and diverse effort towards improving fuzzing in recent years, this surge of work has also made it difficult to gain a comprehensive and coherent view of fuzzing. To help preserve and bring coherence to the vast literature of fuzzing, this paper presents a unified, general-purpose model of fuzzing together with a taxonomy of the current fuzzing literature. We methodically explore the design decisions at every stage of our model fuzzer by surveying the related literature and innovations in the art, science, and engineering that make modern-day fuzzers effective.",1939-3520,,10.1109/TSE.2019.2946563,Siemens; Institute of Information communications Technology Planning Evaluation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863940,software security;automated software testing;fuzzing;fuzz testing,Fuzzing;Security;Computer bugs;Terminology,,,,11.0,,,,11 Oct 2019,,,IEEE,IEEE Early Access Articles
1632,271,Pathidea: Improving Information Retrieval-Based Bug Localization by Re-Constructing Execution Paths Using Logs,A. R. Chen; T. -H. P. Chen; S. Wang,"Gina Cody School of Engineering and Computer Science, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: archen94@gmail.com); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Computer Science, University of Manitoba, 8664 Winnipeg, Manitoba, Canada, R3T 2N2 (e-mail: shaoweiwang.2010@hotmail.com)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"To assist developers with debugging and analyzing bug reports, researchers have proposed information retrieval-based bug localization (IRBL) approaches. IRBL approaches leverage the textual information in bug reports as queries to generate a ranked list of potential buggy files that may need further investigation. Although IRBL approaches have shown promising results, most prior research only leverages the textual information that is visible in bug reports, such as bug description or title. However, in addition to the textual description of the bug, developers also often attach logs in bug reports. Logs provide important information that can be used to re-construct the system execution paths when an issue happens and assist developers with debugging. In this paper, we propose an IRBL approach, Pathidea, which leverages logs in bug reports to re-construct execution paths and helps improve the results of bug localization. Pathidea uses static analysis to create a file-level call graph, and re-constructs the call paths from the reported logs. We evaluate Pathidea on eight open source systems, with a total of 1,273 bug reports that contain logs. We find that Pathidea achieves a high recall (up to 51.9% for Top@5). On average, Pathidea achieves an improvement that varies from 8% to 21% and 5% to 21% over BRTracer in terms of Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR) across studied systems, respectively. Moreover, we find that the re-constructed execution paths can also complement other IRBL approaches by providing a 10% and 8% improvement in terms of MAP and MRR, respectively. Finally, we conduct a parameter sensitivity analysis and provide recommendations on setting the parameter values when applying Pathidea.",1939-3520,,10.1109/TSE.2021.3071473,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397337,bug localization;log;bug report;information retrieval,Computer bugs;Location awareness;Debugging;Static analysis;Information retrieval;History;Tools,,,,,,,IEEE,6 Apr 2021,,,IEEE,IEEE Early Access Articles
1633,272,Automating Change-Level Self-Admitted Technical Debt Determination,M. Yan; X. Xia; E. Shihab; D. Lo; J. Yin; X. Yang,"Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Data-driven Analysis of Software (DAS) Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Singapore Management University, Singapore; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1211,1229,"Technical debt (TD) is a metaphor to describe the situation where developers introduce suboptimal solutions during software development to achieve short-term goals that may affect the long-term software quality. Prior studies proposed different techniques to identify TD, such as identifying TD through code smells or by analyzing source code comments. Technical debt identified using comments is known as Self-Admitted Technical Debt (SATD) and refers to TD that is introduced intentionally. Compared with TD identified by code metrics or code smells, SATD is more reliable since it is admitted by developers using comments. Thus far, all of the state-of-the-art approaches identify SATD at the file-level. In essence, they identify whether a file has SATD or not. However, all of the SATD is introduced through software changes. Previous studies that identify SATD at the file-level in isolation cannot describe the TD context related to multiple files. Therefore, it is beneficial to identify the SATD once a change is being made. We refer to this type of TD identification as “Change-level SATD Determination”, which determines whether or not a change introduces SATD. Identifying SATD at the change-level can help to manage and control TD by understanding the TD context through tracing the introducing changes. To build a change-level SATD Determination model, we first identify TD from source code comments in source code files of all versions. Second, we label the changes that first introduce the SATD comments as TD-introducing changes. Third, we build the determination model by extracting 25 features from software changes that are divided into three dimensions, namely diffusion, history and message, respectively. To evaluate the effectiveness of our proposed model, we perform an empirical study on 7 open source projects containing a total of 100,011 software changes. The experimental results show that our model achieves a promising and better performance than four baselines in terms of AUC and cost-effectiveness (i.e., percentage of TD-introducing changes identified when inspecting 20 percent of changed LOC). On average across the 7 experimental projects, our model achieves AUC of 0.82, cost-effectiveness of 0.80, which is a significant improvement over the comparison baselines used. In addition, we found that “Diffusion” is the most discriminative dimension among the three dimensions of features for determining TD-introducing changes.",1939-3520,,10.1109/TSE.2018.2831232,National Natural Science Foundation of China; China Postdoctoral Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352718,Technical debt;software change;change-level determination;self-admitted technical debt,Feature extraction;Java;Labeling;Software quality,project management;public domain software;software maintenance;software management;software metrics;software quality,long-term software quality;source code comments;source code files;software changes;SATD determination model;self-admitted technical debt determination;efficiency 20.0 percent,,6.0,,77.0,IEEE,30 Apr 2018,,,IEEE,IEEE Journals
1634,273,An Empirical Validation of Oracle Improvement,G. Jahangirova; D. Clark; M. Harman; P. Tonella,"Software Engineering, Fondazione Bruno Kessler, 18466 Trento, Trento Italy (e-mail: g.jahangirova@gmail.com); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: david.clark@ucl.ac.uk); CS, UCL, London, London United Kingdom of Great Britain and Northern Ireland WC1E 6BT (e-mail: mark.harman@ucl.ac.uk); Informatics, Universitá della Svizzera Italiana (USI), Lugano, Ticino Switzerland (e-mail: paolo.tonella@usi.ch)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"We propose a human-in-the-loop approach for oracle improvement and analyse whether the proposed oracle improvement process is helping developers to create better oracles. For this, we conducted two human studies with 68 participants overall: an oracle assessment study and an oracle improvement study. Our results show that developers exhibit poor performance (29% accuracy) when manually assessing whether an assertion oracle contains a false positive, a false negative or none of the two. This shows that automated detection of these oracle deficiencies is beneficial for the users. Our tool OASIs (Oracle ASsessment and Improvement) helps developers produce assertions with higher quality. Participants who used OASIs in the improvement study were able to achieve 33% of full and 67% of partial correctness as opposed to participants without the tool who achieved only 21% of full and 43% of partial correctness.",1939-3520,,10.1109/TSE.2019.2934409,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794642,Oracle Problem;Test Oracle;Oracle Assessment;Oracle Improvement;Human Study;Test Case Generation;Mutation Testing,Tools;Standards;Generators;Indexes;Software testing;Software,,,,1.0,,,,12 Aug 2019,,,IEEE,IEEE Early Access Articles
1635,274,"Machine Learning Testing: Survey, Landscapes and Horizons",J. M. Zhang; M. Harman; L. Ma; Y. Liu,"CREST, University College London, United Kingdom. Mark Harman is also with Facebook London (e-mail: jie.zhang@ucl.ac.uk); CREST, University College London, United Kingdom. Mark Harman is also with Facebook London (e-mail: mark.harman@ucl.ac.uk); Kyushu University, Japan (e-mail: malei.2005@gmail.com); Nanyang Technological University, Singapore (e-mail: yangliu@ntu.edu.sg)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"This paper provides a comprehensive survey of Machine Learning Testing (ML testing) research. It covers 138 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in machine learning testing.",1939-3520,,10.1109/TSE.2019.2962027,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000651,machine learning;software testing;deep neural network,Machine learning;Software testing;Software engineering;Training data;Data models;Robustness,,,,31.0,,,,17 Feb 2020,,,IEEE,IEEE Early Access Articles
1636,275,Specialising Software for Different Downstream Applications Using Genetic Improvement and Code Transplantation,J. Petke; M. Harman; W. B. Langdon; W. Weimer,"University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University of Virginia, Charlottesville, VA",IEEE Transactions on Software Engineering,12 Jun 2018,2018,44,6,574,594,"Genetic improvement uses automated search to find improved versions of existing software. Genetic improvement has previously been concerned with improving a system with respect to all possible usage scenarios. In this paper, we show how genetic improvement can also be used to achieve specialisation to a specific set of usage scenarios. We use genetic improvement to evolve faster versions of a C++ program, a Boolean satisfiability solver called MiniSAT, specialising it for three different applications, each with their own characteristics. Our specialised solvers achieve between 4 and 36 percent execution time improvement, which is commensurate with efficiency gains achievable using human expert optimisation for the general solver. We also use genetic improvement to evolve faster versions of an image processing tool called ImageMagick, utilising code from GraphicsMagick, another image processing tool which was forked from it. We specialise the format conversion functionality to greyscale images and colour images only. Our specialised versions achieve up to 3 percent execution time improvement.",1939-3520,,10.1109/TSE.2017.2702606,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962212,Genetic improvement;GI;code transplants;code specialisation;SAT;ImageMagick;GraphicsMagick,Software;Software engineering;Image processing;C++ languages;Genetic programming;Optimization,Boolean algebra;C++ language;computability;genetic algorithms;image colour analysis;source code (software),genetic improvement;execution time improvement;code transplantation;C++ program;Boolean satisfiability solver;MiniSAT;software specialisation;downstream application;image processing tool;ImageMagick;GraphicsMagick;greyscale images;colour images,,4.0,,97.0,,29 Jun 2017,,,IEEE,IEEE Journals
1637,276,Output Sampling for Output Diversity in Automatic Unit Test Generation,H. Menéndez Benito; M. Boreale; D. Gorla; D. Clark,"Computer Science, Middlesex University, 4907 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: h.menendez@mdx.ac.uk); Computer Science, University of Florence, 9300 Firenze, Toscana Italy (e-mail: michele.boreale@unifi.it); Dept. of Computer Science, University of Rome Sapienza, 00100 Roma, Italy (e-mail: gorla@di.uniroma1.it); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: david.clark@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Diverse test sets are able to expose bugs that test sets generated with structural coverage techniques cannot discover. Input-diverse test set generators have been shown to be effective for this, but also have limitations: e.g., they need to be complemented with semantic information derived from the Software Under Test. We demonstrate how to drive the test set generation process with semantic information in the form of output diversity. We present the first totally automatic output sampling for output diversity unit test set generation tool, called OutGen. OutGen transforms a program into an SMT formula in bit-vector arithmetic. It then applies universal hashing in order to generate an output-based diverse set of inputs. The result offers significant diversity improvements when measured as a high output uniqueness count. It achieves this by ensuring that the test set's output probability distribution is uniform, i.e. highly diverse. The use of output sampling, as opposed to any of input sampling, CBMC, CAVM, behaviour diversity or random testing improves mutation score and bug detection by up to 4150% and 963% respectively on programs drawn from three different corpora: the R-project, SIR and CodeFlaws. OutGen test sets achieve an average mutation score of up to 92%, and 70% of the test sets detect the defect. Moreover, OutGen is the only automatic unit test generation tool that is able to detect bugs on the real number C functions from the R-project.",1939-3520,,10.1109/TSE.2020.2987377,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068446,Unit Testing;Output Sampling;Output Diversity;SMT Solver;OutGen,Computer bugs;Tools;Semantics;Generators;Software engineering;Test pattern generators,,,,,,,,15 Apr 2020,,,IEEE,IEEE Early Access Articles
1638,277,Platform-Independent Dynamic Taint Analysis for JavaScript,R. Karim; F. Tip; A. Sochůrková; K. Sen,"Samsung Research America, Mountain View, CA, USA; College of Computer and Information Science, Northeastern University, Boston, MA, USA; Avast, Prague, Czechia; University of California at Berkeley, Berkeley, CA, USA",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1364,1379,"Previous approaches to dynamic taint analysis for JavaScript are implemented directly in a browser or JavaScript engine, limiting their applicability to a single platform and requiring ongoing maintenance as platforms evolve, or they require nontrivial program transformations. We present an approach that relies on instrumentation to encode taint propagation as instructions for an abstract machine. Our approach has two key advantages: it is platform-independent and can be used with any existing JavaScript engine, and it can track taint on primitive values without requiring the introduction of wrapper objects. Furthermore, our technique enables multiple deployment scenarios by varying when and where the generated instructions are executed and it supports indirect taint sources, i.e., situations where taint enters an application via arguments passed to dynamically registered event-listener functions. We implemented the technique for the ECMAScript 5 language in a tool called Ichnaea, and evaluated it on 22 NPM modules containing several types of injection vulnerabilities, including 4 modules containing vulnerabilities that were not previously discovered and reported. On these modules, run-time overheads range from 3.17x to 38.42x, which is significantly better than a previous transformation-based technique. We also report on a case study that shows how Ichnaea can be used to detect privacy leaks in a Tizen web application for the Samsung Gear S2 smart watch.",1939-3520,,10.1109/TSE.2018.2878020,Czech Technical University; European Research Council; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8511058,Taint analysis;dynamic analysis;JavaScript;platform-independent;instrumentation,Java;Instruments;Browsers;Software engineering;Privacy;Data privacy,authoring languages;data privacy;Internet;program compilers;wearable computers,platform-independent dynamic taint analysis;nontrivial program transformations;taint propagation;abstract machine;JavaScript engine;multiple deployment scenarios;dynamically registered event-listener functions;Tizen Web application;ECMAScript 5 language;Ichnaea;privacy leaks detection;wrapper objects;Samsung Gear S2 smart watch;NPM modules,,3.0,,39.0,IEEE,26 Oct 2018,,,IEEE,IEEE Journals
1639,278,Effects of Personality Traits on Pull Request Acceptance,R. N. Iyer; S. A. Yun; M. Nagappan; J. Hoey,"David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: r3iyer@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: alex.yun@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: mei.nagappan@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: jhoey@cs.uwaterloo.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"In this paper, we examine the influence of personality traits of developers on the pull request evaluation process in GitHub. We first replicate Tsay et al.'s work that examined the influence of social factors (e.g., ‘social distance’) and technical factors (e.g., test file inclusion) for evaluating contributions, and then extend it with personality-based factors. In particular, we extract the Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) of developers from their online digital footprints, such as pull request comments. We analyze the personality traits of 16,935 active developers from 1,860 projects and compare their relative importance to other non-personality factors from past research, in the pull request evaluation process. We find that pull requests from authors (requesters) who are more open and conscientious, but less extroverted, have a higher chance of approval. Furthermore, pull requests that are closed by developers (closers) who are more conscientious, extroverted, and neurotic, have a higher likelihood of acceptance. The larger the difference in personality traits between the requester and the closer, the more positive effect it has on pull request acceptance. Finally, although the effect of personality traits is significant and comparable to technical factors, we find that social factors are still more influential on the likelihood of pull request acceptance.",1939-3520,,10.1109/TSE.2019.2960357,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935389,pull request;GitHub;online collaborative environments;open source systems;personality;Big Five;five-factor model,Psychology;Social factors;Software engineering;Task analysis;Dictionaries;Robots;Software,,,,1.0,,,,17 Dec 2019,,,IEEE,IEEE Early Access Articles
1640,279,Characterizing Crowds to Better Optimize Worker Recommendation in Crowdsourced Testing,J. Wang; S. Wang; J. Chen; T. Menzies; Q. Cui; M. Xie; Q. Wang,"Institute of Software, Chinese Academy of Sciences, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing China 100190 (e-mail: junjie@nfs.iscas.ac.cn); Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario Canada N2L 3G1 (e-mail: song.wang@uwaterloo.ca); Computer science, North Carolina State University, 6798 Raleigh, North Carolina United States 27695 (e-mail: jchen37@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org); Data, Bytedance Inc., Beijing, Beijing China (e-mail: cuiqiang1225@gmail.com); CBG, Huawei Technologies Co Ltd, 115371 Beijing, Beijing China (e-mail: 0520shui@163.com); Institute of Software, Chinese Academy of Sciences, Beijing, Beijing China 100190 (e-mail: wq@itechs.iscas.ac.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Crowdsourced testing is an emerging trend, in which test tasks are entrusted to the online crowd workers. Typically, a crowdsourced test task aims to detect as many bugs as possible within a limited budget. However not all crowd workers are equally skilled at finding bugs; Inappropriate workers may miss bugs, or report duplicate bugs, while hiring them requires nontrivial budget. Therefore, it is of great value to recommend a set of appropriate crowd workers for a test task so that more software bugs can be detected with fewer workers. This paper first presents a new characterization of crowd workers and characterizes them with testing context, capability, and domain knowledge. Based on the characterization, we then propose Multi-Objective Crowd wOrker recoMmendation approach (MOCOM), which aims at recommending a minimum number of crowd workers who could detect the maximum number of bugs for a crowdsourced testing task. Specifically, MOCOM recommends crowd workers by maximizing the bug detection probability of workers, the relevance with the test task, the diversity of workers, and minimizing the test cost. We experimentally evaluate MOCOM on 532 test tasks, and results show that MOCOM significantly outperforms five commonly-used and state-of-the-art baselines. Furthermore, MOCOM can reduce duplicate reports and recommend workers with high relevance and larger bug detection probability; because of this it can find more bugs with fewer workers.",1939-3520,,10.1109/TSE.2019.2918520,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721154,Crowdsourced testing;Crowd worker recommendation;Multi-objective optimization,Task analysis;Computer bugs;Testing;Software;Videos;Software engineering;Optimization,,,,1.0,,,,23 May 2019,,,IEEE,IEEE Early Access Articles
1641,280,Whence to Learn? Transferring Knowledge in Configurable Systems using BEETLE,R. Krishna; V. Nair; P. Jamshidi; T. Menzies,"Computer Science, Columbia University, 5798 New York, New York United States (e-mail: i.m.ralk@gmail.com); Computer Science, NC State University, 6798 Raleigh, North Carolina United States (e-mail: vivekaxl@gmail.com); Computer Science and Engineering, University of South Carolina, Columbia, South Carolina United States (e-mail: pjamshid@cse.sc.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"As software systems grow in complexity and the space of possible configurations increases exponentially, finding the near-optimal configuration of a software system becomes challenging. Recent approaches address this challenge by learning performance models based on a sample set of configurations. However, collecting enough sample configurations can be very expensive since each such sample requires configuring, compiling, and executing the entire system using a complex test suite. When learning on new data is too expensive, it is possible to use Transfer Learning to “transfer” old lessons to the new context. Traditional transfer learning has a number of challenges, specifically, (a) learning from excessive data takes excessive time, and (b) the performance of the models built via transfer can deteriorate as a result of learning from a poor source. To resolve these problems, we propose a novel transfer learning framework called BEETLE, which is a “bellwether”-based transfer learner that focuses on identifying and learning from the most relevant source from amongst the old data. This paper evaluates BEETLE with 57 different software configuration problems based on five software systems (a video encoder, an SAT solver, a SQL database, a high-performance C-compiler, and a streaming data analytics tool). In each of these cases, BEETLE found configurations that are as good as or better than those found by other state-of-the-art transfer learners while requiring only a fraction 1/7th of the measurements needed by those other methods. Based on these results, we say that BEETLE is a new high-water mark in optimally configuring software.",1939-3520,,10.1109/TSE.2020.2983927,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050841,Performance Optimization;SBSE;Transfer Learning;Bellwether,Optimization;Software systems;Data collection;Tools;Computer science;Software engineering,,,,,,,,30 Mar 2020,,,IEEE,IEEE Early Access Articles
1642,281,User Review-Based Change File Localization for Mobile Applications,Y. Zhou; Y. Su; T. Chen; Z. Huang; H. C. Gall; S. Panichella,"Dept. of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China 211106 (e-mail: zhouyu@nuaa.edu.cn); Dept. of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: suyanqi@nuaa.edu.cn); Department of Computer Science and Information Systems, Birkbeck University of London, 4894 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: taolue@dcs.bbk.ac.uk); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu China (e-mail: zqhuang@nuaa.edu.cn); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: gall@ifi.uzh.ch); School of Engineering, Zurcher Hochschule fur Angewandte Wissenschaften, 30944 Winterthur, Zurich Switzerland 8400 (e-mail: panc@zhaw.ch)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"In the current mobile app development, novel and emerging DevOps practices (e.g., Continuous Delivery, Integration, and user feedback analysis) and tools are becoming more widespread. For instance, the integration of user feedback (provided in the form of user reviews) in the software release cycle represents a valuable asset for the maintenance and evolution of mobile apps. To fully make use of these assets, it is highly desirable for developers to establish semantic links between the user reviews and the software artefacts to be changed (e.g., source code and documentation), and thus to localize the potential files to change for addressing the user feedback. In this paper, we propose RISING (Reviews Integration via claSsification, clusterIng, and linkiNG), an automated approach to support the continuous integration of user feedback via classification, clustering, and linking of user reviews. RISING leverages domain-specific constraint information and semi-supervised learning to group user reviews into multiple fine-grained clusters concerning similar users' requests. Then, by combining the textual information from both commit messages and source code, it automatically localizes potential change files to accommodate the users' requests. Our empirical studies demonstrate that the proposed approach outperforms the state-of-the-art baseline work in terms of clustering and localization accuracy, and thus produces more reliable results.",1939-3520,,10.1109/TSE.2020.2967383,ARC Discovery Project; UK EPSRC grant; NSFC grant; National Key R and D Program of China; SNF Project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961125,User review;Mobile apps;Information retrieval;Change File Localization,Software;Mobile applications;Testing;Tools;Maintenance engineering;Reliability;Software engineering,,,,,,,,16 Jan 2020,,,IEEE,IEEE Early Access Articles
1643,282,Combining Code and Requirements Coverage with Execution Cost for Test Suite Reduction,A. Marchetto; G. Scanniello; A. Susi,"NA; University of Basilicata, Potenza, Italy; Fondazione Bruno Kessler, Trento, Italy",IEEE Transactions on Software Engineering,16 Apr 2019,2019,45,4,363,390,"Test suites tend to become large and complex after software evolution iterations, thus increasing effort and cost to execute regression testing. In this context, test suite reduction approaches could be applied to identify subsets of original test suites that preserve the capability of satisfying testing requirements and revealing faults. In this paper, we propose Multi-Objective test suites REduction (named MORE+): a three-dimension approach for test suite reduction. The first dimension is the structural one and concerns the information on how test cases in a suite exercise the under-test application. The second dimension is functional and concerns how test cases exercise business application requirements. The third dimension is the cost and concerns the time to execute test cases. We define MORE+ as a multi-objective approach that reduces test suites so maximizing their capability in revealing faults according to the three considered dimensions. We have compared MORE+ with seven baseline approaches on 20 Java applications. Results showed, in particular, the effectiveness of MORE+ in reducing test suites with respect to these baselines, i.e., significantly more faults are revealed with test suites reduced by applying MORE+.",1939-3520,,10.1109/TSE.2017.2777831,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120000,Multi-objective approach;regression testing;testing;test suite reduction,Testing;Software;Business;Java;Space exploration;Large scale integration;Software engineering,Java;program testing;regression analysis;software fault tolerance;software maintenance,test cases;suite exercise;under-test application;regression testing;original test suites;MultiObjective test suites REduction,,4.0,,79.0,,27 Nov 2017,,,IEEE,IEEE Journals
1644,283,Beyond Technical Aspects: How Do Community Smells Influence the Intensity of Code Smells?,F. Palomba; D. Andrew Tamburri; F. Arcelli Fontana; R. Oliveto; A. Zaidman; A. Serebrenik,"University of Zürich, Zürich, Switzerland; Eindhoven University of Technology, Eindhoven, AZ, The Netherlands; University of Milano Bicocca, Milano, Italy; University of Molise, Campobasso, Italy; Delft Unversity of Technology, Delft, CD, The Netherlands; Eindhoven University of Technology, Eindhoven, AZ, The Netherlands",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,108,129,"Code smells are poor implementation choices applied by developers during software evolution that often lead to critical flaws or failure. Much in the same way, community smells reflect the presence of organizational and socio-technical issues within a software community that may lead to additional project costs. Recent empirical studies provide evidence that community smells are often-if not always-connected to circumstances such as code smells. In this paper we look deeper into this connection by conducting a mixed-methods empirical study of 117 releases from 9 open-source systems. The qualitative and quantitative sides of our mixed-methods study were run in parallel and assume a mutually-confirmative connotation. On the one hand, we survey 162 developers of the 9 considered systems to investigate whether developers perceive relationship between community smells and the code smells found in those projects. On the other hand, we perform a fine-grained analysis into the 117 releases of our dataset to measure the extent to which community smells impact code smell intensity (i.e., criticality). We then propose a code smell intensity prediction model that relies on both technical and community-related aspects. The results of both sides of our mixed-methods study lead to one conclusion: community-related factors contribute to the intensity of code smells. This conclusion supports the joint use of community and code smells detection as a mechanism for the joint management of technical and social problems around software development communities.",1939-3520,,10.1109/TSE.2018.2883603,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546762,Code smells;organizational structure;community smells;mixed-methods study,Predictive models;Software engineering;Open source software;Convergence;Tools;Feature extraction,consumer behaviour;organisational aspects;public domain software;software maintenance;software management;software metrics;software quality,code smells;community smells;socio-technical issues;software community;recent empirical studies;mixed-methods empirical study;mixed-methods study;impact code smell intensity;code smell intensity prediction model;community-related aspects;community-related factors;software development communities,,9.0,,144.0,IEEE,27 Nov 2018,,,IEEE,IEEE Journals
1645,284,Methodological Principles for Reproducible Performance Evaluation in Cloud Computing,A. V. Papadopoulos; L. Versluis; A. Bauer; N. Herbst; J. Von Kistowski; A. Ali-eldin; C. Abad; J. N. Amaral; P. Tůma; A. Iosup,"IDT, Maladalen University, 8177 Vasteras, Vasteras Sweden (e-mail: alessandro.papadopoulos@mdh.se); Computer Science, Vrije Universiteit Amsterdam, 1190 Amsterdam, Noord-Holland Netherlands (e-mail: l.f.d.versluis@vu.nl); Computer Science, Julius-Maximilians-Universitat Wurzburg, 9190 Würzburg, Bavaria Germany (e-mail: andre.bauer@uni-wuerzburg.de); Computer Science, Julius-Maximilians-Universitat Wurzburg, 9190 Würzburg, Bavaria Germany 97070 (e-mail: nikolas.herbst@uni-wuerzburg.de); Computer Science, Julius-Maximilians-Universitat Wurzburg, 9190 Würzburg, Bavaria Germany (e-mail: joakim.kistowski@uni-wuerzburg.de); Department of Computing Science, Umea University, 8075 Umea, Umea Sweden (e-mail: ahmeda@cs.umu.se); Computer Science, Escuela Superior Politecnica del Litoral, 27883 Guayaquil, Guayas Ecuador (e-mail: cabad@fiec.espol.edu.ec); Department of Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada (e-mail: jamaral@ualberta.ca); Department of Distributed and Dependable Systems, Charles University, 37740 Prague, Prague Czech Republic (e-mail: petr.tuma@d3s.mff.cuni.cz); Computer Science, Vrije Universiteit Amsterdam, 1190 Amsterdam, Noord-Holland Netherlands (e-mail: A.Iosup@vu.nl)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The rapid adoption and the diversification of cloud computing technology exacerbate the importance of a sound experimental methodology for this domain. This work investigates how to measure and report performance in the cloud, and how well the cloud research community is already doing it. We propose a set of eight important methodological principles that combine best-practices from nearby fields with concepts applicable only to clouds, and with new ideas about the time-accuracy trade-off. We show how these principles are applicable using a practical use-case experiment. To this end, we analyze the ability of the newly released SPEC Cloud IaaS benchmark to follow the principles, and showcase real-world experimental studies in common cloud environments that meet the principles. Last, we report on a systematic literature review including top conferences and journals in the field, from 2012 to 2017, analyzing if the practice of reporting cloud performance measurements follows the proposed eight principles. Worryingly, this systematic survey and the subsequent two-round human reviews, reveal that few of the published studies follow the eight experimental principles. We conclude that, although these important principles are simple and basic, the cloud community is yet to adopt them broadly to deliver sound measurement of cloud environments.",1939-3520,,10.1109/TSE.2019.2927908,Stiftelsen för Kunskaps- och Kompetensutveckling; Deutsche Forschungsgemeinschaft; Nederlandse Organisatie voor Wetenschappelijk Onderzoek; H2020 Marie Sklodowska-Curie Actions; Vetenskapsradet; Stiftelsen for Strategisk Forskning; Google; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758926,Experimental evaluation;observation study;experimentation,Cloud computing;Performance evaluation;Benchmark testing;Systematics;Computer performance;Software engineering,,,,6.0,,,,10 Jul 2019,,,IEEE,IEEE Early Access Articles
1646,285,Bellwethers: A Baseline Method for Transfer Learning,R. Krishna; T. Menzies,"Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC",IEEE Transactions on Software Engineering,12 Nov 2019,2019,45,11,1081,1105,"Software analytics builds quality prediction models for software projects. Experience shows that (a) the more projects studied, the more varied are the conclusions; and (b) project managers lose faith in the results of software analytics if those results keep changing. To reduce this conclusion instability, we propose the use of “bellwethers”: given N projects from a community the bellwether is the project whose data yields the best predictions on all others. The bellwethers offer a way to mitigate conclusion instability because conclusions about a community are stable as long as this bellwether continues as the best oracle. Bellwethers are also simple to discover (just wrap a for-loop around standard data miners). When compared to other transfer learning methods (TCA+, transfer Naive Bayes, value cognitive boosting), using just the bellwether data to construct a simple transfer learner yields comparable predictions. Further, bellwethers appear in many SE tasks such as defect prediction, effort estimation, and bad smell detection. We hence recommend using bellwethers as a baseline method for transfer learning against which future work should be compared.",1939-3520,,10.1109/TSE.2018.2821670,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329264,Transfer learning;defect prediction;bad smells;issue close time;effort estimation;prediction,Estimation;Software;Software engineering;Task analysis;Benchmark testing;Complexity theory;Analytical models,learning (artificial intelligence);project management;software maintenance;software quality,software analytics;quality prediction models;software projects;transfer learning methods;bellwether data,,6.0,,154.0,,2 Apr 2018,,,IEEE,IEEE Journals
1647,286,Specification Patterns for Robotic Missions,C. Menghi; C. Tsigkanos; P. Pelliccione; C. Ghezzi; T. Berger,"SnT - Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: claudio.menghi@uni.lu); Distibuted Systems Group, TU Vienna, Vienna, Vienna Austria (e-mail: christos.tsigkanos@polimi.it); Department of Computer Science, University of L'Aquila, L'Aquila, aq Italy (e-mail: patrizio.pelliccione@univaq.it); Dip. di Elettronica e Informazione, Politecnico Milano, Milano, Italy Italy 20133 (e-mail: carlo.ghezzi@polimi.it); Department of Computer Science and Engineering, Chalmers | University of Gothenburg, Gothenburg, Gothenburg Sweden (e-mail: thorsten.berger@chalmers.se)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Mobile and general-purpose robots increasingly support our everyday life, requiring dependable robotics control software. Creating such software mainly amounts to implementing their complex behaviors known as missions. Recognizing this need, a large number of domain-specific specification languages has been proposed. These, in addition to traditional logical languages, allow the use of formally specified missions for synthesis, verification, simulation or guiding implementation. For instance, the logical language LTL is commonly used by experts to specify missions as an input for planners, which synthesize the behavior a robot should have. Unfortunately, domain-specific languages are usually tied to specific robot models, while logical languages such as LTL are difficult to use by non-experts. We present a catalog of 22 mission specification patterns for mobile robots, together with tooling for instantiating, composing, and compiling the patterns to create mission specifications. The patterns provide solutions for recurrent specification problems, each of which detailing the usage intent, known uses, relationships to other patterns, and-most importantly-a template mission specification in temporal logic. Our tooling produces specifications expressed in the temporal logics LTL and CTL to be used by planners, simulators or model checkers. The patterns originate from 245 realistic textual mission requirements extracted from the robotics literature, and they are evaluated upon a total of 441 real-world mission requirements and 1251 mission specifications. Five of these reflect scenarios we defined with two well-known industrial partners developing human-size robots. We validated our patterns' correctness with simulators and two different types of real robots.",1939-3520,,10.1109/TSE.2019.2945329,Université du Luxembourg; H2020 European Research Council; H2020 LEIT Information and Communication Technologies; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859226,,Software;Service robots;Natural languages;Software engineering;Tools;Task analysis,,,,5.0,,,,4 Oct 2019,,,IEEE,IEEE Early Access Articles
1648,287,Software Development Process Ambidexterity and Project Performance: A Coordination Cost-Effectiveness View,K. Werder; Y. Li; A. Maedche; B. Ramesh,"University of Cologne, Cologne, Germany; University of Mannheim, Mannheim, Germany; Institute of Information Systems and Marketing (IISM), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Department of Computer Information Systems, Robinson College of Business, Georgia State University, Atlanta",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,836,849,"Software development process ambidexterity (SDPA) is the ability to demonstrate both process alignment and process adaptability simultaneously. Realizing process ambidexterity has recently been suggested as an effective approach to improving the performance of software development (SD) projects. To understand the mechanisms underlying the effects of ambidexterity, we focus in this study on the mediating effects of coordination, one of the most important activity in SD projects. Specifically, we hypothesize a mediating effect of coordination costs and coordination effectiveness on the relationship between SDPA and project performance. We conducted a quantitative study involving 104 SD projects across 10 firms to test the model. The results strongly suggest that the positive relationship between SDPA and project performance is negatively mediated by coordination costs and positively mediated by coordination effectiveness. We validate our research model with a case study in an organization employing several hundred IT professionals and derive several practical implications on this basis.",1939-3520,,10.1109/TSE.2019.2904571,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8665932,Ambidexterity;coordination;coordination cost;cost-effectiveness;project performance;software development,Software;Organizations;Technological innovation;Information systems;Sensors;Software engineering,,,,,,110.0,IEEE,12 Mar 2019,,,IEEE,IEEE Journals
1649,288,Reusing Solutions Modulo Theories,A. Aquino; G. Denaro; M. Pezzè,"Università della Svizzera italiana (USI), Lugano, Switzerland; Università di Milano - Bicocca, Milano, Italy; Università della Svizzera italiana (USI), Lugano, Switzerland",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,948,968,"In this paper we propose an approach for reusing formula solutions to reduce the impact of Satisfiability Modulo Theories (SMT) solvers on the scalability of symbolic program analysis. SMT solvers can efficiently handle huge expressions in relevant logic theories, but they still represent a main bottleneck to the scalability of symbolic analyses, like symbolic execution and symbolic model checking. Reusing proofs of formulas solved during former analysis sessions can reduce the amount of invocations of SMT solvers, thus mitigating the impact of SMT solvers on symbolic program analysis. Early approaches to reuse formula solutions exploit equivalence and inclusion relations among structurally similar formulas, and are strongly tighten to the specific target logics. In this paper, we present an original approach that reuses both satisfiability and unsatisfiability proofs shared among many formulas beyond only equivalent or related-by-implication formulas. Our approach straightforwardly generalises across multiple logics. It is based on the original concept of distance between formulas, which heuristically approximates the likelihood of formulas to share either satisfiability or unsatisfiability proofs. We show the efficiency and the generalisability of our approach, by instantiating the underlying distance function for formulas that belong to most popular logic theories handled by current SMT solvers, and confirm the effectiveness of the approach, by reporting experimental results on over nine millions formulas from five logic theories.",1939-3520,,10.1109/TSE.2019.2898199,Swiss SNF; Italian MIUR PRIN project GAUSS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681653,Symbolic program analysis;symbolic execution;SMT solver;solution reuse,Scalability;Software engineering;Prototypes;Terminology;Model checking;Indexes,,,,1.0,,33.0,OAPA,4 Apr 2019,,,IEEE,IEEE Journals
1650,289,Recommending API Function Calls and Code Snippets to Support Software Development,P. T. Nguyen; J. Di Rocco; C. Di Sipio; D. Di Ruscio; M. Di Penta,"Department of Computer Science, Information Engineering and Mathematics, University of L'Aquila Department of Information Engineering Computer Science and Mathematics, 220003 L'Aquila, L'Aquila, Italy, (e-mail: phuong.nguyen@univaq.it); DISIM, Universit degli Studi dell'Aquila, 9303 L'AQUILA, AQ, Italy, 67100 (e-mail: juri.dirocco@univaq.it); Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Universit degli Studi dell'Aquila, Italy, AQ, Italy, (e-mail: claudio.disipio@univaq.it); Department of Information Engineering Computer Science and Mathematics, University of L'Aquila, L'Aquila, AQ, Italy, 67100 (e-mail: davide.diruscio@univaq.it); Dept. of Engineering, University of Sannio, Benevento, _, Italy, 82100 (e-mail: dipenta@unisannio.it)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Software development activity has reached a high degree of complexity, guided by the heterogeneity of the components, data sources, and tasks. The proliferation of open-source software (OSS) repositories has stressed the need to reuse available software artifacts efciently. To this aim, it is necessary to explore approaches to mine data from software repositories and leverage it to produce helpful recommendations. We designed and implemented FOCUS as a novel approach to provide developers with API calls and source code while they are programming. The system works on the basis of a context-aware collaborative ltering technique to extract API usages from OSS projects. In this work, we show the suitability of FOCUS for Android programming by evaluating it on a dataset of 2,600 mobile apps. The empirical evaluation results show that our approach outperforms two state-of-the-art API recommenders, UP-Miner and PAM, in terms of prediction accuracy. We also point out that there is no signicant relationship between the categories for apps dened in Google Play and their API usages. Finally, we show that participants of a user study positively perceive the API and source code recommended by FOCUS as relevant to the current development context.",1939-3520,,10.1109/TSE.2021.3059907,H2020 LEIT Information and Communication Technologies; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359479,Recommender Systems;API Calls;Source Code Recommendations;Android Programming,Recommender systems;Libraries;Tools;Data mining;Task analysis;Software engineering;Documentation,,,,,,,IEEE,19 Feb 2021,,,IEEE,IEEE Early Access Articles
1651,290,Migrating a Software Factory to Design Thinking: Paying Attention to People and Mind-Sets,N. Mahe; B. Adams; J. Marsan; M. Templier; S. Bissonnette,"Design Thinking Montreal, Montreal, Quebec, Canada; Maintenance, Construction, and Intelligence of Software, Polytechnique Montreal, Montreal, Quebec, Canada; Centre de recherche en technologies de l’information et affaires, Universite Laval, Quebec City, Quebec, Canada; Information Systems, Universite Laval, Quebec City, Quebec, Canada; Proaction Technologies, Montreal, Quebec, Canada",IEEE Software,11 Feb 2020,2020,37,2,32,40,"Design thinking (DT) has found its way into software engineering, promising better requirements elicitation, customer relations, and cohesion within the development team. We report on Proaction Technologies' migration toward DT and evaluate the process through interviews with employees and clients.",1937-4194,,10.1109/MS.2019.2958646,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928978,,Software development management;Prototypes;Companies;Production facilities;Biological system modeling,personnel;software engineering,proaction technologies migration;customer relations;requirements elicitation;software engineering;design thinking;software factory;development team,,,,15.0,,8 Dec 2019,,,IEEE,IEEE Magazines
1652,291,Exercising Power in Software Ecosystems,C. Alves; G. Valença; X. Franch,"Universidade Federal de Pernambuco, Recife, Brazil; Universidade Federal Rural de Pernambuco, Recife, Brazil; Universitat Politècnica de Catalunya, Barcelona, Spain",IEEE Software,16 Apr 2019,2019,36,3,50,54,"Companies in a software ecosystem must understand which power capabilities drive cooperation or generate conflicts. In this article, we analyze how power influences the relationships among companies in ecosystems formed by small-to-medium enterprises as well as in platform ecosystems governed by large keystones.",1937-4194,,10.1109/MS.2018.290101618,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409909,Software;Software Engineering;Software Engineering;Management;organizational management and coordination;computing Milieux;Management of Computing and Information Systems;Software management;services computing;enterprise modeling and management;general;dynamics of services ecosystem;inter-enterprise collaboration;services value chain collaboration;services composition;services computing;strategic information systems planning;project and people management management of computing and information,Ecosystems;Software development management;Object recognition;Customer relationship management;System integration,innovation management;organisational aspects;small-to-medium enterprises,software ecosystem;power capabilities;platform ecosystems;small-to-medium enterprises,,,,11.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1653,292,User Engagement in the Era of Hybrid Agile Methodology,K. Schmitz; R. Mahapatra; S. Nerur,"Georgia State University, United States; University of Texas at Arlington, United States; Information Systems, University of Texas at Arlington, United States",IEEE Software,17 Jun 2019,2019,36,4,32,40,Contemporary software development and implementation projects are increasingly adopting agile methods by tailoring and blending agile techniques into a traditional project framework. Common tailoring methods employed by project teams emphasize flexibility to embrace local project context.,1937-4194,,10.1109/MS.2018.290100623,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409910,agile software development;hybrid project methods;Software development;Software management;Management of Computing and Information Systems;Computing Mil;Software;Software Engineering;Software Engineering;Management;programming teams;project management and collaboration;service-oriented business consulting;service-oriented consulting,Training data;Information exchange;Green products;Software testing;Software development;Couplings,software development management;software prototyping,user engagement;hybrid agile methodology;agile methods;agile techniques;traditional project framework;project teams;local project context;contemporary software development,,,,15.0,,11 Jul 2018,,,IEEE,IEEE Magazines
1654,293,Toward Analysis and Bug Finding in JavaScript Web Applications in the Wild,S. Ryu; J. Park; J. Park,"Computing, Korea Advanced Institute of Science and Technology; Computing, Korea Advanced Institute of Science and Technology; Computing, Korea Advanced Institute of Science and Technology",IEEE Software,16 Apr 2019,2019,36,3,74,82,"We present our journey to analyze and find bugs in JavaScript web applications in the wild. We describe technical challenges in analyzing them and our solutions to address the challenges via a series of open source analysis frameworks, the scalable analysis framework for ECMAScript (SAFE) family.",1937-4194,,10.1109/MS.2018.110113408,National Research Foundation of Korea; Institute for Information and Communications Technology Promotion; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254305,program analysis;semantics of programming languages;logics and meanings of programs;theory of computat;software;software engineering;software engineering;testing and debugging,Computer bugs;Browsers;Object recognition;Java;Electronic publishing;Computer applications,Internet;Java;program debugging;public domain software,bug finding;JavaScript web applications;technical challenges;open source analysis frameworks;scalable analysis framework;ECMAScript family;SAFE,,,,35.0,,11 Jan 2018,,,IEEE,IEEE Magazines
1655,294,Refactoring Inspection Support for Manual Refactoring Edits,E. L. G. Alves; M. Song; T. Massoni; P. D. L. Machado; M. Kim,"Computer Science Department, Federal University of Campina Grande, Campina Grande, Brazil; Computer Science Department, The University of Nebraska at Omaha, Omaha, NE; Computer Science Department, Universidade Federal de Campina Grande, Campina Grande, PB, Brazil; Systems and Computing Department, Federal University of Campina Grande, Campina Grande, Brazil; Computer Science Department, University of California, Los Angeles, CA",IEEE Transactions on Software Engineering,16 Apr 2018,2018,44,4,365,383,"Refactoring is commonly performed manually, supported by regression testing, which serves as a safety net to provide confidence on the edits performed. However, inadequate test suites may prevent developers from initiating or performing refactorings. We propose RefDistiller, a static analysis approach to support the inspection of manual refactorings. It combines two techniques. First, it applies predefined templates to identify potential missed edits during manual refactoring. Second, it leverages an automated refactoring engine to identify extra edits that might be incorrect. RefDistiller also helps determine the root cause of detected anomalies. In our evaluation, RefDistiller identifies 97 percent of seeded anomalies, of which 24 percent are not detected by generated test suites. Compared to running existing regression test suites, it detects 22 times more anomalies, with 94 percent precision on average. In a study with 15 professional developers, the participants inspected problematic refactorings with RefDistiller versus testing only. With RefDistiller, participants located 90 percent of the seeded anomalies, while they located only 13 percent with testing. The results show RefDistiller can help check the correctness of manual refactorings.",1939-3520,,10.1109/TSE.2017.2679742,National Science Foundation; Google Faculty Award; National Institute of Science and Technology for Software Engineering; CNPq/Brasil; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874212,Refactoring;refactoring anomalies;code inspection,Manuals;Inspection;Testing;Computer bugs;Transforms;Engines;Detectors,program diagnostics;program testing;regression analysis;software maintenance,RefDistiller;seeded anomalies;refactoring inspection support;manual refactoring edits;regression testing;inadequate test suites;potential missed edits;automated refactoring engine;extra edits;generated test suites;running existing regression test suites;problematic refactorings,,3.0,,49.0,,8 Mar 2017,,,IEEE,IEEE Journals
1656,295,Predictive Mutation Testing,J. Zhang; L. Zhang; M. Harman; D. Hao; Y. Jia; L. Zhang,"Institute of Software, EECS, Peking University, Beijing, China; Department of Computer Science, University of Texas at Dallas, Richardson, TX; University College London, London, United Kingdom; Institute of Software, EECS, Peking University, Beijing, China; University College London, London, United Kingdom; Institute of Software, EECS, Peking University, Beijing, China",IEEE Transactions on Software Engineering,17 Sep 2019,2019,45,9,898,918,"Test suites play a key role in ensuring software quality. A good test suite may detect more faults than a poor-quality one. Mutation testing is a powerful methodology for evaluating the fault-detection ability of test suites. In mutation testing, a large number of mutants may be generated and need to be executed against the test suite under evaluation to check how many mutants the test suite is able to detect, as well as the kind of mutants that the current test suite fails to detect. Consequently, although highly effective, mutation testing is widely recognized to be also computationally expensive, inhibiting wider uptake. To alleviate this efficiency concern, we propose Predictive Mutation Testing (PMT): the first approach to predicting mutation testing results without executing mutants. In particular, PMT constructs a classification model, based on a series of features related to mutants and tests, and uses the model to predict whether a mutant would be killed or remain alive without executing it. PMT has been evaluated on 163 real-world projects under two application scenarios (cross-version and cross-project). The experimental results demonstrate that PMT improves the efficiency of mutation testing by up to 151.4X while incurring only a small accuracy loss. It achieves above 0.80 AUC values for the majority of projects, indicating a good tradeoff between the efficiency and effectiveness of predictive mutation testing. Also, PMT is shown to perform well on different tools and tests, be robust in the presence of imbalanced data, and have high predictability (over 60 percent confidence) when predicting the execution results of the majority of mutants.",1939-3520,,10.1109/TSE.2018.2809496,National Basic Research Program of China (973 Program); National Natural Science Foundation of China; NSF; EPSRC grant DAASE Dynamic Adaptive Automated Software Engineering; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304576,PMT;mutation testing;machine learning;binary classification,Predictive models;Pattern classification;Software testing;Sensitivity analysis;Software quality;Machine learning,pattern classification;program testing;sensitivity analysis;software quality,predictive mutation testing;good test suite;PMT;mutation testing results;software quality;fault-detection ability;classification model;AUC values;imbalanced data,,18.0,,105.0,,28 Feb 2018,,,IEEE,IEEE Journals
1657,296,Detecting Overly Strong Preconditions in Refactoring Engines,M. Mongiovi; R. Gheyi; G. Soares; M. Ribeiro; P. Borba; L. Teixeira,"Department of Computing and Systems, Federal University of Campina Grande, Campina Grande, PB, Brazil; Department of Computing and Systems, Federal University of Campina Grande, Campina Grande, PB, Brazil; Department of Computing and Systems, Federal University of Campina Grande, Campina Grande, PB, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Informatics Center, Federal University of Pernambuco, Recife, PE, Brazil; Informatics Center, Federal University of Pernambuco, Recife, PE, Brazil",IEEE Transactions on Software Engineering,14 May 2018,2018,44,5,429,452,"Refactoring engines may have overly strong preconditions preventing developers from applying useful transformations. We find that 32 percent of the Eclipse and JRRT test suites are concerned with detecting overly strong preconditions. In general, developers manually write test cases, which is costly and error prone. Our previous technique detects overly strong preconditions using differential testing. However, it needs at least two refactoring engines. In this work, we propose a technique to detect overly strong preconditions in refactoring engines without needing reference implementations. We automatically generate programs and attempt to refactor them. For each rejected transformation, we attempt to apply it again after disabling the preconditions that lead the refactoring engine to reject the transformation. If it applies a behavior preserving transformation, we consider the disabled preconditions overly strong. We evaluate 10 refactorings of Eclipse and JRRT by generating 154,040 programs. We find 15 overly strong preconditions in Eclipse and 15 in JRRT. Our technique detects 11 bugs that our previous technique cannot detect while missing 5 bugs. We evaluate the technique by replacing the programs generated by JDolly with the input programs of Eclipse and JRRT test suites. Our technique detects 14 overly strong preconditions in Eclipse and 4 in JRRT.",1939-3520,,10.1109/TSE.2017.2693982,National Institute of Science and Technology for Software Engineering (INES); CNPq; CAPES; FACEPE; FAPEAL PPGs; DEVASSES; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898404,Refactoring;overly strong preconditions;automated testing;program generation,Engines;Computer bugs;Databases;Testing;Java;Electronic mail;Usability,automatic programming;C language;Java;object-oriented programming;program debugging;program testing;software maintenance,JRRT test suites;refactoring engine;overly strong preconditions;Eclipse;differential testing;rejected transformation;JDolly,,2.0,,53.0,,12 Apr 2017,,,IEEE,IEEE Journals
1658,297,Creating Rich and Representative Personas by Discovering Affordances,M. Mesgari; C. Okoli; A. O. de Guinea,"Loyola Marymount University, CA, U.S.A; Université Côte d'Azur, Paris, France; Department of Strategy and Information Systems, Universidad de Deusto, Bilbo, Bizkaia, Spain",IEEE Transactions on Software Engineering,16 Oct 2019,2019,45,10,967,983,"During the last decade, information system designers have used the persona technique to put user needs and preferences at the center of all development decisions. Persona development teams draw on qualitative data, quantitative data or a combination of both to develop personas that are representative of the target users. Despite the benefits of both approaches, qualitative methods are limited by the cognitive capabilities of the experts, whereas quantitative methods lack contextual richness. To gain the advantages of both approaches, this article suggests a mixed qualitative-quantitative approach to create user personas based on the patterns of the affordances they actualize rather than merely the actions they take. It enriches personas by referring to the purposes fulfilled through affordance actualizations, and it grounds personas in readily available objective log data. This study illustrates the practical value of the proposed methodology by empirically creating personas based on real user data. Furthermore, it demonstrates its value by having practitioners compare the suggested method to that of qualitative-only and quantitative-only methods.",1939-3520,,10.1109/TSE.2018.2826537,Concordia University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8337801,Personas;affordances;mixed qualitative and quantitative methods;user modeling;interview;card sorting;cluster analysis;systems design and implementation;design and evaluation of IT infrastructure;questionnaire surveys,Software;Maintenance engineering;Task analysis;Aging;Interviews;Human computer interaction,formal specification;human computer interaction;information systems;user centred design,persona development teams;qualitative data;quantitative data;cognitive capabilities;user personas;information system designers;human-computer interaction;user-centered design;software engineering;requirements engineering;persona creation,,,,64.0,,13 Apr 2018,,,IEEE,IEEE Journals
1659,298,Group-Development Psychology Training: The Perceived Effects on Agile Software-Development Teams,L. Gren; A. Goldman; C. Jacobsson,"Software Engineering, Chalmers University of Technology, Gothenburg, Sweden; Computer Science, University of Sao Paulo, Sao Paulo, Brazil; Psychology, University of Gothenburg, Gothenburg, Sweden",IEEE Software,15 Apr 2020,2020,37,3,63,69,"Research has shown that the maturity of small workgroups, from a psychological perspective, is intimately connected to team agility. This study showed a perceived positive effect of training agile teams in group developmental psychology. We therefore see huge potential in training agile teams in this topic since the positive effects might span over the entire software development organization.",1937-4194,,10.1109/MS.2019.2955675,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911247,group development;group dynamics;agile teams;behavioral software engineering;psychology,Psychology;Training;Companies;Teamwork;Agile software development,project management;psychology;software development management;software prototyping;team working,group developmental psychology;training agile teams;software development organization;group-development psychology training;agile software-development teams;psychological perspective;perceived positive effect;team agility,,,,16.0,,25 Nov 2019,,,IEEE,IEEE Magazines
1660,299,Actionable Analytics for Strategic Maintenance of Critical Software: An Industry Experience Report,D. Port; B. Taber,University of Hawaii at Manoa; Jet Propulsion Laboratory,IEEE Software,25 Dec 2017,2018,35,1,58,63,"NASA has been successfully sustaining the continuous operation of its critical navigation software systems for over 12 years. To accomplish this, NASA scientists must continuously monitor their process, report on current system quality, forecast maintenance effort, and sustain required staffing levels. This report presents some examples of the use of a robust software metrics and analytics program that enables actionable strategic maintenance management of a critical system (Monte) in a timely, economical, and risk-controlled fashion. This article is part of a special issue on Actionable Analytics for Software Engineering.",1937-4194,,10.1109/MS.2017.4541055,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239926,software maintenance;critical systems;reliability;software analytics;Monte;navigation systems;NASA;software engineering;software development,Computer bugs;Software maintenance;Biological system modeling;Data models;Analytical models,aerospace computing;software maintenance;software metrics,industry experience report;critical navigation software systems;NASA scientists;maintenance effort;robust software metrics;actionable strategic maintenance management;actionable analytics,,,,2.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1661,300,Using Analytics to Guide Improvement during an Agile–DevOps Transformation,B. Snyder; B. Curtis,Fannie Mae; CAST,IEEE Software,25 Dec 2017,2018,35,1,78,83,"Over the past three years, Fannie Mae IT has transformed from a traditional waterfall organization to a lean culture enabled by agile methods and DevOps. Software analytics were used to guide improvements and evaluate progress. Project-level analytics enabled agile teams to improve structural quality and evaluate their practices as they delivered greater functionality over shrinking delivery intervals. Aggregated enterprise metrics displayed an average 38 percent improvement in structural quality, with some applications achieving 48 percent to 70 percent gains. These quality improvements accompanied a 28 percent increase in productivity. The frequency of releases shrank from cycles of nine to 18 months, down to releases every couple of one- to two-month sprints. The article discusses examples of how analytics were used, along with challenges in selecting measures and implementing analytics in an agile-DevOps transformation. This article is part of a special issue on Actionable Analytics for Software Engineering.",1937-4194,,10.1109/MS.2017.4541032,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239932,software measurement;software quality;software productivity;software analytics;DevOps;agile transformation;agile development;software development;software engineering,Productivity;Software measurement;Monitoring;Portfolios;Software testing,software development management;software metrics;software prototyping;systems analysis,lean culture;agile methods;agile teams;aggregated enterprise metrics;software analytics;actionable analytics;agile-DevOps transformation;project-level analytics;structural quality improvement,,1.0,,9.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1662,301,How Robust Is Your Development Team?,L. Xiao; Z. Yu; B. Chen; X. Wang,Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology,IEEE Software,25 Dec 2017,2018,35,1,64,71,"Given the collaborative nature of software development, a robust team is a necessity for project success in both commercial and open source environments. That is, in the event of developers' absence due to various reasons, how could it potentially disrupt a team's routine operations? This article offers an automatic approach to intuitively visualize development team hierarchy, quantify overall team robustness, and identify the point (developers) of risk for team robustness. An investigation of six Apache open source projects has shown its effectiveness. This article is part of a special issue on Actionable Analytics for Software Engineering.",1937-4194,,10.1109/MS.2017.4541052,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239942,software collaboration;social network;information loss;team robustness;mining software repository;software development;software engineering,Software development;Collaboration;Visualization;Loss measurement;Data mining,public domain software;software development management;team working,software development;project success;commercial source environments;open source environments;development team hierarchy;team robustness;Apache open source projects,,,,10.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1663,302,Contrasting Big Bang With Continuous Integration Through Defect Reports,N. Mellegard; H. Burden; D. Levin; K. Lind; A. Magazinius,"RISE Viktoria, Gothenburg, Sweden; RISE Viktoria, Gothenburg, Sweden; Volvo Car Corporation, Sweden; HiMinds Goteborg AB, Sweden; RISE Viktoria, Gothenburg, Sweden",IEEE Software,15 Apr 2020,2020,37,3,14,20,"Continuous integration promises ea rlier defect detection, quality improvements, and more customer value delivered faster. In this case study, we examined development of software for the advanced safety and driver support component of a Swedish vehicle manufacturer in two consecutive projects.",1937-4194,,10.1109/MS.2018.2880822,Vinnova; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573886,Software Engineering Process;Process measurement;Process metrics,Software development management;Software quality;Companies;Automobiles;Software engineering;Manufacturing processes,automobile industry;customer services;production engineering computing;software development management,driver support component;consecutive projects;Swedish vehicle manufacturer;advanced safety;customer value;quality improvements;defect detection;defect reports;continuous integration;contrasting big bang,,1.0,,12.0,,12 Dec 2018,,,IEEE,IEEE Magazines
1664,303,Digital Transformation,C. Ebert; C. H. C. Duarte,Vector Consulting Services; National Bank of Social and Economic Development,IEEE Software,6 Jul 2018,2018,35,4,16,21,This instalment of the Software Technology department discusses how the digital transformation is affecting software technology and the software industry.,1937-4194,,10.1109/MS.2018.2801537,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405624,digital transformation;systems engineering;disruptive technology;software development;software engineering;Software Technology,Software development;Production planning;Production systems;Productivity;Digital systems;Software engineering,,,,8.0,,9.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1665,304,The Effort Savings from Using NLP to Classify Equivalent Requirements,D. Falessi; G. Cantone,"California Polytechnic State University, San Luis Obispo, California United States; University of Rome Tor Vergata, Italy",IEEE Software,14 Jan 2019,2019,36,1,48,55,"When Considering What and how to reuse, one must understand the differences and similarities of the systems being developed; this activity is part of the domain analysis. Among the several ways to perform domain analysis, identifying equivalent requirements (that is, the common elements in the domain) is scalable and noninvasive, and it supports the consolidation of requirements.",1937-4194,,10.1109/MS.2018.2874620,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491267,Empirical software engineering;Requirements consolidation;NLP technique,Natural language processing;Software reliability;Reliability engineering;Software measurement;Software engineering;Classification,natural language processing;software reusability;software tools,NLP;equivalent requirements;domain analysis;requirements consolidation,,,,13.0,,14 Oct 2018,,,IEEE,IEEE Magazines
1666,305,From Incident to Insight: Incident Responders and Software Innovation,R. Biddle; J. M. Brown; S. Greenspan,"Computer Science, Carleton University; Computer Science, Carleton University; CA Technologies",IEEE Software,14 Jan 2019,2019,36,1,56,62,"Over The Last decade, new software processes have appeared that emphasize collaboration among people involved in creating successful software. For example, agile methods stress collaboration between development teams and business clients, 1 and DevOps emphasizes better collaboration between development teams and deployment teams.",1937-4194,,10.1109/MS.2017.442103917,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186462,Software;software engineering;design;methodologies;computing milieux;Computers and Society;organizational impacts;computer-supported collaborative work,Collaborative work;Software engineering;Software development management;Social implications of technology;Sociotechnical systems;Organizations,software development management;software prototyping,development teams;software processes;agile methods;software innovation;incident responders;business clients;deployment teams,,,,16.0,,11 Dec 2017,,,IEEE,IEEE Magazines
1667,306,On the Definition of Microservice Bad Smells,D. Taibi; V. Lenarduzzi,Tampere University of Technology; Tampere University of Technology,IEEE Software,4 May 2018,2018,35,3,56,62,"Code smells and architectural smells (also called bad smells) are symptoms of poor design that can hinder code understandability and decrease maintainability. Several bad smells have been defined in the literature for both generic architectures and specific architectures. However, cloud-native applications based on microservices can be affected by other types of issues. In order to identify a set of microservice-specific bad smells, researchers collected evidence of bad practices by interviewing 72 developers with experience in developing systems based on microservices. Then, they classified the bad practices into a catalog of 11 microservice-specific bad smells frequently considered harmful by practitioners. The results can be used by practitioners and researchers as a guideline to avoid experiencing the same difficult situations in the systems they develop.",1937-4194,,10.1109/MS.2018.2141031,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354414,microservice;antipattern;anti-pattern;code smell;architectural smell;bad smell;cloud computing;software development;software engineering,Interviews;Logic gates;Service computing;Software engineering;Software architecture;Cloud computing;Software development,cloud computing;public domain software;software architecture;software quality,microservice bad smells;architectural smells;code understandability;generic architectures;specific architectures;cloud-native applications;microservice-specific bad smells,,21.0,,18.0,,4 May 2018,,,IEEE,IEEE Magazines
1668,307,Challenges of Domain-Driven Microservice Design: A Model-Driven Perspective,F. Rademacher; J. Sorgalla; S. Sachweh,Dortmund University of Applied Sciences and Arts; Dortmund University of Applied Sciences and Arts; Dortmund University of Applied Sciences and Arts,IEEE Software,4 May 2018,2018,35,3,36,43,"Domain-driven design (DDD) is a model-driven methodology to capture relevant domain knowledge for software design. It provides the means to isolate domain concepts and identify concept relationships. This makes DDD particularly appropriate for designing microservice architectures, because functional microservices focus on realizing distinct business capabilities. This article explores the challenges of domain-driven microservice design and presents ways to cope with them based on model-driven development.",1937-4194,,10.1109/MS.2018.2141028,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354426,microservices;domain-driven design;DDD;model-driven development;MDD;microservice architecture;service engineering;domain-specific architectures;modeling of computer architecture;software engineering;software development,Unified modeling language;Context modeling;Software engineering;Logic gates;Service computing;Software architecture,formal specification;object-oriented programming;software architecture,domain-driven design;software design;domain concepts;microservice design;domain knowledge;domain-driven microservice design;microservice architecture design;model-driven development;functional microservices;model-driven methodology,,14.0,,7.0,,4 May 2018,,,IEEE,IEEE Magazines
1669,308,"Process Improvement Archaeology: What Led Us Here, and What’s Next?",M. Unterkalmsteiner; T. Gorschek,Blekinge Institute of Technology; Blekinge Institute of Technology,IEEE Software,6 Jul 2018,2018,35,4,53,61,"While in every organization corporate culture and history change over time, intentional efforts to identify performance problems are of particular interest when trying to understand the current state of an organization. The results of past improvement initiatives can shed light on the evolution of an organization and represent, with the advantage of perfect hindsight, a learning opportunity for future process improvements. The opportunity to test this premise occurred in an applied research collaboration with the Swedish Transport Administration, the government agency responsible for the planning, implementation, and maintenance of long-term rail, road, shipping, and aviation infrastructure in Sweden. This article is part of a theme issue on Process Improvement.",1937-4194,,10.1109/MS.2018.227110005,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356179,process implementation and change;requirements engineering;process improvement;Process Improvement Archaeology;Swedish Transport Administration;software development;software engineering,Requirements engineering;Software engineering;Process planning;Systematics;Rail transportation;Software development management;Aerospace engineering,business data processing;formal specification;organisational aspects,learning opportunity;applied research collaboration;Swedish Transport Administration;requirements engineering;government agency;process improvement archaeology;corporate culture,,1.0,,15.0,,8 May 2018,,,IEEE,IEEE Magazines
1670,309,Leveraging Software-Defined Networking for Incident Response in Industrial Control Systems,A. F. Murillo Piedrahita; V. Gaur; J. Giraldo; Á. A. Cárdenas; S. J. Rueda,Universidad de los Andes; University of Texas at Dallas; University of Texas at Dallas; University of Texas at Dallas; Universidad de los Andes,IEEE Software,25 Dec 2017,2018,35,1,44,50,"In the past decade, the security of industrial control systems has emerged as a research priority in order to safeguard our critical infrastructures. A large number of research efforts have focused on intrusion detection in industrial networks; however, few of them discuss what to do after an intrusion has been detected. Because the safety of most of these control systems is time sensitive, we need new research on automatic incident response. This article shows how software-defined networks and network function virtualization can facilitate automatic incident response to a variety of attacks against industrial networks. It also presents a prototype of an incident-response solution that detects and responds automatically to sensor attacks and controller attacks. This work shows the promise that cloud-enabled software-defined networks and virtual infrastructures hold as a way to provide novel defense-in-depth solutions for industrial systems. This article is part of a special issue on Software Safety and Security Risk Mitigation in Cyber-physical Systems.",1937-4194,,10.1109/MS.2017.4541054,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239925,software-defined networking;software-defined networks;network function virtualization;SDN;NFV;industrial control systems;incident response;cyber-physical systems;cybersecurity;software safety;software security;software engineering;software development,Sensors;Integrated circuits;Software defined networking;Software development;Computer security;Software engineering;Cyber-physical systems,cloud computing;computer network security;control engineering computing;industrial control;production engineering computing;software defined networking;virtualisation,incident-response solution;industrial systems;Cyber-physical Systems;industrial control systems;critical infrastructures;intrusion detection;industrial networks;automatic incident response;network function virtualization;software safety;software-defined networking,,10.0,,10.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1671,310,"Migrating Enterprise Legacy Source Code to Microservices: On Multitenancy, Statefulness, and Data Consistency",A. Furda; C. Fidge; O. Zimmermann; W. Kelly; A. Barros,"Queensland University of Technology; Queensland University of Technology; University of Applied Sciences of Eastern Switzerland, Rapperswil; Queensland University of Technology; Queensland University of Technology",IEEE Software,4 May 2018,2018,35,3,63,72,"Microservice migration is a promising technique to incrementally modernize monolithic legacy enterprise applications and enable them to exploit the benefits of cloud-computing environments. This article elaborates on three challenges of microservice migration: multitenancy, statefulness, and data consistency. The authors show how to identify each of these challenges in legacy code and explain refactoring and architectural pattern-based migration techniques relevant to microservice architectures. They explain how multitenancy enables microservices to be utilized by different organizations with distinctive requirements, why statefulness affects both the availability and reliability of a microservice system, and why data consistency challenges are encountered when migrating legacy code that operates on a centralized data repository to microservices operating on decentralized data repositories. They also explain the interdependencies between multitenancy, statefulness, and data consistency.",1937-4194,,10.1109/MS.2017.440134612,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186442,microservices;multitenancy;refactoring;architectural patterns;statefulness;data consistency;software development;software engineering,Databases;User interfaces;Object recognition;Logic gates;Cloud computing;Service computing;Software engineering,business data processing;cloud computing;software architecture;software maintenance,migrating enterprise legacy source code;microservice migration;monolithic legacy enterprise applications;cloud-computing environments;refactoring pattern-based migration techniques;architectural pattern-based migration techniques;microservice architectures;microservice system;data consistency challenges;migrating legacy code;decentralized data repositories,,5.0,,20.0,,11 Dec 2017,,,IEEE,IEEE Magazines
1672,311,Context-aware Personalized Crowdtesting Task Recommendation,J. Wang; Y. Yang; S. Wang; C. Chen; D. Wang; Q. Wang,"Institute of Software, Chinese Academy of Sciences, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, 100190 (e-mail: junjie@iscas.ac.cn); School of Systems and Enterprises, Stevens Institute of Technology, 33694 Hoboken, New Jersey, United States, (e-mail: yyang4@stevens.edu); Department of Electrical Engineering and Computer Science, York University, 7991 Toronto, Ontario, Canada, (e-mail: wangsong@eecs.yorku.ca); Faculty of Information Technology, Monash University, Melbourne, Victoria, Australia, 3800 (e-mail: chunyang.chen@monash.edu); Institute of Software, Chinese Academy of Sciences, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, (e-mail: dandan@iscas.ac.cn); Institute of Software, Chinese Academy of Sciences, Beijing, Beijing, China, 100190 (e-mail: wq@itechs.iscas.ac.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Crowdsourced software testing (short for crowdtesting) is a special type of crowdsourcing. It requires that crowdworkers master appropriate skill-sets and commit significant effort for completing a task. Abundant uncertainty may arise during a crowdtesting process due to imperfect information between the task requester and crowdworkers. For example, a worker frequently chooses tasks in an ad hoc manner in crowdtesting context, and an inappropriate task selection may lead to the worker's failing to detect any bugs, and significant testing effort unpaid and wasted. Recent studies have explored methods for supporting task requesters to make informed decisions on task pricing, worker recommendation, and so on. Unfortunately, very few study offers decision making support from the crowdworkers' perspectives. We motivate this study through a pilot study, revealing the large portion (74\%) of unpaid crowdworkers' effort due to the inappropriate task choice. Drawn from our previous work on context-aware crowdworker recommendations, we advocate a more effective alternative to manual task selection would be to provide contextualized and personalized task recommendation considering the diverse distribution of worker preference and expertise, with objectives to increase their winning chances and to potentially reduce the frequency of unpaid crowd work. This paper proposes a context-aware personalized task recommendation approach PTRec, consisting of a testing context model and a learning-based task recommendation model to aid dynamic worker decision in selecting crowdtesting tasks. The testing context model is constructed in two perspectives, i.e., process context and resource context, to capture the in-process progress-oriented information and crowdworkers' characteristics respectively. Built on top of this context model, the learning-based task recommendation model extracts 60 features automatically, and employs random forest learner to generate dynamic and personalized task recommendation which matches workers' expertise and interest. The evaluation is conducted on 636 crowdtesting tasks involving 2,404 crowdworkers from one of the largest crowdtesting platforms, and results show the potential in recommending proper tasks to workers so as to improve bug detection efficiency and increase their monetary earnings.",1939-3520,,10.1109/TSE.2021.3081171,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9435104,Crowdsourced testing;Task recommendation;Testing context model,Task analysis;Computer bugs;Testing;Context modeling;Feature extraction;Crowdsourcing;Videos,,,,,,,IEEE,18 May 2021,,,IEEE,IEEE Early Access Articles
1673,312,"CBUA: A probabilistic, predictive, and practical approach for evaluating test suite effectiveness",P. Zhang; Y. Li; W. Ma; Y. Yang; L. Chen; H. Lu; Y. Zhou; B. Xu,"State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: DZ1833034@smail.nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: yanhuili@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: wwyma@smail.nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: yangyibiao@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: lchen@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: 32493172@qq.com); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: zhouyuming@nju.edu.cn); bwxu@nju.edu.cn, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: bwxu@nju.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Knowing the effectiveness of a test suite is essential for many activities such as guiding the generation of new test cases and assessing the test adequacy of code. Mutation testing is a commonly used defect injection technique for evaluating the effectiveness of a test suite. However, it is usually computationally expensive, as a large number of mutants (buggy versions) are needed to be generated from a production code under test and executed against the test suite. In order to reduce the expensive testing cost, recent studies proposed to use supervised models to predict the effectiveness of a test suite without executing the test suite against the mutants. Nonetheless, the training of such a supervised model requires labeled data, which still depends on the costly mutant execution. Furthermore, existing models are based on traditional supervised learning techniques, which assumes that the training and testing data come from the same distribution. But, in practice, software systems are subject to considerable concept drifts, i.e. the same distribution assumption usually does not hold. This can lead to inaccurate predictions of a learned supervised model on the target code as time progresses. To tackle these problems, in this paper, we propose a Coverage-Based Unsupervised Approach (CBUA) for evaluating the effectiveness of a test suite. The whole process only requires a one-time execution of the test suite against the target production code, without involving any mutant execution and any training data. CBUA can ensure the score monotonicity property (i.e. adding test cases to a test suite does not decrease its mutation score), which may be violated by a supervised approach. The experimental results show that CBUA is very competitive to the state-of-the-art supervised approaches in terms of the prediction accuracy. Since CBUA is an easy-to-implement model with a low cost, we suggest that it should be used as a baseline approach for comparison when any novel prediction approach is proposed in future studies.",1939-3520,,10.1109/TSE.2020.3010361,the National Key R and D Program of China; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144443,Effectiveness;test suites;coverage;unsupervised model;mutation testing,Testing;Predictive models;Production;Data models;Computational modeling;Training;Training data,,,,,,,,20 Jul 2020,,,IEEE,IEEE Early Access Articles
1674,313,Sequential Model Optimization for Software Effort Estimation,T. Xia; R. Shu; X. Shen; T. Menzies,"computer science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: txia4@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, 27695 (e-mail: rshu@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: xshen5@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Many methods have been proposed to estimate how much effort is required to build and maintain software. Much of that research tries to recommend a single method - an approach that makes the dubious assumption that one method can handle the diversity of software project data. To address that drawback, we apply a configuration technique called “ROME” (Rapid Optimizing Methods for Estimation), which uses sequential model-based optimization (SMO) to find what configuration settings of effort estimation techniques work best for a particular data set. We test this method using data from 1161 classic waterfall projects and 120 contemporary projects (from GitHub). In terms of magnitude of relative error and standardized accuracy, we find that ROME achieves better performance than the state-of-the-art methods for both classic and contemporary projects. In addition, we conclude that we should not recommend one method for estimation. Rather, it is better to search through a wide range of different methods to find what works best for the local data. To the best of our knowledge, this is the largest effort estimation experiment yet attempted and the only one to test its methods on classic and contemporary projects.",1939-3520,,10.1109/TSE.2020.3047072,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307246,Effort Estimation;COCOMO;Hyperparameter Tuning;Regression Trees;Sequential Model Optimization,Estimation;Software;Tools;Optimization;Data models;Task analysis;Mathematical model,,,,,,,IEEE,24 Dec 2020,,,IEEE,IEEE Early Access Articles
1675,314,Active Learning of Discriminative Subgraph Patterns for API Misuse Detection,H. J. Kang; D. Lo,"School of Information Systems, Singapore Management University, 54756 Singapore, Singapore, Singapore, (e-mail: hjkang.2018@phdcs.smu.edu.sg); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"A common cause of bugs and vulnerabilities are the violations of usage constraints associated with Application Programming Interfaces (APIs). API misuses are common in software projects, and while there have been techniques proposed to detect such misuses, studies have shown that they fail to reliably detect misuses while reporting many false positives. One limitation of prior work is the inability to reliably identify correct patterns of usage. Many approaches confuse a usage pattern's frequency for correctness. Due to the variety of alternative usage patterns that may be uncommon but correct, anomaly detection-based techniques have limited success in identifying misuses. We address these challenges and propose ALP (Actively Learned Patterns), reformulating API misuse detection as a classication problem. After representing programs as graphs, ALP mines discriminative subgraphs. While still incorporating frequency information, through limited human supervision, we reduce the reliance on the assumption relating frequency and correctness. The principles of active learning are incorporated to shift human attention away from the most frequent patterns. Instead, ALP samples informative and representative examples while minimizing labeling effort. In our empirical evaluation, ALP substantially outperforms prior approaches on both MUBench, an API Misuse benchmark, and a new dataset that we constructed from real-world software projects.",1939-3520,,10.1109/TSE.2021.3069978,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392340,API-Misuse Detection;Discriminative Subgraph Mining;Graph Classification;Active Learning,Detectors;Software development management;Java;Tools;Software;Computer bugs;Ciphers,,,,,,,IEEE,31 Mar 2021,,,IEEE,IEEE Early Access Articles
1676,315,Dominoes: An Interactive Exploratory Data Analysis tool for Software Relationships,J. R. da Silva Junior; D. P. Campagna; E. Clua; A. Sarma; L. G. P. Murta,"Computing, Instituto Federal do Rio de Janeiro, Rio de Janeiro, Rio de Janeiro Brazil (e-mail: jose.junior@ifrj.edu.br); Computing Institute, Universidade Federal Fluminense, Niteri, Rio de Janeiro Brazil (e-mail: dprett@ic.uff.br); Computing Institute, Universidade Federal Fluminense, 28110 Niteroi, Rio de Janeiro Brazil (e-mail: esteban@ic.uff.br); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States 97331 (e-mail: anita.sarma@oregonstate.edu); Computer Science, Universidade Federal Fluminense, Niteri, RJ Brazil 24210-240 (e-mail: leomurta@ic.uff.br)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Project comprehension questions, such as “which modified artifacts can affect my work” and “how can I identify the developers who should be assigned to a given task” are difficult to answer, require an analysis of the project and its data, are context specific, and cannot always be pre-defined. Current research approaches are restricted to post hoc analyses over software repositories. Very few interactive exploratory tools exist because the large amount of data that need to be analyzed prohibits its exploration at interactive rates. Moreover, such analyses typically require the user to create complex scripts or queries to extract the desired information from data. Here we present Dominoes, a tool for interactive data exploration aimed at end users (i.e., project managers or developers). Dominoes allows users to interact with different types and units of data to investigate project relationships and view intermediate results as charts, tables, and graphs. Additionally, it allows users to save the derived data as well as their exploration paths for later use. In a scenario-based evaluation study, participants achieved a success rate of 86% in their explorations, with a mean time of 7.25 minutes for answering a set of (project) exploration questions.",1939-3520,,10.1109/TSE.2020.2988241,Fundao Carlos Chagas Filho de Amparo Pesquisa do Estado do Rio de Janeiro; National Science Foundation; Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico; Coordenao de Aperfeioamento de Pessoal de Nvel Superior; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072287,Design Tools and Techniques;Interactive data exploration and discovery;Evaluation/methodology,Tiles;Data mining;Graphics processing units;Tools;Feature extraction,,,,,,,,20 Apr 2020,,,IEEE,IEEE Early Access Articles
1677,316,A fast clustering algorithm for modularization of large-scale software systems,N. Teymourian; H. Izadkhah; A. Isazadeh,"Department of Computer Science, University of Tabriz, 56947 Tabriz, East Azerbaijan, Iran (the Islamic Republic of), (e-mail: nvd.teymourian@gmail.com); Department of Computer Science, University of Tabriz, Tabriz, Esat Azarbijan, Iran (the Islamic Republic of), (e-mail: habib_eizadkhah@yahoo.com); Department of Computer Science, University of Tabriz, Tabriz, East Azerbaijan, Iran (the Islamic Republic of), (e-mail: isazadeh@tabrizu.ac.ir)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"A software system evolves overtime to meet the needs of users. Understanding a program is the most important step to apply new requirements. Clustering techniques by dividing a program into small and meaningful parts make it possible to understand the program. In general, clustering algorithms are classified into two categories: hierarchical and non-hierarchical algorithms (such as search-based approaches). While clustering problems generally tend to be NP-hard, search-based algorithms produce acceptable clustering, but have time and space constraints and hence they are inefficient in large-scale software systems. Most algorithms currently used in software clustering fields do not scale well when applied to large and very large applications. In this paper, we present a new and fast clustering algorithm, named FCA, that can overcome space and time constraints of existing algorithms by performing operations on the dependency matrix and extracting other matrices based on a set of features. The experimental results on ten small-sized applications, ten folders with different functionalities from Mozilla Firefox, a large-sized application (namely ITK), and a very large-sized application (namely Chromium) demonstrate that the proposed algorithm achieves higher quality modularization compared with hierarchical algorithms. It can also compete with search-based algorithms and a clustering algorithm based on subsystem patterns. But the running time of the proposed algorithm is much shorter than that of the hierarchical and non-hierarchical algorithms. The source code of the proposed algorithm can be accessed at https://github.com/SoftwareMaintenanceLab.",1939-3520,,10.1109/TSE.2020.3022212,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187267,Software clustering;Software modularization;Software maintenance;Software comprehension;Architecture recovery,Clustering algorithms;Software algorithms;Search problems;Software systems;Semantics;Software architecture,,,,,,,,7 Sep 2020,,,IEEE,IEEE Early Access Articles
1678,317,Comparing Block-based Programming Models for Two-armed Robots,N. Ritschel; V. Kovalenko; R. Holmes; R. Garcia; D. C. Shepherd,"Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: ritschel@cs.ubc.ca); Computer Science, Delft University of Technology, 2860 Delft, Zuid-Holland Netherlands (e-mail: v.v.kovalenko@tudelft.nl); Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: rtholmes@cs.ubc.ca); Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: rxg@cs.ubc.ca); Department of Computer Science, Virginia Commonwealth University, 6889 Richmond, Virginia United States (e-mail: shepherdd@vcu.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Modern industrial robots can work alongside human workers and coordinate with other robots. This means they can perform complex tasks, but doing so requires complex programming. Therefore, robots are typically programmed by experts, but there are not enough to meet the growing demand for robots. To reduce the need for experts, researchers have tried to make robot programming accessible to factory workers without programming experience. However, none of that previous work supports coordinating multiple robot arms that work on the same task. In this paper we present four block-based programming language designs that enable end-users to program two-armed robots. We analyze the benefits and trade-offs of each design on expressiveness and user cognition, and evaluate the designs based on a survey of 273 professional participants of whom 110 had no previous programming experience. We further present an interactive experiment based on a prototype implementation of the design we deem best. This experiment confirmed that novices can successfully use our prototype to complete realistic robotics tasks. This work contributes to making coordinated programming of robots accessible to end-users. It further explores how visual programming elements can make traditionally challenging programming tasks more beginner-friendly.",1939-3520,,10.1109/TSE.2020.3027255,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207834,Programming environments;User interfaces;Robot programming;Parallel programming,Robot kinematics;Programming profession;Visualization;Task analysis;Manipulators,,,,,,,,28 Sep 2020,,,IEEE,IEEE Early Access Articles
1679,318,PackerGrind: An Adaptive Unpacking System for Android Apps,L. Xue; H. Zhou; X. Luo; L. Yu; D. Wu; Y. Zhou; X. Ma,"Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong China (e-mail: cslxue@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: sunmoonsky0001@gmail.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxluo@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: yulele08@gmail.com); College of Information Sciences and Technology, Penn State University, University Park, Pennsylvania United States 16802 (e-mail: dwu@ist.psu.edu); Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: yajin_zhou@zju.edu.cn); School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi China (e-mail: ma.xjtu@qq.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"App developers are increasingly using packing services (or packers) to protect their code against being reverse engineered or modified. However, such packing techniques are also leveraged by the malicious developers to prevent the malware from being analyzed and detected by the static malware analysis and detection systems. Though there are already studies on unpacking packed Android apps, they usually leverage the manual reverse engineered packing behaviors to unpack apps packed by the specific packers and cannot be applied to the evolving and new packers. In this paper, we propose a novel unpacking approach with the capacity of adaptively unpacking the evolving and newly encountered packers. Also, we develop a new system, named PackerGrind, based on this adaptive approach for unpacking Android packers. The evaluation with real packed apps demonstrates that PackerGrind can successfully reveal packers? protection mechanisms, effectively handle their evolution and recover Dex files with low overhead.",1939-3520,,10.1109/TSE.2020.2996433,Zhejiang Key RD; Leading Innovative and Entrepreneur Team Introduction Program of Zhejiang; Office of Naval Research; Hong Kong RGC Project; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098088,,Androids;Humanoid robots;Runtime;Subspace constraints;Open area test sites;Tools;Monitoring,,,,1.0,,,,21 May 2020,,,IEEE,IEEE Early Access Articles
1680,319,DEFECTCHECKER: Automated Smart Contract Defect Detection by Analyzing EVM Bytecode,J. Chen; X. Xia; D. Lo; J. Grundy; X. Luo; T. Chen,"Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3168 (e-mail: Jiachi.Chen@monash.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: brokendragon@uestc.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Smart contracts are Turing-complete programs running on the blockchain. They are immutable and cannot be modified, even when bugs are detected. Therefore, ensuring smart contracts are bug-free and well-designed before deploying them to the blockchain is extremely important. A contract defect is an error, flaw or fault in a smart contract that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. Detecting and removing contract defects can avoid potential bugs and make programs more robust. Our previous work defined 20 contract defects for smart contracts and divided them into five impact levels. According to our classification, contract defects with seriousness level between 1-3 can lead to unwanted behaviors, e.g., a contract being controlled by attackers. In this paper, we propose DefectChecker, a symbolic execution-based approach and tool to detect eight contract defects that can cause unwanted behaviors of smart contracts on the Ethereum blockchain platform. DefectChecker can detect contract defects from smart contracts' bytecode. We compare DefectChecker with key previous works, including Oyente, Mythril and Securify by using an open-source dataset. Our experimental results show that DefectChecker performs much better than these tools in terms of both speed and accuracy. We also applied DefectChecker to 165,621 distinct smart contracts on the Ethereum platform. We found that 25,815 of these smart contracts contain at least one of the contract defects that belongs to impact level 1-3, including some real-world attacks.",1939-3520,,10.1109/TSE.2021.3054928,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9337195,Smart Contracts;Ethereum;Contract Defects Detection;Bytecode Analyze;Symbolic Execution,Smart contracts;Blockchain;Tools;Computer bugs;Computer hacking;Virtual machining;Organizations,,,,,,,IEEE,27 Jan 2021,,,IEEE,IEEE Early Access Articles
1681,320,Scrutinizing Implementations of Smart Home Integrations,K. Mahadewa; K. Wang; G. Bai; L. Shi; Y. Liu; J. S. Dong; Z. Liang,"Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: kulani41@comp.nus.edu.sg); Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: dcswaka@nus.edu.sg); School of Information Technology and Electrical Engineering, University of Queensland, 1974 Brisbane, Queensland Australia (e-mail: baiguangdong@gmail.com); Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: shiling@comp.nus.edu.sg); Blockchain Platform, Ant Financial, Hanzhou, Zhejiang China (e-mail: yan.emma.liu@gmail.com); Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: dcsdjs@nus.edu.sg); Computer Science, National University of Singapore, Singapore, Singapore Singapore 117417 (e-mail: liangzk@comp.nus.edu.sg)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"A key feature of the booming smart home is the integration of a wide assortment of technologies, including various standards, proprietary communication protocols and heterogeneous platforms. Due to customization, unsatisfied assumptions and incompatibility in the integration, critical security vulnerabilities are likely to be introduced by the integration. Hence, this work addresses the security problems in smart home systems from an integration perspective, as a complement to numerous studies that focus on the analysis of individual technologies. We propose HOMESCAN, an approach that examines the security of the implementations of smart home systems. It extracts the abstract specification of application-layer protocols and internal behaviors of entities, so that it is able to conduct an end-to-end security analysis against various attack models. Applying HOMESCAN on three extensively-used smart home systems, we have found twelve non-trivial security vulnerabilities, which may lead to unauthorized remote control and credential leakage.",1939-3520,,10.1109/TSE.2019.2960690,National Research Foundation Singapore; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936860,,Security;Smart homes;Zigbee;Protocols;Authentication;Java;Wireless fidelity,,,,,,,,19 Dec 2019,,,IEEE,IEEE Early Access Articles
1682,321,Automatic Generation of Acceptance Test Cases from Use Case Specifications: an NLP-based Approach,C. Wang; F. Pastore; A. Goknil; L. Briand,"SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: wangchunhui@me.com); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: fabrizio.pastore@uni.lu); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: ardagoknil@gmail.com); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg 2721 (e-mail: lionel.briand@uni.lu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Acceptance testing is a validation activity performed to ensure the conformance of software systems with respect to their functional requirements. In safety critical systems, it plays a crucial role since it is enforced by software standards, which mandate that each requirement be validated by such testing in a clearly traceable manner. Test engineers need to identify all the representative test execution scenarios from requirements, determine the runtime conditions that trigger these scenarios, and finally provide the input data that satisfy these conditions. Given that requirements specifications are typically large and often provided in natural language (e.g., use case specifications), the generation of acceptance test cases tends to be expensive and error-prone. In this paper, we present Use Case Modeling for System-level, Acceptance Tests Generation (UMTG), an approach that supports the generation of executable, system-level, acceptance test cases from requirements specifications in natural language, with the goal of reducing the manual effort required to generate test cases and ensuring requirements coverage. More specifically, UMTG automates the generation of acceptance test cases based on use case specifications and a domain model for the system under test, which are commonly produced in many development environments. Unlike existing approaches, it does not impose strong restrictions on the expressiveness of use case specifications. We rely on recent advances in natural language processing to automatically identify test scenarios and to generate formal constraints that capture conditions triggering the execution of the scenarios, thus enabling the generation of test data. In two industrial case studies, UMTG automatically and correctly translated 95% of the use case specification steps into formal constraints required for test data generation; furthermore, it generated test cases that exercise not only all the test scenarios manually implemented by experts, but also some critical scenarios not previously considered.",1939-3520,,10.1109/TSE.2020.2998503,H2020 European Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103626,System Test Case Generation;Use Case Specifications;Natural Language Processing;Semantic Role Labeling,Unified modeling language;Natural language processing;Embedded systems;Test pattern generators;Semantics,,,,,,,,29 May 2020,,,IEEE,IEEE Early Access Articles
1683,322,TkT: Automatic Inference of Timed and Extended Pushdown Automata,F. Pastore; D. Micucci; M. Guzman; L. Mariani,"SnT, University of Luxembourg, Luxembourg, LU Luxembourg (e-mail: fabrizio.pastore@uni.lu); Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Milano Italy 20126 (e-mail: daniela.micucci@unimib.it); Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Milano Italy (e-mail: michell.guzman@unimib.it); Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Milano Italy 20126 (e-mail: mariani@disco.unimib.it)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"To mitigate the cost of manually producing and maintaining models capturing software specifications, specification mining techniques can be exploited to automatically derive up-to-date models that faithfully represent the behavior of software systems. So far, specification mining solutions focused on extracting information about the functional behavior of the system, especially in the form of models that represent the ordering of the operations. Well-known examples are finite state models capturing the usage protocol of software interfaces and temporal rules specifying relations among system events. Although the functional behavior of a software system is a primary aspect of concern, there are several other non-functional characteristics that must be typically addressed jointly with the functional behavior of a software system. Efficiency is one of the most relevant characteristics. In fact, an application delivering the right functionalities inefficiently has a big chance to not satisfy the expectation of its users. Interestingly, the timing behavior is strongly dependent on the functional behavior of a software system. For instance, the timing of an operation depends on the functional complexity and size of the computation that is performed. Consequently, models that combine the functional and timing behaviors, as well as their dependencies, are extremely important to precisely reason on the behavior of software systems. In this paper, we address the challenge of generating models that capture both the functional and timing behavior of a software system from execution traces. The result is the Timed k-Tail (TkT) specification mining technique, which can mine finite state models that capture such an interplay: the functional behavior is represented by the possible order of the events accepted by the transitions, while the timing behavior is represented through clocks and clock constraints of different nature associated with transitions. Our empirical evaluation with several libraries and applications show that TkT can generate accurate models, capable of supporting the identification of timing anomalies due to overloaded environment and performance faults. Furthermore, our study shows that TkT outperforms state-of-the-art techniques in terms of scalability and accuracy of the mined models.",1939-3520,,10.1109/TSE.2020.2998527,H2020 European Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103630,Specification mining;dynamic analysis;trace analysis;model inference;timed automata;performance analysis,Automata;Clocks;Software systems;Timing;Data mining;Computational modeling,,,,,,,,29 May 2020,,,IEEE,IEEE Early Access Articles
1684,323,An Empirical Study of Release Note Production and Usage in Practice,T. Bi; X. Xia; D. Lo; J. Grundy; T. Zimmermann,"Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, (e-mail: tingting.bi@monash.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); Research, Microsoft Corporation, Redmond, Washington, United States, 98052 (e-mail: tzimmer@microsoft.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The release note is one of the most important software artifacts that serves as a bridge for communication among stakeholders. Release notes contain a set of crucial information, such as descriptions of enhancements, improvements, potential issues, development, evolution, testing, and maintenance of projects throughout the whole development lifestyle. A comprehensive understanding of what makes a good release note and how to write one for different stakeholders would be highly beneficial. However, in practice, the release note is often neglected by stakeholders and has not to date been systematically investigated by researchers. In this paper, we conduct a mixed methods study to investigate the use of release notes in practice. We first conducted a large-scale empirical study of 32,425 release notes from 1,000 GitHub projects to understand current contents and information found in real-world release notes. We then performed interviews with 15 practitioners and an online survey with 314 respondents to investigate how key stakeholders perceive release notes. From the analysis of these data, we summarized eight categories of information that are normally documented in release notes in GitHub projects. We found that stakeholders consider that well-formed release notes have a positive impact on software development, such as software evolution. We concluded 28 statements grouped into eight topics based on stakeholders' opinions. There exist significant discrepancies between different stakeholders on how release notes should be written and used. Our study provides new insights on release notes and facilitates stakeholders to better take advantage of them during software development.",1939-3520,,10.1109/TSE.2020.3038881,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9263357,Release Note;Software Documentation;Empirical Study,Software;Production;Software development management;Stakeholders;Feature extraction;Testing;Task analysis,,,,,,,,18 Nov 2020,,,IEEE,IEEE Early Access Articles
1685,324,Revisiting Supervised and Unsupervised Methods for Effort-Aware Cross-Project Defect Prediction,C. Ni; X. Xia; D. Lo; X. Chen; Q. Gu,"School of Software Technology, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: jacknichao920209@gmail.com); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Information Science and Technology, Nantong University, 66479 Nantong, jiangsu China 226019 (e-mail: xchencs@ntu.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: quq@nju.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Cross-project defect prediction (CPDP), aiming to apply defect prediction models built on source projects to a target project, has been an active research topic. A variety of supervised CPDP methods and some simple unsupervised CPDP methods have been proposed. In a recent study, Zhou et al. found that simple unsupervised CPDP methods (i.e., ManualDown and ManualUp) have a prediction performance comparable or even superior to complex supervised CPDP methods. Therefore, they suggested that the ManualDown should be treated as the baseline when considering non-effort-aware performance measures (NPMs) and the ManualUp should be treated as the baseline when considering effort-aware performance measures (EPMs) in future CPDP studies. However, in that work, these unsupervised methods are only compared with existing supervised CPDP methods in terms of one or two NPMs and the prediction results of baselines are directly collected from the primary literature. Besides, the comparison has not considered other recently proposed EPMs, which consider context switches and developer fatigue due to initial false alarms. These limitations may not give a holistic comparison between the supervised methods and unsupervised methods. In this paper, we aim to revisit Zhou et al.'s study. To the best of our knowledge, we are the first to make a comparison between the existing supervised CPDP methods and the unsupervised methods proposed by Zhou et al. in the same experimental setting, considering both NPMs and EPMs. We also propose an improved supervised CPDP method EASC and make a further comparison between this method and the unsupervised methods. According to the results on 82 projects in terms of 12 performance measures, we find that when considering NPMs, EASC can achieve similar results with the unsupervised method ManualDown without statistically significant difference in most cases. However, when considering EPMs, our proposed supervised method EASC can statistically significantly outperform the unsupervised method ManualUp with a large improvement in terms of Cliff's delta in most cases. Therefore, the supervised CPDP methods are more promising than the unsupervised method in practical application scenarios, since the limitation of testing resource and the impact on developers cannot be ignored in these scenarios.",1939-3520,,10.1109/TSE.2020.3001739,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115238,Defect prediction;cross-project;supervised model;unsupervised model,Manuals;Predictive models;Atmospheric measurements;Particle measurements;Data models;Software;Testing,,,,1.0,,,,11 Jun 2020,,,IEEE,IEEE Early Access Articles
1686,325,Data Quality Matters: A Case Study on Data Label Correctness for Security Bug Report Prediction,X. Wu; W. Zheng; X. Xia; D. Lo,"School of Cyberspace Security, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi, China, (e-mail: wuxiaoxue00@gmail.com); School of Software, Northwestern Polytechnical University, 26487 Xi'an, Shannxi, China, (e-mail: wzheng@nwpu.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"In the research of mining software repositories, we need to label a large amount of data to construct a predictive model. The correctness of the labels will affect the performance of a model substantially. However, limited studies have been performed to investigate the impact of mislabeled instances on a predictive model. To bridge the gap, in this work, we perform a case study on the security bug report (SBR) prediction. We found five publicly available datasets for SBR prediction contains many mislabeled instances, which lead to the poor performance of SBR prediction models of recent studies (e.g., the work of Peters et al. and Shu et al.). Furthermore, it might mislead the research direction of SBR prediction. In this paper, we first improve the label correctness of these five datasets by manually analyzing each bug report, and we find 749 SBRs, which are originally mislabeled as Non-SBRs (NSBRs). We then evaluate the impacts of datasets label correctness by comparing the performance of the classification models on both the noisy (i.e., before our correction) and the clean (i.e., after our correction) datasets. The results show that the cleaned datasets result in improvement in the performance of classification models. The performance of the approaches proposed by Peters et al. and Shu et al. on the clean datasets is much better than on the noisy datasets. Furthermore, with the clean datasets, the simple text classification models could significantly outperform the security keywords-matrix-based approaches applied by Peters et al. and Shu et al.",1939-3520,,10.1109/TSE.2021.3063727,Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University; Key Laboratory of Advanced Perception and Intelligent Control of High-end Equipment Ministry of Education; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371393,Security bug report prediction;data quality;label correctness,Computer bugs;Noise measurement;Predictive models;Security;Chromium;Tuning;Data models,,,,,,,IEEE,5 Mar 2021,,,IEEE,IEEE Early Access Articles
1687,326,The Impact of Data Merging on the Interpretation of Cross-Project Just-In-Time Defect Models,D. Lin; C. Tantithamthavorn; A. E. Hassan,"Centre for Software Excellence, Huawei Technologies Co Ltd Canada, 538302 Kingston, Ontario, Canada, (e-mail: dayi.lin@huawei.com); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: chakkrit@monash.edu); School of Computing, Queen's University, Kingston, Ontario, Canada, (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Just-In-Time (JIT) defect models are classification models that identify the code commits that are likely to introduce defects. Cross-project JIT models have been introduced to address the suboptimal performance of JIT models when historical data is limited. However, many studies built cross-project JIT models using a pool of mixed data from multiple projects (i.e., data merging)---assuming that the properties of defect-introducing commits of a project are similar to that of the other projects, which is likely not true. In this paper, we set out to investigate the interpretation of JIT defect models that are built from individual project data and a pool of mixed project data with and without consideration of project-level variances. Through a case study of 20 datasets of open source projects, we found that (1) the interpretation of JIT models that are built from individual projects varies among projects; and (2) the project-level variances cannot be captured by a JIT model that is trained from a pool of mixed data from multiple projects without considering project-level variances (i.e., a global JIT model). On the other hand, a mixed-effect JIT model that considers project-level variances represents the different interpretations better, without sacrificing performance, especially when the contexts of projects are considered. The results hold for different mixed-effect learning algorithms. When the goal is to derive sound interpretation of cross-project JIT models, we suggest that practitioners and researchers should opt to use a mixed-effect modelling approach that considers individual projects and contexts.",1939-3520,,10.1109/TSE.2021.3073920,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408228,Just-In-Time Defect Prediction;Data Merging;Mixed-Effect Model;Cross-Project Defect Prediction,Context modeling;Data models;Predictive models;Measurement;Training;Merging;Planning,,,,,,,IEEE,19 Apr 2021,,,IEEE,IEEE Early Access Articles
1688,327,Erratum to “Accurate and Scalable Cross-Architecture Cross-OS Binary Code Search With Emulation”,Y. Xue; Z. Xu; M. Chandramohan; Y. Liu,"University of Science of Technology of China, Hefei, Anhui, China; Nanyang Technological University, Singapore, Singapore; Nanyang Technological University, Singapore, Singapore; Nanyang Technological University, Singapore, Singapore",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,1088,1088,Presents corrections to author information for the above named paper.,1939-3520,,10.1109/TSE.2021.3069529,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430780,,Emulation;Binary codes,,,,,,1.0,IEEE,13 May 2021,,,IEEE,IEEE Journals
1689,328,Execution of Partial State Machine Models,M. Bagherzadeh; N. Kahani; K. Jahed; J. Dingel,"School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: mojtaba@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario Canada (e-mail: kahani@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario Canada (e-mail: jahed@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario Canada (e-mail: dingel@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The iterative and incremental nature of software development using models typically makes a model of a system incomplete (i.e., partial) until a more advanced and complete stage of development is reached. Existing model execution approaches (interpretation of models or code generation) do not support the execution of partial models. Supporting the execution of partial models at the early stages of software development allows early detection of defects, which can be fixed more easily and at a lower cost. This paper proposes a conceptual framework for the execution of partial models, which consists of three steps: static analysis, automatic refinement, and input-driven execution. First, a static analysis that respects the execution semantics of models is applied to detect problematic elements of models that cause problems for the execution. Second, using model transformation techniques, the models are refined automatically, mainly by adding decision points where missing information can be supplied. Third, refined models are executed, and when the execution reaches the decision points, it uses inputs obtained either interactively or by a script that captures how to deal with partial elements. We created an execution engine called PMExec for the execution of partial models of UML-RT (i.e., a modeling language for the development of soft real-time systems) that embodies our proposed framework. We evaluated PMExec based on several use-cases that show that the static analysis, refinement, and application of user input can be carried out with reasonable performance and that the overhead of approach, which is mostly due to the refinement and the increase in model complexity it causes, is manageable. We also discuss the properties of the refinement formally and show how the refinement preserves the original behaviors of the model.",1939-3520,,10.1109/TSE.2020.3008850,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139402,MDD;Model-level Debugging;Partial Models;Incomplete Models;Model Execution,Tools;Analytical models;Unified modeling language;Context modeling;Static analysis;Real-time systems;Debugging,,,,,,,,13 Jul 2020,,,IEEE,IEEE Early Access Articles
1690,329,Boosting API Recommendation with Implicit Feedback,Y. Zhou; X. Yang; T. Chen; Z. Huang; X. Ma; H. C. Gall,"Dept. of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu, China, 211106 (e-mail: zhouyu@nuaa.edu.cn); College of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu, China, (e-mail: xy_yang@nuaa.edu.cn); Department of Computer Science and Information Systems, Birkbeck University of London, 4894 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: taolue.chen@surrey.ac.uk); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China, (e-mail: zqhuang@nuaa.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China, (e-mail: xxm@nju.edu.cn); Department of Informatics, University of Zurich, Zurich, Zurich, Switzerland, 8050 (e-mail: gall@ifi.uzh.ch)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Developers often need to use appropriate APIs to program efciently, but it is usually a difcult task to identify the exact one they need from a vast list of candidates. To ease the burden, a multitude of API recommendation approaches have been proposed. However, most of the currently available API recommenders do not support the effective integration of user feedback into the recommendation loop. In this paper, we propose a framework, BRAID (Boosting RecommendAtion with Implicit FeeDback), which leverages learning-to-rank and active learning techniques to boost recommendation performance. By exploiting user feedback information, we train a learning-to-rank model to re-rank the recommendation results. In addition, we speed up the feedback learning process with active learning. Existing query-based API recommendation approaches can be plugged into BRAID. We select three state-of-the-art API recommendation approaches as baselines to demonstrate the performance enhancement of BRAID measured by Hit@k (Top-k), MAP, and MRR. Empirical experiments show that, with acceptable overheads, the recommendation performance improves steadily and substantially with the increasing percentage of feedback data, comparing with the baselines.",1939-3520,,10.1109/TSE.2021.3053111,the Natural Science Foundation of Jiangsu Province; Birkbeck BEI School Project; National Key Research and Development Program of China; National Natural Science Foundation of China; Guangdong Science and Technology Department grant; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9329198,API recommendation;learning to rank;active learning;natural language processing,Task analysis;Software;Feature extraction;Training;Programming;History;Engines,,,,,,,IEEE,20 Jan 2021,,,IEEE,IEEE Early Access Articles
1691,330,Flexible Combinatorial Interaction Testing,H. Mercan; A. Javeed; C. Yilmaz,"Computer sciences and engineering, Sabanci Universitesi, 52991 Istanbul, Istanbul Turkey 34956 (e-mail: hanefimercan@sabanciuniv.edu); Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Istanbul Turkey 34956 (e-mail: ajaveed@sabanciuniv.edu); Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Tuzla Turkey 34956 (e-mail: cyilmaz@sabanciuniv.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"We present Flexible Combinatorial Interaction Testing (F-CIT), which aims to improve the flexibility of combinatorial interaction testing (CIT) by eliminating the necessity of developing specialized constructors for CIT problems that cannot be efficiently and effectively addressed by the existing CIT constructors. F-CIT expresses the entities to be covered and the space of valid test cases, from which the samples are drawn to obtain full coverage, as constraints. Computing an F-CIT object (i.e., a set of test cases obtaining full coverage under a given coverage criterion) then turns into an interesting constraint solving problem, which we call cov-CSP. cov-CSP aims to divide the constraints, each representing an entity to be covered, into a minimum number of satisfiable clusters, such that a solution for a cluster represents a test case and the collection of all the test cases generated (one per cluster) constitutes an F-CIT object, covering each required entity at least once. To solve the cov-CSP problem, thus to compute F-CIT objects, we first present two constructors. One of these constructors attempts to cover as many entities as possible in a cluster before generating a test case, whereas the other constructor generates a test case first and then marks all the entities accommodated by this test case as covered. We then use these constructors to evaluate F-CIT in three studies, each of which addresses a different CIT problem. In the first study, we develop structure-based F-CIT objects to obtain decision coverage-adequate test suites. In the second study, we develop order-based F-CIT objects, which enhance a number of existing order-based coverage criteria by taking the reachability constraints imposed by graph-based models directly into account when computing interaction test suites. In the third study, we develop usage-based F-CIT objects to address the scenarios, in which standard covering arrays are not desirable due to their sizes, by choosing the entities to be covered based on their usage statistics collected from the field. We also carry out user studies to further evaluate F-CIT. The results of these studies suggest that F-CIT is more flexible than the existing CIT approaches.",1939-3520,,10.1109/TSE.2020.3010317,Türkiye Bilimsel ve Teknolojik Araştirma Kurumu; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144457,Combinatorial interaction testing;covering arrays;sequence covering arrays;constraint solving;structural coverage;coverage criteria,Testing;Standards;Software;Computational modeling;Computers;Electronic mail;Tools,,,,1.0,,,,20 Jul 2020,,,IEEE,IEEE Early Access Articles
1692,331,A Compositional Approach for Complex Event Pattern Modeling and Transformation to Colored Petri Nets with Black Sequencing Transitions,V. V. Valero; G. Diaz-Descalzo; J. Boubeta-Puig; H. Macia; E. Brazalez-Segovia,"Computing Science, Universidad de Castilla-La Mancha, 16733 Albacete, Castilla-La Mancha, Spain, (e-mail: Valentin.valero@uclm.es); Computer Science, Universidad de Castilla-La Mancha - Campus de Albacete, 73073 Albacete, Albacete, Spain, 02071 (e-mail: gregorio.diaz@uclm.es); Computer Science and Engineering, Universidad de Cdiz, 16727 Cadiz, Andaluca, Spain, (e-mail: juan.boubeta@uca.es); Mathematics, Universidad de Castilla-La Mancha, 16733 Albacete, Castilla-La Mancha, Spain, (e-mail: hermenegilda.macia@uclm.es); Computer Science, University of Castilla-La Mancha, 16733 Albacete, Albacete, Spain, 02071 (e-mail: Enrique.Brazalez@uclm.es)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Prioritized Colored Petri Nets (PCPNs) are a well-known extension of plain Petri nets in which transitions can have priorities and the tokens on the places carry data information. In this paper, we propose an extension of the PCPN model with black sequencing transitions (BPCPN). This extension allows us to easily model the ordered firing of the same transition using an ordered set of tokens on one of its precondition places. Black sequencing transitions are then presented as a shorthand notation in order to model the processing of a flow of events, represented by one of their precondition places. We then show how black sequencing transitions can be encoded into PCPNs, and their application to model Complex Event Processing (CEP), defining a compositional approach to translate some of the most relevant event pattern operators. We have developed MEdit4CEP-BPCPN, an extension of the MEdit4CEP tool, to provide tool support for this novel technique, thus allowing end users to easily define event patterns and obtain an automatic translation into BPCPNs. This can, in turn, be transformed into a corresponding PCPN, and then be immediately used in CPN Tools. Finally, a health case study concerning the monitoring of pregnant women is considered to illustrate how the event patterns are created and how the BPCPN and PCPN models are obtained by using the MEdit4CEP-BPCPN tool.",1939-3520,,10.1109/TSE.2021.3065584,Universidad de Castilla-La Mancha; Junta de Comunidades de Castilla-La Mancha; Ministerio de Ciencia Innovacin y Universidades; European Regional Development Fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376633,Colored Petri Nets;CEP;EPL;Compositional Modeling;Model-Driven Development,Analytical models;Tools;Semantics;Petri nets;Sequential analysis;Syntactics;Image color analysis,,,,,,,CCBY,11 Mar 2021,,,IEEE,IEEE Early Access Articles
1693,332,Deep Learning Based Program Generation from Requirements Text: Are We There Yet?,H. Liu; M. Shen; J. Zhu; N. Niu; G. Li; L. Zhang,"Computer Science and Technology, Software Lab, Beijing, Beijing China 100081 (e-mail: liuhui2005@gmail.com); Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 3120181025@bit.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: zhujiaqi@bit.edu.cn); EECS, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: nan.niu@uc.edu); Software Institute, Peking University, Beijing, Beijing China (e-mail: lige@pku.edu.cn); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"To release developers from time-consuming software development, many approaches have been proposed to generate source code automatically according to software requirements. With significant advances in deep learning and natural language processing, deep learning-based approaches are proposed to generate source code from natural language descriptions. The key insight is that given a large corpus of software requirements and their corresponding implementations, advanced deep learning techniques may learn how to translate software requirements into source code that fulfill such requirements. Although such approaches are reported to be highly accurate, they are evaluated on datasets that are rather small, lack of diversity, and significantly different from real-world software requirements. To this end, we build a large scale dataset that is composed of longer requirements as well as validated implementations. We evaluate the state-of-the-art approaches on this new dataset, and the results suggest that their performance on our dataset is significantly lower than that on existing datasets concerning the common metrics, i.e. BLEU. Evaluation results also suggest that the generated programs often contain syntactic and semantical errors, and none of them can pass even a single predefined test case. Further analysis reveals that the state-of-the-art approaches learn little from software requirements, and most of the successfully generated statements are popular statements in the training programs. Based on this finding, we propose a popularity-based approach that always generates the most popular statements in training programs regardless of the input (software requirements). Evaluation results suggest that none of the state-of-the-art approaches can outperform this simple statistics-based approach. As a conclusion, deep learning-based program generation requires significant improvement in the future, and our dataset may serve as a basis for future research in this direction.",1939-3520,,10.1109/TSE.2020.3018481,National Natural Science Foundation of China; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173704,Software Requirements;Code Generation;Deep Learning;Data Set,Software;Unified modeling language;Object oriented modeling;Syntactics;Tools;DSL;Deep learning,,,,,,,,21 Aug 2020,,,IEEE,IEEE Early Access Articles
1694,333,Algorithmic Profiling for Real-World Complexity Problems,B. Qin; T. Tu; Z. Liu; T. Yu; L. Song,"School of Cyberspace Security, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China, (e-mail: bobbqqin@bupt.edu.cn); State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China, (e-mail: tutengfei.kevin@bupt.edu.cn); College of Information Sciences and Technology, The Pennsylvania State University, 8082 University Park, Pennsylvania, United States, (e-mail: zxl381@psu.edu); Computer Science, University of Kentucky, 4530 Lexington, Kentucky, United States, (e-mail: tyu@cs.uky.edu); College of Information Sciences and Technology, The Pennsylvania State University, 8082 University Park, Pennsylvania, United States, (e-mail: songlh@ist.psu.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Complexity problems are a common type of performance issues, caused by algorithmic inefficiency. Algorithmic profiling aims to automatically attribute execution complexity to an executed code construct. It can identify code constructs in superlinear complexity to facilitate performance optimizations and debugging. However, existing algorithmic profiling techniques suffer from several severe limitations, missing the opportunity to be deployed in production environment and failing to effectively pinpoint root causes for performance failures caused by complexity problems. In this paper, we design a tool, ComAir, which can effectively conduct algorithmic profiling in production environment. We propose several novel instrumentation methods to significantly lower runtime overhead and enable the production-run usage. We also design an effective ranking mechanism to help developers identify root causes of performance failures due to complexity problems. Our experimental results show that ComAir can effectively identify root causes and generate accurate profiling results in production environment, while incurring a negligible runtime overhead",1939-3520,,10.1109/TSE.2021.3067652,Division of Computing and Communication Foundations; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382886,Algorithmic complexity;program analysis,Complexity theory;Computer bugs;Production;Tools;Runtime;Software;Instruments,,,,,,,IEEE,22 Mar 2021,,,IEEE,IEEE Early Access Articles
1695,334,"Quantifying, Characterizing, and Mitigating Flakily Covered Program Elements",S. V. Vaidhyam Subramanian; S. McIntosh; B. Adams,"Electrical and Computer Engineering, McGill University, 5620 Montreal, Quebec Canada (e-mail: shivashree.vaidhyamsubramanian@mail.mcgill.ca); David R. Cheriton School of Computing, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: shane.mcintosh@uwaterloo.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: bram.adams@polymtl.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Code coverage measures the degree to which source code elements (e.g., statements, branches) are invoked during testing. Despite growing evidence that coverage is a problematic measurement, it is often used to make decisions about where testing effort should be invested. For example, using coverage as a guide, tests should be written to invoke the non-covered program elements. At their core, coverage measurements assume that invocation of a program element during any test is equally valuable. Yet in reality, some tests are more robust than others. As a concrete instance of this, we posit in this paper that program elements that are only covered by flaky tests, i.e., tests with non-deterministic behaviour, are also worthy of investment of additional testing effort. In this paper, we set out to quantify, characterize, and mitigate ""flakily covered"" program elements (i.e., those elements that are only covered by flaky tests). To that end, we perform an empirical study of three large software systems from the OpenStack community. In terms of quantification, we find that systems are disproportionately impacted by flakily covered statements with 5% and 10% of the covered statements in Nova and Neutron being flakily covered, respectively, while < 1% of Cinder statements are flakily covered. In terms of characterization, we find that incidences of flakily covered statements could not be well explained by solely using code characteristics, such as dispersion, ownership, and development activity. In terms of mitigation, we propose GreedyFlake - a test effort prioritization algorithm to maximize return on investment when tackling the problem of flakily covered program elements. We find that GreedyFlake outperforms baseline approaches by at least eight percentage points of Area Under the Cost Effectiveness Curve.",1939-3520,,10.1109/TSE.2020.3010045,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143477,Code coverage;Software testing;Flaky tests,Testing;Neutrons;Software;Logic gates;Data mining;Robustness,,,,,,,,17 Jul 2020,,,IEEE,IEEE Early Access Articles
1696,335,Automated Classification of Overfitting Patches with Statically Extracted Code Features,H. Ye; J. Gu; M. Martinez; T. Durieux; M. Monperrus,"TCS, KTH Royal Institute of Technology School of Computer Science and Communication, 156318 Stockholm, Stockholm, Sweden, (e-mail: heye@kth.se); TCS, KTH Royal Institute of Technology School of Computer Science and Communication, 156318 Stockholm, Stockholm, Sweden, (e-mail: jiagu@kth.se); Informatique, Universite de Valenciennes et du Hainaut-Cambresis Antenne de Maubeuge, 244686 Maubeuge, Nord, France, (e-mail: matias.martinez@univ-valenciennes.fr); TCS, KTH, 7655 Stockholm, Stockholm, Sweden, 100 44 (e-mail: thomas@durieux.me); EECS - TCS, KTH Royal Institute of Technology, Stockholm, Stockholm, Sweden, 10044 (e-mail: martin.monperrus@csc.kth.se)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Automatic program repair (APR) aims to reduce the cost of manually fixing software defects. However, APR suffers from generating a multitude of overfitting patches, those patches that fail to correctly repair the defect beyond making the tests pass. This paper presents a novel overfitting patch detection system called ODS to assess the correctness of APR patches. ODS first statically compares a patched program and a buggy program in order to extract code features at the abstract syntax tree (AST) level. Then, ODS uses supervised learning with the captured code features and patch correctness labels to automatically learn a probabilistic model. The learned ODS model can then finally be applied to classify new and unseen program repair patches. We conduct a large-scale experiment to evaluate the effectiveness of ODS on patch correctness classification based on 10,302 patches from Defects4J, Bugs.jar and Bears benchmarks. The empirical evaluation shows that ODS is able to correctly classify 71.9% of program repair patches from 26 projects, which improves the state-of-the-art. ODS is applicable in practice and can be employed as a post-processing procedure to classify the patches generated by different APR systems.",1939-3520,,10.1109/TSE.2021.3071750,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399306,Automatic program repair;Patch assessment;Overfitting patch;Code features,Feature extraction;Maintenance engineering;Training;Tools;Syntactics;Software;Predictive models,,,,,,,IEEE,8 Apr 2021,,,IEEE,IEEE Early Access Articles
1697,336,Automatic Test Case and Test Oracle Generation based on Functional Scenarios in Formal Specifications for Conformance Testing,S. Liu; S. Nakajima,"Computer Science, Hosei University, Koganei-shi, Tokyo Japan (e-mail: sliu@hiroshima-u.ac.jp); Information and Society Research, National Institute of Informatics, Japan, Tokyo, Tokyo Japan (e-mail: nkjm@nii.ac.jp)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Testing a program to confirm whether it consistently implements its requirements specification is a necessary but time-consuming activity in software development. Automatic testing based on specifications can significantly alleviate the workload and cost, but faces a challenge of how to ensure that both the user's concerns in the specification and possible execution paths in the program are all covered. In this paper, we describe a new method, called ""Vibration-Method"" or simply ""V-Method"", for automatic generation of test cases and test oracle from model-based formal specifications, aiming to address this challenge. The proposed method is suitable for testing information systems in which rich data types are used. Supporting the principle of ""divide and conquer"", the method provides a specific technique for generating test cases based on functional scenarios defined in the specification, test case generation criteria, automatic test case generation algorithms, and a well-defined mechanism for deriving test oracle. We elaborate on the method by discussing how initial test cases can be automatically generated, how additional necessary test cases are produced using the ""vibration"" technique, and how a test oracle can be automatically derived for a group of test cases. We also describe a controlled experiment to evaluate the effectiveness of the method and discuss the important issues in relation to the performance and applicability of the method.",1939-3520,,10.1109/TSE.2020.2999884,JSPS KAKENHI; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108630,Specification-based testing;Black-box testing;Functional testing;Model-based testing;Automatic testing,Software;Vibrations;Input variables;Conformance testing;Automatic testing;Information systems,,,,1.0,,,,4 Jun 2020,,,IEEE,IEEE Early Access Articles
1698,337,Mining Similar Methods for Test Adaptation,D. Sondhi; M. Jobanputra; D. Rani; S. Purandare; S. Sharma; R. Purandare,"CSE, Indraprastha Institute of Information Technology Delhi, 243095 New Delhi, Delhi, India, (e-mail: devikas@iiitd.ac.in); Computer Science, IIITD, 243095 New Delhi, Delhi, India, 110020 (e-mail: mayankjobanputra@gmail.com); Computer Science and Engineering, Gandhi Institute For Technological Advancement, 209150 Bhubaneswar, Odisha, India, 752054 (e-mail: ranidivya063@gmail.com); Computer Science and Engineering, Indraprastha Institute of Information Technology Delhi, 243095 New Delhi, Delhi, India, 110020 (e-mail: salil.purandare@gmail.com); Computer Science Engineering, International Institute of Information Technology Bhubaneswar, 267396 Bhubaneswar, Odisha, India, 751003 (e-mail: phs.sakshi@gmail.com); Computer Science and Engineering, Indraprastha Institute of Information Technology, 243095 New Delhi, Delhi, India, (e-mail: purandare@iiitd.ac.in)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Developers may choose to implement a library despite the existence of similar libraries, considering factors such as computational performance, language or platform dependency, accuracy, convenience, and completeness of an API. As a result, GitHub hosts several library projects that have overlaps in their functionalities. These overlaps have been of interest to developers from the perspective of code reuse or the preference of one implementation over the other. Through an empirical study, we explore the extent and nature of existence of these similarities in the library functions. We have further studied whether the similarity of functions across different libraries and their associated test suites can be leveraged to reveal defects in one another. We see scope for effectively using the mining of test suites from the perspective of revealing defects in a program or its documentation. Another noteworthy observation made in the study is that similar functions may exist across libraries implemented in the same language as well as in different languages. Identifying the challenges that lie in building a testing tool, we automate the entire process in Metallicus, a test mining and recommendation tool. Metallicus returns a test suite for the given input of a query function and a template for its test suite. On a dataset of query functions taken from libraries implemented in Java or Python, Metallicus revealed 46 defects.",1939-3520,,10.1109/TSE.2021.3057163,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347715,Test suites;mining;software testing;function similarity,Libraries;Testing;Tools;Software development management;Python;Documentation;Open source software,,,,,,,IEEE,4 Feb 2021,,,IEEE,IEEE Early Access Articles
1699,338,On the Value of Oversampling for Deep Learning in Software Defect Prediction,R. Yedida; T. Menzies,"Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: ryedida@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"One truism of deep learning is that the automatic feature engineering (seen in the first layers of those networks) excuses data scientists from performing tedious manual feature engineering prior to running DL. For the specific case of deep learning for defect prediction, we show that that truism is false. Specifically, when we pre-process data with a novel oversampling technique called fuzzy sampling, as part of a larger pipeline called GHOST (Goal-oriented Hyper-parameter Optimization for Scalable Training), then we can do significantly better than the prior DL state of the art in 14/20 defect data sets. Our approach yields state-of-the-art results significantly faster deep learners. These results present a cogent case for the use of oversampling prior to applying deep learning on software defect prediction datasets.",1939-3520,,10.1109/TSE.2021.3079841,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429914,defect prediction;oversampling;class imbalance;neural networks,Deep learning;Tuning;Predictive models;Standards;Prediction algorithms;Training;Tools,,,,,,,IEEE,12 May 2021,,,IEEE,IEEE Early Access Articles
1700,339,Automated Expansion of Abbreviations Based on Semantic Relation and Transfer Expansion,Y. Jiang; H. Liu; J. Jin; L. Zhang,"Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, China China (e-mail: 2990094974@qq.com); School of Computer Science and Technology, Beijing Institute of Technology, Beijing, Beijing China 100081 (e-mail: liuhui08@bit.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: jinjiahao1993@gmail.com); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Although the negative impact of abbreviations in source code is well-recognized, abbreviations are common for various reasons. To this end, a number of approaches have been proposed to expand abbreviations in identifiers. However, such approaches are either inaccurate or confined to specific identifiers. To this end, in this paper, we propose a generic and accurate approach to expand identifier abbreviations by leveraging both semantic relation and transfer expansion. One of the key insight of the approach is that abbreviations in the name of software entity e have great chance to find their full terms in names of software entities that are semantically related to e. Consequently, the proposed approach builds a knowledge graph to represent such entities and their relationships with e, and searches the graph for full terms. Another key insight is that literally identical abbreviations within the same application are likely (but not necessary) to have identical expansions, and thus the semantics-based expansion in one place may be transferred to other places. To investigate when abbreviation expansion could be transferred safely, we conduct a case study on three open-source applications. The results suggest that a significant part (75%) of expansions could be transferred among lexically identical abbreviations within the same application. However, the risk of transfer varies according to various factors, e.g., length of abbreviations, physical distance between abbreviations, and semantic relations between abbreviations. Based on these findings, we design nine heuristics for transfer expansion, and propose a learning based approach to prioritize both transfer heuristics and semantic-based expansion heuristics. Evaluation results on nine open-source applications suggest that the proposed approach significantly improves the state of the art, improving recall from 29% to 89% and precision from 39% to 92%.",1939-3520,,10.1109/TSE.2020.2995736,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096573,Abbreviation;Expansion;Transfer;Context;Quality,Semantics;Dictionaries;Manuals;Internet;Open source software;Encyclopedias,,,,,,,,19 May 2020,,,IEEE,IEEE Early Access Articles
1701,340,Corrections to “Automatic and Accurate Expansion of Abbreviations in Parameters”,Y. Jiang; H. Liu; J. Zhu; L. Zhang,"School of Computer Science and Technology, Beijing Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, P.R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, P.R. China",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,1039,1039,Presents corrections to author information in the above named paper.,1939-3520,,10.1109/TSE.2020.3015699,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199188,,Computer science;Software,,,,,,1.0,IEEE,17 Sep 2020,,,IEEE,IEEE Journals
1702,341,SigRec: Automatic Recovery of Function Signatures in Smart Contracts,T. Chen; Z. Li; X. Luo; X. Wang; T. Wang; Z. He; K. Fang; Y. Zhang; H. Zhu; H. Li; Y. Cheng; X. -s. Zhang,"Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: brokendragon@uestc.edu.cn); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: gforiq@qq.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); School of Informatics and Computer Science Department, Indiana University at Bloomington, Bloomington, Indiana, United States, 47406 (e-mail: xw7@indiana.edu); College of Information Sciences and Technology, Pennsylvania State University, 8082 University Park, Pennsylvania, United States, (e-mail: inbox.ting@gmail.com); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: ecjgvmhc@gmail.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: fangkezhao@126.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: 2235285714@qq.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: 568991738@qq.com); computer science, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: hongweili@uestc.edu.cn); Blockchain, Ant Group, China., Jiangshu, Zhejiang, China, (e-mail: xiaoge.cy@antgroup.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: johnsonzxs@uestc.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Millions of smart contracts have been deployed onto Ethereum for providing various services, which can be invoked through their functions. For this purpose, the caller needs to know the function signature of a callee, which includes its function id and parameter types. Such signatures are critical to many applications focusing on smart contracts, e.g., reverse engineering, fuzzing, attack detection, and profiling. Unfortunately, it is challenging to recover the function signatures from contract bytecode, since neither debug information nor type information is present in the bytecode. To address this issue, prior approaches rely on source code, or a collection of known signatures from incomplete databases or incomplete heuristic rules, which, however, are far from adequate and cannot cope with the rapid growth of new contracts. In this paper, we propose a novel solution that leverages how functions are handled by Ethereum virtual machine (EVM) to automatically recover function signatures. In particular, we exploit how smart contracts determine the functions to be invoked to locate and extract function ids, and propose a new approach named type-aware symbolic execution (TASE) that utilizes the semantics of EVM operations on parameters to identify the number and the types of parameters.Moreover, we develop SigRec, a new tool for recovering function signatures from contract bytecode without the need of source code and function signature databases. The extensive experimental results show that SigRec outperforms all existing tools, achieving an unprecedented 98.9% accuracy within 0.07 seconds. We further demonstrate that the recovered function signatures are useful in attack detection, fuzzing and reverse engineering of EVM bytecode.",1939-3520,,10.1109/TSE.2021.3078342,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426396,smart contract;function signature;Ethereum;automatic recovery;type-aware symbolic execution,Smart contracts;Databases;Reverse engineering;Semantics;Lenses;Layout;Tools,,,,,,,IEEE,7 May 2021,,,IEEE,IEEE Early Access Articles
1703,342,A Methodology for Analyzing Uptake of SoftwareTechnologies Among Developers,Y. Ma; A. Mockus; R. Zaretzki; B. Bichescu; R. Bradley,"EECS, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: yma28@vols.utk.edu); Avaya Labs Research, Avaya Labs, Basking Ridge, New Jersey United States 07920 (e-mail: audris@utk.edu); Business Analytics and Statistics, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: russell.zaretzki@gmail.com); Business Analytics and Statistics, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: bbichescu@utk.edu); Supply Chain Management, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: rbradley@utk.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Motivation: The question of what combination of attributes drives the adoption of a particular software technology is critical to developers. It determines both those technologies that receive wide support from the community and those which may be abandoned, thus rendering developers' investments worthless. Aim and Context: We model software technology adoption by developers and provide insights on specific technology attributes that are associated with better visibility among alternative technologies. Thus, our findings have practical value for developers seeking to increase the adoption rate of their products. Approach: We leverage social contagion theory and statistical modeling to identify, define, and test empirically measures that are likely to affect software adoption. More specifically, we leverage a large collection of open source repositories to construct a software dependency chain for a specific set of R language source-code files. We formulate logistic regression models, where developers' software library choices are modeled, to investigate the combination of technological attributes that drive adoption among competing data frame (a core concept for a data science languages) implementations in the R language: tidy and data.table. To describe each technology, we quantify key project attributes that might affect adoption (e.g., response times to raised issues, overall deployments, number of open defects, knowledge base) and also characteristics of developers making the selection (performance needs, scale, and their social network). Results: We find that a quick response to raised issues, a larger number of overall deployments, and a larger number of high-score StackExchange questions are associated with higher adoption. Decision makers tend to adopt the technology that is closer to them in the technical dependency network and in author collaborations networks while meeting their performance needs. To gauge the generalizability of the proposed methodology, we investigate the spread of two popular web JavaScript frameworks Angular and React, and discuss the results. Future work: We hope that our methodology encompassing social contagion that captures both rational and irrational preferences and the elucidation of key measures from large collections of version control data provides a general path toward increasing visibility, driving better informed decisions, and producing more sustainable and widely adopted software.",1939-3520,,10.1109/TSE.2020.2993758,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091014,choice models;social contagion;technology adoption;library migration;software supply chain,Software;Supply chains;Technological innovation;Software measurement;Data models;Time factors;Libraries,,,,,,,,11 May 2020,,,IEEE,IEEE Early Access Articles
1704,343,Studying the Association between Bountysource Bounties and the Issue-addressing Likelihood of GitHub Issue Reports,J. Zhou; S. Wang; C. Bezemer; Y. Zou; A. E. Hassan,"School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: jzhou@cs.queensu.ca); Department of Computer Science and Engineering, Mississippi State University, 5547 Mississippi State, Mississippi United States (e-mail: wang@cse.msstate.edu); Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Alberta Canada (e-mail: bezemer@ualberta.ca); Electrical and Computer Enginereing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ying.zou@queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Due to the voluntary nature of open source software, it can be hard to find a developer to work on a particular task. For example, some issue reports may be too cumbersome and unexciting for someone to volunteer to do them, yet these issue reports may be of high priority to the success of a project. To provide an incentive for implementing such issue reports, one can propose a monetary reward, i.e., a bounty, to the developer who completes that particular task. In this paper, we study bounties in open source projects on GitHub to better understand how bounties can be leveraged to evolve such projects in terms of addressing issue reports. We investigated 5,445 bounties for GitHub projects. These bounties were proposed through the Bountysource platform with a total bounty value of 406,425. We find that 1) in general, the timing of proposing bounties is the most important factor that is associated with the likelihood of an issue being addressed. More specifically, issue reports are more likely to be addressed if they are for projects in which bounties are used more frequently and if they are proposed earlier. 2) The bounty value of an issue report is the most important factor that is associated with the issue-addressing likelihood in the projects in which no bounties were used before. 3) There is a risk of wasting money for backers who invest money on long-standing issue reports.",1939-3520,,10.1109/TSE.2020.2974469,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000923,Software evolution;open source software;Bountysource;bounties;GitHub,Security;Open source software;Task analysis;Timing;Computer bugs;Indexes,,,,,,,,17 Feb 2020,,,IEEE,IEEE Early Access Articles
1705,344,CTOS: Compiler Testing for Optimization Sequences of LLVM,H. Jiang; Z. Zhou; Z. Ren; J. Zhang; X. Li,"School of Software, Dalian University of Technology, Dalian, Liaoning, China, 116621 (e-mail: jianghe@dlut.edu.cn); School of Software, Dalian University of Technology, 12399 Dalian, Liaoning, China, (e-mail: cszide@gmail.com); School of Software, Dalian University of Technology, 12399 Dalian, Liaoning, China, (e-mail: zren@dlut.edu.cn); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu, China, (e-mail: jxzhang@nuaa.edu.cn); the SnT Centre for Security, Reliability and Trust, University of Luxembourg, 81872 Luxembourg, Luxembourg, Luxembourg, (e-mail: xiaochen.li@uni.lu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Optimization sequences are often employed in compilers to improve the performance of programs, but may trigger critical compiler bugs, e.g., compiler crashes. Although many methods have been developed to automatically test compilers, no systematic work has been conducted to detect compiler bugs when applying arbitrary optimization sequences. To resolve this problem, two main challenges need to be addressed, namely the acquisition of representative optimization sequences and the selection of representative testing programs, due to the enormous number of optimization sequences and testing programs. In this study, we propose CTOS, a novel compiler testing method based on differential testing, for detecting compiler bugs caused by optimization sequences of LLVM. CTOS firstly leverages the technique Doc2Vec to transform optimization sequences into vectors to capture the information of optimizations and their orders simultaneously. Secondly, a method based on the region graph and call relationships is developed in CTOS to construct the vector representations of testing programssuch that the semantics and the structure information of programs can be captured simultaneously. Then, with the vector representations of optimization sequences and testing programs, a centroid based selection scheme is proposed to address the above two challenges. Finally, CTOS takes in the representative optimization sequences and testing programs as inputs, and tests each testing program with all the representative optimization sequences. If there is an output that is different from the majority of others of a given testing program, then the corresponding optimization sequence is deemed to trigger a compiler bug. Our evaluation demonstrates that CTOS significantly outperforms the baselines by up to 24.76% 45.56% in terms of the bug-finding capability on average. Within seven month evaluations on LLVM, we have reported 104 valid bugs within 5 types, of which 21 have been confirmed or fixed. Most of those bugs are crash bugs (57) and wrong code bugs (24). 47 unique optimizations are identified to be faulty and 15 of them are loop related optimizations.",1939-3520,,10.1109/TSE.2021.3058671,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9353261,Compiler testing;Optimization sequences;LLVM;Program representation;Software testing,Optimization;Computer bugs;Testing;Program processors;Systematics;Electromagnetic interference;Software,,,,,,,IEEE,11 Feb 2021,,,IEEE,IEEE Early Access Articles
1706,345,Will Dependency Conflicts Affect My Program's Semantics,Y. Wang; R. Wu; C. Wang; M. Wen; Y. Liu; S. C. Cheung; H. Yu; C. Xu; Z. -l. Zhu,"Software college, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: wangying@swc.neu.edu.cn); Department of Cyber Space Security, Xiamen University, 12466 Xiamen, Fujian, China, (e-mail: wurongxin@xmu.edu.cn); Software College, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: wangc_neu@163.com); Cyber Science and Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei, China, 430074 (e-mail: mwenaa@hust.edu.cn); Computer Science and Engineering, Southern University of Science and Technology, 255310 Shenzhen, Guangdong, China, (e-mail: liuyp1@sustech.edu.cn); Department of Computer Science and Engineering, Hong Kong University of Science and Technology, 58207 Kowloon, Hong Kong, China, (e-mail: scc@cse.ust.hk); Software College, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: yuhai@mail.neu.edu.cn); Department of Computer Science and Engineering, Nanjing University, 12581 Nanjing, Jiangsu, China, (e-mail: changxu@nju.edu.cn); Software College, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: ZHUZhiLiang_NEU@163.com)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Java projects are often built on top of various third-party libraries. If multiple versions of a library exist on the classpath, JVM will only load one version and shadow the others, which we refer to as dependency conflicts. This would give rise to semantic conflict (SC) issues, if the library APIs referenced by a project have identical method signatures but inconsistent semantics across the loaded and shadowed versions of libraries. SC issues are difficult for developers to diagnose in practice, since understanding them typically requires domain knowledge. Although adapting the existing test generation technique for dependency conflict issues, Riddle, to detect SC issues is feasible, its effectiveness is greatly compromised. This is mainly because Riddle randomly generates test inputs, while the SC issues typically require specific arguments in the tests to be exposed. To address that, we conducted an empirical study of 316 real SC issues to understand the characteristics of such specific arguments in the test cases that can capture the SC issues. Inspired by our empirical findings, we propose an automated testing technique Sensor, which synthesizes test cases using ingredients from the project under test to trigger inconsistent behaviors of the APIs with the same signatures in conflicting library versions. Our evaluation results show that Sensor is effective and useful: it achieved a Precision of 0.898 and a Recall of 0.725 on open-source projects and a Precision of 0.821 on industrial projects; it detected 306 semantic conflict issues in 50 projects, 70.4% of which had been confirmed as real bugs, and 84.2% of the confirmed issues have been fixed quickly.",1939-3520,,10.1109/TSE.2021.3057767,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350237,Third-party Libraries;Test Generation;Empirical Study,Libraries;Semantics;Testing;Open source software;Runtime;Java;Computer science,,,,,,,IEEE,8 Feb 2021,,,IEEE,IEEE Early Access Articles
1707,346,Chatbot4QR: Interactive Query Refinement for Technical Question Retrieval,N. Zhang; Q. Huang; X. Xia; Y. Zou; D. Lo; Z. Xing,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: nengzhang@zju.edu.cn); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: tkdsheep@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); Electrical and Computer Enginereing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ying.zou@queensu.ca); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: zhenchang.xing@anu.edu.au)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Technical Q&A sites (e.g., Stack Overflow(SO)) are important resources for developers to search for knowledge about technical problems. Search engines provided in Q&A sites and information retrieval approaches have limited capabilities to retrieve relevant questions when queries are imprecisely specified, such as missing important technical details (e.g., the user's preferred programming languages). Although many automatic query expansion approaches have been proposed to improve the quality of queries by expanding queries with relevant terms, the information missed is not identified. Moreover, without user involvement, the existing query expansion approaches may introduce unexpected terms and lead to undesired results. In this paper, we propose an interactive query refinement approach for question retrieval, named Chatbot4QR, which assists users in recognizing and clarifying technical details missed in queries and thus retrieve more relevant questions for users. Chatbot4QR automatically detects missing technical details in a query and generates several clarification questions (CQs) to interact with the user to capture their overlooked technical details. To ensure the accuracy of CQs, we design a heuristic-based approach for CQ generation after building two kinds of technical knowledge bases: a manually categorized result of 1,841 technical tags in SO and the multiple version-frequency information of the tags. We collect 1.88 million SO questions as the repository for question retrieval. To evaluate Chatbot4QR, we conduct six user studies with 25 participants on 50 experimental queries. The results show that: (1)On average 60.8% of the CQs generated for a query are useful for helping the participants recognize missing technical details; (2)Chatbot4QR can rapidly respond to the participants after receiving a query within ~1.3 seconds; (3)The refined queries contribute to retrieving more relevant SO questions than nine baseline approaches. For more than 70% of the participants who have preferred techniques on the query tasks, Chatbot4QR significantly outperforms the state-of-the-art word embedding-based retrieval approach with an improvement of at least 54.6% in terms of Pre@k and NDCG@k; and (4)For 48%-88% of the assigned query tasks, the participants obtain more desired results after interacting with Chatbot4QR than directly searching from Web search engines (e.g., the SO search engine and Google) using the original queries.",1939-3520,,10.1109/TSE.2020.3016006,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165927,Interactive Query Refinement;Chatbot;Question Retrieval;Stack Overflow,Search engines;Web search;Java;Task analysis;Engines;Databases,,,,1.0,,,,12 Aug 2020,,,IEEE,IEEE Early Access Articles
1708,347,Are You Still Working on This An Empirical Study on Pull Request Abandonment,Z. Li; Y. Yu; T. Wang; G. Yin; S. Li; H. Wang,"Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: lizhixing15@nudt.edu.cn); computer science, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: yuyue@nudt.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: taowang2005@nudt.edu.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: yingang@nudt.edu.cn); computer science, National University of Defense Technology, Changsha, Hunan, China, (e-mail: shanshanli@nudt.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: hmwang@nudt.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"The great success of numerous community-based open source software (OSS) is based on volunteers continuously submitting contributions, but ensuring sustainability is a persistent challenge in OSS communities. Although the motivations behind and barriers to OSS contributors' joining and retention have been extensively studied, the impacts of, reasons for and solutions to contribution abandonment at the individual level have not been well studied, especially for pull-based development. To bridge this gap, we present an empirical study on pull request abandonment based on a sizable dataset. We manually examine 321 abandoned pull requests on GitHub and then quantify the manual observations by surveying 710 OSS developers. We find that while the lack of integrators' responsiveness, the lack of contributors' time and interest remain the main reasons that deter contributors from participation, limitations during the processes of patch updating and consensus reaching can also cause abandonment. We also show the significant impacts of pull request abandonment on project management and maintenance. Moreover, we elucidate the strategies used by project integrators to cope with abandoned pull requests and highlight the need for a practical handover mechanism. We discuss the actionable suggestions and implications for OSS practitioners and tool builders, which can help to upgrade the infrastructure and optimize the mechanisms of OSS communities.",1939-3520,,10.1109/TSE.2021.3053403,National Grand RD Plan; National Natural ScienceFoundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332267,Pull Request Abandonment;Pull-based Development;Open Source Software,Tools;Collaboration;Sustainable development;Open source software;Manuals;Maintenance engineering;Computer bugs,,,,,,,IEEE,21 Jan 2021,,,IEEE,IEEE Early Access Articles
1709,348,Reuse of Similarly Behaving Software through Polymorphism-Inspired Variability Mechanisms,I. Reinhartz-Berger; A. Zamansky,"Information Systems, University of Haifa, Haifa, Israel Israel 31905 (e-mail: iris@is.haifa.ac.il); Department of Information Systems, University of Haifa, Haifa, Haefa Israel (e-mail: annazam@is.haifa.ac.il)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"In many cases, software artifacts share similarity across projects and development teams. However, often this similarity is only partially reflected on the level of design and implementation, and therefore the possibilities for its detection are limited in current variability analysis, clone detection, and application search approaches. In this paper, we propose a method for identification and comparison of similarly behaving software. The method, supported by a prototype tool, analyzes the behavioral similarity of object-oriented code artifacts based on shallow (behavior interface) and deep (behavior transformation) descriptions of the exhibited operations. It further recommends on suitable mechanisms inspired by the notion of polymorphism in order to guide and support current and future reuse. The approach was evaluated on two data-sets, obtained following two different scenarios: clone-and-own and independent development by different teams.",1939-3520,,10.1109/TSE.2020.3001512,ISRAEL SCIENCE FOUNDATION; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113764,Variability;Reuse;Code Clones;Polymorphism;Software Product Line Engineering,Cloning;Software;Measurement;Software product lines;Java;Object oriented modeling;Tools,,,,,,,,10 Jun 2020,,,IEEE,IEEE Early Access Articles
1710,349,ConEx: Efficient Exploration of Big-Data System Configurations for Better Performance,R. Krishna; C. Tang; K. Sullivan; B. Ray,"Computer Science, Columbia University, 5798 New York, New York, United States, (e-mail: i.m.ralk@gmail.com); Research and Development, Microsoft Corp, 6834 Redmond, Washington, United States, (e-mail: ct4ew@virginia.edu); Computer Science, University of Virginia, Charlottesville, Virginia, United States, (e-mail: sullivan@virginia.edu); Computer Science, Columbia University, New York, New York, United States, (e-mail: rayb@cs.columbia.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Configuration space complexity makes the big-data software systems hard to configure well. Consider Hadoop, with over nine hundred parameters, developers often just use the default configurations provided with Hadoop distributions. The opportunity costs in lost performance are significant. Popular learning-based approaches to auto-tune software does not scale well for big-data systems because of the high cost of collecting training data. We present a new method based on a combination of Evolutionary Markov Chain Monte Carlo (EMCMC)} sampling and cost reduction techniques tofind better-performing configurations for big data systems. For cost reduction, we developed and experimentally tested and validated two approaches: using scaled-up big data jobs as proxies for the objective function for larger jobs and using a dynamic job similarity measure to infer that results obtained for one kind of big data problem will work well for similar problems. Our experimental results suggest that our approach promises to improve the performance of big data systems significantly and that it outperforms competing approaches based on random sampling, basic genetic algorithms (GA), and predictive model learning. Our experimental results support the conclusion that our approach strongly demonstrates the potential toimprove the performance of big data systems significantly and frugally.",1939-3520,,10.1109/TSE.2020.3007560,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134972,Performance Optimization;MCMC;SBSE;Machine Learning,Big Data;Software systems;Machine learning;Markov processes;Monte Carlo methods;Predictive models,,,,,,,,7 Jul 2020,,,IEEE,IEEE Early Access Articles
1711,350,Efficient Parametric Model Checking Using Domain Knowledge,R. Calinescu; C. A. Paterson; K. Johnson,"Computer Science, University of York, York, North Yorkshire United Kingdom of Great Britain and Northern Ireland (e-mail: radu.calinescu@york.ac.uk); Computer Science, University of York, York, North Yorkshire United Kingdom of Great Britain and Northern Ireland YO10 5GH (e-mail: colin.paterson@york.ac.uk); School of Computer and Mathematical Sciences, Auckland University of Technology, 1410 Auckland, Auckland New Zealand (e-mail: kenneth.johnson@aut.ac.nz)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"We introduce an efficient parametric model checking (ePMC) method for the analysis of reliability, performance and other quality-of-service (QoS) properties of software systems. ePMC speeds up the analysis of parametric Markov chains modelling the behaviour of software by exploiting domain-specific modelling patterns for the software components (e.g., patterns modelling the invocation of functionally-equivalent services used to jointly implement the same operation within service-based systems, or the deployment of the components of multi-tier software systems across multiple servers). To this end, ePMC precomputes closed-form expressions for key QoS properties of such patterns, and uses these expressions in the analysis of whole-system models. To evaluate ePMC, we show that its application to service-based systems and multi-tier software architectures reduces the analysis time by several orders of magnitude compared to current parametric model checking methods.",1939-3520,,10.1109/TSE.2019.2912958,Assuring Autonomy International Programme; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8698796,Parametric model checking;Markov models;model abstraction;probabilistic model checking;quality of service,Markov processes;Quality of service;Analytical models;Unified modeling language;Software;Probabilistic logic;Parametric statistics,,,,1.0,,,,25 Apr 2019,,,IEEE,IEEE Early Access Articles
1712,351,Legion: Massively Composing Rankers for Improved Bug Localization at Adobe,D. Jarman; J. Berry; R. Smith; F. Thung; D. Lo,"Analytics, Adobe, Lehi, Utah, United States, (e-mail: djarman@adobe.com); Analytics, Adobe, Lehi, Utah, United States, (e-mail: berry@adobe.com); Analytics, Adobe, Lehi, Utah, United States, (e-mail: rilsmith@adobe.com); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, (e-mail: ferdiant.2013@smu.edu.sg); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Studies have estimated that, in industrial settings, developers spend between 30% and 90% of their time fixing bugs. As such, tools that assist in identifying the location of bugs provide value by reducing debugging costs. One such tool is BugLocator. This study initially aimed to determine if developers working on the Adobe Analytics product could use BugLocator. The initial results show that BugLocator achieves a similar accuracy on 5 of 7 Adobe Analytics repositories and on open-source projects. However, these results do not meet the minimum applicability requirement deemed necessary by Adobe Analytics developers prior to possible adoption. Thus, we consequently examine how BugLocator can achieve the targeted accuracy with two extensions: (1) adding more data corpora, and (2) massively composing individual rankers consisting of augmented BugLocator instances trained on various combinations of corpora and parameter configurations with a Random Forest model. We refer to our final extension as Legion. On average, applying Legion to Adobe Analytics repositories results in at least one buggy file ranked in the top-10 recommendations 76.8% of the time for customer-reported bugs across all 7 repositories. This represents a substantial improvement over BugLocator of 36.4%, and satisfies the minimum applicability requirement. Additionally, our extensions boost Mean Average Precision by 107.7%, Mean Reciprocal Rank by 86.1%, Top 1 by 143.4% and Top 5 by 58.1%.",1939-3520,,10.1109/TSE.2021.3075215,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415126,bug localization;information retrieval;bug reports;data augmentation;ranker composition;industrial study F,Computer bugs;Location awareness;Tools;Debugging;Random forests;Programming;Information retrieval,,,,,,,IEEE,23 Apr 2021,,,IEEE,IEEE Early Access Articles
1713,352,Defect Reduction Planning (using TimeLIME),K. Peng; T. Menzies,"Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: kpeng@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Software comes in releases. An implausible change to software is something that has never been changed in prior releases. When planning how to reduce defects, it is better to use plausible changes, i.e., changes with some precedence in the prior releases. To demonstrate these points, this paper compares several defect reduction planning tools. LIME is a local sensitivity analysis tool that can report the fewest changes needed to alter the classification of some code module (e.g., from ""defective"" to ""non-defective""). TimeLIME is a new tool, introduced in this paper, that improves LIME by restricting its plans to just those attributes which change the most within a project. In this study, we compared the performance of LIME and TimeLIME and several other defect reduction planning algorithms. The generated plans were assessed via (a) the similarity scores between the proposed code changes and the real code changes made by developers; and (b) the improvement scores seen within projects that followed the plans. For nine project trails, we found that TimeLIME outperformed all other algorithms (in 8 out of 9 trials). Hence, we strongly recommend using past releases as a source of knowledge for computing fixes for new releases (using TimeLIME). Apart from these specific results about planning defect reductions and TimeLIME, the more general point of this paper is that our community should be more careful about using off-the-shelf AI tools, without first applying SE knowledge. In this case study, it was not difficult to augment a standard AI algorithm with SE knowledge (that past releases are a good source of knowledge for planning defect reductions). As shown here, once that SE knowledge is applied, this can result in dramatically better systems.",1939-3520,,10.1109/TSE.2021.3062968,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371412,Software analytics;Defect Prediction;Defect Reduction;Plausibility Analysis;Interpretable AI,Software;Planning;Measurement;Tools;Software quality;Software algorithms;Couplings,,,,,,,IEEE,5 Mar 2021,,,IEEE,IEEE Early Access Articles
1714,353,How Different is Test Case Prioritization for Open and Closed Source Projects,X. Ling; R. Agrawal; T. Menzies,"Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: xling4@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: ragrawa3@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Improved test case prioritization means that software developers can detect and fix more software faults sooner than usual. But is there one ""best"" prioritization algorithm Or do different kinds of projects deserve special kinds of prioritization To answer these questions, this paper applies nine prioritization schemes to 31 projects that range from (a) highly rated open-source Github projects to (b) computational science software to (c) a closed-source project. We find that prioritization approaches that work best for open-source projects are can work worst for the closed-source project (and vice versa). From these experiments, we conclude that (a) it is ill-advised to always apply one prioritization scheme to all projects since (b) prioritization requires tuning to different project types.",1939-3520,,10.1109/TSE.2021.3063220,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367020,software testing;regression testing;test case prioritization;open-source software,Testing;Software;Open source software;Software development management;Measurement;Software algorithms;History,,,,,,,IEEE,2 Mar 2021,,,IEEE,IEEE Early Access Articles
1715,354,Evaluating Automatic Program Repair Capabilities to Repair API Misuses,M. Kechagia; S. Mechtaev; F. Sarro; M. Harman,"Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: m.kechagia@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mechtaev@live.com); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); CS, Facebook London, 507852 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"API misuses are well-known causes of software crashes and security vulnerabilities. However, their detection and repair is challenging given that the correct usages of (third-party) APIs might be obscure to the developers of client programs. This paper presents the first empirical study to assess the ability of existing automated bug repair tools to repair API misuses, which is a class of bugs previously unexplored. Our study examines and compares 14 Java test-suite-based repair tools (11 proposed before 2018, and three afterwards) on a manually curated benchmark (APIREPBENCH) consisting of 101 API misuses. We develop an extensible execution framework (APIARTY) to automatically execute multiple repair tools. Our results show that the repair tools are able to generate patches for 28% of the API misuses considered. While the 11 less recent tools are generally fast (the median execution time of the repair attempts is 3.87 minutes and the mean execution time is 30.79 minutes), the three most recent are less efficient (i.e., 98% slower) than their predecessors. The tools generate patches for API misuses that mostly belong to the categories of missing null check, missing value, missing exception, and missing call. Most of the patches generated by all tools are plausible (65%), but only few of these patches are semantically correct to human patches (25%). Our findings suggest that the design of future repair tools should support the localisation of complex bugs, including different categories of API misuses, handling of timeout issues, and ability to configure large software projects. Both APIREPBENCH and APIARTY have been made publicly available for other researchers to evaluate the capabilities of repair tools on detecting and fixing API misuses.",1939-3520,,10.1109/TSE.2021.3067156,European Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381596,Automatic Program Repair;Application Programming Interfaces;API Misuses;Bug Benchmarks,Tools;Maintenance engineering;Computer bugs;Benchmark testing;Software;Java;Security,,,,,,,IEEE,18 Mar 2021,,,IEEE,IEEE Early Access Articles
1716,355,ATOM: Commit Message Generation Based on Abstract Syntax Tree and Hybrid Ranking,S. Liu; C. Gao; S. Chen; N. Lun Yiu; Y. Liu,"SCSE, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: shangqingliu666@gmail.com); Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong Hong Kong (e-mail: gcyydxf@gmail.com); School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore 639798 (e-mail: ecnuchensen@gmail.com); Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: lynie8@cse.cuhk.edu); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: yangliu@ntu.edu.sg)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Commit messages record code changes (e.g., feature modifications and bug repairs) in natural language, and are useful for program comprehension. Due to the frequent updates of software and time cost, developers are generally unmotivated to write commit messages for code changes. Therefore, automating the message writing process is necessitated. Previous studies on commit message generation have been benefited from generation models or retrieval models, but the code structure of changed code, i.e., AST, which can be important for capturing code semantics, has not been explicitly involved. Moreover, although generation models have the advantages of synthesizing commit messages for new code changes, they are not easy to bridge the semantic gap between code and natural languages which could be mitigated by retrieval models. In this paper, we propose a novel commit message generation model, named ATOM, which explicitly incorporates the abstract syntax tree for representing code changes and integrates both retrieved and generated messages through hybrid ranking. Specifically, the hybrid ranking module can prioritize the most accurate message from both retrieved and generated messages regarding one code change. We evaluate the proposed model ATOM on our dataset crawled from 56 popular Java repositories. Experimental results demonstrate that ATOM increases the state-of-the-art models by 30.72% in terms of BLEU-4 (an accuracy measure that is widely used to evaluate text generation systems). Qualitative analysis also demonstrates the effectiveness of ATOM in generating accurate code commit messages.",1939-3520,,10.1109/TSE.2020.3038681,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261989,Commit Message Generation;Code Changes;Abstract Syntax Tree,Syntactics;Semantics;Atomic measurements;Hybrid power systems;Benchmark testing;Writing;Java,,,,,,,,17 Nov 2020,,,IEEE,IEEE Early Access Articles
1717,356,How Gender-biased Tools Shape Newcomer Experiences in OSS Projects,S. H. Padala; C. J. Mendez; L. F. Dias; I. Steinmacher; Z. Steine Hanson; C. Hilderbrand; A. Horvath; C. Hill; L. D. Simpson; M. Burnett; M. Gerosa; A. Sarma,"School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: padalah@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: mendezc@oregonstate.edu); Computer Science, University of Sao Paulo, Sao Paulo, Sao Paulo Brazil (e-mail: fronchettiemail@gmail.com); School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, Arizona United States 860110001 (e-mail: Igor.Steinmacher@nau.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: steinehz@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States 97330 (e-mail: minic@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: horvatha@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: hillchar@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: simpsolo@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon United States 97331 (e-mail: burnett@eecs.oregonstate.edu); School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, Arizona United States (e-mail: Marco.Gerosa@nau.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States 97331 (e-mail: anita.sarma@oregonstate.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Previous research has revealed that newcomer women are disproportionately affected by gender-biased barriers in open source software (OSS) projects. However, this research has focused mainly on social/cultural factors, neglecting the software tools and infrastructure. To shed light on how OSS tools and infrastructure might factor into OSS barriers to entry, we conducted two studies: (1) a field study with five teams of software professionals, who worked through five use cases to analyze the tools and infrastructure used in their OSS projects; and (2) a diary study with 22 newcomers (9 women and 13 men) to investigate whether the barriers matched the ones identified by the software professionals. The field study produced a bleak result: software professionals found gender biases in 73% of all the newcomer barriers they identified. Further, the diary study confirmed these results: Women newcomers encountered gender biases in 63% of barriers they faced. Fortunately, many the kinds of barriers and biases revealed in these studies could potentially be ameliorated through changes to the OSS software environments and tool.",1939-3520,,10.1109/TSE.2020.2984173,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9055190,,Tools;Problem-solving;Open source software;Documentation;Cultural differences;Productivity,,,,3.0,,,,2 Apr 2020,,,IEEE,IEEE Early Access Articles
1718,357,Reinforcement Learning for Test Case Prioritization,M. Bagherzadeh; N. Kahani; L. Briand,"School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: mojtaba@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario, Canada, (e-mail: kahani@cs.queensu.ca); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg, Luxembourg, 2721 (e-mail: lionel.briand@uni.lu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Continuous Integration (CI) significantly reduces integration problems, speeds up development time, and shortens release time. However, it also introduces new challenges for quality assurance activities, including regression testing, which is the focus of this work. Though various approaches for test case prioritization have shown to be very promising in the context of regression testing, specific techniques must be designed to deal with the dynamic nature and timing constraints of CI. Recently, Reinforcement Learning (RL) has shown great potential in various challenging scenarios that require continuous adaptation, such as game playing, real-time ads bidding, and recommender systems. Inspired by this line of work and building on initial efforts in supporting test case prioritization with RL techniques, we perform here a comprehensive investigation of RL-based test case prioritization in a CI context. To this end, taking test case prioritization as a ranking problem, we model the sequential interactions between the CI environment and a test case prioritization agent as an RL problem, using three alternative ranking models. We then rely on carefully selected and tailored state-of-the-art RL techniques to automatically and continuously learn a test case prioritization strategy, whose objective is to be as close as possible to the optimal one. Our extensive experimental analysis shows that the best RL solutions provide a significant accuracy improvement over previous RL-based work, with prioritization strategies getting close to being optimal, thus paving the way for using RL to prioritize test cases in a CI context.",1939-3520,,10.1109/TSE.2021.3070549,Canadian Network for Research and Innovation in Machining Technology Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394799,Continuous Integration;CI;Reinforcement Learning;Test Prioritization,Testing;History;Training;Reinforcement learning;Software systems;Adaptation models;Software algorithms,,,,,,,IEEE,2 Apr 2021,,,IEEE,IEEE Early Access Articles
1719,358,Forecasting Architectural Decay from Evolutionary History,J. Garcia; E. Kouroshfar; N. Ghorbani; S. Malek,"Institute for Software Research, Univ. of California, Irvine, Irvine, California, United States, (e-mail: joshug4@uci.edu); Not Applicable, Amazon.com Inc, 110288 Seattle, Washington, United States, (e-mail: ekouroshfar@gmail.com); Institute for Software Research, Univ. of California, Irvine, Irvine, California, United States, (e-mail: negargh@uci.edu); Informatics, University of California Irvine, Irvine, California, United States, 92697 (e-mail: malek@uci.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"As a software system evolves, its architecture tends to decay, leading to the occurrence of architectural elements that become resistant to maintenance or prone to defects. To address this problem, engineers can significantly benefit from determining which architectural elements will decay before that decay actually occurs. Forecasting decay allows engineers to take steps to prevent decay, such as focusing maintenance resources on the architectural elements most likely to decay. To that end, we construct novel models that predict the quality of an architectural element by utilizing multiple architectural views (both structural and semantic) and architectural metrics as features for prediction. We conduct an empirical study using our prediction models on 38 versions of five systems. Our findings show that we can predict low architectural quality, i.e., architectural decay, with high performanceeven for cases of decay that suddenly occur in an architectural module. We further report the factors that best predict architectural quality.",1939-3520,,10.1109/TSE.2021.3060068,Division of Computer and Network Systems; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357984,software architecture;prediction model;architectural smell;architectural decay,Measurement;Predictive models;Software;Computer architecture;Maintenance engineering;Semantics;Software systems,,,,,,,IEEE,18 Feb 2021,,,IEEE,IEEE Early Access Articles
1720,359,POMP++: Facilitating Postmortem Program Diagnosis with Value-set Analysis,D. Mu; Y. Du; J. Xu; J. Xu; X. Xing; B. Mao; P. Liu,"Computer Science and Technology, Nanjing University, 12581 Nanjing, jiangsu China (e-mail: dzm77@ist.psu.edu); Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: duyunlan@smail.nju.edu.cn); Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: jianhao_xu@smail.nju.edu.cn); Department of Computer Science, Stevens Institute of Technology Charles V Schaefer Jr School of Engineering and Science, 200807 Hoboken, New Jersey United States (e-mail: jxu69@stevens.edu); College of Information Sciences and Technology, Pennsylvania State University, 8082 University Park, Pennsylvania United States (e-mail: xxing@ist.psu.edu); Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: maobing@nju.edu.cn); College of IST, Penn State, University Park, Pennsylvania United States 16802 (e-mail: pliu@ist.psu.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"With the emergence of hardware-assisted processor tracing, execution traces can be logged with lower runtime overhead and integrated into the core dump. In comparison with an ordinary core dump, such a new post-crash artifact provides software developers and security analysts with more clues to a program crash. However, existing works only rely on the resolved runtime information, which leads to limitation in data flow recovery within long execution traces. In this work, we propose POMP++, an automated tool to facilitate the analysis of post-crash artifacts. More specifically, POMP++ introduces a reverse execution mechanism to construct the data flow that a program followed prior to its crash. Furthermore, POMP++ utilizes Value-set Analysis, which helps to verify memory alias relation, to improve the ability of data flow recovery. With the restored data flow, POMP++ then performs backward taint analysis and highlights program statements that actually contribute to the crash. We have implemented POMP++ for Linux system on x86-32 platform, and tested it against various crashes resulting from 31 distinct real-world security vulnerabilities. The evaluation shows that, our work can pinpoint the root causes in 29 cases, increase the amount of recovered memory addresses by 12% and reduce the execution time by 60% compared with existing reverse execution. In short, POMP++ can accurately and efficiently pinpoint program statements that truly contribute to the crashes, making failure diagnosis significantly convenient.",1939-3520,,10.1109/TSE.2019.2939528,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823943,Postmortem Program Diagnosis;Failure Diagnosis;Reverse Execution;Value-set Analysis,Computer crashes;Software;Security;Core dumps;Registers;Runtime;Tools,,,,,,,,4 Sep 2019,,,IEEE,IEEE Early Access Articles
1721,360,Holistic Combination of Structural and Textual Code Information for Context based API Recommendation,C. Chen; X. Peng; Z. Xing; J. Sun; X. Wang; Y. Zhao; W. Zhao,"School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, 201203 (e-mail: 15110240004@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: pengxin@fudan.edu.cn); Research School of Computer Science, Australian National University, 2219 ACTON, Australian Capital Territory, Australia, 2601 (e-mail: zhenchang.xing@anu.edu.au); SIS, Singapore Management University, 54756 Singapore, Singapore, Singapore, 689867 (e-mail: junsun@smu.edu.sg); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: 18212010029@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: 17212010079@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: wyzhao@fudan.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Context based API recommendation is an important way to help developers find the needed APIs effectively and efficiently. For effective API recommendation, we need not only a joint view of both structural and textual code information, but also a holistic view of correlated API usage in control and data flow graph as a whole. Unfortunately, existing API recommendation methods exploit structural or textual code information separately. In this work, we propose a novel API recommendation approach called APIRec-CST (API Recommendation by Combining Structural and Textual code information). APIRec-CST is a deep learning model that combines the API usage with the text information in the source code based on an API Context Graph Network and a Code Token Network that simultaneously learn structural and textual features for API recommendation. We apply APIRec-CST to train a model for JDK library based on 1,914 open-source Java projects and evaluate the accuracy and MRR (Mean Reciprocal Rank) of API recommendation with another 6 open-source projects. The results show that our approach achieves respectively a top-1, top-5, top-10 accuracy and MRR of 60.3%, 81.5%, 87.7% and 69.4%, and significantly outperforms an existing graph-based statistical approach and a tree-based deep learning approach for API recommendation. A further analysis shows that textual code information makes sense and improves the accuracy and MRR. The sensitivity analysis shows that the top-k accuracy and MRR of APIRec-CST are insensitive to the number of APIs to be recommended in a hole. We also conduct a user study in which two groups of students are asked to finish 6 programming tasks with or without our APIRec-CST plugin. The results show that APIRec-CST can help the students to finish the tasks faster and more accurately and the feedback on the usability is overwhelmingly positive.",1939-3520,,10.1109/TSE.2021.3074309,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9409670,API;recommendation;deep learning;data flow;control flow;text,Semantics;Deep learning;Data models;Context modeling;Computational modeling;Task analysis;Token networks,,,,,,,IEEE,20 Apr 2021,,,IEEE,IEEE Early Access Articles
1722,361,On the costs and profit of software defect prediction,S. Herbold,"Institute for Computer Science, Georg-August-Universität Güttingen, Güttingen, Lower Saxony Germany 37077 (e-mail: herbold@cs.uni-goettingen.de)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Defect prediction can be a powerful tool to guide the use of quality assurance resources. However, while lots of research covered methods for defect prediction as well as methodological aspects of defect prediction research, the actual cost saving potential of defect prediction is still unclear. Within this article, we close this research gap and formulate a cost model for software defect prediction. We derive mathematically provable boundary conditions that must be fulfilled by defect prediction models such that there is a positive profit when the defect prediction model is used. Our cost model includes aspects like the costs for quality assurance, the costs of post-release defects, the possibility that quality assurance fails to reveal predicted defects, and the relationship between software artifacts and defects. We initialize the cost model using different assumptions, perform experiments to show trends of the behavior of costs on real projects. Our results show that the unrealistic assumption that defects only affect a single software artifact, which is a standard practice in the defect prediction literature, leads to inaccurate cost estimations. Moreover, the results indicate that thresholds for machine learning metrics are also not suited to define success criteria for software defect prediction.",1939-3520,,10.1109/TSE.2019.2957794,Deutsche Forschungsgemeinschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924628,Defect prediction;costs;return on investment,Predictive models;Software;Quality assurance;Measurement;Mathematical model;Machine learning;Computational modeling,,,,1.0,,,,5 Dec 2019,,,IEEE,IEEE Early Access Articles
1723,362,An Empirical Study of Type-Related Defects in Python Projects,F. Khan; B. Chen; D. Varro; S. Mcintosh,"Electrical and Computer Engineering, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: faizan.khan3@mail.mcgill.ca); Electrical and Computer Engineering, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: boqi.chen@mail.mcgill.ca); Dept. of Measurement and Information Systems, Budapest University of Technology and Economics, Budapest, N/A, Hungary, H-1117 (e-mail: daniel.varro@mcgill.ca); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, N2L 3G1 (e-mail: shane.mcintosh@uwaterloo.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"In recent years, Python has experienced explosive growth in adoption, particularly among open source projects. While Python's dynamically-typed nature provides developers with powerful programming abstractions, that same dynamic type system allows for type-related defects to accumulate in code bases. To aid in the early detection of type-related defects, type annotations were introduced into the Python ecosystem (i.e., PEP-484) and static type checkers like mypy have appeared on the market. While applying a type checker like mypy can in theory help to catch type-related defects before they impact users, little is known about the real impact of adopting a type checker to reveal defects in Python projects. In this paper, we study the extent to which Python projects benefit from such type checking features. For this purpose, we mine the issue tracking and version control repositories of 210 Python projects on GitHub. Inspired by the work of Gao et al. on type-related defects in JavaScript, we add type annotations to test whether detects an error that would have helped developers to avoid real defects. We observe that 15% of the defects could have been prevented by mypy. Moreover, we find that there is no significant difference between the experience level of developers committing type-related defects and the experience of developers committing defects that are not type-related. In addition, a manual analysis of the anti-patterns that most commonly lead to type-checking faults reveals that the redefinition of Python references, dynamic attribute initialization and incorrectly handled Null objects are the most common causes of type-related faults. Since our study is conducted on fixed public defects that have gone through code reviews and multiple test cycles, these results represent a lower bound on the benefits of adopting a type checker. Therefore, we recommend incorporating a static type checker like mypy into the development workflow, as not only will it prevent type-related defects but also mitigate certain anti-patterns during development.",1939-3520,,10.1109/TSE.2021.3082068,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9436020,Software Defects;Static Type Checkers;Dynamic Type Systems;Empirical Study,Python;Annotations;Tools;Task analysis;Ecosystems;Software systems;Software measurement,,,,,,,IEEE,19 May 2021,,,IEEE,IEEE Early Access Articles
1724,363,Can Clean New Code reduce Technical Debt Density,G. Digkas; A. N. Chatzigeorgiou; A. Ampatzoglou; P. C. Avgeriou,"Institute of Mathematics and Computer Science, University of Groningen, 3647 Groningen, Groningen, Netherlands, (e-mail: g.digkas@rug.nl); Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece, 54006 (e-mail: achat@uom.gr); Applied Informatics, University of Macedonia, 68999 Thessaloniki, Thessaloniki, Greece, 56728 (e-mail: apostolos.ampatzoglou@gmail.com); Department of Mathematics and Computing Science, University of Groningen, Groningen, groningen, Netherlands, 9747 AG (e-mail: paris.avgeriou@gmail.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"While technical debt grows in absolute numbers as software systems evolve over time, the density of technical debt (technical debt divided by lines of code) is reduced in some cases. This can be explained by either the application of refactorings or the development of new artifacts with limited Technical Debt. In this paper we explore the second explanation, by investigating the relation between the amount of Technical Debt in new code and the evolution of Technical Debt in the system. To this end, we compare the Technical Debt Density of new code with existing code, and we investigate which of the three major types of code changes (additions, deletions and modifications) is primarily responsible for changes in the evolution of Technical Debt density. Furthermore, we study whether there is a relation between code quality practices and the “cleanness” of new code. To obtain the required data, we have performed a large-scale case study on twenty-seven open-source software projects by the Apache Software Foundation, analyzing 66,661 classes and 56,890 commits. The results suggest that writing “clean” (or at least “cleaner”) new code can be an efficient strategy for reducing Technical Debt Density, and thus preventing software decay over time. The findings also suggest that projects adopting an explicit policy for quality improvement, e.g. through discussions on code quality in board meetings, are associated with a higher frequency of cleaner new code commits. Therefore, we champion the establishment of processes that monitor the density of Technical Debt of new code to control the accumulation of Technical Debt in a software system.",1939-3520,,10.1109/TSE.2020.3032557,H2020 European Institute of Innovation and Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234106,technical debt;refactoring;clean code;case study,Open source software;Writing;Logic gates;Market research;Monitoring;Maintenance engineering,,,,1.0,,,,20 Oct 2020,,,IEEE,IEEE Early Access Articles
1725,364,Formal Verification of Masking Countermeasures for Arithmetic Programs,G. Pengfei; X. Hongyi; P. Sun; J. Zhang; F. Song; T. Chen,"School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: gaopf@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: xiehy@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: sunpu@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: zhangjun@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China 201210 (e-mail: songfu@shanghaitech.edu.cn); Department of Computer Science and Information Systems, Birkbeck University of London, 4894 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: taolue.chen@surrey.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Cryptographic algorithms are widely used to protect data privacy in many aspects of daily lives. Unfortunately, programs implementing cryptographic algorithms may be vulnerable to practical power side-channel attacks, which may infer private data via statistical analysis. To thwart these attacks, several masking schemes have been proposed, giving rise to effective countermeasures for reducing the statistical correlation between private data and power consumptions. However, programs that rely on secure masking schemes are not secure a priori. Indeed, designing effective masking programs is a labor intensive and error-prone task. Although some techniques have been proposed for formally verifying masking countermeasures and for quantifying masking strength, they are currently limited to Boolean programs and suffer from low accuracy. In this work, we propose an approach for formally verifying masking countermeasures of arithmetic programs. Our approach is more accurate for arithmetic programs and more scalable for Boolean programs comparing to the existing approaches. It is essentially a synergistic integration of type inference and model-counting based methods, armed with domain specific heuristics. The type inference system allows a fast deduction of leakage-freeness of most intermediate computations, the model-counting based methods accounts for completeness, namely, to eliminate spurious flaws, and the heuristics facilitate both type inference and model-counting based reasoning, which improve scalability and efficiency in practice. In case that the program does contain leakage, we provide a method to quantify its masking strength. A distuiguished feature of our type sytem lies in its support of compositonal reasoning when verifying programs with procedure calls, so the need of inlining procedures can be significantly reduced. We have implemented our methods in a verification tool QMVERIF which has been extensively evaluated on cryptographic benchmarks including full AES, DES and MAC-Keccak. The experimental results demonstrate the effectiveness and efficiency of our approach, especially for compositional reasoning. In particular, our tool is able to automatically prove leakage-freeness of arithmetic programs for which only manual proofs exist so far; it is also significantly faster than the state-of-the-art tools: EasyCrypt on common arithmetic programs, QMSINFER, SC Sniffer and maskVerif on Boolean programs.",1939-3520,,10.1109/TSE.2020.3008852,Engineering and Physical Sciences Research Council; Natural Science Foundation of Guangdong Province; Guangdong Science and Technology Department; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139284,,Cryptography;Tools;Computational modeling;Software algorithms;Power demand;Cognition,,,,1.0,,,,13 Jul 2020,,,IEEE,IEEE Early Access Articles
1726,365,"Simpler Hyperparameter Optimization for Software Analytics: Why, How, When",A. Agrawal; X. Yang; R. Agrawal; R. Yedida; X. Shen; T. Menzies,"Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: aagrawa8@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: xyang37@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: ragrawa3@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: ryedida@ncsu.edu); Computer Science, North Carolina State University, Raleigh, North Carolina, United States, 27695 (e-mail: xshen5@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"How can we make software analytics simpler and faster One method is to match the complexity of analysis to the intrinsic complexity of the data being explored. For example, hyperparameter optimizers find the control settings for data miners that improve the predictions generated via software analytics. Sometimes, very fast hyperparameter optimization can be achieved by ‘`DODGE-ing’'; i.e. simply steering way from settings that lead to similar conclusions. But when is it wise to use that simple approach and when must we use more complex (and much slower) optimizers To answer this, we applied hyperparameter optimization to 120 SE data sets that explored bad smell detection, predicting Github issue close time, bug report analysis, defect prediction, and dozens of other non-SE problems. We find that the simple DODGE works best for data sets with low ‘`intrinsic dimensionality’' (around 3) and very poorly for higher-dimensional data (around 8). Nearly all the SE data seen here was intrinsically low-dimensional, indicating that DODGE is applicable for many SE analytics tasks.",1939-3520,,10.1109/TSE.2021.3073242,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405415,software analytics;hyperparameter optimization;defect prediction;bad smell detection;issue close time;bug reports F,Software;Optimization;Clustering algorithms;Text mining;Measurement;Computer bugs;Task analysis,,,,,,,IEEE,15 Apr 2021,,,IEEE,IEEE Early Access Articles
1727,366,Authors’ Reply to “Comments on ‘Researcher Bias: The Use of Machine Learning in Software Defect Prediction’”,M. Shepperd; T. Hall; D. Bowes,"Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; University of Hertfordshire, Hatfield, United Kingdom",IEEE Transactions on Software Engineering,11 Nov 2018,2018,44,11,1129,1131,"In 2014 we published a meta-analysis of software defect prediction studies [1] . This suggested that the most important factor in determining results was Research Group, i.e., who conducts the experiment is more important than the classifier algorithms being investigated. A recent re-analysis [2] sought to argue that the effect is less strong than originally claimed since there is a relationship between Research Group and Dataset. In this response we show (i) the re-analysis is based on a small (21 percent) subset of our original data, (ii) using the same re-analysis approach with a larger subset shows that Research Group is more important than type of Classifier and (iii) however the data are analysed there is compelling evidence that who conducts the research has an effect on the results. This means that the problem of researcher bias remains. Addressing it should be seen as a matter of priority amongst those of us who conduct and publish experiments comparing the performance of competing software defect prediction systems.",1939-3520,,10.1109/TSE.2017.2731308,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990255,Software quality assurance;defect prediction;researcher bias,Software;NASA;Measurement;Analysis of variance;Data models;Predictive models;Analytical models,learning (artificial intelligence);pattern classification;program diagnostics,researcher bias;machine learning;meta-analysis;classifier algorithms;re-analysis approach;software defect prediction systems;research group,,1.0,,5.0,,24 Jul 2017,,,IEEE,IEEE Journals
1728,367,Why Do Software Developers Use Static Analysis Tools? A User-Centered Study of Developer Needs and Motivations,L. Nguyen Quang Do; J. Wright; K. Ali,"Computer Science, Universitat Paderborn, 26578 Paderborn, North Rhine-Westphalia Germany (e-mail: lisa.nqd@gmail.com); Department of Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada (e-mail: james.wright@ualberta.ca); Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada (e-mail: karim.ali@ualberta.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"As increasingly complex software is developed every day, a growing number of companies use static analysis tools to reason about program properties ranging from simple coding style rules to more advanced software bugs, to multi-tier security vulnerabilities. While increasingly complex analyses are created, developer support must also be updated to ensure that the tools are used to their best potential. Past research in the usability of static analysis tools has primarily focused on usability issues encountered by software developers, and the causes of those issues in analysis tools. In this article, we adopt a more user-centered approach, and aim at understanding why software developers use analysis tools, which decisions they make when using those tools, what they look for when making those decisions, and the motivation behind their strategies. This approach allows us to derive new tool requirements that closely support software developers (e.g., systems for recommending warnings to fix that take developer knowledge into account), and also open novel avenues for further static-analysis research such as collaborative user interfaces for analysis warnings.",1939-3520,,10.1109/TSE.2020.3004525,Natural Sciences and Engineering Research Council of Canada; Bundesministerium fr Bildung und Forschung; Deutsche Forschungsgemeinschaft; Canadian Institute for Advanced Research; NRW Research Training Group on Human Centered Systems Security; Heinz Nixdorf Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9124719,Program analysis;Development tools;Integrated environments;Graphical environments;Usability,Tools;Static analysis;Usability;Industries;Computer bugs;Security,,,,,,,,24 Jun 2020,,,IEEE,IEEE Early Access Articles
1729,368,A Survey on the Adoption of Patterns for Engineering Software for the Cloud,T. Sousa; H. S. Ferreira; F. F. Correia,"Department of Engineering and Informatics, University of Porto Faculty of Engineering, 112048 Porto, Porto, Portugal, 4200-465 (e-mail: tiagoboldt@gmail.com); Engenharia Informtica, University of Porto Faculty of Engineering, 112048 Porto, Porto, Portugal, 4200-465 (e-mail: hugo.sereno@fe.up.pt); Department of Informatics Engineering, University of Porto Faculty of Engineering, 112048 Porto, Porto, Portugal, 4200-465 (e-mail: filipe.correia@fe.up.pt)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"This work takes as a starting point a collection of patterns for engineering software for the cloud and tries to find how they are regarded and adopted by professionals. Existing literature assessed the adoption of cloud computing with a focus on business and technological aspects and fall short in grasping a holistic view of the underlying approaches. Other authors delved into how independent patterns can be discovered (mined) and verified, but do not provide insights on their adoption. We investigate (1) their relevance for professional software developers, (2) the extent to which product and company characteristics influence their adoption, and (3) how adopting some patterns might correlate with the likelihood of adopting others. For this purpose, we surveyed practitioners using an online questionnaire (n = 102). Among other findings, we conclude that most companies use these patterns, with the overwhelming majority (97%) using at least one. We observe that the mean pattern adoption tends to increase as companies mature, namely when varying the product operation complexity, active monthly users, and company size. Finally, we search for correlations in the adoption of specific patterns and attempt to infer causation among them, further hinting on how some practices are dependent or influence the adoption of others. We conclude that there are patterns of practices adoption that best correlates with a specific company and product characteristics, as well as relationships between the patterns that were not covered by the original pattern language and which might deserve further investigation.",1939-3520,,10.1109/TSE.2021.3052177,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325940,cloud-computing;patterns;pattern adoption;software architecture;microservices;community survey,Cloud computing;Software;Companies;Monitoring;Industries;Containers;Scalability,,,,,,,IEEE,15 Jan 2021,,,IEEE,IEEE Early Access Articles
1730,369,What's Wrong With My Benchmark Results? Studying Bad Practices in JMH Benchmarks,D. E. Damasceno Costa; C. Bezemer; P. Leitner; A. Andrzejak,"Institute of Computer Science, Ruprecht Karls Universitat Heidelberg, 9144 Heidelberg, Baden Wurttemberg Germany 69120 (e-mail: diego.costa@informatik.uni-heidelberg.de); School of Computing, Queen\'s University, Kingston, Ontario Canada (e-mail: bezemer@cs.queensu.ca); Computer Science and Engineering, Chalmers | University of Gothenburg, Gothenburg, Gothenburg Sweden (e-mail: philipp.leitner@chalmers.se); Institute of Computer Science, University of Heidelberg, Heidelberg, Baden-Wurttemberg Germany 69120 (e-mail: artur.andrzejak@informatik.uni-heidelberg.de)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Microbenchmarking frameworks, such as Java's Microbenchmark Harness (JMH), allow developers to write fine-grained performance test suites at the method or statement level. However, due to the complexities of the Java Virtual Machine, developers often struggle with writing expressive JMH benchmarks which accurately represent the performance of such methods or statements. In this paper, we empirically study bad practices of JMH benchmarks. We present a tool that leverages static analysis to identify 5 bad JMH practices. Our empirical study of 123 open source Java-based systems shows that each of these 5 bad practices are prevalent in open source software. Further, we conduct several experiments to quantify the impact of each bad practice in multiple case studies, and find that bad practices often significantly impact the benchmark results. To validate our experimental results, we constructed patches that fix the identified bad practices for six of the studied open source projects, of which five were merged into the main branch of the project. In this paper, we show that developers struggle with accurate Java microbenchmarking, and provide several recommendations to developers of microbenchmarking frameworks on how to improve future versions of their framework.",1939-3520,,10.1109/TSE.2019.2925345,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747433,Performance testing;microbenchmarking;JMH;bad practices;static analysis,Benchmark testing;Java;Optimization;Tools;Writing;Static analysis,,,,,,,,27 Jun 2019,,,IEEE,IEEE Early Access Articles
1731,370,Automated Test Case Generation as a Many-Objective Optimisation Problem with Dynamic Selection of the Targets,A. Panichella; F. M. Kifetew; P. Tonella,"SnT, University of Luxembourg, Luxembourg, Esch-sur-Alzette, Luxembourg; Fondazione Bruno Kessler, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy",IEEE Transactions on Software Engineering,12 Feb 2018,2018,44,2,122,158,"The test case generation is intrinsically a multi-objective problem, since the goal is covering multiple test targets (e.g., branches). Existing search-based approaches either consider one target at a time or aggregate all targets into a single fitness function (whole-suite approach). Multi and many-objective optimisation algorithms (MOAs) have never been applied to this problem, because existing algorithms do not scale to the number of coverage objectives that are typically found in real-world software. In addition, the final goal for MOAs is to find alternative trade-off solutions in the objective space, while in test generation the interesting solutions are only those test cases covering one or more uncovered targets. In this paper, we present Dynamic Many-Objective Sorting Algorithm (DynaMOSA), a novel many-objective solver specifically designed to address the test case generation problem in the context of coverage testing. DynaMOSA extends our previous many-objective technique Many-Objective Sorting Algorithm (MOSA) with dynamic selection of the coverage targets based on the control dependency hierarchy. Such extension makes the approach more effective and efficient in case of limited search budget. We carried out an empirical study on 346 Java classes using three coverage criteria (i.e., statement, branch, and strong mutation coverage) to assess the performance of DynaMOSA with respect to the whole-suite approach (WS), its archive-based variant (WSA) and MOSA. The results show that DynaMOSA outperforms WSA in 28 percent of the classes for branch coverage (+8 percent more coverage on average) and in 27 percent of the classes for mutation coverage (+11 percent more killed mutants on average). It outperforms WS in 51 percent of the classes for statement coverage, leading to +11 percent more coverage on average. Moreover, DynaMOSA outperforms its predecessor MOSA for all the three coverage criteria in 19 percent of the classes with +8 percent more code coverage on average.",1939-3520,,10.1109/TSE.2017.2663435,Fonds National de la Recherche Luxembourg; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840029,Evolutionary testing;many-objective optimisation;automatic test case generation,Heuristic algorithms;Optimization;Testing;Software algorithms;Algorithm design and analysis;Sorting;Genetic algorithms,optimisation;program testing;search problems;sorting,dynamic target selection;Many-Objective Sorting Algorithm;search-based approaches;test sequence;test input data;branch coverage;many-objective solver;MOAs;many-objective optimisation algorithms;multiple test targets;multiobjective problem;Many-Objective optimisation problem;automated test case generation;DynaMOSA,,29.0,,59.0,,2 Feb 2017,,,IEEE,IEEE Journals
1732,371,Grammar Based Directed Testing of Machine Learning Systems,S. S. Udeshi; S. Chattopadhyay,"ISTD, Singapore University of Technology and Design, 233793 Singapore, Singapore Singapore (e-mail: sakshi_udeshi@mymail.sutd.edu.sg); ISTD, Singapore University of Technology and Design, 233793 Singapore, Singapore Singapore 487372 (e-mail: sudipta_chattopadhyay@sutd.edu.sg)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our OGMA approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. OGMA leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our OGMA approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare OGMA with a random test generation approach and observe that OGMA is more effective than such random test generation by up to 489%.",1939-3520,,10.1109/TSE.2019.2953066,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907363,,Machine learning;Grammar;Robustness;Systematics;Test pattern generators;Natural language processing,,,,1.0,,,,20 Nov 2019,,,IEEE,IEEE Early Access Articles
1733,372,Clustering Crowdsourced Test Reports of Mobile Applications Using Image Understanding,D. Liu; Y. Feng; X. Zhang; J. Jones; Z. Chen,"School of Computer Science and Technology, Soochow University, 12582 Suzhou, Jiangsu China (e-mail: dliu0721@stu.suda.edu.cn); Department of Informatics, University of California Irvine, 8788 Irvine, California United States (e-mail: yang.feng@uci.edu); School of Computer Science and Technology, Soochow University, 12582 Suzhou, Jiangsu China (e-mail: xfzhang@suda.edu.cn); Informatics, University of California, Irvine, Irvine, California United States 92697-3440 (e-mail: jajones@uci.edu); State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, Jiangsu China 210093 (e-mail: zychen@nju.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Crowdsourced testing has been widely used to improve software quality as it can detect various bugs and simulate real usage scenarios. Crowdsourced workers perform tasks on crowdsourcing platforms and present their experiences as test reports, which naturally generates an overwhelming number of test reports. Therefore, inspecting these reports becomes a time-consuming yet inevitable task. In recent years, many text-based prioritization and clustering techniques have been proposed to address this challenge. However, in mobile testing, test reports often consist of only short test descriptions but rich screenshots. Compared with the uncertainty of textual information, well-defined screenshots can often adequately express the mobile application's activity views. In this paper, by employing image-understanding techniques, we propose an approach for clustering crowdsourced test reports of mobile applications based on both textual and image features to assist the inspection procedure. We employ Spatial Pyramid Matching (SPM) to measure the similarity of the screenshots and use the natural-language-processing techniques to compute the textual distance of test reports. To validate our approach, we conducted an experiment on 6 industrial crowdsourced projects that contain more than 1600 test reports and 1400 screenshots. The results show that our approach is capable of outperforming the baselines by up to 37% regarding the APFD metric. Further, we analyze the parameter sensitivity of our approach and discuss the settings for different application scenarios.",1939-3520,,10.1109/TSE.2020.3017514,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174926,Crowdsourced Testing;Mobile Testing;Test Report Processing,Testing;Task analysis;Mobile applications;Computer bugs;Software;Mars;Mobile handsets,,,,,,,,24 Aug 2020,,,IEEE,IEEE Early Access Articles
1734,373,Detecting Software Security Vulnerabilities via Requirements Dependency Analysis,W. Wang; F. Dumont; N. Niu; G. Horton,"Electrical Engineering and Computer Science, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: wang2wt@mail.uc.edu); EECS, University of Cincinnati, Cincinnati, Ohio United States (e-mail: dumontfn@mail.uc.edu); EECS, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: nan.niu@uc.edu); UC Libraries, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: glen.horton@uc.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Cyber attacks targeting software applications have a tremendous impact on our daily life. For example, attackers have utilized vulnerabilities of web applications to steal and gain unauthorized use of sensitive data stored in these systems. Previous studies indicate that security testing is highly precise, and therefore is widely applied to validate individual security requirements. However, dependencies between security requirements may cause additional vulnerabilities. Manual dependency detection faces scalability challenges, e.g., a previous study shows that the pairwise dependency analysis of 40 requirements would take around 12 hours. In this paper, we present a novel approach which integrates the interdependency among high-level security requirements, such as those documented in policies, regulations, and standards. We then use automated requirements tracing methods to identify product-level security requirements and their dependencies. Our manual analysis of HIPAA and FIPS 200 leads to the identification of five types of high-level security requirements dependencies, which further inform the automated tracing methods and guide the designs of system-level security tests. Experimental results on five projects in healthcare and education domains show the significant recall improvements at 81%. Our case study on a deployed production system uncovers four previously unknown vulnerabilities by using the detected requirements dependencies as test paths, demonstrating our approach's value in connecting requirements engineering with security testing.",1939-3520,,10.1109/TSE.2020.3030745,Division of Computing and Communication Foundations; Ohio Cyber Range; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222252,Security requirements;requirements dependency management;requirements traceability;vulnerability discovery,Security;Software;Testing;Manuals;Static analysis;Regulation;Scalability,,,,,,,,13 Oct 2020,,,IEEE,IEEE Early Access Articles
1735,374,Conditional Quantitative Program Analysis,M. Gerrard; M. Borges; M. Dwyer; A. Fillieri,"Computer Science, University of Virginia, 2358 Charlottesville, Virginia United States (e-mail: mjg6v@virginia.edu); Computing, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: m.borges@imperial.ac.uk); Computer Science, University of Virginia, Charlottesville, Virginia United States (e-mail: matthewbdwyer@virginia.edu); Department of Computing, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: a.filieri@imperial.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Standards for certifying safety-critical systems have evolved to permit the inclusion of evidence generated by program analysis and verification techniques. The past decade has witnessed the development of several program analyses that are capable of computing guarantees on bounds for the probability of failure. This paper develops a novel program analysis framework, CQA, that combines evidence from different underlying analyses to compute bounds on failure probability. It reports on an evaluation of different CQA-enabled analyses and implementations of state-of-the-art quantitative analyses to evaluate their relative strengths and weaknesses. To conduct this evaluation, we filter an existing verification benchmark to reflect certification evidence generation challenges. Our evaluation across the resulting set of 136 C programs, totaling more than 385k SLOC, each with a probability of failure below $10^4$, demonstrates how CQA extends the state-of-the-art. The CQA infrastructure, including tools, subjects, and generated data is publicly available at bitbucket.org/mgerrard/cqa.",1939-3520,,10.1109/TSE.2020.3016778,National Science Foundation; DARPA ARCOS; U.S. Army Research Office; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9167482,program analysis;model counting;symbolic execution;conditional analysis;software reliability;software certification,Safety;Standards;Static analysis;Software;Reliability;Benchmark testing,,,,,,,,14 Aug 2020,,,IEEE,IEEE Early Access Articles
1736,375,Pegasus: Performance Engineering for Software Applications Targeting HPC Systems,P. Pinto; J. Bispo; J. Cardoso; J. G. Barbosa; D. Gadioli; G. Palermo; J. Martinovic; M. Golasowski; K. Slaninova; R. Cmar; C. SILVANO,"FEUP, Universidade do Porto Faculdade de Engenharia, 112048 Porto, Porto Portugal 4200-465 (e-mail: p.pinto@fe.up.pt); FEUP, Universidade do Porto Faculdade de Engenharia, 112048 Porto, Porto Portugal (e-mail: jbispo@fe.up.pt); FEUP, Universidade do Porto Faculdade de Engenharia, 112048 Porto, Porto Portugal (e-mail: jmpc@fe.up.pt); Engenharia Informtica, Faculdade de Engenharia da Universidade do Porto, Porto, Porto Portugal 4200-465 (e-mail: jbarbosa@fe.up.pt); Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Milano Italy (e-mail: davide.gadioli@polimi.it); Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Milano Italy (e-mail: gianluca.palermo@polimi.it); IT4Innovation, Vysoka Skola Banska-Technicka Univerzita Ostrava, 48278 Ostrava, Moravia Czech Republic (e-mail: jan.martinovic@vsb.cz); IT4Innovations, Vysoka Skola Banska-Technicka Univerzita Ostrava, 48278 Ostrava, Moravia Czech Republic (e-mail: martin.golasowski@vsb.cz); IT4Innovation, Vysoka Skola Banska-Technicka Univerzita Ostrava, 48278 Ostrava, Moravia Czech Republic (e-mail: katerina.slaninova@vsb.cz); -, Sygic, Bratislava, Bratislava Slovakia (e-mail: rcmar@sygic.com); Dipartimento di Elettronica, Informazion, Politecnico di Milano, MILANO, MILANO Italy (e-mail: cristina.silvano@polimi.it)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Developing and optimizing software applications for high performance and energy efficiency is a very challenging task, even when considering a single target machine. For instance, optimizing for multicore-based computing systems requires in-depth knowledge about programming languages, application programming interfaces, compilers, performance tuning tools, and computer architecture and organization. Many of the tasks of performance engineering methodologies require manual efforts and the use of different tools not always part of an integrated toolchain. This paper presents Pegasus, a performance engineering approach supported by a framework that consists of a source-to-source compiler, controlled and guided by strategies programmed in a Domain-Specific Language, and an autotuner. Pegasus is a holistic and versatile approach spanning various decision layers composing the software stack, and exploiting the system capabilities and workloads effectively through the use of runtime autotuning. The Pegasus approach helps developers by automating tasks regarding the efficient implementation of software applications in multicore computing systems. These tasks focus on application analysis, profiling, code transformations, and the integration of runtime autotuning. Pegasus allows developers to program their strategies or to automatically apply existing strategies to software applications in order to ensure the compliance of non-functional requirements, such as performance and energy efficiency. We show how to apply Pegasus and demonstrate its applicability and effectiveness in a complex case study, which includes tasks from a smart navigation system.",1939-3520,,10.1109/TSE.2020.3001257,H2020 Future and Emerging Technologies; Fundao para a Cincia e a Tecnologia; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113456,,Task analysis;Software;Tools;Runtime;Tuning;Power demand;Libraries,,,,,,,,10 Jun 2020,,,IEEE,IEEE Early Access Articles
1737,376,Corrections to “Detecting Bugs by Discovering Expectations and Their Violations”,P. Bian; B. Liang; Y. Zhang; C. Yang; W. Shi; Y. Cai,"School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,8 Jan 2020,2020,46,1,113,113,"In the above named work (ibid., vol. 45, no. 10, pp. 984???1001, Oct. 2019), the corresponding author should have been listed as Bin Liang. The footnote information is corrected here.",1939-3520,,10.1109/TSE.2019.2958750,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952832,,Computer bugs;Computer science;Software;Libraries,,,,,,1.0,IEEE,8 Jan 2020,,,IEEE,IEEE Journals
1738,377,GUI-Guided Test Script Repair for Mobile Apps,M. Pan; T. Xu; Y. Pei; Z. Li; T. Zhang; X. Li,"State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: mxp@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: dz1633014@smail.nju.edu.cn); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: maximilian.pei@gmail.com); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: mg1733033@smail.nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: ztluck@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: lxd@nju.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Graphical User Interface (GUI) testing is widely used to test mobile apps. As mobile apps are frequently updated and need repeated testing, to reduce the test cost, their test cases are often coded as scripts to enable automated execution using test harnesses/tools. When those mobile apps evolve, many of the test scripts, however, may become broken due to changes made to the app GUIs. While it is desirable that the broken scripts get repaired, doing it manually can be preventively expensive if the number of tests need repairing is large. We propose in this paper a novel approach named METER to repairing broken GUI test scripts automatically when mobile apps evolve. METER leverages computer vision techniques to infer GUI changes between two versions of a mobile app and uses the inferred changes to guide the repair of GUI test scripts. Since METER only relies on screenshots to repair GUI tests, it is applicable to apps targeting open or closed source mobile platforms. In experiments conducted on 22 Android apps and 6 iOS apps, repairs produced by METER helped preserve 63.7% and 38.8% of all the test actions broken by the GUI changes, respectively.",1939-3520,,10.1109/TSE.2020.3007664,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136844,,Meters;Graphical user interfaces;Mobile applications;Maintenance engineering;Testing;Tools;Computer vision,,,,,,,,8 Jul 2020,,,IEEE,IEEE Early Access Articles
1739,378,Control and Discovery of Environment Behaviour,M. Keegan; V. A. Braberman; N. D'Ippolito; N. Piterman; S. Uchitel,"FCEN, Universidad de Buenos Aires, 28196 Buenos Aires, Buenos Aires, Argentina, (e-mail: maukeegan1@gmail.com); FCEN, Universidad de Buenos Aires, CONICET-ICC, 28196 Buenos Aires, Buenos Aires, Argentina, (e-mail: victor.braberman@gmail.com); FCEN, Universidad de Buenos Aires, CONICET-ICC, Buenos Aires, Argentina, (e-mail: ndippolito@dc.uba.ar); University of Gothenburg and the University of Leicester (e-mail: nir.piterman@gmail.com); FCEN, Universidad de Buenos Aires, CONICET-ICC and also with Imperial College London 28196 Buenos Aires, CABA, Argentina, (e-mail: suchitel@dc.uba.ar)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"An important ability of self-adaptive systems is to be able to autonomously understand the environment in which they operate and use this knowledge to control the environment behaviour in such a way that system goals are achieved. How can this be achieved when the environment is unknown? Two phase solutions that require a full discovery of environment behaviour before computing a strategy that can guarantee the goals or report the non-existence of such a strategy (i.e., unrealisability) are impractical as the environment may exhibit adversarial behaviour to avoid full discovery. In this paper we formalise a control and discovery problem for reactive system environments. In our approach a strategy must be produced that will, for every environment, guarantee that unrealisablity will be correctly concluded or system goals will be achieved by controlling the environment behaviour. We present a solution applicable to environments characterisable as labeled transition systems (LTS). We use modal transition systems (MTS) to represent partial knowledge of environment behaviour, and rely on MTS controller synthesis to make exploration decisions. Each decision either contributes more knowledge about the environment's behaviour or contributes to achieving the system goals. We present an implementation restricted to GR(1) goals and show its viability.",1939-3520,,10.1109/TSE.2020.3044532,Fondo para la Investigación Científica y Tecnológica; Secretaria de Ciencia y Tecnica Universidad de Buenos Aires; H2020 European Research Council; Consejo Nacional de Investigaciones Científicas y Técnicas; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293408,Adaptive systems;reactive systems;discrete event controllers;environment control and discovery,Protocols;Learning automata;Testing;Sensors;Process control;Knowledge engineering;Internet,,,,,,,IEEE,14 Dec 2020,,,IEEE,IEEE Early Access Articles
1740,379,Heuristic and Neural Network based Prediction of Project-Specific API Member Access,L. Jiang; H. Liu; H. Jiang; L. Zhang; H. Mei,"School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: jianglin17@bit.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, Beijing, Beijing China 100081 (e-mail: liuhui08@bit.edu.cn); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: hejiang@ieee.org); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: meihong@bit.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Code completion is to predict the rest of a statement a developer is typing. Although advanced code completion approaches have greatly improved the accuracy of code completion in modern IDEs, it remains challenging to predict project-specific API method invocations or field accesses because little knowledge about such elements could be learned in advance. To this end, in this paper we propose an accurate approach called HeeNAMA to suggesting the next project-specific API member access. HeeNAMA focuses on a specific but common case of code completion: suggesting the following member access whenever a project-specific API instance is followed by a dot on the right hand side of an assignment. By focusing on such a specific case, HeeNAMA can take full advantages of the context of the code completion, including the type of the left hand side expression of the assignment, the identifier on the left hand side, the type of the base instance, and similar assignments typed in before. All such information together enables highly accurate code completion. Given an incomplete assignment, HeeNAMA generates the initial candidate set according to the type of the base instance, and excludes those candidates that are not type compatible with the left hand side of the assignment. If the enclosing project contains assignments highly similar to the incomplete assignment, it makes suggestions based on such assignments. Otherwise, it selects the one from the initial candidate set that has the greatest lexical similarity with the left hand side of the assignment. Finally, it employs a neural network to filter out risky predictions, which guarantees high precision. Evaluation results on open-source applications suggest that compared to the state-of-the-art approaches and the state-of-the-practice tools HeeNAMA improves precision and recall by 70.68% and 25.23%, relatively.",1939-3520,,10.1109/TSE.2020.3017794,National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171589,Code Completion;Non-API;Deep Learning;Heuristic;LSTM,Hidden Markov models;Neural networks;Computational modeling;Open source software;Java;Data mining;Tools,,,,,,,,19 Aug 2020,,,IEEE,IEEE Early Access Articles
1741,380,"Redundancy, Context, and Preference: An Empirical Study of Duplicate Pull Requests in OSS Projects",Z. Li; Y. Yu; M. Zhou; T. Wang; G. Yin; L. Lan; H. Wang,"College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: lizhixing15@nudt.edu.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: yuyue@nudt.edu.cn); School of Electronics Engineering and Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: zhmh@pku.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: taowang2005@nudt.edu.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: yingang@nudt.edu.cn); AI Team, Peng Cheng Laboratory, Shenzhen, Guangdong China (e-mail: long.lan@pcl.ac.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: hmwang@nudt.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"OSS projects are being developed by globally distributed contributors, who often collaborate through the pull-based model today. While this model lowers the barrier to entry for OSS developers by synthesizing, automating and optimizing the contribution process, coordination among an increasing number of contributors remains as a challenge due to the asynchronous and self-organized nature of distributed development. In particular, duplicate contributions, where multiple different contributors unintentionally submit duplicate pull requests to achieve the same goal, are an elusive problem that may waste effort in automated testing, code review and software maintenance. While the issue of duplicate pull requests has been highlighted, to what extent duplicate pull requests affect the development in OSS communities has not been well investigated. In this paper, we conduct a mixed-approach study to bridge this gap. Based on a comprehensive dataset constructed from 26 popular GitHub projects, we obtain the following findings: (a) Duplicate pull requests result in redundant human and computing resources, exerting a significant impact on the contribution and evaluation process. (b) Contributors' inappropriate working patterns and the drawbacks of their collaborating environment might result in duplicate pull requests. (c) Compared to non-duplicate pull requests, duplicate pull requests have significantly different features, e.g., being submitted by inexperienced contributors, being fixing bugs, touching cold files, and solving tracked issues. (d) Integrators choosing between duplicate pull requests prefer to accept those with early submission time, accurate and high-quality implementation, broad coverage, test code, high maturity, deep discussion, and active response. Finally, actionable suggestions and implications are proposed for OSS practitioners.",1939-3520,,10.1109/TSE.2020.3018726,National Grand RD Plan; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174755,Duplicate pull requests;pull-based development model;distributed collaboration;social coding,Collaboration;Computer bugs;Tools;Cloning;Synchronization;Testing;Encoding,,,,,,,,24 Aug 2020,,,IEEE,IEEE Early Access Articles
1742,381,Smart Greybox Fuzzing,V. Pham; M. Boehme; A. E. Santosa; A. R. Caciulescu; A. Roychoudhury,"Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: thuanpv.nus@gmail.com); Faculty of Information Technology, Monash University, Clayton, Victoria Australia (e-mail: marcel.boehme@monash.edu); School of Information Technology, The University of Sydney, The University of Sydney, New South Wales Australia 2006 (e-mail: santosa_1999@yahoo.com); CS, Universitatea Politehnica din Bucuresti, 195061 Singapore, Bucharest Singapore (e-mail: alexandru.razvan.c@gmail.com); Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: abhik@comp.nus.edu.sg)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Coverage-based greybox fuzzing (CGF) is one of the most successful approaches for automated vulnerability detection. Given a seed file (as a sequence of bits), a CGF randomly flips, deletes or copies some bits to generate new files. CGF iteratively constructs (and fuzzes) a seed corpus by retaining those generated files which enhance coverage. However, random bitflips are unlikely to produce valid files (or valid chunks in files), for applications processing complex file formats. In this work, we introduce smart greybox fuzzing (SGF) which leverages a high-level structural representation of the seed file to generate new files. We define innovative mutation operators that work on the virtual file structure rather than on the bit level which allows SGF to explore completely new input domains while maintaining file validity. We introduce a novel validity-based power schedule that enables SGF to spend more time generating files that are more likely to pass the parsing stage of the program, which can expose vulnerabilities much deeper in the processing logic. Our evaluation demonstrates the effectiveness of SGF. On several libraries that parse complex chunk-based files, our tool AFLSMART achieves substantially more branch coverage (up to 87% improvement), and exposes more vulnerabilities than baseline AFL. Our tool AFLSMART has discovered 42 zero-day vulnerabilities in widely-used, well-tested tools and libraries; so far 17 CVEs were assigned.",1939-3520,,10.1109/TSE.2019.2941681,National Research Foundation Singapore; Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839290,vulnerability detection;smart fuzzing;automated testing;file format;grammar;input structure,Fuzzing;Computer bugs;Libraries;Tools;Dictionaries;Open area test sites;Schedules,,,,9.0,,,,16 Sep 2019,,,IEEE,IEEE Early Access Articles
1743,382,Probabilistic Preference Planning Problem for Markov Decision Processes,M. Li; A. Turrini; E. M. Hahn; Z. She; L. Zhang,"School of Mathematics and System Sciences, Beihang University, 12633 Beijing, Beijing China (e-mail: meilun.li@buaa.edu.cn); State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing China (e-mail: turrini@ios.ac.cn); The School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, 1596 Belfast, Belfast United Kingdom of Great Britain and Northern Ireland (e-mail: e.hahn@qub.ac.uk); School of Mathematics and Systems Science, Beihang University, 12633 Beijing, Beijing China (e-mail: zhikun.she@buaa.edu.cn); State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing China (e-mail: zhanglj@ios.ac.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The classical planning problem aims to find a sequence of permitted actions leading a system to a designed state, i.e., to achieve the system's task. However, in many realistic cases we also have requirements on how to complete the task, indicating that some behaviors and situations are more preferred than others. In this paper, we present the probabilistic preference-based planning problem (P4) for Markov decision processes, where the preferences are defined based on an enriched probabilistic LTL-style logic. We first recall P4Solver, an SMT-based planner computing the preferred plan by reducing the problem to a quadratic programming one previously developed to solve P4. To improve computational efficiency and scalability, we then introduce a new encoding of the probabilistic preference-based planning problem as a multi-objective model checking one, and propose the corresponding planner P4SolverMO. We illustrate the efficacy of both planners on some selected case studies to show that the model checking-based algorithm is considerably more efficient than the quadratic-programming-based one.",1939-3520,,10.1109/TSE.2020.3024215,National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; Guangdong Science and Technology Department; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197644,Planning;Markov Decision Processes;preference;quadratic programming;multi-objective model checking,Planning;Robots;Markov processes;Probabilistic logic;Model checking;Task analysis;Software,,,,,,,,15 Sep 2020,,,IEEE,IEEE Early Access Articles
1744,383,An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples,M. Verdi; A. Sami; J. Akhondali; F. Khomh; G. Uddin; A. Karami Motlagh,"CSE and IT, Shiraz University, 37551 Shiraz, Fars Iran (the Islamic Republic of) (e-mail: m.verdi@shirazu.ac.ir); CSE and IT, Shiraz University, Shiraz, Fars Iran, Islamic Republic of 7134851154 (e-mail: sami@shirazu.ac.ir); CSE and IT, Shiraz University, 37551 Shiraz, Fars Iran (the Islamic Republic of) (e-mail: jafar.akhondali@yahoo.com); Electrical and Computer Engineering, Polytechnique Montral, 5596 Montreal, Quebec Canada (e-mail: foutse.khomh@polymtl.ca); Schulich School of Engineering, Electrical and Computer Engineering, University of Calgary, Calgary, Quebec Canada (e-mail: giasu@cs.mcgill.ca); CSE and IT, Shiraz University, 37551 Shiraz, Fars Iran (the Islamic Republic of) (e-mail: alireza.karami.m@gmail.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software developers share programming solutions in Q&A sites like Stack Overflow, Stack Exchange, Android forum, and so on. The reuse of crowd-sourced code snippets can facilitate rapid prototyping. However, recent research shows that the shared code snippets may be of low quality and can even contain vulnerabilities. This paper aims to understand the nature and the prevalence of security vulnerabilities in crowd-sourced code examples. To achieve this goal, we investigate security vulnerabilities in the C++ code snippets shared on Stack Overflow over a period of 10 years. In collaborative sessions involving multiple human coders, we manually assessed each code snippet for security vulnerabilities following CWE (Common Weakness Enumeration) guidelines. From the 72,483 reviewed code snippets used in at least one project hosted on GitHub, we found a total of 99 vulnerable code snippets categorized into31 types. Many of the investigated code snippets are still not corrected on Stack Overflow. The 99 vulnerable code snippets found in Stack Overflow were reused in a total of 2859 GitHub projects. To help improve the quality of code snippets shared on Stack Overflow,we developed a browser extension that allows Stack Overflow users to be notified for vulnerabilities in code snippets when they see them on the platform.",1939-3520,,10.1109/TSE.2020.3023664,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195034,Stack Overflow;Software Security;C++;SOTorrent;Vulnerability Migration;GitHub;Vulnerability Evolution,Security;C++ languages;Androids;Humanoid robots;Tools;Open source software,,,,,,,,11 Sep 2020,,,IEEE,IEEE Early Access Articles
1745,384,Integrating an Ensemble Surrogate Model's Estimation into Test data Generation,B. Sun; D. Gong; T. Tian; X. Yao,"School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: baicaisun@gmail.com); School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: dwgong@vip.163.com); School of Computer Science and Technology, Shandong Jianzhu University, 105835 Jinan, Shandong China (e-mail: tian_tiantian@126.com); School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: yaoxj@cumt.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"For the path coverage testing of a Message-Passing Interface (MPI) program, test data generation based on an evolutionary optimization algorithm (EOA) has been widely known. However, during the use of the above technique, it is necessary to evaluate the fitness of each evolutionary individual by executing the program, which is generally computationally expensive. In order to reduce the computational cost, this paper proposes a method of integrating an ensemble surrogate model's estimation into the process of generating test data. The proposed method first produces a number of test inputs using an EOA, and forms a training set together with their real fitness. Then, this paper trains an ensemble surrogate model (ESM) based on the training set, which is employed to estimate the fitness of each individual. Finally, a small number of individuals with good estimations are selected to further execute the program, so as to have their real fitness for the subsequent evolution. This paper applies the proposed method to seven benchmark MPI programs, which is compared with several state-of-the-art approaches. The experimental results show that the proposed method can generate test data with significantly low computational cost.",1939-3520,,10.1109/TSE.2020.3019406,National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177064,MPI program;path coverage testing;evolutionary optimization algorithm;ensemble surrogate model;test data,Testing;Estimation;Data models;Optimization;Computational efficiency;Training;Sun,,,,,,,,25 Aug 2020,,,IEEE,IEEE Early Access Articles
1746,385,The Relevance of Classic Fuzz Testing: Have We Solved This One?,B. Miller; M. Zhang; E. Heymann,"Computer Sciences, University of Wisconsin-Madison, 5228 Madison, Wisconsin, United States, 53706 (e-mail: bart@cs.wisc.edu); Computer Sciences, University of Wisconsin-Madison, 5228 Madison, Wisconsin, United States, (e-mail: mzhang464@wisc.edu); Computer Sciences, University of Wisconsin-Madison, 5228 Madison, Wisconsin, United States, (e-mail: elisa@cs.wisc.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"As fuzz testing has passed its 30th anniversary, and in the face of the incredible progress in fuzz testing techniques and tools, the question arises if the classic, basic fuzz technique is still useful and applicable? In that tradition, we have updated the basic fuzz tools and testing scripts and applied them to a large collection of Unix utilities on Linux, FreeBSD, and MacOS. As before, our failure criteria was whether the program crashed or hung. We found that 9 crash or hang out of 74 utilities on Linux, 15 out of 78 utilities on FreeBSD, and 12 out of 76 utilities on MacOS. A total of 24 different utilities failed across the three platforms. We note that these failure rates are somewhat higher than our in previous 1995, 2000, and 2006 studies of the reliability of command line utilities. In the basic fuzz tradition, we debugged each failed utility and categorized the causes the failures. Classic categories of failures, such as pointer and array errors and not checking return codes, were still broadly present in the current results. In addition, we found a couple of new categories of failures appearing. We present examples of these failures to illustrate the programming practices that allowed them to happen. As a side note, we tested the limited number of utilities available in a modern programming language (Rust) and found them to be of no better reliability than the standard ones.",1939-3520,,10.1109/TSE.2020.3047766,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309406,Testing and Debugging;Testing tools,Tools;Testing;Software;Operating systems;Fuzzing;Software reliability;Linux,,,,,,,IEEE,28 Dec 2020,,,IEEE,IEEE Early Access Articles
1747,386,Codee: A Tensor Embedding Scheme for Binary Code Search,J. Yang; C. Fu; X. -Y. Liu; H. Yin; P. Zhou,"School of Cyber Science and Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei, China, (e-mail: d201780841@hust.edu.cn); School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wu Han, Hu Bei Province, China, (e-mail: fucai@hust.edu.cn); Electrical Engineering, Columbia University, 5798 New York, New York, United States, (e-mail: xl2427@columbia.edu); Computer Science and Engineering, University of California Riverside Bourns College of Engineering, 117248 Riverside, California, United States, 92521-0144 (e-mail: heng@cs.ucr.edu); School of Electronic Information and Communications, Huazhong University of Science and Technology, wuhan, Hubei, China, (e-mail: panzhou@hust.edu.cn)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Given a target binary function, the binary code search retrieves top-K similar functions in the repository, and similar functions represent that they are compiled from the same source codes. Searching binary code is particularly challenging due to large variations of compiler tool-chains and options and CPU architectures, as well as thousands of binary codes. Furthermore, there are some pivotal issues in current binary code search schemes, including inaccurate text-based or token-based analysis, slow graph matching, or complex deep learning processes. In this paper, we present an unsupervised tensor embedding scheme, \textbf{Codee}, to carry out code search efficiently and accurately at the binary function level. First, we use an NLP-based neural network to generate the semantic-aware token embedding. Second, we propose an efficient basic block embedding generation algorithm based on the network representation learning model. We learn both the semantic information of instructions and the control flow structural information to generate the basic block embedding. Then we use all basic block embeddings in a function to obtain a variable-length function feature vector. Third, we build a tensor to generate function embeddings based on the tensor singular value decomposition, which compresses the variable-length vectors into short fixed-length vectors to facilitate efficient search afterward. We further propose a dynamic tensor compression algorithm to incrementally update the function embedding database. Finally, we use the local sensitive hash method to find the top-K similar matching functions in the repository. Compared with state-of-the-art cross-optimization-level code search schemes, such as Asm2Vec and DeepBinDiff, our scheme achieves higher average search accuracy, shorter feature vectors, and faster feature generation performance using four datasets, OpenSSL, Coreutils, libgmp and libcurl. Compared with other cross-platform and cross-optimization-level code search schemes, such as Gemini, Safe, the average recall of our method also outperforms others.",1939-3520,,10.1109/TSE.2021.3056139,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345532,Function feature extraction;tensor embedding;code search;tSVD,Binary codes;Tensors;Feature extraction;Semantics;Search problems;Task analysis;Data models,,,,,,,IEEE,2 Feb 2021,,,IEEE,IEEE Early Access Articles
1748,387,Formal Equivalence Checking for Mobile Malware Detection and Family Classification,F. Mercaldo; A. Santone,"IIT, Istituto di Informatica e Telematica Consiglio Nazionale delle Ricerche, 215080 Pisa, Italy, Italy, 56124 (e-mail: francesco.mercaldo@iit.cnr.it); Dipartimento di Bioscienze e Territorio, Universit del Molise, Pesche, Isernia, Italy, (e-mail: antonella.santone@unimol.it)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Several techniques to overcome the weaknesses of the current signature based detection approaches adopted by free and commercial anti-malware were proposed by industrial and research communities. These techniques are mainly supervised machine learning based, requiring optimal class balance to generate good predictive models. In this paper, we propose a method to infer mobile application maliciousness by detecting the belonging family, exploiting formal equivalence checking. We introduce a set of heuristics to reduce the number of mobile application comparisons and we define a metric reflecting the application maliciousness. Real-world experiments on 35 Android malware families (ranging from 2010 to 2018) confirm the effectiveness of the proposed method in mobile malware detection and family identification.",1939-3520,,10.1109/TSE.2021.3067061,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381654,Equivalence Checking;Formal Methods;Android;Malware;Security,Malware;Operating systems;Machine learning;Training;Tools;Smart phones;Automata,,,,,,,IEEE,18 Mar 2021,,,IEEE,IEEE Early Access Articles
1749,388,Generating Unit Tests for Documentation,M. Nassif; A. Hernandez; A. Sridharan; M. P. Robillard,"School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: mnassif@cs.mcgill.ca); School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: alexa.hernandez@mail.mcgill.ca); School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: ashvitha.sridharan@mail.mcgill.ca); School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: martin@cs.mcgill.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Software projects capture redundant information in various kinds of artifacts, as specifications from the source code are also tested and documented. Such redundancy provides an opportunity to reduce development effort by supporting the joint generation of different types of artifact. We introduce a tool-supported technique, called DScribe, that allows developers to combine unit tests and documentation templates, and to invoke those templates to generate documentation and unit tests. DScribe supports the detection and replacement of outdated documentation, and the use of templates can encourage extensive test suites with a consistent style. Our evaluation of 835 specifications revealed that 85% were not tested or correctly documented, and DScribe could be used to automatically generate 97% of the tests and documentation. An additional study revealed that tests generated by DScribe are more focused and readable than those written by human testers or generated by state-of-the-art automated techniques.",1939-3520,,10.1109/TSE.2021.3087087,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447988,Code documentation;Testing;Testing tools;Test generation;Maintainability;Specification management,Documentation;Testing;Skeleton;Java;Software;Redundancy;Libraries,,,,,,,IEEE,7 Jun 2021,,,IEEE,IEEE Early Access Articles
1750,389,CODIT: Code Editing with Tree-Based Neural Models,S. Chakraborty; Y. Ding; M. Allamanis; B. Ray,"Computer Science, Columbia University, 5798 New York, New York United States (e-mail: saikatc@cs.columbia.edu); Computer Science, Columbia University, 5798 New York, New York United States (e-mail: yangruibo.ding@columbia.edu); Machine Intelligence and Perception, Microsoft Research Ltd, 10438 Cambridge, Cambridgeshire United Kingdom of Great Britain and Northern Ireland CB1 2FB (e-mail: miallama@microsoft.com); Computer Science, Columbia University, New York, New York United States (e-mail: rayb@cs.columbia.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The way developers edit day-to-day code tends to be repetitive, often using existing code elements. Many researchers have tried to automate repetitive code changes by learning from specific change templates which are applied to limited scope. The advancement of deep neural networks and the availability of vast open-source evolutionary data opens up the possibility of automatically learning those templates from the wild. However, deep neural network based modeling for code changes and code in general introduces some specific problems that needs specific attention from research community. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art neural network models without adapting the methods to the source code domain yields sub-optimal results. To this end, we propose a novel tree-based neural network system to model source code changes and learn code change patterns from the wild. Specifically, we propose a tree-based neural machine translation model to learn the probability distribution of changes in code. We realize our model with a change suggestion engine, CODIT, and train the model with more than 30k real-world changes and evaluate it on 6k patches. Our evaluation shows the effectiveness of CODIT in learning and suggesting patches. CODIT can also learn specific bug fix pattern from bug fixing patches and can fix 27 bugs out of 75 one line bugs in Defects4J.",1939-3520,,10.1109/TSE.2020.3020502,NSF CNS; NSF CCF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181462,,Computer bugs;Predictive models;Reactive power;Probability distribution;Syntactics;Neural networks;Adaptation models,,,,1.0,,,,31 Aug 2020,,,IEEE,IEEE Early Access Articles
1751,390,Eyes on Code: A Study on Developers Code Navigation Strategies,Z. Sharafi; I. Bertram; M. Flanagan; W. Weimer,"Computer Science and Engineering, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: zohrehsh@umich.edu); Computer Science and Engineering, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: ianbtr@umich.edu); Computer Science and Engineering, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: mflanag@umich.edu); Computer Science and Engineering, University of Michigan, Ann Arbor, Michigan United States (e-mail: weimerw@umich.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"What code navigation strategies do developers use and what mechanisms do they employ to find relevant information Do their strategies evolve over the course of longer tasks Answers to these questions can provide insight to educators and software tool designers to support a wide variety of programmers as they tackle increasingly-complex software systems. However, little research to date has measured developers' code navigation strategies in ecologically-valid settings or analyzed how strategies progressed throughout a maintenance task. We propose a novel experimental design that more accurately represents the software maintenance process in terms of software complexity and IDE interactions. Using this framework, we conduct an eye-tracking study (n=36) of realistic bug-fixing tasks, dynamically and empirically identifying relevant code areas. We introduce a three-phase model to characterize developers' navigation behavior supported by statistical variations in eye movements over time. We also propose quantifiable notion of ``thrashing'' with the code as a navigation activity. We find that thrashing is associated with lower effectiveness. Our results confirm that the relevance of various code elements changes over time, and that our proposed three-phase model is capable of capturing these significant changes. We discuss our findings and their implications for tool designers, educators, and the research community.",1939-3520,,10.1109/TSE.2020.3032064,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229106,Code navigation;Eye tracking;Human factors;Software maintenance,Navigation;Task analysis;Computer bugs;Tools;Maintenance engineering;Software;Switches,,,,,,,,19 Oct 2020,,,IEEE,IEEE Early Access Articles
1752,391,Deprecation of packages and releases in software ecosystems: A case study on npm,F. R. Cogo; G. A. Oliva; A. E. Hassan,"Centre for Software Excellence, Huawei Technologies Co Ltd Canada, 538302 Kingston, Ontario, Canada, (e-mail: filipe.cogo@gmail.com); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 2N8 (e-mail: golivax@gmail.com); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Deprecation is used by developers to discourage the usage of certain features of a software system. Prior studies have focused on the deprecation of source code features, such as API methods. With the advent of software ecosystems, package managers started to allow developers to deprecate higher-level features, such as package releases. This study examines how the deprecation mechanism offered by the npm package manager is used to deprecate releases that are published in the ecosystem. We propose two research questions. In our first RQ, we examine how often package releases are deprecated in npm, ultimately revealing the importance of a deprecation mechanism to the package manager. We found that the proportion of packages that have at least one deprecated release is 3.7% and that 66% of such packages have deprecated all their releases, preventing client packages to migrate from a deprecated to a replacement release. Also, 31% of the partially deprecated packages do not have any replacement release. In addition, we investigate the content of the deprecation messages and identify five rationales behind the deprecation of releases, namely: withdrawal, supersession, defect, test, and incompatibility. In our second RQ, we examine how client packages adopt deprecated releases. We found that, at the time of our data collection, 27% of all client packages directly adopt at least one deprecated release and that 54% of all client packages transitively adopt at least one deprecated release. The direct adoption of deprecated releases is highly skewed, with the top 40 popular deprecated releases accounting for more than half of all deprecated releases adoption. As a discussion that derives from our findings, we highlight the rudimentary aspect of the deprecation mechanism employed by npm and recommend a set of improvements to this mechanism. These recommendations aim at supporting client packages in detecting deprecated releases, understanding their impact, and coping with them.",1939-3520,,10.1109/TSE.2021.3055123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351569,Software ecosystem;Deprecation;Release deprecation;Dependency;npm;JavaScript;Nodejs,Ecosystems;Software;Semantics;Computer bugs;Software systems;Organizations;Optimized production technology,,,,,,,IEEE,9 Feb 2021,,,IEEE,IEEE Early Access Articles
1753,392,Vuln4Real: A Methodology for Counting Actually Vulnerable Dependencies,I. Pashchenko; H. Plate; S. E. Ponta; A. Sabetta; F. Massacci,"Information Engineering and Computer Science, University of Trento, 19034 Trento, TN, Italy, (e-mail: ivan.pashchenko@unitn.it); SAP Security Research, SAP Labs France, Mougins, Alpes-Maritimes, France, 06250 (e-mail: henrik.plate@sap.com); SAP Security Research, SAP Labs France, MOUGINS CEDEX, PACA, France, (e-mail: serena.ponta@sap.com); SAP Security Research, SAP Labs France, Mougins, PACA, France, (e-mail: antonino.sabetta@sap.com); DISIl'Informazione, University of Trento, 19034 Trento, Trentino-Alto Adige, Italy, (e-mail: fabio.massacci@unitn.it)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Vulnerable dependencies are a known problem in today's free open-source software ecosystems because FOSS libraries are highly interconnected, and developers do not always update their dependencies. Our paper proposes Vuln4Real, the methodology for counting actually vulnerable dependencies, that addresses the over-inflation problem of academic and industrial approaches for reporting vulnerable dependencies in FOSS software, and therefore, caters to the needs of industrial practice for correct allocation of development and audit resources. To understand the industrial impact of a more precise methodology, we considered the 500 most popular FOSS Java libraries used by SAP in its own software. Our analysis included 25767 distinct library instances in Maven. We found that the proposed methodology has visible impacts on both ecosystem view and the individual library developer view of the situation of software dependencies: Vuln4Real significantly reduces the number of false alerts for deployed code (dependencies wrongly flagged as vulnerable), provides meaningful insights on the exposure to third-parties (and hence vulnerabilities) of a library, and automatically predicts when dependency maintenance starts lagging, so it may not receive updates for arising issues.",1939-3520,,10.1109/TSE.2020.3025443,H2020 LEIT Information and Communication Technologies; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201023,Vulnerable Dependency;Free Open Source Software;Mining Software Repositories,Libraries;Ecosystems;Security;Open source software;Java;Tools,,,,4.0,,,,21 Sep 2020,,,IEEE,IEEE Early Access Articles
1754,393,"Automatic Detection, Validation and Repair of Race Conditions in Interrupt-Driven Embedded Software",Y. WANG; F. Gao; L. Wang; T. Yu; J. Zhao; X. Li,"State Key Laboratory of Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: yuwang_cs@smail.nju.edu.cn); State Key Laboratory of Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: fjgao@smail.nju.edu.cn); State Key Laboratory of Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: lzwang@nju.edu.cn); Computer Science, University of Kentucky, Lexington, Kentucky United States 40506 (e-mail: tyu@cs.uky.edu); State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: zhaojh@nju.edu.cn); State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: lxd@nju.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Interrupt-driven programs are widely deployed in safety-critical embedded systems to perform hardware and resource dependent data operation tasks. The frequent use of interrupts in these systems can cause race conditions to occur due to interactions between application tasks and interrupt handlers (or two interrupt handlers). Numerous program analysis and testing techniques have been proposed to detect races in multithreaded programs. Little work, however, has addressed race condition problems related to hardware interrupts. In this paper, we present SDRacer, an automated framework that can detect, validate and repair race conditions in interrupt-driven embedded software. It uses a combination of static analysis and symbolic execution to generate input data for exercising the potential races. It then employs virtual platforms to dynamically validate these races by forcing the interrupts to occur at the potential racing points. Finally, it provides repair candidates to eliminate the detected races. We evaluate SDRacer on nine real-world embedded programs written in C language. The results show that SDRacer can precisely detect and successfully fix race conditions.",1939-3520,,10.1109/TSE.2020.2989171,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072666,Embedded Software;Interrupts;Race Condition;Software Testing;Repair Suggestion,Task analysis;Maintenance engineering;Hardware;Embedded systems;Concurrent computing;Testing;Embedded software,,,,1.0,,,,20 Apr 2020,,,IEEE,IEEE Early Access Articles
1755,394,A Systematical Study on Application Performance Management Libraries for Apps,Y. Tang; H. Wang; X. Zhan; X. Luo; Y. Zhou; H. Zhou; Q. Yan; Y. Sui; J. W. Keung,"Department of Computing, ShanghaiTech University, 387433 Shanghai, Pudong, China, (e-mail: csytang@comp.polyu.edu.hk); School of Computer Science, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China, (e-mail: haoyuwang@bupt.edu.cn); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: chichoxian@gmail.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: yajin_zhou@zju.edu.cn); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: sunmoonsky0001@gmail.com); Computer Science and Engineering, Michigan State University, 3078 East Lansing, Michigan, United States, (e-mail: qyan@msu.edu); Faculty of Engineering and Information Technology, UTS, Sydney, New South Wales, Australia, (e-mail: yulei.sui@uts.edu.au); Department of Computer Science, City University of Hong Kong, Kowloon, Kowloon Tong, Hong Kong, KLN (e-mail: Jacky.Keung@cityu.edu.hk)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Being able to automatically detect the performance issues in apps will significantly improve their quality as well as having a positive influence on user satisfaction. Although app developers have been exploiting application performance management (APM)tools to capture these potential performance issues, most of them do not fully understand the internals of these APM tools and the effect on their apps, such as security risks, etc. To fill this gap, in this paper, we conduct the first systematic study on APMs for apps by scrutinizing 25 widely-used APMs for Android apps and develop a framework named APMHunter for exploring the usage of APMs inAndroid apps. Using APMHunter, we conduct a large-scale empirical study on 500,000 Android apps to explore the usage patterns ofAPMs and discover the potential misuses of APMs. We obtain two major findings: 1) some APMs still employ deprecated permissions and approaches, which leads to APM malfunction as expected; 2) inappropriate APMs utilization will cause privacy leakages. Thus, our study suggests that both APM vendors and developers should design and use APMs scrupulously",1939-3520,,10.1109/TSE.2021.3077654,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424465,,,,,,,,,IEEE,5 May 2021,,,IEEE,IEEE Early Access Articles
1756,395,XPro: a Model to Explain the Limited Adoption and Implementation of Experimentation in Software Startups,J. Melegati; H. Edison; X. Wang,"Faculty of Computer Science, Free University of Bozen-Bolzano, 18956 Bolzano, BZ, Italy, (e-mail: jmelegatigoncalves@unibz.it); Business Information Systems, National University of Ireland Galway, 8799 Galway, Galway, Ireland, (e-mail: henry.edison@nuigalway.ie); Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Bozen-Bolzano, Italy, (e-mail: xiaofeng.wang@unibz.it)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software startups develop innovative, software-intensive products or services. Such innovativeness translates into uncertainty regarding a matching need for a product from potential customers, representing a possible determinant reason for startup failure. Research has shown that experimentation, an approach based on the use of experiments to guide several aspects of software development, could improve these companies' success rate by fostering the evaluation of assumptions about customers' needs before developing a full-fledged product. Nevertheless, software startups are not using experimentation as expected. In this study, we investigated the reasons behind such a mismatch between theory and practice. To achieve it, we performed a qualitative survey study of 106 failed software startups. We built the eXperimentation Progression model (XPro), demonstrating that the effective adoption and implementation of experimentation is a staged process: first, teams should be aware of experimentation, then they need to develop an intention to experiment, perform the experiments, analyze the results, and finally act based on the obtained learning. Based on the XPro model, we further identified 25 inhibitors that prevent a team from progressing along the stages properly. Our findings inform researchers of how to develop practices and techniques to improve experimentation adoption in software startups. Practitioners could learn various factors that could lead to their startup failure so they could take action to avoid them.",1939-3520,,10.1109/TSE.2020.3042610,Science Foundation Ireland; H2020 Marie Skłodowska-Curie Actions; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282188,software startups;experimentation;experiment-driven software development;startups,Software;Business;Technological innovation;Companies;Inhibitors;Uncertainty;Testing,,,,,,,IEEE,4 Dec 2020,,,IEEE,IEEE Early Access Articles
1757,396,Inferring Bug Signatures to Detect Real Bugs,H. Zhong; X. Wang; H. Mei,"Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China 200240 (e-mail: zhonghao@sjtu.edu.cn); Computer Science, University of Texas at San Antonio, San Antonio, Texas United States 78249 (e-mail: xiaoyin.wang@utsa.edu); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: meih@sjtu.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Due to the complexity and variety of programs, it is difficult to manually enumerate all bug patterns, especially for those related to API usages or project-specific rules. With the rapid development of software, many past bug fixes accumulate in software version histories. These bug fixes contain valuable samples of illegal coding practices. The gap between existing bug samples and well-defined bug patterns motivates our research. In the literature, researchers have explored techniques on learning bug signatures from existing bugs, and a bug signature is defined as a set of program elements explaining the cause/effect of the bug. However, due to various limitations, existing approaches cannot analyze past bug fixes in large scale, and to the best of our knowledge, no previously unknown bugs were ever reported by their work. The major challenge to automatically analyze past bug fixes is that, bug-inducing inputs are typically not recorded, and many bug fixes are partial programs that have compilation errors. As a result, for most bugs in the version history, it is infeasible to reproduce them for dynamic analysis or to feed buggy/fixed code directly into static analysis tools which mostly depend on compilable complete programs. In this paper, we propose an approach, called DEPA, that extracts bug signatures based on accurate partial-code analysis of bug fixes. With its support, we conduct the first large scale evaluation on 6,048 past bug fixes collected from four popular Apache projects. In particular, we use DEPA to infer bug signatures from these fixes, and to check the latest versions of the four projects with the inferred bug signatures. Our results show that DEPA detected 27 unique previously unknown bugs in total, including at least one bug from each project. These bugs are not detected by their developers nor other researchers. Among them, three of our reported bugs are already confirmed and repaired by their developers. Furthermore, our results show that the state-of-the-art tools detected only two of our found bugs, and our filtering techniques improve our precision from 25.5% to 51.5%.",1939-3520,,10.1109/TSE.2020.2996975,National Key RD Program of China; NSF SHF; HRD-C- SPECC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099449,bug fix;bug signature;partial code analysis,Computer bugs;Tools;Benchmark testing;Software;Manuals;History;Sun,,,,1.0,,,,25 May 2020,,,IEEE,IEEE Early Access Articles
1758,397,Engineering Impacts of Anonymous Author Code Review: A Field Experiment,E. Murphy-Hill; J. Dicker; M. M. Hodges; C. D. Egelman; C. Jaspan; L. Cheng; E. Kammer; B. Holtz; M. Jorde; A. Knight; C. Green,"Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: emersonm@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: jdicker@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: hodgesm@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: cegelman@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: ciera@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: lancheng@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: eakammer@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: benholtz@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: majorde@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: aknight@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: colling@google.com)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Code review is a powerful technique to ensure high quality software and spread knowledge of best coding practices between engineers. Unfortunately, code reviewers may have biases about authors of the code they are reviewing, which can lead to inequitable experiences and outcomes. In principle, anonymous author code review can reduce the impact of such biases by withholding an author's identity from a reviewer. In this paper, to understand the engineering effects of using author anonymous code review in a practical setting, we applied the technique to 5217 code reviews performed by 300 software engineers at Google. Our results suggest that during anonymous author code review, reviewers can frequently guess authors identities; that focus is reduced on reviewer-author power dynamics; and that the practice poses a barrier to offline, high-bandwidth conversations. Based on our findings, we recommend that those who choose to implement anonymous author code review should reveal the time zone of the author by default, have a break-the-glass option for revealing author identity, and reveal author identity directly after the review.",1939-3520,,10.1109/TSE.2021.3061527,Google; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361116,code review;unbiasing,Internet;Browsers;Tools;Software development management;Software;Particle measurements;Licenses,,,,,,,CCBY,23 Feb 2021,,,IEEE,IEEE Early Access Articles
1759,398,The Effect of Feature Characteristics on the Performance of Feature Location Techniques,A. Razzaq; A. Ventresque; R. Koschke; A. De Lucia; J. Buckley,"LERO, University of Limerick, 8808 Limerick, limerick, Ireland, V94 T9PX (e-mail: abdul.razzaq@lero.ie); School of Computer Science, University College Dublin, 8797 Dublin, Dublin, Ireland, (e-mail: anthony.ventresque@ucd.ie); Arbeitsgruppe Softwaretechnik, University of Bremen, 9168 Bremen, Bremen, Germany, (e-mail: koschke@uni-bremen.de); Dipartimento di Matematica e Informatica, Universit di Salerno, Fisciano, Salerno, Italy, 84084 (e-mail: adelucia@unisa.it); CSIS, University of Limerick, Limerick, Limerick, Ireland, none (e-mail: jim.buckley@ul.ie)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Feature Location (FL) is a core software maintenance activity that aims to locate observable functionalities in the source code. Given its key role in software change, a vast array of Feature Location Techniques (FLTs) have been proposed but, as more and more FLTs are introduced, the selection of an appropriate FLT is an increasingly difficult problem. One consideration is the characteristics of the features being sought. For example, in the code associated with the feature, programmers may have named identifiers consistently, and with meaningful naming conventions, or not, and this may impact on the suitability of different FLTs. The suggestion that such characteristics matter has implicit support in the literature: An analysis of existing FLT empirical studies reveals that the system under study can often have a stronger impact on FLT performance than differing FLTs themselves. To understand this interaction between feature characteristics and FLTs better, this paper proposes a suite of feature-characteristic metrics that are hypothesized to control FLTs performance, holistically across FLTs and impacting on individual FLTs to different degrees. To evaluate the suite, a controlled experiment is performed, using 878 features, to probe the relationship between the metrics and the performance of four FTL techniques: three commonly-used techniques and one state-of-the-art technique. The evaluation is performed using four commonly used evaluation measures and extended by employing 41 other established source-code metrics as extraneous variables. Results of the empirical evaluation suggest that the feature-metric suite presented impacts FLT performance holistically, and impacts different FLTs to different degrees. Thus, this paper moves towards the more standard selection of appropriate FLTs, with respect to the prominent feature characteristics in the software systems under study, and more rigorous consideration of the features selected to compare FLTs.",1939-3520,,10.1109/TSE.2021.3049735,Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316225,Feature Location;Bug Localization;Software Maintenance;Software Recommendation;Software Characteristics,Measurement;Feature extraction;Software maintenance;Task analysis;Software systems;Gold;Standards,,,,,,,IEEE,6 Jan 2021,,,IEEE,IEEE Early Access Articles
1760,399,Magnifier: A Compositional Analysis Approach for Autonomous Traffic Control,M. Bagheri; M. Sirjani; E. Khamespanah; C. Baier; A. Movaghar,"Computer Engineering, Sharif University of Technology, 68260 Tehran, Tehran, Iran (the Islamic Republic of), (e-mail: mbagheri@ce.sharif.edu); School of Innovation, Design and Engineering, Malardalen University, Vsters, Vsters, Sweden, (e-mail: marjan.sirjani@mdh.se); School of Electrical and Computer Engineering, University of Tehran, 48425 Tehran, Tehran, Iran (the Islamic Republic of), (e-mail: e.khamespanah@ut.ac.ir); Computer Science, Technische Universitt Dresden, Dresden, Saxony, Germany, (e-mail: Christel.Baier@tu-dresden.de); Computer Engineering, Sharif University of Technology, Tehran, Tehran, Iran (the Islamic Republic of), 14588-89694 (e-mail: movaghar@sharif.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Autonomous traffic control systems are large-scale systems with critical goals. To satisfy expected properties, these systems adapt themselves to possible changes in their environment and in the system itself. The adaptation may result in further changes propagated throughout the system. For each change and its consequent adaptation, assuring the satisfaction of properties of the system at runtime is important. A prominent approach to assure the correct behavior of these systems is verification at runtime, which has strict time and memory limitations. To tackle these limitations, we propose Magnifier, an iterative, incremental, and compositional verification approach that operates on an actor-based model where actors are grouped in components, and components are augmented with a coordinator. The Magnifier idea is zooming on the area (component) affected by a change and verifying the correctness of properties of interest of the system after adapting the component to the change. Magnifier checks if the change is propagating, and if that is the case, then it zooms out to perform adaptation on a larger area to contain the change. The process is iterative and incremental, and considers areas affected by the change one by one. In Magnifier, we use the Coordinated Adaptive Actor model (CoodAA) for traffic control systems. We present a formal semantics for CoodAA as a network of Timed Input-Output Automata (TIOAs), and prove the correctness of our compositional reasoning. We implement our approach in Ptolemy II. The results of our experiments indicate that the proposed approach improves the verification time and the memory consumption compared to the non-compositional approach.",1939-3520,,10.1109/TSE.2021.3069192,Self-Adaptive Actors: SEADA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388903,Self-adaptive Systems;Model@Runtime;Compositional Verification;Track-based Traffic Control Systems;Ptolemy II,Adaptation models;Control systems;Runtime;Tracking;Semantics;Iterative methods;Computer science,,,,,,,IEEE,29 Mar 2021,,,IEEE,IEEE Early Access Articles
1761,400,Quality of Automated Program Repair on Real-World Defects,M. Motwani; M. Soto; Y. Brun; R. Just; C. Le Goues,"College of Information and Computer Sciences, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: mmotwani@cs.umass.edu); School of Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: msotogon@cs.cmu.edu); College of Information and Computer Sciences, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: brun@cs.umass.edu); Paul G. Allen School of Computer Science & Engineering, University of Washington, 7284 Seattle, Washington United States (e-mail: rjust@cs.washington.edu); School of Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: clegoues@cs.cmu.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Automated program repair is a promising approach to reducing the costs of manual debugging and increasing software quality. However, recent studies have shown that automated program repair techniques can be prone to producing patches of low quality, overfitting to the set of tests provided to the repair technique, and failing to generalize to the intended specification. This paper rigorously explores this phenomenon on real-world Java programs, analyzing the effectiveness of four well-known repair techniques, GenProg, Par, SimFix, and TrpAutoRepair, on defects made by the projects' developers during their regular development process. We find that: (1) When applied to real-world Java code, automated program repair techniques produce patches for between 10.6% and 19.0% of the defects, which is less frequent than when applied to C code. (2) The produced patches often overfit to the provided test suite, with only between 13.8% and 46.1% of the patches passing an independent set of tests. (3) Test suite size has an extremely small but significant effect on the quality of the patches, with larger test suites producing higher-quality patches, though, surprisingly, higher-coverage test suites correlate with lower-quality patches. (4) The number of tests that a buggy program fails has a small but statistically significant positive effect on the quality of the produced patches. (5) Test suite provenance, whether the test suite is written by a human or automatically generated, has a significant effect on the quality of the patches, with developer-written tests typically producing higher-quality patches. And (6) the patches exhibit insufficient diversity to improve quality through some method of combining multiple patches. We develop JaRFly, an open-source framework for implementing techniques for automatic search-based improvement of Java programs. Our study uses JaRFly to faithfully reimplement GenProg and TrpAutoRepair to work on Java code, and makes the first public release of an implementation of Par. Unlike prior work, our study carefully controls for confounding factors and produces a methodology, as well as a dataset of automatically-generated test suites, for objectively evaluating the quality of Java repair techniques on real-world defects.",1939-3520,,10.1109/TSE.2020.2998785,Division of Computing and Communication Foundations; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9104918,Automated program repair;patch quality;objective quality measure;Java;GenProg;Par;TrpAutoRepair;Defects4J,Maintenance engineering;Java;Contracts;Manuals;Diversity reception;Inspection;Software quality,,,,1.0,,,,1 Jun 2020,,,IEEE,IEEE Early Access Articles
1762,401,A Survey on Adaptive Random Testing,R. Huang; W. Sun; Y. Xu; H. Chen; D. Towey; X. Xia,"Jiangsu Key Laboratory of Security Technology for Industrial Cyberspace, Jiangsu University, 12676 Zhenjiang, Jiangsu China (e-mail: rbhuang@ujs.edu.cn); School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, Jiangsu China (e-mail: 3140608036@stmail.ujs.edu.cn); School of Computer Science and Communication Engineering, Jiangsu Univeristy, Zhenjiang, Jiangsu China (e-mail: 1361570668@qq.com); School of Computer Science and Communication Engineering, Jiangsu Univeristy, Zhenjiang, Jiangsu China (e-mail: 1048953124@qq.com); Division of Computer Science, University of Nottingham Ningbo China, Ningbo, Zhejiang China 315100 (e-mail: dave.towey@nottingham.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Random testing (RT) is a well-studied testing method that has been widely applied to the testing of many applications, including embedded software systems, SQL database systems, and Android applications. Adaptive random testing (ART) aims to enhance RT's failure-detection ability by more evenly spreading the test cases over the input domain. Since its introduction in 2001, there have been many contributions to the development of ART, including various approaches, implementations, assessment and evaluation methods, and applications. This paper provides a comprehensive survey on ART, classifying techniques, summarizing application areas, and analyzing experimental evaluations. This paper also addresses some misconceptions about ART, and identifies open research challenges to be further investigated in the future work.",1939-3520,,10.1109/TSE.2019.2942921,National Natural Science Foundation of China; China Postdoctoral Science Foundation; Young Backbone Teacher Cultivation Project of Jiangsu University; Senior Personnel Scientific Research Foundation of Jiangsu University; Postgraduate Research and Practice Innovation Program of Jiangsu Province; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846002,Adaptive random testing;random testing;survey,Subspace constraints;Testing;Libraries;Software;Power capacitors;Strips;Art,,,,5.0,,,,23 Sep 2019,,,IEEE,IEEE Early Access Articles
1763,402,SOSRepair: Expressive Semantic Search for Real-World Program Repair,A. Afzal; M. Motwani; K. Stolee; Y. Brun; C. Le Goues,"Institute for Software Research, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: afsoona@cs.cmu.edu); College of Information and Computer Science, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: mmotwani@cs.umass.edu); Computer Science, North Carolina State University, Raleigh, North Carolina United States 27695-8206 (e-mail: ktstolee@ncsu.edu); College of Information and Computer Science, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: brun@cs.umass.edu); Institue for Software Research, Carnegie Mellon University, Pittsburgh, Pennsylvania United States 15213 (e-mail: clegoues@cs.cmu.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Automated program repair holds the potential to significantly reduce software maintenance effort and cost. However, recent studies have shown that it often produces low-quality patches that repair some but break other functionality. We hypothesize that producing patches by replacing likely faulty regions of code with semantically-similar code fragments, and doing so at a higher level of granularity than prior approaches can better capture abstraction and the intended specification, and can improve repair quality. We create SOSRepair, an automated program repair technique that uses semantic code search to replace candidate buggy code regions with behaviorally-similar (but not identical) code written by humans. SOSRepair is the first such technique to scale to real-world defects in real-world systems. On a subset of the ManyBugs benchmark of such defects, SOSRepair produces patches for 22 (34%) of the 65 defects, including 3, 5, and 6 defects for which previous state-of-the-art techniques Angelix, Prophet, and GenProg do not, respectively. On these 22 defects, SOSRepair produces more patches (9, 41%) that pass all independent tests than the prior techniques. We demonstrate a relationship between patch granularity and the ability to produce patches that pass all independent tests. We then show that fault localization precision is a key factor in SOSRepair's success. Manually improving fault localization allows SOSRepair to patch 23 (35%) defects, of which 16 (70%) pass all independent tests. We conclude that (1) higher-granularity, semantic-based patches can improve patch quality, (2) semantic search is promising for producing high-quality real-world defect repairs, (3) research in fault localization can significantly improve the quality of program repair techniques, and (4) semi-automated approaches in which developers suggest fix locations may produce high-quality patches.",1939-3520,,10.1109/TSE.2019.2944914,Division of Computing and Communication Foundations; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854217,Automated program repair;semantic code search;patch quality;program repair quality;SOSRepair,Maintenance engineering;Semantic search;Encoding;Benchmark testing;Computer bugs;Software,,,,2.0,,,,1 Oct 2019,,,IEEE,IEEE Early Access Articles
1764,403,CloudRaid: Detecting Distributed Concurrency Bugs via Log-Mining and Enhancement,J. Lu; C. Liu; F. Li; L. Li; X. Feng; J. Xue,"State Key Laboratories of Computer Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: lujie@ict.ac.cn); State Key Laboratories of Computer Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: liuchen17z@ict.ac.cn); Key Laboratory of Network Assessment Technology, Chinese Academy of Sciences, Beijing Key Laboratory of Network Security and Protection Technology, Institute of Information Engineering Chinese Academy of Sciences, 306628 Beijing, Beijing China (e-mail: lifeng@iie.ac.cn); State Key Laboratories of Computer Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: lianli@Ict.ac.cn); Key Lab. of Computer System and Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: fxb@ict.ac.cn); School of Computer Science and Engineering, University of New South Wales, 7800 Sydney, New South Wales Australia (e-mail: j.xue@unsw.edu.au)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Cloud systems suffer from distributed concurrency bugs, which often lead to data loss and service outage. This paper presents CLOUDRAID, a new automatical tool for finding distributed concurrency bugs efficiently and effectively. Distributed concurrency bugs are notoriously difficult to find as they are triggered by untimely interaction among nodes, i.e., unexpected message orderings. To detect concurrency bugs in cloud systems efficiently and effectively, CLOUDRAID analyzes and tests automatically only the message orderings that are likely to expose errors. Specifically, CLOUDRAID mines the logs from previous executions to uncover the message orderings that are feasible but inadequately tested. In addition, we also propose a log enhancing technique to introduce new logs automatically in the system being tested. These extra logs added improve further the effectiveness of CLOUDRAID without introducing any noticeable performance overhead. Our log-based approach makes it well-suited for live systems. We have applied CLOUDRAID to analyze six representative distributed systems: Apache Hadoop2/Yarn, HBase, HDFS, Cassandra, Zookeeper, and Flink. CLOUDRAID has succeeded in testing 60 different versions of these six systems (10 versions per system) in 35 hours, uncovering 31 concurrency bugs, including nine new bugs that have never been reported before. For these nine new bugs detected, which have all been confirmed by their original developers, three are critical and have already been fixed.",1939-3520,,10.1109/TSE.2020.2999364,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106854,Distributed Systems;Concurrency Bugs;Bug Detection;Cloud Computing,Computer bugs;Concurrent computing;Cloud computing;Task analysis;Runtime;Message systems;Tools,,,,,,,,2 Jun 2020,,,IEEE,IEEE Early Access Articles
1765,404,One-Click Formal Methods,J. Backes; P. Bolignano; B. Cook; A. Gacek; K. S. Luckow; N. Rungta; M. Schaef; C. Schlesinger; R. Tanash; C. Varming; M. Whalen,"Inspector, Amazon Web Services, United States; Software Engineering, Amazon Web Services, United States; University College London, United Kingdom; Automated Reasoning, Amazon Web Services, United States; Automated Reasoning, Amazon Web Services, United States; Formal Services, Amazon Web Services, United States; Software Engineering, Amazon Web Services, United States; Applied Science, Amazon Web Services, United States; Amazon Security Hub, Amazon Web Services, United States; Automated Reasoning, Amazon Web Services, United States; Proof Platforms, Amazon Web Services, United States",IEEE Software,22 Oct 2019,2019,36,6,61,65,"Formal methods are mathematically based approaches for specifying, building, and reasoning about software. Despite 50 years of research and development, formal methods have had only limited impact in industry. While we have seen success in such domains as microprocessor design and aerospace (e.g., proofs of security properties for helicopter control systems1), we have not seen wide adoption of formal methods for large and complex systems, such as web services, industrial automation, or enterprise support software.",1937-4194,,10.1109/MS.2019.2930609,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880058,,Cloud computing;Software tools;Databases;Cognition;Web services;Access control,formal specification;reasoning about programs,one-click formal methods;microprocessor design;Web services;industrial automation;enterprise support software,,4.0,,4.0,,22 Oct 2019,,,IEEE,IEEE Magazines
1766,405,Gender Diversity and Community Smells: Insights From the Trenches,G. Catolino; F. Palomba; D. A. Tamburri; A. Serebrenik; F. Ferrucci,"University of Salerno, Italy; Software Engineering, University of Salerno, Italy; Jheronimus Academy of Data Science, The Netherlands; Software Evolution, Eindhoven University of Technology, Eindhoven, The Netherlands; Software Engineering, University of Salerno, Italy",IEEE Software,20 Dec 2019,2020,37,1,10,16,"Given growing attention to gender diversity in software development teams, we asked practitioners if it was a useful tool to mitigate undesirable communication patterns. While many participants didn't consider gender diversity useful in this context, those who did were motivated by their own professional experience.",1937-4194,,10.1109/MS.2019.2944594,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852638,Gender Diversity;Survey;Community Smell,Software development management;Gender issues,gender issues;software development management;team working,community smells;gender diversity;communication patterns;software development teams,,2.0,,16.0,,30 Sep 2019,,,IEEE,IEEE Magazines
1767,406,Metamorphic Robustness Testing: Exposing Hidden Defects in Citation Statistics and Journal Impact Factors,Z. Q. Zhou; T. H. Tse; M. Witheridge,"School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: zhiquan@uow.edu.au); Department of Computer Science, The University of Hong Kong, Hong Kong, Hong Kong Hong Kong Hong Kong (e-mail: thtse@cs.hku.hk); School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: mw204@uowmail.edu.au)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"We propose a robustness testing approach for software systems that process large amounts of data. Our method uses metamorphic relations to check software output for erroneous input in the absence of a tangible test oracle. We use this technique to test two major citation database systems: Scopus and the Web of Science. We report a surprising finding that the inclusion of hyphens in paper titles impedes citation counts, and that this is a result of the lack of robustness of the citation database systems in handling hyphenated paper titles. Our results are valid for the entire literature as well as for individual fields such as chemistry. We further find a strong and significant negative correlation between the journal impact factor (JIF) of IEEE Transactions on Software Engineering (TSE) and the percentage of hyphenated paper titles published in TSE. Similar results are found for ACM Transactions on Software Engineering and Methodology. A software engineering field-wide study reveals that the higher JIF-ranked journals are publishing a lower percentage of papers with hyphenated titles. Our results challenge the common belief that citation counts and JIFs are reliable measures of the impact of papers and journals, as they can be distorted simply by the presence of hyphens in paper titles.",1939-3520,,10.1109/TSE.2019.2915065,Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708940,Metamorphic robustness testing;metamorphic testing;negative testing;fault-based testing;software robustness;oracle problem;citation count;journal impact factor;Scopus;Web of Science;Google Scholar;verification and validation,Robustness;Database systems;Software;Fuzzing;Google,,,,2.0,,,,7 May 2019,,,IEEE,IEEE Early Access Articles
1768,407,Evaluating Essential and Accidental Code Complexity Triggers by Practitioners’ Perception,V. Antinyan,"Software Quality, Volvo Cars, Gothenburg, Sweden",IEEE Software,23 Oct 2020,2020,37,6,86,93,"Code complexity determines the difficulty of understanding code. Survey results show that many elements influence complexity, most of which are accidental and can be removed. Meanwhile, several elements captured by the traditional complexity metrics have a small influence on complexity. Code complexity has been one of the most researched subjects in software engineering and one of the most measured properties of software.",1937-4194,,10.1109/MS.2020.2976072,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9007382,Code complexity;software metrics;code quality;maintainability;code readability,Complexity theory;Bars;Software;Task analysis;Software measurement;Software engineering,software maintenance;software metrics,code complexity;complexity metrics;software engineering,,,,17.0,,24 Feb 2020,,,IEEE,IEEE Magazines
1769,408,Validation of Autonomous Systems,C. Ebert; M. Weyrich,"Vector Consulting Services; Industrial Automation and Software Engineering, University of Stuttgart, Germany",IEEE Software,15 Aug 2019,2019,36,5,15,23,"Society today depends on autonomous systems, such as intelligent service systems, self-driving trains, and remote surgeries.1 The ultimate validation of the Turing test is that we often do not recognize autonomous systems. This growing usage poses many challenges, such as how to provide transparency, which rules or learning patterns are applied in a complex situation, and if these rules are the right ones. Validation is the key challenge, of which we will provide an overview in this article.",1937-4194,,10.1109/MS.2019.2921037,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802868,,Autonomous systems;Software engineering;Intelligent systems;Safety;Computational modeling;Performance evaluation,artificial intelligence,autonomous systems;Turing test validation,,1.0,,7.0,,15 Aug 2019,,,IEEE,IEEE Magazines
1770,409,"Relationships Between Project Size, Agile Practices, and Successful Software Development: Results and Analysis",M. Jorgensen,"IT Management, SimulaMet, Oslo, Norway",IEEE Software,21 Feb 2019,2019,36,2,39,43,"Large-scale software development succeeds more often when using agile methods. Flexible scope, frequent deliveries to production, a high degree of requirement changes and more competent providers are possible reasons.",1937-4194,,10.1109/MS.2018.2884863,Prosjekt Norge; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648276,,Software development management;Contracts;Frequency measurement;Project management;Organizations;Data collection,project management;software development management;software engineering;software prototyping,successful software development;large-scale software development;agile methods;flexible scope;frequent deliveries;requirement changes;project size;agile practices,,8.0,,6.0,,21 Feb 2019,,,IEEE,IEEE Magazines
1771,410,Successfully Governing Software Ecosystems: Competence Profiles of Partnership Managers,T. Kude; T. Huber; J. Dibbern,"ESSEC Business School, France; ESSEC Business School; Information Systems, University of Bern, Switzerland",IEEE Software,16 Apr 2019,2019,36,3,39,44,"The emergence of software platforms and ecosystems has led platform owners to create the role of the partnership manager. However, it is unclear what the required competences for this new role are. We derive two competence profiles of partnership managers.",1937-4194,,10.1109/MS.2018.2874553,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501932,Software ecosystems;partnership manager;competence profile;platform governance;arm’s length governance;dyadic governance,Ecosystems;Software development management;Collaboration;Engineering management,software engineering,competence profiles;software ecosystems;partnership managers,,,,14.0,,21 Oct 2018,,,IEEE,IEEE Magazines
1772,411,Building Resource Adaptive Software Systems,S. Neema; R. Parikh; S. Jagannathan,"Information Innovation Office, Defense Advanced Research Projects Agency, Arlington, Virginia United States; Information Innovation Office, Defense Advanced Research Projects Agency, Arlington, Virginia United States; Computer Science, Purdue University, West Lafayette, Indiana 47906 United States",IEEE Software,21 Feb 2019,2019,36,2,103,109,The Defense Advanced Research Projects Agency (DARPA) Building Resource Adaptive Software Systems (BRASS) program is an ambitious effort to improve the resilience and longevity of complex software systems. Its vision seeks a principled integration of adaptive reasoning into all aspects of the software design cycle.,1937-4194,,10.1109/MS.2018.2886831,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648261,,Ecosystems;Software systems;Biological system modeling;Adaptive systems;Computer architecture,software architecture;software engineering,Defense Advanced Research Projects Agency Building Resource Adaptive Software Systems program;complex software systems;adaptive reasoning;software design cycle;DARPA;BRASS,,1.0,,9.0,,21 Feb 2019,,,IEEE,IEEE Magazines
1773,412,Gender Differences in Public Code Contributions: A 50-Year Perspective,S. Zacchiroli,"Computer Science, Universite de Paris, Paris, 75013, France",IEEE Software,15 Feb 2021,2021,38,2,45,50,"We study the gender of commits authors over 120 million projects and a period of 50 years. Commits by female authors remain low overall but are growing steadily, providing hope of a more gender-balanced future for collaborative software development.",1937-4194,,10.1109/MS.2020.3038765,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261329,,Gender issues;Market research;Electric breakdown;Statistics;Software development management;Sociology,gender issues;groupware;software engineering,gender differences;public code contributions;female authors;gender-balanced future;collaborative software development,,2.0,,15.0,IEEE,17 Nov 2020,,,IEEE,IEEE Magazines
1774,413,Dual-Track Development,T. Sedano; P. Ralph; C. Peraire,"VMware, Inc., Palo Alto, California United States; Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada; Electrical and Computer Engineering, Carnegie Mellon University, Moffett Field, California United States",IEEE Software,23 Oct 2020,2020,37,6,58,64,"The best way to design good products (human-centered design) assumes a ""waterfall"" process, which is incompatible with agile methods.",1937-4194,,10.1109/MS.2020.3013274,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152985,,Buildings;Stakeholders;Usability;Encoding;Interviews,software engineering;user centred design,dual-track development;human-centered design;software product design;waterfall process,,,,15.0,IEEE,31 Jul 2020,,,IEEE,IEEE Magazines
1775,414,The Impact of Software on Eyecare in India,V. Venkataswamy; B. Seetharam,Drishti; Drishti,IEEE Software,19 Jun 2020,2020,37,4,99,106,"India has a population of 1.3 billion. Over the last decade, it has had record economic growth and reductions in poverty and infant mortality as well as an increase in life expectancy. India has managed to build industries in the areas of pharmaceutical and biotechnology manufacturing and software products with services. India is mostly rural, with more than 65-70% of its population living in vast hinterlands. The need to deliver health-care services in the last mile of every village and to every citizen is a challenge. Of the 1.2 million healthcare workers, 59.2%1 serve 27.8% of the urban population, whereas 40.8% of health-care workers serve 72.2% of the rural population.",1937-4194,,10.1109/MS.2020.2985789,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121628,,Power transmission lines;Ice thickness;Temperature sensors;Bragg gratings;Transmission line measurements;Monitoring,biotechnology;eye;health care;software engineering,India;economic growth;infant mortality;biotechnology manufacturing;software products;health-care services;urban population;rural population;software impact;eyecare,,1.0,,5.0,,19 Jun 2020,,,IEEE,IEEE Magazines
1776,415,Analyzing and Managing Complex Software Ecosystems: A Framework to Understand Value in Information Systems,W. Vorraber; M. Mueller; S. Voessner; W. Slany,"Engineering and Business Informatics, Graz University of Technology; Software Technology, Graz University of Technology; Engineering and Business Informatics, Graz University of Technology; Software Technology, Graz University of Technology",IEEE Software,16 Apr 2019,2019,36,3,55,60,"Managing complex software ecosystems, such as free open source software projects, is crucial for software-producing organizations. We present a framework that helps visualize complex ecosystem settings, gain insights on value engines, and describe relationships between the ecosystem partners.",1937-4194,,10.1109/MS.2018.290100810,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409423,services computing;enterprise modeling and management;general;dynamics of services ecosystem;computing milieux;management of computing and information systems;project and people management,Ecosystems;Visualization;Software development management;Object recognition;Stakeholders,information systems;public domain software;software engineering,complex software ecosystems;free open source software projects;software-producing organizations;information systems,,,,15.0,,10 Jul 2018,,,IEEE,IEEE Magazines
1777,416,Controlling the Controllers: What Software People Can Learn From Control Theory,B. Selic,"Malina Software Corp., Canada",IEEE Software,23 Oct 2020,2020,37,6,99,103,"The author states that AUDIT was an embarrassing admission of defeat, reflecting a development team resigned to the poor quality of their code. It dawned on him much later that the AUDIT program was simply an example of the very ancient feedback control loop pattern. In his experience, there is little awareness of the importance and complexity of the task of controlling software among software developers.",1937-4194,,10.1109/MS.2020.3006970,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238664,,Control theory;Computer bugs;Feedback control;Control systems;Force;Software systems,software engineering,software people;control theory;AUDIT program;software control;software developers;feedback control loop pattern,,,,6.0,,23 Oct 2020,,,IEEE,IEEE Magazines
1778,417,Information Needs: Lessons for Programming Tools,T. D. LaToza,"Computer Science, George Mason University, Fairfax, Virginia United States",IEEE Software,23 Oct 2020,2020,37,6,52,57,Why is programming sometimes so frustrating and annoying and other times so fast and painless? This article surveys a few of the important lessons emerging from studies of programming and the new programming tools they motivate.,1937-4194,,10.1109/MS.2020.3014343,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157879,,Tools;Programming profession;Navigation;Task analysis;Debugging;Psychology,computer science education;information needs;software engineering,programming tools;frustrating times;annoying times;important lessons;information needs,,,,14.0,,4 Aug 2020,,,IEEE,IEEE Magazines
1779,418,Highlights from ICSE 2019: Software Security and Mobile App Energy Consumption,J. C. Carver; L. L. Minku,"Computer Science, University of Alabama; Computer Science, University of Birmingham",IEEE Software,15 Aug 2019,2019,36,5,29,31,"This issue's ""Practitioners' Digest"" department reports on the 2019 International Conference on Software Engineering (ICSE). We focus on two emerging themes: security and energy issues for mobile apps. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in this article, please send me and the author(s) of the article a note about your experiences.",1937-4194,,10.1109/MS.2019.2922457,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802626,,Computer security;Energy consumption;Energy management;Software testing;Software engineering,,,,,,6.0,,15 Aug 2019,,,IEEE,IEEE Magazines
1780,419,From Monolithic to Microservices: An Experience Report from the Banking Domain,A. Bucchiarone; N. Dragoni; S. Dustdar; S. T. Larsen; M. Mazzara,Fondazione Bruno Kessler; Technical University of Denmark and Örebro University; TU Wien; Danske Bank; Innopolis University,IEEE Software,4 May 2018,2018,35,3,50,55,"Microservices have seen their popularity blossoming with an explosion of concrete applications in real-life software. Several companies are currently involved in a major refactoring of their back-end systems in order to improve scalability. This article presents an experience report of a real-world case study, from the banking domain, in order to demonstrate how scalability is positively affected by reimplementing a monolithic architecture into microservices. The case study is based on the FX Core system for converting from one currency to another. FX Core is a mission-critical system of Danske Bank, the largest bank in Denmark and one of the leading financial institutions in Northern Europe.",1937-4194,,10.1109/MS.2018.2141026,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354415,microservices;software architecture;scalability;software development;software engineering;Danske Bank;FX Core,Computer architecture;Service computing;Service-oriented architecture;Databases;Banking;Software development,bank data processing;software architecture,banking domain;microservices;concrete applications;real-life software;refactoring;back-end systems;scalability;monolithic architecture;FX Core system;mission-critical system;Danske Bank;Northern Europe,,15.0,1.0,13.0,,4 May 2018,,,IEEE,IEEE Magazines
1781,420,A Taxonomy of IoT Client Architectures,A. Taivalsaari; T. Mikkonen,Nokia Technologies; University of Helsinki,IEEE Software,4 May 2018,2018,35,3,83,88,"This article defines a taxonomy of software architecture options, derived from industry projects, for Internet of Things (IoT) devices, from the most limited sensing devices to high-end devices featuring fully fledged OSs and developer frameworks. A plethora of architecture options exists for IoT devices, offering very different levels of software development capabilities. These capabilities can significantly affect IoT systems' end-to-end architecture and topology.",1937-4194,,10.1109/MS.2018.2141019,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354417,IoT;Internet of Things;IoT devices;Programmable World;software architecture;software platforms;RTOS;real-time operating systems;software engineering;software development,Computer architecture;Random access memory;Internet of Things;Cloud computing;Taxonomy,Internet of Things;service-oriented architecture;software architecture,taxonomy;IoT client architectures;software architecture options;sensing devices;high-end devices;IoT devices;software development capabilities;IoT systems;Internet of Things devices;fully-fledged OS,,7.0,,8.0,,4 May 2018,,,IEEE,IEEE Magazines
1782,421,A Cambrian Explosion of DevOps Tools,M. Kersten,Tasktop,IEEE Software,12 Mar 2018,2018,35,2,14,17,"Specialization, and the resulting tool diversity, is a fundamental aspect of the modern DevOps toolchain. How does this affect the value stream architecture?",1937-4194,,10.1109/MS.2018.1661330,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314153,agile software development;DevOps;DevOps tools;value stream architecture;software development;software engineering,Software tools;Software development management;Task analysis,project management;software development management,resulting tool diversity;modern DevOps toolchain;Cambrian Explosion;value stream architecture,,3.0,,3.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1783,422,Microservices,X. Larrucea; I. Santamaria; R. Colomo-Palacios; C. Ebert,Tecnalia; Tecnalia; Østfold University College; Vector Consulting Services,IEEE Software,4 May 2018,2018,35,3,96,100,"Microservices are small applications with a single responsibility that can be deployed, scaled, and tested independently. They're gaining momentum across industries to facilitate agile delivery mechanisms for service-oriented architecture and to migrate function-oriented legacy architectures toward highly flexible service orientation. This article presents a brief overview of microservice technologies and how to migrate to them.",1937-4194,,10.1109/MS.2018.2141030,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354423,microservices;Cross-Origin Resource Sharing;CORS;software development;software engineering;Software Technology,Software development;Service computing;Computer architecture;Browsers;Java,service-oriented architecture;Web services,agile delivery mechanisms;function-oriented legacy architectures;microservice technologies;flexible service orientation;service-oriented architecture,,6.0,,6.0,,4 May 2018,,,IEEE,IEEE Magazines
1784,423,Curve Balls,G. J. Holzmann,Nimble Research,IEEE Software,12 Mar 2018,2018,35,2,18,21,"When can we stop testing software, and when is it okay to skip tests? The answers might not be obvious.",1937-4194,,10.1109/MS.2018.1661321,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314157,software testing;software defects;S-curve;unit tests;software development;software engineering;Reliable Code,Software testing;Computer bugs;Software systems;Software reliability,program testing;software quality,curve balls;software testing,,,,2.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1785,424,“It Depends”: Heuristics for Common-Enough Requirements Practice,S. Gregory,Intel Corporation,IEEE Software,6 Jul 2018,2018,35,4,12,15,"How much diversity is permissible in requirements practices in a large corporation? Can different project teams legitimately use different elicitation methods, specification techniques, standards and checklists for reviews, and databases to manage content? Or is allowing any difference at all only inviting trouble? This instalment of the Requirements department shares how requirements specialists at Intel approach these questions through training, with a few examples of what they teach to better enable individuals and teams to continually improve their requirements engineering (RE) practice. It also discusses why practitioner engagement with the broader RE community is critical.",1937-4194,,10.1109/MS.2018.2801551,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405628,software requirements;requirements engineering;heuristics;software development;software engineering;Requirements,Teamwork;Collaboration;Engineering management;Requirements engineering;Problem-solving,formal specification;systems analysis,common-enough requirements practice;specification techniques;requirements specialists;requirements engineering practice;elicitation methods;requirements department,,,,4.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1786,425,"Agility, Risk, and Uncertainty, Part 2: How Risk Impacts Agile Architecture",M. Waterman,Specialised Architecture Services,IEEE Software,4 May 2018,2018,35,3,18,19,The amount of technical risk (and the underlying uncertainty) in a software development project can affect the amount of architecting that developers perform up-front. Software architects must determine the proper balance between risk and agility for their projects.,1937-4194,,10.1109/MS.2018.2141017,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354431,agile development;agile architecture;software architecture;technical risk;architecturally significant requirements;ASR;software development;software engineering;The Pragmatic Architect,Computer architecture;Complexity theory;Risk management;Software development;Uncertainty;Software architecture;Project management;Agile software development,software architecture;software prototyping,technical risk;software development project;agile architecture,,,,8.0,,4 May 2018,,,IEEE,IEEE Magazines
1787,426,Different Databases for Different Strokes,G. Vial,HEC Montréal,IEEE Software,12 Mar 2018,2018,35,2,80,85,"This article provides an overview of current database-management-system technologies and suppliers, along with a case study of an Internet application. The Web Extra at https://extras.computer.org/extra/mso2018020080s1.pdf consists of a table describing various database management systems.",1937-4194,,10.1109/MS.2018.1661308,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314165,relational databases;database management systems;relational database management systems;RDBMS;databases;SQL;NoSQL;CAP theorem;PACELC;Spanner;Google;software engineering;software development,Software development management;Data models;Relational databases;Data structures;Search engines,database management systems;Internet,database-management-system technologies;Internet application,,1.0,,7.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1788,427,"Software Analysis, Evolution, and Reengineering, and ICT Sustainability",J. Carver; B. Penzenstadler; A. Serebrenik,University of Alabama; California State University; Eindhoven University of Technology,IEEE Software,6 Jul 2018,2018,35,4,78,80,"This issue’s article reports on papers from the IEEE 25th International Conference on Software Analysis, Evolution, and Reengineering (SANER 18) and 5th International Conference on Information and Communications Technology for Sustainability (ICT4S 18).",1937-4194,,10.1109/MS.2018.2801553,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405636,"IEEE 25th International Conference on Software Analysis, Evolution, and Reengineering;SANER;5th International Conference on Information and Communications Technology for Sustainability;ICT4S;replication studies;automated program repair;sustainability;software engineering;software development",,,,,,,,,6 Jul 2018,,,IEEE,IEEE Magazines
1789,428,How Common Is Common Enough in Requirements-Engineering Practice?,S. Gregory,Intel Corporation,IEEE Software,4 May 2018,2018,35,3,20,23,"When determining requirements-engineering practices in a complex organization in which different groups might have different needs, the trick is to determine which practices are “common enough” without being too restrictive or too loose.",1937-4194,,10.1109/MS.2018.2141038,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354435,requirements engineering;software requirements;Al Davis;software development;software engineering,Software development;Requirements engineering;Training,formal specification;formal verification;systems analysis,requirements-engineering practice,,2.0,,4.0,,4 May 2018,,,IEEE,IEEE Magazines
1790,429,Requirements Engineering and Continuous Deployment,N. Niu; S. Brinkkemper; X. Franch; J. Partanen; J. Savolainen,University of Cincinnati; Utrecht University; Polytechnic University of Catalonia; Bittium; Danfoss,IEEE Software,12 Mar 2018,2018,35,2,86,90,"This article summarizes the RE in the Age of Continuous Deployment panel at the 25th IEEE International Requirements Engineering Conference. It highlights two synergistic points (user stories and linguistic tooling) and one challenge (nonfunctional requirements) in fast-paced, agile-like projects, and recommends how to carry on the dialogue.",1937-4194,,10.1109/MS.2018.1661332,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314167,requirements engineering;continuous deployment;RE in the Age of Continuous Deployment;25th IEEE International Requirements Engineering Conference;user stories;linguistic tooling;agile software development;nonfunctional requirements;software requirements;software engineering;software development,Software development management;Software reliability;Stakeholders;Pragmatics;Software testing;Task analysis;Requirements engineering,formal specification;formal verification;systems analysis,nonfunctional requirements;Continuous Deployment panel;IEEE International Requirements Engineering Conference;synergistic points;user stories;linguistic tooling,,7.0,,13.0,,12 Mar 2018,,,IEEE,IEEE Magazines
1791,430,"Design with Your Team, Not for Your Team",M. Keeling,IBM,IEEE Software,6 Jul 2018,2018,35,4,86,88,There are two popular creation myths about software architectures: the Solitary Architect and the Emergent Architecture. These myths need to be replaced with new ones: the Architect as Coach and the Architect as Player-Coach.,1937-4194,,10.1109/MS.2018.2801556,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405638,software architecture;software architects;software design;software engineering;software development;Pragmatic Architect,Software architecture;Software development management;Testing,software architecture;software quality;team working,software architectures;Solitary Architect;Emergent Architecture;quality attributes;Architect as Player-Coach;Architect as Coach,,,,5.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1792,431,Choosing a Chatbot Development Tool,S. Pérez-Soler; S. Juárez-Puerta; E. Guerra; J. de Lara,"Ingeniería Informática, Universidad Autonoma de Madrid, Madrid, 28049 Madrid, Spain; Ingeniería Informática, Universidad Autonoma de Madrid, Madrid, Madrid, Spain; Computer Science, Universidad Autonoma de Madrid, Madrid, Madrid, Spain; Ingeniería Informática, Universidad Autonoma de Madrid, Madrid, 28049 Madrid, Spain",IEEE Software,,2021,PP,99,0,0,"Chatbots are programs that supply services to users via conversation in natural language, acting as virtual assistants within social networks or web applications. Companies like Google, IBM, Microsoft or Amazon have released chatbot development tools with different functionalities, capabilities, approaches and pricing models. With so many options, companies that want to offer services through chatbots can find choosing the right tool difficult. To help them make an informed choice, we review the most representative chatbot development tools with a focus on technical and managerial aspects.",1937-4194,,10.1109/MS.2020.3030198,Ministerio de Ciencia e Innovación; Comunidad de Madrid; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364349,Software Engineering;Chatbots;Natural Language Processing,Chatbot;Tools;Libraries;Companies;Social networking (online);Testing;Software,,,,,,,IEEE,26 Feb 2021,,,IEEE,IEEE Early Access Articles
1793,432,Trends in Agile Updated: Perspectives from the Practitioners,R. Prikladnicki; C. Lassenius; J. C. Carver,Pontifical Catholic University of Rio Grande do Sul; Aalto University; University of Alabama,IEEE Software,25 Dec 2017,2018,35,1,109,111,"The Agile Conference is the largest global conference on agile software development, catering particularly to practitioners. This article reports on three keynotes at Agile 2017 and the second year of an IEEE Software conference initiative.",1937-4194,,10.1109/MS.2017.4541042,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239936,agile development;David Marquet;intent-based leadership;Jez Humble;continuous delivery;Denise Jacobs;inner critic;Amy Silberbauer;Mike Griffiths;business analysts;systems engineers;Agile Conference;Agile 2017;software development;software engineering;Practitioners’ Digest,,,,,1.0,,,,25 Dec 2017,,,IEEE,IEEE Magazines
1794,433,Why and How Your Traceability Should Evolve: Insights from an Automotive Supplier,R. Wohlrab; P. Pelliccione; A. Shahrokni; E. Knauss,"Computer Science and Engineering, Chalmers tekniska hogskola Campus Lindholmen, Göteborg, Västra Götaland, Sweden; Department of Computer Science, University of L'Aquila Department of Information Engineering Computer Science and Mathematics, L'Aquila, Abruzzo, Italy; Zerberus, Zenuity AB, Gothenburg, Västra Götaland, Sweden; Computer Science and Engineering, Chalmers tekniska hogskola Campus Lindholmen, Göteborg, Sweden, Sweden",IEEE Software,,2020,PP,99,0,0,"Traceability is a key enabler of various activities in automotive software and systems engineering and required by several standards. However, most existing traceability management approaches do not consider that traceability is situated in constantly changing development contexts involving multiple stakeholders. Together with an automotive supplier, we analyzed how technology, business, and organizational factors raise the need for flexible traceability. We present how traceability can be evolved in the development lifecycle, from early elicitation of traceability needs to the implementation of mature traceability strategies. Moreover, we shed light on how traceability can be managed flexibly within an agile team and more formally when crossing team borders and organizational borders. Based on these insights, we present requirements for flexible tool solutions, supporting varying levels of data quality, change propagation, versioning, and organizational traceability.",1937-4194,,10.1109/MS.2020.2996369,Knut och Alice Wallenbergs Stiftelse; Software Center; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097278,Tracing;Software Engineering Process;Organizational management and coordination,Automotive engineering;Safety;Stakeholders;Tools;Data integrity;Modeling;Companies,,,,,,,,20 May 2020,,,IEEE,IEEE Early Access Articles
1795,434,The Web as a Software Connector: Integration Resting on Linked Resources,C. Pautasso; O. Zimmermann,"University of Lugano; University of Applied Sciences of Eastern Switzerland, Rapperswil",IEEE Software,25 Dec 2017,2018,35,1,93,98,"The web, seen as a graph of linked resources shared between microservices, can serve as an integration style. It offers unique characteristics and possibilities regarding dataflow, control flow, and other qualities, compared to file transfer, shared databases, remote procedure calls, and asynchronous messaging. Carrying these insights in your toolbox will make you aware of all the options to consider next time you build loosely coupled integrated systems.",1937-4194,,10.1109/MS.2017.4541049,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239944,architectural decisions;enterprise application integration;integration styles;microservices;software architecture;REST;Representational State Transfer;WWW;software engineering;software development;the web;Insights,Protocols;Software architecture;Software development;Software architecture;Interoperability;Servers;Web services,data flow computing;integrated software;Internet,loosely coupled integrated systems;control flow;dataflow;software integration;linked resources;Web;software connector,,1.0,,10.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1796,435,Managing Energy Consumption as an Architectural Quality Attribute,R. Kazman; S. Haziyev; A. Yakuba; D. A. Tamburri,University of Hawai’i; SoftServe; SoftServe; Jheronimus Academy of Data Science and Technical University of Eindhoven,IEEE Software,27 Sep 2018,2018,35,5,102,107,"A look at the software for an automated weather station shows that energy can be treated like any other architectural quality attribute. It's no different, from the perspective of architectural design, than modifiability, performance, or availability. It can be modeled and prototyped, and we can reason about the design tradeoffs required to achieve better energy use.",1937-4194,,10.1109/MS.2018.3571227,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474494,energy consumption;software architecture;Internet of Things;IoT;weather stations;automated weather stations;software engineering;software development;The Pragmatic Architect,Energy consumption;Power demand;Meteorology;Current measurement;Energy measurement;Internet of Things;Automation,energy consumption;software architecture;software quality,automated weather station;architectural quality attribute;energy consumption,,2.0,,2.0,,27 Sep 2018,,,IEEE,IEEE Magazines
1797,436,Over-the-Air Updates for Robotic Swarms,V. S. Varadharajan; D. S. Onge; C. Guß; G. Beltrame,École Polytechnique de Montréal; École Polytechnique de Montréal; Hannover University of Applied Sciences and Arts; École Polytechnique de Montréal,IEEE Software,12 Mar 2018,2018,35,2,44,50,"Along with the growing number of robotic devices introduced by automation and the Internet of Things has come the growth of interest in methods and tools for deploying code updates to active sensor arrays and swarms of robots. This article presents a toolset that can perform an over-the-air code update of the robots in a swarm while the swarm is active, without interrupting the swarm's mission. Each update is generated as a patch of the currently deployed code. A consensus mechanism borrowed from swarm intelligence ensures that, at any given time, all robots in the swarm run the same code version. Simulations were conducted with thousands of units to study the scalability and bandwidth consumption of the update process. Real deployment experiments were then performed on a small swarm of commercial quadcopters. This article is part of a theme issue on release engineering.",1937-4194,,10.1109/MS.2018.111095718,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255775,multiagent systems;distributed artificial intelligence;artificial intelligence;AI;distributed applications;distributed systems;information technology;autonomous vehicles;robotics;UAVs;unmanned aerial vehicles;over-the-air;OTA;computers and society;software development;software engineering,Software development management;Robot sensing systems;Software toolds;Software engineeirng;Cryptography,helicopters;mobile robots;particle swarm optimisation;sensor arrays;wireless sensor networks,currently deployed code;swarm intelligence ensures;robots;code version;update process;robotic swarms;robotic devices;Internet of Things;code updates;active sensor arrays;over-the-air code update;over-the-air updates,,2.0,,14.0,,12 Jan 2018,,,IEEE,IEEE Magazines
1798,437,Mining the Ground Truth of Enterprise Toolchains,M. Kersten,Tasktop,IEEE Software,4 May 2018,2018,35,3,12,17,Data on organizations' use of agile and DevOps tools provides the ground truth of enterprise software delivery.,1937-4194,,10.1109/MS.2018.2141029,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354424,DevOps;DevOps tools;toolchains;value stream integration diagrams;software development;software engineering;On DevOps,Organizations;Software tools;Task analysis;Information analysis;Best practices;Enterprise resource planning;Software development,business data processing;cloud computing;data mining,enterprise software delivery;DevOps tools;enterprise toolchains,,3.0,,4.0,,4 May 2018,,,IEEE,IEEE Magazines
1799,438,Blockchain-Enabled E-Voting,N. Kshetri; J. Voas,University of North Carolina at Greensboro; Cigital,IEEE Software,6 Jul 2018,2018,35,4,95,99,Blockchain-enabled e-voting (BEV) could reduce voter fraud and increase voter access. Eligible voters cast a ballot anonymously using a computer or smartphone. BEV uses an encrypted key and tamper-proof personal IDs. This article highlights some BEV implementations and the approach's potential benefits and challenges.,1937-4194,,10.1109/MS.2018.2801546,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405627,blockchain-enabled e-voting;BEV;e-voting;blockchains;elections;voter fraud;voter access;paper ballots;electronic voting;online voting;software development;software engineering;Invited Content,Electronic voting;Urban areas;Cryptography;Blockchain,cryptography;data privacy;fraud;government data processing,eligible voters;ballot anonymously;blockchain-enabled e-voting;tamper-proof personal ID;encrypted key;voter access;voter fraud reduction;BEV,,38.0,,29.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1800,439,"Continuous Delivery: Building Trust in a Large-Scale, Complex Government Organization",R. Siqueira; D. Camarinha; M. Wen; P. Meirelles; F. Kon,University of São Paulo; University of São Paulo; University of São Paulo; University of Brasilia; University of São Paulo,IEEE Software,12 Mar 2018,2018,35,2,38,43,"For many software development teams, the first aspects that come to mind regarding continuous delivery (CD) are the operational challenges and competitive benefits. In the authors' experience, CD was much more: it was a survival technique. This article presents how and why they applied CD in a large governmental project for the development of a collaborative development environment. They share the challenges they faced and the strategies they used to overcome them. The article concludes with a set of lessons learned that can be valuable for readers in a variety of situations. This article is part of a special issue on release engineering.",1937-4194,,10.1109/MS.2018.111095426,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255783,continuous delivery;software release management;configuration management;software engineering;government applications;agile software development;software development,Software development management;Software product lines;Product life cycle management;Software engineeirng,software development management,software development teams;continuous delivery;CD;survival technique;governmental project;collaborative development environment;large-scale complex government organization;release engineering,,,,6.0,,12 Jan 2018,,,IEEE,IEEE Magazines
1801,440,WordPress: A Content Management System to Democratize Publishing,J. Cabot,Universitat Oberta de Catalunya,IEEE Software,4 May 2018,2018,35,3,89,92,"WordPress aims to democratize publishing, ensuring that any nontechnical person can create a website, while building a product that can scale all the way up to enterprise clients with complex needs. The richness and importance of the WordPress code base and ecosystem pose many interesting challenges for the research community.",1937-4194,,10.1109/MS.2018.2141016,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354434,WordPress;website development;content management systems;CMS;plug-ins;software development;software engineering,Software packages;Blogs;Electronic publishing;Content management,content management;publishing;social networking (online),WordPress;content management system;publishing,,2.0,,8.0,,4 May 2018,,,IEEE,IEEE Magazines
1802,441,A Comet Revisited: Lessons Learned from Philaes Landing,A. Balázs,Wigner Research Centre for Physics,IEEE Software,6 Jul 2018,2018,35,4,89,93,"The Philae lander, part of the Rosetta program, was the first to land on and explore a comet. This article explores the lessons learned from the Philae team's experiences with problems that occurred in the hardware and software and in mission operations control.",1937-4194,,10.1109/MS.2018.2801542,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405637,comet 67P/Churyumov-Gerasimenko;Rosetta;Philae;software development;software engineering;Impact,Space missions;Fault tolerant systems;Orbits;Space research,comets;space vehicles,Philae lander;Rosetta program;Philae team;Philaes landing;Philae team experiences;mission operations control,,,,5.0,,6 Jul 2018,,,IEEE,IEEE Magazines
1803,442,Probabilistic Threat Detection for Risk Management in Cyber-physical Medical Systems,A. Rao; N. Carreón; R. Lysecky; J. Rozenblit,University of Arizona; University of Arizona; University of Arizona; University of Arizona,IEEE Software,25 Dec 2017,2018,35,1,38,43,"Medical devices are complex cyber-physical systems incorporating emergent hardware and software components. However, this complexity leads to a wide attack surface posing security risks and vulnerabilities. Mitigation and management of such risks during premarket design and postmarket deployment are required. Dynamically mitigating threat potential in the presence of unknown vulnerabilities requires an adaptive risk-based scheme to assess the system's state, a secure system architecture that can isolate hardware and software components, and design methods that can adaptively adjust the system's topology based on risk changes. The essential complementary aspects during deployment are detecting, characterizing, and quantifying security threats. This article presents a dynamic risk management and mitigation approach based on probabilistic threat estimation. A smart-connected-pacemaker case study illustrates the approach. This article is part of a special issue on Software Safety and Security Risk Mitigation in Cyber-physical Systems.",1937-4194,,10.1109/MS.2017.4541031,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239935,medical-device security;threat estimation;risk assessment and management;software development;software engineering,Computer security;Runtime;Risk management;Pacemakers;Medical devices;Safety;Cyber-physical systems;Cloud computing,computer network security;pacemakers;risk management;security of data,software safety;security risk mitigation;complex cyber-physical medical systems;medical devices;probabilistic threat detection;probabilistic threat estimation;dynamic risk management;quantifying security threats;secure system architecture;postmarket deployment;premarket design;security risks;wide attack surface;software components;emergent hardware,,7.0,,14.0,,25 Dec 2017,,,IEEE,IEEE Magazines
1804,443,Automatic Loop Summarization via Path Dependency Analysis,X. Xie; B. Chen; L. Zou; Y. Liu; W. Le; X. Li,"Tianjin University, Tianjin, China; Fudan University, Shanghai Shi, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Department of Computer Science, Iowa State University, Ames, IA; Tianjin University, Tianjin, China",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,537,557,"Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.",1939-3520,,10.1109/TSE.2017.2788018,National Research Foundation; National Natural Science Foundation of China; National Natural Science Foundation of China; National Natural Science Foundation of China; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241837,Disjunctive loop summary;path dependency automaton;path interleaving,Debugging;Automata;Benchmark testing;Public domain software,program debugging;program diagnostics;program testing;program verification;public domain software,automatic loop summarization;test case generation;program optimization;program analysis;path dependency automaton;PDA;loop classification;loop analysis framework;disjunctive loop summary;Proteus;loop program verification;loop bound analysis;path-sensitive loop effects,,3.0,,77.0,,29 Dec 2017,,,IEEE,IEEE Journals
1805,444,Code Review Knowledge Perception: Fusing Multi-Features for Salient-Class Location,Y. Huang; N. Jia; X. Chen; K. Hong; Z. Zheng,"School of Data and Computer Science, Sun Yat-sen University, Guangzhou, GuangDong China (e-mail: huangyjn@gmail.com); School of Management Science and Engineering, Hebei GEO University, Shijiazhuang, 050031, China, Hebei GEO University, 12410 Shijiazhuang, HeBei China (e-mail: huang_yuan@yahoo.com); Guangdong Key Laboratory for Big Data Analysis and Simulation of Public Opinion, School of Communication and Design, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: chenxp8@mail.sysu.edu.cn); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China, Sun Yat-sen University, guangzhou, Guangdong China (e-mail: hongkai1995@163.com); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: zibinzheng@yeah.net)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Code review is a common software engineering practice of practical importance to reduce software defects. Review today is often with the help of specialized tools, such as Gerrit. However, even in a tool-supported code review involves a significant amount of human effort to understand the code change, because the information required to inspect code changes may distribute across multiple files that reviewers are not familiar with. Code changes are often organized as commits for review. In this paper, we found that most of the commits contain a salient class(es), which is saliently modified and causes the modification of the rest classes in a commit. Our user studies confirmed that identifying the salient class in a commit can facilitate reviewers in understanding code change. Inspired by the effectiveness of machine learning techniques in the classification field, we model the salient class identification as a binary classification problem and extract a number of discriminative features from commit to characterize the salience of a class. The experiment results show that our approach achieves an accuracy of 88%. A user study with industrial developers shows that our approach can really improve the efficiency of reviewers understanding code changes in a reviewing scenario without using comment.",1939-3520,,10.1109/TSE.2020.3021902,National Key RD Program of China; National Natural Science Foundation of China; Key-Area Research and Development Program of Guangdong Province; China Postdoctoral Science Foundation; Guangdong Basic and Applied Basic Research Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186620,Code Review;Code Comprehension;Code Change;Code Discriminative Features;Code Commit,Feature extraction;Semantics;Tools;Couplings;Open source software;Knowledge engineering,,,,,,,,4 Sep 2020,,,IEEE,IEEE Early Access Articles
1806,445,Contextual Documentation Referencing on Stack Overflow,S. Baltes; C. Treude; M. P. Robillard,"School of Computer Science, The University of Adelaide, 1066 Adelaide, South Australia Australia (e-mail: research@sbaltes.com); School of Computer Science, The University of Adelaide, 1066 Adelaide, South Australia Australia (e-mail: christoph.treude@adelaide.edu.au); School of Computer Science, McGill University, Montreal, Quebec Canada H3A 2A7 (e-mail: martin@cs.mcgill.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software engineering is knowledge-intensive and requires software developers to continually search for knowledge, often on community question answering platforms such as Stack Overflow. Such information sharing platforms do not exist in isolation, and part of the evidence that they exist in a broader software documentation ecosystem is the common presence of hyperlinks to other documentation resources found in forum posts. With the goal of helping to improve the information diffusion between Stack Overflow and other documentation resources, we conducted a study to answer the question of how and why documentation is referenced in Stack Overflow threads. We sampled and classified 759 links from two different domains, regular expressions and Android development, to qualitatively and quantitatively analyze the links' context and purpose, including attribution, awareness, and recommendations. We found that links on Stack Overflow serve a wide range of distinct purposes, ranging from citation links attributing content copied into Stack Overflow, over links clarifying concepts using Wikipedia pages, to recommendations of software components and resources for background reading. This purpose spectrum has major corollaries, including our observation that links to documentation resources are a reflection of the information needs typical to a technology domain. We contribute a framework and method to analyze the context and purpose of Stack Overflow links, a public dataset of annotated links, and a description of five major observations about linking practices on Stack Overflow. Those observations include the above-mentioned purpose spectrum, its interplay with documentation resources and applications domains, and the fact that links on Stack Overflow often lack context in form of accompanying quotes or summaries. We further point to potential tool support to enhance the information diffusion between Stack Overflow and other documentation resources.",1939-3520,,10.1109/TSE.2020.2981898,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042358,Community Question Answering;Software Documentation;Information Diffusion;Hyperlinks;Stack Overflow,Documentation;Context;Internet;Software;Encyclopedias;Electronic publishing,,,,,,,,19 Mar 2020,,,IEEE,IEEE Early Access Articles
1807,446,Integrating Provenance Capture and UML with UML2PROV: Principles and Experience,C. Sáenz-Adán; B. Pérez; F. J. García-Izquierdo; L. Moreau,"Department of Mathematics and Computer Science, University of La Rioja, La Rioja, Spain (e-mail: carlos.saenz@unirioja.es); Department of Mathematics and Computer Science, University of La Rioja, La Rioja, Spain (e-mail: beatriz.perez@unirioja.es); Department of Mathematics and Computer Science, University of La Rioja, La Rioja, Spain (e-mail: francisco.garcia@unirioja.es); Department of Informatics, King's College London, London, UK (e-mail: luc.moreau@kcl.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"In response to the increasing calls for algorithmic accountability, UML2PROV is a novel approach to address the existing gap between application design, where models are described by UML diagrams, and provenance design, where generated provenance is meant to describe an application's flows of data, processes and responsibility, enabling greater accountability of this application. The originality of UML2PROV is that designers are allowed to follow their preferred software engineering methodology to create the UML Diagrams for their application, while UML2PROV takes the UML diagrams as a starting point to automatically generate: (1) the design of the provenance to be generated (expressed as PROV templates); and (2) the software library for collecting runtime values of interest (encoded as variable-value associations known as bindings), which can be deployed in the application without developer intervention. At runtime, the PROV templates combined with the bindings are used to generate high-quality provenance suitable for subsequent consumption. UML2PROV is rigorously defined by an extensive set of 17 patterns mapping UML diagrams to provenance templates, and is accompanied by a reference implementation based on Model Driven Development techniques. A systematic evaluation of UML2PROV uses quantitative data and qualitative arguments to show the benefits and trade-offs of applying UML2PROV for software engineers seeking to make applications provenance-aware. In particular, as the UML design drives both the design and capture of provenance, we discuss how the levels of detail in UML designs affect aspects such as provenance design generation, application instrumentation, provenance capability maintenance, storage and run-time overhead, and quality of the generated provenance. Some key lessons are learned such as: starting from a non-tailored UML design leads to the capture of more provenance than required to satisfy provenance requirements and therefore, increases the overhead unnecessarily; alternatively, if the UML design is tailored to focus on addressing provenance requirements, only relevant provenance gets to be collected, resulting in lower overheads.",1939-3520,,10.1109/TSE.2020.2977016,Spanish Ministerio de Economia y Competitividad; University of La Rioja; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018139,provenance;PROV;provenance generation;template,Unified modeling language;Software;Proposals;Runtime;Data models;Tools,,,,,,,,28 Feb 2020,,,IEEE,IEEE Early Access Articles
1808,447,Extending Abstract Interpretation to Dependency Analysis of Database Applications,A. Jana; R. Halder; K. V. Abhishekh; S. D. Ganni; A. Cortesi,"Indian Institute of Technology Patna, Patna, Bihar, India; Indian Institute of Technology Patna, Patna, Bihar, India; Indian Institute of Technology Patna, Patna, Bihar, India; Indian Institute of Technology Patna, Patna, Bihar, India; Università Ca’ Foscari Venezia, Venezia, VE, Italy",IEEE Transactions on Software Engineering,14 May 2020,2020,46,5,463,494,"Dependency information (data- and/or control-dependencies) among program variables and program statements is playing crucial roles in a wide range of software-engineering activities, e.g., program slicing, information flow security analysis, debugging, code-optimization, code-reuse, code-understanding. Most existing dependency analyzers focus on mainstream languages and they do not support database applications embedding queries and data-manipulation commands. The first extension to the languages for relational database management systems, proposed by Willmor et al. in 2004, suffers from the lack of precision in the analysis primarily due to its syntax-based computation and flow insensitivity. Since then no significant contribution is found in this research direction. This paper extends the Abstract Interpretation framework for static dependency analysis of database applications, providing a semantics-based computation tunable with respect to precision. More specifically, we instantiate dependency computation by using various relational and non-relational abstract domains, yielding to a detailed comparative analysis with respect to precision and efficiency. Finally, we present a prototype $\sf{ semDDA}$semDDA, a semantics-based Database Dependency Analyzer integrated with various abstract domains, and we present experimental evaluation results to establish the effectiveness of our approach. We show an improvement of the precision on an average of 6 percent in the interval, 11 percent in the octagon, 21 percent in the polyhedra and 7 percent in the powerset of intervals abstract domains, as compared to their syntax-based counterpart, for the chosen set of Java Server Page (JSP)-based open-source database-driven web applications as part of the GotoCode project.",1939-3520,,10.1109/TSE.2018.2861707,Science and Engineering Research Board; CINI Cybersecurity National Laboratory; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423692,Dependency graphs;static analysis;relational databases;structured query languages,Databases;Semantics;Static analysis;Security;Syntactics;Open source software;Debugging,,,,,,75.0,IEEE,31 Jul 2018,,,IEEE,IEEE Journals
1809,448,A Semantics-Based Hybrid Approach on Binary Code Similarity Comparison,Y. Hu; H. Wang; Y. Zhang; B. Li; D. Gu,"School of Electronic, Information and Electrical Engineering, Shanghai Jiao Tong University - Minhang Campus, 12474 Shanghai, Shanghai China (e-mail: yixiaoxian@gmail.com); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: tony-wh@sjtu.edu.cn); Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: yyjess@sjtu.edu.cn); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: uchihal@sjtu.edu.cn); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: dwgu@sjtu.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Binary code similarity comparison is a methodology for identifying similar or identical code fragments in binary programs. It is indispensable in fields of software engineering and security, which has many important applications (e.g., plagiarism detection, bug detection). With the widespread of smart and IoT (Internet of Things) devices, an increasing number of programs are ported to multiple architectures (e.g. ARM, MIPS). It becomes necessary to detect similar binary code across architectures as well. The main challenge of this topic lies in the semantics-equivalent code transformation resulting from different compilation settings, code obfuscation, and varied instruction set architectures. Another challenge is the trade-off between comparison accuracy and coverage. Unfortunately, existing methods still heavily rely on semantics-less code features which are susceptible to the code transformation. Additionally, they perform the comparison merely either in a static or in a dynamic manner, which cannot achieve high accuracy and coverage simultaneously. In this paper, we propose a semantics-based hybrid method to compare binary function similarity. We execute the reference function with test cases, then emulate the execution of every target function with the runtime information migrated from the reference function. Semantic signatures are extracted during the execution as well as the emulation. Lastly, similarity scores are calculated from the signatures to measure the likeness of functions. We have implemented the method in a prototype system designated as BINMATCH which performs binary code similarity comparison across architectures of x86, ARM and MIPS on the Linux platform. We evaluate BINMATCH with nine real-word projects compiled with different compilation settings, on variant architectures, and with commonly-used obfuscation methods, totally performing over 100 million pairs of function comparison. The experimental results show that BINMATCH is resilient to the semantics-equivalent code transformation. Besides, it not only covers all target functions for similarity comparison, but also improves the accuracy comparing to the state-of-the-art solutions.",1939-3520,,10.1109/TSE.2019.2918326,Major Project of Ministry of Industry and Information Tech- nology of China; National Key Research and Development Program of China; Key Program of National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721093,Binary code similarity comparison;reverse engineering;program analysis;code clone,Binary codes;Semantics;Computer architecture;Runtime;Computer science;Feature extraction;Internet of Things,,,,1.0,,,,23 May 2019,,,IEEE,IEEE Early Access Articles
1810,449,"Software Configuration Engineering in Practice Interviews, Survey, and Systematic Literature Review",M. SAYAGH; N. Kerzazi; B. Adams; F. Petrillo,"Department du Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, QC, Canada; Ecole Nationale Superieure d'Informatique et d'Analyse des Systemes (ENSIAS), Rabat, Morocco; Department du Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, QC, Canada; Département d'informatique et de mathématique, Université du Québec Chicoutimi, Chicoutimi, QC, Canada",IEEE Transactions on Software Engineering,15 Jun 2020,2020,46,6,646,673,"Modern software applications are adapted to different situations (e.g., memory limits, enabling/disabling features, database credentials) by changing the values of configuration options, without any source code modifications. According to several studies, this flexibility is expensive as configuration failures represent one of the most common types of software failures. They are also hard to debug and resolve as they require a lot of effort to detect which options are misconfigured among a large number of configuration options and values, while comprehension of the code also is hampered by sprinkling conditional checks of the values of configuration options. Although researchers have proposed various approaches to help debug or prevent configuration failures, especially from the end users' perspective, this paper takes a step back to understand the process required by practitioners to engineer the run-time configuration options in their source code, the challenges they experience as well as best practices that they have or could adopt. By interviewing 14 software engineering experts, followed by a large survey on 229 Java software engineers, we identified 9 major activities related to configuration engineering, 22 challenges faced by developers, and 24 expert recommendations to improve software configuration quality. We complemented this study by a systematic literature review to enrich the experts' recommendations, and to identify possible solutions discussed and evaluated by the research community for the developers' problems and challenges. We find that developers face a variety of challenges for all nine configuration engineering activities, starting from the creation of options, which generally is not planned beforehand and increases the complexity of a software system, to the non-trivial comprehension and debugging of configurations, and ending with the risky maintenance of configuration options, since developers avoid touching and changing configuration options in a mature system. We also find that researchers thus far focus primarily on testing and debugging configuration failures, leaving a large range of opportunities for future work.",1939-3520,,10.1109/TSE.2018.2867847,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451922,Empirical study;configuration;configuration engineering;Systematic literature review;interviews;survey,Software systems;Interviews;Systematics;Facebook;Bibliographies;Software algorithms,configuration management;Java;program debugging;software quality,software configuration quality;configuration engineering activities;debugging;software configuration engineering;software failures;run-time configuration options;Java software engineers,,4.0,,123.0,IEEE,30 Aug 2018,,,IEEE,IEEE Journals
1811,450,A Layered Reference Architecture for Metamodels to Tailor Quality Modeling and Analysis,R. Heinrich; M. Strittmatter; R. Reussner,"Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,775,800,"Nearly all facets of our everyday life strongly depend on software-intensive systems. Besides correctness, highly relevant quality properties of these systems include performance, as directly perceived by the user, and maintainability, as an important decision factor for evolution. These quality properties strongly depend on architectural design decisions. Hence, to ensure high quality, research and practice is interested in approaches to analyze the system architecture for quality properties. Therefore, models of the system architecture are created and used for analysis. Many different languages (often defined by metamodels) exist to model the systems and reason on their quality. Such languages are mostly specific to quality properties, tools or development paradigms. Unfortunately, the creation of a specific model for any quality property of interest and any different tool used is simply infeasible. Current metamodels for quality modeling and analysis are often not designed to be extensible and reusable. Experience from generalizing and extending metamodels result in hard to evolve and overly complex metamodels. A systematic way of creating, extending and reusing metamodels for quality modeling and analysis, or parts of them, does not exist yet. When comparing metamodels for different quality properties, however, substantial parts show quite similar language features. This leads to our approach to define the first reference architecture for metamodels for quality modeling and analysis. A reference architecture in software engineering provides a general architecture for a given application domain. In this paper, we investigate the applicability of modularization concepts from object-oriented design and the idea of a reference architecture to metamodels for quality modeling and analysis to systematically create, extend and reuse metamodel parts. Thus, the reference architecture allows to tailor metamodels. Requirements on the reference architecture are gathered from a historically grown metamodel. We specify modularization concepts as a foundation of the reference architecture. Detailed application guidelines are described. We argue the reference architecture supports instance compatibility and non-intrusive, independent extension of metamodels. In four case studies, we refactor historically grown metamodels and compare them to the original metamodels. The study results show the reference architecture significantly improves evolvability as well as need-specific use and reuse of metamodels.",1939-3520,,10.1109/TSE.2019.2903797,"Helmholtz Association of German Research Centers and the MWK (Ministry of Science, Research and the Arts Baden-Württemberg) in the funding line Research Seed Capital (RiSC); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8662719,Domain-specific modeling language;reference architecture;metamodel;quality analysis,Computer architecture;Object oriented modeling;Analytical models;Biological system modeling;Tools;Software;Systematics,,,,,,84.0,IEEE,7 Mar 2019,,,IEEE,IEEE Journals
1812,451,Which Variables Should I Log?,Z. Liu; X. Xia; D. Lo; Z. Xing; A. E. Hassan; S. Li,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: liu_zx@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: zhenchang.xing@anu.edu.au); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: shan@zju.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Developers usually depend on inserting logging statements into the source code to collect system runtime information. Such logged information is valuable for software maintenance. A logging statement usually prints one or more variables to record vital system status. However, due to the lack of rigorous logging guidance and the requirement of domain-specific knowledge, it is not easy for developers to make proper decisions about which variables to log. To address this need, in this work, we propose an approach to recommend logging variables for developers during development by learning from existing logging statements. Different from other prediction tasks in software engineering, this task has two challenges: 1) Dynamic labels -- different logging statements have different sets of accessible variables, which means in this task, the set of possible labels of each sample is not the same. 2) Out-of-vocabulary words -- identifiers' names are not limited to natural language words and the test set usually contains a number of program tokens which are out of the vocabulary built from the training set and cannot be appropriately mapped to word embeddings. To deal with the first challenge, we convert this task into a representation learning problem instead of a multi-label classification problem. Given a code snippet which lacks a logging statement, our approach first leverages a neural network with an RNN (recurrent neural network) layer and a self-attention layer to learn the proper representation of each program token, and then predicts whether each token should be logged through a unified binary classifier based on the learned representation. To handle the second challenge, we propose a novel method to map program tokens into word embeddings by making use of the pre-trained word embeddings of natural language tokens. We evaluate our approach on 9 large and high-quality Java projects. Our evaluation results show that the average MAP of our approach is over 0.84, outperforming random guess and an information-retrieval-based method by large margins.",1939-3520,,10.1109/TSE.2019.2941943,NSFC Program; National Key Research and Development Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8840982,Log;Logging Variable;Word Embedding;Representation Learning,Task analysis;Recurrent neural networks;Tools;Compounds;Vocabulary;Software maintenance,,,,2.0,,,,17 Sep 2019,,,IEEE,IEEE Early Access Articles
1813,452,Artificial Intelligence-Powered Worker Engagement in Software Crowdsourcing,J. Wang; Y. Yang; Q. Wang,"Software, Chinese Academy of Sciences, China; Systems and Enterprises, Stevens Institute of Technology; Software, Chinese Academy of Science, China",IEEE Software,26 Oct 2020,2020,37,6,94,98,"Crowdsourced Software Engineering (CSE) evolved from outsourcing and open source development. It has created a fundamental shift; there are now many open-call software minitasks that are advertised and performed through popular CSE platforms. For instance, TopCoder currently has more than 1.5 million registered designers, developers, and quality engineers; uTest has 400,000-plus testing specialists with diverse expertise to validate various aspects of digital quality.",1937-4194,,10.1109/MS.2020.3017035,National Key R and D Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9239287,,Task analysis;Computer bugs;Crowdsourcing;Artificial intelligence;Software;Testing;Context modeling,artificial intelligence;crowdsourcing;personnel;public domain software;software quality,artificial intelligence;crowdsourced software engineering;open source development;TopCoder;digital quality;open call software minitasks;outsourcing development;software crowdsourcing;CSE platforms;worker engagement;quality engineers,,,,4.0,,26 Oct 2020,,,IEEE,IEEE Magazines
1814,453,The Missing Requirements Perspective in Large-Scale Agile System Development,E. Knauss,"Computer Science and Engineering, Chalmers University of Gothenburg, Sweden",IEEE Software,16 Apr 2019,2019,36,3,9,13,"Recent developments in agile methods at scale and continuous delivery have successfully removed major bottlenecks that have, so far, limited the speed at which software can be developed, delivered, and evaluated by customers and end users. Now, the ability to manage requirements and related knowledge in continuous software engineering has become a limiting factor.",1937-4194,,10.1109/MS.2019.2896875,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693079,,Agile software development;Large-scale systems;Software development management;Systems engineering and theory;Contracts;Engineering management;Knowledge engineering,formal verification;software prototyping,agile methods;continuous delivery;continuous software engineering;missing requirements perspective;large-scale agile system development,,,,9.0,,16 Apr 2019,,,IEEE,IEEE Magazines
1815,454,Critical Factors for Open Source Advancement in the U.S. Department of Defense,T. P. Scanlon,"Software Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania United States",IEEE Software,22 Oct 2019,2019,36,6,29,33,Leveraging open source components in Department of Defense (DoD) software systems remains challenging and is often met with resistance. This article describes several factors that will increase the likelihood of successfully deploying open source in DoD projects.,1937-4194,,10.1109/MS.2019.2933769,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790750,,US Department of Defense;Open source software;Software systems;Computer security;Licenses,military computing;public domain software,open source advancement;open source components;DoD projects;department of defense software systems;US department of defense,,,,15.0,,7 Aug 2019,,,IEEE,IEEE Magazines
1816,455,"Ten Years of ""Impact"" Columns—The Good, the Bad, and the Ugly",M. van Genuchten; L. Hatton,"VitalHealth Software, United States; Forensic Software Engineering, Kingston University, United Kingdom",IEEE Software,22 Oct 2019,2019,36,6,57,60,"Ten years ago, we started the ""Impact"" column in IEEE Software. The goal when we started was to ""build better quantitative insight into how software impacts various businesses. How the product uses the software and how the company built it are equally important.""<sup>1</sup> This article is the 45th instance of the column. We have had 69 authors, mostly industry experts writing about the impact of software on their business and, in some cases, on its end users. Many of the authors had neither taken the time nor been given the opportunity to publish about their work before, so it gave them a forum to write about real systems: their size, their development methods, their economic and end-user impacts, and, perhaps most compelling of all, their ubiquity. The columns have been cited more than 400 times and have given our readers insights into some beautiful software solutions, in terms of both technology (e.g., the Mars rover<sup>2</sup>) and in terms of its impact on people (e.g., supporting farmers in Africa<sup>3</sup>). Our colleague, Zeljko Obrenovic, created a complete overview of the ""Impact"" column articles, which is available at https://www.obren359.com/collection.html?id=ieeesw/impact.",1937-4194,,10.1109/MS.2019.2932495,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880054,,Software developnment management;Social implications of technology,,,,2.0,,15.0,,22 Oct 2019,,,IEEE,IEEE Magazines
1817,456,"How Do Open Source Software Contributors Perceive and Address Usability? Valued Factors, Practices, and Challenges",W. Wang; J. Cheng; J. L. C. Guo,"Department of Computer Science, McGill University Faculty of Science, Montreal, Quebec, Canada (email: wenting.wang@mail.mcgill.ca); Department of Computer and Software Engineering, Ecole Polytechnique de Montreal, Montreal, Quebec, Canada (email: jinghuicheng@gmail.com); Department of Computer Science, McGill University Faculty of Science, Montreal, Quebec, Canada (email: jin.guo@cs.mcgill.ca)",IEEE Software,,2020,PP,99,0,0,"Usability is an increasing concern in open source software (OSS). Given the recent changes in the OSS landscape, it is imperative to examine the OSS contributors’ current valued factors, practices, and challenges concerning usability. We accumulated this knowledge through a survey with a wide range of contributors to OSS applications. Through analyzing 84 survey responses, we found that many participants recognized the importance of usability. While most relied on issue tracking systems to collect user feedback, a few participants also adopted typical user-centered design methods. However, most participants demonstrated a system-centric rather than a user-centric view. Understanding the diverse needs and consolidating various feedback of end-users posed unique challenges for the OSS contributors when addressing usability in the most recent development context. Our work provided important insights for OSS practitioners and tool designers in exploring ways for promoting a user-centric mindset and improving usability practice in the current OSS communities.",1937-4194,,10.1109/MS.2020.3009514,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140320,,Usability;Tools;Open source software;Graphical user interfaces;Instruments;Guidelines,,,,,,,,14 Jul 2020,,,IEEE,IEEE Early Access Articles
1818,457,Toward Solving Social and Technical Problems in Open Source Software Ecosystems: Using Cause-and-Effect Analysis to Disentangle the Causes of Complex Problems,J. Marsan; M. Templier; P. Marois; B. Adams; K. Carillo; G. L. Mopenza,"Information Systems, Universite Laval, Canada; Information Systems, Universite Laval, Canada; Information Systems, Universite Laval, Canada; Software Engineering, Polytechnique Montreal, Canada; Toulouse Business School, France; Universite Laval, Canada",IEEE Software,15 Jan 2019,2019,36,1,34,41,"Many open source software (OSS) products today are market leaders, 1 which suggests that the development of OSS is key to the growth of the software industry. OSS projects increasingly tend to be incorporated in large-scale projects or ""software ecosystems"" to reduce effort and accelerate innovation.",1937-4194,,10.1109/MS.2018.2874323,Fonds de Recherche du Québec - Fonds de la Recherche Scientifique; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491285,Open source software;software ecosystem;cause-and-effect analysis;code quality;loss of contributors,Ecosystems;Open source software;Agile software development;Linux;Sociotechnical systems,DP industry;project management;public domain software;software development management,social problems;technical problems;open source software ecosystems;software industry;OSS projects;cause-and-effect analysis;open source software products;OSS ecosystem management,,,,15.0,,14 Oct 2018,,,IEEE,IEEE Magazines
1819,458,"Tailoring Product Ownership in Large-Scale Agile Projects: Managing Scale, Distance, and Governance",J. M. Bass; A. Haxby,"Software Engineering, University of Salford, Salford, United Kingdom; Competa, The Hague, The Netherlands",IEEE Software,21 Feb 2019,2019,36,2,58,63,"In large-scale agile projects, product owners undertake a range of challenging and varied activities beyond those conventionally associated with that role. We describe product-owner activities and behaviors that are valued by experienced product owners and their line managers.",1937-4194,,10.1109/MS.2018.2885524,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648277,,Agile software development;Companies;Standards;Stakeholders;Software development,organisational aspects;project management;risk management;software development management;software prototyping,product ownership;large-scale agile projects;varied activities;product-owner activities;experienced product owners,,,,12.0,,21 Feb 2019,,,IEEE,IEEE Magazines
1820,460,Principle of Least Expressiveness,G. Fairbanks,"Software Engineering, Google",IEEE Software,16 Apr 2019,2019,36,3,116,119,"I'm always delighted to discover a connection between two ideas that I'm already fond of on their own, so I'd like to share a connection I found recently. The first idea is writing code that expresses my thinking about the problem domain, and the second is the principle of least expressiveness (PLE). The connection is that I can use the PLE to reveal my thinking about the problem domain, and because all ambiguity stops at the code, the act of programming using the PLE can help me simplify and debug the flawed ideas I have in my head.",1937-4194,,10.1109/MS.2019.2896876,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693078,,Decoding;Pragmatics;Computational modeling;Software development management;Programming;Resource description framework,program debugging,least expressiveness;problem domain;PLE;flawed ideas,,1.0,,3.0,,16 Apr 2019,,,IEEE,IEEE Magazines
1821,461,Next-Generation Software Verification: An AI Perspective,S. Nejati,"University of Ottawa, and University of Luxembourg",IEEE Software,19 Apr 2021,2021,38,3,126,130,"In recent years, automated software verification has progressed significantly. We can now effectively explore complex software structures through automated testing or to prove properties of complex programs, such as compilers using formal methods. But, for the most part, software testing and formal software verification techniques have advanced independently with relatively few insights on how their research thrusts compare or can be combined.",1937-4194,,10.1109/MS.2021.3049322,NSERC Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407305,,Software testing;Program processors;Software engineering;Artificial intelligence;Next generation networking,,,,,,13.0,IEEE,19 Apr 2021,,,IEEE,IEEE Magazines
1822,462,What Do We Know About Time Pressure in Software Development?,M. Kuutila; M. Mantyla; U. Farooq; M. Claes,"ITEE/M3S, Oulun Yliopisto, Oulu, Oulun lääni, Finland; Computer Science, Oulun Yliopisto Teknillinen Tiedekunta, Oulu, 90014 Pohjois-Pohjanmaa, Finland; ITEE/M3S, Oulun Yliopisto, Oulu, Oulun lääni, Finland; ITEE/M3S, Oulun Yliopisto, Oulu, Oulun lääni, Finland",IEEE Software,,2020,PP,99,0,0,"Time Pressure means that time experienced by an individual is scarce in relation to the task demands at hand. In this article, we summarize findings and provide practitioner takeaways based on a systematic review of existing literature. We find that most empirical evidence supports reduced quality, increased productivity, and negative effects on individuals under time pressure. Time pressure is caused by company culture, poor effort estimates, and project management. The effects of time pressure can be explained by Challenge and Hindrance time pressure, the Yerkes-Dodson Law and The Job Demands-Resources model. Finally we conclude the article by giving practitioner takeaways related to minimizing the negative effects of time pressure.",1937-4194,,10.1109/MS.2020.3020784,KAUTE-Säätiö; Academy of Finland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184214,,Software engineering;Software;Task analysis;Companies;Estimation;Project management;Schedules,,,,,,,,1 Sep 2020,,,IEEE,IEEE Early Access Articles
1823,463,Is Requirements-Engineering Research Delivering What It Promised?: A Review of Its Accomplishments and Opportunities After 10 Years,B. Tenbergen; M. Daun,"Computer Science, State University of New York at Oswego, United States; University of Duisburg-Essen, Germany",IEEE Software,17 Jun 2019,2019,36,4,6,11,"In the 1990s, it was recognized that requirements engineering (RE) laid the foundation for high-quality software. Since then, a substantial research community has formed and set out to enable pract it ioners in the 21st century to systematically adopt proven strategies to solve common development challenges and to enable the engineering of innovative solutions and product features. But is contemporary RE research producing what it set out to deliver? In this article, we provide a brief overview over the accomplishments of the past 10 years and identify open opportunities.",1937-4194,,10.1109/MS.2019.2909127,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738149,,Software systems;Requirements engineering;Software engineering;Engineering education,formal specification;software quality,requirements engineering;high-quality software;RE research,,,,8.0,,17 Jun 2019,,,IEEE,IEEE Magazines
1824,464,Correction,,,IEEE Software,15 Apr 2020,2020,37,3,92,92,"In the “Guest Editors’ Introduction” column published in the January/February issue of IEEE Software [1], the guest editors mistakenly omitted the name of the third guest editor: Smita Ghaisas should have been included in the byline as follows: Rick Kazman, Liliana Pasquale, and Smita Ghaisas. The omitted bio is included here.",1937-4194,,10.1109/MS.2020.2971895,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068302,,Software engineering;Object recognition;Requirements engineering;Software;Cloud computing;Data mining;Web 2.0,,,,,,1.0,,15 Apr 2020,,,IEEE,IEEE Magazines
1825,465,Sentiment Classification Using N-Gram Inverse Document Frequency and Automated Machine Learning,R. Maipradit; H. Hata; K. Matsumoto,"Information Science, Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Science and Technology, Nara Institute of Science and Technology, Japan",IEEE Software,15 Aug 2019,2019,36,5,65,70,"We propose a sentiment classification method with a general machine-learning framework. In comparison to publicly available data sets, our method achieved the highest F1 values in positive and negative sentences on all data sets.",1937-4194,,10.1109/MS.2019.2919573,Japan Society for the Promotion of Science; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725481,Automated machine learning;N-gram IDF;Sentiment classification,Classification;Machine learning;Feature extraction;Software engineering;Training data;Sentiment analysis;Machine learning,learning (artificial intelligence);pattern classification;sentiment analysis,sentiment classification method;general machine-learning framework;data sets;n-gram inverse document frequency;automated machine learning;positive sentences;negative sentences,,,,14.0,,29 May 2019,,,IEEE,IEEE Magazines
1826,466,"Conference Highlights: JIT Fault Prevention, Motivated Modeling, Security in Requirements, and Improving Team Performance",J. C. Carver; B. Penzenstadler; L. L. Minku; R. Colomo-Palacios; X. Larrucea,"Computer Science, University of Alabama, United States; Chalmers/Gothenburg University, Sweden; Computer Science, University of Birmingham; Computer Sciences, Ostfold University College, Halden, Norway; Basque Research and Technology Alliance, TECNALIA, Spain",IEEE Software,19 Jun 2020,2020,37,4,83,86,"This issue's practitioners' Digest reports on papers from the 2018 International Conference on Mining Sof tware Repositories, the 2019 International Conference on Requirements Engineering, and the 2019 European Conference on Software Process Improvement. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in this article, please send me and the author(s) of the paper(s) a note about your experiences.",1937-4194,,10.1109/MS.2020.2986840,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121617,,Security;Software engineering;Requirements engineering;Cloning;Big Data;Computer science;Data mining,,,,,,4.0,,19 Jun 2020,,,IEEE,IEEE Magazines
1827,467,"Release Early, Release Often, and Watch Your Users' Emotions: Lessons From Emotional Patterns",D. Martens; W. Maalej,"Applied Software Technology, University of Hamburg, Germany; Applied Software Technology, University of Hamburg, Germany",IEEE Software,15 Aug 2019,2019,36,5,32,37,"App stores are highly competitive markets, and unexpected app changes might incite even loyal users to explore alternative apps. In this article, we present five release lessons, from emotional patterns identified using sentiment analysis tools, to assist app vendors maintain positive emotions and gain competitive advantages.",1937-4194,,10.1109/MS.2019.2923603,European Union Horizon 2020 Project OpenReq; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738898,,Emotion recognition;Software tools;Software engineering;Sentiment analysis;Market research;Google;Computer applications,emotion recognition;mobile computing;sentiment analysis,app stores;alternative apps;emotional patterns;sentiment analysis tools;app vendors;users emotions,,4.0,,15.0,,18 Jun 2019,,,IEEE,IEEE Magazines
1828,468,Combined Intuition and Rationality Increases Software Feature Novelty for Female Software Designers,C. Pretorius; M. Razavian; K. Eling; F. Langerak,"Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands; Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands; Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands; Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands",IEEE Software,15 Feb 2021,2021,38,2,64,69,"Different cognitive styles can promote novelty when designing software. Through a detailed experiment, we found that female practitioners who had a preference for more than one cognitive style (intuition and rationality) produced the most novel software features of all the participants.",1937-4194,,10.1109/MS.2020.3043663,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286837,,Software engineering;Task analysis;Software design;Particle measurements;Atmospheric measurements;Informatics,gender issues;software development management,software features;software feature novelty;cognitive style;female practitioners;detailed experiment;female software designers,,,,15.0,IEEE,8 Dec 2020,,,IEEE,IEEE Magazines
1829,469,Test Fatigue,G. J. Holzmann,Nimble Research,IEEE Software,19 Jun 2020,2020,37,4,11,16,"As the recent coronavirus outbreak has made painfully clear, the quantity and quality of our test efforts determine what defect rates we measure. If you don't test, or test poorly, you will discover few defects and may be tempted to draw the wrong conclusions about the quality of whatever it was that you were testing.",1937-4194,,10.1109/MS.2020.2986107,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121619,,Complexity theory;Measurement;Switches;Software engineering;Standards;Reliability;Software testing,diseases;epidemics;fatigue;medical computing;testing,test fatigue;defect rates;coronavirus outbreak,,,,7.0,,19 Jun 2020,,,IEEE,IEEE Magazines
1830,470,Coverage Prediction for Accelerating Compiler Testing,J. Chen; G. Wang; D. Hao; Y. Xiong; H. Zhang; L. Zhang; B. Xie,"Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China; University of Newcastle, Newcastle, NSW, Australia; Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,261,278,"Compilers are one of the most fundamental software systems. Compiler testing is important for assuring the quality of compilers. Due to the crucial role of compilers, they have to be well tested. Therefore, automated compiler testing techniques (those based on randomly generated programs) tend to run a large number of test programs (which are test inputs of compilers). The cost for compilation and execution for these test programs is significant. These techniques can take a long period of testing time to detect a relatively small number of compiler bugs. That may cause many practical problems, e.g., bringing a lot of costs including time costs and financial costs, and delaying the development/release cycle. Recently, some approaches have been proposed to accelerate compiler testing by executing test programs that are more likely to trigger compiler bugs earlier according to some criteria. However, these approaches ignore an important aspect in compiler testing: different test programs may have similar test capabilities (i.e., testing similar functionalities of a compiler, even detecting the same compiler bug), which may largely discount their acceleration effectiveness if the test programs with similar test capabilities are executed all the time. Test coverage is a proper approximation to help distinguish them, but collecting coverage dynamically is infeasible in compiler testing since most test programs are generated on the fly by automatic test-generation tools like Csmith. In this paper, we propose the first method to predict test coverage statically for compilers, and then propose to prioritize test programs by clustering them according to the predicted coverage information. The novel approach to accelerating compiler testing through coverage prediction is called COP (short for COverage Prediction). Our evaluation on GCC and LLVM demonstrates that COP significantly accelerates compiler testing, achieving an average of 51.01 percent speedup in test execution time on an existing dataset including three old release versions of the compilers and achieving an average of 68.74 percent speedup on a new dataset including 12 latest release versions. Moreover, COP outperforms the state-of-the-art acceleration approach significantly by improving $17.16\%\sim 82.51\%$17.16%∼82.51% speedups in different settings on average.",1939-3520,,10.1109/TSE.2018.2889771,National Key Research and Development Program of China; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8588375,Compiler testing;test prioritization;machine learning,Testing;Program processors;Computer bugs;Life estimation;Acceleration;Optimization;Electromagnetic interference,,,,3.0,,86.0,IEEE,25 Dec 2018,,,IEEE,IEEE Journals
1831,471,Automatic Mining of Opinions Expressed About APIs in Stack Overflow,G. Uddin; F. Khomh,"School of Computer Science, McGill University, Montreal, QC, Canada; SWAT Team, Ecole Polytechnique de Montréal, QC, Canada",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,522,559,"With the proliferation of online developer forums, developers share their opinions about the APIs they use. The plethora of such information can present challenges to the developers to get quick but informed insights about the APIs. To understand the potential benefits of such API reviews, we conducted a case study of opinions in Stack Overflow using a benchmark dataset of 4,522 sentences. We observed that opinions about diverse API aspects (e.g., usability) are prevalent and offer insights that can shape developers' perception and decisions related to software development. Motivated by the finding, we built a suite of techniques to automatically mine and categorize opinions about APIs from forum posts. First, we detect opinionated sentences in the forum posts. Second, we associate the opinionated sentences to the API mentions. Third, we detect API aspects (e.g., performance, usability) in the reviews. We developed and deployed a tool called Opiner, supporting the above techniques. Opiner is available online as a search engine, where developers can search for APIs by their names to see all the aggregated opinions about the APIs that are automatically mined and summarized from developer forums.",1939-3520,,10.1109/TSE.2019.2900245,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643972,API;opinion;categorization;review;API aspect;API review mining,Benchmark testing;Usability;Search engines;Java;Data mining;Tools,application program interfaces;data handling;data mining;natural language processing;search engines;text analysis,aggregated opinions;opinionated sentences;forum posts;software development;developers;diverse API aspects;API reviews;quick but informed insights;online developer forums;Stack Overflow;opinions expressed,,6.0,,124.0,IEEE,19 Feb 2019,,,IEEE,IEEE Journals
1832,472,"A Systematic Literature Review on Bad Smells–5 W's: Which, When, What, Who, Where",E. V. d. P. Sobrinho; A. De Lucia; M. d. A. Maia,"Department of Electrical Engineering, Federal University of Triângulo Mineiro, Uberaba, Brazil; University of Salerno, Fisciano, (SA), Italy; Faculty of Computing, Federal University of Uberlândia, Uberlândia, Brazil",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,17,66,"Bad smells are sub-optimal code structures that may represent problems needing attention. We conduct an extensive literature review on bad smells relying on a large body of knowledge from 1990 to 2017. We show that some smells are much more studied in the literature than others, and also that some of them are intrinsically inter-related (which). We give a perspective on how the research has been driven across time (when). In particular, while the interest in duplicated code emerged before the reference publications by Fowler and Beck and by Brown et al., other types of bad smells only started to be studied after these seminal publications, with an increasing trend in the last decade. We analyzed aims, findings, and respective experimental settings, and observed that the variability of these elements may be responsible for some apparently contradictory findings on bad smells (what). Moreover, we could observe that, in general, papers tend to study different types of smells at once. However, only a small percentage of those papers actually investigate possible relations between the respective smells (co-studies), i.e., each smell tends to be studied in isolation. Despite of a few relations between some types of bad smells have been investigated, there are other possible relations for further investigation. We also report that authors have different levels of interest in the subject, some of them publishing sporadically and others continuously (who). We observed that scientific connections are ruled by a large “small world” connected graph among researchers and several small disconnected graphs. We also found that the communities studying duplicated code and other types of bad smells are largely separated. Finally, we observed that some venues are more likely to disseminate knowledge on Duplicate Code (which often is listed as a conference topic on its own), while others have a more balanced distribution among other smells (where). Finally, we provide a discussion on future directions for bad smell research.",1939-3520,,10.1109/TSE.2018.2880977,Fundação de Amparo à Pesquisa do Estado de Minas Gerais; Conselho Nacional de Desenvolvimento Científico e Tecnológico; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532309,Software maintenance;reengineering;bad smell,Systematics;Bibliographies;Software;Measurement;Organizations;Tools;Cloning,graph theory;program diagnostics;software maintenance,systematic literature review;bad smells;duplicated code;possible relations;bad smell research;suboptimal code structures;small world connected graph,,2.0,,417.0,IEEE,11 Nov 2018,,,IEEE,IEEE Journals
1833,473,Efficient Summary Reuse for Software Regression Verification,F. He; Q. Yu; L. Cai,"School of Software, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: hefei@tsinghua.edu.cn); School of Software, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: yuqianshan@foxmail.com); School of Software, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: limingcai0101@yeah.net)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Software systems evolve throughout their life cycles. Many revisions are produced over time. Verifying each revision of the software is impractical. Regression verification suggests reusing intermediate results from the previous verification runs. This paper studies regression verification via summary reuse. Not only procedure summaries, but also loop summaries are proposed to be reused. This paper proposes a fully automatic regression verification technique in the context of CEGAR. A lazy counterexample analysis technique is developed to improve the efficiency of summary reuse. We performed extensive experiments on two large sets of industrial programs (3,675 revisions of 488 Linux kernel device drivers). Results show that our summary reuse technique saves 84% to 93% analysis time of the regression verification.",1939-3520,,10.1109/TSE.2020.3021477,National Natural Science Foundation of China; National Key RD Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186032,Regression Verification;Program Verification;Abstraction Refinement;Summary Reuse,Task analysis;Performance evaluation;Linux;Device drivers;Safety;Interpolation,,,,,,,,3 Sep 2020,,,IEEE,IEEE Early Access Articles
1834,474,"Adaptive Test Case Allocation, Selection and Generation Using Coverage Spectrum and Operational Profile",A. Bertolino; B. Miranda; R. Pietrantuono; S. Russo,"ISTI - CNR, Pisa, PI, Italy; Federal University of Pernambuco, Recife, PE, Brazil; Università degli Studi di Napoli Federico II, Napoli, Italy; Università degli Studi di Napoli Federico II, Napoli, Italy",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,881,898,"We present an adaptive software testing strategy for test case allocation, selection and generation, based on the combined use of operational profile and coverage spectrum, aimed at achieving high delivered reliability of the program under test. Operational profile-based testing is a black-box technique considered well suited when reliability is a major concern, as it selects the test cases having the largest impact on failure probability in operation. Coverage spectrum is a characterization of a program’s behavior in terms of the code entities (e.g., branches, statements, functions) that are covered as the program executes. The proposed strategy - named covrel+ - complements operational profile information with white-box coverage measures, so as to adaptively select/generate the most effective test cases for improving reliability as testing proceeds. We assess covrel+ through experiments with subjects commonly used in software testing research, comparing results with traditional operational testing. The results show that exploiting operational and coverage data in an integrated adaptive way allows generally to outperform operational testing at achieving a given reliability target, or at detecting faults under the same testing budget, and that covrel+ has greater ability than operational testing in detecting hard-to-detect faults.",1939-3520,,10.1109/TSE.2019.2906187,PRIN 2015; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669842,Software testing;reliability;operational testing;random testing;sampling,Software reliability;Resource management;Software testing;Subspace constraints;Test pattern generators,,,,,,51.0,IEEE,19 Mar 2019,,,IEEE,IEEE Journals
1835,475,Leveraging Historical Associations between Requirements and Source Code to Identify Impacted Classes,D. Falessi; J. Roll; J. L. C. Guo; J. Cleland-Huang,"California Polytechnic State University, San Luis Obispo, CA, USA; California Polytechnic State University, San Luis Obispo, CA, USA; School of Computer Science, McGill University, Montreal, QC, Canada; Computer Science and Engineering, University of Notre Dame, South Bend, IN, USA",IEEE Transactions on Software Engineering,16 Apr 2020,2020,46,4,420,441,"As new requirements are introduced and implemented in a software system, developers must identify the set of source code classes which need to be changed. Therefore, past effort has focused on predicting the set of classes impacted by a requirement. In this paper, we introduce and evaluate a new type of information based on the intuition that the set of requirements which are associated with historical changes to a specific class are likely to exhibit semantic similarity to new requirements which impact that class. This new Requirements to Requirements Set (R2RS) family of metrics captures the semantic similarity between a new requirement and the set of existing requirements previously associated with a class. The aim of this paper is to present and evaluate the usefulness of R2RS metrics in predicting the set of classes impacted by a requirement. We consider 18 different R2RS metrics by combining six natural language processing techniques to measure the semantic similarity among texts (e.g., VSM) and three distribution scores to compute overall similarity (e.g., average among similarity scores). We evaluate if R2RS is useful for predicting impacted classes in combination and against four other families of metrics that are based upon temporal locality of changes, direct similarity to code, complexity metrics, and code smells. Our evaluation features five classifiers and 78 releases belonging to four large open-source projects, which result in over 700,000 candidate impacted classes. Experimental results show that leveraging R2RS information increases the accuracy of predicting impacted classes practically by an average of more than 60 percent across the various classifiers and projects.",1939-3520,,10.1109/TSE.2018.2861735,Cal Poly SURP; Cal Poly RSCA; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423658,Impact analysis;mining software repositories;traceability,Measurement;Semantics;Natural language processing;Complexity theory;Open source software;Task analysis,public domain software;software maintenance;software metrics;software quality;text analysis,historical associations;impacted classes;source code classes;semantic similarity;existing requirements;R2RS metrics;leveraging R2RS information;requirements to requirements set;VSM;open-source projects,,,,122.0,IEEE,31 Jul 2018,,,IEEE,IEEE Journals
1836,476,Identifying Failure-Causing Schemas in the Presence of Multiple Faults,X. Niu; C. Nie; J. Y. Lei; H. Leung; X. Wang,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA; Department of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Computer Science, University of Texas at San Antonio, San Antonio, TX, USA",IEEE Transactions on Software Engineering,12 Feb 2020,2020,46,2,141,162,"Combinatorial testing (CT) has been proven effective in revealing the failures caused by the interaction of factors that affect the behavior of a system. The theory of Minimal Failure-Causing Schema (MFS) has been proposed to isolate the cause of a failure after CT. Most algorithms that aim to identify MFS focus on handling a single fault in the System Under Test (SUT). However, we argue that multiple faults are more common in practice, under which masking effects may be triggered so that some failures cannot be observed. The traditional MFS theory lacks a mechanism to handle such effects; hence, they may incorrectly isolate the MFS. To address this problem, we propose a new MFS model that takes into account multiple faults. We first formally analyze the impact of the multiple faults on existing MFS identifying algorithms, especially in situations where masking effects are triggered by multiple faults. We then develop an approach that can assist traditional algorithms to better handle multiple faults. Empirical studies were conducted using several kinds of open-source software, which showed that multiple faults with masking effects do negatively affect traditional MFS identifying approaches and that our approach can help to alleviate these effects.",1939-3520,,10.1109/TSE.2018.2844259,National Key Research and Development Plan; National Science Foundation; U.S. Department of Homeland Security; National Institute of Standards and Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372636,Software testing;combinatorial testing;failure-causing schemas;masking effects,Testing;Bars;Fault diagnosis;Computer bugs;Software algorithms;Open source software,fault diagnosis;program testing;software fault tolerance,masking effects;MFS theory;minimal failure-causing schema;combinatorial testing;CT;system under test;SUT;open-source software,,4.0,,51.0,IEEE,5 Jun 2018,,,IEEE,IEEE Journals
1837,477,How Developers Choose Names,D. Feitelson; A. Mizrahi; N. Noy; A. Ben Shabat; O. Eliyahu; R. Sheffer,"Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: feit@cs.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: ayelet.mizrahi@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: nofar.noy@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: aviad.benshabat@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: or.eliyahu@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: roysheffer7@gmail.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The names of variables and functions serve as implicit documentation and are instrumental for program comprehension. But choosing good meaningful names is hard. We perform a sequence of experiments in which a total of 334 subjects are required to choose names in given programming scenarios. The first experiment shows that the probability that two developers would select the same name is low: in the 47 instances in our experiments the median probability was only 6.9%. At the same time, given that a specific name is chosen, it is usually understood by the majority of developers. Analysis of the names given in the experiment suggests a model where naming is a (not necessarily cognizant or serial) three-step process: (1) selecting the concepts to include in the name, (2) choosing the words to represent each concept, and (3) constructing a name using these words. A followup experiment, using the same experimental setup, then checked whether using this model explicitly can improve the quality of names. The results were that names selected by subjects using the model were judged by two independent judges to be superior to names chosen in the original experiment by a ratio of two-to-one. Using the model appears to encourage the use of more concepts and longer names.",1939-3520,,10.1109/TSE.2020.2976920,Israel Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018121,variable naming;code comprehension,Programming profession;Documentation;Natural languages;Unified modeling language,,,,,,,,28 Feb 2020,,,IEEE,IEEE Early Access Articles
1838,478,Service Candidate Identification from Monolithic Systems Based on Execution Traces,W. Jin; T. Liu; Y. Cai; R. Kazman; R. Mo; Q. Zheng,"Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xian, Shaanxi, China; Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xian, Shaanxi, China; Department of Computer Science, Drexel University, Philadelphia, PA, USA; Department of Information Technology Management, University of Hawaii, Honolulu, HI, USA; Department of Computer Science, Drexel University, Philadelphia, PA, USA; Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xian, Shaanxi, China",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,987,1007,"Monolithic systems increasingly suffer from maintainability and scalability issues as they grow in functionality, size, and complexity. It is widely believed that (micro)service-based architectures can alleviate these problems as each service is supposed to have the following characteristics: clearly defined functionality, sufficient modularity, and the ability to evolve independently. Industrial practices show that service extraction from a legacy monolithic system is labor-intensive and complex. Existing work on service candidate identification aims to group entities of a monolithic system into potential service candidates, but this process has two major challenges: first, it is difficult to extract service candidates with consistent quality; second, it is hard to evaluate the identified service candidates regarding the above three characteristics. To address these challenges, this paper proposes the Functionality-oriented Service Candidate Identification (FoSCI) framework to identify service candidates from a monolithic system. Our approach is to record the monolith's execution traces, and extract services candidates using a search-based functional atom grouping algorithm. We also contribute a comprehensive service candidate evaluation suite that uses interface information, structural/conceptual dependency, and commit history. This evaluation system consists of 8 metrics, measuring functionality, modularity, and evolvability respectively of identified service candidates. We compare FoSCI with three existing methods, using 6 widely-used open-source projects as our evaluation subjects. Our results show that FoSCI outperforms existing methods in most measures.",1939-3520,,10.1109/TSE.2019.2910531,National Key Research and Development Program of China; National Natural Science Foundation of China; Ministry of Education Innovation Research Team; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686152,Microservice;monolith decomposition;service candidate;execution trace;functionality;modularity;evolvability,Software;Atomic measurements;Frequency measurement;Testing;Computer architecture;History,,,,7.0,,52.0,IEEE,11 Apr 2019,,,IEEE,IEEE Journals
1839,479,Semantic Learning and Emulation Based Cross-platform Binary Vulnerability Seeker,J. Gao; Y. Jiang; Z. Liu; X. Yang; C. Wang; X. Jiao; Z. Yang; J. Sun,"School of Software, Institute of Software System and Engineering, Beijing, Beijing China (e-mail: gaojian094@gmail.com); Dept.CST, Tsinghua university, Beijing, Beijing China 100084 (e-mail: jiangyu198964@126.com); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: zhe.liu@nuaa.edu.cn); School of Software, Institute of Software System and Engineering, Beijing, Beijing China (e-mail: yangx16@mails.tsinghua.edu.cn); School of Software, Institute of Software System and Engineering, Beijing, Beijing China (e-mail: wangcong15@mails.tsinghua.edu.cn); Computer Science and Engineering, ucsd, Sandiego, California United States (e-mail: xujiao@eng.ucsd.edu); Computer Science, Western Michigan University, Kalamazoo, Michigan United States 49008 (e-mail: zijiang.yang@wmich.edu); School of Software, Tsinghua University, Beijing 100084, Beijing China (e-mail: sunjg@tsinghua.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Clone detection is widely exploited for software vulnerability search. The approaches based on source code analysis cannot be applied to binary clone detection because the same source code can produce significantly different binaries due to different operating systems, microprocessor architectures and compilers. In this paper, we present BinSeeker, a cross-platform binary seeker that integrates semantic learning and emulation. With the help of the labeled semantic flow graph, BinSeeker can quickly identify M candidate functions that are most similar to the vulnerability from the target binary. The value of M is relatively large so this semantic learning procedure essentially eliminates those functions that are very unlikely to have the vulnerability. Then, semantic emulation is conducted on these M candidates to obtain their dynamic signature sequences. By comparing signature sequences, BinSeeker produces top-N functions that exhibit most similar behavior to that of the vulnerability. With fast filtering of semantic learning and accurate comparison of semantic emulation, BinSeeker seeks vulnerability precisely with little overhead. The experiments on six widely used programs with fifteen known CVE vulnerabilities demonstrate that BinSeeker outperforms three state-of-the-art tools Genius, Gemini and CACompare.",1939-3520,,10.1109/TSE.2019.2956932,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918305,semantic emulation;semantic learning;cross-platform binary;vulnerability search;neural network,Drilling machines;Process control;Automation;Rocks;Tools,,,,1.0,,,,2 Dec 2019,,,IEEE,IEEE Early Access Articles
1840,480,Today Was a Good Day: The Daily Life of Software Developers,A. N. Meyer; E. T. Barr; C. Bird; T. Zimmermann,"Department of Informatics, University of Zurich, Zürich, Switzerland; University College London, London, United Kingdom; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,863,880,"What is a good workday for a software developer? What is a typical workday? We seek to answer these two questions to learn how to make good days typical. Concretely, answering these questions will help to optimize development processes and select tools that increase job satisfaction and productivity. Our work adds to a large body of research on how software developers spend their time. We report the results from 5,971 responses of professional developers at Microsoft, who reflected about what made their workdays good and typical, and self-reported about how they spent their time on various activities at work. We developed conceptual frameworks to help define and characterize developer workdays from two new perspectives: good and typical. Our analysis confirms some findings in previous work, including the fact that developers actually spend little time on development and developers’ aversion for meetings and interruptions. It also discovered new findings, such as that only 1.7 percent of survey responses mentioned emails as a reason for a bad workday, and that meetings and interruptions are only unproductive during development phases; during phases of planning, specification and release, they are common and constructive. One key finding is the importance of agency, developers’ control over their workday and whether it goes as planned or is disrupted by external factors. We present actionable recommendations for researchers and managers to prioritize process and tool improvements that make good workdays typical. For instance, in light of our finding on the importance of agency, we recommend that, where possible, managers empower developers to choose their tools and tasks.",1939-3520,,10.1109/TSE.2019.2904957,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666786,Software developer workdays;productivity;job satisfaction;good workdays;typical workdays;quantified workplace,Software;Productivity;Task analysis;Encoding;Tools;Collaboration;Birds,,,,4.0,,111.0,IEEE,13 Mar 2019,,,IEEE,IEEE Journals
1841,481,Automatic Generation of Tests to Exploit XML Injection Vulnerabilities in Web Applications,S. Jan; A. Panichella; A. Arcuri; L. Briand,"University of Luxembourg, Esch-sur-Alzette, Luxembourg; University of Luxembourg, Esch-sur-Alzette, Luxembourg; University of Luxembourg, Esch-sur-Alzette, Luxembourg; University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Software Engineering,16 Apr 2019,2019,45,4,335,362,"Modern enterprise systems can be composed of many web services (e.g., SOAP and RESTful). Users of such systems might not have direct access to those services, and rather interact with them through a single-entry point which provides a GUI (e.g., a web page or a mobile app). Although the interactions with such entry point might be secure, a hacker could trick such systems to send malicious inputs to those internal web services. A typical example is XML injection targeting SOAP communications. Previous work has shown that it is possible to automatically generate such kind of attacks using search-based techniques. In this paper, we improve upon previous results by providing more efficient techniques to generate such attacks. In particular, we investigate four different algorithms and two different fitness functions. A large empirical study, involving also two industrial systems, shows that our technique is effective at automatically generating XML injection attacks.",1939-3520,,10.1109/TSE.2017.2778711,European Research Council (ERC); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125155,Evolutionary testing;XML injection;security testing,XML;Simple object access protocol;Testing;Service-oriented architecture,business data processing;graphical user interfaces;mobile computing;security of data;Web services;XML,search-based techniques;industrial systems;XML injection attacks;XML injection vulnerabilities;modern enterprise systems;single-entry point;mobile app;hacker;malicious inputs;SOAP communications;fitness functions;GUI;internal Web services;Web page;Web applications,,2.0,,71.0,,30 Nov 2017,,,IEEE,IEEE Journals
1842,482,Observation-Enhanced QoS Analysis of Component-Based Systems,C. Paterson; R. Calinescu,"Department of Computer Science, University of York, Heslington, York, United Kingdom; Department of Computer Science, University of York, Heslington, York, United Kingdom",IEEE Transactions on Software Engineering,14 May 2020,2020,46,5,526,548,"We present a new method for the accurate analysis of the quality-of-service (QoS) properties of component-based systems. Our method takes as input a QoS property of interest and a high-level continuous-time Markov chain (CTMC) model of the analysed system, and refines this CTMC based on observations of the execution times of the system components. The refined CTMC can then be analysed with existing probabilistic model checkers to accurately predict the value of the QoS property. The paper describes the theoretical foundation underlying this model refinement, the tool we developed to automate it, and two case studies that apply our QoS analysis method to a service-based system implemented using public web services and to an IT support system at a large university, respectively. Our experiments show that traditional CTMC-based QoS analysis can produce highly inaccurate results and may lead to invalid engineering and business decisions. In contrast, our new method reduced QoS analysis errors by 84.4-89.6 percent for the service-based system and by 94.7-97 percent for the IT support system, significantly lowering the risk of such invalid decisions.",1939-3520,,10.1109/TSE.2018.2864159,Defence Science and Technology Laboratory; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428471,Quality of service;component-based systems;Markov models;probabilistic model checking,Quality of service;Unified modeling language;Analytical models;Markov processes;Probabilistic logic;Component architectures,formal verification;Markov processes;object-oriented programming;probability;quality of service;Web services,observation-enhanced QoS analysis;component-based systems;quality-of-service properties;high-level continuous-time Markov chain model;probabilistic model checkers;model refinement;service-based system;public Web services;IT support system;CTMC-based QoS analysis,,,,74.0,IEEE,7 Aug 2018,,,IEEE,IEEE Journals
1843,483,Mining Likely Analogical APIs Across Third-Party Libraries via Large-Scale Unsupervised API Semantics Embedding,C. Chen; Z. Xing; Y. Liu; K. O. L. Xiong,"Faculty of Information Technology, Monash University, Clayton, VIC, Australia; College of Engineering & Computer Science, Australian National University, Canberra, ACT, Australia; SCSE, Nanayng Technological University, Singapore; SCSE, Nanayng Technological University, Singapore",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,432,447,"Establishing API mappings between third-party libraries is a prerequisite step for library migration tasks. Manually establishing API mappings is tedious due to the large number of APIs to be examined. Having an automatic technique to create a database of likely API mappings can significantly ease the task. Unfortunately, existing techniques either adopt supervised learning mechanism that requires already-ported or functionality similar applications across major programming languages or platforms, which are difficult to come by for an arbitrary pair of third-party libraries, or cannot deal with lexical gap in the API descriptions of different libraries. To overcome these limitations, we present an unsupervised deep learning based approach to embed both API usage semantics and API description (name and document) semantics into vector space for inferring likely analogical API mappings between libraries. Based on deep learning models trained using tens of millions of API call sequences, method names and comments of 2.8 millions of methods from 135,127 GitHub projects, our approach significantly outperforms other deep learning or traditional information retrieval (IR) methods for inferring likely analogical APIs. We implement a proof-of-concept website (https://similarapi.appspot.com) which can recommend analogical APIs for 583,501 APIs of 111 pairs of analogical Java libraries with diverse functionalities. This scale of third-party analogical-API database has never been achieved before.",1939-3520,,10.1109/TSE.2019.2896123,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630054,Analogical API;word embedding;skip thoughts,Libraries;Semantics;Databases;Task analysis;Recurrent neural networks;Deep learning;Java,application program interfaces;data mining;database management systems;deep learning (artificial intelligence);Java;software libraries;unsupervised learning,unsupervised API semantics embedding;third-party analogical-API database;analogical Java libraries;API call sequences;analogical API mappings;API usage semantics;unsupervised deep learning;API descriptions;library migration tasks;third-party libraries,,8.0,,84.0,IEEE,30 Jan 2019,,,IEEE,IEEE Journals
1844,484,SQAPlanner: Generating Data-Informed Software Quality Improvement Plans,D. Rajapaksha; C. Tantithamthavorn; C. Bergmeir; W. Buntine; J. Jiarpakdee; J. Grundy,"Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: dilini.rajapakshahewaranasinghage@monash.edu); Information Technology, Monash University, 2541 Clayton, Victoria, Australia, 3800 (e-mail: chakkrit@monash.edu); Information Technology, Monash University, Melbourne, Australia, Melbourne, Victoria, Australia, (e-mail: christoph.bergmeir@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: Wray.Buntine@monash.edu); Information Technology, Monash University, Melbourne, Australia, Melbourne, Victoria, Australia, (e-mail: jirayus.jiarpakdee@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: john.grundy@monash.edu)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Software Quality Assurance (SQA) planning aims to define proactive plans, such as defining maximum file size, to prevent the occurrence of software defects in future releases. To aid this, defect prediction models have been proposed to generate insights as the most important factors that are associated with software quality. Such insights that are derived from traditional defect models are far from actionable---i.e., practitioners still do not know what they should do or avoid to decrease the risk of having defects, and what is the risk threshold for each metric. A lack of actionable guidance and risk threshold can lead to inefficient and ineffective SQA planning processes. In this paper, we investigate the practitioners' perceptions of current SQA planning activities, current challenges of such SQA planning activities, and propose four types of guidance to support SQA planning. We then propose and evaluate our AI-Driven SQAPlanner approach, a novel approach for generating four types of guidance and their associated risk thresholds in the form of rule-based explanations for the predictions of defect prediction models. Finally, we develop and evaluate a visualization for our SQAPlanner approach. Through the use of qualitative survey and empirical evaluation, our results lead us to conclude that SQAPlanner is needed, effective, stable, and practically applicable. We also find that 80% of our survey respondents perceived that our visualization is more actionable. Thus, our SQAPlanner paves a way for novel research in actionable software analytics---i.e., generating actionable guidance on what should practitioners do and not do to decrease the risk of having defects to support SQA planning.",1939-3520,,10.1109/TSE.2021.3070559,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394771,Software Quality Assurance;SQA Planning;Actionable Software Analytics;Explainable AI,Planning;Software;Predictive models;Visualization;Tools;Artificial intelligence;Software quality,,,,,,,IEEE,2 Apr 2021,,,IEEE,IEEE Early Access Articles
1845,485,Two-Phase Assessment Approach to Improve the Efficiency of Refactoring Identification,A. Han; S. Cha,"Department of Computer Science and Engineering, Korea University, Sungbuk-gu, Seoul, South Korea; Department of Computer Science and Engineering, Korea University, Sungbuk-gu, Seoul, South Korea",IEEE Transactions on Software Engineering,14 Oct 2018,2018,44,10,1001,1023,"To automate the refactoring identification process, a large number of candidates need to be compared. Such an overhead can make the refactoring approach impractical if the software size is large and the computational load of a fitness function is substantial. In this paper, we propose a two-phase assessment approach to improving the efficiency of the process. For each iteration of the refactoring process, refactoring candidates are preliminarily assessed using a lightweight, fast delta assessment method called the Delta Table. Using multiple Delta Tables, candidates to be evaluated with a fitness function are selected. A refactoring can be selected either interactively by the developer or automatically by choosing the best refactoring, and the refactorings are applied one after another in a stepwise fashion. The Delta Table is the key concept enabling a two-phase assessment approach because of its ability to quickly calculate the varying amounts of maintainability provided by each refactoring candidate. Our approach has been evaluated for three large-scale open-source projects. The results convincingly show that the proposed approach is efficient because it saves a considerable time while still achieving the same amount of fitness improvement as the approach examining all possible candidates.",1939-3520,,10.1109/TSE.2017.2731853,Basic Science Research Program; National Research Foundation of Korea (NRF); Ministry of Education; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990580,Refactoring assessment;refactoring identification;maintainability improvement,Measurement;Couplings;Symmetric matrices;Open source software;Computational efficiency;System analysis and design,iterative methods;public domain software;software maintenance,two-phase assessment approach;refactoring identification process;fitness function;computational load;delta assessment method;lightweight method;delta table;large-scale open-source projects,,,,60.0,,25 Jul 2017,,,IEEE,IEEE Journals
1846,486,Kernel Spectral Embedding Transfer Ensemble for Heterogeneous Defect Prediction,H. Tong; B. Liu; S. Wang,"School of Reliability and Systems Engineering, Beihang University, 12633 Beijing, Beijing China 100083 (e-mail: tonghaonan@buaa.edu.cn); School of Reliability and Systems Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: liubin@buaa.edu.cn); School of Reliability and Systems Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: wangshihai@buaa.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Cross-project defect prediction (CPDP) refers to predicting defects in the target project lacking of defect data by using prediction models trained on the historical defect data of other projects (i.e., source data). However, CPDP requires the source and target projects have common metric set (CPDP-CM). Recently, heterogeneous defect prediction (HDP) has drawn the increasing attention, which predicts defects across projects having heterogeneous metric sets. However, building high-performance HDP methods remains a challenge owing to several serious challenges including class imbalance problem, nonlinear, and the distribution differences between source and target datasets. In this paper, we propose a novel kernel spectral embedding transfer ensemble (KSETE) approach for HDP. KSETE first addresses the class-imbalance problem of the source data and then tries to find the latent common feature space for the source and target datasets by combining kernel spectral embedding, transfer learning, and ensemble learning. Experiments are performed on 22 public projects in both HDP and CPDP-CM scenarios in terms of multiple well-known performance measures such as, AUC, G-Measure, and MCC. The experimental results show that (1) KSETE improves the performance over previous HDP methods by at least 22.7%, 138.9%, and 494.4% in terms of AUC, G-Measure, and MCC, respectively. (2) KSETE improves the performance over previous CPDP-CM methods by at least 4.5%, 30.2%, and 17.9% in AUC, G-Measure, and MCC, respectively. It can be concluded that the proposed KSETE is very effective in both the HDP scenario and the CPDP-CM scenario.",1939-3520,,10.1109/TSE.2019.2939303,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823052,heterogeneous defect prediction;cross-project defect prediction;class imbalance learning;spectral embedding;transfer learning;ensemble learning;multiple kernel learning,Kernel;Predictive models;Software metrics;Correlation;Buildings;Data models,,,,1.0,,,,3 Sep 2019,,,IEEE,IEEE Early Access Articles
1847,487,Evolution of the Unix System Architecture: An Exploratory Case Study,D. Spinellis; P. C. Avgeriou,"Department of Management Science and Technology, Athens University of Economics and Business, Athina, Attiki Greece (e-mail: dds@aueb.gr); Department of Mathematics and Computing Science, University of Groningen, Groningen, groningen Netherlands 9747 AG (e-mail: paris@cs.rug.nl)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Unix has evolved for almost five decades, shaping modern operating systems, key software technologies, and development practices. Studying the evolution of this remarkable system from an architectural perspective can provide insights on how to manage the growth of large, complex, and long-lived software systems. Along main Unix releases leading to the FreeBSD lineage we examine core architectural design decisions, the number of features, and code complexity, based on the analysis of source code, reference documentation, and related publications. We report that the growth in size has been uniform, with some notable outliers, while cyclomatic complexity has been religiously safeguarded. A large number of Unix-defining design decisions were implemented right from the very early beginning, with most of them still playing a major role. Unix continues to evolve from an architectural perspective, but the rate of architectural innovation has slowed down over the system's lifetime. Architectural technical debt has accrued in the forms of functionality duplication and unused facilities, but in terms of cyclomatic complexity it is systematically being paid back through what appears to be a self-correcting process. Some unsung architectural forces that shaped Unix are the emphasis on conventions over rigid enforcement, the drive for portability, a sophisticated ecosystem of other operating systems and development organizations, and the emergence of a federated architecture, often through the adoption of third-party subsystems. These findings have led us to form an initial theory on the architecture evolution of large, complex operating system software.",1939-3520,,10.1109/TSE.2019.2892149,Horizon 2020 Framework Programme; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704965,Unix;Software Architecture;Software Evolution;Architecture Design Decisions;Operating Systems,Computer architecture;Complexity theory;Evolution (biology);Linux;Kernel,,,,,,,CCBY,2 May 2019,,,IEEE,IEEE Early Access Articles
1848,488,A Look into Programmers’ Heads,N. Peitek; J. Siegmund; S. Apel; C. Kästner; C. Parnin; A. Bethmann; T. Leich; G. Saake; A. Brechmann,"Leibniz Institute for Neurobiology Magdeburg, Magdeburg, Germany; University of Passau, Passau, Germany; University of Passau, Passau, Germany; Carnegie Mellon University, Pittsburgh, PA, USA; NC State University, Raleigh, NC, USA; Leibniz Institute for Neurobiology Magdeburg, Magdeburg, Germany; Metop Research Institute, Magdeburg, Germany; University of Magdeburg, Magdeburg, Germany; Leibniz Institute for Neurobiology Magdeburg, Magdeburg, Germany",IEEE Transactions on Software Engineering,20 Apr 2020,2020,46,4,442,462,"Program comprehension is an important, but hard to measure cognitive process. This makes it difficult to provide suitable programming languages, tools, or coding conventions to support developers in their everyday work. Here, we explore whether functional magnetic resonance imaging (fMRI) is feasible for soundly measuring program comprehension. To this end, we observed 17 participants inside an fMRI scanner while they were comprehending source code. The results show a clear, distinct activation of five brain regions, which are related to working memory, attention, and language processing, which all fit well to our understanding of program comprehension. Furthermore, we found reduced activity in the default mode network, indicating the cognitive effort necessary for program comprehension. We also observed that familiarity with Java as underlying programming language reduced cognitive effort during program comprehension. To gain confidence in the results and the method, we replicated the study with 11 new participants and largely confirmed our findings. Our results encourage us and, hopefully, others to use fMRI to observe programmers and, in the long run, answer questions, such as: How should we train programmers? Can we train someone to become an excellent programmer? How effective are new languages and tools for program comprehension?",1939-3520,,10.1109/TSE.2018.2863303,"DFG; Bavarian State Ministry of Education, Science; DFG; National Science Foundation; AFRL and DARPA; ERC; National Science Foundation; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425769,Functional magnetic resonance imaging;program comprehension,Functional magnetic resonance imaging;Task analysis;Cognition;Brain;Programming;Blood,biomedical MRI;brain;cognition;Java;medical computing;neurophysiology,default mode network;Java;programming language reduced cognitive effort;language processing;working memory;brain regions;fMRI scanner;programming language;program comprehension;functional magnetic resonance imaging,,1.0,,112.0,IEEE,6 Aug 2018,,,IEEE,IEEE Journals
1849,489,Empirical Assessment of Multimorphic Testing,P. Temple; M. Acher; J. M. Jezequel,"Faculty of Computer Science, University of Namur, 54501 Namur, Belgium Belgium (e-mail: paul.temple@unamur.be); Computer Science, University of Rennes 1 / Inria / IRISA, Rennes, Ille et Vilaine France 35200 (e-mail: mathieu.acher@irisa.fr); Computer Science, University of Rennes 1 / Inria / IRISA, Rennes, Ille et Vilaine France (e-mail: Jean-Marc.Jezequel@irisa.fr)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The performance of software systems (such as speed, memory usage, correct identification rate) tends to be an evermore important concern, often nowadays on par with functional correctness for critical systems.Systematically testing these performance concerns is however extremely difficult, in particular because there exists no theory underpinning the evaluation of a performance test suite, i.e., to tell the software developer whether such a test suite is ""good enough"" or even whether a test suite is better than another one. This paper proposes to apply Multimorphic testing and empirically assess the effectiveness of performance test suites of software systems coming from various domains. By analogy with mutation testing, our core idea is to leverage the typical configurability of these systems, and to check whether it makes any difference in the outcome of the tests: i.e., are some tests able to ""kill"" underperforming system configurations? More precisely, we propose a framework for defining and evaluating the coverage of a test suite with respect to a quantitative property of interest. Such properties can be the execution time, the memory usage or the success rate in tasks performed by a software system. This framework can be used to assess whether a new test case is worth adding to a test suite or to select an optimal test suite with respect to a property of interest. We evaluate several aspects of our proposal through 3 empirical studies carried out in different fields: object tracking in videos, object recognition in images, and code generators.",1939-3520,,10.1109/TSE.2019.2926971,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8755468,software product lines;software testing;performance testing;test evaluation,Testing;Software measurement;Software systems;Videos;Task analysis;Generators,,,,,,,,4 Jul 2019,,,IEEE,IEEE Early Access Articles
1850,490,An Integration Test Order Strategy to Consider Control Coupling,S. JIANG; M. Zhang; Y. Zhang; R. Wang; Q. Yu; J. W. Keung,"School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China 221116 (e-mail: shjjiang@cumt.edu.cn); Computer Science, City University of Hong Kong, 53025 Kowloon, Hong Kong Hong Kong (e-mail: miazhang9-c@my.cityu.edu.hk); Mine Digitization Engineering Research Center of the Ministry of Education, School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: ymzhang@cumt.edu.cn); School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: rcwang@cumt.edu.cn); school of Computer Science and technology, Jiangsu Normal University, 12675 Xuzhou, Jiangsu China (e-mail: yuqiao@jsnu.edu.cn); Department of Computer Science, City University of Hong Kong, Kowloon, Kowloon Tong Hong Kong KLN (e-mail: Jacky.Keung@cityu.edu.hk)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Integration testing is a very important step in software testing. Existing methods evaluate the stubbing cost for class inte-gration test orders by considering only the interclass direct relationships such as inheritance, aggregation, and associa-tion, but they omit the interclass indirect relationship caused by control coupling, which can also affect the test orders and the stubbing cost. In this paper, we introduce an integration test order strategy to consider control coupling. We ad-vance the concept of transitive relationship to describe this kind of interclass dependency and propose a new measure-ment method to estimate the complexity of control coupling, which is the complexity of stubs created for a transitive rela-tionship. We evaluate our integration test order strategy on 10 programs on various scales. The results show that consid-ering the transitive relationship when generating class integration test orders can significantly reduce the stubbing cost for most programs and that our integration test order strategy obtains satisfactory results more quickly than other methods.",1939-3520,,10.1109/TSE.2019.2921965,National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province under grant; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734013,control coupling;integration test order;software testing;stubbing cost,Couplings;Complexity theory;Measurement;Marine vehicles;Mathematical model;Software testing,,,,,,,,10 Jun 2019,,,IEEE,IEEE Early Access Articles
1851,491,Recommending Participants for Collaborative Merge Sessions,C. d. S. Costa; J. J. Figueiredo; J. F. Pimentel; A. Sarma; L. G. P. Murta,"Technology and Exacts Science Center, Universidade Federal do Acre, 37872 Rio Branco, Rio Branco Brazil (e-mail: catarinasouzacosta@gmail.com); Computing Institute, Universidade Federal do Acre, 37872 Rio Branco, AC Brazil (e-mail: jjcfigueiredo@ufac.br); Computing Institute, Fluminense Federal University, Niterói, Rio de Janeiro Brazil (e-mail: jpimentel@ic.uff.br); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: anita.sarma@oregonstate.edu); Computer Science, Universidade Federal Fluminense, Niterói, RJ Brazil 24210-240 (e-mail: leomurta@ic.uff.br)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Development of large projects often involves parallel work performed in multiple branches. Eventually, these branches need to be reintegrated through a merge operation. During merge, conflicts may arise and developers need to communicate to reach consensus about the desired resolution. For this reason, including the right developers to a collaborative merge session is fundamental. However, this task can be difficult especially when many different developers have made significant changes on each branch over a large number of files. In this paper, we present TIPMerge, an approach designed to recommend participants for collaborative merge sessions. TIPMerge analyzes the project history and builds a ranked list of developers who are the most appropriate to integrate a pair of branches (Developer Ranking) by considering developers' changes in the branches, in the previous history, and in the dependencies among files across branches. Simply selecting the top developers in such a ranking is easy, but is not effective for collaborative merge sessions as the top developers may have overlapping knowledge. To support collaborative merge, TIPMerge employs optimization techniques to recommend developers with complementary knowledge (Team Recommendation) aiming to maximize joint knowledge coverage. Our results show a mean normalized improvement of 49.5% (median 50.4%) for the joint knowledge coverage with the optimization techniques for assembling teams of three developers for collaborative merge in comparison to choosing the top-3 developers in the ranked list.",1939-3520,,10.1109/TSE.2019.2917191,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716294,Version Control;Branch Merging;Collaborative Merge;Developer Recommendation;Optimization,Collaboration;History;Optimization;Data mining;Merging;Task analysis;Software,,,,,,,,16 May 2019,,,IEEE,IEEE Early Access Articles
1852,492,makeSense: Simplifying the Integration of Wireless Sensor Networks into Business Processes,L. Mottola; G. P. Picco; F. J. Oppermann; J. Eriksson; N. Finne; H. Fuchs; A. Gaglione; S. Karnouskos; P. M. Montero; N. Oertel; K. Römer; P. Spieß; S. Tranquillini; T. Voigt,"RISE Swedish Institute of Computer Science, Kista, Sweden; University of Trento, Trento, Italy; Graz University of Technology, Ultimo, NSW, Australia; RISE Swedish Institute of Computer Science, Kista, Sweden; RISE Swedish Institute of Computer Science, Kista, Sweden; SAP, Walldorf, Germany; University of Trento, Trento, Italy; SAP, Walldorf, Germany; Acciona Infraestructuras S.A. Alcobendas, Madrid, Spain; SAP, Walldorf, Germany; Graz University of Technology, Ultimo, NSW, Australia; SAP, Walldorf, Germany; University of Trento, Trento, Italy; RISE Swedish Institute of Computer Science, Kista, Sweden",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,576,596,"A wide gap exists between the state of the art in developing Wireless Sensor Network (WSN) software and current practices concerning the design, execution, and maintenance of business processes. WSN software is most often developed based on low-level OS abstractions, whereas business process development leverages high-level languages and tools. This state of affairs places WSNs at the fringe of industry. The makeSense system addresses this problem by simplifying the integration of WSNs into business processes. Developers use BPMN models extended with WSN-specific constructs to specify the application behavior across both traditional business process execution environments and the WSN itself, which is to be equipped with application-specific software. We compile these models into a high-level intermediate language-also directly usable by WSN developers-and then into OS-specific deployment-ready binaries. Key to this process is the notion of meta-abstraction, which we define to capture fundamental patterns of interaction with and within the WSN. The concrete realization of meta-abstractions is application-specific; developers tailor the system configuration by selecting concrete abstractions out of the existing codebase or by providing their own. Our evaluation of makeSense shows that i) users perceive our approach as a significant advance over the state of the art, providing evidence of the increased developer productivity when using makeSense; ii) in large-scale simulations, our prototype exhibits an acceptable system overhead and good scaling properties, demonstrating the general applicability of makeSense; and, iii) our prototype-including the complete tool-chain and underlying system support-sustains a real-world deployment where estimates by domain specialists indicate the potential for drastic reductions in the total cost of ownership compared to wired and conventional WSN-based solutions.",1939-3520,,10.1109/TSE.2017.2787585,European Union 7th Framework Programme (FP7-ICT-2009-5); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240710,Business processes;wireless sensor networks;embedded software;internet of things,Wireless sensor networks;Business;Programming;Ventilation;Software;Concrete,business data processing;operating systems (computers);wireless sensor networks,wireless sensor networks;business processes;WSN software;low-level OS abstractions;makeSense system;WSN-specific constructs;application-specific software;OS-specific deployment-ready binaries;meta-abstraction;concrete abstractions;complete tool-chain;wired WSN-based solutions;high-level intermediate language;developer productivity;WSN developers;business process execution environments;business process development;high-level languages,,,,93.0,,27 Dec 2017,,,IEEE,IEEE Journals
1853,493,Debugging of Behavioural Models using Counterexample Analysis,G. Barbon; V. Leroy; G. Salaun,"LIG, Universite Grenoble Alpes, 27015 Saint-Martin-d'Heres, Rhone-Alpes France (e-mail: gianluca.barbon@gmail.com); LIG, Universite Grenoble Alpes, 133618 Saint-Martin-d'Heres, Rhone-Alpes France (e-mail: vincent.leroy@imag.fr); LIG, Universite Grenoble Alpes, 27015 Saint-Martin-d'Heres, Rhone-Alpes France (e-mail: gwen.salaun@inria.fr)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Model checking is an established technique for automatically verifying that a model satisfies a given temporal property. When the model violates the property, the model checker returns a counterexample, which is a sequence of actions leading to a state where the property is not satisfied. Understanding this counterexample for debugging the specification is a complicated task for several reasons: (i) the counterexample can contain a large number of actions, (ii) the debugging task is mostly achieved manually, and (iii) the counterexample does not explicitly highlight the source of the bug that is hidden in the model. This article presents a new approach that improves the usability of model checking by simplifying the comprehension of counterexamples. To do so, we first extract in the model all the counterexamples. Second, we define an analysis algorithm that identifies actions that make the model skip from incorrect to correct behaviours, making these actions relevant from a debugging perspective. Third, we develop a set of abstraction techniques to extract these actions from counterexamples. Our approach is fully automated by a tool we implemented and was applied on real-world case studies from various application areas for evaluation purposes.",1939-3520,,10.1109/TSE.2019.2915303,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708934,,Computer bugs;Debugging;Safety;Model checking;Task analysis;Tools;Analytical models,,,,,,,,7 May 2019,,,IEEE,IEEE Early Access Articles
1854,494,Combinatorial Test Generation for Multiple Input Models with Shared Parameters,C. Rao; N. Li; Y. Lei; J. Guo; Y. Zhang; R. Kacker; D. R. R. Kuhn,"School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan, China, 611756 (e-mail: changrao@my.swjtu.edu.cn); Research and Development, Dassault Systems, New York, New York, United States, (e-mail: nli1@gmu.edu); Computer Science and Engineering, The University of Texas at Arlington, Arlington, Texas, United States, 76019 (e-mail: ylei@cse.uta.edu); School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan, China, (e-mail: jguo_scce@home.swjtu.edu.cn); School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan, China, (e-mail: ydzhang@home.swjtu.edu.cn); math division, National Institute of Standards & Technology, Gaithersburg, Maryland, United States, (e-mail: raghu.kacker@nist.gov); computer security division, National Institute of Standards & Technology, Gaithersburg, Maryland, United States, 20899 (e-mail: kuhn@nist.gov)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Combinatorial testing typically considers a single input model and creates a single test set that achieves t-way coverage. This paper addresses the problem of combinatorial test generation for multiple input models with shared parameters. We formally define the problem and propose an efficient approach to generating multiple test sets, one for each input model, that together satisfy t-way coverage for all of these input models while minimizing the amount of redundancy between these test sets. We report an experimental evaluation that applies our approach to five real-world applications. The results show that our approach can significantly reduce the amount of redundancy between the test sets generated for multiple input models and perform better than a post-optimization approach.",1939-3520,,10.1109/TSE.2021.3065950,Fundamental Research Funds for the Central Universities; China State Railway Corporation; China Scholarship Council; National Natural Science Foundation of China; National Institute of Standards and Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380551,Combinatorial Testing;T-way Test Generation;Multiple Input Models;Shared Parameters,Testing;Test pattern generators;Redundancy;Tools;Schedules;Presses;Information science,,,,,,,IEEE,17 Mar 2021,,,IEEE,IEEE Early Access Articles
1855,495,Managing Episodic Volunteers in Free/Libre/Open Source Software Communities,A. Barcomb; K. Stol; B. Fitzgerald; D. Riehle,"Open Source Research Group, Friedrich-Alexander-Universitat Erlangen-Nurnberg Technische Fakultat, 88768 Erlangen, Bayern Germany (e-mail: ann@barcomb.org); Computer Science, University College Cork, Cork, Cork Ireland (e-mail: klaas-jan.stol@lero.ie); CSIS, Lero Irish Software Research Centre, Limerick, Limerick Ireland (e-mail: brian.fitzgerald@ul.ie); Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, 9171 Erlangen, Bavaria Germany 91058 (e-mail: dirk@riehle.org)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"We draw on the concept of episodic volunteering (EV) from the general volunteering literature to identify practices for managing EV in free/libre/open source software (FLOSS) communities. Infrequent but ongoing participation is widespread, but the practices that community managers are using to manage EV, and their concerns about EV, have not been previously documented. We conducted a policy Delphi study involving 24 FLOSS community managers from 22 different communities. Our panel identified 16 concerns related to managing EV in FLOSS, which we ranked by prevalence. We also describe 65 practices for managing EV in FLOSS. Almost three-quarters of these practices are used by at least three community managers. We report these practices using a systematic presentation that includes context, relationships between practices, and concerns that they address. These findings provide a coherent framework that can help FLOSS community managers to better manage episodic contributors.",1939-3520,,10.1109/TSE.2020.2985093,Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057411,best practices;community management;episodic volunteering;free software;open source software,Software;Computer bugs;Organizations;Systematics;Lenses;Sustainable development;Object recognition,,,,,,,,6 Apr 2020,,,IEEE,IEEE Early Access Articles
1856,496,Detecting Bugs by Discovering Expectations and Their Violations,P. Bian; B. Liang; Y. Zhang; C. Yang; W. Shi; Y. Cai,"Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; State Key Laboratory of Computer Science, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,16 Oct 2019,2019,45,10,984,1001,"Code mining has been proven to be a promising approach to inferring implicit programming rules for finding software bugs. However, existing methods may report large numbers of false positives and false negatives. In this paper, we propose a novel approach called EAntMiner to improve the effectiveness of code mining. EAntMiner elaborately reduces noises from statements irrelevant to interesting rules and different implementation forms of the same logic. During preprocessing, we employ program slicing to decompose the original source repository into independent sub-repositories. In each sub-repository, statements irrelevant to critical operations (automatically extracted from source code) are excluded and various semantics-equivalent implementations are normalized into a canonical form as far as possible. Moreover, to tackle the challenge that some bugs are difficult to be detected by mining frequent patterns as rules, we further developed a kNN-based method to identify them. We have implemented EAntMiner and evaluated it on four large-scale C systems. EAntMiner successfully detected 105 previously unknown bugs that have been confirmed by corresponding development communities. A set of comparative evaluations also demonstrate that EAntMiner can effectively improve the precision of code mining.",1939-3520,,10.1109/TSE.2018.2816639,National Natural Science Foundation of China; National 973 program of China; National Science and Technology Major Project of China; Youth Innovation Promotion Association of the Chinese Academy of Sciences; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8318656,Bug detection;code mining;program slicing;instance-based learning,Computer bugs;Data mining;Linux;Programming;Kernel;Semantics,data mining;nearest neighbour methods;program debugging;program slicing;program testing,code mining;implicit programming rules;software bugs;false positives;false negatives;EAntMiner;different implementation forms;frequent pattern mining;unknown bugs;kNN-based method;canonical form;semantics-equivalent implementations;source code;sub-repository;independent sub-repositories;original source repository;program slicing,,3.0,,66.0,,16 Mar 2018,,,IEEE,IEEE Journals
1857,497,The ORIS Tool: Quantitative Evaluation of Non-Markovian Systems,M. Paolieri; M. Biagi; L. Carnevali; E. Vicario,"Department of Computer Science, University of Southern California, 5116 Los Angeles, California United States (e-mail: paolieri@usc.edu); Department of Information Engineering, University of Florence, Florence, Florence Italy (e-mail: marco.biagi@unifi.it); Department of Information Engineering, University of Florence, Florence, Florence Italy 50139 (e-mail: laura.carnevali@unifi.it); Information Engineering department, University of Florence, Florence, Florence Italy 50139 (e-mail: enrico.vicario@unifi.it)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"We present the next generation of ORIS, a toolbox for quantitative evaluation of concurrent models with non-Markovian timers. The tool shifts the focus from timed models to stochastic ones: it includes a new graphical user interface, new analysis methods and a Java Application Programming Interface (API). Models can be specified as Stochastic Time Petri Nets (STPNs) through the graphical editor, validated using an interactive token game, and analyzed through several techniques to compute instantaneous or cumulative rewards. STPNs can also be exported as Java code to conduct extensive parametric studies through the Java library, now distributed as open-source. A well-engineered software architecture allows the user to implement new features for STPNs, new modeling formalisms, and new analysis methods. The most distinctive features of ORIS include transient and steady-state analysis of STPNs modeling Markov Regenerative Processes (MRPs), and transient analysis of STPNs modeling generalized semi-Markov processes. ORIS also supports state-space analysis of time Petri nets, simulation of STPNs, and standard analysis techniques for continuous-time Markov chains or MRPs with at most one non-exponential timer in each state. We illustrate the general workflow for the application of ORIS to the modeling and evaluation of non-functional requirements of software-intensive systems.",1939-3520,,10.1109/TSE.2019.2917202,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719961,Quantitative Evaluation;Formal Methods;Stochastic Models;Concurrency;Stochastic Petri Nets;Non-Markovian Processes;Markov Regenerative Processes;Performance;Reliability;Software Tools and Libraries,Analytical models;Stochastic processes;Transient analysis;Java;Petri nets;Numerical models;Graphical user interfaces,,,,,,,,22 May 2019,,,IEEE,IEEE Early Access Articles
1858,498,Entropy Based Software Reliability Analysis of Multi-Version Open Source Software,V. B. Singh; M. Sharma; H. Pham,"University of Delhi, Delhi, India; University of Delhi, Delhi, India; Department of Industrial and Systems Engineering, Rutgers, State University of New Jersey, Piscataway, NJ",IEEE Transactions on Software Engineering,9 Dec 2018,2018,44,12,1207,1223,"The number of issues fixed in the current release of the software is one of the factors which decides the next release of the software. The source code files get changed during fixing of these issues. The uncertainty arises due to these changes is quantified using entropy based measures. We developed a Non-Homogeneous Poisson Process model for Open Source Software to understand the fixing of issues across releases. Based on this model, optimal release-updating using entropy and maximizing the active user's satisfaction level subject to fixing of issues up to a desired level, is investigated as well. The proposed models have been validated on five products of the Apache open source project. The optimal release time estimated from the proposed model is close to the observed release time at different active user's satisfaction levels. The proposed decision model can assist management to appropriately determine the optimal release-update time. The proposed entropy based model for issues estimation shows improvement in performance for 21 releases out of total 23 releases, when compared with well-known traditional software reliability growth models, namely GO model [1] and S-shaped model [2] . The proposed model is also found statistically significant.",1939-3520,,10.1109/TSE.2017.2766070,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8081836,Entropy;feature improvement;new feature;release time problem;software repositories;cobb-douglas,Entropy;Software reliability;Software product lines;Computer bugs;Open source software,entropy;program diagnostics;public domain software;software maintenance;software reliability;source code (software);stochastic processes,multiversion Open Source Software;source code files;NonHomogeneous Poisson Process model;Apache open source project;GO model;S-shaped model;software reliability analysis;entropy,,4.0,,55.0,,24 Oct 2017,,,IEEE,IEEE Journals
1859,499,Coordination Challenges in Large-Scale Software Development: A Case Study of Planning Misalignment in Hybrid Settings,S. Bick; K. Spohrer; R. Hoda; A. Scheerer; A. Heinzl,"SAP SE, Walldorf, Germany; University of Mannheim, Mannheim, Germany; University of Auckland, Auckland, New Zealand; SAP SE, Walldorf, Germany; University of Mannheim, Mannheim, Germany",IEEE Transactions on Software Engineering,14 Oct 2018,2018,44,10,932,950,"Achieving effective inter-team coordination is one of the most pressing challenges in large-scale software development. Hybrid approaches of traditional and agile development promise combining the overview and predictability of long-term planning on an inter-team level with the flexibility and adaptability of agile development on a team level. It is currently unclear, however, why such hybrids often fail. Our case study within a large software development unit of 13 teams at a global enterprise software company explores how and why a combination of traditional planning on an inter-team level and agile development on a team level can result in ineffective coordination. Based on a variety of data, including interviews with scrum masters, product owners, architects and senior management, and using Grounded Theory data analysis procedures, we identify a lack of dependency awareness across development teams as a key explanation of ineffective coordination. Our findings show how a lack of dependency awareness emerges from misaligned planning activities of specification, prioritization, estimation and allocation between agile team and traditional inter-team levels and ultimately prevents effective coordination. Knowing about these issues, large-scale hybrid projects in similar contexts can try to better align their planning activities across levels to improve dependency awareness and in turn achieve more effective coordination.",1939-3520,,10.1109/TSE.2017.2730870,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990187,Large-scale software development;agile;hybrid;inter-team coordination;dependency awareness;planning alignment;information systems development,Software;Planning;Agile software development;Companies;Task analysis;Interviews,data analysis;project management;software development management;software prototyping;team working,large-scale software development;agile development;long-term planning;inter-team level;software development unit;global enterprise software company;ineffective coordination;agile team;large-scale hybrid projects;coordination challenges;planning misalignment;hybrid settings;effective inter-team coordination;pressing challenges;scrum masters;product owners;architects;senior management;grounded theory data analysis procedures,,5.0,,97.0,,24 Jul 2017,,,IEEE,IEEE Journals
1860,500,An Interleaving Approach to Combinatorial Testing and Failure-Inducing Interaction Identification,X. Niu; C. Nie; H. Leung; Y. Lei; X. Wang; J. Xu; Y. Wang,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science, University of Texas at San Antonio, San Antonio, TX, USA; School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, Jiangsu, China; School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, Jiangsu, China",IEEE Transactions on Software Engineering,15 Jun 2020,2020,46,6,584,615,"Combinatorial testing (CT) seeks to detect potential faults caused by various interactions of factors that can influence the software systems. When applying CT, it is a common practice to first generate a set of test cases to cover each possible interaction and then to identify the failure-inducing interaction after a failure is detected. Although this conventional procedure is simple and forthright, we conjecture that it is not the ideal choice in practice. This is because 1) testers desire to identify the root cause of failures before all the needed test cases are generated and executed 2) the early identified failure-inducing interactions can guide the remaining test case generation so that many unnecessary and invalid test cases can be avoided. For these reasons, we propose a novel CT framework that allows both generation and identification process to interact with each other. As a result, both generation and identification stages will be done more effectively and efficiently. We conducted a series of empirical studies on several open-source software, the results of which show that our framework can identify the failure-inducing interactions more quickly than traditional approaches while requiring fewer test cases.",1939-3520,,10.1109/TSE.2018.2865772,National Key Research and Development Plan; National Science Foundation; U.S. Department of Homeland Security; National Institute of Standards and Technologies Award; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438906,Software testing;combinatorial testing;covering array;failure-inducing interactions,Testing;Software systems;Computer science;Fault diagnosis;Open source software;Indexes,program testing;software fault tolerance,interleaving approach;combinatorial testing;failure-inducing interaction identification;test case generation;CT framework;identification process;failure-inducing interaction,,4.0,,73.0,OAPA,17 Aug 2018,,,IEEE,IEEE Journals
1861,501,SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair,Z. Chen; S. J. Kommrusch; M. Tufano; L. -N. Pouchet; D. Poshyvanyk; M. Monperrus,"Department of Theoretical Computer Science (TCS), Kungliga Tekniska Hogskolan, 7655 Stockholm, Stockholm Sweden (e-mail: zimin@kth.se); Computer Science, Colorado State University, 3447 Fort Collins, Colorado United States 80523-1019 (e-mail: steve.kommrusch@gmail.com); Computer Science, College of William and Mary, 8604 Williamsburg, Virginia United States 23187-8795 (e-mail: mtufano@email.wm.edu); Computer Science, colorado state university, Fort Collins, Colorado United States (e-mail: pouchet@cs.ucla.edu); Computer Science, William and Mary, Williamsburg, Virginia United States 23188 (e-mail: denys@cs.wm.edu); Department of Theoretical Computer Science (TCS), KTH Royal Institute of Technology, 7655 Stockholm, Stockholm Sweden (e-mail: martin.monperrus@csc.kth.se)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a technique, called SEQUENCER, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate SEQUENCER on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SEQUENCER is able to perfectly predict the fixed line for 950/4,711 testing samples, and find correct patches for 14 bugs in Defects4J benchmark. SEQUENCER captures a wide range of repair operators without any domain-specific top-down design.",1939-3520,,10.1109/TSE.2019.2940179,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827954,program repair;machine learning,Maintenance engineering;Computer bugs;Vocabulary;Training;Natural languages;Benchmark testing,,,,14.0,,,IEEE,10 Sep 2019,,,IEEE,IEEE Early Access Articles
1862,502,VT-Revolution: Interactive Programming Video Tutorial Authoring and Watching System,L. Bao; Z. Xing; X. Xia; D. Lo,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; Research School of Computer Science, Australian National University, Canberra, ACT, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Information Systems, Singapore Management University, Singapore",IEEE Transactions on Software Engineering,26 Aug 2019,2019,45,8,823,838,"Procedural knowledge describes actions and manipulations that are carried out to complete programming tasks. An effective way to document procedural knowledge is programming video tutorials. Unlike text-based software artifacts and tutorials that can be effectively searched and linked using information retrieval techniques, the streaming nature of programming videos limits the ways to explore the captured workflows and interact with files, code and program output in the videos. Existing solutions to adding interactive workflow and elements to programming videos have a dilemma between the level of desired interaction and the efforts required for authoring tutorials. In this work, we tackle this dilemma by designing and building a programming video tutorial authoring system that leverages operating system level instrumentation to log workflow history while tutorial authors are creating programming videos, and the corresponding tutorial watching system that enhances the learning experience of video tutorials by providing programming-specific workflow history and timeline-based browsing interactions. Our tutorial authoring system does not incur any additional burden on tutorial authors to make programming videos interactive. Given a programming video accompanied by synchronously-logged workflow history, our tutorial watching system allows tutorial watchers to freely explore the captured workflows and interact with files, code and program output in the tutorial. We conduct a user study of 135 developers to evaluate the design and effectiveness of our system in helping developers learn programming knowledge in video tutorials.",1939-3520,,10.1109/TSE.2018.2802916,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283605,Program comprehension;human-computer interaction;workflow,Tutorials;Programming;Streaming media;Tools;Task analysis;History;Software,authoring systems;computer aided instruction;computer science education;interactive systems;multimedia systems;programming,interactive programming video tutorial authoring;procedural knowledge;video tutorials;text-based software artifacts;authoring tutorials;programming video tutorial authoring system;programming-specific workflow history;programming tasks;tutorial watching system;operating system level instrumentation,,1.0,,43.0,,6 Feb 2018,,,IEEE,IEEE Journals
1863,503,A Deep Learning Model for Estimating Story Points,M. Choetkiertikul; H. K. Dam; T. Tran; T. Pham; A. Ghose; T. Menzies,"Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; Deakin University, Waurn Ponds, VIC, Australia; Deakin University, Waurn Ponds, VIC, Australia; Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; North Carolina State University, Raleigh, NC",IEEE Transactions on Software Engineering,16 Jul 2019,2019,45,7,637,656,"Although there has been substantial research in software analytics for effort estimation in traditional software projects, little work has been done for estimation in agile projects, especially estimating the effort required for completing user stories or issues. Story points are the most common unit of measure used for estimating the effort involved in completing a user story or resolving an issue. In this paper, we propose a prediction model for estimating story points based on a novel combination of two powerful deep learning architectures: long short-term memory and recurrent highway network. Our prediction system is end-to-end trainable from raw input data to prediction outcomes without any manual feature engineering. We offer a comprehensive dataset for story points-based estimation that contains 23,313 issues from 16 open source projects. An empirical evaluation demonstrates that our approach consistently outperforms three common baselines (Random Guessing, Mean, and Median methods) and six alternatives (e.g., using Doc2Vec and Random Forests) in Mean Absolute Error, Median Absolute Error, and the Standardized Accuracy.",1939-3520,,10.1109/TSE.2018.2792473,Mahidol University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255666,Software analytics;effort estimation;story point estimation;deep learning,Project management;Software architecture;Learning (artificial intelligence);Deep learning,learning (artificial intelligence);project management;public domain software;software architecture;software management,software analytics;effort estimation;agile projects;prediction model;end-to-end trainable;story points-based estimation;software projects;open source projects;deep learning architectures;mean absolute error;median absolute error;standardized accuracy,,13.0,,111.0,,12 Jan 2018,,,IEEE,IEEE Journals
1864,504,Smart Contract Development: Challenges and Opportunities,W. Zou; D. Lo; P. S. Kochhar; X. D. Le; X. Xia; Y. Feng; Z. Chen; B. Xu,"State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: wqzou@smail.nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Information Systems, Singapore Management University School of Information Systems, 274434 Singapore, Singapore Singapore (e-mail: kochharps.2012@phdis.smu.edu.sg); School of Computing and Information Systems, The University of Melbourne - Parkville Campus, 2281 Melbourne, Victoria Australia (e-mail: bachldx@cmu.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, Jiangsu China (e-mail: charles.fy0708@gmail.com); State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, Jiangsu China 210093 (e-mail: zychen@nju.edu.cn); Computer, Nanjing University, Nanjing, Jiangsu China (e-mail: bwxu@nju.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Smart contract, a term which was originally coined to refer to the automation of legal contracts in general, has recently seen much interest due to the advent of blockchain technology. Recently, the term is popularly used to refer to low-level code scripts running on a blockchain platform. Our study focuses exclusively on this subset of smart contracts. Such smart contracts have increasingly been gaining ground, finding numerous important applications (e.g., crowdfunding) in the real world. Despite the increasing popularity, smart contract development still remains somewhat a mystery to many developers largely due to its special design and applications. Are there any differences between smart contract development and traditional software development? What kind of challenges are faced by developers during smart contract development? Questions like these are important but have not been explored by researchers yet. In this paper, we performed an exploratory study to understand the current state and potential challenges developers are facing in developing smart contracts on blockchains, with a focus on Ethereum (the most popular public blockchain platform for smart contracts). Toward this end, we conducted this study in two phases. In the first phase, we conducted semi-structured interviews with 20 developers from GitHub and industry professionals who are working on smart contracts. In the second phase, we performed a survey on 232 practitioners to validate the findings from the interviews. Our interview and survey results revealed several major challenges developers are facing during smart contract development: (1) there is no effective way to guarantee the security of smart contract code; (2) existing tools for development are still very basic; (3) the programming languages and the virtual machines still have a number of limitations; (4) performance problems are hard to handle under resource constrained running environment; and (5) online resources (including advanced/updated documents and community support) are still limited. Our study suggests several directions that researchers and practitioners can work on to help improve developers? experience on developing high-quality smart contracts.",1939-3520,,10.1109/TSE.2019.2942301,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847638,Smart Contract;Challenges;Empirical Study;Blockchain,Smart contracts;Blockchain;Law;Interviews;Software,,,,8.0,,,,24 Sep 2019,,,IEEE,IEEE Early Access Articles
1865,505,A Test Case Prioritization Genetic Algorithm Guided by the Hypervolume Indicator,D. Di Nucci; A. Panichella; A. Zaidman; A. De Lucia,"Vrije Universiteit Brussel, Brussels, Belgium; Delft University of Technology, Delft, CD, The Netherlands; Delft University of Technology, Delft, CD, The Netherlands; University of Salerno, Fisciano (SA), Italy",IEEE Transactions on Software Engineering,15 Jun 2020,2020,46,6,674,696,"Regression testing is performed during maintenance activities to assess whether the unchanged parts of a software behave as intended. To reduce its cost, test case prioritization techniques can be used to schedule the execution of the available test cases to increase their ability to reveal regression faults earlier. Optimal test ordering can be determined using various techniques, such as greedy algorithms and meta-heuristics, and optimizing multiple fitness functions, such as the average percentage of statement and branch coverage. These fitness functions condense the cumulative coverage scores achieved when incrementally running test cases in a given ordering using Area Under Curve (AUC) metrics. In this paper, we notice that AUC metrics represent a bi-dimensional (simplified) version of the hypervolume metric, which is widely used in many-objective optimization. Thus, we propose a Hypervolume-based Genetic Algorithm, namely HGA, to solve the Test Case Prioritization problem when using multiple test coverage criteria. An empirical study conducted with respect to five state-of-the-art techniques shows that (i) HGA is more cost-effective, (ii) HGA improves the efficiency of Test Case Prioritization, (iii) HGA has a stronger selective pressure when dealing with more than three criteria.",1939-3520,,10.1109/TSE.2018.2868082,F.R.S.-FNRS and FWO-Vlaanderen EOS Seco-Assist project; STAMP ICT-16-10; NWO TestRoots project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453036,Test case prioritization;genetic algorithm;hypervolume,Measurement;Greedy algorithms;Genetic algorithms;Testing;Software systems;Fault detection,genetic algorithms;greedy algorithms;program testing;regression analysis;statistical testing,hypervolume metric;many-objective optimization;HGA;multiple test coverage criteria;test case prioritization genetic algorithm;hypervolume indicator;regression testing;maintenance activities;regression faults;optimizing multiple fitness functions;AUC metrics;bi-dimensional version;hypervolume-based genetic algorithm;area under curve metrics;software behave,,5.0,,83.0,IEEE,31 Aug 2018,,,IEEE,IEEE Journals
1866,506,The best laid plans or lack thereof: Security decision-making of different stakeholder groups,B. Shreeve; J. Hallett; M. Edwards; K. M. Ramokapane; R. Atkins; A. Rashid,"Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: ben.shreeve@bristol.ac.uk); Bristol Cyber Security Group, University of Bristol, Bristol, Clifton United Kingdom of Great Britain and Northern Ireland BS8 1UB (e-mail: joseph.hallett@bristol.ac.uk); Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: matthew.john.edwards@bristol.ac.uk); Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: marvin.ramokapane@bristol.ac.uk); Cyber Griffin, City of London Police, 89794 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: Richard.Atkins@city-of-london.pnn.police.uk); Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: awais.rashid@bristol.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Cyber security requirements are influenced by the priorities and decisions of a range of stakeholders. Board members and CISOs determine strategic priorities. Managers have responsibility for resource allocation and project management. Legal professionals concern themselves with regulatory compliance. Little is understood about how the security decision-making approaches of these different stakeholders contrast, and if particular groups of stakeholders have a better appreciation of security requirements during decision-making. Are risk analysts better decision makers than CISOs Do security experts exhibit more effective strategies than board members' This paper explores the effect that different experience and diversity of expertise has on the quality of a team's cyber security decision-making and whether teams with members from more varied backgrounds perform better than those with more focused, homogeneous skill sets. Using data from 208 sessions and 948 players of a tabletop game run in the wild by a major national organization over 16 months, we explore how choices are affected by player background (e.g., cyber security experts versus risk analysts, board-level decision makers versus technical experts) and different team make-ups (homogeneous teams of security experts versus various mixes). We find that no group of experts makes significantly better, or even different decisions than anyone else. Instead we discover that experts of all kinds often obsess over technology, becoming fixated on singular issues, regularly failing to fully comprehend what it is they are defending or how the defenses available to them really work.",1939-3520,,10.1109/TSE.2020.3023735,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195777,,Games;Stakeholders;Computer security;Decision making;Organizations;Investment,,,,,,,IEEE,14 Sep 2020,,,IEEE,IEEE Early Access Articles
1867,507,Semantic Slicing of Software Version Histories,Y. Li; C. Zhu; J. Rubin; M. Chechik,"Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada",IEEE Transactions on Software Engineering,12 Feb 2018,2018,44,2,182,201,"Software developers often need to transfer functionality, e.g., a set of commits implementing a new feature or a bug fix, from one branch of a configuration management system to another. That can be a challenging task as the existing configuration management tools lack support for matching high-level, semantic functionality with low-level version histories. The developer thus has to either manually identify the exact set of semantically-related commits implementing the functionality of interest or sequentially port a segment of the change history, “inheriting” additional, unwanted functionality. In this paper, we tackle this problem by providing automated support for identifying the set of semantically-related commits implementing a particular functionality, which is defined by a set of tests. We formally define the semantic slicing problem, provide an algorithm for identifying a set of commits that constitute a slice, and propose techniques to minimize the produced slice. We then instantiate the overall approach, CSlicer, in a specific implementation for Java projects managed in Git and evaluate its correctness and effectiveness on a set of open-source software repositories. We show that it allows to identify subsets of change histories that maintain the functionality of interest but are substantially smaller than the original ones.",1939-3520,,10.1109/TSE.2017.2664824,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7843626,Software changes;version control;dependency;program analysis,History;Semantics;Software;Minimization;Context;Computer bugs;Java,configuration management;Java;program slicing;public domain software,CSlicer;configuration management system;software developers;software version histories;open-source software repositories;semantic slicing problem;semantically-related commits,,9.0,,63.0,,6 Feb 2017,,,IEEE,IEEE Journals
1868,508,ConPredictor: Concurrency Defect Prediction in Real-World Applications,T. Yu; W. Wen; X. Han; J. H. Hayes,"Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,558,575,"Concurrent programs are difficult to test due to their inherent non-determinism. To address this problem, testing often requires the exploration of thread schedules of a program; this can be time-consuming when applied to real-world programs. Software defect prediction has been used to help developers find faults and prioritize their testing efforts. Prior studies have used machine learning to build such predicting models based on designed features that encode the characteristics of programs. However, research has focused on sequential programs; to date, no work has considered defect prediction for concurrent programs, with program characteristics distinguished from sequential programs. In this paper, we present ConPredictor, an approach to predict defects specific to concurrent programs by combining both static and dynamic program metrics. Specifically, we propose a set of novel static code metrics based on the unique properties of concurrent programs. We also leverage additional guidance from dynamic metrics constructed based on mutation analysis. Our evaluation on four large open source projects shows that ConPredictor improved both within-project defect prediction and cross-project defect prediction compared to traditional features.",1939-3520,,10.1109/TSE.2018.2791521,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252721,Concurrency;defect prediction;software quality;software metrics,Concurrent computing;Predictive models;Software;Programming;Testing;Synchronization,concurrency control;program diagnostics;program testing;public domain software;software fault tolerance;software metrics;software quality,real-world programs;software defect prediction;predicting models;sequential programs;concurrent programs;program characteristics;ConPredictor;static program metrics;dynamic program metrics;within-project defect prediction;cross-project defect prediction;concurrency defect prediction;static code metrics;mutation analysis;open source projects,,1.0,,100.0,,9 Jan 2018,,,IEEE,IEEE Journals
1869,509,Rebooting Research on Detecting Repackaged Android Apps: Literature Review and Benchmark,L. Li; T. F. Bissyandé; J. Klein,"Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg",IEEE Transactions on Software Engineering,20 Apr 2021,2021,47,4,676,693,"Repackaging is a serious threat to the Android ecosystem as it deprives app developers of their benefits, contributes to spreading malware on users’ devices, and increases the workload of market maintainers. In the space of six years, the research around this specific issue has produced 57 approaches which do not readily scale to millions of apps or are only evaluated on private datasets without, in general, tool support available to the community. Through a systematic literature review of the subject, we argue that the research is slowing down, where many state-of-the-art approaches have reported high-performance rates on closed datasets, which are unfortunately difficult to replicate and to compare against. In this work, we propose to reboot the research in repackaged app detection by providing a literature review that summarises the challenges and current solutions for detecting repackaged apps and by providing a large dataset that supports replications of existing solutions and implications of new research directions. We hope that these contributions will re-activate the direction of detecting repackaged apps and spark innovative approaches going beyond the current state-of-the-art.",1939-3520,,10.1109/TSE.2019.2901679,"Monash-Warwick Alliance Catalyst Fund (2018/2019); European Union, under the SPARTA project; Fonds National de la Recherche, Luxembourg; University of Luxembourg, under the VulFix project; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653409,Android;repackaging;clone;literature review;benchmark,Bibliographies;Malware;Cloning;Systematics;Tools;Aging;Libraries,,,,7.0,,110.0,IEEE,26 Feb 2019,,,IEEE,IEEE Journals
1870,510,Contract-Based Program Repair without The Contracts: An Extended Study,L. Chen; Y. Pei; C. A. Furia,"Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: cslschen@comp.polyu.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: maximilian.pei@gmail.com); Computer Science and Engineering, Chalmers tekniska hogskola, 11248 Goteborg, Vastra Gotaland Sweden 412 96 (e-mail: furiac@usi.ch)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Most techniques for automated program repair (APR) use tests to drive the repair process; this makes them prone to generating spurious repairs that overfit the available tests unless additional information about expected program behavior is available. Our previous work on JAID, an APR technique for Java programs, showed that constructing detailed state abstractions-similar to those employed by techniques for programs with contracts-from plain Java code without any special annotations provides valuable additional information, and hence helps mitigate the overfitting problem. This paper extends the work on JAID with a comprehensive experimental evaluation involving 693 bugs in three different benchmark suites. The evaluation shows, among other things, that: 1) JAID is effective: it produced correct fixes for over 15% of all bugs, with a precision of nearly 60%; 2) JAID is reasonably efficient: on average, it took less than 30 minutes to output a correct fix; 3) JAID is competitive with the state of the art, as it fixed more bugs than any other technique, and 11 bugs that no other tool can fix; 4) JAID is robust: its heuristics are complementary and their effectiveness does not depend on the fine-tuning of parameters. The experimental results also indicate the main trade-offs involved in designing an APR technique based on tests, as well as possible directions for further progress in this line of work.",1939-3520,,10.1109/TSE.2020.2970009,Schweizerischer Nationalfonds zur Forderung der Wissenschaftlichen Forschung; The Hong Kong Polytechnic University Internal Fund; Research Grants Council University Grants Committee; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972483,,Maintenance engineering;Computer bugs;Tools;Java;Monitoring;Contracts;Programming,,,,,,,,28 Jan 2020,,,IEEE,IEEE Early Access Articles
1871,511,Dynamic Update of Discrete Event Controllers,L. Nahabedian; V. Braberman; N. D'Ippolito; S. Honiden; J. Kramer; K. Tei; S. Uchitel,"FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina; FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina; FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina; National Institute of Informatics, Tokyo, Japan; Department of Computing, Imperial College, London, United Kingdom; National Institute of Informatics, Tokyo, Japan; FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina",IEEE Transactions on Software Engineering,13 Nov 2020,2020,46,11,1220,1240,"Discrete event controllers are at the heart of many software systems that require continuous operation. Changing these controllers at runtime to cope with changes in its execution environment or system requirements change is a challenging open problem. In this paper we address the problem of dynamic update of controllers in reactive systems. We present a general approach to specifying correctness criteria for dynamic update and a technique for automatically computing a controller that handles the transition from the old to the new specification, assuring that the system will reach a state in which such a transition can correctly occur and in which the underlying system architecture can reconfigure. Our solution uses discrete event controller synthesis to automatically build a controller that guarantees both progress towards update and safe update.",1939-3520,,10.1109/TSE.2018.2876843,"ANPCYT; Secretaría de Ciencia y Técnica, Universidad de Buenos Aires; Consejo Nacional de Investigaciones Científicas y Técnicas; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8500345,Controller synthesis;dynamic update;adaptive systems,Tools;Runtime;Paints;Control systems;Business;Safety,control system synthesis;discrete event systems,discrete event controllers;software systems;reactive systems;event controller synthesis,,2.0,,71.0,IEEE,19 Oct 2018,,,IEEE,IEEE Journals
1872,512,Network-Clustered Multi-Modal Bug Localization,T. Hoang; R. J. Oentaryo; T. B. Le; D. Lo,"Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore",IEEE Transactions on Software Engineering,16 Oct 2019,2019,45,10,1002,1023,"Developers often spend much effort and resources to debug a program. To help the developers debug, numerous information retrieval (IR)-based and spectrum-based bug localization techniques have been devised. IR-based techniques process textual information in bug reports, while spectrum-based techniques process program spectra (i.e., a record of which program elements are executed for each test case). While both techniques ultimately generate a ranked list of program elements that likely contain a bug, they only consider one source of information-either bug reports or program spectra-which is not optimal. In light of this deficiency, this paper presents a new approach dubbed Network-clustered Multi-modal Bug Localization (NetML), which utilizes multi-modal information from both bug reports and program spectra to localize bugs. NetML facilitates an effective bug localization by carrying out a joint optimization of bug localization error and clustering of both bug reports and program elements (i.e., methods). The clustering is achieved through the incorporation of network Lasso regularization, which incentivizes the model parameters of similar bug reports and similar program elements to be close together. To estimate the model parameters of both bug reports and methods, NetML employs an adaptive learning procedure based on Newton method that updates the parameters on a per-feature basis. Extensive experiments on 355 real bugs from seven software systems have been conducted to benchmark NetML against various state-of-the-art localization methods. The results show that NetML surpasses the best-performing baseline by 31.82, 22.35, 19.72, and 19.24 percent, in terms of the number of bugs successfully localized when a developer inspects the top 1, 5, and 10 methods and Mean Average Precision (MAP), respectively.",1939-3520,,10.1109/TSE.2018.2810892,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306117,Bug localization;information retrieval;program spectra,Computer bugs;Adaptation models;Optimization;Debugging;Task analysis;Computational modeling;Information retrieval,information retrieval;learning (artificial intelligence);Newton method;program debugging,Network-clustered Multimodal Bug Localization;NetML;multimodal information;effective bug localization;bug localization error;bug reports;information retrieval-based bug localization techniques;bug localization techniques;IR-based techniques process textual information;program spectra;spectrum-based techniques process;program elements;mean average precision,,5.0,,81.0,,2 Mar 2018,,,IEEE,IEEE Journals
1873,513,Chaff from the Wheat: Characterizing and Determining Valid Bug Reports,Y. Fan; X. Xia; D. Lo; A. E. Hassan,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang Sheng, China; Faculty of Information Technology, Monash University, Melbourne, Australia; School of Information Systems, Singapore Management University, Singapore; School of Computing, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,14 May 2020,2020,46,5,495,525,"Developers use bug reports to triage and fix bugs. When triaging a bug report, developers must decide whether the bug report is valid (i.e., a real bug). A large amount of bug reports are submitted every day, with many of them end up being invalid reports. Manually determining valid bug report is a difficult and tedious task. Thus, an approach that can automatically analyze the validity of a bug report and determine whether a report is valid can help developers prioritize their triaging tasks and avoid wasting time and effort on invalid bug reports. In this study, motivated by the above needs, we propose an approach which can determine whether a newly submitted bug report is valid. Our approach first extracts 33 features from bug reports. The extracted features are grouped along 5 dimensions, i.e., reporter experience, collaboration network, completeness, readability and text. Based on these features, we use a random forest classifier to identify valid bug reports. To evaluate the effectiveness of our approach, we experiment on large-scale datasets containing a total of 560,697 bug reports from five open source projects (i.e., Eclipse, Netbeans, Mozilla, Firefox and Thunderbird). On average, across the five datasets, our approach achieves an F1-score for valid bug reports and F1-score for invalid ones of 0.74 and 0.67, respectively. Moreover, our approach achieves an average AUC of 0.81. In terms of AUC and F1-scores for valid and invalid bug reports, our approach statistically significantly outperforms two baselines using features that are proposed by Zanetti et al. [104] . We also study the most important features that distinguish valid bug reports from invalid ones. We find that the textual features of a bug report and reporter's experience are the most important factors to distinguish valid bug reports from invalid ones.",1939-3520,,10.1109/TSE.2018.2864217,National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428477,Bug report;feature generation;machine learning,Computer bugs;Feature extraction;Collaboration;Forestry;Support vector machines;Task analysis;Software,feature extraction;program debugging,bug reports;feature extraction;AUC,,6.0,,109.0,IEEE,7 Aug 2018,,,IEEE,IEEE Journals
1874,514,A Theoretical and Empirical Analysis of Program Spectra Diagnosability,A. Perez; R. Abreu; A. Van Deursen,"Faculty of Engineering, University of Porto, Porto, Portugal; INESC-ID and Instituto Superior Ténico, University of Lisbon, Lisbon, Portugal; Delft University of Technology, Delft, The Netherlands",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,412,431,"Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines, branches, paths) covered by the suite, but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric, called DDU, aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability, i.e., the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites, so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. We have performed a topology-based simulation of thousands of spectra and have found that DDU can effectively establish an upper bound on the effort to diagnose faults. Furthermore, our empirical experiments using the Defects4J dataset show that optimizing a test suite with respect to DDU yields a 34 percent gain in spectrum-based fault localization report accuracy when compared to the standard branch-coverage metric.",1939-3520,,10.1109/TSE.2019.2895640,Fundação para a Ciência e Tecnologia; FaultLocker Project; FCT scholarship; EU Project STAMP; 4TU project; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8627980,Testing;coverage;diagnosability,Software;Measurement uncertainty;Diversity reception;Cognition;Current measurement;Tools,fault diagnosis;program debugging;program diagnostics;program testing;software fault tolerance,DDU;adequacy measurements;fault-localization techniques;test suite;program spectra diagnosability;test-suite;spectrum-based fault localization techniques;fault isolation;branch-coverage metric;bug location,,,,54.0,IEEE,27 Jan 2019,,,IEEE,IEEE Journals
1875,515,Automated Documentation of Android Apps,E. Aghajani; G. Bavota; M. Linares-Vásquez; M. Lanza,"Università della Svizzera italiana (USI), Lugano, Switzerland; Università della Svizzera italiana (USI), Lugano, Switzerland; Universidad de los Andes, Bogotá, Colombia; Università della Svizzera italiana (USI), Lugano, Switzerland",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,204,220,"Developers do not always have the knowledge needed to understand source code and must refer to different resources (e.g., teammates, documentation, the web). This non-trivial process, called program comprehension, is very time-consuming. While many approaches support the comprehension of a given code at hand, they are mostly focused on defining extractive summaries from the code (i.e., on selecting from a given piece of code the most important statements/comments to comprehend it). However, if the information needed to comprehend the code is not there, their usefulness is limited. We present ADANA, an approach to automatically inject comments describing a given piece of Android code. ADANA reuses the descriptions of similar and well-documented code snippets retrieved from various online resources. Our evaluation has shown that ADANA is able to aid the program comprehension process.",1939-3520,,10.1109/TSE.2018.2890652,Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598894,Program comprehension;documentation;Android,Knowledge based systems;Documentation;Java;Cloning;Asia;Task analysis;Data mining,Android (operating system);document handling;Internet;mobile computing;program diagnostics;query processing;reverse engineering;software maintenance,program comprehension process;online resources;well-documented code snippets;Android code;ADANA;given piece;defining extractive summaries;given code;called program comprehension;nontrivial process;teammates;source code;android apps;automated documentation,,1.0,,71.0,IEEE,1 Jan 2019,,,IEEE,IEEE Journals
1876,516,Are Fix-Inducing Changes a Moving Target? A Longitudinal Case Study of Just-In-Time Defect Prediction,S. McIntosh; Y. Kamei,"Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; Principles of Software Languages Group (POSL), Kyushu University, Fukuoka, Japan",IEEE Transactions on Software Engineering,14 May 2018,2018,44,5,412,428,"Just-In-Time (JIT) models identify fix-inducing code changes. JIT models are trained using techniques that assume that past fix-inducing changes are similar to future ones. However, this assumption may not hold, e.g., as system complexity tends to accrue, expertise may become more important as systems age. In this paper, we study JIT models as systems evolve. Through a longitudinal case study of 37,524 changes from the rapidly evolving Qt and OpenStack systems, we find that fluctuations in the properties of fix-inducing changes can impact the performance and interpretation of JIT models. More specifically: (a) the discriminatory power (AUC) and calibration (Brier) scores of JIT models drop considerably one year after being trained; (b) the role that code change properties (e.g., Size, Experience) play within JIT models fluctuates over time; and (c) those fluctuations yield over- and underestimates of the future impact of code change properties on the likelihood of inducing fixes. To avoid erroneous or misleading predictions, JIT models should be retrained using recently recorded data (within three months). Moreover, quality improvement plans should be informed by JIT models that are trained using six months (or more) of historical data, since they are more resilient to period-specific fluctuations in the importance of code change properties.",1939-3520,,10.1109/TSE.2017.2693980,Natural Sciences and Engineering Research Council of Canada (NSERC); JSPS KAKENHI; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898457,Just-In-Time prediction;defect prediction;mining software repositories,Predictive models;Data models;Software;Complexity theory;Market research;Context modeling;Calibration,data mining;just-in-time;learning (artificial intelligence);public domain software;software management;software quality;source code (software),Just-In-Time models;fix-inducing code changes;code change properties;target moving;just-in-time defect prediction;fix-inducing changes;JIT models;OpenStack systems;Qt systems;mining software repositories,,21.0,,48.0,,12 Apr 2017,,,IEEE,IEEE Journals
1877,517,MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction,K. E. Bennin; J. Keung; P. Phannachitta; A. Monden; S. Mensah,"Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, Thailand; Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong",IEEE Transactions on Software Engineering,12 Jun 2018,2018,44,6,534,550,"Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant pf values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.",1939-3520,,10.1109/TSE.2017.2731766,General Research Fund of the Research Grants Council of Hong Kong; City University of Hong Kong; JSPS KAKENHI; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990590,Software defect prediction;class imbalance learning;synthetic sample generation;data sampling methods;classification problems,Biological cells;Software;Predictive models;Animals;Electronic mail;Sampling methods,learning (artificial intelligence);pattern classification;sampling methods;software quality,MAHAKIL;software defect prediction;software defect datasets;nondefective modules;minority defective modules;class distribution;data instances;less diverse data;distinct sub-classes;data distribution;Random Oversampling;No sampling approach;prediction performance;defect prediction models;highly imbalanced datasets;defective modules;class imbalance issue;synthetic oversampling approaches;synthetic oversampling approach,,28.0,,80.0,,25 Jul 2017,,,IEEE,IEEE Journals
1878,518,Complete and Interpretable Conformance Checking of Business Processes,L. García-Bañuelos; N. R. T. P. van Beest; M. Dumas; M. L. Rosa; W. Mertens,"University of Tartu, Tartu, Estonia; Data61, CSIRO, Brisbane, QLD, Australia; University of Tartu, Tartu, Estonia; Queensland University of Technology, Brisbane, QLD, Australia; Queensland University of Technology, Brisbane, QLD, Australia",IEEE Transactions on Software Engineering,13 Mar 2018,2018,44,3,262,290,"This article presents a method for checking the conformance between an event log capturing the actual execution of a business process, and a model capturing its expected or normative execution. Given a process model and an event log, the method returns a set of statements in natural language describing the behavior allowed by the model but not observed in the log and vice versa. The method relies on a unified representation of process models and event logs based on a well-known model of concurrency, namely event structures. Specifically, the problem of conformance checking is approached by converting the event log into an event structure, converting the process model into another event structure, and aligning the two event structures via an error-correcting synchronized product. Each difference detected in the synchronized product is then verbalized as a natural language statement. An empirical evaluation shows that the proposed method can handle real datasets and produces more concise and higher-level difference descriptions than state-of-the-art conformance checking methods. In a survey designed according to the technology acceptance model, practitioners showed a preference towards the proposed method with respect to a state-of-the-art baseline.",1939-3520,,10.1109/TSE.2017.2668418,Australian Research Council Discovery; Estonian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852436,Process mining;conformance checking;process model;event log;event structure,Business;Synchronization;Computational modeling;Data mining;Natural languages;Software systems;Context modeling,business data processing;data mining;natural languages,event log;process model;event structure;conformance checking;technology acceptance model;business process expected execution;business process normative execution;concurrency model;error-correcting synchronized product;natural language statement,,8.0,,39.0,,13 Feb 2017,,,IEEE,IEEE Journals
1879,519,Using Local Clocks to Reproduce Concurrency Bugs,Z. Wang; C. Wu; X. Yuan; Z. Wang; J. Li; P. -C. Yew; J. Huang; X. Feng; Y. Lan; Y. Chen; Y. Lai; Y. Guan,"Institute of Computing Technology, University of Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; Huawei Technologies, Huairou, Beijing, P.R. China; Huawei Technologies, Huairou, Beijing, P.R. China; Horizon Robotics, Inc. Huairou, Beijing, P.R. China; Department of Computer Science and Engineering, University of Minnesota at Twin-Cities, Minnesota, MN; Department of Computer Science and Engineering, Texas A&M University, College Station, TX; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; Capital Normal University, Huairou, Beijing, P.R. China",IEEE Transactions on Software Engineering,12 Nov 2018,2018,44,11,1112,1128,"Multi-threaded programs play an increasingly important role in current multi-core environments. Exposing concurrency bugs and debugging such multi-threaded programs are quite challenging due to their inherent non-determinism. In order to mitigate such non-determinism, many approaches such as record-and-replay have been proposed. However, those approaches often suffer significant performance degradation because they require a large amount of recorded information and/or long analysis and replay time. In this paper, we propose an efficient and effective approach, ReCBuLC (reproducing concurrency bugs using local clocks), to take advantage of the hardware clocks available on modern processors. The key idea is to reduce the recording overhead and the time to analyze events’ global order by recording timestamps in each thread. These timestamps are used to determine the global order of shared accesses. To avoid the large overhead in accessing system-wide global clock, we opt to use local per-core clocks that incur much less access overhead. We then propose techniques to resolve skews among local clocks and obtain an accurate global event order. By using per-core clocks, state-of-the-art bug reproducing systems such as PRES and CLAP can reduce their recording overheads by up to 85 percent, and the analysis time up to 84.66% $\sim$ 99.99%, respectively.",1939-3520,,10.1109/TSE.2017.2752158,National High Technology Research and Development Program of China; National Natural Science Foundation of China (NSFC); Innovation Research Group of NSFC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8038023,Concurrency;bug reproducing;local clock,Clocks;Program processors;Computer bugs;Concurrent computing;Hardware;Debugging;Computer architecture,,,,,,44.0,,14 Sep 2017,,,IEEE,IEEE Journals
1880,520,Checking Smart Contracts with Structural Code Embedding,Z. Gao; L. Jiang; X. Xia; D. Lo; J. Grundy,"Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: zhipeng.gao@monash.edu); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 178902 (e-mail: lxjiang@smu.edu.sg); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Smart contracts have been increasingly used together with blockchains to automate financial and business transactions. However, many bugs and vulnerabilities have been identified in many contracts which raises serious concerns about smart contract security, not to mention that the blockchain systems on which the smart contracts are built can be buggy. Thus, there is a significant need to better maintain smart contract code and ensure its high reliability. In this paper, we propose an automated approach to learn characteristics of smart contracts in Solidity, useful for repetitive contract code, bug detection and contract validation. Our new approach is based on word embeddings and vector space comparison. We parse smart contract code into word streams with code structural information, convert code elements (e.g., statements, functions) into numerical vectors that are supposed to encode the code syntax and semantics, and compare the similarities among the vectors encoding code and known bugs, to identify potential issues. We have implemented the approach in a prototype, named SmartEmbed, and evaluated it with more than 22,000 smart contracts collected from the Ethereum blockchain. Results show that our tool can effectively identify many repetitive instances of Solidity code, where the clone ratio is around 90%. Code clones such as type-III or even type-IV semantic clones can also be detected. Our tool can identify more than 500 clone related bugs based on our bug databases efficiently and accurately. Our tool can also help to efficiently validate any given smart contract against the known set of bugs, which can help to improve the users' confidence in the reliability of the contract.",1939-3520,,10.1109/TSE.2020.2971482,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8979435,,Computer bugs;Smart contracts;Cloning;Tools;Blockchain;Security,,,,3.0,,,,3 Feb 2020,,,IEEE,IEEE Early Access Articles
1881,521,Automated Selection of Optimal Model Transformation Chains via Shortest-Path Algorithms,F. Basciani; M. D'Emidio; D. D. Ruscio; D. Frigioni; L. Iovino; A. Pierantonio,"Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Gran Sasso Science Institute (GSSI), L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy",IEEE Transactions on Software Engineering,13 Mar 2020,2020,46,3,251,279,"Conventional wisdom on model transformations in Model-Driven Engineering (MDE) suggests that they are crucial components in modeling environments to achieve superior automation, whether it be refactoring, simulation, or code generation. While their relevance is well-accepted, model transformations are challenging to design, implement, and verify because of the inherent complexity that they must encode. Thus, defining transformations by chaining existing ones is key to success for enhancing their reusability. This paper proposes an approach, based on well-established algorithms, to support modellers when multiple transformation chains are available to bridge a source metamodel with a target one. The all-important goal of selecting the optimal chain has been based on the quality criteria of coverage and information loss. The feasibility of the approach has been demonstrated by means of experiments operated on chains obtained from transformations borrowed from a publicly available repository.",1939-3520,,10.1109/TSE.2018.2846223,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8383962,Model-driven engineering;model transformation composition;graph algorithms;shortest paths,Unified modeling language;Adaptation models;Bridges;Analytical models;Model driven engineering;Ecosystems,graph theory;program processors;software maintenance;software quality,model-driven engineering;optimal chain;optimal model transformation chains;automated selection;shortest-path algorithms;quality criteria,,1.0,,63.0,IEEE,13 Jun 2018,,,IEEE,IEEE Journals
1882,522,Testing with Fewer Resources: An Adaptive Approach to Performance-Aware Test Case Generation,G. Grano; C. Laaber; A. Panichella; S. Panichella,"Department of Informatics, University of Zurich, Zurich, Zurich Switzerland (e-mail: grano@ifi.uzh.ch); Department of Informatics, University Of Zurich, Zurich, Zurich Switzerland (e-mail: laaber@ifi.uzh.ch); EWI, Technische Universiteit Delft Faculteit Elektrotechniek Wiskunde en Informatica, 225112 Delft, Zuid Holland Netherlands (e-mail: A.Panichella@tudelft.nl); School of Engineering, Zurcher Hochschule fur Angewandte Wissenschaften, 30944 Winterthur, Zurich Switzerland (e-mail: panc@zhaw.ch)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects. In this regard, runtime and memory usage are two essential dimensions: less expensive tests reduce the resource demands for the generation process and later regression testing phases. This study shows that performance-aware test case generation requires solving two main challenges: providing a good approximation of resource usage with minimal overhead and avoiding detrimental effects on both final coverage and fault detection effectiveness. To tackle these challenges, we conceived a set of performance proxies -inspired by previous work on performance testing- that provide a reasonable estimation of the test execution costs (i.e., runtime and memory usage). Thus, we propose an adaptive strategy, called aDynaMOSA, which leverages these proxies by extending DynaMOSA, a state-of-the-art evolutionary algorithm in unit testing. Our empirical study -involving 110 non-trivial Java classes- reveals that our adaptive approach generates test suite with statistically significant improvements in runtime (-25%) and heap memory consumption (-15%) compared to DynaMOSA. Additionally, aDynaMOSA has comparable results to DynaMOSA over seven different coverage criteria and similar fault detection effectiveness. Our empirical investigation also highlights that the usage of performance proxies (i.e., without the adaptiveness) is not sufficient to generate more performant test cases without compromising the overall coverage.",1939-3520,,10.1109/TSE.2019.2946773,Schweizerischer Nationalfonds zur Furderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865437,Evolutionary testing;many-objective optimization;performance,Testing;Runtime;Genetic algorithms;Memory management;Fault detection;Sociology;Statistics,,,,,,,,14 Oct 2019,,,IEEE,IEEE Early Access Articles
1883,523,A Survey of Recent Trends in Testing Concurrent Software Systems,F. A. Bianchi; A. Margara; M. Pezzè,"Faculty of Informatics, Univeristà della Svizzera italiana, USI Lugano, Lugano, Switzerland; Faculty of Informatics, Univeristà della Svizzera italiana, USI Lugano, Lugano, Switzerland; Faculty of Informatics, Univeristà della Svizzera italiana, USI Lugano, Lugano, Switzerland",IEEE Transactions on Software Engineering,13 Aug 2018,2018,44,8,747,783,"Many modern software systems are composed of multiple execution flows that run simultaneously, spanning from applications designed to exploit the power of modern multi-core architectures to distributed systems consisting of multiple components deployed on different physical nodes. We collectively refer to such systems as concurrent systems. Concurrent systems are difficult to test, since the faults that derive from their concurrent nature depend on the interleavings of the actions performed by the individual execution flows. Testing techniques that target these faults must take into account the concurrency aspects of the systems. The increasingly rapid spread of parallel and distributed architectures led to a deluge of concurrent software systems, and the explosion of testing techniques for such systems in the last decade. The current lack of a comprehensive classification, analysis and comparison of the many testing techniques for concurrent systems limits the understanding of the strengths and weaknesses of each approach and hampers the future advancements in the field. This survey provides a framework to capture the key features of the available techniques to test concurrent software systems, identifies a set of classification criteria to review and compare the available techniques, and discusses in details their strengths and weaknesses, leading to a thorough assessment of the field and paving the road for future progresses.",1939-3520,,10.1109/TSE.2017.2707089,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7932530,Survey;classification;testing;concurrent systems;parallel systems;distributed systems,Testing;Software systems;Message passing;History;Concurrent computing;Computer architecture;Synchronization,formal specification;multiprocessing systems;object-oriented programming;parallel architectures;program testing,distributed systems;testing techniques;concurrency aspects;modern software systems;modern multicore architectures;concurrent software system testing;multiple execution flows;parallel architecture;distributed architecture;classification criteria,,7.0,,216.0,,23 May 2017,,,IEEE,IEEE Journals
1884,524,"Characterizing the Usage, Evolution and Impact of Java Annotations in Practice",Z. Yu; C. Bai; L. Seinturier; M. Monperrus,"KTH Royal Institute of Technology, Stockholm, Sweden; Beihang University, Beijing, China; Inria Lille Nord Europe, Villeneuve d’Ascq, France; KTH Royal Institute of Technology, Stockholm, Sweden",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,969,986,"Annotations have been formally introduced into Java since Java 5. Since then, annotations have been widely used by the Java community for different purposes, such as compiler guidance and runtime processing. Despite the ever-growing use, there is still limited empirical knowledge about the actual usage of annotations in practice, the changes made to annotations during software evolution, and the potential impact of annotations on code quality. To fill this gap, we perform the first large-scale empirical study about Java annotations on 1,094 notable open-source projects hosted on GitHub. Our study systematically investigates annotation usage, annotation evolution, and annotation impact, and generates 10 novel and important findings. We also present the implications of our findings, which shed light for developers, researchers, tool builders, and language or library designers in order to improve all facets of Java annotation engineering.",1939-3520,,10.1109/TSE.2019.2910516,"Wallenberg AI, Autonomous Systems and Software Program; Knut och Alice Wallenbergs Stiftelse; National Natural Science Foundation of China; Equipment Preliminary R&D Project of China; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686056,Annotation;software evolution;empirical study;statistical modelling,Annotations;Java;Tools;Libraries;Runtime;Open source software,,,,,,54.0,IEEE,11 Apr 2019,,,IEEE,IEEE Journals
1885,525,Automatically Categorizing Software Technologies,M. Nassif; C. Treude; M. P. Robillard,"School of Computer Science, McGill University, Montréal, QC, Canada; School of Computer Science, University of Adelaide, Adelaide, SA, Australia; School of Computer Science, McGill University, Montréal, QC, Canada",IEEE Transactions on Software Engineering,8 Jan 2020,2020,46,1,20,32,"Informal language and the absence of a standard taxonomy for software technologies make it difficult to reliably analyze technology trends on discussion forums and other on-line venues. We propose an automated approach called Witt for the categorization of software technologies (an expanded version of the hypernym discovery problem). Witt takes as input a phrase describing a software technology or concept and returns a general category that describes it (e.g., integrated development environment), along with attributes that further qualify it (commercial, php, etc.). By extension, the approach enables the dynamic creation of lists of all technologies of a given type (e.g., web application frameworks). Our approach relies on Stack Overflow and Wikipedia, and involves numerous original domain adaptations and a new solution to the problem of normalizing automatically-detected hypernyms. We compared Witt with six independent taxonomy tools and found that, when applied to software terms, Witt demonstrated better coverage than all evaluated alternative solutions, without a corresponding degradation in false positive rate.",1939-3520,,10.1109/TSE.2018.2836450,Natural Sciences and Engineering Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359344,Taxonomy;information retrieval;natural language processing;Wikipedia;tagging,Software;Encyclopedias;Electronic publishing;Internet;Taxonomy;Tools,encyclopaedias;public domain software;Web sites,Witt;software terms;software technology;hypernym discovery problem;taxonomy tools;stack overflow;Wikipedia;software technologies categorization;online venues;forums,,4.0,,46.0,IEEE,15 May 2018,,,IEEE,IEEE Journals
1886,526,Deep Semantic Feature Learning for Software Defect Prediction,S. Wang; T. Liu; J. Nam; L. Tan,"Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; School of Computer Science and Electrical Engineering, Handong Global University, Pohang, Korea; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1267,1293,"Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction.",1939-3520,,10.1109/TSE.2018.2877612,Natural Sciences and Engineering Research Council of Canada; National Research Foundation of Korea; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502853,Defect prediction;quality assurance;deep learning;semantic features,Semantics;Predictive models;Feature extraction;Quality assurance;Computer bugs;Data models;Prediction models,abstract data types;belief networks;feature extraction;learning (artificial intelligence);program debugging;program testing;programming language semantics;software quality;tree data structures,deep semantic feature learning;software defect prediction;defective code regions;semantic differences;semantic representations;source code files;file-level defect prediction models;source code changes;change-level defect prediction models;file-level within-project defect prediction;change-level within-project defect prediction;DBN-based semantic features;file-level cross-project defect prediction;change-level cross-project defect prediction;representation-learning algorithm;defect prediction features;deep belief network;token vectors;abstract syntax trees,,15.0,,111.0,IEEE,23 Oct 2018,,,IEEE,IEEE Journals
1887,527,Towards Security Threats of Deep Learning Systems: A Survey,Y. He; G. Meng; K. Chen; X. Hu; J. He,"Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: heyingzhe@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: mengguozhu@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: chenkai@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: huxingbo@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: hejinwen@iie.ac.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Deep learning has gained tremendous success and great popularity in the past few years. However, deep learning systems are suffering several inherent weaknesses, which can threaten the security of learning models. Deep learning's wide use further magnifies the impact and consequences. To this end, lots of research has been conducted with the purpose of exhaustively identifying intrinsic weaknesses and subsequently proposing feasible mitigation. Yet few are clear about how these weaknesses are incurred and how effective these attack approaches are in assaulting deep learning. In order to unveil the security weaknesses and aid in the development of a robust deep learning system, we undertake an investigation on attacks towards deep learning, and analyze these attacks to conclude some findings in multiple views. In particular, we focus on four types of attacks associated with security threats of deep learning: model extraction attack, model inversion attack, poisoning attack and adversarial attack. For each type of attack, we construct its essential workflow as well as adversary capabilities and attack goals. Pivot metrics are devised for comparing the attack approaches, by which we perform quantitative and qualitative analyses. From the analysis, we have identified significant and indispensable factors in an attack vector, <i>e.g.</i>, how to reduce queries to target models, what distance should be used for measuring perturbation. We shed light on 18 findings covering these approaches' merits and demerits, success probability, deployment complexity and prospects. Moreover, we discuss other potential security weaknesses and possible mitigation which can inspire relevant research in this area.",1939-3520,,10.1109/TSE.2020.3034721,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252914,deep learning;poisoning attack;adversarial attack;model extraction attack;model inversion attack,Deep learning;Security;Data models;Privacy;Predictive models;Training data,,,,1.0,,,IEEE,9 Nov 2020,,,IEEE,IEEE Early Access Articles
1888,528,FutureWare: Designing a Middleware for Anticipatory Mobile Computing,A. Mehrotra; V. Pejovic; M. Musolesi,"Department of Geography, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: abhinav.iims@gmail.com); Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, Ljubljana Slovenia (e-mail: veljko.pejovic@fri.uni-lj.si); Department of Geography, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: m.musolesi@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Ubiquitous computing is moving from context-awareness to context-prediction. In order to build truly anticipatory systems developers have to deal with many challenges, from multimodal sensing to modeling context from sensed data, and, when necessary, coordinating multiple predictive models across devices. Novel expressive programming interfaces and paradigms are needed for this new class of mobile and ubiquitous applications. In this paper we present FutureWare, a middleware for seamless development of mobile applications that rely on context prediction. FutureWare exposes an expressive API to lift the burden of mobile sensing, individual and group behavior modeling, and future context querying, from an application developer. We implement FutureWare as an Android library, and through a scenario-based testing and a demo app we show that it represents an efficient way of supporting anticipatory applications, reducing the necessary coding effort by two orders of magnitude.",1939-3520,,10.1109/TSE.2019.2943554,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847471,Anticipatory computing;mobile middleware;mobile sensing;prediction,Middleware;Sensors;Predictive models;Context modeling;Machine learning;Servers;Mobile applications,,,,,,,,24 Sep 2019,,,IEEE,IEEE Early Access Articles
1889,529,Too Many User-Reviews! What Should App Developers Look at First?,E. Noei; F. Zhang; Y. Zou,"Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,367,378,"Due to the rapid growth in the number of mobile applications (apps) in the past few years, succeeding in mobile app markets has become ruthless. Online app markets, such as Google Play Store, let users rate apps on a five-star scale and leave feedback. Given the importance of high star-ratings to the success of an app, it is crucial to help developers find the key topics of user-reviews that are significantly related to star-ratings of a given category. Having considered the key topics of user-reviews, app developers can narrow down their effort to the user-reviews that matter to be addressed for receiving higher star-ratings. We study 4,193,549 user-reviews of 623 Android apps that were collected from Google Play Store in ten different categories. The results show that few key topics commonly exist across categories, and each category has a specific set of key topics. We also evaluated the identified key topics with respect to the changes that are made to each version of the apps for 19 months. We observed, for 77 percent of the apps, considering the key topics in the next versions shares a significant relationship with increases in star-ratings.",1939-3520,,10.1109/TSE.2019.2893171,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613795,Mobile application;empirical study;software release;user-review,Google;Measurement;Crawlers;Natural language processing;Computer bugs;Tools;Filtering,Android (operating system);mobile computing,app developers;mobile app markets;online app markets;Google Play Store;high star-ratings;user-reviews;Android apps,,4.0,,77.0,IEEE,16 Jan 2019,,,IEEE,IEEE Journals
1890,530,Studying Ad Library Integration Strategies of Top Free-to-Download Apps,M. Ahasanuzzaman; S. Hassan; A. E. Hassan,"School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: md.ahasanuzzaman@queensu.ca); School of Computing, Queen's University School of Computing, 374016 Ontario, Ontario Canada (e-mail: shassan@cs.queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"In-app advertisements have become a major revenue source for app developers in the mobile app ecosystem. Ad libraries play an integral part in this ecosystem as app developers integrate these libraries into their apps to display ads. In this paper, we study ad library integration practices by analyzing 35,459 updates of 1,837 top free-to-download apps of the Google Play Store. We observe that ad libraries (e.g., Google AdMob) are not always used for serving ads -- 22.5% of the apps that integrate Google AdMob do not display ads. They instead depend on Google AdMob for analytical purposes. Among the apps that display ads, we observe that 57.9% of them integrate multiple ad libraries. We observe that such integration of multiple ad libraries occurs commonly in apps with a large number of downloads and ones in app categories with a high proportion of ad-displaying apps. We manually analyze a sample of apps and derive a set of rules to automatically identify four common strategies for integrating multiple ad libraries. Our analysis of the apps across the identified strategies shows that app developers prefer to manage their own integrations instead of using off-the-shelf features of ad libraries for integrating multiple ad libraries. Our findings are valuable for ad library developers who wish to learn first hand about the challenges of integrating ad libraries.",1939-3520,,10.1109/TSE.2020.2983399,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9052472,Ad libraries;Integration strategies;Mining Android mobile apps;Google Play Store,Libraries;Google;Advertising;Mobile applications;Tools;Ecosystems;Companies,,,,,,,,1 Apr 2020,,,IEEE,IEEE Early Access Articles
1891,531,Lightweight Assessment of Test-Case Effectiveness Using Source-Code-Quality Indicators,G. Grano; F. Palomba; H. C. Gall,"University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,758,774,"Test cases are crucial to help developers preventing the introduction of software faults. Unfortunately, not all the tests are properly designed or can effectively capture faults in production code. Some measures have been defined to assess test-case effectiveness: the most relevant one is the mutation score, which highlights the quality of a test by generating the so-called mutants, i.e., variations of the production code that make it faulty and that the test is supposed to identify. However, previous studies revealed that mutation analysis is extremely costly and hard to use in practice. The approaches proposed by researchers so far have not been able to provide practical gains in terms of mutation testing efficiency. This leaves the problem of efficiently assessing test-case effectiveness as still open. In this paper, we investigate a novel, orthogonal, and lightweight methodology to assess test-case effectiveness: in particular, we study the feasibility to exploit production and test-code-quality indicators to estimate the mutation score of a test case. We first select a set of 67 factors and study their relation with test-case effectiveness. Then, we devise a mutation score estimation model exploiting such factors and investigate its performance as well as its most relevant features. The key results of the study reveal that our estimation model only based on static features has 86 percent of both F-Measure and AUC-ROC. This means that we can estimate the test-case effectiveness, using source-code-quality indicators, with high accuracy and without executing the tests. As a consequence, we can provide a practical approach that is beyond the typical limitations of current mutation testing techniques.",1939-3520,,10.1109/TSE.2019.2903057,Swiss National Science Foundation (SNSF); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658120,Automated software testing;mutation testing;software quality,Testing;Production;Estimation;Measurement;Predictive models;Machine learning;Computational modeling,,,,4.0,,108.0,IEEE,4 Mar 2019,,,IEEE,IEEE Journals
1892,532,Tracking Load-Time Configuration Options,M. Lillack; C. Kästner; E. Bodden,"University of Leipzig, Leipzig, Germany; Carnegie Mellon University, Pittsburgh, PA; Paderborn University & Fraunhofer IEM, Paderborn, Germany",IEEE Transactions on Software Engineering,9 Dec 2018,2018,44,12,1269,1291,"Many software systems are highly configurable, despite the fact that configuration options and their interactions make those systems significantly harder to understand and maintain. In this work, we consider load-time configuration options, such as parameters from the command-line or from configuration files. They are particularly hard to reason about: tracking configuration options from the point at which they are loaded to the point at which they influence control-flow decisions is tedious and error-prone, if done manually. We design and implement Lotrack, an extended static taint analysis to track configuration options automatically. Lotrack derives a configuration map that explains for each code fragment under which configurations it may be executed. An evaluation on Android apps and Java applications from different domains shows that Lotrack yields high accuracy with reasonable performance. We use Lotrack to empirically characterize how much of the implementation of Android apps depends on the platform's configuration options or interactions of these options.",1939-3520,,10.1109/TSE.2017.2756048,German Federal Ministry of Education and Research; US National Science Foundation; Science of Security Lablet; AFRL and DARPA; German Research Foundation (DFG); Heinz Nixdorf Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049300,Variability mining;configuration options;static analysis,Androids;Humanoid robots;Java;Static analysis;Bluetooth;Data mining,Java;mobile computing,configuration map;Lotrack;tracking load-time configuration options;configuration files;tracking configuration options,,7.0,,58.0,,25 Sep 2017,,,IEEE,IEEE Journals
1893,533,Enriching API Documentation with Code Samples and Usage Scenarios from Crowd Knowledge,J. Zhang; H. Jiang; Z. Ren; T. Zhang; Z. Huang,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: jxzhang@nuaa.edu.cn); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: jianghe@dlut.edu.cn); School of Software, Dalian university of technology, Dalian, Liaoning China (e-mail: zren@dlut.edu.cn); College of Computer Science and Technology, Harbin Engineering University, 12428 Harbin, Heilongjiang China (e-mail: cstzhang@hrbeu.edu.cn); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu China (e-mail: zqhuang@nuaa.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"As one key resource to learn Application Programming Interfaces (APIs), a lot of API reference documentation lacks code samples with usage scenarios, thus heavily hindering developers from programming with APIs. Although researchers have investigated how to enrich API documentation with code samples from general code search engines, two main challenges remain to be resolved, including the quality challenge of acquiring high-quality code samples and the mapping challenge of matching code samples to usage scenarios. In this study, we propose a novel approach named ADECK towards enriching API documentation with code samples and corresponding usage scenarios by leveraging crowd knowledge from Stack Overflow, a popular technical Question and Answer (Q&A) website attracting millions of developers. Given an API related Q&A pair, a code sample in the answer is extensively evaluated by developers and targeted towards resolving the question under the specified usage scenario. Hence, ADECK can obtain high-quality code samples and map them to corresponding usage scenarios to address the above challenges. Extensive experiments on the Java SE and Android API documentation show that the number of code-sample-illustrated API types in the ADECK-enriched API documentation is 3.35 and 5.76 times as many as that in the raw API documentation. Meanwhile, the quality of code samples obtained by ADECK is better than that of code samples by the baseline approach eXoaDocs in terms of correctness, conciseness, and usability, e.g., the average correctness values of representative code samples obtained by ADECK and eXoaDocs are 4.26 and 3.28 on a 5-point scale in the enriched Java SE API documentation. In addition, an empirical study investigating the impacts of different types of API documentation on the productivity of developers shows that, compared against the raw and the eXoaDocs-enriched API documentation, the ADECK-enriched API documentation can help developers complete 23.81% and 14.29% more programming tasks and reduce the average completion time by 9.43% and 11.03%.",1939-3520,,10.1109/TSE.2019.2919304,National Key Research and Development Plan of China; China Postdoctoral Science Foundation; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723145,API Documentation;Code Sample;Usage Scenario;Stack Overflow;Crowd knowledge,Documentation;Programming;Java;Knowledge engineering;Search engines;Productivity;Task analysis,,,,3.0,,,,27 May 2019,,,IEEE,IEEE Early Access Articles
1894,534,Heterogeneous Defect Prediction,J. Nam; W. Fu; S. Kim; T. Menzies; L. Tan,"Handong Global University, Pohang, Korea; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,16 Sep 2018,2018,44,9,874,896,"Many recent studies have documented the success of cross-project defect prediction (CPDP) to predict defects for new projects lacking in defect data by using prediction models built by other projects. However, most studies share the same limitations: it requires homogeneous data; i.e., different projects must describe themselves using the same metrics. This paper presents methods for heterogeneous defect prediction (HDP) that matches up different metrics in different projects. Metric matching for HDP requires a “large enough” sample of distributions in the source and target projects-which raises the question on how large is “large enough” for effective heterogeneous defect prediction. This paper shows that empirically and theoretically, “large enough” may be very small indeed. For example, using a mathematical model of defect prediction, we identify categories of data sets were as few as 50 instances are enough to build a defect prediction model. Our conclusion for this work is that, even when projects use different metric sets, it is possible to quickly transfer lessons learned about defect prediction.",1939-3520,,10.1109/TSE.2017.2720603,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959597,Defect prediction;quality assurance;heterogeneous metrics;transfer learning,Predictive models;Software metrics;Quality assurance;Training,data handling;pattern matching,metric matching;cross-project defect prediction;defect data;homogeneous data;heterogeneous defect prediction;metric sets,,30.0,,103.0,,27 Jun 2017,,,IEEE,IEEE Journals
1895,535,Analyzing the Effects of Bugs on Software Interfaces,R. Natella; S. Winter; D. Cotroneo; N. Suri,"DIETI Department, Federico II University of Naples, Napoli, NA, Italy; DEEDS Group, TU Darmstadt, Darmstadt, Germany; DIETI Department, Federico II University of Naples, Napoli, NA, Italy; DEEDS Group, TU Darmstadt, Darmstadt, Germany",IEEE Transactions on Software Engineering,13 Mar 2020,2020,46,3,280,301,"Critical systems that integrate software components (e.g., from third-parties) need to address the risk of residual software defects in these components. Software fault injection is an experimental solution to gauge such risk. Many error models have been proposed for emulating faulty components, such as by injecting error codes and exceptions, or by corrupting data with bit-flips, boundary values, and random values. Even if these error models have been able to find breaches in fragile systems, it is unclear whether these errors are in fact representative of software faults. To pursue this open question, we propose a methodology to analyze how software faults in C/C++ software components turn into errors at components' interfaces (interface error propagation), and present an experimental analysis on what, where, and when to inject interface errors. The results point out that the traditional error models, as used so far, do not accurately emulate software faults, but that richer interface errors need to be injected, by: injecting both fail-stop behaviors and data corruptions; targeting larger amounts of corrupted data structures; emulating silent data corruptions not signaled by the component; combining bit-flips, boundary values, and data perturbations.",1939-3520,,10.1109/TSE.2018.2850755,Universit?? degli Studi di Napoli Federico II; Compagnia di San Paolo; BMBF TUD-CRISP; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8396273,Dependability;fault injection;software components;error propagation;error modeling;error handling,Software;Unified modeling language;Computer bugs;Perturbation methods;Testing;Fault tolerance,C++ language;data structures;program debugging;software fault tolerance;source code (software);user interfaces,software faults;boundary values;software interfaces;critical systems;residual software defects;software fault injection;error codes;bug effects;C/C++ software components;interface error propagation;data structure;bit-flips;data perturbations,,1.0,,95.0,IEEE,26 Jun 2018,,,IEEE,IEEE Journals
1896,536,An Empirical Study of Dependency Downgrades in the npm Ecosystem,F. R. Cogo; G. A. Oliva; A. E. Hassan,"School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: filipe.cogo@gmail.com); School of Computing, Queen's University, Kingston, Ontario Canada K7L 2N8 (e-mail: golivax@gmail.com); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"In a software ecosystem, a dependency relationship enables a client package to reuse a certain version of a provider package. Packages in a software ecosystem often release versions containing bug fixes, new functionalities, and security enhancements. Hence, updating the provider version is an important maintenance task for client packages. Despite the number of investigations about dependency updates, there is a lack of studies about dependency downgrades in software ecosystems. A downgrade indicates that the adopted version of a provider package is not suitable to the client package at a certain moment. In this paper, we investigate downgrades in the npm ecosystem. We address three research questions. In our first RQ, we provide a list of the reasons behind the occurrence of downgrades. Two categories of downgrades according to their rationale: reactive and preventive. The reasons behind reactive downgrades are defects in a specific version of a provider, unexpected feature changes in a provider, and incompatibilities. In turn, preventive downgrades are an attempt to avoid issues in future releases. In our second RQ, we investigate how the versioning of dependencies is modified when a downgrade occurs. We observed that 49% of the downgrades are performed by replacing a range of acceptable versions of a provider by a specific old version. Also, 48% of the downgrades reduce the provider version by a minor level (e.g., from 2.1.0 to 2.0.0). In our third RQ we observed that 50% of the downgrades are performed at a rate that is four times as slow as the median time-between-releases of their associated client packages. We also observed that downgrades that follow an explicit update of a provider package occur 9 times faster than downgrades that follow an implicit update. Explicit updates occur when the provider is updated by means of an explicit change to the versioning specification (i.e., the string used by client packages to define the provider version that they are willing to adopt). We conjecture that, due to the controlled nature of explicit updates, it is easier for client packages to identify the provider that is associated with the problem that motivated the downgrade.",1939-3520,,10.1109/TSE.2019.2952130,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894401,downgrades;dependency management;npm;software ecosystems,Ecosystems;Software;Computer bugs;Tools;Security;Task analysis,,,,2.0,,,,8 Nov 2019,,,IEEE,IEEE Early Access Articles
1897,537,Review Dynamics and Their Impact on Software Quality,P. Thongtanunam; A. E. Hassan,"School of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria Australia (e-mail: patanamon.t@unimelb.edu.au); School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Code review is a crucial activity for ensuring the quality of software products. Unlike the traditional code review process of the past where reviewers independently examine software artifacts, contemporary code review processes allow teams to collaboratively examine and discuss proposed patches. While the visibility of reviewing activities including review discussions in a contemporary code review tends to increase developer collaboration and openness, little is known whether such visible information influences the evaluation decision of a reviewer or not (i.e., knowing others' feedback about the patch before providing ones own feedback). Therefore, in this work, we set out to investigate the review dynamics, i.e., a practice of providing a vote to accept a proposed patch, in a code review process. To do so, we first characterize the review dynamics by examining the relationship between the evaluation decision of a reviewer and the visible information about a patch under review (e.g., comments and votes that are provided by prior co-reviewers). We then investigate the association between the characterized review dynamics and the defect-proneness of a patch. Through a case study of 83,750 patches of the OpenStack and Qt projects, we observe that the amount of feedback (either votes and comments of prior reviewers) and the co-working frequency of a reviewer with the patch author are highly associated with the likelihood that the reviewer will provide a positive vote to accept a proposed patch. Furthermore, we find that the proportion of reviewers who provided a vote consistent with prior reviewers is significantly associated with the defect-proneness of a patch. However, the associations of these review dynamics are not as strong as the confounding factors (i.e., patch characteristics and overall reviewing activities). Our observations shed light on the implicit influence of the visible information about a patch under review on the evaluation decision of a reviewer. Our findings suggest that the code reviewing policies that are mindful of these practices may help teams improve code review effectiveness. Nonetheless, such review dynamics should not be too concerning in terms of software quality.",1939-3520,,10.1109/TSE.2020.2964660,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951283,Code review;Collaboration;Human Aspects;Software Quality;Peer Review;Biases,Software quality;Tools;Collaboration;Measurement;Manuals;Proposals,,,,4.0,,,,7 Jan 2020,,,IEEE,IEEE Early Access Articles
1898,538,Moving from Closed to Open Source: Observations from Six Transitioned Projects to GitHub,P. S. Kochhar; E. Kalliamvakou; N. Nagappan; T. Zimmermann; C. Bird,"Information Systems, Singapore Management University School of Information Systems, 274434 Singapore, Singapore Singapore (e-mail: kochharps.2012@phdis.smu.edu.sg); Computer Science, University of Victoria, Victoria, British Columbia Canada V8W 2Y2 (e-mail: ikaliam@uvic.ca); Testing, Verification and Measurement Research, Microsoft Research, Redmond, Washington United States 98052 (e-mail: nachin@microsoft.com); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Microsoft Research, Microsoft Corportation, Redmond, Washington United States 98052 (e-mail: cbird@microsoft.com)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Open source software systems have gained a lot of attention in the past few years. With the emergence of open source platforms like GitHub, developers can contribute, store, and manage their projects with ease. Large organizations like Microsoft, Google, and Facebook are open sourcing their in-house technologies in an effort to more broadly involve the community in the development of software systems. Although closed source and open source systems have been studied extensively, there has been little research on the transition from closed source to open source systems. Through the study we report in this paper we aim to: a) provide guidance and insight for other teams planning to open source their projects and b) to help them avoid pitfalls during the transition process. We studied six Microsoft systems, which were recently open-sourced i.e., CoreFX, CoreCLR, Roslyn, Entity Framework, MVC, and Orleans. This paper presents the transition from the viewpoints of both Microsoft and the open source community based on interviews with eleven Microsoft developer, five Microsoft senior managers involved in the decision to open source, and eleven open-source developers. From Microsoft's perspective we discuss the reasons for the transition, experiences of developers involved, and the transition's outcomes and challenges. Our results show that building a vibrant community, prompt answers, developing an open source culture, security regulations and business opportunities are the factors which persuade companies to open source their products. We also discuss the transition outcomes on processes such as code reviews, version control systems, continuous integration as well as developers' perception of these changes. From the open source community's perspective, we illustrate the response to the open-sourcing initiative through contributions and interactions with the internal developers and provide guidelines for other projects planning to go open source.",1939-3520,,10.1109/TSE.2019.2937025,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812899,Empirical Study;GitHub;Open-source;Microsoft,Interviews;Encoding;Planning;Software systems;Open source software;Companies,,,,1.0,,,,26 Aug 2019,,,IEEE,IEEE Early Access Articles
1899,539,Test Generation and Test Prioritization for Simulink Models with Dynamic Behavior,R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann,"SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; Delphi Automotive Systems, Luxembourg",IEEE Transactions on Software Engineering,17 Sep 2019,2019,45,9,919,944,"All engineering disciplines are founded and rely on models, although they may differ on purposes and usages of modeling. Among the different disciplines, the engineering of Cyber Physical Systems (CPSs) particularly relies on models with dynamic behaviors (i.e., models that exhibit time-varying changes). The Simulink modeling platform greatly appeals to CPS engineers since it captures dynamic behavior models. It further provides seamless support for two indispensable engineering activities: (1) automated verification of abstract system models via model simulation, and (2) automated generation of system implementation via code generation. We identify three main challenges in the verification and testing of Simulink models with dynamic behavior, namely incompatibility, oracle and scalability challenges. We propose a Simulink testing approach that attempts to address these challenges. Specifically, we propose a black-box test generation approach, implemented based on meta-heuristic search, that aims to maximize diversity in test output signals generated by Simulink models. We argue that in the CPS domain test oracles are likely to be manual and therefore the main cost driver of testing. In order to lower the cost of manual test oracles, we propose a test prioritization algorithm to automatically rank test cases generated by our test generation algorithm according to their likelihood to reveal a fault. Engineers can then select, according to their test budget, a subset of the most highly ranked test cases. To demonstrate scalability, we evaluate our testing approach using industrial Simulink models. Our evaluation shows that our test generation and test prioritization approaches outperform baseline techniques that rely on random testing and structural coverage.",1939-3520,,10.1109/TSE.2018.2811489,"H2020 European Research Council; Delphi Automotive Systems, Luxembourg; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305644,Simulink models;search-based software testing;test generation;test prioritization;test oracle;output diversity;signal features;structural coverage,Software packages;Testing;Tools;Computational modeling;Vehicle dynamics;Scalability,computer simulation;cyber-physical systems;program compilers;program testing;program verification;search problems,industrial Simulink models;random testing;Simulink modeling platform;dynamic behavior models;abstract system models;code generation;Simulink testing approach;black-box test generation approach;test output signals;CPS domain test oracles;test budget;cyber physical systems;automated verification;automated generation;meta-heuristic search;cost driver;test prioritization approach;structural coverage,,9.0,,124.0,,1 Mar 2018,,,IEEE,IEEE Journals
1900,540,Empirical Evaluation of the Impact of Object-Oriented Code Refactoring on Quality Attributes: A Systematic Literature Review,J. Al Dallal; A. Abdin,"Department of Information Science, Kuwait University, Safat, Kuwait; Department of Information Science, Kuwait University, Safat, Kuwait",IEEE Transactions on Software Engineering,8 Jan 2018,2018,44,1,44,69,"Software refactoring is a maintenance task that addresses code restructuring to improve its quality. Many studies have addressed the impact of different refactoring scenarios on software quality. This study presents a systematic literature review that aggregates, summarizes, and discusses the results of 76 relevant primary studies (PSs) concerning the impact of refactoring on several internal and external quality attributes. The included PSs were selected using inclusion and exclusion criteria applied to relevant articles published before the end of 2015. We analyzed the PSs based on a set of classification criteria, including software quality attributes and measures, refactoring scenarios, evaluation approaches, datasets, and impact results. We followed the vote-counting approach to determine the level of consistency among the PS reported results concerning the relationship between refactoring and software quality. The results indicated that different refactoring scenarios sometimes have opposite impacts on different quality attributes. Therefore, it is false that refactoring always improves all software quality aspects. The vote-counting study provided a clear view of the impacts of some individual refactoring scenarios on some internal quality attributes such as cohesion, coupling, complexity, inheritance, and size, but failed to identify their impacts on external and other internal quality attributes due to insufficient findings.",1939-3520,,10.1109/TSE.2017.2658573,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833023,quality attribute;quality measure;refactoring scenario;systematic literature review,Software quality;Systematics;Unified modeling language;Bibliographies;Libraries;Object oriented modeling,software maintenance;software metrics;software quality,76 relevant primary studies;PSs;internal quality;external quality;classification criteria;software quality attributes;evaluation approaches;vote-counting approach;different refactoring scenarios;opposite impacts;different quality attributes;software quality aspects;vote-counting study;individual refactoring scenarios;systematic literature review;software refactoring;maintenance task;code restructuring,,6.0,,99.0,,25 Jan 2017,,,IEEE,IEEE Journals
1901,541,Enhancing the Description-to-Behavior Fidelity in Android Apps with Privacy Policy,L. Yu; X. Luo; C. Qian; S. Wang; H. K. N. Leung,"Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong",IEEE Transactions on Software Engineering,16 Sep 2018,2018,44,9,834,854,"Since more than 96 percent of mobile malware targets the Android platform, various techniques based on static code analysis or dynamic behavior analysis have been proposed to detect malicious apps. As malware is becoming more complicated and stealthy, recent research proposed a promising detection approach that looks for the inconsistency between an app's permissions and its description. In this paper, we first revisit this approach and reveal that using description and permission will lead to many false positives because descriptions often fail to declare all sensitive operations. Then, we propose exploiting an app's privacy policy and its bytecode to enhance the malware detection based on description and permissions. It is non-trivial to automatically analyze privacy policy and perform the cross-verification among these four kinds of software artifacts including, privacy policy, bytecode, description, and permissions. To address these challenging issues, we first propose a novel data flow model for analyzing privacy policy, and then develop a new system, named TAPVerifier, for carrying out investigation of individual software artifacts and conducting the cross-verification. The experimental results show that TAPVerifier can analyze privacy policy with a high accuracy and recall rate. More importantly, integrating privacy policy and bytecode level information can remove up to 59.4 percent false alerts of the state-of-the-art systems, such as AutoCog, CHABADA, etc.",1939-3520,,10.1109/TSE.2017.2730198,Hong Kong GRF; Shenzhen City Science and Technology R&D Fund; Hong Kong RGC Project; HKPolyU Research; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987793,Mobile applications;privacy policy,Privacy;Data privacy;Semantics;Malware;Permission;Google;Androids,Android (operating system);data privacy;invasive software;mobile computing;program diagnostics,privacy policy;permission;description-to-behavior fidelity;Android apps;static code analysis;dynamic behavior analysis;malicious apps;promising detection approach;malware detection;mobile malware;TAPVerifier,,10.0,,91.0,,21 Jul 2017,,,IEEE,IEEE Journals
1902,542,Defining Smart Contract Defects on Ethereum,J. Chen; X. Xia; D. Lo; J. Grundy; X. Luo; T. Chen,"Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: Jiachi.Chen@monash.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxluo@comp.polyu.edu.hk); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan China (e-mail: brokendragon@uestc.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Smart contracts are programs running on a blockchain. They are immutable to change, and hence can not be patched for bugs once deployed. Thus it is critical to ensure they are bug-free and well-designed before deployment. Code smells are symptoms in source code that possibly indicate e.g. security, architecture and/or usability problems. The detection of code smells is a method to avoid potential bugs and improve the design of existing code. However, traditional code smell patterns are designed for centralized OO programs, e.g., Java or C++. Smart contracts are however decentralized and contain numerous distinctive features, such as the gas system. To fill this gap, we collected smart-contract-related posts from Ethereum Stack Exchange, as well as real-world smart contracts. We manually analyzed these posts and used them to define 20 kinds of code smells for smart contracts. We categorized these into indicating potential security, architecture, and usability problems. To validate if practitioners consider these contract smells as harmful, we created an online survey and received 96 responses from 24 different countries. Feedback showed these code smells are harmful and removing them would improve the quality and robustness of smart contracts. We manually identified our defined code smells in 587 contract accounts and publicly released our dataset. Finally, we summarized 5 impacts caused by contract code smells. These help developers better understand the symptoms of the smells and removal priority.",1939-3520,,10.1109/TSE.2020.2989002,National Key RD Program of China; ARC Laureate Fellowship; ARC Discovery Project; Hong Kong RGC Project; National Natural Science Foundation of China; Australian Research Councils Discovery Early Career Researcher Award DECRA; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072659,Empirical Study;Smart Contracts;Ethereum;Contract Defect,Contracts;Computer bugs;Robustness;Protocols;Bitcoin,,,,2.0,,,,20 Apr 2020,,,IEEE,IEEE Early Access Articles
1903,543,Smart Bound Selection for the Verification of UML/OCL Class Diagrams,R. Clarisó; C. A. González; J. Cabot,"IT, Multimedia and Telecommunication Department, Universitat Oberta de Catalunya, Barcelona, Spain; University of Luxembourg, Esch-sur-Alzette, Luxembourg; ICREA, Pg. Lluís Companys 23, Barcelona, Spain",IEEE Transactions on Software Engineering,16 Apr 2019,2019,45,4,412,426,"Correctness of UML class diagrams annotated with OCL constraints can be checked using bounded verification techniques, e.g., SAT or constraint programming (CP) solvers. Bounded verification detects faults efficiently but, on the other hand, the absence of faults does not guarantee a correct behavior outside the bounded domain. Hence, choosing suitable bounds is a non-trivial process as there is a trade-off between the verification time (faster for smaller domains) and the confidence in the result (better for larger domains). Unfortunately, bounded verification tools provide little support in the bound selection process. In this paper, we present a technique that can be used to (i) automatically infer verification bounds whenever possible, (ii) tighten a set of bounds proposed by the user and (iii) guide the user in the bound selection process. This approach may increase the usability of UML/OCL bounded verification tools and improve the efficiency of the verification process.",1939-3520,,10.1109/TSE.2017.2777830,H2020 ECSEL; Spanish Ministry of Economy and Competitivity; Internet Interdisciplinary Institute (IN3); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119996,Formal verification;UML;class diagram;OCL;constraint propagation;SAT,Unified modeling language;Tools;Sociology;Statistics;Analytical models;Computational modeling;Software,constraint handling;formal verification;Unified Modeling Language,UML class diagrams;OCL constraints;constraint programming solvers;bounded verification detects faults;correct behavior;bounded domain;suitable bounds;nontrivial process;verification time;bounded verification tools;bound selection process;automatically infer verification;verification process;smart bound selection;UML-OCL class diagrams,,1.0,,51.0,,27 Nov 2017,,,IEEE,IEEE Journals
1904,544,Studying Task Processes for Improving Programmer Productivity,P. Jalote; D. Kamma,"IIIT-Delhi, New Delhi, Delhi, India; Robert Bosch Engineering and Business Solutions Limited, Bengaluru, Karnataka, India",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,801,817,"Productivity of a software development organization can be enhanced by improving the software process, using better tools/technology, and enhancing the productivity of programmers. This work focuses on improving programmer productivity by studying the process used by a programmer for executing an assigned task, which we call the task process. We propose a general framework for studying the impact of task processes on programmer productivity and also the impact of transferring task processes of high-productivity programmers to average-productivity peers. We applied the framework to a few live projects in Robert Bosch Engineering and Business Solutions Limited, a CMMI Level 5 company. In each project, we identified two groups of programmers: high-productivity and average-productivity programmers. We requested each programmer to video capture their computer screen while executing his/her assigned tasks. We then analyzed these task videos to extract the task processes and then used them to identify the differences between the task processes used by the two groups. Some key differences were found between the task processes, which could account for the difference in productivities of the two groups. Similarities between the task processes were also analyzed quantitatively by modeling each task process as a Markov chain. We found that programmers from the same group used similar task processes, but the task processes of the two groups differed considerably. The task processes of high-productivity programmers were transferred to the average-productivity programmers by training them on the key steps missing in their process but commonly present in the work of their high-productivity peers. A substantial productivity gain was found in the average-productivity programmers as a result of this transfer. The study shows that task processes of programmers impact their productivity, and it is possible to improve the productivity of average-productivity programmers by transferring task processes from high-productivity programmers to them.",1939-3520,,10.1109/TSE.2019.2904230,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664196,Programmer;productivity;task processes;task execution;industrial study;software;efficiency;improvement;experiments,Task analysis;Productivity;Software;Companies;Markov processes,,,,,,67.0,IEEE,10 Mar 2019,,,IEEE,IEEE Journals
1905,545,Design Rule Spaces: A New Model for Representing and Analyzing Software Architecture,Y. Cai; L. Xiao; R. Kazman; R. Mo; Q. Feng,"Department of Computer Science, Drexel University, Philadelphia, PA; Stevens Institute of Technology, Hoboken, NJ; Department of Information Technology Management, University of Hawaii, Honolulu, HI; Department of Computer Science, Drexel University, Philadelphia, PA; Department of Computer Science, Drexel University, Philadelphia, PA",IEEE Transactions on Software Engineering,16 Jul 2019,2019,45,7,657,682,"In this paper, we propose an architecture model called Design Rule Space (DRSpace). We model the architecture of a software system as multiple overlapping DRSpaces, reflecting the fact that any complex software system must contain multiple aspects, features, patterns, etc. We show that this model provides new ways to analyze software quality. In particular, we introduce an Architecture Root detection algorithm that captures DRSpaces containing large numbers of a project's bug-prone files, which are called Architecture Roots (ArchRoots). After investigating ArchRoots calculated from 15 open source projects, the following observations become clear: from 35 to 91 percent of a project's most bug-prone files can be captured by just 5 ArchRoots, meaning that bug-prone files are likely to be architecturally connected. Furthermore, these ArchRoots tend to live in the system for significant periods of time, serving as the major source of bug-proneness and high maintainability costs. Moreover, each ArchRoot reveals multiple architectural flaws that propagate bugs among files and this will incur high maintenance costs over time. The implication of our study is that the quality, in terms of bug-proneness, of a large, complex software project cannot be fundamentally improved without first fixing its architectural flaws.",1939-3520,,10.1109/TSE.2018.2797899,Division of Computing and Communication Foundations; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268667,Software architecture;reverse-engineering;defect prediction;technical debt;code smells;bug localization,Computer bugs;Computer architecture;Software architecture;Production facilities;Analytical models;Software systems,computer debugging;software architecture;software maintenance;software quality,architecture model;DRSpace;complex software system;multiple aspects;software quality;ArchRoot;bug-prone files;complex software project;software architecture;design rule spaces;architecture root detection algorithm,,8.0,,118.0,,24 Jan 2018,,,IEEE,IEEE Journals
1906,546,Enhancing Trustability of Android Applications via User-Centric Flexible Permissions,G. L. Scoccia; I. Malavolta; M. Autili; A. Di Salle; P. Inverardi,"Department of Information Engineering Computer Science and Mathematics, University of L'Aquila Department of Information Engineering Computer Science and Mathematics, 220003 L'Aquila, Abruzzo Italy (e-mail: gianluca.scoccia@univaq.it); Computer Science, Vrije Universiteit Amsterdam, 1190 Amsterdam, Noord-Holland Netherlands (e-mail: i.malavolta@vu.nl); Department of Information Engineering Computer Science and Mathematics, University of L'Aquila, L'Aquila, Italy Italy 67100 (e-mail: marco.autili@univaq.it); Department of Information Engineering Computer Science and Mathematics, University of L'Aquila, L'Aquila, AQ Italy (e-mail: amleto.disalle@univaq.it); Informatica, Universita dell'Aquila, L'Aquila, Italy Italy I-67010 (e-mail: paola.inverardi@univaq.it)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The Android OS market is experiencing a growing share globally. It is becoming the mobile platform of choice for an increasing number of users. People rely on Android mobile devices for surfing the web, purchasing products, or to be part of a social network. The large amount of personal information that is exchanged makes privacy an important concern. As a result, the trustability of mobile apps is a fundamental aspect to be considered, particularly with regard to meeting the expectations of end users. The rigidities of the Android permission model confine end users into a secondary role, offering the only option of choosing between either privacy or functionalities. In this paper, we aim at improving the trustability of Android apps by proposing a user-centric approach to the flexible management of Android permissions.The proposed approach empowers end users to selectively grant permission by specifying (i) the desired level of permissions granularity and (ii) the specific features of the app in which the chosen permission levels are granted. Four experiments have been designed, conducted, and reported for evaluating it. The experiments consider performance, usability, and acceptance from both the end users and developers perspective. Results confirm confidence on the approach.",1939-3520,,10.1109/TSE.2019.2941936,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844813,Android Permissions;Static Analysis;Trustability,Privacy;Runtime;Usability;Social networking (online);Libraries;Fatigue;Smart phones,,,,2.0,,,,19 Sep 2019,,,IEEE,IEEE Early Access Articles
1907,547,Accelerating Continuous Integration by Caching Environments and Inferring Dependencies,K. Gallaba; Y. Junqueira; J. Ewart; S. Mcintosh,"Department of Electrical & Computer Engineering, McGill University, Montreal, Quebec, Canada, H3A 0E9 (e-mail: keheliya.gallaba@mail.mcgill.ca); Engineering, YourBase Inc., Redmond, Washington, United States, (e-mail: yves@yourbase.io); Engineering, YourBase Inc., Redmond, Washington, United States, (e-mail: john@yourbase.io); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: shane.mcintosh@uwaterloo.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"To facilitate the rapid release cadence of modern software (on the order of weeks, days, or even hours), software development organizations invest in practices like Continuous Integration (CI), where each change submitted by developers is built (e.g., compiled, tested, linted) to detect problematic changes early. A fast and efficient build process is crucial to provide timely CI feedback to developers. If CI feedback is too slow, developers may switch contexts to other tasks, which is known to be a costly operation for knowledge workers. Thus, minimizing the build execution time for CI services is an important task. While recent work has made several important advances in the acceleration of CI builds, optimizations often depend upon explicitly defined build dependency graphs (e.g., make, Gradle, CloudBuild, Bazel). These hand-maintained graphs may be (a) underspecified, leading to incorrect build behaviour; or (b) overspecified, leading to missed acceleration opportunities. In this paper, we propose Kotinos'a language-agnostic approach to infer data from which build acceleration decisions can be made without relying upon build specifications. After inferring this data, our approach accelerates CI builds by caching the build environment and skipping unaffected build steps. Kotinos is at the core of a commercial CI service with a growing customer base. To evaluate Kotinos, we mine 14,364 historical CI build records spanning three proprietary and seven open-source software projects. We find that: (1) at least 87.9% of the builds activate at least one Kotinos acceleration; and (2) 74% of accelerated builds achieve a speed-up of two-fold with respect to their non-accelerated counterparts. Moreover, (3) the benefits of Kotinos can also be replicated in open source software systems; and (4) Kotinos imposes minimal resource overhead (i.e., < 1% median CPU usage, 2 MB - 2.2 GB median memory usage, and 0.4 GB - 5.2 GB median storage overhead) and does not compromise build outcomes. Our results suggest that migration to Kotinos yields substantial benefits with minimal investment of effort (e.g., no migration of build systems is necessary).",1939-3520,,10.1109/TSE.2020.3048335,Mitacs; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311876,Automated Builds;Build Systems;Continuous Integration,Acceleration;Software;Tools;Statistics;Sociology;Organizations;Testing,,,,,,,IEEE,31 Dec 2020,,,IEEE,IEEE Early Access Articles
1908,548,Studying Bad Updates of Top Free-to-Download Apps in the Google Play Store,S. Hassan; C. Bezemer; A. E. Hassan,"Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,15 Jul 2020,2020,46,7,773,793,"Developers always focus on delivering high-quality updates to improve, or maintain the rating of their apps. Prior work has studied user reviews by analyzing all reviews of an app. However, this app-level analysis misses the point that users post reviews to provide their feedback on a certain update. For example, two bad updates of an app with a history of good updates would not be spotted using app-level analysis. In this paper, we examine reviews at the update-level to better understand how users perceive bad updates. We focus our study on the top 250 bad updates (i.e., updates with the highest increase in the percentage of negative reviews relative to the prior updates of the app) from 26,726 updates of 2,526 top free-to-download apps in the Google Play Store. We find that feature removal and UI issues have the highest increase in the percentage of negative reviews. Bad updates with crashes and functional issues are the most likely to be fixed by a later update. However, developers often do not mention these fixes in the release notes. Our work demonstrates the necessity of an update-level analysis of reviews to capture the feelings of an app's user-base about a particular update.",1939-3520,,10.1109/TSE.2018.2869395,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457304,Mobile app reviews;Google Play Store;bad updates;Android mobile apps,Google;Computer bugs;Feature extraction;Global Positioning System;User interfaces;History,Android (operating system);mobile computing;user interfaces,free-to-download apps;Google Play Store;user reviews;update-level analysis;UI issues;Android mobile apps,,2.0,,49.0,IEEE,11 Sep 2018,,,IEEE,IEEE Journals
1909,549,"Perceptions, Expectations, and Challenges in Defect Prediction",Z. Wan; X. Xia; A. E. Hassan; D. Lo; J. Yin; X. Yang,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada; School of Information Systems, Singapore Management University, Singapore; College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China",IEEE Transactions on Software Engineering,11 Nov 2020,2020,46,11,1241,1266,"Defect prediction has been an active research area for over four decades. Despite numerous studies on defect prediction, the potential value of defect prediction in practice remains unclear. To address this issue, we performed a mixed qualitative and quantitative study to investigate what practitioners think, behave and expect in contrast to research findings when it comes to defect prediction. We collected hypotheses from open-ended interviews and a literature review of defect prediction papers that were published at ICSE, ESEC/FSE, ASE, TSE and TOSEM in the last 6 years (2012-2017). We then conducted a validation survey where the hypotheses became statements or options of our survey questions. We received 395 responses from practitioners from over 33 countries across five continents. Some of our key findings include: 1) Over 90 percent of respondents are willing to adopt defect prediction techniques. 2) There exists a disconnect between practitioners' perceptions and well supported research evidence regarding defect density distribution and the relationship between file size and defectiveness. 3) 7.2 percent of the respondents reveal an inconsistency between their behavior and perception regarding defect prediction. 4) Defect prediction at the feature level is the most preferred level of granularity by practitioners. 5) During bug fixing, more than 40 percent of the respondents acknowledged that they would make a “work-around” fix rather than correct the actual error-causing code. Through a qualitative analysis of free-form text responses, we identified reasons why practitioners are reluctant to adopt defect prediction tools. We also noted features that practitioners expect defect prediction tools to deliver. Based on our findings, we highlight future research directions and provide recommendations for practitioners.",1939-3520,,10.1109/TSE.2018.2877678,National Key Research and Development Program of China; NSFC Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502824,Defect prediction;empirical study;practitioner;survey,Interviews;Tools;Software;Bibliographies;Computer bugs;Companies;Continents,program debugging;software development management;software maintenance;software metrics;software quality;software reliability,defect prediction papers;defect prediction techniques;defect prediction tools;bug fixing;efficiency 90.0 percent;efficiency 7.2 percent;efficiency 40.0 percent,,9.0,,103.0,IEEE,23 Oct 2018,,,IEEE,IEEE Journals
1910,550,CHiP: A Configurable Hybrid Parallel Covering Array Constructor,H. Mercan; C. Yilmaz; K. Kaya,"Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1270,1291,"We present a configurable, hybrid, and parallel covering array constructor, called CHiP. CHiP is parallel in that it utilizes vast amount of parallelism provided by graphics processing units (GPUs). CHiP is hybrid in that it bundles the bests of two construction approaches for computing covering arrays; a metaheuristic search-based approach for efficiently covering a large portion of the required combinations and a constraint satisfaction-based approach for effectively covering the remaining hard-to-cover-by-chance combinations. CHiP is configurable in that a trade-off between covering array sizes and construction times can be made. We have conducted a series of experiments, in which we compared the efficiency and effectiveness of CHiP to those of a number of existing constructors by using both full factorial designs and well-known benchmarks. In these experiments, we report new upper bounds on covering array sizes, demonstrating the effectiveness of CHiP, and the first results for a higher coverage strength, demonstrating the scalability of CHiP.",1939-3520,,10.1109/TSE.2018.2837759,Türkiye Bilimsel ve Teknolojik Araştirma Kurumu; Nvidia; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360512,Covering arrays;parallel computing;graphics processing units;CUDA;metaheuristic search;constraint satisfaction problem,Simulated annealing;Graphics processing units;Parallel processing;Benchmark testing;Upper bound;Scalability,constraint satisfaction problems;graphics processing units;parallel architectures;search problems,full factorial designs;covering array sizes;hard-to-cover-by-chance combinations;GPU;graphics processing units;CHiP;constraint satisfaction-based approach;metaheuristic search-based approach;construction approaches;configurable hybrid parallel covering array constructor,,2.0,,59.0,IEEE,17 May 2018,,,IEEE,IEEE Journals
1911,551,Metamorphic Testing of RESTful Web APIs,S. Segura; J. A. Parejo; J. Troya; A. Ruiz-Cortés,"Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain; Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain; Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain; Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain",IEEE Transactions on Software Engineering,11 Nov 2018,2018,44,11,1083,1099,"Web Application Programming Interfaces (APIs) allow systems to interact with each other over the network. Modern Web APIs often adhere to the REST architectural style, being referred to as RESTful Web APIs. RESTful Web APIs are decomposed into multiple resources (e.g., a video in the YouTube API) that clients can manipulate through HTTP interactions. Testing Web APIs is critical but challenging due to the difficulty to assess the correctness of API responses, i.e., the oracle problem. Metamorphic testing alleviates the oracle problem by exploiting relations (so-called metamorphic relations) among multiple executions of the program under test. In this paper, we present a metamorphic testing approach for the detection of faults in RESTful Web APIs. We first propose six abstract relations that capture the shape of many of the metamorphic relations found in RESTful Web APIs, we call these Metamorphic Relation Output Patterns (MROPs). Each MROP can then be instantiated into one or more concrete metamorphic relations. The approach was evaluated using both automatically seeded and real faults in six subject Web APIs. Among other results, we identified 60 metamorphic relations (instances of the proposed MROPs) in the Web APIs of Spotify and YouTube. Each metamorphic relation was implemented using both random and manual test data, running over 4.7K automated tests. As a result, 11 issues were detected (3 in Spotify and 8 in YouTube), 10 of them confirmed by the API developers or reproduced by other users, supporting the effectiveness of the approach.",1939-3520,,10.1109/TSE.2017.2764464,European Commission (FEDER) and Spanish Government; Andalusian Government project COPAS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074764,Metamorphic testing;REST;RESTful Web services;web API,Testing;YouTube;Web services;Companies;Standards;Manuals;Indexes,application program interfaces;hypermedia;program testing;social networking (online);transport protocols;Web services,metamorphic relation output pattern;web application programming interfaces;RESTful web API;REST architectural style;HTTP interaction;oracle problem;abstract relation;MROP;YouTube;Spotify,,14.0,,63.0,,19 Oct 2017,,,IEEE,IEEE Journals
1912,552,Machine Learning-Based Prototyping of Graphical User Interfaces for Mobile Apps,K. Moran; C. Bernal-Cárdenas; M. Curcio; R. Bonett; D. Poshyvanyk,"Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA",IEEE Transactions on Software Engineering,12 Feb 2020,2020,46,2,196,221,"It is common practice for developers of user-facing software to transform a mock-up of a graphical user interface (GUI) into code. This process takes place both at an application's inception and in an evolutionary context as GUI changes keep pace with evolving features. Unfortunately, this practice is challenging and time-consuming. In this paper, we present an approach that automates this process by enabling accurate prototyping of GUIs via three tasks: detection, classification, and assembly. First, logical components of a GUI are detected from a mock-up artifact using either computer vision techniques or mock-up metadata. Then, software repository mining, automated dynamic analysis, and deep convolutional neural networks are utilized to accurately classify GUI-components into domain-specific types (e.g., toggle-button). Finally, a data-driven, K-nearest-neighbors algorithm generates a suitable hierarchical GUI structure from which a prototype application can be automatically assembled. We implemented this approach for Android in a system called ReDraw. Our evaluation illustrates that ReDraw achieves an average GUI-component classification accuracy of 91 percent and assembles prototype applications that closely mirror target mock-ups in terms of visual affinity while exhibiting reasonable code structure. Interviews with industrial practitioners illustrate ReDraw's potential to improve real development workflows.",1939-3520,,10.1109/TSE.2018.2844788,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374985,GUI;CNN;mobile;prototyping;machine-learning;mining software repositories,Graphical user interfaces;Software;Task analysis;Prototypes;Metadata;Androids;Humanoid robots,computer vision;data mining;graphical user interfaces;image classification;learning (artificial intelligence);mobile computing;neural nets;program testing,prototype application;GUI-component classification accuracy;assembles prototype applications;target mock-ups;reasonable code structure;machine learning-based prototyping;graphical user interface;mobile applications;user-facing software;evolutionary context;GUI changes;logical components;computer vision techniques;software repository mining;automated dynamic analysis;deep convolutional neural networks;hierarchical GUI structure,,6.0,,109.0,IEEE,7 Jun 2018,,,IEEE,IEEE Journals
1913,553,Comparing Methods for Large-Scale Agile Software Development: A Systematic Literature Review,H. Edison; X. Wang; K. Conboy,"The Maersk Mc Kinney Moller Institute, Syddansk Universitet, DK-5230 Odense, Syddanmark, Denmark, (e-mail: hedis@mmmi.sdu.dk); Computer Science, Free University of Bozen-Bolzano, 18956 Bolzano, Trentino-Alto Adige, Italy, (e-mail: xiaofeng.wang@unibz.it); Business Information Systems, National University of Ireland Galway, H91 TK33 Galway, Galway, Ireland, (e-mail: Kieran.Conboy@nuigalway.ie)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Following the highly pervasive and effective use of agile methods at the team level, many software organisations now wish to replicate this success at the organisational level, adopting large-scale agile methods such as SAFe, Scrum-at-Scale, and others. However, this has proven significantly challenging. An analysis of the extant literature reveals a disparate set of studies across each individual method, with no cross-method comparison based on empirical evidence. This systematic literature review compares the main large-scale agile methods, namely SAFe, LeSS, Scrum-at-Scale, DAD, and the Spotify model. It is the first study to analyse and compare each of the method's principles, practices, tools, and metrics in a standardised manner. For each method, it presents not just the original method specifications but also all extensions and modifications to each method proposed by subsequent empirical research. It includes in this comparison not just commercial large-scale methods but also those that have been custom-built in organisations such as Nokia, Ericsson, and others. Based on the findings reported in this study, practitioners can make a more informed decision as to which commercial method or method component or, indeed, custom-built method is better suited to their needs. Our study reveals a number of theoretical and practical issues in the current literature, such as an emphasis on the practices of commercial frameworks at the expense of their underlying principles, or indeed any of the custom method. A set of challenges and success factors associated with the use of large-scale agile methods are identified. The study also identifies a number of research gaps to be addressed across methods.",1939-3520,,10.1109/TSE.2021.3069039,Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387593,large-scale agile;critical assessment;challenges and success factors;systematic literature review,Bibliographies;Systematics;Software;Tools;Measurement;Information systems;Libraries,,,,,,,CCBY,26 Mar 2021,,,IEEE,IEEE Early Access Articles
1914,554,"A Rigorous Framework for Specification, Analysis and Enforcement of Access Control Policies",A. Margheri; M. Masi; R. Pugliese; F. Tiezzi,"University of Southampton, Southampton, United Kingdom; Tiani “Spirit” GmbH, Wien, Austria; Dipartimento di Statistica, Università degli Studi di Firenze, Firenze, Italy; Università di Camerino, Camerino, Italy",IEEE Transactions on Software Engineering,8 Jan 2019,2019,45,1,2,33,"Access control systems are widely used means for the protection of computing systems. They are defined in terms of access control policies regulating the access to system resources. In this paper, we introduce a formally-defined, fully-implemented framework for specification, analysis and enforcement of attribute-based access control policies. The framework rests on FACPL, a language with a compact, yet expressive, syntax for specification of real-world access control policies and with a rigorously defined denotational semantics. The framework enables the automated verification of properties regarding both the authorisations enforced by single policies and the relationships among multiple policies. Effectiveness and performance of the analysis rely on a semantic-preserving representation of FACPL policies in terms of SMT formulae and on the use of efficient SMT solvers. Our analysis approach explicitly addresses some crucial aspects of policy evaluation, such as missing attributes, erroneous values and obligations, which are instead overlooked in other proposals. The framework is supported by Java-based tools, among which an Eclipse-based IDE offering a tailored development and analysis environment for FACPL policies and a Java library for policy enforcement. We illustrate the framework and its formal ingredients by means of an e-Health case study, while its effectiveness is assessed by means of performance stress tests and experiments on a well-established benchmark.",1939-3520,,10.1109/TSE.2017.2765640,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8081817,Attribute-based access control;policy languages;policy analysis;SMT,Semantics;Authorization;Tools;Syntactics;Proposals;Java,authorisation;Java;programming language semantics,access control systems;attribute-based access control policies;real-world access control policies;rigorously defined denotational semantics;FACPL policies;authorisations;semantic-preserving representation;SMT formulae;SMT solvers;Java-based tools;Eclipse-based IDE,,5.0,,68.0,,24 Oct 2017,,,IEEE,IEEE Journals
1915,555,Where2Change: Change Request Localization for App Reviews,T. Zhang; J. Chen; X. Zhan; X. Luo; D. Lo; H. Jiang,"Faculty of Information Technology, Macau University of Science and Technology, Macao, China (e-mail: tazhang@must.edu.mo); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csjcchen@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxzhan@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxluo@comp.polyu.edu.hk); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: jianghe@dlut.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Million of mobile apps have been released to the market. App developers usually extract useful information from user reviews to maintain and evolve mobile apps. One of the important activities that developers need to do while reading user reviews is to locate the source code related to requested changes. Unfortunately, this manual work is costly and time consuming since: (1) an app can receive thousands of reviews, and (2) a mobile app can consist of hundreds of source code files. To address this challenge, Palomba et al. recently proposed CHANGEADVISOR that utilizes user reviews to locate source code to be changed. However, we find that it cannot identify real source code to be changed for part of reviews. In this paper, we propose a novel approach that can achieve higher accuracy in change localization. Our approach first extracts the informative sentences (i.e., user feedback) from user reviews and identifies user feedback related to various problems and feature requests, and then cluster the corresponding user feedback into groups. Each group reports the similar users' needs. Next, these groups are mapped to issue reports by using W ord2V ec. The resultant enriched text consisting of user feedback and their corresponding issue reports is used to identify source code classes that should be changed by using our novel weight selection-based cosine similarity metric. We have evaluated the new proposed change request localization approach (Where2Change) on 31,597 user reviews and 3,272 issue reports of 10 open source mobile apps. The experiments demonstrate that Where2Change can successfully locate more source code classes related to the change requests for more user feedback clusters than CHANGEADVISOR as demonstrated by higher Top-N and Recall values. In addition, we also compare the performance of Where2Change and two previous Information Retrieval (IR)-based fault localization technologies:BLUiR and BLIA. The results showed that our approach performs better than them. We also conduct an empirical study to investigate the value of using both user reviews and historical issue reports for change request localization; the results shown that historical issue reports can help to improve the performance of change localization.",1939-3520,,10.1109/TSE.2019.2956941,Natural Science Foundation of Heilongjiang Province; National Natural Science Foundation of China; Hong Kong RGC Project; National Key Research and Development Plan of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924692,User review;Issue report;Mobile app;Change Request localization;Software maintenance,Information retrieval;Measurement;Task analysis;Tools;Feature extraction;Software maintenance,,,,2.0,,,CCBY,5 Dec 2019,,,IEEE,IEEE Early Access Articles
1916,556,Uncovering the Periphery: A Qualitative Survey of Episodic Volunteering in Free/Libre and Open Source Software Communities,A. Barcomb; A. Kaufmann; D. Riehle; K. -J. Stol; B. Fitzgerald,"Open Source Research Group, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Open Source Research Group, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Open Source Research Group, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Lero, Irish Software Research Centre, University College Cork, Cork, Ireland; Lero, Irish Software Research Centre, University of Limerick, Limerick, Ireland",IEEE Transactions on Software Engineering,16 Sep 2020,2020,46,9,962,980,"Free/Libre and Open Source Software (FLOSS) communities are composed, in part, of volunteers, many of whom contribute infrequently. However, these infrequent volunteers contribute to the sustainability of FLOSS projects, and should ideally be encouraged to continue participating, even if they cannot be persuaded to contribute regularly. Infrequent contributions are part of a trend which has been widely observed in other sectors of volunteering, where it has been termed “episodic volunteering” (EV). Previous FLOSS research has focused on the Onion model, differentiating core and peripheral developers, with the latter considered as a homogeneous group. We argue this is too simplistic, given the size of the periphery group and the myriad of valuable activities they perform beyond coding. Our exploratory qualitative survey of 13 FLOSS communities investigated what episodic volunteering looks like in a FLOSS context. EV is widespread in FLOSS communities, although not specifically managed. We suggest several recommendations for managing EV based on a framework drawn from the volunteering literature. Also, episodic volunteers make a wide range of value-added contributions other than code, and they should neither be expected nor coerced into becoming habitual volunteers.",1939-3520,,10.1109/TSE.2018.2872713,Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477174,Community management;episodic volunteering;free software;open source software;peripheral developer,Companies;Lenses;Open source software;Sustainable development;Task analysis,public domain software,episodic volunteering;open source software communities;infrequent volunteers;FLOSS projects;episodic volunteers;value-added contributions;habitual volunteers;Free/Libre,,1.0,,142.0,CCBY,30 Sep 2018,,,IEEE,IEEE Journals
1917,557,Topology-Specific Synthesis of Self-Stabilizing Parameterized Systems with Constant-Space Processes,A. Ebnenasir; A. P. Klinkhamer,"Department of Computer Science, Michigan Technological University, Houghton, MI, USA; Google, Mountain View, CA, USA",IEEE Transactions on Software Engineering,16 Mar 2021,2021,47,3,614,629,"This paper investigates the synthesis of parameterized systems that are self-stabilizing by construction. To this end, we present several significant results. First, we show a counterintuitive result that despite the undecidability of verifying self-stabilization for parameterized unidirectional rings, synthesizing self-stabilizing unidirectional rings is decidable! This is surprising because it is known that, in general, the synthesis of distributed systems is harder than their verification. Second, we present a topology-specific synthesis method (derived from our proof of decidability) that generates the state transition system of template processes of parameterized self-stabilizing systems with elementary unidirectional topologies (e.g., rings, chains, trees). We also provide a software tool that implements our synthesis algorithms and generates interesting self-stabilizing parameterized unidirectional rings in less than 50 microseconds on a regular laptop. We validate the proposed synthesis algorithms for decidable cases in the context of several interesting distributed protocols. Third, we show that synthesis of self-stabilizing bidirectional rings remains undecidable.",1939-3520,,10.1109/TSE.2019.2901485,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651426,Self-stabilization;distributed programming;formal methods;program synthesis,Topology;Protocols;Convergence;Software algorithms;Portable computers;Automata;Transforms,decidability;distributed algorithms;formal specification;formal verification;stability;topology,distributed protocols;decidability proof;undecidability;constant-space process;topology-specific synthesis;self-stabilizing parameterized unidirectional rings;bidirectional rings;synthesis algorithms;elementary unidirectional topologies;parameterized self-stabilizing systems;template process;state transition system;distributed systems;self-stabilization;self-stabilizing parameterized systems,,,,43.0,IEEE,24 Feb 2019,,,IEEE,IEEE Journals
1918,558,Detecting Trivial Mutant Equivalences via Compiler Optimisations,M. Kintis; M. Papadakis; Y. Jia; N. Malevris; Y. Le Traon; M. Harman,"Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette 4365, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette 4365, Luxembourg; CREST Centre, University College London, London, United Kingdom; Athens University of Economics and Business, Athens, Greece; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette 4365, Luxembourg; CREST Centre, University College London, London, United Kingdom",IEEE Transactions on Software Engineering,16 Apr 2018,2018,44,4,308,333,"Mutation testing realises the idea of fault-based testing, i.e., using artificial defects to guide the testing process. It is used to evaluate the adequacy of test suites and to guide test case generation. It is a potentially powerful form of testing, but it is well-known that its effectiveness is inhibited by the presence of equivalent mutants. We recently studied Trivial Compiler Equivalence (TCE) as a simple, fast and readily applicable technique for identifying equivalent mutants for C programs. In the present work, we augment our findings with further results for the Java programming language. TCE can remove a large portion of all mutants because they are determined to be either equivalent or duplicates of other mutants. In particular, TCE equivalent mutants account for 7.4 and 5.7 percent of all C and Java mutants, while duplicated mutants account for a further 21 percent of all C mutants and 5.4 percent Java mutants, on average. With respect to a benchmark ground truth suite (of known equivalent mutants), approximately 30 percent (for C) and 54 percent (for Java) are TCE equivalent. It is unsurprising that results differ between languages, since mutation characteristics are language-dependent. In the case of Java, our new results suggest that TCE may be particularly effective, finding almost half of all equivalent mutants.",1939-3520,,10.1109/TSE.2017.2684805,"Research Centre of Athens University of Economics and Business (RC/AUEB); National Research Fund, Luxembourg; Microsoft Azure; UK EPSRC projects; Centre for Research on Evolution Search and Testing (CREST); UCL; EPSRC project; Microsoft Azure; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882714,Mutation testing;equivalent mutants;duplicated mutants;compiler optimisation,Java;Testing;Optimization;Syntactics;Program processors;Electronic mail,Java;program compilers;program testing,mutation testing;test case generation;Java programming language;TCE equivalent mutants;trivial mutant equivalences detection;fault-based testing;TCE duplicated mutants;Java mutants;compiler equivalence,,10.0,,75.0,CCBY,20 Mar 2017,,,IEEE,IEEE Journals
1919,559,Tracking Buggy Files: New Efficient Adaptive Bug Localization Algorithm,M. M. Fejzer; J. Narebski; P. M. Przymus; K. Stencel,"The Faculty of Mathematics and Computer Science, Nicolaus Copernicus University in Torun, 49577 Torun, Kuyavian-Pomeranian Voivodeship, Poland, (e-mail: mfejzer@mat.umk.pl); Faculty of Mathematics and Computer Science, Nicolaus Copernicus University in Torun, 49577 Torun, Kuyavian-Pomeranian Voivodeship, Poland, (e-mail: jnareb@mat.umk.pl); The Faculty of Mathematics and Computer Science, Nicolaus Copernicus University in Torun, 49577 Torun, Kuyavian-Pomeranian Voivodeship, Poland, (e-mail: piotr.przymus@mat.umk.pl); Institute of Informatics, University of Warsaw Faculty of Mathematics Informatics and Mechanics, 121883 Warszawa, Masovian Voivodeship, Poland, (e-mail: stencel@mimuw.edu.pl)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Upon receiving a new bug report, developers need to find its cause in the source code. Bug localization can be helped by a tool that ranks all source files according to how likely they include the bug. This problem was thoroughly examined by numerous scientists. We introduce a novel adaptive bug localization algorithm. The concept behind it is based on new feature weighting approaches and an adaptive selection algorithm utilizing pointwise learntorank method. The algorithm is evaluated on publicly available datasets, and is competitive in terms of accuracy and required computational resources compared to stateoftheart. Additionally, to improve reproducibility we provide extended datasets that include computed features and partial steps, and we also provide the source code.",1939-3520,,10.1109/TSE.2021.3064447,Narodowa Agencja Wymiany Akademickiej; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372820,Bug reports;software maintenance;learning to rank,Computer bugs;Location awareness;Software;History;Software algorithms;Machine learning algorithms;Training,,,,,,,CCBY,8 Mar 2021,,,IEEE,IEEE Early Access Articles
1920,560,Toward a Smell-Aware Bug Prediction Model,F. Palomba; M. Zanoni; F. A. Fontana; A. De Lucia; R. Oliveto,"Delft University of Technology, Delft, The Netherlands; University of Milano-Bicocca, Milano, MI, Italy; University of Milano-Bicocca, Milano, MI, Italy; University of Salerno, Fisciano, SA, Italy; University of Molise, Campobasso, Italy",IEEE Transactions on Software Engineering,12 Feb 2019,2019,45,2,194,218,"Code smells are symptoms of poor design and implementation choices. Previous studies empirically assessed the impact of smells on code quality and clearly indicate their negative impact on maintainability, including a higher bug-proneness of components affected by code smells. In this paper, we capture previous findings on bug-proneness to build a specialized bug prediction model for smelly classes. Specifically, we evaluate the contribution of a measure of the severity of code smells (i.e., code smell intensity) by adding it to existing bug prediction models based on both product and process metrics, and comparing the results of the new model against the baseline models. Results indicate that the accuracy of a bug prediction model increases by adding the code smell intensity as predictor. We also compare the results achieved by the proposed model with the ones of an alternative technique which considers metrics about the history of code smells in files, finding that our model works generally better. However, we observed interesting complementarities between the set of buggy and smelly classes correctly classified by the two models. By evaluating the actual information gain provided by the intensity index with respect to the other metrics in the model, we found that the intensity index is a relevant feature for both product and process metrics-based models. At the same time, the metric counting the average number of code smells in previous versions of a class considered by the alternative model is also able to reduce the entropy of the model. On the basis of this result, we devise and evaluate a smell-aware combined bug prediction model that included product, process, and smell-related features. We demonstrate how such model classifies bug-prone code components with an F-Measure at least 13 percent higher than the existing state-of-the-art models.",1939-3520,,10.1109/TSE.2017.2770122,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097044,Code smells;bug prediction;empirical study;mining software repositories,Computer bugs;Measurement;Predictive models;Indexes;Software;Complexity theory;Entropy,program debugging;software maintenance;software quality,bug-prone code components;process metrics-based models;code smell intensity;smell-aware combined bug prediction model,,4.0,,132.0,,7 Nov 2017,,,IEEE,IEEE Journals
1921,561,Toxic Code Snippets on Stack Overflow,C. Ragkhitwetsagul; J. Krinke; M. Paixao; G. Bianco; R. Oliveto,"Computer Science, Faculty of Information and Communication Technology, Mahidol University, Salaya, Thailand; Computer Science, University College London, London, United Kingdom; Computer Science, Universidade Estadual do Ceara, Fortaleza, Brazil; Computer Science, Universita degli Studi del Molise, Campobasso, Italy; Department of Bioscience and Territory, University of Molise, Pesche, Italy",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,560,581,"Online code clones are code fragments that are copied from software projects or online sources to Stack Overflow as examples. Due to an absence of a checking mechanism after the code has been copied to Stack Overflow, they can become toxic code snippets, e.g., they suffer from being outdated or violating the original software license. We present a study of online code clones on Stack Overflow and their toxicity by incorporating two developer surveys and a large-scale code clone detection. A survey of 201 high-reputation Stack Overflow answerers (33 percent response rate) showed that 131 participants (65 percent) have ever been notified of outdated code and 26 of them (20 percent) rarely or never fix the code. 138 answerers (69 percent) never check for licensing conflicts between their copied code snippets and Stack Overflow's CC BY-SA 3.0. A survey of 87 Stack Overflow visitors shows that they experienced several issues from Stack Overflow answers: mismatched solutions, outdated solutions, incorrect solutions, and buggy code. 85 percent of them are not aware of CC BY-SA 3.0 license enforced by Stack Overflow, and 66 percent never check for license conflicts when reusing code snippets. Our clone detection found online clone pairs between 72,365 Java code snippets on Stack Overflow and 111 open source projects in the curated Qualitas corpus. We analysed 2,289 non-trivial online clone candidates. Our investigation revealed strong evidence that 153 clones have been copied from a Qualitas project to Stack Overflow. We found 100 of them (66 percent) to be outdated, of which 10 were buggy and harmful for reuse. Furthermore, we found 214 code snippets that could potentially violate the license of their original software and appear 7,112 times in 2,427 GitHub projects.",1939-3520,,10.1109/TSE.2019.2900307,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643998,Code clone detection;stack overflow;outdated code;software licensing,Cloning;Licenses;Software;Programming;Computer bugs;Security;Tutorials,Java;public domain software;software reusability,toxic code snippets;online code clones;code fragments;large-scale code clone detection;high-reputation Stack Overflow answerers;outdated code;Stack Overflow answers;buggy code;Java code snippets;code snippet reusing;Stack Overflow's CC BY-SA 3.0 license;software project;curated Qualitas corpus;efficiency 20.0 percent;efficiency 69.0 percent;efficiency 85.0 percent;efficiency 66.0 percent;efficiency 33.0 percent;efficiency 65.0 percent,,5.0,,82.0,IEEE,19 Feb 2019,,,IEEE,IEEE Journals
1922,562,Orderly Generation of Test Data via Sorting Mutant Branches Based on Their Dominance Degrees for Weak Mutation Testing,X. Yao; G. Zhang; F. Pan; D. Gong; C. Wei,"School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: yaoxj@cumt.edu.cn); School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: zhanggongjie@126.com); School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: fengpan0315@126.com); School of Information and Electrical Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: dwgong@vip.163.com); School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: 1536113693@qq.com)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Compared with traditional structural test criteria, test data generated based on mutation testing are proved more effective at detecting faults. However, not all test data have the same potence in detecting software faults. If test data are prioritized while generating for mutation testing, the defect detectability of the test suite can be further strengthened. In view of this, we propose a method of test data generation for weak mutation testing via sorting mutant branches based on their dominance degrees. First, the problem of weak mutation testing is transformed into that of covering mutant branches for a transformed program. Then, the dominance relation of mutant branches in the transformed program is analyzed to obtain the non-dominated mutant branches and their dominance degrees. Following that, we prioritize all non-dominated mutant branches in descending order by virtue of their dominance degrees. Finally, the test data are generated in an orderly manner by selecting the mutant branches sequentially. The experimental results on 15 programs show that compared with other methods, the proposed test data generation method can not only improve the error detectability of the test suite, but also has higher efficiency.",1939-3520,,10.1109/TSE.2020.3014960,Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162547,Software testing;Mutation testing;Test data generation;Mutant branch;Dominance degree,Software;Software testing;Fault detection;Control engineering;Data mining;Sorting,,,,,,,,7 Aug 2020,,,IEEE,IEEE Early Access Articles
1923,563,The Impact of Correlated Metrics on the Interpretation of Defect Models,J. Jiarpakdee; C. Tantithamthavorn; A. E. Hassan,"Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,320,331,"Defect models are analytical models for building empirical theories related to software quality. Prior studies often derive knowledge from such models using interpretation techniques, e.g., ANOVA Type-I. Recent work raises concerns that correlated metrics may impact the interpretation of defect models. Yet, the impact of correlated metrics in such models has not been investigated. In this paper, we investigate the impact of correlated metrics on the interpretation of defect models and the improvement of the interpretation of defect models when removing correlated metrics. Through a case study of 14 publicly- available defect datasets, we find that (1) correlated metrics have the largest impact on the consistency, the level of discrepancy, and the direction of the ranking of metrics, especially for ANOVA techniques. On the other hand, we find that removing all correlated metrics (2) improves the consistency of the produced rankings regardless of the ordering of metrics (except for ANOVA Type-I); (3) improves the consistency of ranking of metrics among the studied interpretation techniques; (4) impacts the model performance by less than 5 percentage points. Thus, when one wishes to derive sound interpretation from defect models, one must (1) mitigate correlated metrics especially for ANOVA analyses; and (2) avoid using ANOVA Type-I even if all correlated metrics are removed.",1939-3520,,10.1109/TSE.2019.2891758,Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8608002,Software quality assurance;defect models;hypothesis testing;correlated metrics;model specification,Measurement;Analytical models;Analysis of variance;Complexity theory;Software quality;Computer bugs;Correlation,software quality;statistical analysis,defect models;software quality;interpretation techniques;ANOVA Type-I,,5.0,,88.0,IEEE,10 Jan 2019,,,IEEE,IEEE Journals
1924,564,A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches,S. Herbold; A. Trautsch; J. Grabowski,"University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany",IEEE Transactions on Software Engineering,16 Sep 2018,2018,44,9,811,833,"Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However, within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article, we provide a benchmark for CPDP. We replicate 24 approaches proposed by researchers between 2008 and 2015 and evaluate their performance on software products from five different data sets. Based on our benchmark, we determined that an approach proposed by Camargo Cruz and Ochimizu (2009) based on data standardization performs best and is always ranked among the statistically significant best results for all metrics and data sets. Approaches proposed by Turhan et al. (2009), Menzies et al. (2011), and Watanabe et al. (2008) are also nearly always among the best results. Moreover, we determined that predictions only seldom achieve a high performance of 0.75 recall, precision, and accuracy. Thus, CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.",1939-3520,,10.1109/TSE.2017.2724538,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7972992,Cross-project defect prediction;benchmark;comparison;replication,Benchmark testing;Prediction methods;Software;Quality assurance;Measurement;Correlation,project management;quality assurance;software metrics;software quality,benchmark cross-Project Defect Prediction approaches;CPDP;quality assurance;software projects;software products;data standardization;performance metrics;data sets,,25.0,,90.0,,11 Jul 2017,,,IEEE,IEEE Journals
1925,565,A Framework for Temporal Verification Support in Domain-Specific Modelling,B. Meyers; H. Vangheluwe; J. Denil; R. Salay,"Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Computer Science, University of Toronto, Toronto, ON, Canada",IEEE Transactions on Software Engineering,16 Apr 2020,2020,46,4,362,404,"In Domain-Specific Modelling (DSM) the general goal is to provide Domain-Specific Modelling Languages (DSMLs) for domain users to model systems using concepts and notations they are familiar with, in their problem domain. Verifying whether a model satisfies a set of requirements is considered to be an important challenge in DSM, but is nevertheless mostly neglected. We present a solution in the form of ProMoBox, a framework that integrates the definition and verification of temporal properties in discrete-time behavioural DSMLs, whose semantics can be described as a schedule of graph rewrite rules. Thanks to the expressiveness of graph rewriting, this covers a very large class of problems. With ProMoBox, the domain user models not only the system with a DSML, but also its properties, input model, run-time state and output trace. A DSML is thus comprised of five sublanguages, which share domain-specific syntax, and are generated from a single metamodel. Generic transformations to and from a verification backbone ensure that both the language engineer and the domain user are shielded from underlying notations and techniques. We explicitly model the ProMoBox framework's process in the paper. Furthermore, we evaluate ProMoBox to assert that it supports the specification and verification of properties in a highly flexible and automated way.",1939-3520,,10.1109/TSE.2018.2859946,Flanders Make vzw; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419296,Domain-specific modelling;model-driven engineering;language engineering,Syntactics;Semantics;Formal specifications;Formal verification;Model driven engineering;Model checking,formal specification;formal verification;graph theory;rewriting systems;temporal logic,domain-specific modelling languages;domain user models;input model;share domain-specific syntax;ProMoBox framework;temporal verification support;discrete-time behavioural DSML;generic transformations;verification backbone,,4.0,,88.0,IEEE,25 Jul 2018,,,IEEE,IEEE Journals
1926,566,"On the Nature of Merge Conflicts: A Study of 2,731 Open Source Java Projects Hosted by GitHub",G. Ghiotto; L. Murta; M. Barros; A. van der Hoek,"Computing Institute, Fluminense Federal University, Niterói, RJ, Brazil; Computing Institute, Fluminense Federal University, Niterói, RJ, Brazil; Information Systems Program, UNIRIO, Rio de Janeiro, RJ, Brazil; Department of Informatics, University of California Irvine, Irvine, CA, USA",IEEE Transactions on Software Engineering,13 Aug 2020,2020,46,8,892,915,"When multiple developers change a software system in parallel, these concurrent changes need to be merged to all appear in the software being developed. Numerous merge techniques have been proposed to support this task, but none of them can fully automate the merge process. Indeed, it has been reported that as much as 10 to 20 percent of all merge attempts result in a merge conflict, meaning that a developer has to manually complete the merge. To date, we have little insight into the nature of these merge conflicts. What do they look like, in detail? How do developers resolve them? Do any patterns exist that might suggest new merge techniques that could reduce the manual effort? This paper contributes an in-depth study of the merge conflicts found in the histories of 2,731 open source Java projects. Seeded by the manual analysis of the histories of five projects, our automated analysis of all 2,731 projects: (1) characterizes the merge conflicts in terms of number of chunks, size, and programming language constructs involved, (2) classifies the manual resolution strategies that developers use to address these merge conflicts, and (3) analyzes the relationships between various characteristics of the merge conflicts and the chosen resolution strategies. Our results give rise to three primary recommendations for future merge techniques, that - when implemented - could on one hand help in automatically resolving certain types of conflicts and on the other hand provide the developer with tool-based assistance to more easily resolve other types of conflicts that cannot be automatically resolved.",1939-3520,,10.1109/TSE.2018.2871083,Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; Conselho Nacional de Desenvolvimento Científico e Tecnológico; Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468085,Software merge;merge conflict;merge resolution,Tools;History;Electronic mail;Java;Software;Task analysis,Java;merging;parallel processing;public domain software,merge conflicts;open source Java projects;GitHub;software system;parallel software;programming language,,8.0,,45.0,IEEE,19 Sep 2018,,,IEEE,IEEE Journals
1927,567,Automatically Assessing Code Understandability,S. Scalabrino; G. Bavota; C. Vendome; M. Linares-Vásquez; D. Poshyvanyk; R. Oliveto,"University of Molise, Campobasso, CB, Italy; Università della Svizzera italiana(USI), Lugano, Switzerland; Miami University, Oxford, OH, USA; Universidad de los Andes, Bogota, Colombia; College of William & Mary, Williamsburg, VA, USA; University of Molise, Campobasso, CB, Italy",IEEE Transactions on Software Engineering,16 Mar 2021,2021,47,3,595,613,"Understanding software is an inherent requirement for many maintenance and evolution tasks. Without a thorough understanding of the code, developers would not be able to fix bugs or add new features timely. Measuring code understandability might be useful to guide developers in writing better code, and could also help in estimating the effort required to modify code components. Unfortunately, there are no metrics designed to assess the understandability of code snippets. In this work, we perform an extensive evaluation of 121 existing as well as new code-related, documentation-related, and developer-related metrics. We try to (i) correlate each metric with understandability and (ii) build models combining metrics to assess understandability. To do this, we use 444 human evaluations from 63 developers and we obtained a bold negative result: none of the 121 experimented metrics is able to capture code understandability, not even the ones assumed to assess quality attributes apparently related, such as code readability and complexity. While we observed some improvements while combining metrics in models, their effectiveness is still far from making them suitable for practical applications. Finally, we conducted interviews with five professional developers to understand the factors that influence their ability to understand code snippets, aiming at identifying possible new metrics.",1939-3520,,10.1109/TSE.2019.2901468,SNF project JITRA; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651396,Software metrics;code understandability;empirical study;negative result,Complexity theory;Software;Computer bugs;Readability metrics;Software measurement;Indexes,program debugging;software maintenance;software metrics;software quality,code-related;code components;measuring code understandability;evolution tasks;maintenance;inherent requirement;understanding software;assessing code understandability;code snippets;professional developers;code readability;121 experimented metrics;444 human evaluations;developer-related metrics;documentation-related,,8.0,,55.0,IEEE,24 Feb 2019,,,IEEE,IEEE Journals
1928,568,Locating Latent Design Information in Developer Discussions: A Study on Pull Requests,G. Viviani; M. Famelis; X. Xia; C. Janik-Jones; G. C. Murphy,"Department of Computer Science, University of British Columbia, Vancouver, British Columbia Canada (e-mail: vivianig@cs.ubc.ca); Department of Computer Science and Operations Research, Université de Montréal, Montréal, Quebec Canada (e-mail: famelis@iro.umontreal.ca); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: xxkidd@zju.edu.cn); Department of Speech-Language Pathology, University Of Toronto, Toronto, Ontario Canada (e-mail: cal.janik.jones@mail.utoronto.ca); Department of Computer Science, University of British Columbia, Vancouver, British Columbia Canada (e-mail: murphy@cs.ubc.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"A software system's design determines many of its properties, such as maintainability and performance. An understanding of design is needed to maintain system properties as changes to the system occur. Unfortunately, many systems do not have up-to-date design documentation and approaches that have been developed to recover design often focus on how a system works by extracting structural and behaviour information rather than information about the desired design properties, such as robustness or performance. In this paper, we explore whether it is possible to automatically locate where design is discussed in on-line developer discussions. We investigate and introduce a classifier that can locate paragraphs in pull request discussions that pertain to design with an average AUC score of 0.87. We show that this classifier agrees with human developers in 81% of cases considered. To show how the location of latent design information in developer discussions is useful, we present a proof-of-concept tool that can identify design concerns automatically from the identified design discussions and describe how this extracted design information might be provided to developers.",1939-3520,,10.1109/TSE.2019.2924006,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742578,Design Discussions;Latent Design;Conversations;Prediction Model;Design Recovery,System analysis and design;Tools;Documentation;Robustness;Predictive models;Software systems,,,,3.0,,,,20 Jun 2019,,,IEEE,IEEE Early Access Articles
1929,569,How Does Refactoring Impact Security When Improving Quality? A Security-Aware Refactoring Approach,C. Abid; M. Kessentini; V. Alizadeh; M. Dhouadi; R. Kazman,"CIS, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: cabid@umich.edu); CIS, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: marouane@umich.edu); CIS Department, University of Michigan, Dearborn, Michigan United States (e-mail: alizadeh@umich.edu); CIS Department, University of Michigan, Dearborn, Michigan United States (e-mail: mounad@umich.edu); Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii United States 96822 (e-mail: kazman@hawaii.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"While state of the art of software refactoring research uses various quality attributes to identify refactoring opportunities and evaluate refactoring recommendations, the impact of refactoring on the security of software systems when improving other quality objectives is under-explored. It is critical to understand how a system is resistant to security risks after refactoring to improve quality metrics. For instance, refactoring is widely used to improve the reusability of code, however such an improvement may increase the attack surface due to the created abstractions. Increasing the spread of security-critical classes in the design to improve modularity may result in reducing the resilience of software systems to attacks. In this paper, we investigated the possible impact of improving different quality attributes (e.g. reusability, extendibility, etc.), from the QMOOD model, effectiveness on a set of 8 security metrics defined in the literature related to the data access. We also studied the impact of different refactorings on these static security metrics. Then, we proposed a multi-objective refactoring recommendation approach to find a balance between quality attributes and security based on the correlation results to guide the search. We evaluated our tool on 30 open source projects. We also collected the practitioner perceptions on the refactorings recommended by our tool in terms of the possible impact on both security and other quality attributes. Our results confirm that developers need to make trade-offs between security and other qualities when refactoring software systems due to the negative correlations between them.",1939-3520,,10.1109/TSE.2020.3005995,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130035,Quality;critical code;security metrics;attack surface;refactoring;multi-objective search,Security;Measurement;Tools;Correlation;Software systems;Computer bugs,,,,,,,,30 Jun 2020,,,IEEE,IEEE Early Access Articles
1930,570,Discipline Matters: Refactoring of Preprocessor Directives in the #ifdef  Hell,F. Medeiros; M. Ribeiro; R. Gheyi; S. Apel; C. Kästner; B. Ferreira; L. Carvalho; B. Fonseca,"Federal Institute of Alagoas, AL, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Department of Computing and Systems, Federal University of Campina Grande, PB, Brazil; Department of Informatics and Mathematics, University of Passau, Passau, Germany; Institute for Software Research, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil",IEEE Transactions on Software Engineering,14 May 2018,2018,44,5,453,469,"The C preprocessor is used in many C projects to support variability and portability. However, researchers and practitioners criticize the C preprocessor because of its negative effect on code understanding and maintainability and its error proneness. More importantly, the use of the preprocessor hinders the development of tool support that is standard in other languages, such as automated refactoring. Developers aggravate these problems when using the preprocessor in undisciplined ways (e.g., conditional blocks that do not align with the syntactic structure of the code). In this article, we proposed a catalogue of refactorings and we evaluated the number of application possibilities of the refactorings in practice, the opinion of developers about the usefulness of the refactorings, and whether the refactorings preserve behavior. Overall, we found 5,670 application possibilities for the refactorings in 63 real-world C projects. In addition, we performed an online survey among 246 developers, and we submitted 28 patches to convert undisciplined directives into disciplined ones. According to our results, 63 percent of developers prefer to use the refactored (i.e., disciplined) version of the code instead of the original code with undisciplined preprocessor usage. To verify that the refactorings are indeed behavior preserving, we applied them to more than 36 thousand programs generated automatically using a model of a subset of the C language, running the same test cases in the original and refactored programs. Furthermore, we applied the refactorings to three real-world projects: BusyBox, OpenSSL, and SQLite. This way, we detected and fixed a few behavioral changes, 62 percent caused by unspecified behavior in the C programming language.",1939-3520,,10.1109/TSE.2017.2688333,"Conselho Nacional de Desenvolvimento Científico e Tecnológico; FAPEAL PPGs; CAPES; DEVASSES; European Union's Seventh Framework Programme for research, technological development and demonstration; NSF; Science of Security Lablet; AFRL; DARPA; German Research Foundation; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888579,Configurable systems;preprocessors;and refactoring,Syntactics;C languages;Guidelines;Linux;Kernel;Standards,C language;program compilers;program diagnostics;program processors;public domain software;software maintenance,refactored programs;preprocessor directives;C preprocessor;automated refactoring;preprocessor usage;BusyBox;OpenSSL;SQLite;C programming language,,5.0,,50.0,,28 Mar 2017,,,IEEE,IEEE Journals
1931,571,Gray Computing: A Framework for Computing with Background JavaScript Tasks,Y. Pan; J. White; Y. Sun; J. Gray,"Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN; Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN; Department of Computer Science, California State Polytechnic University, Pomona, CA; Department of Computer Science, University of Alabama, Tuscaloosa, AL",IEEE Transactions on Software Engineering,12 Feb 2019,2019,45,2,171,193,"Website visitors are performing increasingly complex computational work on the websites' behalf, such as validating forms, rendering animations, and producing data visualizations. In this article, we explore the possibility of increasing the work offloaded to web visitors' browsers. The idle computing cycles of web visitors can be turned into a large-scale distributed data processing engine, which we term gray computing. Past research has looked primarily at either volunteer computing with specialized clients or browser-based volunteer computing where the visitors keep their browsers open to a single web page for a long period of time. This article provides a comprehensive analysis of the architecture, performance, security, cost effectiveness, user experience, and other issues of gray computing distributed data processing engines with heterogeneous computing power, non-uniform page view times, and high computing pool volatility. Several real-world applications are examined and gray computing is shown to be cost effective for a number of complex tasks ranging from computer vision to bioinformatics to cryptology.",1939-3520,,10.1109/TSE.2017.2772812,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8105894,Software economics;JavaScript;web browser;cloud computing,Distributed processing;Browsers;Data processing;Web pages;Cloud computing,data visualisation;grey systems;Java;volunteer computing;Web sites,computer vision;gray computing;website visitors;increasingly complex computational work;idle computing cycles;large-scale distributed data processing engine;browser-based volunteer computing;heterogeneous computing power;JavaScript tasks;computing pool volatility;bioinformatics;cryptology;data visualizations,,,,96.0,,13 Nov 2017,,,IEEE,IEEE Journals
1932,572,Metric-based Fault Prediction for Spreadsheets,P. Koch; K. Schekotihin; D. Jannach; B. Hofer; F. Wotawa,"Applied Informatics, Alpen-Adria Universitat Klagenfurt Fakultat fur Technische Wissenschaften, 392327 Klagenfurt, Carinthia Austria (e-mail: patrick.koch@aau.at); Applied Informatics, Alpen-Adria Universitat Klagenfurt Fakultat fur Technische Wissenschaften, 392327 Klagenfurt, Carinthia Austria (e-mail: konstantin.schekotihin@aau.at); Applied Informatics, Alpen-Adria Universitat Klagenfurt Fakultat fur Technische Wissenschaften, 392327 Klagenfurt, Carinthia Austria (e-mail: Dietmar.Jannach@aau.at); Institute for Software Technology, Technische Universitat Graz, 27253 Graz, Steiermark Austria (e-mail: bhofer@ist.tugraz.at); Institute for Software Technology, TU Graz, Graz, Styria Austria 8010 (e-mail: wotawa@ist.tugraz.at)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Electronic spreadsheets are widely used in organizations for various data analytics and decision-making tasks. Even though faults within such spreadsheets are common and can have significant negative consequences, today's tools for creating and handling spreadsheets provide limited support for fault detection, localization, and repair. Being able to predict whether a certain part of a spreadsheet is faulty or not is often central for the implementation of such supporting functionality. In this work, we propose a novel approach to fault prediction in spreadsheet formulas, which combines an extensive catalog of spreadsheet metrics with modern machine learning algorithms. An analysis of the individual metrics from our catalog reveals that they are generally suited to discover a wide range of faults. Their predictive power is, however, limited when considered in isolation. Therefore, in our approach we apply supervised learning algorithms to obtain fault predictors that utilize all data provided by multiple spreadsheet metrics from our catalog. Experiments on different datasets containing faulty spreadsheets show that particularly Random Forests classifiers are often effective. As a result, the proposed method is in many cases able to make highly accurate predictions whether a given formula of a spreadsheet is faulty.",1939-3520,,10.1109/TSE.2019.2944604,Austrian Science Fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859280,Spreadsheets;Fault Prediction;Machine Learning,Measurement;Software;Prediction algorithms;Predictive models;Tools;Radio frequency;Task analysis,,,,,,,CCBY,4 Oct 2019,,,IEEE,IEEE Early Access Articles
1933,573,"An Empirical Comparison of Combinatorial Testing, Random Testing and Adaptive Random Testing",H. Wu; C. Nie; J. Petke; Y. Jia; M. Harman,"Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; CREST, Computer Science, University College London, London, United Kingdom; Facebook Inc., London, United Kingdom; Facebook Inc., London, United Kingdom",IEEE Transactions on Software Engineering,13 Mar 2020,2020,46,3,302,320,"We present an empirical comparison of three test generation techniques, namely, Combinatorial Testing (CT), Random Testing (RT) and Adaptive Random Testing (ART), under different test scenarios. This is the first study in the literature to account for the (more realistic) testing setting in which the tester may not have complete information about the parameters and constraints that pertain to the system, and to account for the challenge posed by faults (in terms of failure rate). Our study was conducted on nine real-world programs under a total of 1683 test scenarios (combinations of available parameter and constraint information and failure rate). The results show significant differences in the techniques' fault detection ability when faults are hard to detect (failure rates are relatively low). CT performs best overall; no worse than any other in 98 percent of scenarios studied. ART enhances RT, and is comparable to CT in 96 percent of scenarios, but its computational cost can be up to 3.5 times higher than CT when the program is highly constrained. Additionally, when constraint information is unavailable for a highly-constrained program, a large random test suite is as effective as CT or ART, yet its computational cost of test generation is significantly lower than that of other techniques.",1939-3520,,10.1109/TSE.2018.2852744,National Key Research and Development Plan; Nanjing University; DAASE EPSRC; EPSRC Fellowship; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405609,Combinatorial testing;random testing;adaptive random testing,Testing;Subspace constraints;Computational efficiency;Fault detection;Analytical models;Software systems,program testing,constraint information;failure rate;CT;random test suite;empirical comparison;combinatorial testing;adaptive random testing;test generation techniques;different test scenarios;testing setting;test scenarios;efficiency 98.0 percent;efficiency 96.0 percent,,5.0,,57.0,OAPA,6 Jul 2018,,,IEEE,IEEE Journals
1934,574,PPChecker: Towards Accessing the Trustworthiness of Android Apps’ Privacy Policies,L. Yu; X. Luo; J. Chen; H. Zhou; T. Zhang; H. Chang; H. K. N. Leung,"Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Law, University of Hong Kong, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,221,242,"Recent years have witnessed a sharp increase of malicious apps that steal users' personal information. To address users' concerns about privacy risks and to comply with data protection laws, more and more apps are supplied with privacy policies written in natural language to help users understand an app's privacy practices. However, little is known whether these privacy policies are trustworthy or not. Questionable privacy policies may be prepared by careless app developers or someone with malicious intention. In this paper, we carry out a systematic study on privacy policy by proposing a novel approach to automatically identify five kinds of problems in privacy policy. After tackling several challenging issues, we implement the approach in a system, named PPChecker, and evaluate it with real apps and their privacy policies. The experimental results show that PPChecker can effectively identify questionable privacy policies with high precision. Applying PPChecker to 2,500 popular apps, we find that 1,850 apps (i.e., 74.0 percent) have at least one kind of problems. This study sheds light on the research of improving and regulating apps' privacy policies.",1939-3520,,10.1109/TSE.2018.2886875,Hong Kong RGC Projects; HKPolyU Research; National Natural Science Foundation of China; China Postdoctoral Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576579,Android apps;privacy policy,Privacy;Google;Natural languages;Mobile handsets;Data protection;Force,Android (operating system);data privacy;mobile computing;trusted computing,PPChecker;malicious apps;privacy policy;app developers;Android app privacy policies,,,,92.0,OAPA,14 Dec 2018,,,IEEE,IEEE Journals
1935,575,Integrative Double Kaizen Loop (IDKL): Towards a Culture of Continuous Learning and Sustainable Improvements for Software Organizations,O. Al-Baik; J. Miller,"Department of Electronics & Computer Engineering, University of Alberta Edmonton, Edmonton, AB, Canada; Department of Electronics & Computer Engineering, University of Alberta Edmonton, Edmonton, AB, Canada",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1189,1210,"In the past decades, software organizations have been relying on implementing process improvement methods to advance quality, productivity, and predictability of their development and maintenance efforts. However, these methods have proven to be challenging to implement in many situations, and when implemented, their benefits are often not sustained. Commonly, the workforce requires guidance during the initial deployment, but what happens after the guidance stops? Why do not traditional improvement methods deliver the desired results? And, how do we maintain the improvements when they are realized? In response to these questions, we have combined social and organizational learning methods with Lean's continuous improvement philosophy, Kaizen, which has resulted in an IDKL model that has successfully promoted continuous learning and improvement. The IDKL has evolved through a real-life project with an industrial partner; the study employed ethnographic action research with 231 participants and had lasted for almost 3 years. The IDKL requires employees to continuously apply small improvements to the daily routines of the work-procedures. The small improvements by themselves are unobtrusive. However, the IDKL has helped the industrial partner to implant continuous improvement as a daily habit. This has led to realizing sustainable and noticeable improvements. The findings show that on average, Lead Time has dropped by 46 percent, Process Cycle Efficiency has increased by 137 percent, First-Pass Process Yield has increased by 27 percent, and Customer Satisfaction has increased by 25 percent.",1939-3520,,10.1109/TSE.2018.2829722,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345680,Kaizen;lean;organization learning;double loop learning;case study;empirical research,Continuous improvement;Research and development;Standards organizations;Learning systems,continuous improvement;customer satisfaction;organisational aspects;personnel;project management;software development management,process improvement methods;continuous improvement philosophy;first-pass process yield;process cycle efficiency;industrial partner;IDKL model;organizational learning methods;social learning methods;software organizations;sustainable improvements;continuous learning;integrative double Kaizen loop;efficiency 46.0 percent;efficiency 137.0 percent;efficiency 27.0 percent;efficiency 25.0 percent;time 3.0 year,,,,66.0,IEEE,24 Apr 2018,,,IEEE,IEEE Journals
1936,576,ProXray: Protocol Model Learning and Guided Firmware Analysis,F. Fowze; D. J. Tian; G. Hernandez; K. Butler; T. Yavuz,"Electrical and Computer Engineering, University of florida, Gainesville, Florida United States 32611 (e-mail: farhaan104@ufl.edu); CISE Department, University of Florida Herbert Wertheim College of Engineering, 130358 Gainesville, Florida United States (e-mail: root@davetingjian.org); CISE Department, University of Florida Herbert Wertheim College of Engineering, 130358 Gainesville, Florida United States (e-mail: grant.hernandez@ufl.edu); Computer and Information Science and Engineering, University of Florida, Gainesville, Florida United States 32611-1906 (e-mail: butler@ufl.edu); Electrical and Computer Engineering, University of Florida, Gainesville, Florida United States 32611 (e-mail: tuba@ece.ufl.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The number of Internet of Things (IoT) has reached 7 billion globally in early 2018 and are nearly ubiquitous in daily life. Knowing whether or not these devices are safe and secure to use is becoming critical. IoT devices usually implement communication protocols such as USB and Bluetooth within firmware to allow a wide range of functionality. Thus analyzing firmware using domain knowledge from these protocols is vital to understand device behavior, detect implementation bugs, and identify malicious components. Unfortunately, due to the complexity of these protocols, there is usually no formal specification available that can help automate the firmware analysis; as a result significant manual effort is currently required to study these protocols and to reverse engineer the device firmware. In this paper, we propose a new firmware analysis methodology using symbolic execution called ProXray, which can learn a protocol model from known firmware, and apply the model to recognize the protocol relevant fields and detect functionality within unknown firmware automatically. After the training phase, ProXray can fully automate the firmware analysis process while supporting user's queries in the form of protocol relevant constraints. We have applied ProXray to the USB and the Bluetooth protocols by learning protocol constraint models from firmware that implement these protocols. We are then able to map protocol fields and identify USB functionality automatically within all 6 unknown USB firmware while achieving more than an order of magnitude speedup in achieving protocol relevant targets in unknown Bluetooth firmware. Our model achieved high coverage of the USB and Bluetooth specifications for several important protocol fields. ProXray provides a new method to apply domain knowledge to firmware analysis automatically.",1939-3520,,10.1109/TSE.2019.2939526,Division of Computer and Network Systems; Semiconductor Research Corporation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823941,Protocol Learning;Model Extraction;Firmware;Symbolic Execution,Protocols;Universal Serial Bus;Bluetooth;Hidden Markov models;Analytical models;Microprogramming;Feature extraction,,,,,,,,4 Sep 2019,,,IEEE,IEEE Early Access Articles
1937,577,Correction of “A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches”,S. Herbold; A. Trautsch; J. Grabowski,"University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,632,636,"Unfortunately, the article “A Comparative Study to Benchmark Cross-project Defect Prediction Approaches” has a problem in the statistical analysis which was pointed out almost immediately after the pre-print of the article appeared online. While the problem does not negate the contribution of the the article and all key findings remain the same, it does alter some rankings of approaches used in the study. Within this correction, we will explain the problem, how we resolved it, and present the updated results.",1939-3520,,10.1109/TSE.2018.2790413,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8248781,Cross-project defect prediction;benchmark;comparison;replication;correction,Sociology;Measurement;Benchmark testing;Statistical analysis;Ranking (statistics);Terminology,,,,,,13.0,,8 Jan 2018,,,IEEE,IEEE Journals
1938,578,Safety Practices in Requirements Engineering: The Uni-REPM Safety Module,J. Vilela; J. Castro; L. E. G. Martins; T. Gorschek,"Universidade Federal do Ceará (UFC), Quixadá, Cear??, Brazil; Universidade Federal de Pernambuco (UFPE), Recife-PE, Brazil; Departamento de Ciência e Tecnologia, Universidade Federal de São Paulo (UNIFESP), José dos, S??o Paulo, Brazil; Blekinge Institute of Technology (BTH), Karlskrona, Sweden",IEEE Transactions on Software Engineering,13 Mar 2020,2020,46,3,222,250,"Context: Software is an important part in safety-critical system (SCS) development since it is becoming a major source of hazards. Requirements-related hazards have been associated with many accidents and safety incidents. Requirements issues tend to be mitigated in companies with high processes maturity levels since they do their business in a systematic, consistent and proactive approach. However, requirements engineers need systematic guidance to consider safety concerns early in the development process. Goal: the paper investigates which safety practices are suitable to be used in the Requirements Engineering (RE) process for SCS and how to design a safety maturity model for this area. Method: we followed the design science methodology to propose Uni-REPM SCS, a safety module for Unified Requirements Engineering Process Maturity Model (Uni-REPM). We also conducted a static validation with two practitioners and nine academic experts to evaluate its coverage, correctness, usefulness, and applicability. Results: The module has seven main processes, fourteen sub-processes and 148 practices that form the basis of safety processes maturity. Moreover, we describe its usage through a tool. Conclusions: The validation indicates a good coverage of practices and well receptivity by the experts. Finally, the module can help companies in evaluating their current practices.",1939-3520,,10.1109/TSE.2018.2846576,Funda????o de Amparo ?? Ci??ncia e Tecnologia do Estado de Pernambuco; Conselho Nacional de Desenvolvimento Cient??fico e Tecnol??gico; The Knowledge Foundation Sweden; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382315,Safety-critical systems;requirements engineering;maturity models;Uni-REPM;safety engineering,Safety;Companies;Software;Capability maturity model;Requirements engineering;Systematics;Standards,DP industry;safety-critical software;systems analysis,design science methodology;Uni-REPM SCS;Unified Requirements Engineering Process Maturity Model;safety processes maturity;safety practices;Uni-REPM safety module;safety-critical system development;Requirements-related hazards;high processes maturity levels;safety maturity model,,,,98.0,IEEE,12 Jun 2018,,,IEEE,IEEE Journals
1939,579,Companies' Participation in OSS Development - An Empirical Study of OpenStack,Y. Zhang; M. Zhou; A. Mockus; Z. Jin,"School of Electronics Engineering and Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: yuxiaz@pku.edu.cn); School of Electronics Engineering and Computer Science, Peking University, Software Institute, Beijing, Beijing China 100871 (e-mail: zhmh@pku.edu.cn); Avaya Labs Research, Avaya Labs, Basking Ridge, New Jersey United States 07920 (e-mail: audris@utk.edu); School of EECS, Peking University, Beijing, Beijing China 100871 (e-mail: zhijin@pku.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Commercial participation continues to grow in open source software (OSS) projects and novel arrangements appear to emerge in company-dominated projects and ecosystems. What is the nature of these novel arrangements' Does volunteers' participation remain critical for these ecosystems' Despite extensive research on commercial participation in OSS, the exact nature and extent of company contributions to OSS development, and the impact of this engagement may have on the volunteer community have not been clarified. To bridge the gap, we perform an exploratory study of OpenStack: a large OSS ecosystem with intense commercial participation. We quantify companies' contributions via the developers that they provide and the commits made by those developers. We find that companies made far more contributions than volunteers and the distribution of the contributions made by different companies is also highly unbalanced. We observe eight unique contribution models based on companies' commercial objectives and characterize each model according to three dimensions: contribution intensity, extent, and focus. Companies providing full cloud solutions tend to make both intensive (more than other companies) and extensive (involving a wider variety of projects) contributions. Usage-oriented companies make extensive but less intense contributions. Companies driven by particular business needs focus their contributions on the specific projects addressing these needs. Minor contributors include community players (e.g., the Linux Foundation) and research groups. A model relating the number of volunteers to the diversity of contribution, shows a strong positive association between them.",1939-3520,,10.1109/TSE.2019.2946156,National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862903,Open source ecosystem;software development;commercial participation;contribution extent;contribution intensity;contribution focus,Companies;Ecosystems;Biological system modeling;Software;Cloud computing;Linux,,,,3.0,,,CCBY,8 Oct 2019,,,IEEE,IEEE Early Access Articles
1940,580,Text Filtering and Ranking for Security Bug Report Prediction,F. Peters; T. T. Tun; Y. Yu; B. Nuseibeh,"University of Limerick, Limerick, Ireland; Department of Computing and Communications, The Open University, Milton Keynes, United Kingdom; Department of Computing and Communications, The Open University, Milton Keynes, United Kingdom; University of Limerick, Limerick, Ireland",IEEE Transactions on Software Engineering,12 Jun 2019,2019,45,6,615,631,"Security bug reports can describe security critical vulnerabilities in software products. Bug tracking systems may contain thousands of bug reports, where relatively few of them are security related. Therefore finding unlabelled security bugs among them can be challenging. To help security engineers identify these reports quickly and accurately, text-based prediction models have been proposed. These can often mislabel security bug reports due to a number of reasons such as class imbalance, where the ratio of non-security to security bug reports is very high. More critically, we have observed that the presence of security related keywords in both security and non-security bug reports can lead to the mislabelling of security bug reports. This paper proposes FARSEC, a framework for filtering and ranking bug reports for reducing the presence of security related keywords. Before building prediction models, our framework identifies and removes non-security bug reports with security related keywords. We demonstrate that FARSEC improves the performance of text-based prediction models for security bug reports in 90 percent of cases. Specifically, we evaluate it with 45,940 bug reports from Chromium and four Apache projects. With our framework, we mitigate the class imbalance issue and reduce the number of mislabelled security bug reports by 38 percent.",1939-3520,,10.1109/TSE.2017.2787653,Science Foundation Ireland; H2020 European Research Council; EPSRC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240740,Security cross words;security related keywords;security bug reports;text filtering;ranking;prediction models;transfer learning,Security;Computer bugs;Predictive models;Software;Data models;Measurement;Buildings,information filtering;program debugging;public domain software;security of data;text analysis,security bug report prediction;security critical vulnerabilities;text-based prediction models;text filtering;software products;FARSEC,,3.0,,50.0,,27 Dec 2017,,,IEEE,IEEE Journals
1941,581,Empirical Evaluation of Fault Localisation Using Code and Change Metrics,J. Sohn; S. Yoo,"School of Computing, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: kasio555@kaist.ac.kr); School of Computing, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: shin.yoo@kaist.ac.kr)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Fault localisation aims to reduce the debugging efforts of human developers by highlighting the program elements that are suspected to be the root cause of the observed failure. Spectrum Based Fault Localisation (SBFL), a coverage based approach, has been widely studied in many researches as a promising localisation technique. Recently, however, it has been proven that SBFL techniques have reached the limit of further improvement. To overcome the limitation, we extend SBFL with code and change metrics that have been mainly studied in defect prediction, such as size, age, and churn. FLUCCS, our fault learn-to-rank localisation technique, employs both existing SBFL formulas and these metrics as input. We investigate the effect of employing code and change metrics for fault localisation using four different learn-to-rank techniques: Genetic Programming, Gaussian Process Modelling, Support Vector Machine, and Random Forest. We evaluate the performance of FLUCCS with 386 real world faults collected from Defects4J repository. The results show that FLUCCS with code and change metrics places 144 faults at the top and 304 faults within the top ten. This is a significant improvement over the state-of-art SBFL formulas, which can locate 65 and 212 faults at the top and within the top ten, respectively. We also investigate the feasibility of cross-project transfer learning of fault localisation. The results show that, while there exist project-specific properties that can be exploited for better localisation per project, ranking models learnt from one project can be applied to others without significant loss of effectiveness.",1939-3520,,10.1109/TSE.2019.2930977,National Research Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772166,Fault Localisation;SBSE;Genetic Programming,Measurement;Debugging;Genetic programming;Feature extraction;Support vector machines;Training,,,,3.0,,,,25 Jul 2019,,,IEEE,IEEE Early Access Articles
1942,582,MSeer—An Advanced Technique for Locating Multiple Bugs in Parallel,R. Gao; W. E. Wong,"University of Texas at Dallas, Richardson, TX; University of Texas at Dallas, Richardson, TX",IEEE Transactions on Software Engineering,13 Mar 2019,2019,45,3,301,318,"In practice, a program may contain multiple bugs. The simultaneous presence of these bugs may deteriorate the effectiveness of existing fault-localization techniques to locate program bugs. While it is acceptable to use all failed and successful tests to identify suspicious code for programs with exactly one bug, it is not appropriate to use the same approach for programs with multiple bugs because the due-to relationship between failed tests and underlying bugs cannot be easily identified. One solution is to generate fault-focused clusters by grouping failed tests caused by the same bug into the same clusters. We propose MSeer-an advanced fault localization technique for locating multiple bugs in parallel. Our major contributions include the use of (1) a revised Kendall tau distance to measure the distance between two failed tests, (2) an innovative approach to simultaneously estimate the number of clusters and assign initial medoids to these clusters, and (3) an improved K-medoids clustering algorithm to better identify the due-to relationship between failed tests and their corresponding bugs. Case studies on 840 multiple-bug versions of seven programs suggest that MSeer performs better in terms of effectiveness and efficiency than two other techniques for locating multiple bugs in parallel.",1939-3520,,10.1109/TSE.2017.2776912,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119545,Software fault localization;parallel debugging;multiple bugs;clustering;distance metrics,Computer bugs;Clustering algorithms;Measurement;Software;Indexes;Debugging;Runtime,fault diagnosis;pattern clustering;program debugging;program testing;software fault tolerance,failed tests;corresponding bugs;multiple-bug versions;locating multiple bugs;program bugs;successful tests;underlying bugs;fault-focused clusters;MSeer;advanced fault localization technique;K-medoids clustering algorithm,,3.0,,76.0,,23 Nov 2017,,,IEEE,IEEE Journals
1943,583,Verification Templates for the Analysis of User Interface Software Design,M. D. Harrison; P. Masci; J. C. Campos,"School of Computing, Newcastle University, Newcastle upon Tyne, United Kingdom; HASLab/INESC TEC and Universidade do Minho, Braga, Portugal; HASLab/INESC TEC and Universidade do Minho, Braga, Portugal",IEEE Transactions on Software Engineering,26 Aug 2019,2019,45,8,802,822,"The paper describes templates for model-based analysis of usability and safety aspects of user interface software design. The templates crystallize general usability principles commonly addressed in user-centred safety requirements, such as the ability to undo user actions, the visibility of operational modes, and the predictability of user interface behavior. These requirements have standard forms across different application domains, and can be instantiated as properties of specific devices. The modeling and analysis process is carried out using the Prototype Verification System (PVS), and is further facilitated by structuring the specification of the device using a format that is designed to be generic across interactive systems. A concrete case study based on a commercial infusion pump is used to illustrate the approach. A detailed presentation of the automated verification process using PVS shows how failed proof attempts provide precise information about problematic user interface software features.",1939-3520,,10.1109/TSE.2018.2804939,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8289349,Human-computer interaction;model-based development;formal specifications;formal verification;prototype verification system (PVS),User interfaces;Safety;ISO Standards;Usability,program verification;security of data;user interfaces,user interface software design;model-based analysis;safety aspects;general usability principles;user-centred safety requirements;automated verification process;prototype verification system;verification templates,,,,62.0,,12 Feb 2018,,,IEEE,IEEE Journals
1944,584,LEILA: Formal Tool for Identifying Mobile Malicious Behaviour,G. Canfora; F. Martinelli; F. Mercaldo; V. Nardone; A. Santone; C. A. Visaggio,"Department of Engineering, University of Sannio, Benevento, BN, Italy; National Research Council of Italy (CNR), Pisa, Italy; National Research Council of Italy (CNR), Pisa, Italy; Department of Engineering, University of Sannio, Benevento, BN, Italy; Department of Bioscience and Territory, University of Molise, Pesche (IS), CB, Italy; Department of Engineering, University of Sannio, Benevento, BN, Italy",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1230,1252,"With the increasing diffusion of mobile technologies, nowadays mobile devices represent an irreplaceable tool to perform several operations, from posting a status on a social network to transfer money between bank accounts. As a consequence, mobile devices store a huge amount of private and sensitive information and this is the reason why attackers are developing very sophisticated techniques to extort data and money from our devices. This paper presents the design and the implementation of LEILA (formaL tool for idEntifying mobIle maLicious behAviour), a tool targeted at Android malware families detection. LEILA is based on a novel approach that exploits model checking to analyse and verify the Java Bytecode that is produced when the source code is compiled. After a thorough description of the method used for Android malware families detection, we report the experiments we have conducted using LEILA. The experiments demonstrated that the tool is effective in detecting malicious behaviour and, especially, in localizing the payload within the code: we evaluated real-world malware belonging to several widespread families obtaining an accuracy ranging between 0.97 and 1.",1939-3520,,10.1109/TSE.2018.2834344,H2020 EU; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356128,Security;malware;model checking;testing;Android,Malware;Androids;Humanoid robots;Payloads;Computer security;Model checking;Automata,Android (operating system);formal verification;invasive software;Java;mobile computing,LEILA;Android malware families detection;real-world malware;formal tool;mobile technologies;nowadays mobile devices;irreplaceable tool;social network;bank accounts;private information;sensitive information;sophisticated techniques;mobile malicious behaviour;identifying mobile malicious behaviour,,8.0,,55.0,IEEE,8 May 2018,,,IEEE,IEEE Journals
1945,585,The Mutation and Injection Framework: Evaluating Clone Detection Tools with Mutation Analysis,J. Svajlenko; C. K. Roy,"Department of Computer Science, University of Saskatchewan, Saskatoon, SK, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, SK, Canada",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,1060,1087,"An abundant number of clone detection tools have been proposed in the literature due to the many applications and benefits of clone detection. However, there has been difficulty in the performance evaluation and comparison of these clone detectors. This is due to a lack of reliable benchmarks, and the manual efforts required to validate a large number of candidate clones. In particular, there has been a lack of a synthetic benchmark that can precisely and comprehensively measure clone-detection recall. In this paper, we present a mutation-analysis based benchmarking framework that can be used not only to evaluate the recall of clone detection tools for different types of clones but also for specific kinds of clone edits and without any manual efforts. The framework uses an editing taxonomy of clone synthesis for generating thousands of artificial clones, injects into code bases and automatically evaluates the subject clone detection tools following the mutation analysis approach. Additionally, the framework has features where custom clone pairs could also be used in the framework for evaluating the subject tools. This gives the opportunity of evaluating specialized tools for specialized contexts such as evaluating a tool’s capability for the detection of complex Type-4 clones or real world clones without writing complex mutation operators for them. We demonstrate this framework by evaluating the performance of ten modern clone detection tools across two clone granularities (function and block) and three programming languages (Java, C and C#). Furthermore, we provide a variant of the framework that can be used to evaluate specialized tools such as for large gaped clone detection. Our experiments demonstrate confidence in the accuracy of our Mutation and Injection Framework when comparing against the expected results of the corresponding tools, and widely used real-world benchmarks such as Bellon’s benchmark and BigCloneBench. We provide features so that most clone detection tools that report clones in the form of clone pairs (either in filename/line numbers or filename/tokens) could be evaluated using the framework.",1939-3520,,10.1109/TSE.2019.2912962,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695849,Clone;clone detection;benchmark;mutation analysis;mutation operators;recall,Cloning;Tools;Benchmark testing;Software systems;Detectors;Atmospheric measurements;Particle measurements,,,,1.0,,53.0,IEEE,23 Apr 2019,,,IEEE,IEEE Journals
1946,586,Modeling and Recommending Open Source Licenses with findOSSLicense,G. M. Kapitsaki; G. Charalambous,"University of Cyprus, Nicosia, Cyprus; University of Cyprus, Nicosia, Cyprus",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,919,935,"Open source software is widely used in the software industry and the academia. Licenses applied to open source software provide the terms for its further use and distribution. Decisions regarding licensing for new software systems are essential for the system's future use. In this paper, we introduce findOSSLicense, a license recommender that guides users into choosing the appropriate open source license for their software under creation. We also introduce our license modeling concept that is used in the recommendation process. The license modeling captures the properties usually found in existing open source licenses following an analysis performed on license texts. The recommendation process of findOSSLicense is based on a hybrid recommender that uses constraint-based, content-based and collaborative filtering giving also space for flexibility in the use of the system by its end-users who can adapt some system properties. User input, but also external sources of information including existing open source projects, are considered for the creation of the recommendations, whereas licenses used in third party software employed in the software are examined on a limited basis. findOSSLicense has been evaluated with the participation of users of various expertise.",1939-3520,,10.1109/TSE.2019.2909021,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680684,Open source software;recommender systems;software reusability;software tools,Licenses;Task analysis;Encoding;Analytical models;Open source software;Law,,,,,,54.0,IEEE,2 Apr 2019,,,IEEE,IEEE Journals
1947,587,A Chaos Engineering System for Live Analysis and Falsification of Exception-handling in the JVM,L. Zhang; B. Morin; P. Haller; B. Baudry; M. Monperrus,"EECS - TCS, KTH Royal Institute of Technology, Stockholm, Stockholm Sweden 10044 (e-mail: longz@kth.se); ICT, SINTEF, Oslo, Norway Norway 0314 (e-mail: brice.morin@sintef.no); EECS - TCS, KTH Royal Institute of Technology, Stockholm, Stockholm Sweden (e-mail: phaller@kth.se); EECS - SCS, KTH Royal Institute of Technology, Stockholm, Stockholm Sweden (e-mail: baudry@kth.se); Department of Computer Science, KTH Royal Institute of Technology School of Electrical Engineering and Computer Science, Stockholm, Stockholm Sweden (e-mail: martin.monperrus@csc.kth.se)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Software systems contain resilience code to handle those failures and unexpected events happening in production. It is essential for developers to understand and assess the resilience of their systems. Chaos engineering is a technology that aims at assessing resilience and uncovering weaknesses by actively injecting perturbations in production. In this paper, we propose a novel design and implementation of a chaos engineering system in Java called ChaosMachine. It provides a unique and actionable analysis on exception-handling capabilities in production, at the level of try-catch blocks. To evaluate our approach, we have deployed ChaosMachine on top of 3 large-scale and well-known Java applications totaling 630k lines of code. Our results show that ChaosMachine reveals both strengths and weaknesses of the resilience code of a software system at the level of exception handling.",1939-3520,,10.1109/TSE.2019.2954871,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908767,dynamic analysis;exception-handling;production systems;chaos engineering,Chaos;Production;Perturbation methods;Resilience;Measurement;Monitoring;Java,,,,2.0,,,,21 Nov 2019,,,IEEE,IEEE Early Access Articles
1948,588,Towards Prioritizing Documentation Effort,P. W. McBurney; S. Jiang; M. Kessentini; N. A. Kraft; A. Armaly; M. W. Mkaouer; C. McMillan,"Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer and Information Science, University of Michigan-Dearborn, Dearborn, MI; ABB Corporate Research, Raleigh, NC; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer and Information Science, University of Michigan-Dearborn, Dearborn, MI; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN",IEEE Transactions on Software Engineering,17 Sep 2018,2018,44,9,897,913,"Programmers need documentation to comprehend software, but they often lack the time to write it. Thus, programmers must prioritize their documentation effort to ensure that sections of code important to program comprehension are thoroughly explained. In this paper, we explore the possibility of automatically prioritizing documentation effort. We performed two user studies to evaluate the effectiveness of static source code attributes and textual analysis of source code towards prioritizing documentation effort. The first study used open-source API Libraries while the second study was conducted using closed-source industrial software from ABB. Our findings suggest that static source code attributes are poor predictors of documentation effort priority, whereas textual analysis of source code consistently performed well as a predictor of documentation effort priority.",1939-3520,,10.1109/TSE.2017.2716950,National Science Foundation Graduate Research Fellowship Program; National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953505,Code documentation;program comprehension;software maintenance,Documentation;Libraries;Java;Gold;Programming;Software;Neural networks,application program interfaces;program diagnostics;public domain software;software maintenance,prioritizing documentation effort;static source code attributes;open-source API Libraries;closed-source industrial software;documentation effort priority,,1.0,,78.0,,19 Jun 2017,,,IEEE,IEEE Journals
1949,589,Better Data Labelling with EMBLEM (and how that Impacts Defect Prediction),H. Tu; Z. Yu; T. Menzies,"Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States (e-mail: hqtu@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States 27606 (e-mail: zyu9@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Standard automatic methods for recognizing problematic development commits can be greatly improved via the incremental application of human+artificial expertise. In this approach, called EMBLEM, an AI tool first explore the software development process to label commits that are most problematic. Humans then apply their expertise to check those labels (perhaps resulting in the AI updating the support vectors within their SVM learner). We recommend this human+AI partnership, for several reasons. When a new domain is encountered, EMBLEM can learn better ways to label which comments refer to real problems. Also, in studies with 9 open source software projects, labelling via EMBLEM's incremental application of human+AI is at least an order of magnitude cheaper than existing methods (approximately, eight times). Further, EMBLEM is very effective. For the data sets explored here, EMBLEM better labelling methods significantly improved Popt(20) and G-scores performance in nearly all the projects studied here.",1939-3520,,10.1109/TSE.2020.2986415,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064604,Human-in-the-loop AI;Data Labelling;Defect Prediction;Software Analytics,Labeling;Computer bugs;Data models;Software;Support vector machines;Standards;Task analysis,,,,2.0,,,,13 Apr 2020,,,IEEE,IEEE Early Access Articles
1950,590,Historical Spectrum based Fault Localization,M. Wen; J. Chen; Y. Tian; R. Wu; D. Hao; S. Han; S. C. Cheung,"Cyber Science and Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: mwenaa@cse.ust.hk); College of Intelligence and Computing, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: junjiechen@tju.edu.cn); Computer Science and Engineering, the Hong Kong University of Science and Technology, Hong Kong, Hong Kong Hong Kong (e-mail: ytianas@cse.ust.hk); the Department of Cyber Space Security, Xiamen University, 12466 Xiamen, Fujian China (e-mail: wurongxin@xmu.edu.cn); EECS,Peking University, Institute of Software, Beijing, Beijing China 100871 (e-mail: haodan@pku.edu.cn); Software Analytics, Microsoft Research Asia, Beijing, Beijing China 100080 (e-mail: shihan@microsoft.com); Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon Hong Kong (e-mail: scc@cse.ust.hk)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Spectrum-based fault localization (SBFL) techniques are widely studied and have been evaluated to be effective in locating faults. Recent studies also showed that developers from industry value automated SBFL techniques. However, their effectiveness is still limited by two main reasons. First, the test coverage information leveraged to construct the spectrum does not reflect the root cause directly. Second, SBFL suffers from the tie issue so that the buggy code entities can not be well differentiated from non-buggy ones. To address these challenges, we propose to leverage the information of version histories in fault localization based on the following two intuitions. First, version histories record how bugs are introduced to software projects and this information reflects the root cause of bugs directly. Second, the evolution histories of code can help differentiate those suspicious code entities ranked in tie by SBFL. Our intuitions are also inspired by the observations on debugging practices from large open source projects and industry. Based on the intuitions, we propose a novel technique HSFL (historical spectrum based fault localization). Specifically, HSFL identifies bug-inducing commits from the version history in the first step. It then constructs historical spectrum (denoted as Histrum) based on bug-inducing commits, which is another dimension of spectrum orthogonal to the coverage based spectrum used in SBFL. HSFL finally ranks the suspicious code elements based on our proposed Histrum and the conventional spectrum. HSFL outperforms the state-of-the-art SBFL techniques significantly on the Defects4J benchmark. Specifically, it locates and ranks the buggy statement at Top-1 for 77.8% more bugs as compared with SBFL, and 33.9% more bugs at Top-5. Besides, for the metrics MAP and MRR, HSFL achieves an average improvement of 28.3% and 40.8% over all bugs, respectively. Moreover, HSFL can also outperform other six families of fault localization techniques, and our proposed Histrum model can be integrated with different families of techniques and boost their performance.",1939-3520,,10.1109/TSE.2019.2948158,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873606,Fault Localization;Version Histories;Bug-Inducing Commits,Computer bugs;History;Debugging;Industries;Software;Benchmark testing;Maintenance engineering,,,,1.0,,,,17 Oct 2019,,,IEEE,IEEE Early Access Articles
1951,591,Coverage-Based Greybox Fuzzing as Markov Chain,M. Böhme; V. Pham; A. Roychoudhury,"Department of Computer Science, National University of Singpore, Singapore; Department of Computer Science, National University of Singpore, Singapore; Department of Computer Science, National University of Singpore, Singapore",IEEE Transactions on Software Engineering,15 May 2019,2019,45,5,489,506,"Coverage-based Greybox Fuzzing (CGF) is a random testing approach that requires no program analysis. A new test is generated by slightly mutating a seed input. If the test exercises a new and interesting path, it is added to the set of seeds; otherwise, it is discarded. We observe that most tests exercise the same few “high-frequency” paths and develop strategies to explore significantly more paths with the same number of tests by gravitating towards low-frequency paths. We explain the challenges and opportunities of CGF using a Markov chain model which specifies the probability that fuzzing the seed that exercises path i generates an input that exercises path j. Each state (i.e., seed) has an energy that specifies the number of inputs to be generated from that seed. We show that CGF is considerably more efficient if energy is inversely proportional to the density of the stationary distribution and increases monotonically every time that seed is chosen. Energy is controlled with a power schedule. We implemented several schedules by extending AFL. In 24 hours, AFLFast exposes 3 previously unreported CVEs that are not exposed by AFL and exposes 6 previously unreported CVEs 7x faster than AFL. AFLFast produces at least an order of magnitude more unique crashes than AFL. We compared AFLFast to the symbolic executor Klee. In terms of vulnerability detection, AFLFast is significantly more effective than Klee on the same subject programs that were discussed in the original Klee paper. In terms of code coverage, AFLFast only slightly outperforms Klee while a combination of both tools achieves best results by mitigating the individual weaknesses.",1939-3520,,10.1109/TSE.2017.2785841,National Research Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233151,Vulnerability detection;fuzzing;path exploration;symbolic execution;automated testing,Schedules;Markov processes;Computer crashes;Search problems;Tools;Systematics,Markov processes;probability;program diagnostics;program testing,CGF;random testing approach;program analysis;seed input;high-frequency paths;low-frequency paths;Markov chain model;code coverage;coverage-based greybox fuzzing;AFLFast,,22.0,,37.0,,21 Dec 2017,,,IEEE,IEEE Journals
1952,592,"Developer Testing in the IDE: Patterns, Beliefs, and Behavior",M. Beller; G. Gousios; A. Panichella; S. Proksch; S. Amann; A. Zaidman,"Delft University of Technology, Delft, CD, The Netherlands; Delft University of Technology, Delft, CD, The Netherlands; University of Luxembourg, Esch-sur-Alzette, Luxembourg; Technische Universität Darmstadt, Darmstadt, Germany; Technische Universität Darmstadt, Darmstadt, Germany; Delft University of Technology, Delft, CD, The Netherlands",IEEE Transactions on Software Engineering,13 Mar 2019,2019,45,3,261,284,"Software testing is one of the key activities to achieve software quality in practice. Despite its importance, however, we have a remarkable lack of knowledge on how developers test in real-world projects. In this paper, we report on a large-scale field study with 2,443 software engineers whose development activities we closely monitored over 2.5 years in four integrated development environments (IDEs). Our findings, which largely generalized across the studied IDEs and programming languages Java and C#, question several commonly shared assumptions and beliefs about developer testing: half of the developers in our study do not test; developers rarely run their tests in the IDE; most programming sessions end without any test execution; only once they start testing, do they do it extensively; a quarter of test cases is responsible for three quarters of all test failures; 12 percent of tests show flaky behavior; Test-Driven Development (TDD) is not widely practiced; and software developers only spend a quarter of their time engineering tests, whereas they think they test half of their time. We summarize these practices of loosely guiding one's development efforts with the help of testing in an initial summary on Test-Guided Development (TGD), a behavior we argue to be closer to the development reality of most developers than TDD.",1939-3520,,10.1109/TSE.2017.2776152,Dutch Science Foundation; German Federal Ministry of Education and Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8116886,Developer testing;unit tests;testing effort;field study;test-driven development (TDD);JUnit;TestRoots WatchDog;KaVE FeedBag++,Testing;Software;Visualization;Servers;Java;Androids;Humanoid robots,C# language;Java;program testing;software quality,developer testing;IDE;software testing;integrated development environments;test execution;test cases;test failures;software developers;time engineering tests;development reality;test-driven development;software engineers;test-guided development;software quality;programming languages;Java;C#;programming sessions,,11.0,,107.0,,22 Nov 2017,,,IEEE,IEEE Journals
1953,593,Diversified Third-party Library Prediction for Mobile App Development,Q. He; B. Li; F. Chen; J. Grundy; X. Xia; Y. Yang,"School of Software and Electrical Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: qhe@swin.edu.au); School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Victoria Australia (e-mail: boli@swin.edu.au); School of Information Technology, Deakin University, Burwood, Victoria Australia (e-mail: feifei.chen@deakin.edu.au); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu); Faculty of Information Technology, Monash University, 2541 MELBOURNE, Victoria Australia 3800 (e-mail: xin.xia@monash.edu); School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Victoria Australia 3122 (e-mail: yyang@swin.edu.au)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"The rapid growth of mobile apps has significantly promoted the use of third-party libraries in mobile app development. However, mobile app developers are now facing the challenge of finding useful third-party libraries for improving their apps, e.g., to enhance user interfaces, to add social features, etc. An effective approach is to leverage collaborative filtering (CF) to predict useful third-party libraries for developers. We employed Matrix Factorization (MF) approaches - the classic CF-based prediction approaches - to make the predictions based on a total of 31,432 Android apps from Google Play. However, our investigation shows that there is a significant lack of diversity in the prediction results - a small fraction of popular third-party libraries dominate the prediction results while most other libraries are ill-served. The low diversity in the prediction results limits the usefulness of the prediction because it lacks novelty and serendipity which are much appreciated by mobile app developers. In order to increase the diversity in the prediction results, we designed an innovative MF-based approach, namely LibSeek, specifically for predicting useful third-party libraries for mobile apps. It employs an adaptive weighting mechanism to neutralize the bias caused by the popularity of third-party libraries. In addition, it introduces neighborhood information, i.e., information about similar apps and similar third-party libraries, to personalize the predictions for individual apps. The experimental results show that LibSeek can significantly diversify the prediction results, and in the meantime, increase the prediction accuracy.",1939-3520,,10.1109/TSE.2020.2982154,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043686,Third-party library;prediction;mobile app development;matrix factorization;diversity;accuracy bias,Libraries;Mobile applications;Predictive models;Google;Gold;User interfaces;Collaboration,,,,2.0,,,,20 Mar 2020,,,IEEE,IEEE Early Access Articles
1954,594,Fine-grained Dynamic Resource Allocation for Big-Data Applications,L. Baresi; A. Leva; G. Quattrocchi,"Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, MI Italy (e-mail: baresi@elet.polimi.it); Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Mlano, MI Italy (e-mail: alberto.leva@polimi.it); Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, 18981 Milano, MI Italy (e-mail: giovanni.quattrocchi@polimi.it)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Big-data applications are batch applications that exploit dedicated frameworks to perform massively parallel computations across clusters of machines. The time needed to process the entirety of the inputs represents the application's response time, which can be subject to deadlines. Spark, probably the most famous incarnation of these frameworks today, allocates resources to applications statically at the beginning of the execution and deviations are not managed: to meet the applications' deadlines, resources must be allocated carefully. This paper proposes an extension to Spark, called xSpark, that is able to allocate and redistribute resources to applications dynamically to meet deadlines and cope with the execution of unanticipated applications. This work is based on two key enablers: containers, to isolate Spark's parallel executors and allow for the dynamic and fast allocation of resources, and control-theory to govern resource allocation at runtime and obtain the precision and speed that are needed. Our evaluation shows that xSpark can (i) allocate resources efficiently to execute single applications with respect to set deadlines and (ii) reduce deadline violations (w.r.t. Spark) when executing multiple concurrent applications.",1939-3520,,10.1109/TSE.2019.2931537,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778680,Distributed architectures;Control theory;Quality assurance;Batch processing systems,Sparks;Resource management;Dynamic scheduling;Containers;Task analysis;Runtime;Control theory,,,,4.0,,,,29 Jul 2019,,,IEEE,IEEE Early Access Articles
1955,595,A Developer Centered Bug Prediction Model,D. Di Nucci; F. Palomba; G. De Rosa; G. Bavota; R. Oliveto; A. De Lucia,"University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; Università della Svizzera Italiana (USI), Lugano, Switzerland; University of Molise, Pesche (IS), Campobasso, Italy; University of Salerno, Fisciano, SA, Italy",IEEE Transactions on Software Engineering,8 Jan 2018,2018,44,1,5,24,"Several techniques have been proposed to accurately predict software defects. These techniques generally exploit characteristics of the code artefacts (e.g., size, complexity, etc.) and/or of the process adopted during their development and maintenance (e.g., the number of developers working on a component) to spot out components likely containing bugs. While these bug prediction models achieve good levels of accuracy, they mostly ignore the major role played by human-related factors in the introduction of bugs. Previous studies have demonstrated that focused developers are less prone to introduce defects than non-focused developers. According to this observation, software components changed by focused developers should also be less error prone than components changed by less focused developers. We capture this observation by measuring the scattering of changes performed by developers working on a component and use this information to build a bug prediction model. Such a model has been evaluated on 26 systems and compared with four competitive techniques. The achieved results show the superiority of our model, and its high complementarity with respect to predictors commonly used in the literature. Based on this result, we also show the results of a “hybrid” prediction model combining our predictors with the existing ones.",1939-3520,,10.1109/TSE.2017.2659747,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835258,Scattering metrics;bug prediction;empirical study;mining software repositories,Measurement;Computer bugs;Predictive models;Complexity theory;Scattering;Entropy;Software,object-oriented programming;program debugging;software maintenance;software reliability,software components;hybrid prediction model;code artefacts;software defects prediction;developer centered bug prediction model,,18.0,,54.0,,26 Jan 2017,,,IEEE,IEEE Journals
1956,596,A Model-Integrated Approach to Designing Self-Protecting Systems,S. Iannucci; S. Abdelwahed; A. Montemaggio; M. Hannis; L. Leonard; J. S. King; J. A. Hamilton,"Department of Computer Science and Engineering, Mississippi State University, Starkville, MS, USA; Department of Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA, USA; Center for Cyber Innovation (CCI), Mississippi State University, Starkville, MS, USA; Center for Cyber Innovation (CCI), Mississippi State University, Starkville, MS, USA; U.S. Army Engineer Research and Development Center (ERDC), Vicksburg, MS, USA; U.S. Army Engineer Research and Development Center (ERDC), Vicksburg, MS, USA; Center for Cyber Innovation (CCI), Mississippi State University, Starkville, MS, USA",IEEE Transactions on Software Engineering,10 Dec 2020,2020,46,12,1380,1392,"One of the major trends in research on Self-Protecting Systems is to use a model of the system to be protected to predict its evolution. However, very often, devising the model requires special knowledge of mathematical frameworks, that prevents the adoption of this technique outside of the academic environment. Furthermore, some of the proposed approaches suffer from the curse of dimensionality, as their complexity is exponential in the size of the protected system. In this paper, we introduce a model-integrated approach for the design of Self-Protecting Systems, which automatically generates and solves Markov Decision Processes (MDPs) to obtain optimal defense strategies for systems under attack. MDPs are created in such a way that the size of the state space does not depend on the size of the system, but on the scope of the attack, which allows us to apply it to systems of arbitrary size.",1939-3520,,10.1109/TSE.2018.2880218,Engineer Research and Development Center; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528892,Intrusion response system;autonomic security management,Computational modeling;Servers;Microwave integrated circuits;Predictive models;Security;Mathematical model,Markov processes;security of data,model-integrated approach;protected system;Self-Protecting Systems;MarkoV decision processes;optimal defense strategies;curse of dimensionality,,1.0,,62.0,IEEE,9 Nov 2018,,,IEEE,IEEE Journals
1957,597,The Impact of Class Rebalancing Techniques on the Performance and Interpretation of Defect Prediction Models,C. Tantithamthavorn; A. E. Hassan; K. Matsumoto,"Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan",IEEE Transactions on Software Engineering,11 Nov 2020,2020,46,11,1200,1219,"Defect models that are trained on class imbalanced datasets (i.e., the proportion of defective and clean modules is not equally represented) are highly susceptible to produce inaccurate prediction models. Prior research compares the impact of class rebalancing techniques on the performance of defect models but arrives at contradictory conclusions due to the use of different choice of datasets, classification techniques, and performance measures. Such contradictory conclusions make it hard to derive practical guidelines for whether class rebalancing techniques should be applied in the context of defect models. In this paper, we investigate the impact of class rebalancing techniques on the performance measures and interpretation of defect models. We also investigate the experimental settings in which class rebalancing techniques are beneficial for defect models. Through a case study of 101 datasets that span across proprietary and open-source systems, we conclude that the impact of class rebalancing techniques on the performance of defect prediction models depends on the used performance measure and the used classification techniques. We observe that the optimized SMOTE technique and the under-sampling technique are beneficial when quality assurance teams wish to increase AUC and Recall, respectively, but they should be avoided when deriving knowledge and understandings from defect models.",1939-3520,,10.1109/TSE.2018.2876537,Grant-in-Aid for JSPS Fellows; Natural Sciences and Engineering Research Council of Canada; Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8494821,Software quality assurance;software defect prediction;class rebalancing techniques;experimental design;empirical investigation,Predictive models;Training;Analytical models;Guidelines;Context modeling;Open source software,learning (artificial intelligence);pattern classification;sampling methods;software metrics;software quality;software reliability,classification techniques;class rebalancing techniques;defect prediction models;SMOTE technique;class imbalanced datasets;performance measure,,17.0,,99.0,IEEE,17 Oct 2018,,,IEEE,IEEE Journals
1958,598,Implementing and Evaluating Candidate-Based Invariant Generation,A. Betts; N. Chong; P. Deligiannis; A. F. Donaldson; J. Ketema,"Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom",IEEE Transactions on Software Engineering,16 Jul 2018,2018,44,7,631,650,"The discovery of inductive invariants lies at the heart of static program verification. Presently, many automatic solutions to inductive invariant generation are inflexible, only applicable to certain classes of programs, or unpredictable. An automatic technique that circumvents these deficiencies to some extent is candidate-based invariant generation, whereby a large number of candidate invariants are guessed and then proven to be inductive or rejected using a sound program analyzer. This paper describes our efforts to apply candidate-based invariant generation in GPUVerify, a static checker for programs that run on GPUs. We study a set of 383 GPU programs that contain loops, drawn from a number of open source suites and vendor SDKs. Among this set, 253 benchmarks require provision of loop invariants for verification to succeed. We describe the methodology we used to incrementally improve the invariant generation capabilities of GPUVerify to handle these benchmarks, through candidate-based invariant generation, using cheap static analysis to speculate potential program invariants. We also describe a set of experiments that we used to examine the effectiveness of our rules for candidate generation, assessing rules based on their generality (the extent to which they generate candidate invariants), hit rate (the extent to which the generated candidates hold), worth (the extent to which provable candidates actually help in allowing verification to succeed), and influence (the extent to which the success of one generation rule depends on candidates generated by another rule). We believe that our methodology may serve as a useful framework for other researchers interested in candidate-based invariant generation. The candidates produced by GPUVerify help to verify 231 of the 253 programs. This increase in precision, however, makes GPUVerify sluggish: the more candidates that are generated, the more time is spent determining which are inductive invariants. To speed up this process, we have investigated four under-approximating program analyses that aim to reject false candidates quickly and a framework whereby these analyses can run in sequence or in parallel. Across two platforms, running Windows and Linux, our results show that the best combination of these techniques running sequentially-speeds up invariant generation across our benchmarks by 1.17× (Windows) and 1.01× (Linux), with per-benchmark best speedups of 93.58× (Windows) and 48.34× (Linux), and worst slowdowns of 10.24× (Windows) and 43.31× (Linux). We find that parallelizing the strategies marginally improves overall invariant generation speedups to 1.27× (Windows) and 1.11× (Linux), maintains good best-case speedups of 91.18× (Windows) and 44.60× (Linux), and, importantly, dramatically reduces worst-case slowdowns to 3.15× (Windows) and 3.17× (Linux).",1939-3520,,10.1109/TSE.2017.2718516,EU FP7 STREP project CARP; EPSRC PSL; Imperial College London’s EPSRC Impact Acceleration Account; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7955079,Formal verification;GPUs;invariant generation,Linux;Graphics processing units;Benchmark testing;Tools;Cognition;Acceleration,formal verification;graphics processing units;Linux;Microsoft Windows (operating systems);program verification,invariant generation speedups;inductive invariant generation;candidate invariants;invariant generation capabilities;potential program invariants;GPUVerify;SDK;candidate-based invariant generation evaluation;GPU programs;Windows;Linux;static program verification,,,,62.0,,22 Jun 2017,,,IEEE,IEEE Journals
1959,599,Interlocking Safety Cases for Unmanned Autonomous Systems in Shared Airspaces,M. Vierhauser; S. Bayley; J. Wyngaard; W. Xiong; J. Cheng; J. Huseman; R. Lutz; J. Cleland-Huang,"Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Engineering, Polythechnique Montréal, Montreal, QC, Canada; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,899,918,"The growing adoption of unmanned aerial vehicles (UAVs) for tasks such as eCommerce, aerial surveillance, and environmental monitoring introduces the need for new safety mechanisms in an increasingly cluttered airspace. In our work we thus emphasize safety issues that emerge at the intersection of infrastructures responsible for controlling the airspace, and the diverse UAVs operating in their space. We build on safety assurance cases (SAC) – a state-of-the-art solution for reasoning about safety – and propose a novel approach based on interlocking SACs. The infrastructure safety case (ISAC) specifies assumptions upon UAV behavior, while each UAV demonstrates compliance to the ISAC by presenting its own (pluggable) safety case (pSAC) which connects to the ISAC through a set of interlock points. To collect information on each UAV we enforce a “trust but monitor” policy, supported by runtime monitoring and an underlying reputation model. We evaluate our approach in three ways: first by developing ISACs for two UAV infrastructures, second by running simulations to evaluate end-to-end effectiveness, and finally via an outdoor field-study with physical UAVs. The results show that interlocking SACs can be effective for identifying, specifying, and monitoring safety-related constraints upon UAVs flying in a controlled airspace.",1939-3520,,10.1109/TSE.2019.2907595,National Science Foundation; Austrian Science Fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674543,UAV;unmanned autonomous systems;safety assurance cases;monitoring,Safety;Unmanned aerial vehicles;Monitoring;Runtime;Software;Atmospheric modeling;NASA,,,,1.0,,121.0,IEEE,26 Mar 2019,,,IEEE,IEEE Journals
1960,600,CBGA-ES+: A Cluster-Based Genetic Algorithm with Non-Dominated Elitist Selection for Supporting Multi-Objective Test Optimization,D. Pradhan; S. Wang; S. Ali; T. Yue; M. Liaaen,"Simula Research Laboratory, Lysaker, Norway; Testify As, Lysaker, Norway; Simula Research Laboratory, Lysaker, Norway; Simula Research Laboratory, Lysaker, Norway; Cisco Systems, Oslo, Norway",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,86,107,"Many real-world test optimization problems (e.g., test case prioritization) are multi-objective intrinsically and can be tackled using various multi-objective search algorithms (e.g., Non-dominated Sorting Genetic Algorithm (NSGA-II)). However, existing multi-objective search algorithms have certain randomness when selecting parent solutions for producing offspring solutions. In a worse case, suboptimal parent solutions may result in offspring solutions with bad quality, and thus affect the overall quality of the solutions in the next generation. To address such a challenge, we propose CBGA-ES+, a novel cluster-based genetic algorithm with non-dominated elitist selection to reduce the randomness when selecting the parent solutions to support multi-objective test optimization. We empirically compared CBGA-ES+ with random search and greedy (as baselines), four commonly used multi-objective search algorithms (i.e., Multi-objective Cellular genetic algorithm (MOCell), NSGA-II, Pareto Archived Evolution Strategy (PAES), and Strength Pareto Evolutionary Algorithm (SPEA2)), and the predecessor of CBGA-ES+ (named CBGA-ES) using five multi-objective test optimization problems with eight subjects (two industrial, one real world, and five open source). The results showed that CBGA-ES+ managed to significantly outperform the selected search algorithms for a majority of the experiments. Moreover, for the solutions in the same search space, CBGA-ES+ managed to perform better than CBGA-ES, MOCell, NSGA-II, PAES, and SPEA2 for 2.2, 13.6, 14.5, 17.4, and 9.9 percent, respectively. Regarding the running time of the algorithm, CBGA-ES+ was faster than CBGA-ES for all the experiments.",1939-3520,,10.1109/TSE.2018.2882176,Norges Forskningsråd; RCN funded Zen-Configurator; RCN funded MBT4CPS; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540431,Elitist selection;multi-objective genetic algorithm;multi-objective test optimization;search,Optimization;Genetic algorithms;Sociology;Statistics;Search problems;Clustering algorithms;Software algorithms,evolutionary computation;genetic algorithms;Pareto optimisation;search problems,nondominated elitist selection;real-world test optimization problems;test case prioritization;nondominated sorting genetic algorithm;NSGA-II;multiobjective search algorithms;offspring solutions;suboptimal parent solutions;cluster-based genetic algorithm;multiobjective cellular genetic algorithm;strength Pareto evolutionary algorithm;search algorithms;CBGA-ES+;multiobjective test optimization;Pareto archived evolution strategy,,1.0,,98.0,IEEE,18 Nov 2018,,,IEEE,IEEE Journals
1961,601,Instance Migration Validity for Dynamic Evolution of Data-Aware Processes,W. Song; X. Ma; H. Jacobsen,"School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Middleware Systems Research Group, Technische Universität München, Garching, Germany",IEEE Transactions on Software Engineering,26 Aug 2019,2019,45,8,782,801,"Likely more than many other software artifacts, business processes constantly evolve to adapt to ever changing application requirements. To enable dynamic process evolution, where changes are applied to in-flight processes, running process instances have to be migrated. On the one hand, as many instances as possible should be migrated to the changed process. On the other hand, the validity to migrate an instance should be guaranteed to avoid introducing dynamic change bugs after migration. As our theoretical results show, when the state of variables is taken into account, migration validity of data-aware process instances is undecidable. Based on the trace of an instance, existing approaches leverage trace replaying to check migration validity. However, they err on the side of caution, not identifying many instances as potentially safe to migrate. We present a more relaxed migration validity checking approach based on the dependence graph of a trace. We evaluate effectiveness and efficiency of our approach experimentally showing that it allows for more instances to safely migrate than for existing approaches and that it scales in the number of instances checked.",1939-3520,,10.1109/TSE.2018.2802925,National Key R&D Program of China; National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Fundamental Research Funds for the Central Universities; Deutsche Forschungsgemeinschaft; American Friends of the Alexander von Humboldt Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283529,Data-aware process;dynamic evolution;instance migration;migration validity;trace slicing,Process control;Business data processing;Debugging;Software architecture,business data processing;graph theory;program debugging;program diagnostics;software architecture,instance migration validity;dynamic evolution;business processes;dynamic process evolution;in-flight processes;data-aware process instances;trace replaying;dependence graph,,2.0,,62.0,,6 Feb 2018,,,IEEE,IEEE Journals
1962,602,Evaluating Model-Driven Development Claims with Respect to Quality: A Family of Experiments,J. I. Panach; Ó. Dieste; B. Marín; S. España; S. Vegas; Ó. Pastor; N. Juristo,"Departament d'Informàtica, Escola Tècnica Superior d'Enginyeria, Universitat de València, Avinguda de la Universitat, València, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain; Escuela de Informática y Telecomunicaciones, Facultad de Ingeniería, Universidad Diego Portales, Santiago, Chile; Utrecht University, Utrecht, The Netherlands; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain; Centro de Investigación en Métodos de Producción de Software, Universitat Politècnica de València, Valencia, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,130,145,"Context: There is a lack of empirical evidence on the differences between model-driven development (MDD), where code is automatically derived from conceptual models, and traditional software development method, where code is manually written. In our previous work, we compared both methods in a baseline experiment concluding that quality of the software developed following MDD was significantly better only for more complex problems (with more function points). Quality was measured through test cases run on a functional system. Objective: This paper reports six replications of the baseline to study the impact of problem complexity on software quality in the context of MDD. Method: We conducted replications of two types: strict replications and object replications. Strict replications were similar to the baseline, whereas we used more complex experimental objects (problems) in the object replications. Results: MDD yields better quality independently of problem complexity with a moderate effect size. This effect is bigger for problems that are more complex. Conclusions: Thanks to the bigger size of the sample after aggregating replications, we discovered an effect that the baseline had not revealed due to the small sample size. The baseline results hold, which suggests that MDD yields better quality for more complex problems.",1939-3520,,10.1109/TSE.2018.2884706,Ministerio de Ciencia e Innovación; European Regional Development Fund; Generalitat Valenciana; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565892,Automatic programming;methodologies;validation,Unified modeling language;Productivity;Complexity theory;Inspection;Model-driven development;Software quality,program testing;software quality,object replications;strict replications;complex experimental objects;MDD;problem complexity;model-driven development;software development;function points;functional system;software quality;test cases,,1.0,,50.0,IEEE,6 Dec 2018,,,IEEE,IEEE Journals
1963,603,Eliminating Path Redundancy via Postconditioned Symbolic Execution,Q. Yi; Z. Yang; S. Guo; C. Wang; J. Liu; C. Zhao,"National Engineering Research Center for Fundamental Software, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA; Department of Computer Science, University of Southern California, Los Angeles, CA; Key Laboratory of Network Assessment Technology and Beijing Key Laboratory of Network Security Technology, Institute of Information Engineering and University of Chinese Academy of Sciences, Chinese Academy of Sciences, Beijing, China; National Engineering Research Center for Fundamental Software and State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,8 Jan 2018,2018,44,1,25,43,"Symbolic execution is emerging as a powerful technique for generating test inputs systematically to achieve exhaustive path coverage of a bounded depth. However, its practical use is often limited by path explosion because the number of paths of a program can be exponential in the number of branch conditions encountered during the execution. To mitigate the path explosion problem, we propose a new redundancy removal method called postconditioned symbolic execution. At each branching location, in addition to determine whether a particular branch is feasible as in traditional symbolic execution, our approach checks whether the branch is subsumed by previous explorations. This is enabled by summarizing previously explored paths by weakest precondition computations. Postconditioned symbolic execution can identify path suffixes shared by multiple runs and eliminate them during test generation when they are redundant. Pruning away such redundant paths can lead to a potentially exponential reduction in the number of explored paths. Since the new approach is computationally expensive, we also propose several heuristics to reduce its cost. We have implemented our method in the symbolic execution engine KLEE [1] and conducted experiments on a large set of programs from the GNU Coreutils suite. Our results confirm that redundancy due to common path suffix is both abundant and widespread in real-world applications.",1939-3520,,10.1109/TSE.2017.2659751,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835264,Symbolic execution;testing and debugging;testing tools,Concrete;Explosions;Input variables;Redundancy;Software;Syntactics;Testing,program diagnostics;program testing,common path suffix;postconditioned symbolic execution;exhaustive path coverage;branch conditions;path explosion problem;redundancy removal method;branching location;traditional symbolic execution;path suffixes;path redundancy elimination,,4.0,,67.0,,26 Jan 2017,,,IEEE,IEEE Journals
1964,604,Global-Aware Recommendations for Repairing Violations in Exception Handling,E. A. Barbosa; A. Garcia,"Federal University of Rio Grande do Norte, Caicó - RN, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro - RJ, Brazil",IEEE Transactions on Software Engineering,16 Sep 2018,2018,44,9,855,873,"Empirical evidence suggests exception handling is not reliably implemented. Most faults in exception handling are related to global exceptions violating the intended exception handling design. However, repairing these violations is a cumbersome and error-prone task. It requires knowing the intended design and understanding how the source code violates it. It also requires changing the source code to make it compliant with the intended design. But changing the exception handling code is a difficult task, since changes in exception handling requires changing different parts of a program. Currently, there is still no solution to assist the repair of this type of violations. To bridge this gap, we present RAVEN, a heuristic strategy aware of the global context of exceptions that produces recommendations of how violations in exception handling may be repaired. This strategy takes advantage of explicit specifications of the intended design, although their availability is not mandatory. Our results revealed RAVEN provides recommendations able to repair violations in 69 percent of the cases when policy specifications are not available and in 97 percent of the cases when specifications are available. Thus, development teams may benefit from RAVEN, even when exception handling design decisions are not documented in their projects.",1939-3520,,10.1109/TSE.2017.2716925,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953550,Exception handling;recommender heuristic;software repair,Source coding;Robustness;Runtime;Software development management;Software reliability,exception handling;recommender systems;software fault tolerance;software quality,intended exception handling design;source code;repair violations;exception handling design decisions;global-aware recommendations;RAVEN strategy,,2.0,,51.0,,19 Jun 2017,,,IEEE,IEEE Journals
1965,605,A Screening Test for Disclosed Vulnerabilities in FOSS Components,S. Dashevskyi; A. D. Brucker; F. Massacci,"University of Trento, TN, Italy; University of Sheffield, Sheffield, United Kingdom; University of Trento, Trento, TN, Italy",IEEE Transactions on Software Engineering,16 Oct 2019,2019,45,10,945,966,"Free and Open Source Software (FOSS) components are ubiquitous in both proprietary and open source applications. Each time a vulnerability is disclosed in a FOSS component, a software vendor using this component in an application must decide whether to update the FOSS component, patch the application itself, or just do nothing as the vulnerability is not applicable to the older version of the FOSS component used. This is particularly challenging for enterprise software vendors that consume thousands of FOSS components and offer more than a decade of support and security fixes for their applications. Moreover, customers expect vendors to react quickly on disclosed vulnerabilities-in case of widely discussed vulnerabilities such as Heartbleed, within hours. To address this challenge, we propose a screening test: a novel, automatic method based on thin slicing, for estimating quickly whether a given vulnerability is present in a consumed FOSS component by looking across its entire repository. We show that our screening test scales to large open source projects (e.g., Apache Tomcat, Spring Framework, Jenkins) that are routinely used by large software vendors, scanning thousands of commits and hundred thousands lines of code in a matter of minutes. Further, we provide insights on the empirical probability that, on the above mentioned projects, a potentially vulnerable component might not actually be vulnerable after all.",1939-3520,,10.1109/TSE.2018.2816033,European Commission; CISCO Country Digitalization; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316943,Security maintenance;security vulnerabilities;patch management;free and open source software,Security;Maintenance engineering;Tools;Jacobian matrices;Patents;Open source software,DP industry;program slicing;program testing;public domain software;security of data,proprietary source applications;open source applications;screening test;disclosed vulnerabilities;FOSS component;free and open source software component;thin slicing;enterprise software vendors,,2.0,,51.0,,15 Mar 2018,,,IEEE,IEEE Journals
1966,606,How Well Do Change Sequences Predict Defects? Sequence Learning from Software Changes,M. Wen; R. Wu; S. -C. Cheung,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China",IEEE Transactions on Software Engineering,11 Nov 2020,2020,46,11,1155,1175,"Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources. Various features to build defect prediction models have been proposed and evaluated. Among them, process metrics are one important category. Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution. Are the change sequences derived from such information useful to characterize buggy program modules? How can we leverage such sequences to build good defect prediction models? Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length. This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers. To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically. In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis. It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN. Our evaluations on 10 open source projects show that Fences can predict defects with high performance. In particular, our approach achieves an average F-measure of 0.657, which improves the prediction models built on traditional metrics significantly. The improvements vary from 31.6 to 46.8 percent on average. In terms of AUC, Fences achieves an average value of 0.892, and the improvements over baselines vary from 4.2 to 16.1 percent. Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.",1939-3520,,10.1109/TSE.2018.2876256,Hong Kong RGC/GRF; 2018 MSRA collaborative research fund; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493303,Defect prediction;process metrics;sequence learning,Measurement;Software;Predictive models;Semantics;History;Machine learning;Feature extraction,learning (artificial intelligence);program debugging;program diagnostics;public domain software;recurrent neural nets;software maintenance;software metrics;software quality,software changes;software defect prediction;software evolution;defect prediction models;fine-grained change analysis;sequence labeling problem;sequence learning;Fences approach;RNN;recurrent neural network;efficiency 16.1 percent;efficiency 46.8 percent,,,,74.0,IEEE,16 Oct 2018,,,IEEE,IEEE Journals
1967,607,Deep Learning Based Code Smell Detection,H. Liu; J. Jin; Z. Xu; Y. Bu; Y. Zou; L. Zhang,"Computer Science and Technology, Software Lab, Beijing, Beijing China 100081 (e-mail: liuhui2005@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: jinjiahao1993@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 848602422@qq.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: yifan_bu@qq.com); Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, 12465 Beijing, Beijing China (e-mail: zouyz@pku.edu.cn); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Code smells are structures in the source code that suggest the possibility of refactorings. Consequently, developers may identify refactoring opportunities by detecting code smells. However, manual identification of code smells is challenging and tedious. To this end, a number of approaches have been proposed to identify code smells automatically or semi-automatically. Most of such approaches rely on manually designed heuristics to map manually selected source code metrics into predictions. However, it is challenging to manually select the best features. It is also difficult to manually construct the optimal heuristics. To this end, in this paper we propose a deep learning based novel approach to detecting code smells. The key insight is that deep neural networks and advanced deep learning techniques could automatically select features of source code for code smell detection, and could automatically build the complex mapping between such features and predictions. A big challenge for deep learning based smell detection is that deep learning often requires a large number of labeled training data (to tune a large number of parameters within the employed deep neural network) whereas existing datasets for code smell detection are rather small. To this end, we propose an automatic approach to generating labeled training data for the neural network based classifier, which does not require any human intervention. As an initial try, we apply the proposed approach to four common and well-known code smells, i.e., feature envy, long method, large class, and misplaced class. Evaluation results on open-source applications suggest that the proposed approach significantly improves the state-of-the-art.",1939-3520,,10.1109/TSE.2019.2936376,National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807230,Software Refactoring;Code Smells;Identification;Deep Learning;Quality,Software;Deep learning;Feature extraction;Training data;Neural networks;Measurement,,,,4.0,,,,20 Aug 2019,,,IEEE,IEEE Early Access Articles
1968,608,An Empirical Study of Boosting Spectrum-based Fault Localization via PageRank,M. Zhang; Y. Li; X. Li; L. Chen; Y. Zhang; L. Zhang; S. Khurshid,"Electrical and Computer Engineering, University of Texas at Austin, 12330 Austin, Texas United States (e-mail: mengshi.zhang@utexas.edu); Computer Science and Engineering, South University of Science and Technology, 255310 Shenzhen, Guangdong China (e-mail: liyx@mail.sustc.edu.cn); Computer Science, University of Texas at Dallas, Dallas, Texas United States (e-mail: xxl124730@utdallas.edu); Computer Science, University of Texas at Dallas, Dallas, Texas United States (e-mail: lxc170330@utdallas.edu); Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong China (e-mail: zhangyq@sustc.edu.cn); Computer Science, University of Texas at Dallas, Richardson, Texas United States (e-mail: lingming.zhang@utdallas.edu); Electrical and Computer Engineering, University of Texas at Austin, Austin, Texas United States (e-mail: khurshid@ece.utexas.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Manual debugging is notoriously tedious and time-consuming. Therefore, various automated fault localization techniques have been proposed to help with manual debugging. Among the existing fault localization techniques, spectrum-based fault localization (SBFL) is one of the most widely studied techniques due to being lightweight. The focus of the existing SBFL techniques is to consider how to differentiate program entities (i.e., one dimension in program spectra); indeed, this focus is aligned with the ultimate goal of finding the faulty lines of code. Our key insight is to enhance the existing SBFL techniques by additionally considering how to differentiate tests (i.e., the other dimension in program spectra), which, to the best of our knowledge, has not been studied in prior work. We present our basic approach, PRFL, a lightweight technique that boosts SBFL by differentiating tests using PageRank algorithm. Specifically, given the original program spectrum information, PRFL uses PageRank to recompute the spectrum by considering the contributions of different tests. Next, traditional SBFL techniques are applied to the recomputed spectrum to achieve more effective fault localization. On top of PRFL, we explore PRFL+ and PRFLMA, two variants which extend PRFL by optimizing its components and integrating Method-level Aggregation technique, respectively. Though being simple and lightweight, PRFL has been demonstrated to outperform state-of-the-art SBFL techniques significantly (e.g., ranking 39.2% / 82.3% more real/artificial faults within Top-1 compared with the most effective traditional SBFL technique) with low overhead on 395 real faults from 6 Defects4J projects and 96925 artificial faults from 240 GitHub projects. To further validate PRFL's effectiveness, we compare PRFL with multiple recent proposed fault localization techniques (e.g., Multric, Metallaxis and MBFL-hybrid-avg), and the experimental results show that PRFL outperforms them as well. Furthermore, we study the performance of PRFLMA, and the experimental results present it can locate 137 real faults (73.4% / 24.5% more compared with the most effective SBFL/PRFL technique) and 35058 artificial faults (159.6% / 28.1% more than SBFL/PRFL technique) at Top-1. At last, we study the generalizability of PRFL on another benchmark Bugs.jar, and the result shows PRFL can help locate around 30% more faults at Top 1.",1939-3520,,10.1109/TSE.2019.2911283,UT Dallas start-up fund; Google Faculty Research Award; Shenzhen Peacock Plan; Science and Technology Innovation Committee Foundation of Shenzhen; National Science Foundation; Ministry of Science and Technology of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8698881,Software testing;Automated debugging;Spectrum-based fault localization;SBFL;PageRank analysis,Debugging;Benchmark testing;Spectral analysis;Java;Boosting;Manuals,,,,5.0,,,,25 Apr 2019,,,IEEE,IEEE Early Access Articles
1969,609,Automatic Software Repair: A Survey,L. Gazzola; D. Micucci; L. Mariani,"Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy; Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy; Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy",IEEE Transactions on Software Engineering,8 Jan 2019,2019,45,1,34,67,"Despite their growing complexity and increasing size, modern software applications must satisfy strict release requirements that impose short bug fixing and maintenance cycles, putting significant pressure on developers who are responsible for timely producing high-quality software. To reduce developers workload, repairing and healing techniques have been extensively investigated as solutions for efficiently repairing and maintaining software in the last few years. In particular, repairing solutions have been able to automatically produce useful fixes for several classes of bugs that might be present in software programs. A range of algorithms, techniques, and heuristics have been integrated, experimented, and studied, producing a heterogeneous and articulated research framework where automatic repair techniques are proliferating. This paper organizes the knowledge in the area by surveying a body of 108 papers about automatic software repair techniques, illustrating the algorithms and the approaches, comparing them on representative examples, and discussing the open challenges and the empirical evidence reported so far.",1939-3520,,10.1109/TSE.2017.2755013,EU H2020; ERC Consolidator; MIUR; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8089448,Automatic program repair;generate and validate;search-based;semantics-driven repair;correct by construction;program synthesis;self-repairing,Software;Maintenance engineering;Debugging;Computer bugs;Software algorithms;Fault diagnosis;Conferences,program debugging;software maintenance;software quality,modern software applications;maintenance cycles;software programs;heterogeneous research framework;articulated research framework;automatic software repair techniques;high-quality software,,27.0,,176.0,,30 Oct 2017,,,IEEE,IEEE Journals
1970,610,The Scent of a Smell: An Extensive Comparison Between Textual and Structural Smells,F. Palomba; A. Panichella; A. Zaidman; R. Oliveto; A. De Lucia,"TU Delft, Delft, The Netherlands; SnT Centre—University of Luxembourg, Esch-sur-Alzette, Luxembourg; TU Delft, Delft, The Netherlands; University of Molise, Campobasso, Italy; University of Salerno, Fisciano, Italy",IEEE Transactions on Software Engineering,15 Oct 2018,2018,44,10,977,1000,"Code smells are symptoms of poor design or implementation choices that have a negative effect on several aspects of software maintenance and evolution, such as program comprehension or change- and fault-proneness. This is why researchers have spent a lot of effort on devising methods that help developers to automatically detect them in source code. Almost all the techniques presented in literature are based on the analysis of structural properties extracted from source code, although alternative sources of information (e.g., textual analysis) for code smell detection have also been recently investigated. Nevertheless, some studies have indicated that code smells detected by existing tools based on the analysis of structural properties are generally ignored (and thus not refactored) by the developers. In this paper, we aim at understanding whether code smells detected using textual analysis are perceived and refactored by developers in the same or different way than code smells detected through structural analysis. To this aim, we set up two different experiments. We have first carried out a software repository mining study to analyze how developers act on textually or structurally detected code smells. Subsequently, we have conducted a user study with industrial developers and quality experts in order to qualitatively analyze how they perceive code smells identified using the two different sources of information. Results indicate that textually detected code smells are easier to identify and for this reason they are considered easier to refactor with respect to code smells detected using structural properties. On the other hand, the latter are often perceived as more severe, but more difficult to exactly identify and remove.",1939-3520,,10.1109/TSE.2017.2752171,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8038053,Code smells;empirical study;mining software repositories,Tools;Data mining;Software systems;Detectors;Maintenance engineering;Large scale integration,data mining;software maintenance;software quality;source code (software),source code;textually detected code smells;structurally detected code smells;software maintenance;software repository mining;qualitatively analyze,,9.0,,111.0,,14 Sep 2017,,,IEEE,IEEE Journals
1971,611,ConfigMiner: Identifying the Appropriate Configuration Options for Config-related User Questions by Mining Online Forums,M. Sayagh; A. E. Hassan,"Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: sayaghmohammed@gmail.com); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"While the behavior of a software system can be easily changed by modifying the values of a couple of configuration options, finding one out of hundreds or thousands of available options is, unfortunately, a challenging task. Therefore, users often spend a considerable amount of time asking and searching around for the appropriate configuration options in online forums such as StackOverflow. In this paper, we propose ConfigMiner, an approach to automatically identify the appropriate option(s) to config-related user questions by mining already-answered config-related questions in online forums. Our evaluation on 2,061 config-related user questions for seven software systems shows that ConfigMiner can identify the appropriate option(s) for a median of 83% (up to 91%) of user questions within the top-20 recommended options, improving over state-of-the-art approaches by a median of 130%. Besides, ConfigMiner reports the relevant options at a median rank of 4, compared to a median of 16-20.5 as reported by the state-of-the-art approaches.",1939-3520,,10.1109/TSE.2020.2973997,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999583,Configuration;user questions;online forums;stackOverflow,Software systems;Computer bugs;Debugging;Statistical analysis;Task analysis;Prediction algorithms;Data mining,,,,1.0,,,,14 Feb 2020,,,IEEE,IEEE Early Access Articles
1972,612,A PVS-Simulink Integrated Environment for Model-Based Analysis of Cyber-Physical Systems,C. Bernardeschi; A. Domenici; P. Masci,"Department of Information Engineering, University of Pisa, PI, Italy; Department of Information Engineering, University of Pisa, PI, Italy; HASLab/INESC TEC and Universidade do Minho, Braga, Portugal",IEEE Transactions on Software Engineering,12 Jun 2018,2018,44,6,512,533,"This paper presents a methodology, with supporting tool, for formal modeling and analysis of software components in cyber-physical systems. Using our approach, developers can integrate a simulation of logic-based specifications of software components and Simulink models of continuous processes. The integrated simulation is useful to validate the characteristics of discrete system components early in the development process. The same logic-based specifications can also be formally verified using the Prototype Verification System (PVS), to gain additional confidence that the software design complies with specific safety requirements. Modeling patterns are defined for generating the logic-based specifications from the more familiar automata-based formalism. The ultimate aim of this work is to facilitate the introduction of formal verification technologies in the software development process of cyber-physical systems, which typically requires the integrated use of different formalisms and tools. A case study from the medical domain is used to illustrate the approach. A PVS model of a pacemaker is interfaced with a Simulink model of the human heart. The overall cyber-physical system is co-simulated to validate design requirements through exploration of relevant test scenarios. Formal verification with the PVS theorem prover is demonstrated for the pacemaker model for specific safety aspects of the pacemaker design.",1939-3520,,10.1109/TSE.2017.2694423,"North Portugal Regional Operational Programme; PORTUGAL 2020 Partnership Agreement, and through the European Regional Development Fund (ERDF); ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900400,Real-time and embedded systems;modeling techniques;specification;formal methods,Software packages;Automata;Analytical models;Cyber-physical systems;Mathematical model;Data models,cyber-physical systems;formal specification;program testing;program verification;software development management;software tools;theorem proving,formal modeling;software components;cyber-physical system;Simulink model;discrete system components;logic-based specifications;Prototype Verification System;formal verification technologies;software development process;PVS model;pacemaker model;PVS-Simulink integrated environment;software design;formal verification,,5.0,,76.0,,14 Apr 2017,,,IEEE,IEEE Journals
1973,613,Easy-to-Deploy API Extraction by Multi-Level Feature Embedding and Transfer Learning,S. Ma; Z. Xing; C. Chen; C. Chen; L. Qu; G. Li,"Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: u6095071@anu.edu.au); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: zhenchang.xing@anu.edu.au); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: chunyang.chen@monash.edu); Research School of Computer Science, Australian National University, Canberra, Australian Capital Territory Australia (e-mail: u5969643@anu.edu.au); Faculty of Information Technology, Monash University, 2541 Caulfield, Victoria Australia (e-mail: lizhen.qu@data61.csiro.au); School of Software, Shanghai Jiao Tong University, Shanghai, ShangHai China 200240 (e-mail: li.g@sjtu.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Application Programming Interfaces (APIs) have been widely discussed on social-technical platforms (e.g., Stack Overflow). Extracting API mentions from such informal software texts is the prerequisite for API-centric search and summarization of programming knowledge. Machine learning based API extraction has demonstrated superior performance than rule-based methods in informal software texts that lack consistent writing forms and annotations. However, machine learning based methods have a significant overhead in preparing training data and effective features. In this paper, we propose a multi-layer neural network based architecture for API extraction. Our architecture automatically learns character-, word- and sentence-level features from the input texts, thus removing the need for manual feature engineering and the dependence on advanced features (e.g., API gazzetter) beyond the input texts. We also propose to adopt transfer learning to adapt a source-library-trained model to a target-library, thus reducing the overhead of manual training-data labeling when the software text of multiple programming languages and libraries need to be processed. We conduct extensive experiments with six libraries of four programming languages which support diverse functionalities and have different API-naming and API-mention characteristics. Our experiments investigate the performance of our neural architecture for API extraction in informal software texts, the importance of different features, the effectiveness of transfer learning. Our results confirm not only the superior performance of our neural architecture than existing machine learning based methods for API extraction in informal software texts, but also the easy-to-deploy characteristic of our neural architecture.",1939-3520,,10.1109/TSE.2019.2946830,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865646,API extraction;CNN;Word embedding;LSTM;Transfer learning,Libraries;Feature extraction;Machine learning;Software;Computer architecture;Training data;Manuals,,,,3.0,,,,14 Oct 2019,,,IEEE,IEEE Early Access Articles
1974,614,ARJA: Automated Repair of Java Programs via Multi-Objective Genetic Programming,Y. Yuan; W. Banzhaf,"Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA",IEEE Transactions on Software Engineering,14 Oct 2020,2020,46,10,1040,1067,"Automated program repair is the problem of automatically fixing bugs in programs in order to significantly reduce the debugging costs and improve the software quality. To address this problem, test-suite based repair techniques regard a given test suite as an oracle and modify the input buggy program to make the entire test suite pass. GenProg is well recognized as a prominent repair approach of this kind, which uses genetic programming (GP) to rearrange the statements already extant in the buggy program. However, recent empirical studies show that the performance of GenProg is not fully satisfactory, particularly for Java. In this paper, we propose ARJA, a new GP based repair approach for automated repair of Java programs. To be specific, we present a novel lower-granularity patch representation that properly decouples the search subspaces of likely-buggy locations, operation types and potential fix ingredients, enabling GP to explore the search space more effectively. Based on this new representation, we formulate automated program repair as a multi-objective search problem and use NSGA-II to look for simpler repairs. To reduce the computational effort and search space, we introduce a test filtering procedure that can speed up the fitness evaluation of GP and three types of rules that can be applied to avoid unnecessary manipulations of the code. Moreover, we also propose a type matching strategy that can create new potential fix ingredients by exploiting the syntactic patterns of existing statements. We conduct a large-scale empirical evaluation of ARJA along with its variants on both seeded bugs and real-world bugs in comparison with several state-of-the-art repair approaches. Our results verify the effectiveness and efficiency of the search mechanisms employed in ARJA and also show its superiority over the other approaches. In particular, compared to jGenProg (an implementation of GenProg for Java), an ARJA version fully following the redundancy assumption can generate a test-suite adequate patch for more than twice the number of bugs (from 27 to 59), and a correct patch for nearly four times of the number (from 5 to 18), on 224 real-world bugs considered in Defects4J. Furthermore, ARJA is able to correctly fix several real multi-location bugs that are hard to be repaired by most of the existing repair approaches.",1939-3520,,10.1109/TSE.2018.2874648,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485732,Program repair;patch generation;genetic programming;multi-objective optimization;genetic improvement,Maintenance engineering;Computer bugs;Java;Genetic programming;Search problems;Sociology;Statistics,genetic algorithms;Java;program debugging;program testing;search problems;software maintenance;software quality;sorting,ARJA;multiobjective genetic programming;automated program repair;test-suite based repair techniques;buggy program;GenProg;GP based repair approach;search space;multiobjective search problem;real-world bugs;multilocation bugs;test filtering;automated repair of Java programs;program bugs;debugging costs;software quality;NSGA-II,,8.0,,87.0,IEEE,7 Oct 2018,,,IEEE,IEEE Journals
1975,615,Debugging Static Analysis,L. N. Q. Do; S. Krüger; P. Hill; K. Ali; E. Bodden,"Paderborn University, Paderborn, Germany; Paderborn University, Paderborn, Germany; Paderborn University, Paderborn, Germany; University of Alberta, Edmonton, AB, Canada; Paderborn University & Fraunhofer IEM, Paderborn, Germany",IEEE Transactions on Software Engineering,15 Jul 2020,2020,46,7,697,709,"Static analysis is increasingly used by companies and individual code developers to detect and fix bugs and security vulnerabilities. As programs grow more complex, the analyses have to support new code concepts, frameworks and libraries. However, static-analysis code itself is also prone to bugs. While more complex analyses are written and used in production systems every day, the cost of debugging and fixing them also increases tremendously. To understand the difficulties of debugging static analysis, we surveyed 115 static-analysis writers. From their responses, we determined the core requirements to build a debugger for static analyses, which revolve around two main issues: abstracting from both the analysis code and the code it analyses at the same time, and tracking the analysis internal state throughout both code bases. Most tools used by our survey participants lack the capabilities to address both issues. Focusing on those requirements, we introduce Visuflow, a debugging environment for static data-flow analysis. Visuflow features graph visualizations and custom breakpoints that enable users to view the state of an analysis at any time. In a user study on 20 static-analysis writers, Visuflow helped identify 25 and fix 50 percent more errors in the analysis code compared to the standard Eclipse debugging environment.",1939-3520,,10.1109/TSE.2018.2868349,Heinz Nixdorf Foundation; DFG; Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453858,Testing and debugging;program analysis;development tools;integrated environments;graphical environments;usability testing,Debugging;Static analysis;Tools;Computer bugs;Standards;Writing;Encoding,data flow analysis;data visualisation;program debugging;program diagnostics,code bases;static data-flow analysis;code developers;libraries;static-analysis code;security vulnerabilities;graph visualizations;Visuflow;Eclipse debugging environment,,,,36.0,IEEE,2 Sep 2018,,,IEEE,IEEE Journals
1976,616,Symbolic Refinement of Extended State Machines with Applications to the Automatic Derivation of Sub-Components and Controllers,K. El-Fakih; G. V. Bochmann,"College of Engineering, American University of Sharjah, Sharjah, UAE; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,1,16,"Nowadays, extended state machines are prominent requirements specification techniques due to their capabilities of modeling complex systems in a compact way. These machines extend the standard state machines with variables and have transitions guarded by enabling predicates and may include variable update statements. Given a system modeled as an extended state machine, with possibly infinite state space and some non-controllable (parameterized) interactions, a pruning procedure is proposed to symbolically derive a maximal sub-machine of the original system that satisfies certain conditions; namely, some safeness and absence of undesirable deadlocks which could be produced during pruning. In addition, the user may specify, as predicates associated with states, some general goal assertions that should be preserved in the obtained sub-machine. Further, one may also specify some specific requirements such as the elimination of certain undesirable deadlocks at states, or fail states that should never be reached. Application examples are given considering deadlock avoidance and loops including infinite loops over non-controllable interactions showing that the procedure may not terminate. In addition, the procedure is applied for finding a controller of a system to be controlled. The approach generalizes existing work in respect to the considered extended machine model and the possibility of user defined control objectives written as assertions at states.",1939-3520,,10.1109/TSE.2018.2878728,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8515084,Requirements/specifications;component design and refinement;discrete event control systems;extended state machines;submodule construction and automatic derivation of a component behavior,System recovery;Control systems;Calculators;Facsimile;Electronic mail;Unified modeling language;Computer architecture,control engineering computing;finite state machines;formal specification;formal verification;large-scale systems,prominent requirements specification techniques;standard state machines;extended state machine;possibly infinite state space;noncontrollable interactions;maximal sub-machine;considered extended machine model,,,,31.0,IEEE,30 Oct 2018,,,IEEE,IEEE Journals
1977,617,Accurate and Scalable Cross-Architecture Cross-OS Binary Code Search with Emulation,Y. Xue; Z. Xu; M. Chandramohan; Y. Liu,"University of Science of Technology of China, Hefei, Anhui, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore",IEEE Transactions on Software Engineering,12 Nov 2019,2019,45,11,1125,1149,"Different from source code clone detection, clone detection (similar code search) in binary executables faces big challenges due to the gigantic differences in the syntax and the structure of binary code that result from different configurations of compilers, architectures and OSs. Existing studies have proposed different categories of features for detecting binary code clones, including CFG structures, n-gram in CFG, input/output values, etc. In our previous study and the tool BinGo, to mitigate the huge gaps in CFG structures due to different compilation scenarios, we propose a selective inlining technique to capture the complete function semantics by inlining relevant library and user-defined functions. However, only features of input/output values are considered in BinGo. In this study, we propose to incorporate features from different categories (e.g., structural features and high-level semantic features) for accuracy improvement and emulation for efficiency improvement. We empirically compare our tool, BinGo-E, with the pervious tool BinGo and the available state-of-the-art tools of binary code search in terms of search accuracy and performance. Results show that BinGo-E achieves significantly better accuracies than BinGo for cross-architecture matching, cross-OS matching, cross-compiler matching and intra-compiler matching. Additionally, in the new task of matching binaries of forked projects, BinGo-E also exhibits a better accuracy than the existing benchmark tool. Meanwhile, BinGo-E takes less time than BinGo during the process of matching.",1939-3520,,10.1109/TSE.2018.2827379,National Research Foundation; CAS Pioneer Hundred Talents Program of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338420,Binary code search;binary clone detection;vulnerability matching;emulation;3D-CFG,Binary codes;Semantics;Tools;Feature extraction;Cloning;Syntactics;Emulation,binary codes;Java;program compilers;program diagnostics;public domain software,source code clone detection;similar code search;binary executables;binary code clones;CFG structures;selective inlining technique;structural features;high-level semantic features;BinGo-E;cross-architecture matching;cross-OS matching;cross-compiler matching;intra-compiler matching;BinGo tool;compilation scenario;cross-architecture cross-OS binary code search,,1.0,,59.0,,16 Apr 2018,,,IEEE,IEEE Journals
1978,618,Automatic Detection and Removal of Ineffective Mutants for the Mutation Analysis of Relational Database Schemas,P. McMinn; C. J. Wright; C. J. McCurdy; G. M. Kapfhammer,"Department of Computer Science, University of Sheffield, Sheffield, South Yorkshire, United Kingdom; Department of Computer Science, University of Sheffield, Sheffield, South Yorkshire, United Kingdom; Department of Computer Science, Allegheny College, Meadville, PA; Department of Computer Science, Allegheny College, Meadville, PA",IEEE Transactions on Software Engineering,14 May 2019,2019,45,5,427,463,"Data is one of an organization's most valuable and strategic assets. Testing the relational database schema, which protects the integrity of this data, is of paramount importance. Mutation analysis is a means of estimating the fault-finding “strength” of a test suite. As with program mutation, however, relational database schema mutation results in many “ineffective” mutants that both degrade test suite quality estimates and make mutation analysis more time consuming. This paper presents a taxonomy of ineffective mutants for relational database schemas, summarizing the root causes of ineffectiveness with a series of key patterns evident in database schemas. On the basis of these, we introduce algorithms that automatically detect and remove ineffective mutants. In an experimental study involving the mutation analysis of 34 schemas used with three popular relational database management systems-HyperSQL, PostgreSQL, and SQLite-the results show that our algorithms can identify and discard large numbers of ineffective mutants that can account for up to 24 percent of mutants, leading to a change in mutation score for 33 out of 34 schemas. The tests for seven schemas were found to achieve 100 percent scores, indicating that they were capable of detecting and killing all non-equivalent mutants. The results also reveal that the execution cost of mutation analysis may be significantly reduced, especially with “heavyweight” DBMSs like PostgreSQL.",1939-3520,,10.1109/TSE.2017.2786286,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240964,software testing;software quality;software tools;relational databases,Relational databases;Algorithm design and analysis;Testing;Taxonomy;Google;Software,program diagnostics;program testing;relational databases;SQL,mutation analysis;program mutation;test suite quality estimates;SQLite;PostgreSQL;HyperSQL;relational database management systems;relational database schemas,,2.0,,84.0,,27 Dec 2017,,,IEEE,IEEE Journals
1979,619,Fully Reflective Execution Environments: Virtual Machines for More Flexible Software,G. Chari; D. Garbervetsky; S. Marr; S. Ducasse,"Departamento de Computación, FCEyN, UBA, ICC CONICET, Buenos Aires, Argentina; Departamento de Computación, FCEyN, UBA, ICC CONICET, Buenos Aires, Argentina; University of Kent, Canterbury, United Kingdom; RMoD project team, Inria Lille - Nord Europe, Villeneuve d'Ascq, France",IEEE Transactions on Software Engineering,17 Sep 2019,2019,45,9,858,876,"VMs are complex pieces of software that implement programming language semantics in an efficient, portable, and secure way. Unfortunately, mainstream VMs provide applications with few mechanisms to alter execution semantics or memory management at run time. We argue that this limits the evolvability and maintainability of running systems for both, the application domain, e.g., to support unforeseen requirements, and the VM domain, e.g., to modify the organization of objects in memory. This work explores the idea of incorporating reflective capabilities into the VM domain and analyzes its impact in the context of software adaptation tasks. We characterize the notion of a fully reflective VM, a kind of VM that provides means for its own observability and modifiability at run time. This enables programming languages to adapt the underlying VM to changing requirements. We propose a reference architecture for such VMs and present TruffleMATE as a prototype for this architecture. We evaluate the mechanisms TruffleMATE provides to deal with unanticipated dynamic adaptation scenarios for security, optimization, and profiling aspects. In contrast to existing alternatives, we observe that TruffleMATE is able to handle all scenarios, using less than 50 lines of code for each, and without interfering with the application's logic.",1939-3520,,10.1109/TSE.2018.2812715,"ANPCYT; UBA-CYT 384; CONICET; Austrian Science Fund; Johannes Kepler University Linz, Austria; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307099,Reflection;virtual machines;metaobject protocols;dynamic adaptation,Software;Memory management;Task analysis;Virtual machining;Semantics;Shape,programming language semantics;security of data;software maintenance;virtual machines,reflective execution environments;virtual machines;flexible software;mainstream VMs;execution semantics;memory management;evolvability;maintainability;software adaptation tasks;fully reflective VM;programming languages;reference architecture;programming language semantics;dynamic adaptation scenarios;TruffleMATE mechanism,,,,74.0,,6 Mar 2018,,,IEEE,IEEE Journals
1980,620,Decomposition-Based Approach for Model-Based Test Generation,P. Arcaini; A. Gargantini; E. Riccobene,"Department of Distributed and Dependable Systems, Charles University, Praha, Czech Republic; Dipartimento di Ingegneria, University of Bergamo, Dalmine, Bergamo, Italy; Computer Science, Universita degli Studi di Milano, Crema, CR, Italy",IEEE Transactions on Software Engineering,14 May 2019,2019,45,5,507,520,"Model-based test generation by model checking is a well-known testing technique that, however, suffers from the state explosion problem of model checking and it is, therefore, not always applicable. In this paper, we address this issue by decomposing a system model into suitable subsystem models separately analyzable. Our technique consists in decomposing that portion of a system model that is of interest for a given testing requirement, into a tree of subsystems by exploiting information on model variable dependency. The technique generates tests for the whole system model by merging tests built from those subsystems. We measure and report effectiveness and efficiency of the proposed decomposition-based test generation approach, both in terms of coverage and time.",1939-3520,,10.1109/TSE.2017.2781231,Grantová Agentura České Republiky; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170269,Model-based testing;test case generation;model checking;state explosion problem;decomposition,Model checking;Unified modeling language;Valves;Silicon;Explosions;Presses,formal verification;program testing,decomposition-based approach;model-based test generation;model checking;testing technique;model variable dependency;decomposition-based test generation approach;testing requirement,,1.0,,41.0,,8 Dec 2017,,,IEEE,IEEE Journals
1981,621,Detecting Developers' Task Switches and Types,A. N. Meyer; C. Satterfield; M. Züger; K. Kevic; G. C. Murphy; T. Zimmermann; T. Fritz,"Department of Informatics, University of Zurich, Zurich, ZH Switzerland 8050 (e-mail: ameyer@ifi.uzh.ch); Department of Informatics, University of British Columbia, Vancouver, British Columbia Canada (e-mail: cds00@cs.ub.ca); Department of Informatics, University of Zurich, Zurich, ZH Switzerland (e-mail: zuger@ifi.uzh.ch); Microsoft Research, Microsoft Research, 214606 Cambridge, Cambridge United Kingdom of Great Britain and Northern Ireland (e-mail: kakevic@microsoft.com); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: fritz@ifi.uzh.ch)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Developers work on a broad variety of tasks during their workdays and constantly switch between them. While these task switches can be beneficial, they can also incur a high cognitive burden on developers, since they have to continuously remember and rebuild task context - the artifacts and applications relevant to the task. Researchers have therefore proposed to capture task context more explicitly and use it to provide better task support, such as task switch reduction or task resumption support. Yet, these approaches generally require the developer to manually identify task switches. Automatic approaches for predicting task switches have so far been limited in their accuracy, scope, evaluation, and the time discrepancy between predicted and actual task switches. In our work, we examine the use of automatically collected computer interaction data for detecting developers' task switches as well as task types. In two field studies - a 4h observational study and a multi-day study with experience sampling - we collected data from a total of 25 professional developers. Our study results show that we are able to use temporal and semantic features from developers' computer interaction data to detect task switches and types in the field with high accuracy of 84% and 61% respectively, and within a short time window of less than 1.6 minutes on average from the actual task switch. We discuss our findings and their practical value for a wide range of applications in real work settings.",1939-3520,,10.1109/TSE.2020.2984086,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069309,Task Detection;Task Switching;Multi-Tasking;Work Fragmentation;Activity Recognition;Machine Learning,Task analysis;Feature extraction;Semantics;Microsoft Windows;Switches;Machine learning,,,,1.0,,,CCBY,16 Apr 2020,,,IEEE,IEEE Early Access Articles
1982,622,Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention,W. Wang; Y. Zhang; Y. Sui; Y. Wan; Z. Zhao; J. Wu; P. Yu; G. Xu,"Computer Science and Engineering, Southern University of Science and Technology, 255310 Shenzhen, Guangdong China (e-mail: cs_wwhua@163.com); Computer science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong China (e-mail: zhangyq@sustc.edu.cn); Faculty of Engineering and Information Technology, UTS, Sydney, New South Wales Australia (e-mail: yulei.sui@uts.edu.au); College of Computer Science and Technology, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: wanyao1992@gmail.com); Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: zhaozhou@zju.edu.cn); Computer Science, Zhejiang University, Hangzhou, Zhejiang China 310027 (e-mail: wujian2000@zju.edu.cn); Computer Science, UIC, Chicago, Illinois United States (e-mail: psyu@uic.edu); Faculty of Engineering and IT, University of Technology Sidney, Chippendale, New South Wales Australia 2008 (e-mail: guandong.xu@uts.edu.au)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Code summarization (aka comment generation) provides a high-level natural language description of the function performed by code, which can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, the state-of-the-art approaches follow an encoder-decoder framework which encodes source code into a hidden space and later decodes it into a natural language space. Such approaches suffer from the following drawbacks: (a) they are mainly input by representing code as a sequence of tokens while ignoring code hierarchy; (b) most of the encoders only input simple features (e.g., tokens) while ignoring the features that can help capture the correlations between comments and code; (c) the decoders are typically trained to predict subsequent words by maximizing the likelihood of subsequent ground truth words, while in real world, they are excepted to generate the entire word sequence from scratch. As a result, such drawbacks lead to inferior and inconsistent comment generation accuracy. To address the above limitations, this paper presents a new code summarization approach using hierarchical attention network by incorporating multiple code features, including type-augmented abstract syntax trees and program control flows. Such features, along with plain code sequences, are injected into a deep reinforcement learning (DRL) framework (e.g., actor-critic network) for comment generation. Our approach assigns weights (pays “attention”) to tokens and statements when constructing the code representation to reflect the hierarchical code structure under different contexts regarding code features (e.g., control flows and abstract syntax trees). Our reinforcement learning mechanism further strengthens the prediction results through the actor network and the critic network, where the actor network provides the confidence of predicting subsequent words based on the current state, and the critic network computes the reward values of all the possible extensions of the current state to provide global guidance for explorations. Eventually, we employ an advantage reward to train both networks and conduct a set of experiments on a real-world dataset. The experimental results demonstrate that our approach outperforms the baselines by around 22% to 45% in BLEU-1 and outperforms the state-of-the-art approaches by around 5% to 60% in terms of S-BLEU and C-BLEU.",1939-3520,,10.1109/TSE.2020.2979701,Australian Research Council; Science and Technology Innovation Committee Foundation of Shenzhen; National Natural Science Foundation of China; Shenzhen Peacock Plan; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031440,Code summarization;hierarchical attention;reinforcement learning,Software;Recurrent neural networks;Training;Machine learning;Decoding;Syntactics;Maintenance engineering,,,,3.0,,,,10 Mar 2020,,,IEEE,IEEE Early Access Articles
1983,623,Finding Substitutable Binary Code By Synthesizing Adapters,V. Sharma; K. Hietala; S. McCamant,"Department of Computer Science and Engineering, University of Minnesota, Minneapolis, Minnesota United States (e-mail: vaibhav@umn.edu); Department of Computer Science, University of Maryland, College Park, Maryland United States (e-mail: kesha@cs.umd.edu); Computer Science & Engineering, University of Minnesota, Minneapolis, Minnesota United States 55455 (e-mail: mccamant@cs.umn.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Independently developed codebases typically contain many segments of code that perform same or closely related operations (semantic clones). Finding functionally equivalent segments enables applications like replacing a segment by a more efficient or more secure alternative. Such related segments often have different interfaces, so some glue code (an adapter) is needed to replace one with the other. We present an algorithm that searches for replaceable code segments by attempting to synthesize an adapter between them from some finite family of adapters; it terminates if it finds no possible adapter. We implement our technique using concrete adapter enumeration based on Intel's Pin framework and binary symbolic execution, and explore the relation between size of adapter search space and total search time. We present examples of applying adapter synthesis for improving security of binary functions and switching between binary implementations of RC4. We present two large-scale evaluations: (1) we run adapter synthesis on more than 13,000 function pairs from the Linux C library, and (2) we reverse engineer fragments of ARM binary code by running more than a million adapter synthesis tasks. Our results confirm that several instances of adaptably equivalent binary functions exist in real-world code, and suggest that adapter synthesis can be applied for automatically replacing binary code with its adaptably equivalent variants.",1939-3520,,10.1109/TSE.2019.2931000,Division of Computing and Communication Foundations; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8776650,,Tools;Binary codes;Libraries;Security;Task analysis;Reverse engineering;Computer science,,,,1.0,,,,25 Jul 2019,,,IEEE,IEEE Early Access Articles
1984,624,A Multi-Armed Bandit Approach for Test Case Prioritization in Continuous Integration Environments,J. A. d. Prado Lima; S. R. Vergilio,"Computer Science, Federal University of Parana, 28122 Curitiba, Paran Brazil (e-mail: jacksonpradolima@gmail.com); Computer Science Department, Federal University of Paran - UFPR, Curitiba, Parana Brazil 81531-970 (e-mail: silvia@inf.ufpr.br)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Continuous Integration (CI) environments have been increasingly adopted in the industry to allow frequent integration of software changes, making software evolution faster and cost-effective. In such environments, Test Case Prioritization (TCP) techniques play an important role to reduce regression testing costs, establishing a test case execution order that usually maximizes early fault detection. Existing works on TCP in CI environments (TCPCI) present some limitations. Few pieces of work consider CI particularities, such as the test case volatility, that is, they do not consider the dynamic environment of the software life-cycle in which new test cases can be added or removed (discontinued), characteristic related to the Exploration versus Exploitation (EvE) dilemma. To solve such a dilemma an approach needs to balance: i) the diversity of test suite; and ii) the quantity of new test cases and test cases that are error-prone or that comprise high fault-detection capabilities. To deal with this, most approaches use, besides the failure-history, other measures that rely on code instrumentation or require additional information, such as testing coverage. However, to maintain the information updated can be difficult and time-consuming, not scalable due to the test budget of CI environments. In this context, and to properly deal with the TCPCI problem, this work presents an approach based on Multi-Armed Bandit (MAB) called COLEMAN (Combinatorial VOlatiLE Multi-Armed BANdit). The TCPCI problem falls into the category of volatile and combinatorial MAB, because multiple arms (test cases) need to be selected, and they are added or removed over the cycles. We conducted an evaluation considering three time budgets and eleven systems. The results show the applicability of our approach and that COLEMAN outperforms the most similar approach from literature in terms of early fault detection and performance.",1939-3520,,10.1109/TSE.2020.2992428,Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico; Coordenao de Aperfeioamento de Pessoal de Nvel Superior; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086053,Test Case Prioritization;Continuous Integration;Multi-Armed Bandit,Testing;Fault detection;Software;Instruments;Google;Industries;Companies,,,,,,,,4 May 2020,,,IEEE,IEEE Early Access Articles
1985,625,Large-Scale Third-Party Library Detection in Android Markets,M. Li; P. Wang; W. Wang; S. Wang; D. Wu; J. Liu; R. Xue; W. Huo; W. Zou,"Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA, USA; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA, USA; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA, USA; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,981,1003,"With the thriving of mobile app markets, third-party libraries are pervasively used in Android applications. The libraries provide functionalities such as advertising, location, and social networking services, making app development much more productive. However, the spread of vulnerable and harmful third-party libraries can also hurt the mobile ecosystem, leading to various security problems. Therefore, third-party library identification has emerged as an important problem, being the basis of many security applications such as repackaging detection, vulnerability identification, and malware analysis. Previously, we proposed a novel approach to identifying third-party Android libraries at a massive scale. Our method uses the internal code dependencies of an app to recognize library candidates and further classify them. With a fine-grained feature hashing strategy, we can better handle code whose package and method names are obfuscated than historical work. We have developed a prototypical tool called LibD and evaluated it with an up-to-date dataset containing 1,427,395 Android apps. Our experiment results show that LibD outperforms existing tools in detecting multi-package third-party libraries with the presence of name-based obfuscation, leading to significantly improved precision without the loss of scalability. In this paper, we extend our early work by investigating the possibility of employing effective and scalable library detection to boost the performance of large-scale app analyses in the real world. We show that the technique of LibD can be used to accelerate whole-app Android vulnerability detection and quickly identify variants of vulnerable third-party libraries. This extension paper sheds light on the practical value of our previous research.",1939-3520,,10.1109/TSE.2018.2872958,National Natural Science Foundation of China; Beijing Municipal Science and Technology Commission; National Science Foundation; Office of Naval Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478000,Android;third-party library;software mining;code similarity detection,Libraries;Androids;Humanoid robots;Tools;Security;Java;Feature extraction,Android (operating system);invasive software;mobile computing;security of data;smart phones;software libraries,Android apps;third-party Android libraries;third-party library identification;app development;Android applications;mobile app markets;Android markets;third-party library detection;whole-app Android vulnerability detection;large-scale app analyses;scalable library detection,,,,79.0,IEEE,30 Sep 2018,,,IEEE,IEEE Journals
1986,626,Automated Generation of Consistent Graph Models with Multiplicity Reasoning,K. Marussy; O. Semerath; D. Varro,"Department of Measurement and Information Systems, Budapest University of Technology and Economics Faculty of Electrical Engineering and Informatics, 309392 Budapest, Budapest, Hungary, 1117 (e-mail: marussy@mit.bme.hu); Department of Measurement and Information System, Budapest University of Technology and Economics, 61810 Budapest, Budapest, Hungary, (e-mail: semerath@mit.bme.hu); Department of Electrical & Computer Engineering, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: daniel.varro@mcgill.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Advanced tools used in model-based systems engineering (MBSE) frequently represent their models as graphs. In order to test those tools, the automated generation of well-formed (or intentionally malformed) graph models is necessitated which is often carried out by solver-based model generation techniques. In many model generation scenarios, one needs more refined control over the generated unit tests to focus on the more relevant models. Type scopes allow to precisely define the required number of newly generated elements, thus one can avoid the generation of unrealistic and highly symmetric models having only a single type of elements. In this paper, we propose a 3-valued scoped partial modeling formalism, which innovatively extends partial graph models with predicate abstraction and counter abstraction. As a result, well-formedness constraints and multiplicity requirements can be evaluated in an approximated way on incomplete (unfinished) models by using advanced graph query engines with numerical solvers (e.g. IP or LP solvers). Based on the refinement of 3-valued scoped partial models, we propose an efficient model generation algorithm that generates models that are both well-formed and satisfy the scope requirements. We show that the proposed approach scales significantly better than existing SAT-solver techniques or the original graph solver without multiplicity reasoning. We illustrate our approach in a complex design-space exploration case study of collaborating satellites introduced by researchers at NASA Jet Propulsion Lab.",1939-3520,,10.1109/TSE.2020.3025732,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201551,D.2.11.b Domain-specific architectures;E.1.d Graphs and networks;F.4.1.d Logic and constraint programming;I.6.4 Model Validation and Analysis,Numerical models;Tools;Object oriented modeling;Generators;Unified modeling language;Biological system modeling,,,,,,,CCBY,21 Sep 2020,,,IEEE,IEEE Early Access Articles
1987,627,Code Reviews with Divergent Review Scores: An Empirical Study of the OpenStack and Qt Communities,T. Hirao; S. McIntosh; A. Ihara; K. Matsumoto,"Graduate School of Information Science, Nara Institute of Science and Technology, Japan (e-mail: hirao.toshiki.ho7@is.naist.jp); Department of Electrical and Computer Engineering, McGill University, Canada (e-mail: shane.mcintosh@mcgill.ca); Fuculty of System Engineering, Wakayama University, Japan (e-mail: ihara@sys.wakayama-u.ac.jp); Graduate School of Information Science, Nara Institute of Science and Technology, Japan (e-mail: matumoto@is.naist.jp)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Code review is a broadly adopted software quality practice where developers critique each others' patches. In addition to providing constructive feedback, reviewers may provide a score to indicate whether the patch should be integrated. Since reviewer opinions may differ, patches can receive both positive and negative scores. If reviews with divergent scores are not carefully resolved, they may contribute to a tense reviewing culture and may slow down integration. In this paper, we study patches with divergent review scores in the OPENSTACK and QT communities. Quantitative analysis indicates that patches with divergent review scores: (1) account for 15%-37% of patches that receive multiple review scores; (2) are integrated more often than they are abandoned; and (3) receive negative scores after positive ones in 70% of cases. Furthermore, a qualitative analysis indicates that patches with strongly divergent scores that: (4) are abandoned more often suffer from external issues (e.g., integration planning, content duplication) than patches with weakly divergent scores and patches without divergent scores; and (5) are integrated often address reviewer concerns indirectly (i.e., without changing patches). Our results suggest that review tooling should integrate with release schedules and detect concurrent development of similar patches to optimize review discussions with divergent scores. Moreover, patch authors should note that even the most divisive patches are often integrated through discussion, integration timing, and careful revision.",1939-3520,,10.1109/TSE.2020.2977907,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023005,Modern Code Review;Divergent discussion;Empirical Study,Testing;Timing;Software quality;Statistical analysis;Planning;Organizations,,,,1.0,,,,3 Mar 2020,,,IEEE,IEEE Early Access Articles
1988,628,Reviving Sequential Program Birthmarking for Multithreaded Software Plagiarism Detection,Z. Tian; T. Liu; Q. Zheng; E. Zhuang; M. Fan; Z. Yang,"Department of Computer Science and Technology, Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science and Technology, Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xi'an, China; Department of Computer Science and Technology, Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xi'an, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI",IEEE Transactions on Software Engineering,9 May 2018,2018,44,5,491,511,"As multithreaded programs become increasingly popular, plagiarism of multithreaded programs starts to plague the software industry. Although there has been tremendous progress on software plagiarism detection technology, existing dynamic birthmark approaches are applicable only to sequential programs, due to the fact that thread scheduling nondeterminism severely perturbs birthmark generation and comparison. We propose a framework called TOB (Thread-oblivious dynamic Birthmark) that revives existing techniques so they can be applied to detect plagiarism of multithreaded programs. This is achieved by thread-oblivious algorithms that shield the influence of thread schedules on executions. We have implemented a set of tools collectively called TOB-PD (TOB based Plagiarism Detection tool) by applying TOB to three existing representative dynamic birthmarks, including SCSSB (System Call Short Sequence Birthmark), DYKIS (DYnamic Key Instruction Sequence birthmark) and JB (an API based birthmark for Java). Our experiments conducted on large number of binary programs show that our approach exhibits strong resilience against state-of-the-art semantics-preserving code obfuscation techniques. Comparisons against the three existing tools SCSSB, DYKIS and JB show that the new framework is effective for plagiarism detection of multithreaded programs. The tools, the benchmarks and the experimental results are all publicly available.",1939-3520,,10.1109/TSE.2017.2688383,National Key Research and Development Program of China; National Science Foundation of China; Fok Ying-Tong Education Foundation; Ministry of Education Innovation Research Team; Science and Technology Project in Shaanxi Province of China; Fundamental Research Funds for the Central Universities; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888597,Software plagiarism detection;multithreaded program;software birthmark;thread-oblivious birthmark,Plagiarism;Instruction sets;Computer science;Dynamic scheduling;Indexes;Electronic mail,computer crime;fraud;multi-threading;scheduling,sequential program birthmarking;multithreaded programs;software industry;software plagiarism detection technology;dynamic birthmark approaches;thread scheduling nondeterminism;birthmark generation;Thread-oblivious dynamic Birthmark;thread-oblivious algorithms;thread schedules;Plagiarism Detection tool;System Call Short Sequence Birthmark;DYnamic Key Instruction Sequence birthmark;API based birthmark;binary programs;multithreaded software,,7.0,,65.0,,28 Mar 2017,,,IEEE,IEEE Journals
1989,629,A Systematic Literature Review of Applications of the Physics of Notations,D. van der Linden; I. Hadar,"Department of Computer Science, University of Bristol, Bristol, United Kingdom; Department of Information Systems, University of Haifa, Haifa, Israel",IEEE Transactions on Software Engineering,26 Aug 2019,2019,45,8,736,759,"INTRODUCTION: The Physics of Notations (PoN) is a theory for the design of cognitively effective visual notations, emphasizing the need for design grounded in objective and verifiable rationale. Although increasingly applied, no systematic analysis of PoN applications has yet been performed to assess the theory's efficacy in practice. OBJECTIVES: Our primary objective was to assess the scope and verifiability of PoN applications. METHOD: We performed a systematic literature review (SLR) of peer-reviewed PoN applications. We analyzed what visual notations have been evaluated and designed using the PoN, for what reasons, to what degree applications consider requirements of their notation's users, and how verifiable these applications are. RESULTS: Seventy PoN applications were analyzed. We found major differences between applications evaluating existing notations and applications designing new notations. Particularly, in the case of new notations, we found that most applications adopted the PoN with little critical thought towards it, rarely considered its suitability for a particular context, and typically treated and discussed the PoN with few, if any, verifiable details and data. CONCLUSION: The results warrant consideration for those applying the PoN to do so carefully, and show the need for additional means to guide designers in systematically applying the PoN.",1939-3520,,10.1109/TSE.2018.2802910,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283537,Systematic literature review;physics of notations;visual notations;cognitive effectiveness;design rationale,Visualization;Unified modeling language;Semantics;Complexity theory;Physics,data visualisation;formal specification;visual languages,systematic literature review;cognitively effective visual notations;verifiable rationale;systematic analysis;peer-reviewed PoN applications;physics of notations;SLR;objective rationale,,,,113.0,,6 Feb 2018,,,IEEE,IEEE Journals
1990,630,Requirements Framing Affects Design Creativity,R. Mohanani; B. Turhan; P. Ralph,"Dept. of CSE & HCD, IIIT Delhi, New Delhi, Delhi, India; M3S Group, University of Oulu, FI, Finland; Dept. of Comp. Sci., Univ. of Auckland, Auckland, New Zealand",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,936,947,"Design creativity, the originality and practicality of a solution concept, is critical for the success of many software projects. However, little research has investigated the relationship between the way desiderata are presented and design creativity. This study therefore investigates the impact of presenting desiderata as ideas, requirements or prioritized requirements on design creativity. Two between-subjects randomized controlled experiments were conducted with 42 and 34 participants. Participants were asked to create design concepts from a list of desiderata. Participants who received desiderata framed as requirements or prioritized requirements created designs that are, on average, less original but more practical than the designs created by participants who received desiderata framed as ideas. This suggests that more formal, structured presentations of desiderata are less appropriate where more innovative solutions are desired. The results also show that design performance is highly susceptible to minor changes in the vernacular used to communicate desiderata.",1939-3520,,10.1109/TSE.2019.2909033,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680661,Cognitive bias;creativity;design;experiment;originality;practicality;requirements;prioritization,Creativity;Software;Task analysis;Requirements engineering;Random access memory;Ferroelectric films;Nonvolatile memory,,,,2.0,,93.0,IEEE,2 Apr 2019,,,IEEE,IEEE Journals
1991,631,RefDiff 2.0: A Multi-language Refactoring Detection Tool,D. Silva; J. Silva; G. J. De Souza Santos; R. Terra; M. T. O. Valente,"Department of Computer Science, Universidade Federal de Minas Gerais, 28114 Belo Horizonte, MG Brazil (e-mail: danilofes@gmail.com); n/a, Quimbik, Inc., San Rafael, California United States (e-mail: joao@jpribeiro.com.br); COENS, Universidade Tecnológica Federal do Paraná, 74354 Dois Vizinhos, Paranó Brazil (e-mail: gustavosantos@utfpr.edu.br); DCC, Universidade Federal de Lavras, Lavras, MG Brazil (e-mail: rterrabh@gmail.com); Department of Computer Science, Universidade Federal de Minas Gerais, 28114 Belo Horizonte, MG Brazil (e-mail: mtov@dcc.ufmg.br)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Identifying refactoring operations in source code changes is valuable to understand software evolution. Therefore, several tools have been proposed to automatically detect refactorings applied in a system by comparing source code between revisions. The availability of such infrastructure has enabled researchers to study refactoring practice in large scale, leading to important advances on refactoring knowledge. However, although a plethora of programming languages are used in practice, the vast majority of existing studies are restricted to the Java language due to limitations of the underlying tools. This fact poses an important threat to external validity. Thus, to overcome such limitation, in this paper we propose RefDiff 2.0, a multi-language refactoring detection tool. Our approach leverages techniques proposed in our previous work and introduces a novel refactoring detection algorithm that relies on the Code Structure Tree (CST), a simple yet powerful representation of the source code that abstracts away the specificities of particular programming languages. Despite its language-agnostic design, our evaluation shows that RefDiff's precision (96%) and recall (80%) are on par with state-of-the-art refactoring detection approaches specialized in the Java language. Our modular architecture also enables one to seamless extend RefDiff to support other languages via a plugin system. As a proof of this, we implemented plugins to support two other popular programming languages: JavaScript and C. Our evaluation in these languages reveals that precision and recall ranges from 88% to 91%. With these results, we envision RefDiff as a viable alternative for breaking the single-language barrier in refactoring research and in practical applications of refactoring detection.",1939-3520,,10.1109/TSE.2020.2968072,Fundacao de Amparo a Pesquisa do Estado de Minas Gerais; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966516,,Tools;Java;Software;History;Crawlers;Measurement,,,,,,,,22 Jan 2020,,,IEEE,IEEE Early Access Articles
1992,632,On the Energy Footprint of Mobile Testing Frameworks,L. Cruz; R. Abreu,"SERG, Delft University of Technology, 2860 Delft, Zuid-Holland Netherlands (e-mail: luiscruz@fe.up.pt); Computer Science and Engineering, Instituto Superior Técnico, University of Lisbon, Lisbon, Lisbon Portugal 1049-001 (e-mail: rui@computer.org)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"High energy consumption is a challenging issue that an ever increasing number of mobile applications face today. However, energy consumption is being tested in an ad hoc way, despite being an important non-functional requirement of an application. Such limitation becomes particularly disconcerting during software testing: on the one hand, developers do not really know how to measure energy; on the other hand, there is no knowledge as to what is the energy overhead imposed by the testing framework. In this paper, as we evaluate eight popular mobile UI automation frameworks, we have discovered that there are automation frameworks that increase energy consumption up to roughly 2200%. While limited in the interactions one can do, Espresso is the most energy efficient framework. However, depending on the needs of the tester, Appium, Monkeyrunner, or UIAutomator are good alternatives. In practice, results show that deciding which is the most suitable framework is vital. We provide a decision tree to help developers make an educated decision on which framework suits best their testing needs.",1939-3520,,10.1109/TSE.2019.2946163,"Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862921,Mobile Testing;Testing Frameworks;Energy Consumption,Automation;Energy consumption;Testing;Tools;Energy measurement;Monitoring;Robots,,,,,,,,8 Oct 2019,,,IEEE,IEEE Early Access Articles
1993,633,"Incidents Are Meant for Learning, Not Repeating: Sharing Knowledge About Security Incidents in Cyber-Physical Systems",F. Alrimawi; L. Pasquale; D. Mehta; N. Yoshioka; B. Nuseibeh,"Lero-The Irish Software Research Centre, University of Limerick, 8808 Limerick, Munster Ireland (e-mail: faeq.rimawi@gmail.com); Computer Science, University College Dublin, 8797 Dublin, Belfield Ireland (e-mail: liliana.pasquale@ucd.ie); UTRC, United Technologies Research Center, 129535 Cork, Munster Ireland (e-mail: MehtaD@utrc.utc.com); NII, National Institute of Informatics, 13513 Chiyoda-ku, Tokyo Japan (e-mail: nobukazu@nii.ac.jp); Lero-The Irish Software Research Centre, University of Limerick, 8808 Limerick, Munster Ireland (e-mail: bashar.nuseibeh@lero.ie)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Cyber-physical systems (CPSs) are part of many critical infrastructures such as industrial automation and transportation systems. Thus, security incidents targeting CPSs can have disruptive consequences to assets and people. As incidents tend to re-occur, sharing knowledge about these incidents can help organizations be more prepared to prevent, mitigate or investigate future incidents. This paper proposes a novel approach to enable representation and sharing of knowledge about CPS incidents across different organizations. To support sharing, we represent incident knowledge (incident patterns) capturing incident characteristics that can manifest again, such as incident activities or vulnerabilities exploited by offenders. Incident patterns are a more abstract representation of specific incident instances and, thus, are general enough to be applicable to various systems - different than the one in which the incident occurred. They can also avoid disclosing potentially sensitive information about an organization's assets and resources. We provide an automated technique to extract an incident pattern from a specific incident instance. To understand how an incident pattern can manifest again in other cyber-physical systems, we also provide an automated technique to instantiate incident patterns to specific systems. We demonstrate the feasibility of our approach in the application domain of smart buildings. We evaluate correctness, scalability, and performance using two substantive scenarios inspired by real-world systems and incidents.",1939-3520,,10.1109/TSE.2020.2981310,ERC Advanced Grant; Science Foundation Ireland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039700,Cyber-physical systems;Security incidents;Smart building;Knowledge Sharing,Security;Smart buildings;Cyber-physical systems;Organizations;HVAC;Servers,,,,1.0,,,,17 Mar 2020,,,IEEE,IEEE Early Access Articles
1994,634,Value-Flow-Based Demand-Driven Pointer Analysis for C and C++,Y. Sui; J. Xue,"Artificial Intelligence (CAI), University of Technology Sydney (UTS), Ultimo, NSW, Australia; University of New South Wales (UNSW), Sydney, NSW, Australia",IEEE Transactions on Software Engineering,13 Aug 2020,2020,46,8,812,835,"We present Supa, a value-flow-based demand-driven flow- and context-sensitive pointer analysis with strong updates for C and C++ programs. Supa enables computing points-to information via value-flow refinement, in environments with small time and memory budgets. We formulate Supa by solving a graph-reachability problem on an inter-procedural value-flow graph representing a program's def-use chains, which are pre-computed efficiently but over-approximately. To answer a client query (a request for a variable's points-to set), Supa reasons about the flow of values along the pre-computed def-use chains sparsely (rather than across all program points), by performing only the work necessary for the query (rather than analyzing the whole program). In particular, strong updates are performed to filter out spurious def-use chains through value-flow refinement as long as the total budget is not exhausted. We have implemented Supa on top of LLVM (4.0.0) together with a comprehensive micro-benchmark suite after a years-long effort (consisting of around 400 test cases, including hand-written ones and the ones extracted from real programs). We have evaluated Supa by choosing uninitialized pointer detection and C++ virtual table resolution as two major clients, using 24 real-world programs including 18 open-source C programs and 6 large CPU2000/2006 C++ benchmarks. For uninitialized pointer client, Supa achieves improved precision as the analysis budget increases, with its flow-sensitive (context-insensitive) analysis reaching 97.4 percent of that achieved by whole-program Sparse Flow-Sensitive analysis (SFS) by consuming about 0.18 seconds and 65 KB of memory per query, on average (with a budget of at most 10,000 value-flow edges per query). With context-sensitivity also considered, Supa becomes more precise for some programs but also incurs more analysis times. To further demonstrate the effectiveness of Supa, we have also evaluated Supa in resolving C++ virtual tables by querying the function pointers at every virtual callsite. Compared to analysis without strong updates for heap objects, Supa's demand-driven context-sensitive strong update analysis reduces 7.35 percent spurious virtual table targets with only 0.4 secs per query, on average.",1939-3520,,10.1109/TSE.2018.2869336,Australian Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457263,Strong updates;value flow;pointer analysis;flow sensitivity,C++ languages;Resource management;Open source software;Sensitivity;Reachability analysis;Instruction sets;Registers,data flow analysis;data structures;flow graphs;object-oriented programming;optimising compilers;program diagnostics;reachability analysis;sensitivity analysis,value-flow-based demand-driven flow;context-sensitive pointer analysis;value-flow refinement;inter-procedural value-flow graph;pre-computed def-use chains;pointer client;sparse flow-sensitive analysis;value-flow-based demand-driven pointer analysis;Supa demand-driven context-sensitive strong update analysis;C++ program;C program;time 0.4 s;memory size 65.0 KByte;temperature 2006.0 C;efficiency 97.4 percent;efficiency 7.35 percent,,2.0,,58.0,IEEE,11 Sep 2018,,,IEEE,IEEE Journals
1995,635,Tell You a Definite Answer: Whether Your Data is Tainted During Thread Scheduling,X. Zhang; Z. Yang; Q. Zheng; Y. Hao; P. Liu; T. Liu,"Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,916,931,"With the advent of multicore processors, there is a great need to write parallel programs to take advantage of parallel computing resources. However, due to the nondeterminism of parallel execution, the malware behaviors sensitive to thread scheduling are extremely difficult to detect. Dynamic taint analysis is widely used in security problems. By serializing a multithreaded execution and then propagating taint tags along the serialized schedule, existing dynamic taint analysis techniques lead to under-tainting with respect to other possible interleavings under the same input. In this paper, we propose an approach called DSTAM that integrates symbolic analysis and guided execution to systematically detect tainted instances on all possible executions under a given input. Symbolic analysis infers alternative interleavings of an executed trace that cover new tainted instances, and computes thread schedules that guide future executions. Guided execution explores new execution traces that drive future symbolic analysis. We have implemented a prototype as part of an educational tool that teaches secure C programming, where accuracy is more critical than efficiency. To the best of our knowledge, DSTAM is the first algorithm that addresses the challenge of taint analysis for multithreaded program under fixed inputs.",1939-3520,,10.1109/TSE.2018.2871666,National Key R&D Program of China; National Natural Science Foundation of China; Fok Ying Tung Education Foundation; Ministry of Education Innovation Research Team; Project of China Knowledge Centre for Engineering Science and Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472790,Taint analysis;multithreaded programs;symbolic analysis;encoding;guided execution,Instruction sets;Security;Tools;Monitoring;Schedules;Prototypes,invasive software;microprocessor chips;multiprocessing systems;multi-threading;parallel programming;program diagnostics;scheduling,tainted instances;thread schedules;guide future executions;drive future symbolic analysis;secure C programming;DSTAM;multithreaded program;definite answer;thread scheduling;multicore processors;parallel programs;parallel computing resources;parallel execution;security problems;multithreaded execution;taint tags;serialized schedule;dynamic taint analysis techniques;alternative interleavings;executed trace,,,,62.0,IEEE,26 Sep 2018,,,IEEE,IEEE Journals
1996,636,A Study of Feature Scattering in the Linux Kernel,L. Passos; R. Queiroz; M. Mukelabai; T. Berger; S. Apel; K. Czarnecki; J. A. Padilla,"Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Computer Science and Engineering, Chalmers University of Technology, Gothenburg, SE, Sweden; Computer Science and Engineering, Chalmers University of Technology, Gothenburg, SE, Sweden; Informatics and Mathematics, University of Passau, Bavaria, DE, Germany; Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; SAP, SAP Waterloo, Waterloo, ON, Canada",IEEE Transactions on Software Engineering,8 Jan 2021,2021,47,1,146,164,"Feature code is often scattered across a software system. Scattering is not necessarily bad if used with care, as witnessed by systems with highly scattered features that evolved successfully. Feature scattering, often realized with a pre-processor, circumvents limitations of programming languages and software architectures. Unfortunately, little is known about the principles governing scattering in large and long-living software systems. We present a longitudinal study of feature scattering in the Linux kernel, complemented by a survey with 74, and interviews with nine Linux kernel developers. We analyzed almost eight years of the kernel's history, focusing on its largest subsystem: device drivers. We learned that the ratio of scattered features remained nearly constant and that most features were introduced without scattering. Yet, scattering easily crosses subsystem boundaries, and highly scattered outliers exist. Scattering often addresses a performance-maintenance tradeoff (alleviating complicated APIs), hardware design limitations, and avoids code duplication. While developers do not consciously enforce scattering limits, they actually improve the system design and refactor code, thereby mitigating pre-processor idiosyncrasies or reducing its use.",1939-3520,,10.1109/TSE.2018.2884911,Vinnova Sweden; Vetenskapsrådet; Deutsche Forschungsgemeinschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565973,"Pre-processor, linux kernel, feature, scattering",Scattering;Kernel;Linux;Interviews;Software systems;Maintenance engineering,device drivers;Linux;operating system kernels;software maintenance;source code (software),refactor code;feature scattering;feature code;software system;Linux kernel developers;system design;device drivers,,3.0,,63.0,IEEE,6 Dec 2018,,,IEEE,IEEE Journals
1997,637,A Framework for Quantitative Modeling and Analysis of Highly (Re)configurable Systems,M. H. Ter Beek; A. Legay; A. L. Lafuente; A. Vandin,"Istituto di Scienza e Tecnologie dell'Informazione, Consiglio Nazionale delle Ricerche, Pisa, Italy; Inria Rennes, Rennes, France; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kgs. Lyngby, Denmark",IEEE Transactions on Software Engineering,13 Mar 2020,2020,46,3,321,345,"This paper presents our approach to the quantitative modeling and analysis of highly (re)configurable systems, such as software product lines. Different combinations of the optional features of such a system give rise to combinatorially many individual system variants. We use a formal modeling language that allows us to model systems with probabilistic behavior, possibly subject to quantitative feature constraints, and able to dynamically install, remove or replace features. More precisely, our models are defined in the probabilistic feature-oriented language QFLan, a rich domain specific language (DSL) for systems with variability defined in terms of features. QFLan specifications are automatically encoded in terms of a process algebra whose operational behavior interacts with a store of constraints, and hence allows to separate system configuration from system behavior. The resulting probabilistic configurations and behavior converge seamlessly in a semantics based on discrete-time Markov chains, thus enabling quantitative analysis. Our analysis is based on statistical model checking techniques, which allow us to scale to larger models with respect to precise probabilistic analysis techniques. The analyses we can conduct range from the likelihood of specific behavior to the expected average cost, in terms of feature attributes, of specific system variants. Our approach is supported by a novel Eclipse-based tool which includes state-of-the-art DSL utilities for QFLan based on the Xtext framework as well as analysis plug-ins to seamlessly run statistical model checking analyses. We provide a number of case studies that have driven and validated the development of our framework.",1939-3520,,10.1109/TSE.2018.2853726,EU project QUANTICOL; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405597,Software product lines;probabilistic modeling;quantitative constraints;statistical model checking;formal methods,Probabilistic logic;Model checking;Tools;Analytical models;Runtime;Computational modeling;DSL,formal specification;formal verification;Markov processes;probability;process algebra;specification languages;statistical analysis,system configuration;system behavior;resulting probabilistic configurations;quantitative analysis;statistical model checking techniques;larger models;precise probabilistic analysis techniques;specific behavior;feature attributes;specific system variants;analysis plug-ins;statistical model checking analyses;highlyconfigurable systems;quantitative modeling;software product lines;optional features;combinatorially many individual system variants;formal modeling language;probabilistic behavior;quantitative feature constraints;probabilistic feature-oriented language QFLan;rich domain specific language;QFLan specifications;process algebra,,1.0,,95.0,IEEE,6 Jul 2018,,,IEEE,IEEE Journals
1998,638,A Cost-efficient Auto-scaling Algorithm for Large-scale Graph Processing in Cloud Environments with Heterogeneous Resources,S. Heidari; R. Buyya,"The School of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria Australia (e-mail: sheidari@student.unimelb.edu.au); CSSE, TThe University of Melbourne, Melbourne, Victoria Australia 3010 (e-mail: rbuyya@unimelb.edu.au)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Graph processing model is being adopted extensively in various domains such as online gaming, social media, scientific computing and Internet of Things (IoT). Many frameworks have been developed in recent years to facilitate analytics and computing of large-scale graphs. Dynamic scalability is always a major concern and It becomes even more important when there is a correlation between scalability and monetary cost. The pay-as-you-go model that is used by public cloud providers enables users to pay only for the number of resources they utilize. Nevertheless, processing large-scale graphs in such environments has been less studied. In this paper, we have developed algorithms to take advantage of resource heterogeneity in cloud environments. Using these algorithms, the system can automatically adjust the number and types of virtual machines according to the computation requirements for convergent graph applications to improve the performance and reduce the dollar cost of the entire operation. Also, a smart profiling mechanism along with a novel dynamic repartitioning approach helps to distribute graph partitions expeditiously. It is shown that this method outperforms popular frameworks such as Giraph and decreases more than 50% of the dollar cost compared to Giraph.",1939-3520,,10.1109/TSE.2019.2934849,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798698,Cloud Computing;Large-scale Graph Processing;Auto-scaling;Cost Saving;Heterogeneous Resources,Cloud computing;Scalability;Computational modeling;Internet of Things;Heuristic algorithms;Software algorithms;Clustering algorithms,,,,,,,,14 Aug 2019,,,IEEE,IEEE Early Access Articles
1999,639,Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning,Y. Yamagata; S. Liu; T. Akazaki; Y. Duan; J. Hao,"Cyber Physical Security Research Center, National Institute of Advanced Industrial Science and Technology Kansai Center, 73773 Ikeda, Osaka Japan (e-mail: yoriyuki.yamagata@aist.go.jp); College of Intelligence and Computing, Tianjin University, China. (e-mail: shuang.liu@tju.edu.cn); Software Laboratory, Fujitsu Laboratories Ltd, 133674 Kawasaki, Kanagawa Japan (e-mail: akazaki.takumi@jp.fujitsu.com); College of Intellegence and Computing, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: duanyihai@tju.edu.cn); College of Intelligence and Computing, Tianjin University, China and Noah’s Ark Lab, Huawei. (e-mail: jianye.hao@tju.edu.cn)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"A Cyber-Physical System (CPS) is a system which consists of software components and physical components. Traditional system verification techniques such as model checking or theorem proving are difficult to apply to CPS because the physical components have infinite number of states. To solve this problem, robustness guided falsification of CPS is introduced. Robustness measures how robustly the given specification is satisfied. Robustness guided falsification tries to minimize the robustness by changing inputs and parameters of the system. The input with a minimal robustness (counterexample) is a good candidate to violate the specification. Existing methods use several optimization techniques to minimize robustness. However, those methods do not use temporal structures in a system input and often require a large number of simulation runs to the minimize robustness. In this paper, we explore state-of-the-art Deep Reinforcement Learning (DRL) techniques, i.e., Asynchronous Advantage Actor-Critic (A3C) and Double Deep Q Network (DDQN), to reduce the number of simulation runs required to find such counterexamples. We theoretically show how robustness guided falsification of a safety property is formatted as a reinforcement learning problem. Then, we experimentally compare the effectiveness of our methods with three baseline methods, i.e., random sampling, cross entropy and simulated annealing, on three well known CPS systems. We thoroughly analyse the experiment results and identify two factors of CPS which make DRL based methods better than existing methods. The most important factor is the availability of the system internal dynamics to the reinforcement learning algorithm. The other factor is the existence of learnable structure in the counterexample.",1939-3520,,10.1109/TSE.2020.2969178,Special Program of Artificial Intelligence of Tianjin Municipal Science and Technology Commission; The New Energy and Industrial Technology Development Organization Japan; Special Program of Artificial Intelligence Tianjin Research Program of Application Foundation and Advanced Technology; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967146,Robustness guided falsification;CPS;Reinforcement Learning,Robustness;Reinforcement learning;Model checking;Measurement;Software;Optimization,,,,1.0,,,,23 Jan 2020,,,IEEE,IEEE Early Access Articles
2000,640,On the Multiple Sources and Privacy Preservation Issues for Heterogeneous Defect Prediction,Z. Li; X. Jing; X. Zhu; H. Zhang; B. Xu; S. Ying,"Wuhan University, Wuhan, China; Wuhan University, Wuhan, China; Henan University, Kaifeng, China; University of Newcastle, Callaghan, NSW, Australia; Wuhan University, Wuhan, China; Wuhan University, Wuhan, China",IEEE Transactions on Software Engineering,16 Apr 2019,2019,45,4,391,411,"Heterogeneous defect prediction (HDP) refers to predicting defect-proneness of software modules in a target project using heterogeneous metric data from other projects. Existing HDP methods mainly focus on predicting target instances with single source. In practice, there exist plenty of external projects. Multiple sources can generally provide more information than a single project. Therefore, it is meaningful to investigate whether the HDP performance can be improved by employing multiple sources. However, a precondition of conducting HDP is that the external sources are available. Due to privacy concerns, most companies are not willing to share their data. To facilitate data sharing, it is essential to study how to protect the privacy of data owners before they release their data. In this paper, we study the above two issues in HDP. Specifically, to utilize multiple sources effectively, we propose a multi-source selection based manifold discriminant alignment (MSMDA) approach. To protect the privacy of data owners, a sparse representation based double obfuscation algorithm is designed and applied to HDP. Through a case study of 28 projects, our results show that MSMDA can achieve better performance than a range of baseline methods. The improvement is 3.4-15.3 percent in g-measure and 3.0-19.1 percent in AUG.",1939-3520,,10.1109/TSE.2017.2780222,General Technology Fundamental Research United Fund; National Key Research and Development Program of China; National Natural Science Foundation of China; Science and Technology Program in Henan province; Science and Technique Development Program of Henan; Province-School-Region Project of Henan University; Research Foundation of Henan University; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168387,Heterogeneous defect prediction;multiple sources;privacy preservation;utility;source selection;manifold discriminant alignment,Measurement;Software;Data privacy;Privacy;Predictive models;Training data;Companies,data privacy;learning (artificial intelligence);software metrics,defect-proneness;target project;heterogeneous metric data;HDP methods;HDP performance;external sources;data owners;multisource selection;privacy preservation issues;heterogeneous defect prediction;efficiency 3.4 percent to 15.3 percent;efficiency 3.0 percent to 19.1 percent,,16.0,,101.0,,6 Dec 2017,,,IEEE,IEEE Journals
2001,641,What is Discussed about Blockchain? A Case Study on the Use of Balanced LDA and the Reference Architecture of a Domain to Capture Online Discussions about Blockchain platforms across the Stack Exchange Communities,Z. Wan; X. Xia; A. E. Hassan,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: wanzhiyuan@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxkidd@zju.edu.cn); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Blockchain-related discussions have become increasingly prevalent in programming Q\&A websites, such as Stack Overflow and other Stack Exchange communities. Analyzing and understanding those discussions could provide insights about the topics of interest to practitioners, and help the software development and research communities better understand the needs and challenges facing developers as they work in this new domain. Prior studies propose the use of LDA to study the Stack Exchange discussions. However, a simplistic use of LDA would capture the topics in discussions blindly without keeping in mind the variety of the dataset and domain-specific concepts. Specifically, LDA is biased towards larger sized corpora; LDA-derived topics are not linked to higher level domain-specific concepts. We propose an approach that combines balanced LDA (which ensures that the topics are balanced across the domain) with the reference architecture of a domain to capture and compare topics of discussions across the Stack Exchange communities. We make a number of interesting observations, including: (1) Bitcoin, Ethereum, Hyperledger Fabric and Corda are the four most commonly-discussed blockchain platforms on the Stack Exchange communities; (2) A broad range of topics are discussed at distinct layers in our derived reference architecture. The consensus layer topics are most commonly discussed; (3) We observe an overall growth in the absolute impact for all architectural layer topics. The application layer topics have the greatest absolute impact over time in comparison to other layer topics; (4) Application layer, API layer, consensus layer and network layer topics are commonly discussed across the studied blockchain platforms. Based on our findings, we highlight future directions and provide recommendations for practitioners and researchers.",1939-3520,,10.1109/TSE.2019.2921343,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732384,Empirical Study;Reference Architecture;Blockchain;Stack Overflow;Stack Exchange,Blockchain;Peer-to-peer computing;Computer architecture;Smart contracts;Programming;Bitcoin,,,,4.0,,,,6 Jun 2019,,,IEEE,IEEE Early Access Articles
2002,642,Deep Transfer Bug Localization,X. Huo; F. Thung; M. Li; D. Lo; S. Shi,"Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: huox@lamda.nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore (e-mail: ferdiant.2013@phdis.smu.edu.sg); Nanjing University, Nantional key Lab for Novel Software Technology, Nanjing, Jiangsu China 210093 (e-mail: lim@nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: shist@lamda.nju.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Many projects often receive more bug reports than what they can handle. To help debug and close bug reports, a number of bug localization techniques have been proposed. These techniques analyze a bug report and return a ranked list of potentially buggy source code files. Recent development on bug localization has resulted in the construction of effective supervised approaches that use historical data of manually localized bugs to boost performance. Unfortunately, as highlighted by Zimmermann et al., sufficient bug data is often unavailable for many projects and companies. This raises the need for cross-project bug localization -- the use of data from a project to help locate bugs in another project. To fill this need, we propose a deep transfer learning approach for cross-project bug localization. Our proposed approach named TRANP-CNN extracts transferable semantic features from source project and fully exploits labeled data from target project for effective cross-project bug localization. We have evaluated TRANP-CNN on curated high-quality bug datasets and our experimental results show that TRANP-CNN can locate buggy files correctly at top 1, top 5, and top 10 positions for 29.9%, 51.7%, 61.3% of the bugs respectively, which significantly outperform state-of-the-art bug localization solution based on deep learning and several other advanced alternative solutions considering various standard evaluation metrics.",1939-3520,,10.1109/TSE.2019.2920771,National Key Research and Development Program; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736995,Cross-project bug localization;transfer learning;deep learning,Computer bugs;Feature extraction;Task analysis;Encoding;Computer languages;Semantics;Data models,,,,1.0,,,,14 Jun 2019,,,IEEE,IEEE Early Access Articles
2003,643,"The Good, the Bad and the Ugly: A Study of Security Decisions in a Cyber-Physical Systems Game",S. Frey; A. Rashid; P. Anthonysamy; M. Pinto-Albuquerque; S. A. Naqvi,"University of Southampton, Southampton, United Kingdom; University of Bristol, Bristol, United Kingdom; Google, Zurich, CH, Switzerland; Instituto Universita rio de Lisboa (ISCTE-IUL), Lisboa, Portugal; Lancaster University, Lancaster, United Kingdom",IEEE Transactions on Software Engineering,14 May 2019,2019,45,5,521,536,"Stakeholders' security decisions play a fundamental role in determining security requirements, yet, little is currently understood about how different stakeholder groups within an organisation approach security and the drivers and tacit biases underpinning their decisions. We studied and contrasted the security decisions of three demographics-security experts, computer scientists and managers-when playing a tabletop game that we designed and developed. The game tasks players with managing the security of a cyber-physical environment while facing various threats. Analysis of 12 groups of players (4 groups in each of our demographics) reveals strategies that repeat in particular demographics, e.g., managers and security experts generally favoring technological solutions over personnel training, which computer scientists preferred. Surprisingly, security experts were not ipso facto better players-in some cases, they made very questionable decisions-yet they showed a higher level of confidence in themselves. We classified players' decision-making processes, i.e., procedure-, experience-, scenario- or intuition-driven. We identified decision patterns, both good practices and typical errors and pitfalls. Our game provides a requirements sandbox in which players can experiment with security risks, learn about decision-making and its consequences, and reflect on their own perception of security.",1939-3520,,10.1109/TSE.2017.2782813,UK Engineering and Physical Science Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8194898,Security decisions;security requirements;game;decision patterns,Games;Data security;Cyber-physical systems;Decision making,computer games;cyber-physical systems;decision making;security of data,cyber-physical systems game;tabletop game;cyber-physical environment;decision patterns;security risks;decision-making,,1.0,,29.0,CCBY,13 Dec 2017,,,IEEE,IEEE Journals
2004,644,Automatic Detection and Repair Recommendation of Directive Defects in Java API Documentation,Y. Zhou; C. Wang; X. Yan; T. Chen; S. Panichella; H. Gall,"College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Computer Science and Information Systems, Birkbeck, University of London, Bloomsbury, London, United Kingdom; Department of Informatics, Zurich University of Applied Science, Winterthur, Switzerland; Department of Informatics, University of Zurich, Zurich, Switzerland",IEEE Transactions on Software Engineering,17 Sep 2020,2020,46,9,1004,1023,"Application Programming Interfaces (APIs) represent key tools for software developers to build complex software systems. However, several studies have revealed that even major API providers tend to have incomplete or inconsistent API documentation. This can severely hamper the API comprehension and, as a consequence, the quality of the software built on them. In this paper, we propose DRONE (Detect and Repair of dOcumentatioN dEfects), a framework to automatically detect and repair defects from API documents by leveraging techniques from program analysis, natural language processing, and constraint solving. Specifically, we target at the directives of API documents, which are related to parameter constraints and exception handling declarations. Furthermore, in presence of defects, we also provide a prototypical repair recommendation system. We evaluate our approach on parts of the well-documented APIs of JDK 1.8 APIs (including javaFX) and Android 7.0 (level 24). Across the two empirical studies, our approach can detect API defects with an average F-measure of 79.9, 71.7, and 81.4 percent, respectively. The API repairing capability has also been evaluated on the generated recommendations in a further experiment. User judgments indicate that the constraint information is addressed correctly and concisely in the rendered directives.",1939-3520,,10.1109/TSE.2018.2872971,National Key R&D Program of China; Collaborative Innovation Center of Novel Software Technology in China; UK EPSRC; ARC Discovery Project; National Natural Science Foundation of China; Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478004,API documentation;directive defects;natural language processing;repair recommendation,Documentation;Maintenance engineering;Software;Drones;Androids;Humanoid robots;Facebook,Android (operating system);application program interfaces;Java;natural language processing;software libraries;system documentation,application programming interfaces;software developers;complex software systems;API providers;incomplete API documentation;inconsistent API documentation;API comprehension;repair defects;API documents;program analysis;prototypical repair recommendation system;API repairing capability;automatic detection;directive defects;java API documentation;API defects;documentation defects;JDK 1.8 API;javaFX;Android 7.0,,,,72.0,IEEE,30 Sep 2018,,,IEEE,IEEE Journals
2005,645,Understanding and Detecting Fragmentation-Induced Compatibility Issues for Android Apps,L. Wei; Y. Liu; S. -C. Cheung; H. Huang; X. Lu; X. Liu,"Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Shenzhen Key Laboratory of Computational Intelligence, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China",IEEE Transactions on Software Engineering,11 Nov 2020,2020,46,11,1176,1199,"Android ecosystem is heavily fragmented. The numerous combinations of different device models and operating system versions make it impossible for Android app developers to exhaustively test their apps, and thus various compatibility issues arise. Unfortunately, little is known on the characteristics of such fragmentation-induced compatibility issues. No mature tools exist to help developers quickly diagnose and fix these issues. To bridge the gap, we conducted an empirical study on 220 real-world compatibility issues collected from five popular open-source Android apps. We further interviewed Android practitioners and conducted an online survey to gain insights from real practices. Via the studies, we characterized compatibility issues, investigated common practices to handle compatibility issues, and disclosed that these issues exhibit common patterns. With these findings, we propose a technique, FicFinder, to automatically detect compatibility issues in Android apps. FicFinder performs static code analysis based on a model that captures Android APIs as well as their associated context by which compatibility issues can be triggered. FicFinder reports actionable debugging information to developers when it detects potential issues. We evaluated FicFinder with 53 large-scale open-source Android apps. The results show that FicFinder can precisely detect compatibility issues in these apps and uncover previously-unknown issues.",1939-3520,,10.1109/TSE.2018.2876439,Hong Kong RGC/GRF; National Natural Science Foundation of China; Science and Technology Innovation Committee Foundation of Shenzhen; MSRA collaborative research fund; Hong Kong PhD Fellowship Scheme; Nvidia; Google; MSRA; National Key R&D Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493348,Mobile applications;android applications;android fragmentation;compatibility issues;empirical study;program analysis,Androids;Humanoid robots;Biological system modeling;Smart phones;Hardware;Testing;Ecosystems,Android (operating system);application program interfaces;mobile computing;program debugging;program diagnostics;smart phones,large-scale open-source Android apps;Android app developers;fragmentation-induced compatibility issues;FicFinder technique,,7.0,,106.0,IEEE,16 Oct 2018,,,IEEE,IEEE Journals
2006,646,A Systematic Evaluation of Static API-Misuse Detectors,S. Amann; H. A. Nguyen; S. Nadi; T. N. Nguyen; M. Mezini,"Technische Universität Darmstadt, Darmstadt, Germany; Iowa State University, Ames, IA, USA; University of Alberta, Edmonton, AB, Canada; University of Texas-Dallas, Richardson, TX, USA; Technische Universität Darmstadt, Darmstadt, Germany",IEEE Transactions on Software Engineering,10 Dec 2019,2019,45,12,1170,1188,"Application Programming Interfaces (APIs) often have usage constraints, such as restrictions on call order or call conditions. API misuses, i.e., violations of these constraints, may lead to software crashes, bugs, and vulnerabilities. Though researchers developed many API-misuse detectors over the last two decades, recent studies show that API misuses are still prevalent. Therefore, we need to understand the capabilities and limitations of existing detectors in order to advance the state of the art. In this paper, we present the first-ever qualitative and quantitative evaluation that compares static API-misuse detectors along the same dimensions, and with original author validation. To accomplish this, we develop MUC, a classification of API misuses, and MUBENCHPIPE, an automated benchmark for detector comparison, on top of our misuse dataset, MUBENCH. Our results show that the capabilities of existing detectors vary greatly and that existing detectors, though capable of detecting misuses, suffer from extremely low precision and recall. A systematic root-cause analysis reveals that, most importantly, detectors need to go beyond the naive assumption that a deviation from the most-frequent usage corresponds to a misuse and need to obtain additional usage examples to train their models. We present possible directions towards more-powerful API-misuse detectors.",1939-3520,,10.1109/TSE.2018.2827384,"German Federal Ministry of Education and Research; Hessen State Ministry for Higher Education, Research and the Arts; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338426,API-misuse detection;survey;misuse classification;benchmark;MUBench,Detectors;Benchmark testing;Classification;Systematics;Computer bugs,application program interfaces;failure analysis;program diagnostics;security of data,static API-misuse detectors;misuse dataset;MUBENCHPIPE benchmark;systematic root-cause analysis;MUBENCH dataset,,12.0,,53.0,IEEE,16 Apr 2018,,,IEEE,IEEE Journals
2007,647,Exploiting Natural Language Structures in Software Informal Documentation,A. Di Sorbo; S. Panichella; C. A. Visaggio; M. Di Penta; G. Canfora; H. C. Gall,"Department of Engineering, Universita degli Studi del Sannio, 18952 Benevento, Benevento Italy (e-mail: disorbo@unisannio.it); Department of Engineering, Zurcher Hochschule fur Angewandte Wissenschaften, 30944 Winterthur, Obere Kirchgasse 2 Switzerland (e-mail: spanichella@gmail.com); Research Centre on Software Technology, Univeristy of Sannio, Benevento, Italy Italy 82100 (e-mail: visaggio@unisannio.it); Dept. of Engineering, University of Sannio, Benevento, _ Italy 82100 (e-mail: dipenta@unisannio.it); Dept. of Engineering, University of Sannio, Benevento, BN Italy (e-mail: canfora@unisannio.it); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: gall@ifi.uzh.ch)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Communication means, such as issue trackers, mailing lists, Q&A forums, and app reviews, are premier means of collaboration among developers, and between developers and end-users. Analyzing such sources of information is crucial to build recommenders for developers, for example suggesting experts, re-documenting source code, or transforming user feedback in maintenance and evolution strategies for developers. To ease this analysis, in previous work we proposed DECA (Development Emails Content Analyzer), a tool based on Natural Language Parsing that classifies with high precision development emails' fragments according to their purpose. However, DECA has to be trained through a manual tagging of relevant patterns, which is often effort-intensive, error-prone and requires specific expertise in natural language parsing. In this paper, we first show, with a study involving Master's and Ph.D. students, the extent to which producing rules for identifying such patterns requires effort, depending on the nature and complexity of patterns. Then, we propose an approach, named NEON (Nlp-based softwarE dOcumentation aNalyzer), that automatically mines such rules, minimizing the manual effort. We assess the performances of NEON in the analysis and classification of mobile app reviews, developers discussions, and issues. NEON simplifies the patterns' identification and rules' definition processes, allowing a savings of more than 70% of the time otherwise spent on performing such activities manually. Results also show that NEON-generated rules are close to the manually identified ones, achieving comparable recall.",1939-3520,,10.1109/TSE.2019.2930519,Schweizerischer Nationalfonds zur Furderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769918,Mining Unstructured Data;Natural Language Processing;Empirical Study,Neon;Software;Linguistics;Pattern recognition;Documentation;Manuals,,,,,,,,23 Jul 2019,,,IEEE,IEEE Early Access Articles
2008,648,Automatic Repair of Timestamp Comparisons,G. Liva; M. T. Khan; M. Pinzger; F. Spegni; L. Spalazzi,"Institute of Informatics Systems, Alpen-Adria-Universitat Klagenfurt, 27256 Klagenfurt, Carinthia Austria (e-mail: giovanni.liva@aau.at); Computing and Information Systems, University of Greenwich, 4918 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: m.t.khan@surrey.ac.uk); Institute of Informatics Systems, Alpen-Adria-Universitat Klagenfurt, 27256 Klagenfurt, Carinthia Austria (e-mail: martin.pinzger@aau.at); Ingegneria dell'Informazione, Universita Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: f.spegni@univpm.it); Ingegneria dell'Informazione, Universita Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: l.spalazzi@univpm.it)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Automated program repair has the potential to reduce the developers' effort to fix errors in their code. In particular, modern programming languages, such as Java, C, and C\#, represent time as integer variables that suffer from integer overflow, introducing subtle errors that are hard to discover and repair. Recent researches on automated program repair rely on test cases to discover failures to correct, making them suitable only for regression errors. We propose a new strategy to automatically repair programs that suffer from timestamp overflows that are manifested in comparison expressions. It unifies the benefits of static analysis and automatic program repair avoiding dependency on testing to identify and correct defected code. Our approach performs an abstract analysis over the time domain of a program using a Time Type System to identify the problematic comparison expressions. The repairing strategy rewrites the timestamp comparisons exploiting the binary representation of machine numbers to correct the code. We have validated the applicability of our approach with 20 open source Java projects. The results show that it is able to correctly repair all 246 identified errors. To further validate the reliability of our approach, we have proved the soundness of both, type system and repairing strategy. Furthermore, several patches for three open source projects have been acknowledged and accepted by their developers.",1939-3520,,10.1109/TSE.2019.2948351,Osterreichische Forschungsforderungsgesellschaft; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877769,Software/Program Verification;Formal methods;Error handling and recovery,Maintenance engineering;Java;Semantics;Static analysis;Software;Testing,,,,,,,,21 Oct 2019,,,IEEE,IEEE Early Access Articles
2009,649,A Longitudinal Study of Application Structure and Behaviors in Android,H. Cai; B. G. Ryder,"School of Electrical Engineering and Computer Science, Washington State University, 6760 Pullman, Washington United States (e-mail: chapering@gmail.com); Computer Science, Virginia Polytechnic Institute and State University, 1757 Blacksburg, Virginia United States (e-mail: ryder@cs.vt.edu)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"With the rise of the mobile computing market, Android has received tremendous attention from both academia and industry. Application programming in Android is known to have unique characteristics, and Android apps be particularly vulnerable to various security attacks. In response, numerous solutions for particular security issues have been proposed. However, there is little broad understanding about Android app code structure and behaviors along with their implications for app analysis and security defense, especially in an evolutionary perspective. To mitigate this gap, we present a longitudinal characterization study of Android apps to systematically investigate how they are built and execute over time. Through lightweight static analysis and method-level tracing, we examined the code and execution of 17,664 apps sampled from the apps developed in each of eight past years, with respect to metrics in three complementary dimensions. Our study revealed that (1) apps functionalities heavily rely on the Android framework/SDK, and the reliance continues to grow, (2) Activity components constantly dominated over other types of components and were responsible for the invocation of most lifecycle callbacks, (3) event-handling callbacks consistently focused more on user-interface events than system events, (4) the overall use of callbacks has been slowly diminishing over time, (5) the majority of exercised inter-component communications (ICCs) did not carry any data payloads, and (6) sensitive data sources and sinks targeted only one/two dominant categories of information or operations, and the ranking of source/sink categories remained quite stable throughout the eight years. We discuss the implications of our empirical findings for cost-effective app analysis and security defense for Android, and make cost-effectiveness improvement recommendations accordingly.",1939-3520,,10.1109/TSE.2020.2975176,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003217,Android;code structure;app behavior;longitudinal study;evolution;app analysis;security;ICC,Androids;Humanoid robots;Security;Runtime;Measurement;Libraries;Lenses,,,,2.0,,,,19 Feb 2020,,,IEEE,IEEE Early Access Articles
2010,650,Enabling Good Work Habits in Software Developers through Reflective Goal-Setting,A. N. Meyer; G. C. Murphy; T. Zimmermann; T. Fritz,"Department of Informatics, University of Zurich, Zurich, ZH Switzerland 8050 (e-mail: ameyer@ifi.uzh.ch); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: fritz@ifi.uzh.ch)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Software developers are generally interested in developing better habits to increase their workplace productivity and well-being, but have difficulties identifying concrete goals and actionable strategies to do so. In several areas of life, such as the physical activity and health domain, self-reflection has been shown to be successful at increasing people's awareness about a problematic behavior, motivating them to define a self-improvement goal, and fostering goal-achievement. We therefore designed a reflective goal-setting study to learn more about developers' goals and strategies to improve or maintain good habits at work. In our study, 52 professional software developers self-reflected about their work on a daily basis during two to three weeks, which resulted in a rich set of work habit goals and actionable strategies that developers pursue at work. We also found that purposeful, continuous self-reflection not only increases developers' awareness about productive and unproductive work habits (84.5%), but also leads to positive self-improvements that increase developer productivity and well-being (79.6%). We discuss how tools could support developers with a better trade-off between the cost and value of workplace self-reflection and increase long-term engagement.",1939-3520,,10.1109/TSE.2019.2938525,Schweizerischer Nationalfonds zur Furderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823032,Productivity;Work Habits;Goals;Self-Reflection;Reflective Goal-Setting;Personal Analytics;Workplace Awareness,Productivity;Software;Employment;Task analysis;Tools;Informatics;Monitoring,,,,2.0,,,,3 Sep 2019,,,IEEE,IEEE Early Access Articles
2011,651,Restore: Retrospective Fault Localization Enhancing Automated Program Repair,T. Xu; L. Chen; Y. Pei; T. Zhang; M. Pan; C. A. Furia,"State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: dz1633014@smail.nju.edu.cn); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: cslschen@comp.polyu.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: maximilian.pei@gmail.com); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: ztluck@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: mxp@nju.edu.cn); Computer Science and Engineering, Chalmers tekniska hogskola, 11248 Goteborg, Vastra Gotaland Sweden 412 96 (e-mail: furiac@usi.ch)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Fault localization is a crucial step of automated program repair, because accurately identifying program locations that are most closely implicated with a fault greatly affects the effectiveness of the patching process. An ideal fault localization technique would provide precise information while requiring moderate computational resources—to best support an efficient search for correct fixes. In contrast, most automated program repair tools use standard fault localization techniques—which are not tightly integrated with the overall program repair process, and hence deliver only subpar efficiency. In this paper, we present retrospective fault localization: a novel fault localization technique geared to the requirements of automated program repair. A key idea of retrospective fault localization is to reuse the outcome of failed patch validation to support mutation-based dynamic analysis—providing accurate fault localization information without incurring onerous computational costs. We implemented retrospective fault localization in a tool called RESTORE—based on the JAID Java program repair system. Experiments involving faults from the DEFECTS4J standard benchmark indicate that retrospective fault localization can boost automated program repair: RESTORE efficiently explores a large fix space, delivering state-of-the-art effectiveness (41 DEFECTS4J bugs correctly fixed, 8 of which no other automated repair tool for Java can fix) while simultaneously boosting performance (speedup over 3 compared to JAID). Retrospective fault localization is applicable to any automated program repair techniques that rely on fault localization and dynamic validation of patches.",1939-3520,,10.1109/TSE.2020.2987862,the Hong Kong Polytechnic University Internal Fund; Research Grants Council University Grants Committee; National Natural Science Foundation of China; Fundamental Research Research Funds for The Central Universities; Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068412,,Maintenance engineering;Tools;Java;Computer bugs;Software;Standards;Electronic mail,,,,,,,,15 Apr 2020,,,IEEE,IEEE Early Access Articles
2012,652,The impact of surface features on choice of (in)secure answers by Stackoverflow readers,D. van der Linden; E. Williams; J. Hallett; A. Rashid,"Department of Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: djt.vanderlinden@gmail.com); School of Psychological Sciences, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: emma.williams@bristol.ac.uk); Department of Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: joseph.hallett@bristol.ac.uk); Department of Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: awais.rashid@bristol.ac.uk)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Existing research has shown that developers will use StackOverflow to answer programming questions: but what draws them to one particular answer over any other? The choice of answer they select can mean the difference between a secure application and insecure one, as the quality of supposedly secure answers can vary. Prior work has studied people posting on Stack Overflow—a two-way communication between the original poster and the Stack Overflow community. Instead, we study the situation of one-way communication, where people only read a Stack Overflow thread without being actively involved in it, sometimes long after a thread has closed. We report on a mixed-method study including a controlled between-groups experiment and qualitative analysis of participants' rationale (N=1188), investigating whether explanation detail, answer scoring, accepted answer marks, as well as the security of the code snippet itself affect the answers participants accept. Our findings indicate that explanation detail affects what answers participants reading a thread select (p<0.01), while answer score and acceptance do not (p>0.05)—the inverse of what research has shown for those asking and answering questions. The qualitative analysis of participants' rationale further explains how several cognitive biases underpin these findings. Correspondence bias, in particular, plays an important role in instilling readers with a false sense of confidence in an answer through the way it looks, regardless of whether it works, is secure, or if the community agrees with it. As a result, we argue that StackOverflow's use as a knowledge base by people not actively involved in threads'when there is only one-way-communication—may inadvertently contribute to the spread of insecure code, as the community's voting mechanisms hold little power to deter them from answers.",1939-3520,,10.1109/TSE.2020.2981317,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072521,Software Security;Stack Overflow;Human Factors;Rationale,Security;Semantics;Software;Documentation;Knowledge based systems;Message systems;Licenses,,,,,,,CCBY,20 Apr 2020,,,IEEE,IEEE Early Access Articles
2013,653,Test Case Generation for Boolean Expressions by Cell Covering,L. Yu; W. Tsai,"School of Software and Microelectronics in Peking University, Beijing, China; Beihang University, Beijing, China",IEEE Transactions on Software Engineering,10 Jan 2018,2018,44,1,70,99,"This paper characterizes Boolean expression faults as changes of the topological structures in terms of shrinking and/or expanding regions in K-map. A cell-covering is a set of cells (test cases) in K-map to cover the fault regions such that faults guarantee to be detected. Minimizing cell covering can be formulated as an Integer Linear Programming (ILP) problem. By analyzing the structures of the constraint coefficient matrix, the original problem can be decomposed into sub-programs that can be solved instead of the original problem, and this significantly reduces the time needed for ILP execution. An efficient approximate algorithm with a tight theoretical bound is used to address those complex Boolean expressions by corresponding the cell-covering problem to the set-covering problem. The optimal approach and the approximate approach are combined into a hybrid process to identify test cases based on the fraction analysis on the ILP relaxation. The proposed approach is evaluated by three sets of Boolean expressions and the results are compared with three leading approaches with respect to test sizes, time consumption and fault detection capabilities. For most Boolean expressions encountered, the proposed approach obtains optimal solutions quickly, and produces near-optimal solutions rapidly for those rare and complex expressions.",1939-3520,,10.1109/TSE.2017.2669184,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7855791,Boolean expression testing;fault characterization;cell-covering problem;approximate algorithms,Fault detection;Approximation algorithms;Optimization;Periodic structures;Algorithm design and analysis;Testing;Software,approximation theory;Boolean functions;computational complexity;fault diagnosis;integer programming;linear programming;set theory,test case generation;Boolean expression faults;topological structures;cell-covering;complex Boolean expressions;set-covering problem;fault detection capabilities;complex expressions;integer linear programming problem;cell covering minimization,,1.0,,51.0,,14 Feb 2017,,,IEEE,IEEE Journals
2014,654,The Impact of Changes Mislabeled by SZZ on Just-in-Time Defect Prediction,Y. Fan; X. Xia; D. Alencar da Costa; D. Lo; A. E. Hassan; S. Li,"College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: yrfan@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxkidd@zju.edu.cn); Information Science Department, University of Otago, 2495 Dunedin, Dunedin New Zealand (e-mail: daniel.calencar@gmail.com); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: shan@zju.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Just-in-Time (JIT) defect prediction---a technique which aims to predict bugs at change level---has been paid more attention. JIT defect prediction leverages the SZZ approach to identify bug-introducing changes. Recently, researchers found that the performance of SZZ (including its variants) is impacted by many noises. SZZ may considerably mislabel changes that are used to train a JIT defect prediction model, and thus impact the prediction accuracy.",1939-3520,,10.1109/TSE.2019.2929761,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765743,Just-in-Time Defect Prediction;SZZ;Noisy Data;Mining Software Repositories,Predictive models;Data models;Computer bugs;Measurement;Inspection;Analytical models;Testing,,,,3.0,,,,18 Jul 2019,,,IEEE,IEEE Early Access Articles
2015,655,Inductive Validity Cores,E. Ghassabani; M. Whalen; A. Gacek; M. Heimdahl,"Department of Computer Science & Engineering, University of Minnesota, MN, USA; Department of Computer Science & Engineering, University of Minnesota, MN, USA; Rockwell Collins, Advanced Technology Center, Cedar Rapids, IA, USA; Department of Computer Science & Engineering, University of Minnesota, MN, USA",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,279,299,"Symbolic model checkers can construct proofs of properties over highly complex models. However, the results reported by the tool when a proof succeeds do not generally provide much insight to the user. It is often useful for users to have traceability information related to the proof: which portions of the model were necessary to construct it. This traceability information can be used to diagnose a variety of modeling problems such as overconstrained axioms and underconstrained properties, measure completeness of a set of requirements over a model, and assist with design optimization given a set of requirements for an existing or synthesized implementation. In this paper, we present a comprehensive treatment of a suite of algorithms to compute inductive validity cores (IVCs), minimal sets of model elements necessary to construct inductive proofs of safety properties for sequential systems. The algorithms are based on the UNSAT core support built into current SMT solvers and novel encodings of the inductive problem to generate approximate and guaranteed minimal inductive validity cores as well as all inductive validity cores. We demonstrate that our algorithms are correct, describe their implementation in the JKind model checker for Lustre models, and present several use cases for the algorithms. We then present a substantial experiment in which we benchmark the efficiency and efficacy of the algorithms.",1939-3520,,10.1109/TSE.2019.2891709,DARPA Systems of Systems Integration Technology and Experimentation; NASA Compositional Verification of Flight-Critical Systems; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606278,Inductive validity cores;SMT-based model checking;requirements analysis;proof explanation,Computational modeling;Analytical models;Tools;Safety;Mathematical model;Approximation algorithms;Model checking,approximation theory;computability;encoding;formal verification;optimisation;program verification,modeling problems;underconstrained properties;minimal sets;model elements;inductive proofs;safety properties;UNSAT core support;inductive problem;minimal inductive validity cores;JKind model checker;Lustre models;symbolic model checkers;highly complex models;traceability information,,,,95.0,IEEE,9 Jan 2019,,,IEEE,IEEE Journals
2016,656,Explaining Regressions via Alignment Slicing and Mending,H. Wang; Y. Lin; Z. Yang; J. Sun; Y. Liu; J. S. Dong; Q. Zheng; T. Liu,"Ant Financial Services Group, Singapore, Singapore (e-mail: haijun.wang@ntu.edu.sg); School of Computing, National University of Singapore, Singapore, Singapore Singapore 520164 (e-mail: llmhyy@gmail.com); Computer Science, Western Michigan University, Kalamazoo, Michigan United States 49008 (e-mail: zijiang.yang@wmich.edu); School of Information System, Singapore Management University, 54756 Singapore, Singapore Singapore (e-mail: sunjun@sutd.edu.sg); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: yangliu@ntu.edu.sg); CS, National University of Singapore, Singapore, S Singapore 117543 (e-mail: dongjs@comp.nus.edu.sg); computer science and technology, Xi'an Jiaotong University, Xi'an, Shaanxi China 710049 (e-mail: qhzheng@mail.xjtu.edu.cn); Control, System Engineering Institute, Xi'an, Shaanxi China 710049 (e-mail: tingliu@mail.xjtu.edu.cn)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Regression faults, which make working code stop functioning, are often introduced when developers make changes to the software. Many regression fault localization techniques have been proposed. However, issues like inaccuracy and lack of explanation are still obstacles for their practical application. In this work, we propose a trace-based approach to identifying not only where the root cause of a regression bug lies, but also how the defect is propagated to its manifestation as the explanation. In our approach, we keep the trace of original correct version as reference and infer the faulty steps on the trace of regression version so that we can build a causality graph of how the defect is propagated. To this end, we overcomes two technical challenges. First, we align two traces derived from two versions of programs by extending state-of-the-art trace alignment technique for regression fault with novel relaxation technique. Second, we construct causality graph (i.e., explanation) by adopting a technique called alignment slicing and mending to isolate the failure-inducing changes and explain the failure. Our comparative experiment with the state-of-the-art techniques including dynamic slicing, delta-debugging, and symbolic execution on 24 real-world regressions shows that (1) our approach is more accurate on isolating the failure-inducing changes, (2) the generated explanation requires acceptable manual effort to inspect, and (3) our approach requires lower runtime overhead. In addition, we also conduct an applicability experiment based on Defects4J bug repository, showing the potential limitations of our trace-based approach and providing guidance for its practical use.",1939-3520,,10.1109/TSE.2019.2949568,National Natural Science Foundation of China; the National Cybersecurity R D Directorate; the Singapore Ministry of Education Academic Research Fund Tier 2 Grant; National Key R D Program of China; Singapore Telecommunications Limited; the National Research Foundation Prime Ministers Office Singapore under its Corporate Laboratory University Scheme National University of Singapore and under its National Cybersecurity RD Program; the National Satellite of Excellence in Trustworthy Software Systems funded by NRF Singapore under National Cyber-security R D programme; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883062,Regression bug;trace alignment;alignment slicing and mending;fault localization,Computer bugs;Semantics;Debugging;Java;Software;Runtime;Task analysis,,,,2.0,,,,25 Oct 2019,,,IEEE,IEEE Early Access Articles
2017,657,An Empirical Study of Fault Localization Families and Their Combinations,D. Zou; J. Liang; Y. Xiong; M. D. Ernst; L. Zhang,"School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; Department of Computer Science & Engineering, University of Washington, Seattle, WA, USA; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,332,347,"The performance of fault localization techniques is critical to their adoption in practice. This paper reports on an empirical study of a wide range of fault localization techniques on real-world faults. Different from previous studies, this paper (1) considers a wide range of techniques from different families, (2) combines different techniques, and (3) considers the execution time of different techniques. Our results reveal that a combined technique significantly outperforms any individual technique (200 percent increase in faults localized in Top 1), suggesting that combination may be a desirable way to apply fault localization techniques and that future techniques should also be evaluated in the combined setting. Our implementation is publicly available for evaluating and combining fault localization techniques.",1939-3520,,10.1109/TSE.2019.2892102,National Key Research and Development Program of China; National Natural Science Foundation of China; Air Force Research Laboratory; DARPA of the U.S.A.; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607117,Fault localization;learning to rank;program debugging;software testing;empirical study,Switches;Debugging;Software;Fault diagnosis;Task analysis;Computer bugs;History,fault diagnosis;program debugging;program testing;software fault tolerance,software testing;program debugging;fault localization families,,26.0,,79.0,IEEE,10 Jan 2019,,,IEEE,IEEE Journals
2018,658,Evolving JavaScript code to reduce load time,F. Farzat; M. O. Barros; G. H. Travassos,"Computer Science, COPPE/UFRJ, Rio de Janeiro, RJ Brazil (e-mail: ffarzat@cos.ufrj.br); DIA, UNIRIO, Rio de Janeiro, Rio de Janeiro Brazil 22290-240 (e-mail: marcio.barros@uniriotec.br); Computer Science, COPPE/UFRJ, Rio de Janeiro, Rio de Janeiro Brazil 21942-970 (e-mail: ght@cos.ufrj.br)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"JavaScript is one of the most used programming languages for front-end development of Web applications. The increase in complexity of front-end features brings concerns about performance, especially the load and execution time of JavaScript code. In this paper, we propose an evolutionary program improvement technique to reduce the size of JavaScript programs and, therefore, the time required to load and execute them in Web applications. To guide the development of such technique, we performed an experimental study to characterize the patches applied to JavaScript programs to reduce their size while keeping the functionality required to pass all test cases in their test suites. We applied this technique to 19 JavaScript programs varying from 92 to 15,602 LOC and observed reductions from 0.2% to 73.8% of the original code, as well as a relationship between the quality of a program's test suite and the ability to reduce the size of its source code.",1939-3520,,10.1109/TSE.2019.2928293,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762190,JavaScript;source code improvement;genetic programming;local search,Software;Syntactics;Genetic programming;Software algorithms;Heuristic algorithms;Libraries;Runtime,,,,1.0,,,,15 Jul 2019,,,IEEE,IEEE Early Access Articles
2019,659,Ensuring the Observability of Structural Test Obligations,Y. Meng; G. Gay; M. Whalen,"Department of Computer Science & Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science & Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA",IEEE Transactions on Software Engineering,15 Jul 2020,2020,46,7,748,772,"Test adequacy criteria are widely used to guide test creation. However, many of these criteria are sensitive to statement structure or the choice of test oracle. This is because such criteria ensure that execution reaches the element of interest, but impose no constraints on the execution path after this point. We are not guaranteed to observe a failure just because a fault is triggered. To address this issue, we have proposed the concept of observability-an extension to coverage criteria based on Boolean expressions that combines the obligations of a host criterion with an additional path condition that increases the likelihood that a fault encountered will propagate to a monitored variable. Our study, conducted over five industrial systems and an additional forty open-source systems, has revealed that adding observability tends to improve efficacy over satisfaction of the traditional criteria, with average improvements of 125.98 percent in mutation detection with the common output-only test oracle and per-model improvements of up to 1760.52 percent. Ultimately, there is merit to our hypothesis-observability reduces sensitivity to the choice of oracle and to the program structure.",1939-3520,,10.1109/TSE.2018.2869146,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456606,Software testing;automated test generation;test adequacy criteria;model-based test generation,Observability;Test pattern generators;Monitoring;Sensitivity;Software;Complexity theory,program testing;public domain software,structural test obligations;test adequacy criteria;test creation;statement structure;execution path;observability;coverage criteria;Boolean expressions;host criterion;path condition;industrial systems;program structure;open-source systems;mutation detection;onput-only test oracle,,,,77.0,IEEE,6 Sep 2018,,,IEEE,IEEE Journals
2020,660,IntRepair: Informed Repairing of Integer Overflows,P. Muntean; M. Monperrus; H. Sun; J. Grossklags; C. Eckert,"Department of Informatics, Technical University of Munich, 85748 Garching near Munich, Bavaria, Germany (e-mail: paul.muntean@sec.in.tum.de); Department of Computer Science, KTH Royal Institute of Technology, Sweden, 10044 Stockholm, Sweden (e-mail: martin.monperrus@csc.kth.se); Department of Computer Science and Technology, Nanjing University, Xianlin Campus Mailbox 603, Nanjing 210023, China (email: shqking@gmail.com); Department of Informatics, Technical University of Munich, 85748 Garching near Munich, Bavaria, Germany (e-mail: jens.grossklags@in.tum.de); Department of Informatics, Technical University of Munich, 85748 Garching near Munich, Bavaria, Germany (e-mail: claudia.eckert@sec.in.tum.de)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Integer overflows have threatened software applications for decades. Thus, in this paper, we propose a novel technique to provide automatic repairs of integer overflows in C source code. Our technique, based on static symbolic execution, fuses detection, repair generation and validation. This technique is implemented in a prototype named IntRepair. We applied IntRepair to 2,052 C programs (approx. 1 million lines of code) contained in SAMATE's Juliet test suite and 50 synthesized programs that range up to 20 KLOC. Our experimental results show that IntRepair is able to effectively detect integer overflows and successfully repair them, while only increasing the source code (LOC) and binary (Kb) size by around 1%, respectively. Furthermore, we present the results of a user study with 30 participants showing that IntRepair repairs are more efficient than manual repairs.",1939-3520,,10.1109/TSE.2019.2946148,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862860,Program repair;source code refactoring;integer overflow;software bug;symbolic execution;static program analysis,Maintenance engineering;Software;Tools;Fault detection;Runtime;Engines;Fuses,,,,1.0,,,,8 Oct 2019,,,IEEE,IEEE Early Access Articles
2021,661,Generic Adaptive Scheduling for Efficient Context Inconsistency Detection,H. Wang; C. Xu; B. Guo; X. Ma; J. Lu,"State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China",IEEE Transactions on Software Engineering,15 Mar 2021,2021,47,3,464,497,"Many applications use contexts to understand their environments and make adaptation. However, contexts are often inaccurate or even conflicting with each other (a.k.a. context inconsistency). To prevent applications from behaving abnormally or even failing, one promising approach is to deploy constraint checking to detect context inconsistencies. A variety of constraint checking techniques have been proposed, based on different incremental or parallel mechanisms for the efficiency. They are commonly deployed with the strategy that schedules constraint checking immediately upon context changes. This assures no missed inconsistency, but also limits the detection efficiency. One may break the limit by grouping context changes for checking together, but this can cause severe inconsistency missing problem (up to 79.2 percent). In this article, we propose a novel strategy GEAS to isolate latent interferences among context changes and schedule constraint checking with adaptive group sizes. This makes GEAS not only improve the detection efficiency, but also assure no missed inconsistency with theoretical guarantee. We experimentally evaluated GEAS with large-volume real-world context data. The results show that GEAS achieved significant efficiency gains for context inconsistency detection by 38.8-566.7 percent (or 1.4x-6.7x). When enhanced with an extended change-cancellation optimization, the gains were up to 2,755.9 percent (or 28.6x).",1939-3520,,10.1109/TSE.2019.2898976,National Key Research and Development Program of China; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8640044,Context inconsistency detection;consistency constraint;scheduling strategy;susceptibility/cancellation condition,Unified modeling language;Software;Public transportation;Schedules;Adaptive scheduling;XML,optimisation;scheduling;ubiquitous computing,inconsistency missing problem;context inconsistency detection;adaptive group;schedule constraint checking;parallel mechanisms;different incremental mechanisms;constraint checking techniques;generic adaptive scheduling;real-world context data;GEAS,,1.0,,75.0,IEEE,12 Feb 2019,,,IEEE,IEEE Journals
2022,662,Understanding How and Why Developers Seek and Analyze API-Related Opinions,G. Uddin; O. Baysal; L. Guerrouj; F. Khomh,"Bank of Canada, Ottawa, ON, Canada; School of Computer Science, Carleton University, Ottawa, ON, Canada; Département LOG et TI, École de Technologie Supérieure, Montreal, QC, Canada; SWAT Lab, Polytechnique Montreal, Montreal, QC, Canada",IEEE Transactions on Software Engineering,16 Apr 2021,2021,47,4,694,735,"With the advent and proliferation of online developer forums as informal documentation, developers often share their opinions about the APIs they use. Thus, opinions of others often shape the developer’s perception and decisions related to software development. For example, the choice of an API or how to reuse the functionality the API offers are, to a considerable degree, conditioned upon what other developers think about the API. While many developers refer to and rely on such opinion-rich information about APIs, we found little research that investigates the use and benefits of public opinions. To understand how developers seek and evaluate API opinions, we conducted two surveys involving a total of 178 software developers. We analyzed the data in two dimensions, each corresponding to specific needs related to API reviews: (1) Needs for seeking API reviews, and (2) Needs for automated tool support to assess the reviews. We observed that developers seek API reviews and often have to summarize those for diverse development needs (e.g., API suitability). Developers also make conscious efforts to judge the trustworthiness of the provided opinions and believe that automated tool support for API reviews analysis can assist in diverse development scenarios, including, for example, saving time in API selection as well as making informed decisions on a particular API features.",1939-3520,,10.1109/TSE.2019.2903039,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658125,Opinion mining;API informal documentation;opinion summaries;survey;opinion quality;developer’s perception,Tools;Documentation;Task analysis;Java;Data mining;Open source software,,,,1.0,,113.0,IEEE,4 Mar 2019,,,IEEE,IEEE Journals
2023,663,Architecture Anti-Patterns: Automatically Detectable Violations of Design Principles,R. Mo; Y. Cai; R. Kazman; L. Xiao; Q. Feng,"Computer Science, Central China Normal University, Wuhan, Hubei, China; Computer Science, Drexel University, Philadelphia, PA, USA; Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii, USA; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Computer Science, Drexel University, Philadelphia, PA, USA",IEEE Transactions on Software Engineering,13 May 2021,2021,47,5,1008,1028,"In large-scale software systems, error-prone or change-prone files rarely stand alone. They are typically architecturally connected and their connections usually exhibit architecture problems causing the propagation of error-proneness or change-proneness. In this paper, we propose and empirically validate a suite of architecture anti-patterns that occur in all large-scale software systems and are involved in high maintenance costs. We define these architecture anti-patterns based on fundamental design principles and Baldwin and Clark’s design rule theory. We can automatically detect these anti-patterns by analyzing a project’s structural relationships and revision history. Through our analyses of 19 large-scale software projects, we demonstrate that these architecture anti-patterns have significant impact on files’ bug-proneness and change-proneness. In particular, we show that 1) files involved in these architecture anti-patterns are more error-prone and change-prone; 2) the more anti-patterns a file is involved in, the more error-prone and change-prone it is; and 3) while all of our defined architecture anti-patterns contribute to file’s error-proneness and change-proneness, Unstable Interface and Crossing contribute the most by far.",1939-3520,,10.1109/TSE.2019.2910856,National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691586,Software architecture;software maintenance;software quality,Computer architecture;Maintenance engineering;History;Software systems;Tools;Observers;Java,,,,5.0,,81.0,IEEE,14 Apr 2019,,,IEEE,IEEE Journals
2024,664,ElementRank: Ranking Java Software Classes and Packages using a Multilayer Complex Network-Based Approach,W. Pan; H. Ming; C. Chang; Z. Yang; D. Kim,"Computer Science and Information Engineering, Zhejiang Gongshang University, 12625 Hangzhou, Zhejiang China (e-mail: wfpan@zjgsu.edu.cn); Computer Science and Engineering, Oakland University, 6918 Rochester, Michigan United States 48309-4479 (e-mail: ming@oakland.edu); Computer Science, IOWA STATE UNIVERSITY, Ames, Iowa United States 50011 (e-mail: chang@iastate.edu); Computer Science, Western Michigan University, Kalamazoo, Michigan United States 49008 (e-mail: zijiang.yang@wmich.edu); Computer Science and Engineering, Oakland University, Rochester, Michigan United States 48309 (e-mail: kim2@oakland.edu)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Software comprehension is an important part of software maintenance. To understand a piece of large and complex software, the first problem to be solved is where to start the understanding process. Choosing to start the comprehension process from the important software elements has proven to be a practical way. Research on complex networks opens new opportunities for identifying important elements, and many approaches have been proposed. However, the software networks that existing approaches use neglect the multilayer nature of software systems. That is, nodes in the network can have different types of relationships at the same time, and each type of relationship forms a specific layer. Worse still, they mainly focus on identifying important classes, and little work has been done on quantifying package importance. In this paper, we propose an ElementRank approach to provide a ranked list of classes (or packages) for maintainers to start the comprehension process. The top-ranked classes (or packages) can be seen as the starting points for the software comprehension process at the class (or package) level. First, we introduce two kinds of multilayer software networks to describe the topological structure of software at the class level and package level, respectively. Second, we propose a weighted PageRank algorithm to calculate the weighted PageRank value of classes (or packages) in each layer of the corresponding multilayer software network. Then, we use AHP (Analytic Hierarchy Process) to weigh each layer in the corresponding multilayer software network, and further aggregate the weighted PageRank value to obtain the global weighted PageRank value for each class (or package). Finally, all the classes (or packages) are ranked according to their global weighted PageRank values in a descending order, and the top-ranked classes (or packages) can serve as the starting points for the software comprehension process at the class (or package) level. ElementRank is validated theoretically using the widely accepted Weyuker's criteria. Theoretical results show that the global weighted PageRank value for classes (or packages) satisfies most of Weyuker's properties. Furthermore, ElementRank is evaluated empirically using a set of twelve open source software systems. Through a set of experiments, we show the rank correlation between the results of ElementRank and that of the approaches in the related work, and the benefits of ElementRank are also illustrated in comparison with other approaches in the related work. Empirical results also show that ElementRank can be applied to large software systems.",1939-3520,,10.1109/TSE.2019.2946357,the Commonweal Project of Science and Technology Department of Zhejiang Province; National Key RD Program of China; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862895,Important software elements;weighted PageRank algorithm;complex network;software comprehension;static analysis,Software systems;Nonhomogeneous media;Complex networks;Maintenance engineering;Measurement;Computer science,,,,5.0,,,,8 Oct 2019,,,IEEE,IEEE Early Access Articles
2025,665,Use and Misuse of Continuous Integration Features: An Empirical Study of Projects That (Mis)Use Travis CI,K. Gallaba; S. McIntosh,"Department of Electrical and Computer Engineering, McGill University, Montreal, Quebec, Canada; Department of Electrical and Computer Engineering, McGill University, Montreal, Quebec, Canada",IEEE Transactions on Software Engineering,8 Jan 2020,2020,46,1,33,50,"Continuous Integration (CI) is a popular practice where software systems are automatically compiled and tested as changes appear in the version control system of a project. Like other software artifacts, CI specifications require maintenance effort. Although there are several service providers like TRAVIS CI offering various CI features, it is unclear which features are being (mis)used. In this paper, we present a study of feature use and misuse in 9,312 open source systems that use TRAVIS CI. Analysis of the features that are adopted by projects reveals that explicit deployment code is rare-48.16 percent of the studied TRAVIS CI specification code is instead associated with configuring job processing nodes. To analyze feature misuse, we propose HANSEL-an anti-pattern detection tool for TRAVIS CI specifications. We define four anti-patterns and HANSEL detects anti-patterns in the TRAVIS CI specifications of 894 projects in the corpus (9.60 percent), and achieves a recall of 82.76 percent in a sample of 100 projects. Furthermore, we propose GRETEL-an anti-pattern removal tool for TRAVIS CI specifications, which can remove 69.60 percent of the most frequently occurring antipattern automatically. Using GRETEL, we have produced 36 accepted pull requests that remove TRAVIS CI anti-patterns automatically.",1939-3520,,10.1109/TSE.2018.2838131,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360943,Continuous integration;anti-patterns;mining software repositories,Object oriented programming;Software development management;Software maintenance;Software quality;Software performance,object-oriented programming;program testing;software development management;software maintenance;software metrics;software performance evaluation;software quality,continuous Integration features;software systems;version control system;CI features;studied TRAVIS CI specification code;anti-pattern detection tool;CI anti-patterns;open source systems;efficiency 48.16 percent;efficiency 9.6 percent;efficiency 69.6 percent,,8.0,,32.0,IEEE,18 May 2018,,,IEEE,IEEE Journals
2026,666,Automatic Software Refactoring via Weighted Clustering in Method-Level Networks,Y. Wang; H. Yu; Z. Zhu; W. Zhang; Y. Zhao,"Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China",IEEE Transactions on Software Engineering,13 Mar 2018,2018,44,3,202,236,"In this study, we describe a system-level multiple refactoring algorithm, which can identify the move method, move field, and extract class refactoring opportunities automatically according to the principle of “high cohesion and low coupling.” The algorithm works by merging and splitting related classes to obtain the optimal functionality distribution from the system-level. Furthermore, we present a weighted clustering algorithm for regrouping the entities in a system based on merged method-level networks. Using a series of preprocessing steps and preconditions, the “bad smells” introduced by cohesion and coupling problems can be removed from both the non-inheritance and inheritance hierarchies without changing the code behaviors. We rank the refactoring suggestions based on the anticipated benefits that they bring to the system. Based on comparisons with related research and assessing the refactoring results using quality metrics and empirical evaluation, we show that the proposed approach performs well in different systems and is beneficial from the perspective of the original developers. Finally, an open source tool is implemented to support the proposed approach.",1939-3520,,10.1109/TSE.2017.2679752,"National Natural Science Foundation of China; MOE research center for online education, China; Ph.D. Start-up Foundation of Liaoning Province, China; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874207,Clustering analysis;cohesion;coupling;complex network;software refactoring,Couplings;Clustering algorithms;Software algorithms;Measurement;Software systems;Partitioning algorithms,network theory (graphs);pattern clustering;software maintenance;software quality,high cohesion;low coupling;merging classes;splitting related classes;optimal functionality distribution;weighted clustering algorithm;merged method-level networks;preprocessing steps;coupling problems;inheritance hierarchies;refactoring suggestions;refactoring results;automatic software refactoring;system-level multiple refactoring algorithm;class refactoring opportunities;open source tool,,3.0,,52.0,,8 Mar 2017,,,IEEE,IEEE Journals
2027,667,Changeset-Based Topic Modeling of Software Repositories,C. S. Corley; K. Damevski; N. A. Kraft,"Department of Computer Science, University of Alabama, Tuscaloosa, AL, USA; Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA; ABB Corporate Research, Raleigh, NC, USA",IEEE Transactions on Software Engineering,14 Oct 2020,2020,46,10,1068,1080,"The standard approach to applying text retrieval models to code repositories is to train models on documents representing program elements. However, code changes lead to model obsolescence and to the need to retrain the model from the latest snapshot. To address this, we previously introduced an approach that trains a model on documents representing changesets from a repository and demonstrated its feasibility for feature location. In this paper, we expand our work by investigating: a second task (developer identification), the effects of including different changeset parts in the model, the repository characteristics that affect the accuracy of our approach, and the effects of the time invariance assumption on evaluation results. Our results demonstrate that our approach is as accurate as the standard approach for projects with most changes localized to a subset of the code, but less accurate when changes are highly distributed throughout the code. Moreover, our results demonstrate that context and messages are key to the accuracy of changeset-based models and that the time invariance assumption has a statistically significant effect on evaluation results, providing overly-optimistic results. Our findings indicate that our approach is a suitable alternative to the standard approach, providing comparable accuracy while eliminating retraining costs.",1939-3520,,10.1109/TSE.2018.2874960,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486696,Changesets;feature location;developer identification;program comprehension;mining software repositories;online topic modeling,Task analysis;Standards;Feature extraction;Resource management;Software maintenance;Maintenance engineering,information retrieval;software packages;source code (software);text analysis,changeset-based topic modeling;software repositories;text retrieval models;code repositories;program elements;code changes;time invariance assumption;changeset-based models,,,,56.0,IEEE,9 Oct 2018,,,IEEE,IEEE Journals
2028,668,Towards Model Checking Android Applications,G. Bai; Q. Ye; Y. Wu; H. Botha; J. Sun; Y. Liu; J. S. Dong; W. Visser,"Singapore Institute of Technology, Singapore; National University of Singapore, Singapore; Huawei; Stellenbosch University, Stellenbosch, South Africa; Singapore University of Technology and Design, Singapore; Nanyang Technological University, Singapore; National University of Singapore, Singapore; Stellenbosch University, Stellenbosch, South Africa",IEEE Transactions on Software Engineering,12 Jun 2018,2018,44,6,595,612,"As feature-rich Android applications (apps for short) are increasingly popularized in security-sensitive scenarios, methods to verify their security properties are highly desirable. Existing approaches on verifying Android apps often have limited effectiveness. For instance, static analysis often suffers from a high false-positive rate, whereas approaches based on dynamic testing are limited in coverage. In this work, we propose an alternative approach, which is to apply the software model checking technique to verify Android apps. We have built a general framework named DroidPF upon Java PathFinder (JPF), towards model checking Android apps. In the framework, we craft an executable mock-up Android OS which enables JPF to dynamically explore the concrete state spaces of the tested apps; we construct programs to generate user interaction and environmental input so as to drive the dynamic execution of the apps; and we introduce Android specific reduction techniques to help alleviate the state space explosion. DroidPF focuses on common security vulnerabilities in Android apps including sensitive data leakage involving a non-trivial flow- and context-sensitive taint-style analysis. DroidPF has been evaluated with 131 apps, which include real-world apps, third-party libraries, malware samples and benchmarks for evaluating app analysis techniques like ours. DroidPF precisely identifies nearly all of the previously known security issues and nine previously unreported vulnerabilities/bugs.",1939-3520,,10.1109/TSE.2017.2697848,"Singapore NRF; NRF; National Research Foundation, Prime Ministers Office, Singapore; National Cybersecurity R&D Program; National Cybersecurity R&D Directorate; National University of Singapore and Singapore University of Technology and Design; ",https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7911333,Software model checking;security verification;android application,Androids;Humanoid robots;Model checking;Java;Security;Software;Libraries,Android (operating system);invasive software;Java;mobile computing;program diagnostics;program verification;public domain software,security properties;DroidPF;Android OS;tested apps;Android specific reduction techniques;context-sensitive taint-style analysis;real-world apps;app analysis techniques;feature-rich Android applications;security-sensitive scenarios;model checking;Android apps verification;Java PathFinder;concrete state spaces;user interaction;environmental input;dynamic execution;state space explosion;sensitive data leakage;nontrivial flow-style analysis;third-party libraries;malware samples,,5.0,,75.0,,25 Apr 2017,,,IEEE,IEEE Journals
2029,669,An Empirical Study on API Usages,H. Zhong; H. Mei,"Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China",IEEE Transactions on Software Engineering,16 Apr 2019,2019,45,4,319,334,"API libraries provide thousands of APIs, and are essential in daily programming tasks. To understand their usages, it has long been a hot research topic to mine specifications that formally define legal usages for APIs. Furthermore, researchers are working on many other research topics on APIs. Although the research on APIs is intensively studied, many fundamental questions on APIs are still open. For example, the answers to open questions, such as which format can naturally define API usages and in which case, are still largely unknown. We notice that many such open questions are not concerned with concrete usages of specific APIs, but usages that describe how to use different types of APIs. To explore these questions, in this paper, we conduct an empirical study on API usages, with an emphasis on how different types of APIs are used. Our empirical results lead to nine findings on API usages. For example, we find that single-type usages are mostly strict orders, but multi-type usages are more complicated since they include both strict orders and partial orders. Based on these findings, for the research on APIs, we provide our suggestions on the four key aspects such as the challenges, the importance of different API elements, usage patterns, and pitfalls in designing evaluations. Furthermore, we interpret our findings, and present our insights on data sources, extraction techniques, mining techniques, and formats of specifications for the research of mining specifications.",1939-3520,,10.1109/TSE.2017.2782280,National Key Basic Research Program of China; National Natural Science Foundation of China; Science and Technology Commission of Shanghai Municipality; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186224,API usage;mining specification;empirical study,Libraries;Data mining;Programming;Law;Tools;Concrete,application program interfaces;data mining,API usages;API libraries;open questions;single-type usages;multitype usages;API elements;specific API;mining specifications,,4.0,,94.0,,11 Dec 2017,,,IEEE,IEEE Journals
2030,670,How Do Static and Dynamic Test Case Prioritization Techniques Perform on Modern Software Systems? An Extensive Study on GitHub Projects,Q. Luo; K. Moran; L. Zhang; D. Poshyvanyk,"Department of Computer Science, College of William and Mary, Williamsburg, VA; Department of Computer Science, College of William and Mary, Williamsburg, VA; Department of Computer Science, University of Texas at Dallas, Dallas, TX; Department of Computer Science, College of William and Mary, Williamsburg, VA",IEEE Transactions on Software Engineering,12 Nov 2019,2019,45,11,1054,1080,"Test Case Prioritization (TCP) is an increasingly important regression testing technique for reordering test cases according to a pre-defined goal, particularly as agile practices gain adoption. To better understand these techniques, we perform the first extensive study aimed at empirically evaluating four static TCP techniques, comparing them with state-of-research dynamic TCP techniques across several quality metrics. This study was performed on 58 real-word Java programs encompassing 714 KLoC and results in several notable observations. First, our results across two effectiveness metrics (the Average Percentage of Faults Detected APFD and the cost cognizant APFDc) illustrate that at test-class granularity, these metrics tend to correlate, but this correlation does not hold at test-method granularity. Second, our analysis shows that static techniques can be surprisingly effective, particularly when measured by APFDc. Third, we found that TCP techniques tend to perform better on larger programs, but that program size does not affect comparative performance measures between techniques. Fourth, software evolution does not significantly impact comparative performance results between TCP techniques. Fifth, neither the number nor type of mutants utilized dramatically impact measures of TCP effectiveness under typical experimental settings. Finally, our similarity analysis illustrates that highly prioritized test cases tend to uncover dissimilar faults.",1939-3520,,10.1109/TSE.2018.2822270,NSF; NSF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329518,Regression testing;test case prioritization;static;dynamic;mutation analysis,Testing;Measurement;Computer bugs;Software systems;Java;Fault detection,fault diagnosis;Java;program testing;regression analysis,regression testing technique;static TCP techniques;dynamic TCP techniques;quality metrics;real-word Java programs;test-class granularity;test-method granularity;static techniques;TCP effectiveness;static test case prioritization techniques;dynamic test case prioritization techniques;software systems;GitHub projects,,2.0,,76.0,,2 Apr 2018,,,IEEE,IEEE Journals
2031,671,Specifying Callback Control Flow of Mobile Apps Using Finite Automata,D. D. Perez; W. Le,"Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA",IEEE Transactions on Software Engineering,11 Feb 2021,2021,47,2,379,392,"Given the event-driven and framework-based architecture of Android apps, finding the ordering of callbacks executed by the framework remains a problem that affects every tool that requires inter-callback reasoning. Previous work has focused on the ordering of callbacks related to the Android components and GUI events. But the execution of callbacks can also come from direct calls of the framework (API calls). This paper defines a novel program representation, called Callback Control Flow Automata (CCFA), that specifies the control flow of callbacks invoked via a variety of sources. We present an analysis to automatically construct CCFAs by combining two callback control flow representations developed from the previous research, namely, Window Transition Graphs (WTGs) and Predicate Callback Summaries (PCSs). To demonstrate the usefulness of our representation, we integrated CCFAs into two client analyses: a taint analysis using FLOWDROID, and a value-flow analysis that computes source and sink pairs of a program. Our evaluation shows that we can compute CCFAs efficiently and that CCFAs improved the callback coverages over WTGs. As a result of using CCFAs, we obtained 33 more true positive security leaks than FLOWDROID over a total of 55 apps we have run. With a low false positive rate, we found that 22.76 percent of source-sink pairs we computed are located in different callbacks and that 31 out of 55 apps contain source-sink pairs spreading across components. Thus, callback control flow graphs and inter-callback analysis are indeed important. Although this paper mainly uses Android, we believe that CCFAs can be useful for modeling control flow of callbacks for other event-driven, framework-based systems.",1939-3520,,10.1109/TSE.2019.2893207,Government of Panama; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613913,Event-driven;framework-based;callbacks;control flow;extended finite automata;android;mobile;program analysis;information flow,Tools;Automata;Microsoft Windows;Graphical user interfaces;Computer architecture;Static analysis;Cameras,Android (operating system);application program interfaces;data flow analysis;finite automata;graph theory;graphical user interfaces;mobile computing;program testing;program verification;security of data,true positive security;FLOWDROID;PCSs;WTGs;window transition graphs;predicate callback summaries;callback control flow automata;event-driven framework-based architecture;value-flow analysis;taint analysis;callback control flow representations;program representation;API calls;direct calls;GUI events;Android components;inter-callback reasoning;Android apps;finite automata;mobile apps;callback control flow graphs;source-sink pairs;CCFAs,,,,41.0,IEEE,16 Jan 2019,,,IEEE,IEEE Journals
2032,672,checsdm: A Method for Ensuring Consistency in Heterogeneous Safety-Critical System Design,A. Paz; G. El Boussaidi; M. Hafedh,"Département de génie logiciel et des TI, école de technologie supérieure, 14849 Montreal, Quebec Canada (e-mail: andres.paz-loboguerrero.1@ens.etsmtl.ca); Software and IT engineering, école de technologie supérieure, 14849 Montreal, Quebec Canada H3C 1K3 (e-mail: ghizlane.elboussaidi@etsmtl.ca); Département d'informatique, Université du Québec - Montréal, Montreal, Quebec Canada (e-mail: mili.hafedh@uqam.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Safety-critical systems are highly heterogeneous, combining different characteristics. Effectively designing such systems requires a complex modelling approach that deals with diverse components (e.g., mechanical, electronic, software)-each having its own underlying domain theories and vocabularies-as well as with various aspects of the same component (e.g., function, structure, behaviour). Furthermore, the regulated nature of such systems prescribes the objectives for their design verification and validation. This paper proposes checsdm, a systematic approach, based on Model-Driven Engineering (MDE), for assisting engineering teams in ensuring consistency of heterogeneous design of safety-critical systems. The approach is developed as a generic methodology and a tool framework, that can be applied to various design scenarios involving different modelling languages and different design guidelines. The methodology comprises an iterative three-phased process. The first phase, elicitation, aims at specifying requirements of the heterogeneous design scenario. Using the proposed tool framework, the second phase, codification, consists in building a particular tool set that supports the heterogeneous design scenario and helps engineers in flagging consistency errors for review and eventual correction. The third phase, operation, applies the tool set to actual system designs. Empirical evaluation of the work is presented through two executions of the checsdm approach for the specific cases of a design scenario involving a mix of UML, Simulink and Stateflow, and a design scenario involving a mix of AADL, Simulink and Stateflow. The operation phase of the first case was performed over three avionics systems and the identified inconsistencies in the design models of these systems were compared to the results of a fully manual verification carried out by professional engineers. The evaluation also includes an assessment workshop with industrial practitioners to examine their perceptions about the approach. The empirical validation indicates the feasibility and ""cost-effectiveness"" of the approach. Inconsistencies were identified in the three avionics systems with a greater recall rate over the manual verification. The assessment workshop shows the practitioners found the approach easy to understand and gave an overall likelihood of adoption within the context of their work.",1939-3520,,10.1109/TSE.2020.2966994,Natural Sciences and Engineering Research Council of Canada; Consortium for Research and Innovation in Aerospace in Quebec; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8960313,Model-Driven Engineering;safety-critical systems;heterogeneous design;consistency;design guidelines;DO-178C,Unified modeling language;Software packages;Tools;Object oriented modeling;Design methodology;Aerospace electronics;Gears,,,,,,,,15 Jan 2020,,,IEEE,IEEE Early Access Articles
2033,673,Effectively Incorporating Expert Knowledge in Automated Software Remodularisation,M. Hall; N. Walkinshaw; P. McMinn,"Department of Computer Science, University of Sheffield, Sheffield, United Kingdom; Department of Informatics, University of Leicester, Leicester, United Kingdom; Department of Computer Science, University of Sheffield, Sheffield, United Kingdom",IEEE Transactions on Software Engineering,16 Jul 2018,2018,44,7,613,630,"Remodularising the components of a software system is challenging: sound design principles (e.g., coupling and cohesion) need to be balanced against developer intuition of which entities conceptually belong together. Despite this, automated approaches to remodularisation tend to ignore domain knowledge, leading to results that can be nonsensical to developers. Nevertheless, suppling such knowledge is a potentially burdensome task to perform manually. A lot information may need to be specified, particularly for large systems. Addressing these concerns, we propose the SUpervised reMOdularisation (SUMO) approach. SUMO is a technique that aims to leverage a small subset of domain knowledge about a system to produce a remodularisation that will be acceptable to a developer. With SUMO, developers refine a modularisation by iteratively supplying corrections. These corrections constrain the type of remodularisation eventually required, enabling SUMO to dramatically reduce the solution space. This in turn reduces the amount of feedback the developer needs to supply. We perform a comprehensive systematic evaluation using 100 real world subject systems. Our results show that SUMO guarantees convergence on a target remodularisation with a tractable amount of user interaction.",1939-3520,,10.1109/TSE.2017.2786222,Engineering and Physical Sciences Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259332,Software remodularisation;domain knowledge;set partitioning,Clustering algorithms;Tools;Software algorithms;Software systems;Algorithm design and analysis,knowledge based systems;learning (artificial intelligence);reverse engineering;software maintenance,automated software remodularisation;domain knowledge;SUMO;target remodularisation;expert knowledge;supervised remodularisation approach,,1.0,,49.0,CCBY,15 Jan 2018,,,IEEE,IEEE Journals
2034,674,On the Semantics of Distributed Reactive Programming: The Cost of Consistency,A. Margara; G. Salvaneschi,"Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milan, Italy; Department of Computer Science, Technische Universität Darmstadt, Darmstadt, Germany",IEEE Transactions on Software Engineering,16 Jul 2018,2018,44,7,689,711,"The reactive programming paradigm aims to simplify the development of reactive systems. It provides abstractions to define time-changing values that are automatically updated by the runtime according to their dependencies. The benefits of reactive programming in distributed settings have been recognized for long. Yet, existing solutions for distributed reactive programming enforce the same semantics as in single processes, introducing communication and synchronization costs that hamper scalability. Establishing suitable abstractions for distributed reactive programming demands for a deeper investigation of the semantics of change propagation. This paper takes a foundational approach and defines precise propagation semantics in terms of consistency guarantees that constrain the order and isolation of value updates. We study the benefits and costs of these consistency guarantees both theoretically and empirically, using case studies and synthetic benchmarks. We show that different applications require different levels of consistency and that manually implementing the required level on a middleware that provides a lower one annuls the abstraction improvements of reactive programming. This motivates a framework that enables the developers to select the best trade-off between consistency and overhead for the problem at hand. To this end, we present DREAM, a distributed reactive programming middleware with flexible consistency guarantees.",1939-3520,,10.1109/TSE.2018.2833109,H2020 European Research Council; German Research Foundation (DFG); DFG; AWS Cloud Credits; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354906,Distributed reactive programming;consistency guarantees;reactive programming middleware;DREAM,Programming;Semantics;Artificial intelligence;Runtime;Middleware;Games;Computational modeling,middleware,synchronization costs;distributed reactive programming demands;foundational approach;value updates;distributed reactive programming middleware;flexible consistency guarantees;reactive programming paradigm;reactive systems;time-changing values;distributed settings,,4.0,,97.0,,4 May 2018,,,IEEE,IEEE Journals
2035,675,Comparative Analysis of Constraint Handling Techniques for Constrained Combinatorial Testing,H. Wu; N. Changhai; J. Petke; Y. Jia; M. Harman,"Computer Science and Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: hywu@nju.edu.cn); Computer Science and Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: changhainie@nju.edu.cn); CS, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: j.petke@ucl.ac.uk); CS, Facebook London, 507852 London, UK United Kingdom of Great Britain and Northern Ireland (e-mail: yue.jia@ucl.ac.uk); CS, Facebook London, 507852 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: mark.harman@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Constraints depict the dependency relationships between parameters in a software system under test. Because almost all systems are constrained in some way, techniques that adequately cater for constraints have become a crucial factor for adoption, deployment and exploitation of Combinatorial Testing (CT). Currently, despite a variety of different constraint handling techniques available, the relationship between these techniques and the generation algorithms that use them remains unknown, yielding an important gap and pressing concern in the literature of constrained combination testing. In this paper, we present a comparative empirical study to investigate the impact of four common constraint handling techniques on the performance of six representative (greedy and search-based) test suite generation algorithms. The results reveal that the Verify technique implemented with the Minimal Forbidden Tuple (MFT) approach is the fastest, while the Replace technique is promising for producing the smallest constrained covering arrays, especially for algorithms that construct test cases one-at-a-time. The results also show that there is an interplay between effectiveness of the constraint handler and the test suite generation algorithm into which it is developed.",1939-3520,,10.1109/TSE.2019.2955687,National Key Research and Development Plan; National Natural Science Foundation of China; EPSRC Fellowship; DAASE EPSRC Grant; Natural Science Foundation of Jiangsu Province; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913600,combinatorial testing;constraint;survey;comparative study,Combinatorial testing;Software systems;Computational efficiency,,,,2.0,,,CCBY,26 Nov 2019,,,IEEE,IEEE Early Access Articles
2036,676,A Formal Specification and Verification Framework for Timed Security Protocols,L. Li; J. Sun; Y. Liu; M. Sun; J. Dong,"ISTD, Singapore University of Technology and Design, Singapore; ISTD, Singapore University of Technology and Design, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; School of Mathematical Sciences, Peking University, Beijing, China; School of Computing, National University of Singapore, Singapore",IEEE Transactions on Software Engineering,13 Aug 2018,2018,44,8,725,746,"Nowadays, protocols often use time to provide better security. For instance, critical credentials are often associated with expiry dates in system designs. However, using time correctly in protocol design is challenging, due to the lack of time related formal specification and verification techniques. Thus, we propose a comprehensive analysis framework to formally specify as well as automatically verify timed security protocols. A parameterized method is introduced in our framework to handle timing parameters whose values cannot be decided in the protocol design stage. In this work, we first propose timed applied p-calculus as a formal language for specifying timed security protocols. It supports modeling of continuous time as well as application of cryptographic functions. Then, we define its formal semantics based on timed logic rules, which facilitates efficient verification against various authentication and secrecy properties. Given a parameterized security protocol, our method either produces a constraint on the timing parameters which guarantees the security property satisfied by the protocol, or reports an attack that works for any parameter value. The correctness of our verification algorithm has been formally proved. We evaluate our framework with multiple timed and untimed security protocols and successfully find a previously unknown timing attack in Kerberos V.",1939-3520,,10.1109/TSE.2017.2712621,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939995,Timed security protocol;timed applied   $\pi$     -calculus;parameterized verification;secrecy and authentication,Cryptographic protocols;Formal specifications;Authentication;Formal verification,cryptographic protocols;formal specification;formal verification;protocols,comprehensive analysis framework;timing parameters;protocol design stage;formal language;formal semantics;parameterized security protocol;security property;formal verification techniques;formal specification framework;timed security protocols,,,,50.0,,6 Jun 2017,,,IEEE,IEEE Journals
2037,677,ConTesa: Directed Test Suite Augmentation for Concurrent Software,T. Yu; Z. Huang; C. Wang,"Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA",IEEE Transactions on Software Engineering,16 Apr 2020,2020,46,4,405,419,"As software evolves, test suite augmentation techniques may be used to identify which part of the program needs to be tested due to code changes and how to generate these new test cases for regression testing. However, existing techniques focus exclusively on sequential software, without considering concurrent software in which multiple threads may interleave with each other during the execution and thus lead to a combinatorial explosion. To fill the gap, we propose ConTesa, the first test suite augmentation tool for concurrent software. The goal is to generate new test cases capable of exercising both code changes and the thread interleavings affected by these code changes. At the center of ConTesa is a two-pronged approach. First, it judiciously reuses the current test inputs while amplifying their interleaving coverage using random thread schedules. Then, it leverages an incremental symbolic execution technique to generate more test inputs and interleavings, to cover the new concurrency-related program behaviors. We have implemented ConTesa and evaluated it on a set of real-world multithreaded Linux applications. Our results show that it can achieve a significantly high interleaving coverage and reveal more bugs than state-of-the-art testing techniques.",1939-3520,,10.1109/TSE.2018.2861392,National Science Foundation; Office of Naval Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423082,Regression testing;concurrent programming;symbolic execution;dynamic analysis,Testing;Schedules;Instruction sets;Concurrent computing;Tools;Context,Linux;multi-threading;program debugging;program diagnostics;program testing,concurrent software;code changes;thread interleavings;ConTesa;test inputs;random thread schedules;incremental symbolic execution technique;concurrency-related program behaviors;high interleaving coverage;directed test suite augmentation;test suite augmentation techniques;regression testing;sequential software;multiple threads;test suite augmentation tool,,,,68.0,IEEE,30 Jul 2018,,,IEEE,IEEE Journals
2038,678,Using Docker to Assist Q&A Forum Users,L. Melo; I. S. Wiese; M. D'Amorim,"Computer Science, Universidade Federal de Pernambuco, 28116 Recife, Pernambuco Brazil (e-mail: luish.melo@gmail.com); Department of Computing, Federal University of Technology-Paraná, Paraná, Curitiba Brazil (e-mail: igor@utfpr.edu.br); Computer Science, Universidade Federal de Pernambuco, Recife, Pernambuco Brazil (e-mail: damorim@cin.ufpe.br)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Q&A forums are today a valuable tool to assist developers in programming tasks. Unfortunately, contributions to these forums are often unclear and incomplete. Docker is a container solution that enables software developers to encapsulate an operating environment and could help address reproducibility issues. This paper reports on a feasibility study to evaluate if Docker can help improve reproducibility in Stack Overflow. We started surveying Stack Overflow users to understand their perceptions on the proposal of using Docker to reproduce Stack Overflow posts. Participants were critical and mentioned two important aspects: cost and need. To validate their criticism, we conducted an exploratory study focused on understanding how costly the task of creating containers for posts is for developers. Overall, results indicate that the cost of creating containers is not high, especially due to the fact that Dockerfiles are highly similar and small. Based on these findings we developed a tool, dubbed FRISK, to assist developers in creating containers for those posts. We then conducted a user study to evaluate interest of Stack Overflow developers on the tool. We found that, on average, users spent nearly ten minutes interacting with FRISK and that 45.3% of the 563 FRISK sessions we created for existing posts resulted in a successful access to the corresponding web service by the owners of the post. Overall, this paper provides early evidence that the use of Docker in Q&A forums should be encouraged for configuration-related posts.",1939-3520,,10.1109/TSE.2019.2956919,Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior; Fundacao de Amparo a Ciencia e Tecnologia do Estado de Pernambuco; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918334,,Containers;Servers;Tools;Web services;Proposals;Electronic mail,,,,,,,,2 Dec 2019,,,IEEE,IEEE Early Access Articles
2039,679,Finding Faster Configurations Using FLASH,V. Nair; Z. Yu; T. Menzies; N. Siegmund; S. Apel,"Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science and Engineering, Bauhaus-University Weimar, Weimar, Germany; Department of Informatics and Mathematics, University of Passau, Passau, Germany",IEEE Transactions on Software Engineering,15 Jul 2020,2020,46,7,794,811,"Finding good configurations of a software system is often challenging since the number of configuration options can be large. Software engineers often make poor choices about configuration or, even worse, they usually use a sub-optimal configuration in production, which leads to inadequate performance. To assist engineers in finding the better configuration, this article introduces Flash, a sequential model-based method that sequentially explores the configuration space by reflecting on the configurations evaluated so far to determine the next best configuration to explore. Flash scales up to software systems that defeat the prior state-of-the-art model-based methods in this area. Flash runs much faster than existing methods and can solve both single-objective and multi-objective optimization problems. The central insight of this article is to use the prior knowledge of the configuration space (gained from prior runs) to choose the next promising configuration. This strategy reduces the effort (i.e., number of measurements) required to find the better configuration. We evaluate Flash using 30 scenarios based on 7 software systems to demonstrate that Flash saves effort in 100 and 80 percent of cases in single-objective and multi-objective problems respectively by up to several orders of magnitude compared to state-of-the-art techniques.",1939-3520,,10.1109/TSE.2018.2870895,Deutsche Forschungsgemeinschaft; DFG; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8469102,Performance prediction;search-based SE;configuration;multi-objective optimization;sequential model-based methods,Software systems;Optimization;Throughput;Storms;Task analysis;Cloud computing,evolutionary computation;optimisation;search problems;software fault tolerance,software systems;multiobjective problems;configuration options;software engineers;sub-optimal configuration;sequential model-based method;configuration space;Flash scales;multiobjective optimization problems,,6.0,,65.0,IEEE,20 Sep 2018,,,IEEE,IEEE Journals
2040,680,A Systematic Literature Review and Meta-Analysis on Cross Project Defect Prediction,S. Hosseini; B. Turhan; D. Gunarathna,"University of Oulu, Oulu, Finland; Department of Computer Science, Brunel University London, London, United Kingdom; Vaimo Finland (Oy), Oulu, Finland",IEEE Transactions on Software Engineering,12 Feb 2019,2019,45,2,111,147,"Background: Cross project defect prediction (CPDP) recently gained considerable attention, yet there are no systematic efforts to analyse existing empirical evidence. Objective: To synthesise literature to understand the state-of-the-art in CPDP with respect to metrics, models, data approaches, datasets and associated performances. Further, we aim to assess the performance of CPDP versus within project DP models. Method: We conducted a systematic literature review. Results from primary studies are synthesised (thematic, meta-analysis) to answer research questions. Results: We identified 30 primary studies passing quality assessment. Performance measures, except precision, vary with the choice of metrics. Recall, precision, f-measure, and AUC are the most common measures. Models based on Nearest-Neighbour and Decision Tree tend to perform well in CPDP, whereas the popular naïve Bayes yields average performance. Performance of ensembles varies greatly across f-measure and AUC. Data approaches address CPDP challenges using row/column processing, which improve CPDP in terms of recall at the cost of precision. This is observed in multiple occasions including the meta-analysis of CPDP versus WPDP. NASA and Jureczko datasets seem to favour CPDP over WPDP more frequently. Conclusion: CPDP is still a challenge and requires more research before trustworthy applications can take place. We provide guidelines for further research.",1939-3520,,10.1109/TSE.2017.2770124,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097045,Defect prediction;fault prediction;cross project;systematic literature review;meta-analysis;within project,Object oriented modeling;Systematics;Measurement;Bibliographies;Predictive models;Context modeling;Data models,Bayes methods;decision trees;learning (artificial intelligence);pattern classification;software maintenance;software metrics;software quality;statistical analysis,systematic literature review;meta-analysis;cross project defect prediction;systematic efforts;associated performances;project DP models;CPDP;AUC;f-measure;nearest-neighbour;decision tree;NASA;Jureczko datasets;WPDP;row-column processing,,54.0,,150.0,,7 Nov 2017,,,IEEE,IEEE Journals
2041,681,Mining Semantic Loop Idioms,M. Allamanis; E. T. Barr; C. Bird; P. Devanbu; M. Marron; C. Sutton,"University of Edinburgh, Edinburgh, United Kingdom; University College London, London, United Kingdom; Microsoft Research, Redmond, WA; University of California, Davis, CA; Microsoft Research, Redmond, WA; University of Edinburgh, Edinburgh, United Kingdom",IEEE Transactions on Software Engineering,16 Jul 2018,2018,44,7,651,668,"To write code, developers stitch together patterns, like API protocols or data structure traversals. Discovering these patterns can identify inconsistencies in code or opportunities to replace these patterns with an API or a language construct. We present coiling, a technique for automatically mining code for semantic idioms: surprisingly probable, semantic patterns. We specialize coiling for loop idioms, semantic idioms of loops. First, we show that automatically identifiable patterns exist, in great numbers, with a largescale empirical study of loops over 25MLOC. We find that most loops in this corpus are simple and predictable: 90 percent have fewer than 15LOC and 90 percent have no nesting and very simple control. Encouraged by this result, we then mine loop idioms over a second, buildable corpus. Over this corpus, we show that only 50 loop idioms cover 50 percent of the concrete loops. Our framework opens the door to data-driven tool and language design, discovering opportunities to introduce new API calls and language constructs. Loop idioms show that LINQ would benefit from an Enumerate operator. This can be confirmed by the exitence of a StackOverflow question with 542k views that requests precisely this feature.",1939-3520,,10.1109/TSE.2018.2832048,Microsoft Research; Engineering and Physical Sciences Research Council; US National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355713,Data-driven tool design;idiom mining;code patterns,Semantics;Tools;Syntactics;Data mining;C# languages;Machine learning;Testing,application program interfaces;data mining;data structures,data structure traversals;automatically mining code;semantic idioms;semantic patterns;automatically identifiable patterns;concrete loops;semantic loop idiom mining,,2.0,,68.0,,7 May 2018,,,IEEE,IEEE Journals
2042,682,A Study of Bug Management Using the Stack Exchange Question and Answering Platform,A. Bhatia; S. Wang; M. Asaduzzaman; A. E. Hassan,"School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: aaditya.bhatia@cs.queensu.ca); Department of Computer Science, University of Manitoba, Canada (e-mail: shaowei@cs.umanitoba.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: muhammad.asaduzzaman@cs.queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"Traditional bug management systems, like Bugzilla, are widely used in open source and commercial projects. Stack Exchange uses its online question and answer (Q&A) platform to collect and manage bugs, which brings several new unique features that are not offered in traditional bug management systems. Users can edit bug reports, use different communication channels, and vote on bug reports, answers, and their associated comments. Understanding how these features manage bug reports can provide insights to the designers of traditional bug management systems, like whether a feature should be introduced? and how would users leverage such a feature? We performed a large-scale analysis of 19,151 bug reports of the bug management system of Stack Exchange and studied the in-place editing, the answering and commenting, and the voting features. We find that: 1) The three features are used actively. 2) 57% of the edits improved the quality of bug reports. 3) Commenting provides a channel for discussing bug-related information, while answering offers a channel for explaining the causes of a bug and bug-fix information. 4) Downvotes are made due to the disagreement of the reported “bug” being a real bug and the low quality of bug reports. Based on our findings, we provide suggestions for traditional bug management systems.",1939-3520,,10.1109/TSE.2020.2994006,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091233,Bug management systems;Stack Exchange;Question & answer platform,Computer bugs;Tagging;History;Communication channels;Software;Message systems;Indexes,,,,,,,,11 May 2020,,,IEEE,IEEE Early Access Articles
2043,683,Automated Refactoring of OCL Constraints with Search,H. Lu; S. Wang; T. Yue; s. Ali; J. F. Nygård,"Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Cancer Registry of Norway, Oslo, Norway",IEEE Transactions on Software Engineering,12 Feb 2019,2019,45,2,148,170,"Object Constraint Language (OCL) constraints are typically used to provide precise semantics to models developed with the Unified Modeling Language (UML). When OCL constraints evolve regularly, it is essential that they are easy to understand and maintain. For instance, in cancer registries, to ensure the quality of cancer data, more than one thousand medical rules are defined and evolve regularly. Such rules can be specified with OCL. It is, therefore, important to ensure the understandability and maintainability of medical rules specified with OCL. To tackle such a challenge, we propose an automated search-based OCL constraint refactoring approach (SBORA) by defining and applying four semantics-preserving refactoring operators (i.e., Context Change, Swap, Split and Merge) and three OCL quality metrics (Complexity, Coupling, and Cohesion) to measure the understandability and maintainability of OCL constraints. We evaluate SBORA along with six commonly used multi-objective search algorithms (e.g., Indicator-Based Evolutionary Algorithm (IBEA)) by employing four case studies from different domains: healthcare (i.e., cancer registry system from Cancer Registry of Norway (CRN)), Oil&Gas (i.e., subsea production systems), warehouse (i.e., handling systems), and an open source case study named SEPA. Results show: 1) IBEA achieves the best performance among all the search algorithms and 2) the refactoring approach along with IBEA can manage to reduce on average 29.25 percent Complexity and 39 percent Coupling and improve 47.75 percent Cohesion, as compared to the original OCL constraint set from CRN. To further test the performance of SBORA, we also applied it to refactor an OCL constraint set specified on the UML 2.3 metamodel and we obtained positive results. Furthermore, we conducted a controlled experiment with 96 subjects and results show that the understandability and maintainability of the original constraint set can be improved significantly from the perspectives of the 96 participants of the controlled experiment.",1939-3520,,10.1109/TSE.2017.2774829,RFF Hovedstaden; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114267,Constraints;metrics/measurement;methodologies;CASE,Cancer;Unified modeling language;Measurement;Couplings;Complexity theory;Semantics;Computational modeling,cancer;evolutionary computation;health care;object-oriented programming;search problems;Unified Modeling Language,multiobjective search algorithms;semantics-preserving refactoring operators;OCL quality metrics;cancer registry;object constraint language;UML;Unified Modeling Language;medical rules;SBORA;search-based OCL constraint refactoring approach;indicator-based evolutionary algorithm;IBEA;healthcare;CRN;Norway,,1.0,,59.0,,17 Nov 2017,,,IEEE,IEEE Journals
2044,684,Bridging Semantic Gaps between Natural Languages and APIs with Word Embedding,X. Li; H. Jiang; Y. Kamei; X. Chen,"Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; Principles of Software Languages Group (POSL), Kyushu University, Fukuoka, Japan; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China",IEEE Transactions on Software Engineering,14 Oct 2020,2020,46,10,1081,1097,"Developers increasingly rely on text matching tools to analyze the relation between natural language words and APIs. However, semantic gaps, namely textual mismatches between words and APIs, negatively affect these tools. Previous studies have transformed words or APIs into low-dimensional vectors for matching; however, inaccurate results were obtained due to the failure of modeling words and APIs simultaneously. To resolve this problem, two main challenges are to be addressed: the acquisition of massive words and APIs for mining and the alignment of words and APIs for modeling. Therefore, this study proposes Word2API to effectively estimate relatedness of words and APIs. Word2API collects millions of commonly used words and APIs from code repositories to address the acquisition challenge. Then, a shuffling strategy is used to transform related words and APIs into tuples to address the alignment challenge. Using these tuples, Word2API models words and APIs simultaneously. Word2API outperforms baselines by 10-49.6 percent of relatedness estimation in terms of precision and NDCG. Word2API is also effective on solving typical software tasks, e.g., query expansion and API documents linking. A simple system with Word2API-expanded queries recommends up to 21.4 percent more related APIs for developers. Meanwhile, Word2API improves comparison algorithms by 7.9-17.4 percent in linking questions in Question&Answer communities to API documents.",1939-3520,,10.1109/TSE.2018.2876006,National Key Research and Development Program of China; National Natural Science Foundation of China; JSPS KAKENHI; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493293,Relatedness estimation;word embedding;word2Vec;query expansion;API documents linking,Tools;Natural languages;Training;Software;Task analysis;Semantics;Estimation,application program interfaces;computational linguistics;data mining;natural language processing;pattern matching;query processing;text analysis,shuffling strategy;word alignment;mining;textual mismatches;text matching tools;word embedding;semantic gaps;natural language words;Word2API-expanded queries;API documents,,3.0,,57.0,IEEE,16 Oct 2018,,,IEEE,IEEE Journals
2045,685,A Study of Social Interactions in Open Source Component Use,M. Palyart; G. C. Murphy; V. Masrani,"Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada",IEEE Transactions on Software Engineering,9 Dec 2018,2018,44,12,1132,1145,"All kinds of software projects, whether open or closed source, rely on open source components. Repositories that serve open source components to organizations, such as the Central Repository and npmjs.org, report billions of requests per year. Despite the widespread reliance of projects on open source components, little is known about the social interactions that occur between developers of a project using a component and developers of the component itself. In this paper, we investigate the social interactions that occur for 5,133 pairs of projects, from two different communities (Java and Ruby) representing user projects that depend on a component project. We consider such questions as how often are there social interactions when a component is used? When do the social interactions occur? And, why do social interactions occur? From our investigation, we observed that social interactions typically occur after a component has been chosen for use and relied upon. When social interactions occur, they most frequently begin with creating issues or feature requests. We also found that the more use a component receives, the less likely it is that developers of project using the component will interact with the component project, and when those interactions occur, they will be shorter in duration. Our results provide insight into how socio-technical interactions occur beyond the level of an individual or small group of projects previously studied by others and identify the need for a new model of socio-technical congruence for dependencies between, instead of within, projects.",1939-3520,,10.1109/TSE.2017.2756043,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049385,Software reuse;collaboration;social interactions;OSS components,Social factors;Computer bugs;Java;Collaboration;Software reusability;Open source software;Project management,human computer interaction;Java;object-oriented programming;project management;public domain software;software development management,open source components;social interactions;component project;Ruby;Java;sociotechnical congruence;sociotechnical interactions;software projects,,,,27.0,,25 Sep 2017,,,IEEE,IEEE Journals
2046,686,Software Deployment on Heterogeneous Platforms: A Systematic Mapping Study,H. Andrade; J. Schroeder; I. Crnkovic,"Computer Science and Engineering, Chalmers University of Technology, 11248 Gothenburg, Vastra Gotaland Sweden (e-mail: sica@chalmers.se); Computer Science and Engineering, University of Gothenburg, 3570 Gothenburg, Vastra Gotaland Sweden (e-mail: jan.schroder@gu.se); Computer Science and Engineering, Chalmers University of Technology, 11248 Gothenburg, Vastra Gotaland Sweden (e-mail: crnkovic@chalmers.se)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Context: Multiple types of processing units (e.g., CPUs, GPUs and FPGAs) can be used jointly to achieve better performance in computational systems. However, these units are built with fundamentally different characteristics and demand attention especially towards software deployment. Objective: The goal of this work is to summarize the state-of-the-art of software deployment on heterogeneous platforms. We provide an overview of the research area by searching for and categorizing relevant studies, as well as discussing gaps and trends of the field. We are interested in the main concerns (RQ1) and the approaches used (RQ2) when deploying software on heterogeneous platforms. Method: In order to achieve our goal, we performed a systematic mapping study, which refers to a method for reviewing literature with basis on predefined search strategies and a multi-step selection process. Results: We selected and analyzed 146 primary studies from multiple sources and found that the area of research is dominated by solution proposals. The majority of the studies discuss concerns about scheduling, the quality of the software, and its architecture. A large number of studies focuses on the problem of scheduling tasks and processes. We found approaches that are applied at different binding times (i.e., design time, runtime, orthogonal). Conclusion: The evaluation of the proposed solutions in an industrial context is missing. Also, the proposed methods have not been evaluated in development processes. Most of the methods address a particular concern, or a few concerns, while there is a lack of a holistic approach.",1939-3520,,10.1109/TSE.2019.2932665,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786134,Software Deployment;Heterogeneous Computing;Heterogeneous Platforms;Systematic Mapping Study,Task analysis;Program processors;Systematics;Heterogeneous networks;Central Processing Unit;Field programmable gate arrays,,,,3.0,,,,5 Aug 2019,,,IEEE,IEEE Early Access Articles
2047,687,Hybrid Program Dependence Approximation for Effective Dynamic Impact Prediction,H. Cai,"School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA",IEEE Transactions on Software Engineering,16 Apr 2018,2018,44,4,334,364,"Impact analysis determines the effects that program entities of interest, or changes to them, may have on the rest of the program for software measurement, maintenance, and evolution tasks. Dynamic impact analysis could be one major approach to impact analysis that computes smaller impact setsthan static alternatives for concrete sets of executions. However, existing dynamic approaches often produce impact sets that are too large to be useful, hindering their adoption in practice. To address this problem, we propose to exploit static program dependencies to drastically prune false-positive impacts that are not exercised by the set of executions utilized by the analysis, via hybrid dependence approximation. Further, we present a novel dynamic impact analysis called Diver which leverages both the information provided by the dependence graph and method-execution events to identify runtimemethod-level dependencies, hence dynamic impact sets, much more precisely without reducing safety and at acceptable costs. We evaluate Diver on ten Java subjects of various sizes and application domains against both arbitrary queries covering entire programs and practical queries based on changes actually committed by developers to actively evolving software repositories. Our extensive empirical studies show that Diver can significantly improve the precision of impact prediction, with 100-186 percent increase, with respect to a representative existing alternative thus provide a far more effective option for dynamic impact prediction. Following a similar rationale to Diver, we further developed and evaluated an online dynamic impact analysis called DiverOnline which produces impact sets immediately upon the termination of program execution. Our results show that compared to the offline approach, for the same precision, the online approach can reduce the time by 50 percent on average for answering all possible queries in the given program at once albeit at the price of possibly significant increase in runtime overhead. For users interested in one specific query only, the online approach may compute the impact set for that query during runtime without much slowing down normal program operation. Further, the online analysis, which does not incur any space cost beyond the static-analysis phase, may be favored against the offline approach when trace storage and/or related file-system resource consumption becomes a serious challenge or even stopper for adopting dynamic impact prediction. Therefore, the online and offline analysis together offer complementary options to practitioners accommodating varied application/task scenarios and diverse budget constraints.",1939-3520,,10.1109/TSE.2017.2692783,ONR; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7895205,Static program dependence;dynamic analysis;impact prediction;online impact analysis;precision;efficiency,Performance analysis;Runtime;Software;Java;Concrete;Software measurement;Maintenance engineering,graph theory;Java;program diagnostics;software maintenance;system monitoring,dynamic impact prediction;software measurement;software maintenance;software evolution;Java;software repositories;DiverOnline;runtime method-level dependencies;dependence graph;false-positive impacts;static program dependencies;hybrid program dependence approximation;offline analysis;static-analysis phase;program execution;online dynamic impact analysis;Diver,,3.0,,92.0,,12 Apr 2017,,,IEEE,IEEE Journals
2048,688,PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel,T. Hoang; J. Lawall; Y. Tian; R. J. Oentaryo; D. Lo,"School of Information System, Singapore Management University, 54756 Singapore, Singapore Singapore 188065 (e-mail: vdthoang.2016@smu.edu.sg); Computer Science, Inria/LIP6/UPMC/Sorbonne University-Regal, Paris, France France 75005 (e-mail: julia.lawall@lip6.fr); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: yuan.tian@cs.queensu.ca); McLaren Applied Technologies, McLaren, Singapore, Singapore Singapore (e-mail: richard.oentaryo@mclaren.com); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"Linux kernel stable versions serve the needs of users who value stability of the kernel over new features. The quality of such stable versions depends on the initiative of kernel developers and maintainers to propagate bug fixing patches to the stable versions. Thus, it is desirable to consider to what extent this process can be automated. A previous approach relies on words from commit messages and a small set of manually constructed code features. This approach, however, shows only moderate accuracy. In this paper, we investigate whether deep learning can provide a more accurate solution. We propose PatchNet, a hierarchical deep learning-based approach capable of automatically extracting features from commit messages and commit code and using them to identify stable patches. PatchNet contains a deep hierarchical structure that mirrors the hierarchical and sequential structure of commit code, making it distinctive from the existing deep learning models on source code. Experiments on 82,403 recent Linux patches confirm the superiority of PatchNet against various state-of-the-art baselines, including the one recently-adopted by Linux kernel maintainers.",1939-3520,,10.1109/TSE.2019.2952614,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896061,,Kernel;Linux;Computer bugs;Feature extraction;Deep learning;Indexes;Manuals,,,,2.0,,,,11 Nov 2019,,,IEEE,IEEE Early Access Articles
2049,689,oo7: Low-overhead Defense against Spectre attacks via Program Analysis,G. Wang; S. Chattopadhyay; I. Gotovchits; T. Mitra; A. Roychoudhury,"Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: wangghge@gmail.com); ISTD, Singapore University of Technology and Design, 233793 Singapore, Singapore Singapore (e-mail: sudipta_chattopadhyay@sutd.edu.sg); CyLab Security and Privacy Institute, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: ivg@ieee.org); Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: tulika@comp.nus.edu.sg); Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: abhik@comp.nus.edu.sg)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The Spectre vulnerability in modern processors has been widely reported. The key insight in this vulnerability is that speculative execution in processors can be misused to access secrets speculatively. Subsequently even though the speculatively executed instructions are squashed, the secret may linger in micro-architectural states such as cache, and can potentially be accessed by an attacker via side channels. In this paper, we take the analysis approach, and try to see how Spectre attacks can be mitigated using static analysis. We propose oo7, a static analysis approach that can mitigate Spectre attacks by detecting potentially vulnerable code snippets in program binaries and protecting them against the attack. Our key contribution is to balance the concerns of effectiveness, analysis time and run-time overheads. We employ control flow extraction, taint analysis and address analysis to detect tainted conditional branches and speculative memory accesses. oo7 can detect all fifteen purpose-built Spectre-vulnerable code patterns, whereas Microsoft compiler with Spectre mitigation option can only detect two of them. We also report the results of a large-scale study on applying oo7 to over 500 program binaries (average binary size 261 KB) from different real-world projects. We protect programs against Spectre attack by selectively inserting fences only at vulnerable conditional branches to prevent speculative execution. Our approach is experimentally observed to incur low performance overheads on SPECint benchmarks.",1939-3520,,10.1109/TSE.2019.2953709,National Research Foundation Singapore; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902081,,Program processors;Malware;Arrays;Transient analysis;Benchmark testing;Analytical models;Maintenance engineering,,,,1.0,,,,15 Nov 2019,,,IEEE,IEEE Early Access Articles
2050,690,EnergyPatch: Repairing Resource Leaks to Improve Energy-Efficiency of Android Apps,A. Banerjee; L. K. Chong; C. Ballabriga; A. Roychoudhury,"School of Computing, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore; University of Lille, Villeneuve, France; School of Computing, National University of Singapore, Singapore",IEEE Transactions on Software Engineering,14 May 2018,2018,44,5,470,490,"Increased usage of mobile devices, such as smartphones and tablets, has led to widespread popularity and usage of mobile apps. If not carefully developed, such apps may demonstrate energy-inefficient behaviour, where one or more energy-intensive hardware components (such as Wifi, GPS, etc) are left in a high-power state, even when no apps are using these components. We refer to such kind of energy-inefficiencies as energy bugs. Executing an app with an energy bug causes the mobile device to exhibit poor energy consumption behaviour and a drastically shortened battery life. Since mobiles apps can have huge input domains, therefore exhaustive exploration is often impractical. We believe that there is a need for a framework that can systematically detect and fix energy bugs in mobile apps in a scalable fashion. To address this need, we have developed EnergyPatch, a framework that uses a combination of static and dynamic analysis techniques to detect, validate and repair energy bugs in Android apps. The use of a light-weight, static analysis technique enables EnergyPatch to quickly narrow down to the potential program paths along which energy bugs may occur. Subsequent exploration of these potentially buggy program paths using a dynamic analysis technique helps in validations of the reported bugs and to generate test cases. Finally, EnergyPatch generates repair expressions to fix the validated energy bugs. Evaluation with real-life apps from repositories such as F-droid and Github, shows that EnergyPatch is scalable and can produce results in reasonable amount of time. Additionally, we observed that the repair expressions generated by EnergyPatch could bring down the energy consumption on tested apps up to 60 percent.",1939-3520,,10.1109/TSE.2017.2689012,Singapore MoE Tier 2; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889026,Mobile apps;energy bugs;non-functional testing;energy-aware test generation,Computer bugs;Androids;Humanoid robots;Maintenance engineering;Mobile handsets;Energy consumption;Batteries,Android (operating system);energy consumption;mobile computing;power aware computing;program debugging;program diagnostics;program testing;smart phones,EnergyPatch;energy-efficiency;Android apps;mobile device;mobile apps;energy-inefficient behaviour;energy-intensive hardware components;energy-inefficiencies;energy bug;poor energy consumption behaviour;mobiles apps;validated energy bugs;real-life apps;tested apps;smartphones;tablets;static analysis techniques;dynamic analysis techniques;buggy program paths;F-droid;Github,,7.0,,58.0,,29 Mar 2017,,,IEEE,IEEE Journals
2051,691,Emerging App Issue Identification via Online Joint Sentiment-Topic Tracing,C. Gao; J. Zeng; Z. Wen; D. Lo; X. Xia; I. King; M. R. Lyu,"Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong, Hong Kong, (e-mail: gcyydxf@gmail.com); Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong, Hong Kong, (e-mail: jczeng@cse.cuhk.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong, Hong Kong, (e-mail: cszwen@comp.polyu.edu.hk); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); Faculty of Information Technology, Monash University, 2541 MELBOURNE, Victoria, Australia, 3800 (e-mail: xin.xia@monash.edu); Computer Science & Engineering, The Chinese University of Hong Kong, Shatin, NT, Hong Kong, SAR (e-mail: king@cse.cuhk.edu.hk); Computer Science & Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong, Hong Kong, 00000 (e-mail: lyu@cse.cuhk.edu.hk)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Millions of mobile apps are available in app stores, such as Apple's App Store and Google Play. For a mobile app, it would be increasingly challenging to stand out from the enormous competitors and become prevalent among users. Good user experience and well-designed functionalities are the keys to a successful app. To achieve this, popular apps usually schedule their updates frequently. If we can capture the critical app issues faced by users in a timely and accurate manner, developers can make timely updates, and good user experience can be ensured. There exist prior studies on analyzing reviews for detecting emerging app issues. These studies are usually based on topic modeling or clustering techniques. However, the short-length characteristics and sentiment of user reviews have not been considered. In this paper, we propose a novel emerging issue detection approach named MERIT to take into consideration the two aforementioned characteristics. Specifically, we propose an Adaptive Online Biterm Sentiment-Topic (AOBST) model for jointly modeling topics and corresponding sentiments that takes into consideration app versions. Based on the AOBST model, we infer the topics negatively reflected in user reviews for one app version, and automatically interpret the meaning of the topics with most relevant phrases and sentences. Experiments on popular apps from Google Play and Apple's App Store demonstrate the effectiveness of MERIT in identifying emerging app issues, improving the state-of-the-art method by 22.3% in terms of F1-score. In terms of efficiency, MERIT can return results within acceptable time.",1939-3520,,10.1109/TSE.2021.3076179,National Research Foundation Singapore under its Industry Alignment Fund Pre-positioning IAF-PP Funding Initiative; Research Grants Council of the Hong Kong Special Administrative Region; National Natural Science Foundation of China; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417702,User reviews;online topic modeling;emerging issues;review sentiment;word embedding,Magneto electrical resistivity imaging technique;Social networking (online);User experience;Labeling;Mobile applications;Internet;Adaptation models,,,,,,,IEEE,28 Apr 2021,,,IEEE,IEEE Early Access Articles
2052,692,A Combinatorial Testing-Based Approach to Fault Localization,L. Sh. Ghandehari; Y. Lei; R. Kacker; R. Kuhn; T. Xie; D. Kung,"Department of Computer Science and Engineering, University of Texas, Arlington, TX, USA; Department of Computer Science and Engineering, University of Texas, Arlington, TX, USA; Information Technology Lab, National Institute of Standards and Technology, Gaithersburg, MD, USA; Information Technology Lab, National Institute of Standards and Technology, Gaithersburg, MD, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science and Engineering, University of Texas, Arlington, TX, USA",IEEE Transactions on Software Engineering,15 Jun 2020,2020,46,6,616,645,"Combinatorial testing has been shown to be a very effective strategy for software testing. After a failure is detected, the next task is to identify one or more faulty statements in the source code that have caused the failure. In this paper, we present a fault localization approach, called BEN, which produces a ranking of statements in terms of their likelihood of being faulty by leveraging the result of combinatorial testing. BEN consists of two major phases. In the first phase, BEN identifies a combination that is very likely to be failure-inducing. A combination is failure-inducing if it causes any test in which it appears to fail. In the second phase, BEN takes as input a failure-inducing combination identified in the first phase and produces a ranking of statements in terms of their likelihood to be faulty. We conducted an experiment in which our approach was applied to the Siemens suite and four real-world programs, flex, grep, gzip and sed, from Software Infrastructure Repository (SIR). The experimental results show that our approach can effectively and efficiently localize the faulty statements in these programs.",1939-3520,,10.1109/TSE.2018.2865935,National Institute of Standards and Technology; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438933,Combinatorial testing;fault localization;debugging,Testing;Fault diagnosis;Flexible printed circuits;Software;Task analysis;Debugging;Computer science,program debugging;program testing;software fault tolerance,combinatorial testing-based approach;software testing;faulty statements;fault localization approach;failure-inducing combination;software infrastructure repository;BEN approach,,9.0,,59.0,IEEE,17 Aug 2018,,,IEEE,IEEE Journals
2053,693,On the Use of Hidden Markov Model to Predict the Time to Fix Bugs,M. Habayeb; S. S. Murtaza; A. Miranskyy; A. B. Bener,"Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada; Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada; Department of Computer Science, Ryerson University, Toronto, Ontario, Canada; Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada",IEEE Transactions on Software Engineering,9 Dec 2018,2018,44,12,1224,1244,"A significant amount of time is spent by software developers in investigating bug reports. It is useful to indicate when a bug report will be closed, since it would help software teams to prioritise their work. Several studies have been conducted to address this problem in the past decade. Most of these studies have used the frequency of occurrence of certain developer activities as input attributes in building their prediction models. However, these approaches tend to ignore the temporal nature of the occurrence of these activities. In this paper, a novel approach using Hidden Markov Models and temporal sequences of developer activities is proposed. The approach is empirically demonstrated in a case study using eight years of bug reports collected from the Firefox project. Our proposed model correctly identifies bug reports with expected bug fix times. We also compared our proposed approach with the state of the art technique in the literature in the context of our case study. Our approach results in approximately 33 percent higher F-measure than the contemporary technique based on the Firefox project data.",1939-3520,,10.1109/TSE.2017.2757480,NSERC; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052546,Bug repositories;temporal activities;time to fix a bug;hidden markov model,Computer bugs;Hidden Markov models;Predictive models;Software quality;Data science;Stochastic processes,hidden Markov models;program debugging;public domain software;software maintenance;software quality,bug report;fix bugs;hidden Markov model;time prediction;temporal sequences;Firefox project,,5.0,,42.0,,28 Sep 2017,,,IEEE,IEEE Journals
2054,694,A Survey of Performance Optimization for Mobile Applications,M. Hort; M. Kechagia; F. Sarro; M. Harman,"Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: max.hort.19@ucl.ac.uk); Computer Science, University College London, 4919 London, Greater London, United Kingdom of Great Britain and Northern Ireland, (e-mail: m.kechagia@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)",IEEE Transactions on Software Engineering,,2021,PP,99,1,1,"Nowadays there is a mobile application for almost everything a user may think of, ranging from paying bills and gathering information to playing games and watching movies. In order to ensure user satisfaction and success of applications, it is important to provide high performant applications. This is particularly important for resource constraint systems such as mobile devices. Thereby, non-functional performance characteristics, such as energy and memory consumption, play an important role for user satisfaction. This paper provides a comprehensive survey of non-functional performance optimization for Android applications. We collected 155 unique publications, published between 2008 and 2020, that focus on the optimization of non-functional performance of mobile applications. We target our search at four performance characteristics, in particular: responsiveness, launch time, memory and energy consumption. For each performance characteristic, we categorize optimization approaches based on the method used in the corresponding publications. Furthermore, we identify research gaps in the literature for future work.",1939-3520,,10.1109/TSE.2021.3071193,H2020 European Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397392,mobile applications;android;non-functional performance optimization;software optimization;literature survey,Mobile applications;Optimization;Smart phones;Performance evaluation;Energy consumption;Software;Hardware,,,,,,,IEEE,6 Apr 2021,,,IEEE,IEEE Early Access Articles
2055,695,Automatic and Accurate Expansion of Abbreviations in Parameters,Y. Jiang; H. Liu; J. Zhu; L. Zhang,"School of Computer Science and Technology, Beijinag Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijinag Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijinag Institute of Technology, Beijing, P.R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, P.R. China",IEEE Transactions on Software Engineering,15 Jul 2020,2020,46,7,732,747,"Abbreviations are widely used in identifiers. However, they have severe negative impact on program comprehension and IR-based software maintenance activities, e.g., concept location, software clustering, and recovery of traceability links. Consequently, a number of efficient approaches have been proposed successfully to expand abbreviations in identifiers. Most of such approaches rely heavily on dictionaries, and rarely exploit the specific and fine-grained context of identifiers. As a result, such approaches are less accurate in expanding abbreviations (especially short ones) that may match multiple dictionary words. To this end, in this paper we propose an automatic approach to improve the accuracy of abbreviation expansion by exploiting the specific and fine-grained context. It focuses on a special but common category of abbreviations (abbreviations in parameter names), and thus it can exploit the specific and fine-grained context, i.e., the type of the enclosing parameter as well the corresponding formal (or actual) parameter name. The recent empirical study on parameters suggest that actual parameters are often lexically similar to their corresponding formal parameters. Consequently, it is likely that an abbreviation in a formal parameter can find its full terms in the corresponding actual parameter, and vice versa. Based on this assumption, a series of heuristics are proposed to look for full terms from the corresponding actual (or formal) parameter names. To the best of our knowledge, we are the first to expand abbreviations by exploiting the lexical similarity between actual and formal parameters. We also search for full terms in the data type of the enclosing parameter. Only if all such heuristics fail, the approach turns to the traditional abbreviation dictionaries. We evaluate the proposed approach on seven well known open-source projects. Evaluation results suggest that when only parameter abbreviations are involved, the proposed approach can improve the precision from 26 to 95 percent and recall from 26 to 65 percent compared against the state-of-the-art general purpose approach. Consequently, the proposed approach could be employed as a useful supplement to existing approaches to expand parameter abbreviations.",1939-3520,,10.1109/TSE.2018.2868762,National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454758,Abbreviation;expansion;comprehension;lexical similarity;quality;information retrieval,Dictionaries;Open source software;Syntactics;Approximation algorithms;Software maintenance;Indexes,information retrieval;software maintenance,formal parameter;parameter abbreviations;IR-based software maintenance activities;abbreviation expansion;parameter names;program comprehension,,1.0,,44.0,IEEE,5 Sep 2018,,,IEEE,IEEE Journals
2056,696,On Company Contributions to Community Open Source Software Projects,S. Butler; J. Gamalielsson; B. Lundell; C. Brax; J. Sjoberg; A. Mattsson; T. Gustavsson; J. Feist; E. Lonroth,"School of Informatics, University of Skovde, Skovde, Vastra Gotaland Sweden (e-mail: simon.butler@his.se); School of Informatics, University of Skovde, Skovde, Vastra Gotaland Sweden (e-mail: jonas.gamalielsson@his.se); School of Humanities and Informatics, University of Skovde, Skovde, Skovde Sweden 541 28 (e-mail: bjorn.lundell@his.se); not applicable, Combitech AB, Linkaping, not applicable Sweden (e-mail: christoffer.brax@combitech.se); not applicable, Findwise AB, Goteborg, not applicable Sweden (e-mail: johan.sjoberg@findwise.com); not applicable, Husqvarna AB, 355215 Huskvarna, not applicable Sweden (e-mail: anders.mattsson@husqvarnagroup.com); not applicable, PrimeKey Solutions AB, Stockholm, not applicable Sweden (e-mail: tomas.gustavsson@primekey.com); not applicable, RedBridge AB, Stockholm, not applicable Sweden (e-mail: jonas.feist@redbridge.se); not applicable, Scania IT AB, Sadertolje, not applicable Sweden (e-mail: erik.lonroth@scania.com)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The majority of contributions to community open source software (OSS) projects are made by practitioners acting on behalf of companies and other organisations. Previous research has addressed the motivations of both individuals and companies to engage with OSS projects. However, limited research has been undertaken that examines and explains the practical mechanisms or work practices used by companies and their developers to pursue their commercial and technical objectives when engaging with OSS projects. This research investigates the variety of work practices used in public communication channels by company contributors to engage with and contribute to eight community OSS projects. Through interviews with contributors to the eight projects we draw on their experiences and insights to explore the motivations to use particular methods of contribution. We find that companies utilise work practices for contributing to community projects which are congruent with the circumstances and their capabilities that support their short- and long-term needs. We also find that companies contribute to community OSS projects in ways that may not always be apparent from public sources, such as employing core project developers, making donations, and joining project steering committees in order to advance strategic interests. The factors influencing contributor work practices can be complex and are often dynamic arising from considerations such as company and project structure, as well as technical concerns and commercial strategies. The business context in which software created by the OSS project is deployed is also found to influence contributor work practices.",1939-3520,,10.1109/TSE.2019.2919305,The Swedish Knowledge Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737777,Open source software;company contribution;work practices,Companies;Software;Technological innovation;Collaboration;Interviews;Licenses,,,,2.0,,,CCBY,17 Jun 2019,,,IEEE,IEEE Early Access Articles
2057,697,A Large Scale Study of Long-Time Contributor Prediction for GitHub Projects,L. Bao; X. Xia; D. Lo; G. C. Murphy,"Computer Science, Zhejiang University City College, 34705 Hangzhou, Zhejiang, Zhejiang China (e-mail: baolf@zucc.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxkidd@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca)",IEEE Transactions on Software Engineering,,2019,PP,99,1,1,"The continuous contributions made by long time contributors LTCsare a key factor enabling open source software (OSS) projects to be successful and survival. We study Github as it has a large number of OSS projects and millions of contributors, which enables the study of the transition from newcomers to LTCs. In this paper, we investigate whether we can effectively predict newcomers in OSS projects to be LTCs based on their activity data that is collected from Github. We collect Github data from GHTorrent, a mirror of Github data. We select the most popular 917 projects, which contain 75,046 contributors. We determine a developer as a LTC of a project if the time interval between his/her first and last commit in the project is larger than a certain time T. In our experiment, we use three different settings on the time interval: 1, 2, and 3 years. There are 9,238, 3,968, and 1,577 contributors who become LTCs of a project in three settings of time interval, respectively. To build a prediction model, we extract many features from the activities of developers on Github, which group into five dimensions: developer profile, repository profile, developer monthly activity, repository monthly activity, and collaboration network. We apply several classifiers including naive Bayes, SVM, decision tree, kNN and random forest. We find that random forest classifier achieves the best performance with AUCs of more than 0.75 in all three settings of time interval for LTCs. We also investigate the most important features that differentiate newcomers who become LTCs from newcomers who stay in the projects for a short time. We find that the number of followers is the most important feature in all three settings of the time interval studied. We also find that the programming language and the average number of commits contributed by other developers when a newcomer joins a project also belong to the top 10 most important features in all three settings of time interval for LTCs. Finally, we provide several implications for action based on our analysis results to help OSS projects retain newcomers.",1939-3520,,10.1109/TSE.2019.2918536,National Basic Research Program of China (973 Program); Fundamental Research Funds for the Central Universities; Project of Science and Technology Research and Development Program of China Railway Corporation; NSFC Program; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721092,Long Time Contributor;GitHub;Prediction Model,Predictive models;Feature extraction;Computer languages;Task analysis;Computer bugs;Mirrors,,,,1.0,,,,23 May 2019,,,IEEE,IEEE Early Access Articles
2058,698,On How Bit-Vector Logic Can Help Verify LTL-based Specifications,M. M. Pourhashem Kallehbasti; M. G. Rossi; L. Baresi,"Department of Computer Engineering, University of Science and Technology of Mazandaran, 531623 Behshahr, Mazandaran Iran (the Islamic Republic of) (e-mail: pourhashem@mazust.ac.ir); Dipartimento di Meccanica, Politecnico di Milano, Milan, Lombardia Italy (e-mail: matteo.rossi@polimi.it); Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, 18981 Milano, Lombardia Italy (e-mail: luciano.baresi@polimi.it)",IEEE Transactions on Software Engineering,,2020,PP,99,1,1,"This paper studies how bit-vector logic (bv logic) can help improve the efficiency of verifying specifications expressed in Linear Temporal Logic (LTL). First, it exploits the notion of Bounded Satisfiability Checking to propose an improved encoding of LTL formulae into formulae of bv logic, which can be formally verified by means of Satisfiability Modulo Theories (SMT) solvers. To assess the gain in efficiency, we compare the proposed encoding, implemented in our tool Zot, against three well-known encodings available in the literature: the classic bounded encoding and the optimized, incremental one, as implemented in both NuSMV and nuXmv, and the encoding optimized for metric temporal logic, which was the “standard” implementation provided by Zot. We also compared the newly proposed solution against five additional efficient algorithms proposed by nuXmv, which is the state-of-the-art tool for verifying LTL specifications. The experiments show that the new encoding provides significant benefits with respect to existing tools. Since the first set of experiments only used Z3 as SMT solver, we also wanted to assess whether the benefits were induced by the specific solver or were more general. This is why we also embedded different SMT solvers in Zot. Besides Z3, we also carried out experiments with CVC4, Mathsat, Yices2, and Boolector, and compared the results against the first and second best solutions provided by either NuSMV or nuXmv. Obtained results witness that the benefits of the bv logic encoding are independent of the specific solver. Bv logic-based solutions are better than traditional ones with only a few exceptions. It is also true that there is no particular SMT solver that outperformed the others. Boolector is often the best as for memory usage, while Yices2 and Z3 are often the fastest ones.",1939-3520,,10.1109/TSE.2020.3014394,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159928,Formal Methods;Linear Temporal Logic;Bounded Satisfiability Checking;Bit-Vector Logic,Encoding;Tools;Standards;Unified modeling language;Optimization;Semantics;Measurement,,,,,,,,5 Aug 2020,,,IEEE,IEEE Early Access Articles
2059,699,Listening to the Crowd for the Release Planning of Mobile Apps,S. Scalabrino; G. Bavota; B. Russo; M. D. Penta; R. Oliveto,"University of Molise, Campobasso, Italy; Università della Svizzera Italiana (USI), Lugano, Switzerland; Free University of Bozen-Bolzano, Bolzano, South Tyrol, Italy; University of Sannio, Benevento, Italy; University of Molise, Campobasso, Italy",IEEE Transactions on Software Engineering,8 Jan 2019,2019,45,1,68,86,"The market for mobile apps is getting bigger and bigger, and it is expected to be worth over 100 Billion dollars in 2020. To have a chance to succeed in such a competitive environment, developers need to build and maintain high-quality apps, continuously astonishing their users with the coolest new features. Mobile app marketplaces allow users to release reviews. Despite reviews are aimed at recommending apps among users, they also contain precious information for developers, reporting bugs and suggesting new features. To exploit such a source of information, developers are supposed to manually read user reviews, something not doable when hundreds of them are collected per day. To help developers dealing with such a task, we developed CLAP (Crowd Listener for releAse Planning), a web application able to (i) categorize user reviews based on the information they carry out, (ii) cluster together related reviews, and (iii) prioritize the clusters of reviews to be implemented when planning the subsequent app release. We evaluated all the steps behind CLAP, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. Also, given the availability of CLAP as a working tool, we assessed its applicability in industrial environments.",1939-3520,,10.1109/TSE.2017.2759112,SNF; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057860,Release planning;mobile apps;mining software repositories,Data mining;Internet;Mobile applications;Google;Mobile communication;Pattern clustering,data mining;Internet;mobile computing;pattern clustering,mobile app marketplaces;user reviews;CLAP;clustering reviews;crowd listener for release planning;Web application;categorizing reviews,,6.0,,42.0,,4 Oct 2017,,,IEEE,IEEE Journals
2060,700,The AI Effect: Working at the Intersection of AI and SE,A. D. Carleton; E. Harper; T. Menzies; T. Xie; S. Eldh; M. R. Lyu,"Software Engineering, Carnegie Mellon University; Carnegie Mellon University; North Carolina State University; Computer Science and Technology, Peking University, China; Ericsson AB, Stockholm, Sweden; Computer Science and Engineering, The Chinese University of Hong Kong",IEEE Software,19 Jun 2020,2020,37,4,26,35,"This special issue explores the intersection of artificial intelligence (AI) and software engineering (SE), that is, what can AI do for SE, and how can we as software engineers design and build better AI systems?",1937-4194,,10.1109/MS.2020.2987666,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121618,,,,,,,,25.0,,19 Jun 2020,,,IEEE,IEEE Magazines
2061,701,The Sound of Software Development: Music Listening Among Software Engineers,L. Barton; G. Candan; T. Fritz; T. Zimmermann; G. C. Murphy,"Computer Science, University of British Columbia, Vancouver, British Columbia, Canada; Avigilon, Vancouver, British Columbia, Canada; University of Zurich, Zurich, Switzerland; Research, Microsoft, Redmond, Washington United States; Computer Science, University of British Columbia, Vancouver, British Columbia, Canada",IEEE Software,11 Feb 2020,2020,37,2,78,85,"Listening to music is a common phenomenon among software developers in today's work environments. Music can reduce stress, improve happiness, and even increase performance. We conducted two surveys with 2,242 professional software developers and found that between 63 and 88.2% of participants listen to music at work at least some of the time often when writing code or doing repetitive tasks, and that these listeners tend to be more extroverted.",1937-4194,,10.1109/MS.2019.2906312,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669868,,Music;Software development management;Task analysis;Mood;Writing;Noise measurement;Productivity,hearing;music;software development management;software engineering,software development;music listening;software engineers;work environments;professional software developers;repetitive tasks;stress,,,,15.0,,19 Mar 2019,,,IEEE,IEEE Magazines
2062,702,Insights Into Nonmerged Pull Requests in GitHub: Is There Evidence of Bias Based on Perceptible Race?,R. Nadri; G. Rodriguez-Perez; M. Nagappan,"University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada; Computer Science, University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada; Computer Science, University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada",IEEE Software,15 Feb 2021,2021,38,2,51,57,This article is a qualitative study that analyzes whether there is evidence of bias based on perceptible race in the written comments of nonmerged pull requests in GitHub.,1937-4194,,10.1109/MS.2020.3036758,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250363,,Software development management;Cultural differences;Psychology;Corporate acquisitions;Computer science;Cognition,distributed processing;public domain software;software engineering,GitHub;perceptible race;qualitative study;nonmerged pull requests,,,,14.0,IEEE,6 Nov 2020,,,IEEE,IEEE Magazines
2063,703,"Performance Issues? Hey DevOps, Mind the Uncertainty",C. Trubiani; P. Jamshidi; J. Cito; W. Shang; Z. M. Jiang; M. Borg,"Gran Sasso Science Institute, L'Aquila, Italy; University of South Carolina; Massachusetts Institute Technology, Cambridge, Massachuestts United States; Concordia University, Montreal, Canada; York University, Toronto, Canada; RISE Research Institutes of Sweden AB, Lund, Sweden",IEEE Software,21 Feb 2019,2019,36,2,110,117,DevOps is a novel trend that aims to bridge the gap between software development and operation teams. This article presents an experience report that better identifies performance uncertainties through a case study and provides a step-by-step guide to practitioners for controlling system uncertainties.,1937-4194,,10.1109/MS.2018.2875989,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501933,Uncertainty;Performance Analysis;DevOps;Software Development,Software development;Runtime;Predictive models;Analytical models;Hardware;Performance analysis,cloud computing;software engineering,step-by-step guide;system uncertainties;performance issues;software development;operation teams;experience report;performance uncertainties;Hey DevOps,,3.0,,15.0,,21 Oct 2018,,,IEEE,IEEE Magazines
2064,704,Gendered Experiences of Software Engineers During the COVID-19 Crisis,L. S. Machado; C. Caldeira; M. Gattermann Perin; C. R. B. de Souza,"Computer Science, Federal University of Para, Belem, 66075-110 Para, Brazil; Computer Science, Federal University of Para, Belem, 66075-110 Para, Brazil; Business Administration, Fundação Getulio Vargas’s Sao Paulo, Sao Paulo, 01313-902, Brazil; Computer Science, Federal University of Para, Belem, 66075-110 Para, Brazil",IEEE Software,17 Feb 2021,2021,38,2,38,44,"Although gender divides are largely due to cultural and environmental conditions, changes in the nature of professional and domestic work due to the COVID-19 pandemic have had unprecedented implications on gender inequality.",1937-4194,,10.1109/MS.2020.3040135,Conselho Nacional de Desenvolvimento Científico e Tecnológico; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268454,,Collaboration;Organizations;Software;Pandemics;COVID-19;Task analysis;Couplings,diseases;gender issues;software engineering,gender inequality;gendered experiences;software engineers;COVID-19 crisis;gender divides;cultural conditions;environmental conditions;professional work;domestic work;COVID-19 pandemic,,,,13.0,IEEE,24 Nov 2020,,,IEEE,IEEE Magazines
2065,705,Enabling the Study of Software Development Behavior With Cross-Tool Logs,C. Jaspan; M. Jorde; C. Egelman; C. Green; B. Holtz; E. Smith; M. Hodges; A. Knight; L. Kammer; J. Dicker; C. Sadowski; J. Lin; L. Cheng; M. Canning; E. Murphy-Hill,"Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Bloomberg, New York, New York United States; Developer Infrastructure, Artech, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States",IEEE Software,23 Oct 2020,2020,37,6,44,51,"Capturing developers' behavior at scale can be challenging. In this article, we describe our experience creating a system that integrates log data from dozens of development tools at Google.",1937-4194,,10.1109/MS.2020.3014573,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159122,,Tools;Task analysis;Google;Licenses;Measurement;Software;Electronic mail,data loggers;data mining;software engineering,software development behavior;cross-tool logs;developers behavior;log data;development tools;Google,,,,8.0,CCBY,5 Aug 2020,,,IEEE,IEEE Magazines
2066,706,Innovative Practices for Knowledge Sharing in Large-Scale DevOps,A. Hemon; B. Fitzgerald; B. Lyonnet; F. Rowe,"ESSCA School of Management, Angers, France; Lero Software Research, University of Limerick, Limerick, Ireland; Management Sciences, University of Nantes, France; University of Nantes, France",IEEE Software,15 Apr 2020,2020,37,3,30,37,"Agile development methods and DevOps require adaptation during implementation to meet the needs of a constantly changing softwaredevelopment environment. The emergence of knowledge-sharing practices for large-scale DevOps has not been the subject of much research. Our in-depth case study, consisting of 106 interviews at a multinational company operating in a DevOps-at-scale environment, identified a number of innovative practices.",1937-4194,,10.1109/MS.2019.2958900,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930607,Agile method;DevOps;Large-Scale;Innovative Practices;Knowledge Sharing,Companies;Software development management;Collaboration;Automation;Large-scale systems;Software tools,formal specification;innovation management;knowledge management;organisational aspects;software engineering,innovative practices;knowledge sharing practices;large-scale DevOps;agile development methods;knowledge-sharing practices;in-depth case study;DevOps-at-scale environment;constantly changing software development environment,,,,20.0,,10 Dec 2019,,,IEEE,IEEE Magazines
2067,707,A Taxonomy to Assess and Tailor Risk-Based Testing in Recent Testing Standards,J. Grossmann; M. Felderer; J. Viehmann; I. Schieferdecker,"Critical Systems Engineering, Fraunhofer Institute for Open Communication Systems, Berlin, Germany; Computer Science, University of Innsbruck, Innsbruck, Tyrol, Austria; Critical Systems Engineering, Fraunhofer Institute for Open Communication Systems, Berlin, Germany; Critical Systems Engineering, Fraunhofer Institute for Open Communication Systems, Berlin, Germany",IEEE Software,20 Dec 2019,2020,37,1,40,49,"This article provides a taxonomy for risk-based testing that serves as a tool to define, tailor, or assess such approaches. In this setting, the taxonomy is used to systematically identify deviations between the requirements from public standards and the individual testing approaches.",1937-4194,,10.1109/MS.2019.2915297,Bundesministerium für Bildung und Forschung; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708236,Risk management;Testing strategies;Test management;Security and Privacy Protection,Software testing;Risk management;Taxonomy;ISO Standards;Computer security;IEC Standards,program testing;risk management;software engineering,taxonomy;testing standards;risk-based testing;software product risks;software development,,,,15.0,,7 May 2019,,,IEEE,IEEE Magazines
2068,708,What We Know about Software Test Maturity and Test Process Improvement,V. Garousi; M. Felderer; T. Hacaloğlu,Hacettepe University; University of Innsbruck; Atilim University,IEEE Software,25 Dec 2017,2018,35,1,84,92,"In many companies, software testing practices and processes are far from mature and are usually conducted in an ad hoc fashion. Such immature practices lead to negative outcomes-for example, testing that doesn't detect all the defects or that incurs cost and schedule overruns. To conduct test maturity assessment (TMA) and test process improvement (TPI) systematically, researchers and practitioners have proposed various approaches and frameworks. Motivated by a recent industrial project in TMA and TPI and wanting to identify the state of the art and practice in this area, researchers conducted a review of both the scientific literature and practitioners' gray literature (for example, blog posts). The review identified 58 test maturity models and many sources with varying degrees of empirical evidence. The review's results can serve as an evidence-based overview of and index to the vast body of knowledge in this important, fast-growing area. Using this knowledge, both researchers and practitioners should be able to assess and improve the maturity of test processes.",1937-4194,,10.1109/MS.2017.4541043,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239941,software testing;test maturity;test maturity assessment;TMA;test process improvement;TPI;test process assessment;Test Maturity Model Integration;TMMi;multivocal literature review;systematic literature review;software development;software engineering,Capability maturity model;Software testing;Software development;Unified modeling language,program testing;project management;Web sites,software test maturity;test process improvement;software testing practices;immature practices;schedule overruns;test maturity assessment;TMA;TPI;test processes;test maturity models,,3.0,,20.0,,25 Dec 2017,,,IEEE,IEEE Magazines
2069,709,A Tool for Generating Health Applications Using Archetypes,A. Araujo; V. Times; M. Silva,"Federal University of Pernambuco, Maceio, Brazil; Informatics, Federal University of Pernambuco, Maceio, Brazil; Computer Science, Federal University of Pernambuco, Maceio, Brazil",IEEE Software,20 Dec 2019,2020,37,1,60,67,"Template4EHR is a to ol for the dynamic creation of data schemas for electronic health-record storage and user creation and customization of graphical user interfaces. In experimental tests with IT and health professionals, Template4EHR obtained an 81.22% satisfaction rate.",1937-4194,,10.1109/MS.2018.110162508,Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254325,computing milieux;computers and society;public policy issues;computer-related health issues;graphical user interfaces;user interfaces;information interfaces and representation (hci);information;distributed/internet based software engineering tools and techniques;design tools and techniques;software;information technology and systems;database management;systems;relational databases,Graphical user interfaces;Software tools;Terminology;Data mining;XML;Computer architecture,graphical user interfaces;medical information systems,Template4EHR;dynamic creation;data schemas;user creation;graphical user interfaces;health professionals;electronic health-record storage;health application generation;archetypes,,1.0,,15.0,,11 Jan 2018,,,IEEE,IEEE Magazines
2070,710,Practitioners’ Agile-Methodology Use and Job Perceptions,W. Sun; C. Schmidt,Washburn University; Washburn University,IEEE Software,12 Mar 2018,2018,35,2,52,61,"To examine software professionals' job perceptions related to different levels of agile-methodology use, researchers conducted a survey. The respondents generally reported high professional efficacy, high job satisfaction, moderate work overload, and low cynicism. The respondents with high agile-methodology use reported higher professional efficacy, higher job satisfaction, lower work ambiguity, lower work exhaustion, and lower individual autonomy than those with low agile-methodology use. No difference existed between the two groups regarding role conflict, work overload, and cynicism.",1937-4194,,10.1109/MS.2018.1661333,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314163,software engineering;software development;agile-methodology use;job perceptions;agile development;Extreme Programming,Agile software development;Programming profession;Encoding;Software testing;Information systems,human resource management;industrial psychology;occupational stress;personnel;professional aspects,job perceptions;software professionals;agile-methodology use;work exhaustion;work ambiguity;job satisfaction;professional efficacy;work overload,,,,21.0,,12 Mar 2018,,,IEEE,IEEE Magazines
2071,711,"A Scalable, Reactive Architecture for Cloud Applications",A. Debski; B. Szczepanik; M. Malawski; S. Spahr; D. Muthig,AGH University of Science and Technology; AGH University of Science and Technology; AGH University of Science and Technology; Lufthansa Systems; Lufthansa Systems,IEEE Software,12 Mar 2018,2018,35,2,62,71,"As cloud infrastructures gain popularity, new concepts and design patterns such as Command Query Responsibility Segregation (CQRS) and Event Sourcing (ES) promise to facilitate the development of scalable applications. Despite recent research and the availability of many blogs and tutorials devoted to these topics, few reports on real-world implementations exist that provide experimental insight into their scalability. To bridge this gap, researchers developed an architecture that exploits both CQRS and ES in accordance with Reactive Manifesto guidelines. Using that architecture, they implemented a prototype interactive flight-scheduling application to investigate this approach's scalability. A performance evaluation in a cloud environment of 15 virtual machines demonstrated the CQRS and ES patterns' horizontal scalability, observed independently for the application's read and write models. This article explains how to assemble this type of architecture, first on a conceptual level and then with specific technologies including Akka, Cassandra, Kafka, and Neo4J. A reference implementation is available as an open-source project. This approach provides many interesting advantages without compromising performance, so its rapid adoption by the industry seems likely.",1937-4194,,10.1109/MS.2017.265095722,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950867,scalability;Command Query Responsibility Segregation;CQRS;Event Sourcing;domain-driven design;reactive;Akka;flight scheduling;Reactive Manifesto;software engineering;software development,Cloud computing;Computer architecture;Scalability;Load modeling;Query processing,cloud computing;query processing;software architecture;virtual machines;Web sites,CQRS;ES;reference implementation;open-source project;cloud applications;design patterns;scalable applications;blogs;tutorials;Reactive Manifesto guidelines;prototype interactive flight-scheduling application;performance evaluation;cloud environment;virtual machines;pattern horizontal scalability;command query responsibility segregation;event sourcing,,1.0,,8.0,,16 Jun 2017,,,IEEE,IEEE Magazines
2072,712,Daily Stand-Up Meetings: Start Breaking the Rules,V. Stray; N. B. Moe; D. I. K. Sjoberg,"Informatics, University of Oslo, Oslo, Norway; SINTEF, Trondheim, Norway; University of Oslo, Oslo, Norway",IEEE Software,15 Apr 2020,2020,37,3,70,77,"Daily stand-up meetings are commonly used for software teams to collaborate and exchange information, but conducting them in a way that benefits the whole team can be challenging. We describe factors that can affect meetings and propose recommendations for improving them.",1937-4194,,10.1109/MS.2018.2875988,The Research Council of Norway Grant 267704; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501962,Agile practices;Daily Scrum;Teamwork;Self-organizing software teams;Team autonomy;Coordination;Communication;Empirical software engineering;Case study;Agile Software Development,Companies;Software;Task analysis;Interviews;Decision making;Problem-solving;Scrum (Software development),DP industry;software development management;software prototyping;team working,software teams;daily stand-up meetings,,,,12.0,,21 Oct 2018,,,IEEE,IEEE Magazines
2073,713,Code Reviewing in the Trenches: Challenges and Best Practices,L. MacLeod; M. Greiler; M. Storey; C. Bird; J. Czerwonka,Microsoft; Microsoft; University of Victoria; Microsoft Research; Microsoft,IEEE Software,6 Jul 2018,2018,35,4,34,42,"Code review has been widely adopted by and adapted to open source and industrial projects. Code review practices have undergone extensive research, with most studies relying on trace data from tool reviews, sometimes augmented by surveys and interviews. Several recent industrial research studies, along with blog posts and white papers, have revealed additional insights on code reviewing “from the trenches.” Unfortunately, the lessons learned about code reviewing are widely dispersed and poorly summarized by the existing literature. In particular, practitioners wishing to adopt or reflect on an existing or new code review process might have difficulty determining what challenges to expect and which best practices to adopt for their development context. Building on the existing literature, this article adds insights from a recent large-scale study of Microsoft developers to summarize the challenges that code-change authors and reviewers face, suggest best code-reviewing practices, and discuss tradeoffs that practitioners should consider. This article is part of a theme issue on Process Improvement.",1937-4194,,10.1109/MS.2017.265100500,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950877,peer review;social technologies;learning technologies;code inspection;code walkthroughs;testing;debugging;software engineering;software development,Encoding;Best practices;Interviews;Context awareness;Object recognition;Stakeholders,software quality;software reviews;source code (software),tool reviews;code-change authors;code-reviewing practices;Microsoft developers;code-change reviewers,,14.0,,11.0,,16 Jun 2017,,,IEEE,IEEE Magazines
2074,714,A Framework for Determining Blockchain Applicability,B. A. Scriber,CableLabs,IEEE Software,6 Jul 2018,2018,35,4,70,77,"Researchers analyzed 23 blockchain implementation projects, each tracked for design decisions and architectural alignment showing benefits, detriments, or no effects from blockchain use. The results provide the basis for a framework that lets engineers, architects, investors, and project leaders evaluate blockchain technology's suitability for a given application. This analysis also led to an understanding of why some domains are inherently problematic for blockchains. Blockchains can be used to solve some trust-based problems but aren't always the best or optimal technology. Some problems that can be solved using them can also be solved using simpler methods that don't necessitate as big an investment.",1937-4194,,10.1109/MS.2018.2801552,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405623,blockchains;software architectures;patterns;trust;immutability;transparency;identity;distributed ledgers;transaction;efficiency;software development;software engineering,Ecosystems;Computer architecture;Cryptography;Blockchain,investment;optimisation;software architecture,trust-based problems;optimal technology;design decisions;architectural alignment;blockchain technology;investment,,8.0,,9.0,,6 Jul 2018,,,IEEE,IEEE Magazines
2075,715,Lessons in Persisting Object Data Using Object-Relational Mapping,G. Vial,"Information Technology, HEC Montreal, Canada",IEEE Software,22 Oct 2019,2019,36,6,43,52,"In this article, object-relational mapping (ORM) engines in object-oriented programming are introduced. The tradeoffs that must be considered when using ORM are discussed and four lessons that will help software developers take advantage of ORM in transaction processing scenarios are provided.",1937-4194,,10.1109/MS.2018.227105428,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356175,Information Technology and Systems;database management;systems;relational databases;object-oriented programming;coding tools and techniques;Software Engineering;Software,Databases;Software development management;Object recognition;Java;Object oriented programming;Information technology,object-oriented programming;transaction processing,object data;object-relational mapping engines;ORM;object-oriented programming;transaction processing scenarios,,2.0,,15.0,,8 May 2018,,,IEEE,IEEE Magazines
2076,716,"Safe, Secure Executions at the Network Edge: Coordinating Cloud, Edge, and Fog Computing",N. Mäkitalo; A. Ometov; J. Kannisto; S. Andreev; Y. Koucheryavy; T. Mikkonen,University of Helsinki; Tampere University of Technology; Tampere University of Technology; Tampere University of Technology; Tampere University of Technology; University of Helsinki,IEEE Software,25 Dec 2017,2018,35,1,30,37,"System design where cyber-physical applications are securely coordinated from the cloud may simplify the development process. However, all private data are then pushed to these remote “swamps,” and human users lose actual control as compared to when the applications are executed directly on their devices. At the same time, computing at the network edge is still lacking support for such straightforward multidevice development, which is essential for a wide range of dynamic cyber-physical services. This article proposes a novel programming model as well as contributes the associated secure-connectivity framework for leveraging safe coordinated device proximity as an additional degree of freedom between the remote cloud and the safety-critical network edge, especially under uncertain environment constraints. This article is part of a special issue on Software Safety and Security Risk Mitigation in Cyber-physical Systems.",1937-4194,,10.1109/MS.2017.4541037,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239948,fog computing;edge computing;programming models;security and trust;proximate connectivity;systems and software design;programmable world;software development;software engineering,Edge computing;Programming;Computer security;Software development;Cyber-physical systems;Computational modeling,cloud computing;data privacy;mobile computing;security of data,secure executions;fog computing;cyber-physical applications;private data;dynamic cyber-physical services;secure-connectivity framework;safety-critical network edge;security risk mitigation;edge computing;cyber-physical systems;cloud computing,,11.0,,12.0,,25 Dec 2017,,,IEEE,IEEE Magazines
2077,717,Games for Requirements Engineers: Analysis and Directions,F. Dalpiaz; K. M. L. Cooper,"Software Systems, Utrecht University, The Netherlands; Independent Scholar, Canada",IEEE Software,20 Dec 2019,2020,37,1,50,59,"The requirements engineering (RE) discipline keeps evolving to cope with increasingly complex systems and shorter development cycles. Using a lightweight analysis framework, we review the current landscape of games for RE and provide guidance for the practitioner interested in improving their skills using innovative game-based RE.",1937-4194,,10.1109/MS.2018.227105450,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356183,Software;Software Engineering;Requirements;specifications;serious games,Games;Requirements engineering;Knowledge engineering;Object recognition;Training data;Task analysis,computer games;formal specification;formal verification;systems analysis,innovative game-based RE;lightweight analysis;development cycles;requirements engineering,,2.0,,16.0,,8 May 2018,,,IEEE,IEEE Magazines
2078,718,What We Know about Testing Embedded Software,V. Garousi; M. Felderer; Ç. M. Karapıçak; U. Yılmaz,Wageningen University; University of Innsbruck; KUASOFT A. Ş.; ASELSAN A. Ş.,IEEE Software,6 Jul 2018,2018,35,4,62,69,"To cost-effectively test embedded software, practitioners and researchers have proposed many test techniques, approaches, tools, and frameworks. However, obtaining an overview of the state of the art and state of the practice in this area is challenging for practitioners or new researchers. In addition, owing to an inadequate overview of what already exists in this area, some companies often reinvent the wheel by designing a test approach that's new to them but already exists. To address these problems, the authors conducted a systematic literature review of this area that covered the testing topics, testing activities, test artifacts, and industries on which the studies focused. The results can benefit both practitioners and researchers by serving as an index to the vast body of knowledge in this important, fast-growing area.",1937-4194,,10.1109/MS.2018.2801541,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405633,software testing;embedded systems;embedded software;systematic literature mapping;systematic literature review;software engineering;software development,Testing;Unified modeling language;Automation;Automotive engineering;Embedded software,embedded systems;program testing,test techniques;test approach;testing topics;test artifacts;embedded software testing;testing activities,,2.0,,15.0,,6 Jul 2018,,,IEEE,IEEE Magazines
2079,719,Requirements Quality Is Quality in Use,H. Femmer; A. Vogelsang,"Qualicen; Systems Engineering, Technical University of Berlin, Germany",IEEE Software,16 Apr 2019,2019,36,3,83,91,Creating a requirements engineering artifact is rarely an end in itself; it is a means to understand and reach the project's goals. So such an artifact's purpose is to support the stakeholders in whatever activities they're performing in the project.,1937-4194,,10.1109/MS.2018.110161823,German Federal Ministry of Education and Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254303,software;software engineering;requirements;specifications;software quality;sqa;general;standards,Stakeholders;Q-factor;ISO Standards;Requirements engineering;Pragmatics,formal specification;systems analysis,requirements quality;requirements engineering artifact;project goals;stakeholders,,1.0,,15.0,,11 Jan 2018,,,IEEE,IEEE Magazines
2080,720,Automated Testing of Simulation Software in the Aviation Industry: An Experience Report,V. Garousi; S. Tasli; O. Sertel; M. Tokgoz; K. Herkiloglu; H. F. E. Arkin; O. Bilir,"Software Engineering, Wageningen University; HAVELSAN; HAVELSAN; HAVELSAN; HAVELSAN; HAVELSAN; HAVELSAN",IEEE Software,17 Jun 2019,2019,36,4,63,75,An industry-academia collaboration developed a test automation framework for aviation simulation software. The technology has been successfully deployed in several test teams.,1937-4194,,10.1109/MS.2018.227110307,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356168,automated testing;test automation;simulation software;aviation industry,Object recognition;Monitoring;Software testing;Aerospace and electronic systems,aerospace computing;aerospace industry;aerospace simulation;program testing,automated testing;aviation industry;experience report;industry-academia collaboration;test automation framework;aviation simulation software;test teams,,3.0,,22.0,,8 May 2018,,,IEEE,IEEE Magazines
2081,721,Overcoming Challenges With Continuous Integration and Deployment Pipelines: An Experience Report From a Small Company,V. Debroy; S. Miller,"Software Engineering, AT&T, Dallas, Texas United States; Dottid, United States",IEEE Software,15 Apr 2020,2020,37,3,21,29,"We moved from a monolithic to a microservice-based architecture for the next generation of our applications at Varidesk. This initiative created challenges such as the inability to scale. In this article, we detail how we tackled the problems.",1937-4194,,10.1109/MS.2019.2947004,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8866741,Microservices;Automation;Cloud computing;DevOps;Continuous Integration;Continuous Deployment;Containerization;Orchestration,Software development management;Computer architecture;Cloud computing;Task analysis;Companies,computer centres;maintenance engineering;power system reliability;service-oriented architecture;solar cell arrays;solar power;solar power stations,microservice-based architecture;deployment pipelines;continuous integration;Varidesk,,,,15.0,,14 Oct 2019,,,IEEE,IEEE Magazines
2082,722,Automatic Recovery of Missing Issue Type Labels,F. Elzanaty; C. Rezk; S. Lijbrink; W. van Bergen; M. Cote; S. McIntosh,"Electrical And Computer Engineering, McGill University, Montreal, H3A 0E9 Quebec, Canada; Software Engineering, McGill University, Montreal, H3A 0E9 Quebec, Canada; Production Engineering, Shopify, Inc., Ottawa, K2P 1L4 Ontario, Canada; Production Engineering, Shopify, Inc., Ottawa, K2P 1L4 Ontario, Canada; Production Engineering, Shopify, Inc., Ottawa, K2P 1L4 Ontario, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada",IEEE Software,19 Apr 2021,2021,38,3,35,42,"Ag ile software organizations empower developers to make appropriate decisions rather than enforce adherence to a process, resulting in incomplete and noisy data in software archives. Since software analytics techniques are trained using this data, automated techniques are required to recover it.",1937-4194,,10.1109/MS.2020.3004060,Natural Sciences and Engineering Research Council of Canada; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121712,,Data models;Computer bugs;Organizations;Feature extraction;Manuals;Training,,,,,,14.0,IEEE,19 Jun 2020,,,IEEE,IEEE Magazines
2083,723,What We Know About Smells in Software Test Code,V. Garousi; B. Kucuk; M. Felderer,"Software Engineering, Wageningen University; Proven Information Technologies Ltd.; University of Innsbruck, Austria",IEEE Software,16 Apr 2019,2019,36,3,61,73,"Test smells are poorly designed tests and negatively affect the quality of test suites and production code. We present the largest catalog of test smells, along with a summary of guidelines, techniques, and tools used to deal with test smells.",1937-4194,,10.1109/MS.2018.2875843,Scientific and Technological Research Council of Turkey; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501942,Software testing;test automation;test scripts;test smells;test anti-patterns;multivocal literature review;systematic literature review,Software testing;Automation;Software development management;Bibliographies;Encoding;Guidelines;Software tools,program testing;software maintenance;source code (software),software test code;test suites;production code;catalog;test smells,,2.0,,23.0,,21 Oct 2018,,,IEEE,IEEE Magazines
2084,724,On Integrating Design Thinking for Human-Centered Requirements Engineering,J. Hehn; D. Mendez; F. Uebernickel; W. Brenner; M. Broy,"Information Management, University of St. Gallen, St. Gallen, Switzerland; Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Blekinge, Sweden; Hasso Plattner Institute, University of Potsdam, Potsdam, Brandenburg, Germany; Information Management, University of St. Gallen, St. Gallen, Switzerland; Technical University of Munich, Germany",IEEE Software,11 Feb 2020,2020,37,2,25,31,"We elaborate on the possibilities and needs to integrate design thinking into requirements engineering, drawing from our research and project experiences. We suggest three approaches for tailoring and integrating design thinking and requirements engineering with complementary synergies and point at open challenges for research and practice.",1937-4194,,10.1109/MS.2019.2957715,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922700,Design Thinking;Requirements Engineering,Requirements engineering;Prototypes;Software design;Design methodology;Organizations,formal specification;formal verification;systems analysis,human-centered requirements engineering;project experiences;design thinking,,3.0,,10.0,,4 Dec 2019,,,IEEE,IEEE Magazines
2085,725,Software Reuse in the Era of Opportunistic Design,T. Mikkonen; A. Taivalsaari,"Software Engineering, University of Helsinki; Nokia Bell Labs",IEEE Software,16 Apr 2019,2019,36,3,105,111,"Opportunistic design, an approach in which people develop new software systems by routinely reusing and combining components that were not designed to be used together, has become very popular. This emergent pattern places focus on largescale reuse and developer convenience with the developers ""trawling"" for most suitable open source components and modules online. The availability of open source assets for almost all imaginable domains has led to software systems in which the visible application code, as written by the application developers themselves, forms only the ""tip of the iceberg,"" compared to the reused bulk that remains mostly unknown to the developers. The actual reuse takes place in an ad hoc, mix-and-match fashion. In this article, we take a look at this increasingly popular approach in light of our industry experiences. We argue that challenges associated with such a development model are quite different from traditional software development and reuse.",1937-4194,,10.1109/MS.2018.2884883,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693072,,Cloud computing;Software systems;Open source software;Computer architecture;Software reusability,Internet;software reliability;software reusability,software reuse;opportunistic design;software systems;emergent pattern places focus;largescale reuse;developer convenience;suitable open source components;modules online;open source assets;imaginable domains;visible application code;application developers;reused bulk;increasingly popular approach;development model;traditional software development,,2.0,,22.0,,16 Apr 2019,,,IEEE,IEEE Magazines
2086,726,IEEE 2430 Non-Functional Sizing Measurements: A Numerical Placebo,A. Abran,"Software Engineering & Information Technology, Ecole de technologie superieure, Montreal, Quebec, Canada",IEEE Software,19 Apr 2021,2021,38,3,113,120,The IEEE 2430 measurement design fails primary school mathematics and produces numerical noise rather than a number with metrological properties required in engineering. This article presents an alternative approach to nonfunctional requirement sizing utilizing the COSMIC ISO 19761 method.,1937-4194,,10.1109/MS.2020.3028061,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210110,IEEE 2430™;non-functional requirements;NFR;SNAP;COSMIC;Function Points;metrology,Measurement units;Size measurement;Complexity theory;Software measurement;ISO Standards;Current measurement,,,,,,15.0,IEEE,30 Sep 2020,,,IEEE,IEEE Magazines
2087,727,An Exploratory Study of Machine Learning Model Stores,M. Xiu; Z. M. J. Jiang; B. Adams,"Electrical Engineering and Computer Science, York University, Toronto, Ontario, Canada; Electrical Engineering and Computer Science, York University, Toronto, Ontario, Canada; Software Engineering, Queen’s University, Kingston, Ontario, Canada",IEEE Software,23 Dec 2020,2021,38,1,114,122,Several organizations have introduced stores that provide public access to pretrained machine learning models and infrastructure. We examine three of them and compare the information they provide against two mobileapp stores and among themselves.,1937-4194,,10.1109/MS.2020.2975159,Natural Sciences and Engineering Research Council of Canada; Institut de Valorisation des Données; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003231,,Training;Software;Machine learning;Documentation;Data models;Computational modeling,learning (artificial intelligence);mobile computing;software quality;user interfaces,pretrained machine learning models;mobileapp stores;machine learning model stores;organizations;public access,,,,15.0,IEEE,19 Feb 2020,,,IEEE,IEEE Magazines
2088,728,The Online Controlled Experiment Lifecycle,A. Fabijan; P. Dmitriev; H. Holmstrom Olsson; J. Bosch,"Malmo University, Malmo, Sweden; Outreach, Seattle, Washington United States; Computer Science and Media Technology, Malmo University, Malmo, Sweden; Software Engineering, Chalmers University of Technology, Goteborg, Sweden",IEEE Software,11 Feb 2020,2020,37,2,60,67,"Unlike other techniques for learning from customers, online controlled experiments (OCEs) establish an accurate and causal relationship between a change and the impact observed. We show that OCEs help optimize infrastructure needs and aid in project planning and measuring team efforts. We conclude that product development should fully integrate the experiment lifecycle to benefit from the OCEs.",1937-4194,,10.1109/MS.2018.2875842,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501922,Data-driven development;A/B tests;online controlled experiments;experiment lifecycle,Software design;Companies;Software development management;Computer science;Product development;Media;Planning;Market research;Customer satisfaction,consumer behaviour;product development;team working,OCE;accurate relationship;causal relationship;online controlled experiment lifecycle;learning;project planning;team efforts,,1.0,,16.0,,21 Oct 2018,,,IEEE,IEEE Magazines
2089,729,Visualizing Change in Agile Safety-Critical Systems,J. Cleland-Huang; A. Agrawal; M. Vierhauser; C. Mayr-Dorn,"Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana 46556 United States; Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana 46556 United States; Software Engineering, Johannes Kepler Universitat Linz, Linz, 4040 Linz, Austria; Software and Systems Engineering, Johannes Kepler Universitat Linz, Linz, 4040 Linz, Austria",IEEE Software,19 Apr 2021,2021,38,3,43,51,"High dependability software systems must be developed and maintained using rigorous safety-assurance practices. By leveraging traceability, we can visualize and analyze changes as they occur, mitigate potential hazards, and support greater agility.",1937-4194,,10.1109/MS.2020.3000104,Austrian Science Fund; United States National Science Foundation; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108244,Agility;Safety-Critical Systems;Visualization;Software Traceability,Hazards;Software;Visualization;Drones;Software safety;Mission critical systems,,,,,,16.0,IEEE,4 Jun 2020,,,IEEE,IEEE Magazines
2090,730,Agile Scalability Engineering: The ScrumScale Method,G. Brataas; G. K. Hanssen; N. Herbst; A. van Hoorn,"Process Innovation, SINTEF Digital, Trondheim, Trondelag, Norway; Process Innovation, SINTEF Digital, Trondheim, Trondelag, Norway; Software Engineering, University of Wurzburg, Germany; Software Technology, University of Stuttgart, Stuttgart, Germany",IEEE Software,21 Aug 2020,2020,37,5,77,84,"Scalability is a property that must be carefully designed into a system. A case study in the largest Norwegian public portal, Altinn, illustrates how developers and scalability experts improved scalability and spent less time during scalability testing. With minor adjustments to an agile development process, stakeholders spend more up-front time together.",1937-4194,,10.1109/MS.2019.2923184,Deutsche Forschungsgemeinschaft; Norges Forskningsråd; German Federal Ministry of Education and Research; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736723,,Scalability;Agile software development;Stakeholders;Databases;Collaboration;Finance;Computer crashes,information retrieval;portals;probability;software development management;software prototyping,agile scalability engineering;ScrumScale method;largest Norwegian public portal;scalability testing;agile development process,,,,15.0,CCBY,14 Jun 2019,,,IEEE,IEEE Magazines
2091,731,Understanding the Working Time of Developers in IT Companies in China and the United States,J. Zhang; Y. Chen; Q. Gong; X. Wang; A. Y. Ding; Y. Xiao; P. Hui,"Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Delft University of Technology, The Netherlands; Aalto University, Finland; University of Helsinki, Finland, and Hong Kong University of Science and Technology, China",IEEE Software,15 Feb 2021,2021,38,2,96,106,"We identified three temporal patterns shown in commit activities among Chinese and American companies and found that Chinese businesses are more likely to follow long work hours than American ones. We also conducted a survey on the trends of, reasons for, and results of overtime work. Our study could provide references for developers to choose workplaces and for companies to make regulations.",1937-4194,,10.1109/MS.2020.2988022,National Natural Science Foundation of China; CERNET Innovation Project; Research Grants Council of Hong Kong; 5GEAR project; FIT project from the Academy of Finland; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068220,working time of developers;overtime;IT company;China;United States;GitHub,Companies;Rhythm;Software;Time-frequency analysis;Social network services;Software engineering;Information technology,human resource management;organisational aspects,United States;temporal patterns;Chinese companies;American companies;overtime work;IT companies;workplaces;online developers,,2.0,,20.0,IEEE,15 Apr 2020,,,IEEE,IEEE Magazines
2092,732,Bumps in the Code: Error Handling During Software Development,T. Lopez; H. Sharp; M. Petre; B. Nuseibeh,"School of Computing and Communications, The Open University, Milton Keynes, MK7 6AA Milton Keynes, United Kingdom of Great Britain and Northern Ireland; School of Computing and Communications, The Open University, Milton Keynes, MK7 6AA Buckinghamshire, United Kingdom of Great Britain and Northern Ireland; Dept of Computing, Open University, Milton Keynes, MK7 6AA Buckinghamshire, United Kingdom of Great Britain and Northern Ireland; School of Computing and Communications, Open University, Milton Keynes, Buckinghamshire, United Kingdom of Great Britain and Northern Ireland",IEEE Software,19 Apr 2021,2021,38,3,26,34,"Problems come up during software development all the time. When developers hit these bumps, they must figure out what has gone wrong. Findings from three studies suggest that the way developers handle errors contributes to professional growth.",1937-4194,,10.1109/MS.2020.3024981,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200759,,Task analysis;Software engineering;Computer bugs;Software tools;Software development management;Problem-solving,,,,,,15.0,IEEE,18 Sep 2020,,,IEEE,IEEE Magazines
2093,733,Digital Transformation - A Primer for Practitioners,G. Doukidis; D. Spinellis; C. Ebert,"Management Science and Technology, Athens University of Economics and Business, Greece; Management Science and Technology, Athens University of Economics and Business, Greece; Vector Consulting Services",IEEE Software,21 Aug 2020,2020,37,5,13,21,"Digital Transformation (DX) has revolutionized entire industries, propelled IT start-ups to stratospheric stock market valuations, and is sustaining legions of consultants evangelizing its message. Yet, beyond the creative disruption, hype, and lip service, we see that many organizations ignore or misapply its principles, ideas, and methods. This gap between theory and practice raises an important responsibility for software engineers and particularly for requirements engineers and software architects. If as a professional you specify and design software-intensive systems that ignore how modern digital technology radically transforms customer experience, business processes, business models, and whole organizations, you are short-changing your employer or client. Based on our industry consulting, government service, and volunteering experience, we provide a taxonomy, a road map, and examples of DX opportunities that will allow you to spot and exploit them.",1937-4194,,10.1109/MS.2020.2999969,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173638,,Biological system modeling;Software engineering;Companies;Training data;Modeling;Digital systems,,,,1.0,,8.0,,21 Aug 2020,,,IEEE,IEEE Magazines
2094,734,Fuzzing: Challenges and Reflections,M. Boehme; C. Cadar; A. ROYCHOUDHURY,"Faculty of IT, Monash University, Clayton, Victoria, Australia; Department of Computing, Imperial College London, London, SW7 2AZ London, United Kingdom of Great Britain and Northern Ireland; Computer Science, National University of Singapore, Singapore, 117417 Singapore, Singapore",IEEE Software,19 Apr 2021,2021,38,3,79,86,We summarize the open challenges and opportunities for fuzzing and symbolic execution as they emerged in discussions among researchers and practitioners in a Shonan Meeting and that were validated in a subsequent survey.,1937-4194,,10.1109/MS.2020.3016773,Australian Research Council; National Research Foundation Singapore; Engineering and Physical Sciences Research Council; H2020 European Research Council; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166552,,Fuzzing;Computer bugs;Software engineering;Security;Industries,,,,,,22.0,CCBY,13 Aug 2020,,,IEEE,IEEE Magazines
2095,735,Can a Machine Learn Through Customer Sentiment?: A Cost-Aware Approach to Predict Support Ticket Escalations,C. Werner; Z. S. Li; D. Damian,"University of Victoria, British Columbia, Canada; University of Victoria, British Columbia, Canada; Computer Science, University of Victoria, British Columbia, Canada",IEEE Software,15 Aug 2019,2019,36,5,38,45,"Given the connection between customer happiness and support ticket escalation, we describe an approach that 1) analyzes the emotions in conversations between a customer and a support analyst and 2) provides organizations with a cost-based mechanism to evaluate machine-learning algorithms trained on emotion-related features to predict support ticket escalations.",1937-4194,,10.1109/MS.2019.2923408,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737665,Sentiment analysis;Natural language;Affective Computing;Machine learning;Modeling and prediction;cost-sensitive learning;data mining;defect escalation;machine learning;software defect escalation prediction,Training data;Software engineering;Sentiment analysis;Machine learning algorithms;Data mining;Emotion recognition,customer services;learning (artificial intelligence),customer sentiment;cost-aware approach;customer happiness;cost-based mechanism;machine-learning algorithms;support ticket escalations;emotion-related features,,2.0,,16.0,,17 Jun 2019,,,IEEE,IEEE Magazines
2096,736,Think Your Artificial Intelligence Software Is Fair? Think Again,R. K. E. Bellamy; K. Dey; M. Hind; S. C. Hoffman; S. Houde; K. Kannan; P. Lohia; S. Mehta; A. Mojsilovic; S. Nagar; K. N. Ramamurthy; J. Richards; D. Saha; P. Sattigeri; M. Singh; K. R. Varshney; Y. Zhang,"IBM Research, Yorktown Heights, New York United States; IBM Research, New Delhi, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Bangalore, India; IBM Research, Bangalore, India; IBM Research, Bangalore, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Bangalore, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Bangalore, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States",IEEE Software,17 Jun 2019,2019,36,4,76,80,"Today, machine-learning software is used to help make decisions that affect people's lives. Some people believe that the application of such software results in fairer decisions because, unlike humans, machine-learning software generates models that are not biased. Think again. Machine-learning software is also biased, sometimes in similar ways to humans, often in different ways. While fair model- assisted decision making involves more than the application of unbiased models-consideration of application context, specifics of the decisions being made, resolution of conflicting stakeholder viewpoints, and so forth-mitigating bias from machine-learning software is important and possible but difficult and too often ignored.",1937-4194,,10.1109/MS.2019.2908514,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738152,,Machine learning;Software engineering;Measurement;Software algorithms;Software testing,decision making;learning (artificial intelligence),artificial intelligence software;machine-learning software;forth-mitigating bias;conflicting stakeholder viewpoints;unbiased models;fair model-assisted decision making,,3.0,,20.0,,17 Jun 2019,,,IEEE,IEEE Magazines
2097,737,"Shockingly Simple:""KEYS"" for Better AI for SE",T. Menzies,"North Carolina State University, Raleigh, North Carolina 27695 United States",IEEE Software,15 Feb 2021,2021,38,2,114,118,"As 2020 drew to a close, I was thinking about what lessons we have learned about software engineering (SE) for artificial intelligence (AI)-things that we can believe now but, in the last century, would have seemed somewhat shocking. One very surprising lesson, at least for me, is the success of the very complex and very simple. At the complex end, there is now much evidence for the value of deep learners for high-dimensional software engineering problems. For example, consider signal processing for autonomous cars. When reasoning over (say) 10,000 wavelets collected from a vision system, then deep learning can automate much of the engineering required to cover all those data.",1937-4194,,10.1109/MS.2020.3043014,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354395,,Artificial intelligence,,,,,,25.0,IEEE,15 Feb 2021,,,IEEE,IEEE Magazines
2098,738,A Novel Approach For Search-Based Program Repair,L. Trujillo; O. M. Villanueva; D. E. Hernández,"Tecnlogico Nacional de Mexico/IT de Tijuana, Tijuana, Mexico; Tecnlogico Nacional de Mexico/IT de Tijuana, Tijuana, Mexico; Tecnlogico Nacional de Mexico/IT de Tijuana, Tijuana, Mexico",IEEE Software,,2021,PP,99,0,0,"In search-based software engineering, automatic bug repair methods use use an objective function that measures a patch’s quality to guide the search. This work presents results of the first study that focuses on solution novelty instead. Novelty search works under the assumption that most real-world problems are intrinsically difficult. By shifting how program patches are evaluated, away from quality and towards novelty, this technique increases a bug repair system’s ability to explore the solution space, produce more viable patches and repair more bugs.",1937-4194,,10.1109/MS.2021.3070552,Consejo Nacional de Ciencia y Tecnología; Tecnologico Nacional de México; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393496,,Computer bugs;Search problems;Maintenance engineering;Standards;Linear programming;Statistics;Space exploration,,,,,,,IEEE,1 Apr 2021,,,IEEE,IEEE Early Access Articles
2099,739,Towards an Adaptive Software Architecture for Archetype-Based Healthcare Applications,M. A. Pereira da Silva; V. Cesário Times; A. M. Costa da Araüjo; P. Caetano da Silva,"Center for Informatics, Federal University of Pernambuco, Recife, Pernambuco, Brazil; Center for Informatics, Federal University of Pernambuco, Recife, Pernambuco, Brazil; Department of Information Systems, Federal University of Alagoas, Penedo, Alagoas, Brazil; Master's Program in Computing, Salvador University, Salvador, BA, Brazil",IEEE Software,,2021,PP,99,0,0,"Self-adaptation gives software systems the ability to adjust their behavior or structure in changing environments such as the health software domain. However, adaptability significantly complicates software implementation and brings great challenges to software engineering. This paper proposes an Adaptive Healthcare Software Architecture (AHSA), which is based on international health standards and offers at-runtime adaptation. Three components (Dynamic Linker, Runtime Locator, and Autonomous Component) have been specified to compose AHSA. A tool called AdaptiveHIS has also been developed to dynamically generate AHSA components, and this generation is exemplified through an algorithm. Within two real-world COVID-19 pandemic healthcare scenarios, an assessment compared the adaptability of AHSA and other software architectures built using state-of-art tools. Results based on the level of system adaptability metric respectively showed that AHSA offered 20% and 72% more adaptability in the two real-world scenarios.",1937-4194,,10.1109/MS.2021.3070418,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391997,Healthcare Applications;Adaptability;Software Architecture;openEHR Archetype,Software;Tools;Runtime;Medical services;Graphical user interfaces;Software architecture;Standards,,,,,,,IEEE,31 Mar 2021,,,IEEE,IEEE Early Access Articles
2100,740,Mind the Gap: On the Relationship Between Automatically Measured and Self-Reported Productivity,M. Beller; V. Orgovan; S. Buja; T. Zimmermann,"Probability, Facebook Inc, Menlo Park, California 94025 United States; Microsoft Corp, Redmond, Washington 98052 United States; Microsoft Corp, Redmond, Washington 98052 United States; Research, Microsoft Corporation, Redmond, Washington 98052 United States",IEEE Software,,2020,PP,99,0,0,"To improve software developers’ productivity has been the holy grail of software engineering research. But before we can claim to have improved it, we must first be able to measure productivity. This is far from trivial. In fact, two separate research lines on software engineers’ productivity have co-existed almost in complete isolation for a long time: automated product and process measures on the one hand and self-reported or perceived productivity on the other hand. In this article, we bridge the gap between the two with an empirical study of 81 software developers at Microsoft.",1937-4194,,10.1109/MS.2020.3048200,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311217,,Productivity;Telemetry;Software;Particle measurements;Encoding;Data models;Atmospheric measurements,,,,,,,IEEE,30 Dec 2020,,,IEEE,IEEE Early Access Articles
2101,741,John Doran on Fixing a Broken Development Process,J. Jung,Security Industry,IEEE Software,29 Nov 2018,2018,35,6,77,80,"In this excerpt from Episode 332 of Software Engineering Radio, host Jeremy Jung talks with guest John Doran about his experiences repairing the engineering process at Phorest, a Dublin-based company that books appointments in the hair and beauty salon industry. In this excerpt, Doran discusses how technical debt threatened to sink the company, how the company diagnosed the problems, and how it fixed them by changing technology, process, and culture. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2018.4321233,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552646,John Doran;Phorest;technical debt;continuous integration;CI;software engineering;software development;Software Engineering Radio,Interviews;Software development;Software engineering,software engineering,broken development process;technical debt;Dublin-based company;Phorest;engineering process;Software Engineering Radio,,,,0.0,,29 Nov 2018,,,IEEE,IEEE Magazines
2102,742,Collaborative Modeling in Software Engineering,H. Muccini; J. Bosch; A. van der Hoek,"University of L’Aquila; Chalmers University of Technology; University of California, Irvine",IEEE Software,29 Nov 2018,2018,35,6,20,24,"The topic of collaborative modeling has long been relevant in software. Collaborative facilities are part and parcel of modeling tools, and every day hundreds of thousands of developers engage in collaborative modeling of some sort. This theme issue contains four articles spanning a variety of areas in collaborative modeling. The first article offers a somewhat classic approach to handling collaborative-design conflicts. The second one addresses securely sharing only parts of a collaborative model. The third discusses whether distance still matters in collaborative design. The fourth introduces a timely approach to collaborative modeling through chatbots.",1937-4194,,10.1109/MS.2018.4321244,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552641,collaborative modeling;collaborative software engineering;collaborative design;chatbots;social networks;software engineering;software development,Special issues and sections;Software engineering;Software development;Collaborative software,,,,,,9.0,,29 Nov 2018,,,IEEE,IEEE Magazines
2103,743,50 Years of Software Engineering,H. Erdogmus; N. Medvidović; F. Paulisch,Carnegie Mellon University; University of Southern California; Siemens Healthineers,IEEE Software,27 Sep 2018,2018,35,5,20,24,"This theme issue on software engineering’s 50th anniversary presents a range of contributions—from pioneers and well-established software engineers, to younger contributors whose imprint on the field is perhaps yet to come. These contributions come in a variety of formats that provide a balanced look at our field’s past, present, and likely future. The topics include both timeless ideas that appeared to fade for a while, only to pop up again in a new incarnation, and entirely new paradigms that have disrupted the field.",1937-4194,,10.1109/MS.2018.3571240,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474511,software engineering;software development,Special issues and sections;Software engineering;History;IEEE publishing,,,,1.0,,7.0,,27 Sep 2018,,,IEEE,IEEE Magazines
2104,744,Ben Sigelman on Distributed Tracing [Software Engineering Radio],R. Blumen,,IEEE Software,14 Jan 2019,2019,36,1,98,101,"We bring you this month one of my own shows, Software Engineering Radio Episode 337, featuring guest Ben Sigelman. Sigelman is the cofounder and chief executive officer of LightStep, where he is building reliability management software, and a coauthor of the OpenTracing project. We discuss tracing in general and distributed tracing, which involves the propagation of tracing across process boundaries in a distributed system. The discussion covers the basics of tracing, how distributed tracing is different, the instrumentation required to collect tracing data, what is collected and how, where the data go, and use cases for the data itself, including monitoring, analytics, and capacity planning. The excerpt presented here contains about one half of the interview, with the remaining half available for download from our website or via RSS.",1937-4194,,10.1109/MS.2018.2880598,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611462,,Interviews;Software engineering;Distributed databases;Reliability engineering,,,,,,0.0,,14 Jan 2019,,,IEEE,IEEE Magazines
2105,745,Release Engineering 3.0,B. Adams; S. Bellomo; C. Bird; B. Debić; F. Khomh; K. Moir; J. O’Duinn,Polytechnique Montreal; Software Engineering Institute; Microsoft; Google; Polytechnique Montreal; Mozilla; CivicActions.com,IEEE Software,12 Mar 2018,2018,35,2,22,25,"This theme issue aims to stimulate industry practitioners and researchers to reflect on what future release-engineering practices and tools could look like and how they could evolve out of more-advanced forms of current release engineering. Each of the four articles in this issue highlights a different facet of release engineering, with two articles focusing on fundamental technologies and practices and two articles discussing new application domains.",1937-4194,,10.1109/MS.2018.1661327,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314150,release engineering;continuous experimentation;build systems;continuous delivery;over-the-air software updates;swarm robots;software engineering;software development,Special issues and sections;Software engineering;Product life cycle management;Software development management,,,,2.0,,1.0,,12 Mar 2018,,,IEEE,IEEE Magazines
2106,746,"Gender, Sentiment and Emotions, and Safety-Critical Systems",J. Carver; R. Capilla; B. Penzenstadler; A. Serebrenik; A. Valdezate,"University of Alabama; Rey Juan Carlos University of Madrid; California State University, Long Beach; Eindhoven University of Technology; Ibermática and Rey Juan Carlos University of Madrid",IEEE Software,29 Nov 2018,2018,35,6,16,19,This issue’s article reports from the 40th International Conference on Software Engineering (ICSE 18) and the 17th International Conference on Software Reuse (ICSR 18). The ICSE papers focus on sociotechnical issues related to gender and sentiment or emotion. The ICSR paper focuses on safety-critical systems.,1937-4194,,10.1109/MS.2018.4321243,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552648,40th International Conference on Software Engineering;17th International Conference on Software Reuse;gender;gender stereotypes;GenderMag;sentiment;sentiment analysis;Stack Overflow;Senti4SD;software product lines;SPL;software product line engineering;SPLE;variability management;safety-critical systems;software engineering education;software reuse;software development;software engineering;Practitioners’ Digest,,,,,1.0,,,,29 Nov 2018,,,IEEE,IEEE Magazines
2107,747,Nate Taggart on Serverless,K. Bhatia,BCG Digital Ventures,IEEE Software,6 Jul 2018,2018,35,4,101,104,"In this excerpt from Software Engineering Radio, Nate Taggart, cofounder and CEO of Stackery, discusses serverless—the ability to purchase function as a service in which the cloud provider assumes responsibility for providing a server and an execution environment on demand to run a piece of code. To hear the full interview, visit www.se-radio.net or access our archives via RSS at feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2018.2801544,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405632,Nate Taggart;serverless;Software Engineering Radio;software engineering;software development,Software engineering;Computational modeling;FAA,,,,1.0,,,,6 Jul 2018,,,IEEE,IEEE Magazines
2108,748,Being a Software Developer,D. Spinellis,Athens University of Economics and Business,IEEE Software,6 Jul 2018,2018,35,4,4,7,"If you want to be a professional developer, you'll need to continuously invest substantial time to acquire highly specialized knowledge and develop diverse cognitive and interpersonal skills. A university can kindle your passion and provide incentives to expand your horizons, and your employer may support specialized training. But in the end, becoming a professional software developer is your decision and responsibility.",1937-4194,,10.1109/MS.2018.2801555,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405631,professional development;career development;job skills;From the Editor;software engineering;software development,,cognition;professional aspects;software engineering,interpersonal skills;specialized training;professional software developer;software developer;cognitive skills;knowledge acquisition,,1.0,,1.0,,6 Jul 2018,,,IEEE,IEEE Magazines
2109,749,The Challenges and Practices of Release Engineering,D. Spinellis,Athens University of Economics and Business,IEEE Software,12 Mar 2018,2018,35,2,4,7,"Release-engineering teams are responsible for building and delivering software to the customer and for enabling its development on an industrial scale. This has always been a tall order. In modern software development, a number of factors make release engineering even more challenging. Thankfully, following a handful of established practices lets us address these challenges and deliver software reliably, dependably, and efficiently.",1937-4194,,10.1109/MS.2018.1661312,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314162,release engineering;software engineering;software development;From the Editor,,software development management;software engineering;software reliability,release-engineering teams;industrial scale;modern software development,,,,3.0,,12 Mar 2018,,,IEEE,IEEE Magazines
2110,750,Complexity: Let's Not Make This Complicated,A. Hindle,,IEEE Software,21 Feb 2019,2019,36,2,130,132,"This article discusses the simplicity in agile software, the relationship between architectural patterns and complexity, the value of simplicity in software engineering research, and why we should refer to the formerly perceived complexity in software as complicated software. Complex software in software engineering typically refers to complicated code. Most measures of complexity are measures of information content in the code, whether it is McCabe's cyclomatic complexity measuring branching or Halstead's volume measuring the information within a block of code- Halstead's volume is very similar to the entropy of tokens multiplied by the number of tokens in a code block.",1937-4194,,10.1109/MS.2018.2883875,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648275,,Software engineering;Complexity theory;Software design,software architecture;software prototyping;source code (software),entropy;code block;Halstead's volume;McCabe's cyclomatic complexity;software engineering;complicated software;perceived complexity;software engineering research;architectural patterns;architectural complexity;agile software,,,,5.0,,21 Feb 2019,,,IEEE,IEEE Magazines
2111,751,Sentiment and Emotion in Software Engineering,N. Novielli; A. Serebrenik,University of Bari; Eindhoven University of Technology,IEEE Software,15 Aug 2019,2019,36,5,6,23,"We are glad to present the ""Sentiment and Emotion in Software Engineering"" special issue of <italic>IEEE Software</italic>. In recent years, this topic has gained attention from both the research community and industry. Indeed, academic researchers have organized a number of highly successful workshops, such as the International Workshop on Emotional Awareness in Software Engineering (SEmotion) in 2016-2019. The topic was also explored in a special issue of <italic>The Journal of Systems and Software</italic>.<sup>1</sup> Both small and large companies have considered emotions in some aspects of their work. For example, Microsoft considers emotions in the context of inclusive hiring and support of neurodiverse developers.<sup>2</sup> Meanwhile, SkyTV aims at enhancing productivity of teams<sup>3</sup> by increasing their emotional awareness. Yet another company, source{d}, designs techniques for detection of sentiment in source-code repositories.<sup>4</sup>",1937-4194,,10.1109/MS.2019.2924013,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802324,,Special issues and sections;Emotion recognition;Sentiment analysis;Computational linguistics;Information analysis;Machine learning;Software development management,,,,6.0,,11.0,,15 Aug 2019,,,IEEE,IEEE Magazines
2112,752,Ur-Technical Debt,G. Fairbanks,"Software Engineering, Google",IEEE Software,19 Jun 2020,2020,37,4,95,98,"These days, everyone uses the term technical debt. It's so prevalent that we shorten it to tech debt tech debt or even just TD. Tech debt is also hacky code, code written by novices, code written without consideration of software architecture (so-called big balls of mud), and code with antipatterns flagged by static analysis tools.",1937-4194,,10.1109/MS.2020.2986613,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121630,,Computer architecture;Software engineering;Codes,program diagnostics;source code (software),static analysis tools;hacky code;tech debt;technical debt,,2.0,,2.0,,19 Jun 2020,,,IEEE,IEEE Magazines
2113,753,Under the Covers of IEEE Software,D. Spinellis,Athens University of Economics and Business,IEEE Software,25 Dec 2017,2018,35,1,4,7,"Ecosystems that thrive are those whose members contribute more than they take away. Judging by the growth of its offerings and volunteers, IEEE Software is clearly such a case: over the past year, more than 1,500 people have contributed to it as authors, reviewers, editors, podcast hosts and guests, advisors, curators, and many other roles. Here, Editor in Chief Diomidis Spinellis discusses what makes Software tick and how can you participate in its community of volunteers.",1937-4194,,10.1109/MS.2017.4541035,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239946,IEEE Software;Software Engineering Radio;SE-Radio;IEEE Software Blog;software engineering;software development;From the Editor,,,,,1.0,,1.0,,25 Dec 2017,,,IEEE,IEEE Magazines
2114,754,The Success of a Heavenly Marriage,D. Spinellis,Athens University of Economics and Business,IEEE Software,27 Sep 2018,2018,35,5,3,6,"For a field that sprang out of a so-called software crisis, software engineering has done rather well over the past half-century. By riding on the coattails of Moore’s law, it has progressed phenomenally. The field’s achievements are visible through the large, complex, yet effective software systems that power our everyday lives. By looking at the drivers of the field’s progress and taking stock of its achievements, we can appreciate the challenges in front of us and confidently plan for the future. This article is part of a theme issue on software engineering’s 50th anniversary.",1937-4194,,10.1109/MS.2018.3571251,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474499,software engineering;software development;From the Editor,,,,,,,0.0,,27 Sep 2018,,,IEEE,IEEE Magazines
2115,756,State of the Journal,M. Dwyer,,IEEE Transactions on Software Engineering,8 Jan 2018,2018,44,1,1,2,Presents the state of the journal for this issue of the publication.,1939-3520,,10.1109/TSE.2017.2778898,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249614,,,,,,,,,,8 Jan 2018,,,IEEE,IEEE Journals
2116,758,The Editor’s Retrospective,D. Spinellis,Athens University of Economics and Business,IEEE Software,29 Nov 2018,2018,35,6,4,7,"Outgoing Editor in Chief Diomidis Spinellis reviews the past four years, looking on what went well for the magazine, what could be improved, and what the magazine’s volunteers can do to make IEEE Software an even better publication over the coming years.",1937-4194,,10.1109/MS.2018.4321238,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552645,software engineering;software development;From the Editor,,,,,,,5.0,,29 Nov 2018,,,IEEE,IEEE Magazines
2117,759,Self-Evolving Software Architectures,D. Spinellis,Athens University of Economics and Business,IEEE Software,4 May 2018,2018,35,3,4,7,Nature provides the inspiration for self-evolving software architectures that can deal with the increasing size and complexity of software systems.,1937-4194,,10.1109/MS.2018.2141027,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354428,self-evolving software;self-evolving software architecture;software architecture;software engineering;software development;From the Editor,,,,,,,2.0,,4 May 2018,,,IEEE,IEEE Magazines
2118,760,Scylladb optimizes database architecture to maximize hardware performance,N. Suneja,"Amazon Web Services, Palo Alto, California United States",IEEE Software,17 Jun 2019,2019,36,4,96,100,"In Episode 354 of “Software Engineering Radio,” guest Avi Kivity, chief technology officer of ScyllaDB, talks with host Ninchant Suneja about ScyllaDB and what makes it a high-performance version of Cassandra, a distributed key-value data store. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http:// feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2019.2909854,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738153,,Interviews;Computer architecture;Distributed databases,database management systems;storage management,database architecture;hardware performance;Software Engineering Radio;distributed key-value data store;Cassandra,,,,0.0,,17 Jun 2019,,,IEEE,IEEE Magazines
2119,761,Better Code Reviews With Design by Contract,G. Fairbanks,"Software Engineering, Google, United States",IEEE Software,22 Oct 2019,2019,36,6,53,56,"Design by contract (DBC) is a technique that improves the quality of your team's code. It yields code with both a logical and a procedural nature, where the contracts state declaratively what will happen, and the implementations procedurally cause the desired effect. The team can reason either logically, by using the contracts, or procedurally, by following the code line by line, but the former allows them to reason about far larger programs. It also creates conditions for deliberate practice so developers using DBC grow their design skills faster.",1937-4194,,10.1109/MS.2019.2934192,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880061,,Encoding;Cognition;Pragmatics;Software quality,contracts;reasoning about programs;software quality;source code (software),DBC;design skills;code reviews;procedural nature;code line;design by contract;team code quality,,,,3.0,,22 Oct 2019,,,IEEE,IEEE Magazines
2120,762,The Voice of the Developer,I. Ozkaya,Carnegie Mellon Software Engineering Institute,IEEE Software,15 Aug 2019,2019,36,5,3,5,"Developers are seldom shy about expressing how they feel about the current task at hand, especially when the task triggers stress and impacts productivity negatively:",1937-4194,,10.1109/MS.2019.2926545,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802319,,,,,,1.0,,8.0,,15 Aug 2019,,,IEEE,IEEE Magazines
2121,763,"Emerging Trends, Challenges, and Experiences in DevOps and Microservice APIs",U. Zdun; E. Wittern; P. Leitner,"Software Architecture, University of Vienna, Vienna, Austria; IBM, Hamburg, Germany; Software Engineering, Chalmers University of Technology",IEEE Software,20 Dec 2019,2020,37,1,87,91,"In August 2019, we organized the second Vienna Software Seminar (VSS) with the topic ""DevOps and Microservice APIs.""<sup>1</sup> Embracing the positive reception of its first iteration in 2017,<sup>2</sup> VSS is an opportunity for attendees to discuss recent software technologies, practices, and related research. The seminar's 34 participants included a mix of practitioners and academics, who were invited based on their roles and experiences. The explicit intention of the seminar was to provide ample opportunities for exchange and communication: six themed sessions consisted of one invited keynote and two lightning talks, giving different perspectives on the session?s topic and (ideally) sparking ideas for follow-up discussions. After the talks, all participants decided on subtopics for two to three breakout sessions (i.e., informal, self-organized discussions among interested participants). Breakout session topics included microservice security, tooling for application programming interface (API) evolution, serverless programming models, and identification of microservices using domaindriven design. The sessions provided opportunities for detailed discussions and identifying challenges to address in future collaborations. Toward the end of each session, all participants gathered once more to summarize the breakout discussions. Additional opportunities for communication were provided during shared lunch breaks and social events in the evenings.",1937-4194,,10.1109/MS.2019.2947982,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938118,,,,,,,,18.0,,20 Dec 2019,,,IEEE,IEEE Magazines
2122,764,"Interact, Collaborate, Debate",I. Ozkaya,"Carnegie Mellon Software Engineering Institute, United States",IEEE Software,22 Oct 2019,2019,36,6,3,6,"How information is shared has changed signifi cantly due to technology and will continue to change. The pace of innovation in and dependence on software further creates an environment in which models of knowledge production and consumption are continually challenged. Information gets distributed quicker, almost real time, through myriad available social media channels.",1937-4194,,10.1109/MS.2019.2936955,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880052,,,,,,,,6.0,,22 Oct 2019,,,IEEE,IEEE Magazines
2123,765,James Smith on Software Bugs and Quality,P. Raghavan,,IEEE Software,19 Apr 2021,2021,38,3,142,144,"Presents an interview conducted with James Smith of Bugsnag regarding software bugs and quality. Host Priyanka Raghavan spoke with Smith on topics including causes, types, and history of bugs; user experience and environments causing different bugs; and measuring, benchmarking, and fixing bugs based on data. We provide summary excerpts below; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio ",1937-4194,,10.1109/MS.2021.3058704,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407307,,Interviews;Computer bugs;Software engineering;Mobile applications,,,,,,0.0,IEEE,19 Apr 2021,,,IEEE,IEEE Magazines
2124,766,A Manifesto for Energy-Aware Software,A. Fonseca; R. Kazman; P. Lago,"Faculdade de Ciencias, Universidade de Lisboa, Portugal; University of Hawaii, Honolulu, United States; Vrije Universiteit Amsterdam, The Netherlands",IEEE Software,22 Oct 2019,2019,36,6,79,82,"According to recent estimates, computing and communications could account for 20% of energy usage globally by 2025.1 This trend shows no sign of slowing. The annual growth in power consumption of Internet-connected devices is 20%. Data centers alone are now accounting for more than 3% of global emissions. Even if you are not worried about this trend on the mega scale, you are likely concerned with the power consumption of the devices in your pocket, on your wrist, and in your ears. Software, hardware, and network attributes all contribute to power usage, but little attention has been given to this topic by the information and communications technology (ICT) community.",1937-4194,,10.1109/MS.2019.2924498,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880037,,Software engineering;Energy efficiency;Energy consumption;Market research;Complexity theory;Information and communication technology,computer centres;Internet;power aware computing;power consumption,Internet-connected devices;data centers;energy-aware software;information and communications technology community;ICT community,,3.0,,7.0,,22 Oct 2019,,,IEEE,IEEE Magazines
2125,767,Howard Chu on Lightning Memory-Mapped Database,G. Henry,SureVoIP,IEEE Software,22 Oct 2019,2019,36,6,83,87,Gavin Henry: What's the history of LMDB [Lightning Memory-Mapped Database]?,1937-4194,,10.1109/MS.2019.2936273,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880032,,Databases;Software engineering;Computer crashes;History,,,,1.0,,0.0,,22 Oct 2019,,,IEEE,IEEE Magazines
2126,768,Jonathan Boccara on Legacy Code,A. G. Bell,Tenable,IEEE Software,15 Aug 2019,2019,36,5,80,84,"Presents an interview conducted with Jonathan Boccara, author of The Legacy Code Programmer’s Toolbox. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2019.2922802,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802867,,Interviews;Software engineering;Source coding;Operating systems,,,,,,0.0,,15 Aug 2019,,,IEEE,IEEE Magazines
2127,769,Microservices: The Journey So Far and Challenges Ahead,P. Jamshidi; C. Pahl; N. C. Mendonça; J. Lewis; S. Tilkov,Carnegie Mellon University; Free University of Bozen-Bolzano; University of Fortaleza; ThoughtWorks; INNOQ,IEEE Software,4 May 2018,2018,35,3,24,35,"Microservices are an architectural approach emerging out of service-oriented architecture, emphasizing self-management and lightweightness as the means to improve software agility, scalability, and autonomy. This article examines microservice evolution from the technological and architectural perspectives and discusses key challenges facing future microservice developments.",1937-4194,,10.1109/MS.2018.2141039,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354433,microservices;service-oriented architecture;SOA;domain-driven design;DDD;model-driven development;MDD;architectural antipatterns;legacy systems;software development;software engineering,Special issues and sections;Service computing;Software development,,,,43.0,,23.0,,4 May 2018,,,IEEE,IEEE Magazines
2128,770,Matt Lacey on Mobile App Usability,G. Henry,"SureVoIP, United Kingdom",IEEE Software,15 Feb 2021,2021,38,2,134,136,"Presents an interview conducted with Matt Lacey, author of Usability Matters. Lacey discusses usability for consumers and business or in-house users. Host Gavin Henry spoke with Lacey about the six components of great app experiences, things every app should do, native apps, password managers, accessibility, feedback, telemetry, locations, nonmobile devices, examples of good and bad apps, testing, connectivity, user involvement during development, and usability and software engineering. We provide summary excerpts below; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.—Robert Blumen",1937-4194,,10.1109/MS.2020.3042424,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354393,,Interviews;Computer applications;Mobile communication,,,,,,0.0,IEEE,15 Feb 2021,,,IEEE,IEEE Magazines
2129,771,Johnathan Nightingale on Scaling Engineering Management,T. Kimmel,GitPrime,IEEE Software,16 Apr 2019,2019,36,3,120,124,"In Episode 352 of “Software Engineering Radio,” guest Johnathan Nightingale talks with host Travis Kimmel about scaling engineering management. Portions not included here go into more depth about the organizational structure of engineering teams, seniority in management, career growth, management titles, predictability in management, and goals. To hear the full interview, visit http://www.se-radio.net.",1937-4194,,10.1109/MS.2019.2899530,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693083,,Interviews;Engineering management,,,,,,0.0,,16 Apr 2019,,,IEEE,IEEE Magazines
2130,772,Justin Richer on OAuth,G. Henry,SureVoIP,IEEE Software,20 Dec 2019,2020,37,1,98,100,"In Episode 376 of “Software Engineering Radio,” Justin Richer, lead author of OAuth2 in Action and editor of OAuth extensions RFC 7591, 7592, and 7662, discusses the key technical features of the OAuth 2.0 protocol for authorization. Gavin Henry spoke with Richer about browser-based OAuth2, types of tokens, OpenID Connect, PKCE, JavaScript Object Notation Web Token pros and cons, where to store them, client secrets, single-page apps, mobile apps, current best practices, OAuth.XYZ, HEART, MITREid, token validation, dynamic client registration, the decision factors of the various types of authorization grants to use, and what is next for OAuth. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http:// feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2019.2949648,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938121,,Interviews;Authorization;Best practices;Token networks,,,,,,0.0,,20 Dec 2019,,,IEEE,IEEE Magazines
2131,773,Boris Cherny on TypeScript,N. Black,Sleeperbot,IEEE Software,11 Feb 2020,2020,37,2,98,100,"In Episode 384 of “Software Engineering Radio,” Boris Cherny, author of Programming TypeScript, speaks with Nate Black, explaining how TypeScript can scale JavaScript projects to larger teams, larger code bases, and across devices. TypeScript is a gradually typed language, allowing you to add compile-time verification to a JavaScript project bit by bit. TypeScript aims to be practical by catching common mistakes but without adding too much burden on the programmer. Other topics include: structural typing, type refinement and programmer intuition, when to use escape hatches and how to ban them, interoperability with JavaScript, and using TypeScript with frameworks such as Angular, React, and React Native. We provide summary excerpts below; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2019.2958155,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994835,,Java;Computer languages,,,,,,0.0,,11 Feb 2020,,,IEEE,IEEE Magazines
2132,774,Chris McCord on Phoenix's LiveView Functionality,A. Conrad,"Engineering, Indigo",IEEE Software,15 Apr 2020,2020,37,3,98,100,"In Episode 394 of “Software Engineering Radio,” Chris McCord, creator of the Phoenix framework and author of Programming Phoenix 1.4, discusses Phoenix’s LiveView functionality. Host Adam Conrad spoke with McCord about how LiveView was created, use cases for integrating LiveView with Phoenix applications, the benefits and drawbacks of LiveView in comparison to such frameworks as React, Angular, and Vue, and the internal workings of LiveView. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner .com/se-radio.",1937-4194,,10.1109/MS.2020.2968207,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068368,,Interviews,,,,,,0.0,,15 Apr 2020,,,IEEE,IEEE Magazines
2133,775,Jeremy Miller on Waterfall Versus Agile,J. Doolittle,,IEEE Software,19 Jun 2020,2020,37,4,107,C3,"Jeremy Miller is a senior software architect at Calavista Software. He is involved in open source .NET development as the author of StructureMap and Storyteller and as the lead developer of Marten. In Episode 401 of “Software Engineering Radio,” host Jeff Doolittle spoke with Miller about Waterfall versus Agile, Extreme Programming, pair programming, specialization and self-contained teams, the emergence of Scrum, YAGNI, Agile teams, reversibility, nonfunctional requirements, integration testing, and abstraction and encapsulation. We provide summary excerpts in this column; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.",1937-4194,,10.1109/MS.2020.2987493,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121615,,Interviews;Software architecture,,,,1.0,,0.0,,19 Jun 2020,,,IEEE,IEEE Magazines
2134,776,Blockchain and Smart Contract Engineering,X. Larrucea; C. Pautasso,"Basque Research and Technology Alliance, TECNALIA; Software, USI Faculty of Informatics, Lugano, Switzerland",IEEE Software,21 Aug 2020,2020,37,5,23,29,"Blockchains help to build trust among a decentralized network of unknown and untrusted peers who need to agree on a common protocol and trust the correctness and compatibility of the corresponding software implementations. The software engineering discipline cannot ignore this trend, as it fundamentally affects the way software is designed, developed, deployed, and delivered.1 As with the emergence of the Internet, software smart contracts for solving new classes of real-world problems, as opposed to introducing blockchains everywhere, where they may be unnecessary, or provide an inefficient and environmentally unsound solution.4",1937-4194,,10.1109/MS.2020.3000354,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173634,,Special issues and sections;Smart contracts;Software;Bitcoin;Peer-to-peer computing;Computer architecture;Blockchain,,,,,,32.0,,21 Aug 2020,,,IEEE,IEEE Magazines
2135,777,2017 Index IEEE Transactions on Software Engineering Vol. 43,,,IEEE Transactions on Software Engineering,8 Jan 2018,2018,44,1,1,9,Presents the 2017 subject/author index for this publication.,1939-3520,,10.1109/TSE.2017.2784782,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249567,,,,,,,,,,8 Jan 2018,,,IEEE,IEEE Journals
2136,778,Intellectual Control [Pragmatic Designer],G. Fairbanks,"Software Engineering, Google",IEEE Software,14 Jan 2019,2019,36,1,91,94,"In the early days of software engineering, Edsger Dijkstra warned us not to let the size and complexity of our programs cause us to lose “intellectual control” due to the limited nature of our minds. To my knowledge, he never defined precisely what intellectual control was. Our software today is staggeringly larger than the programs of the 1960s, so does that mean we have it under our intellectual control, or did we find ways to make progress without Dijkstra's high standards? I see signs that we have some software that is under intellectual control and other software that is not. In this column, I'm going to discuss how we can recognize these two categories, what happens when engineers on a project have different attitudes about intellectual control, some advice on when we probably should insist on it, and some ideas about how we achieve it.",1937-4194,,10.1109/MS.2018.2874294,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611447,,Software engineering;Standards;Project management;Intelligent control,software engineering,software engineering;program complexity;intellectual control,,2.0,,1.0,,14 Jan 2019,,,IEEE,IEEE Magazines
2137,779,Actionable Analytics for Software Engineering,Y. Yang; D. Falessi; T. Menzies; J. Hihn,"Stevens Institute of Technology; California Polytechnic State University, San Luis Obispo; North Carolina State University; Jet Propulsion Laboratory",IEEE Software,25 Dec 2017,2018,35,1,51,53,"Although intensive research on software analytics has been going on for nearly a decade, a repeated complaint in software analytics is that industrial practitioners find it hard to apply the results generated from data science. This theme issue aims to reflect on actionable analytics for software engineering and to document a catalog of success stories in which analytics has been proven actionable and useful, in some significant way, in an organization. This issue features five articles covering promising analytical methods for improving change triage, strategic maintenance, and team robustness, as well as the success stories of applying analytical tools during an organizational transformation.",1937-4194,,10.1109/MS.2017.4541039,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239931,actionable analytics;context-driven software engineering;software analytics;change triage;agile development;DevOps;software engineering;software development,,,,,4.0,,4.0,,25 Dec 2017,,,IEEE,IEEE Magazines
2138,780,The Behavioral Science of Software Engineering and Human–Machine Teaming,I. Ozkaya,"Software Engineering, Carnegie Mellon",IEEE Software,23 Oct 2020,2020,37,6,3,6,"Designing and sustaining sociotechnical systems where relationships among humans, machines, and environmental aspects are intertwined is not new to software engineering. Emery and Trist1 coined the term sociotechnical systems in 1960 to draw attention to the need for people, machines, and context to all be considered when developing and sustaining these systems. Interactions and dependencies in sociotechnical systems get complex quickly as the interdisciplinary nature of such systems drive different design priorities and information flow mechanisms: sociologists see social systems, psychologists observe them as cognitive systems, computer scientists approach them as information systems, and engineers see the hardware systems.2 All of these perspectives are not only valid but also are essential elements of sociotechnical systems.",1937-4194,,10.1109/MS.2020.3019190,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238651,,,,,,,,10.0,,23 Oct 2020,,,IEEE,IEEE Magazines
2139,781,Protecting the Health and Longevity of the Peer-Review Process in the Software Engineering Community,I. Ozkaya,"Software Engineering, Carnegie Mellon, Pittsburg, Pennsylvania United States",IEEE Software,23 Dec 2020,2021,38,1,3,6,"Peer review is the evaluation of scientific, academic, and professional work by other experts in the same field. The main purpose of the peerreview process is to maintain the integrity of the scientific process and increase the quality of the work product by providing timely, professional, and unbiased feedback. The most substantive scientific activity that relies on the success and integrity of the peer-review process is, by all means, scientific publications. All software engineering conferences and workshops as well as all journals and magazines, including IEEE Software's focus and feature articles, select which articles to publish after a peer-review process.",1937-4194,,10.1109/MS.2020.3028681,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305906,,,,,,,,8.0,IEEE,23 Dec 2020,,,IEEE,IEEE Magazines
2140,783,Requirements Engineering (RE) for Social Good: RE Cares [Requirements],A. Dekhtyar; J. Huffman Hayes; I. Hadar; E. Combs; A. Ferrari; S. Gregory; J. Horkoff; M. Levy; M. Nayebi; B. Paech; J. Payne; M. Primrose; P. Spoletini; S. Clarke; C. Brophy; D. Amyot; W. Maalej; G. Ruhe; J. Cleland-Huang; D. Zowghi,"California Polytechnic University, San Luis Obispo, United States; Computer Science, University of Kentucky, United States; University of Haifa; Lexmark; Istituto di Scienza e Tecnologie dell’Informazione; Intel Corporation; Chalmers; Shenkar College of Engineering and Design; Ecole Polytechnique de Montreal, Canada; Software Engineering, Heidelberg University; University of Kentucky, United States; Intel Corporation; Kennesaw State University; Mutual Aid Alberta, Canada; Celsus Management, Inc.; University of Ottawa, Canada; University of Hamburg; University of Calgary, Canada; University of Notre Dame; Software Engineering, University of Technology Sydney, Australia",IEEE Software,14 Jan 2019,2019,36,1,86,94,"As researchers and teachers and practitioners, we “software types” excel at multitasking. This, in part, led us to ask the question: Can one attend a software engineering conference and do something good for society? We found the answer to be a resounding yes. In this article, we present our first experience of running RE Cares, a conference collocated event. This event included a workshop, conference sessions, and a hackathon for developing an application to support emergency field activity for Mutual Aid Alberta, a nonprofit organization coordinating natural disaster responses in the Canadian province.",1937-4194,,10.1109/MS.2018.2874327,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611463,,,disasters;emergency management;formal specification;software engineering,requirements engineering;social good;software types;multitasking;software engineering conference;conference collocated event;emergency field activity;Mutual Aid Alberta;RE Cares;nonprofit organization;natural disaster responses;Canadian province,,3.0,,1.0,,14 Jan 2019,,,IEEE,IEEE Magazines
2141,786,2018 Index IEEE Transactions on Software Engineering Vol. 44,,,IEEE Transactions on Software Engineering,8 Jan 2019,2019,45,1,1,9,Presents the 2018 subject/author index for this publication.,1939-3520,,10.1109/TSE.2018.2887195,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8605397,,,,,,,,,,8 Jan 2019,,,IEEE,IEEE Journals
2142,788,Software Engineering in Society,R. Kazman; L. Pasquale,"Information Technology, University of Hawaii, Manoa, Hawaii United States; Computer Science, University College Dublin, Dublin, Ireland",IEEE Software,20 Dec 2019,2020,37,1,7,9,"Modern Software Systems pervade our lives. They have become more open and hyperconnected, manage large amounts of our personal data, and are used to support the lives of individuals and communities and the functions of businesses and governments. They are a part of our society and play an important role in shaping it.",1937-4194,,10.1109/MS.2019.2949322,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938101,,,,,,,,0.0,,20 Dec 2019,,,IEEE,IEEE Magazines
2143,789,Behavioral Science of Software Engineering,M. Petre; J. Buckley; L. Church; M. -A. Storey; T. Zimmermann,"Computing and Communications, The Open University; Computer Science and Information Systems, University of Limerick, Ireland; Computer Science and Technology, University of Cambridge, United Kingdom; Applied Data Science, University of Victoria, Canada; Microsoft Research, Redmond, Washington United States",IEEE Software,23 Oct 2020,2020,37,6,21,25,"Large-scale software development is a sociotechnical activity only bounded by human imagination, ingenuity, and creativity. It involves teams of developers progressing by coordinating their activities and communicating their bottlenecks, goals, and advancements toward the wider goal of creating large, high-quality software systems. The stakeholders they serve are diverse (for example, clients, infrastructure providers, open source communities, project managers, and regulatory authorities), and often they have many competing, implicit requirements. But, as the political and legal implications of algorithms and data (https://harvardmagazine.com/2000/01/code-is-law-html) increasingly affect society, it is imperative that the systems the developers build are high quality in terms of accurately embodying all of those requirements.",1937-4194,,10.1109/MS.2020.3014413,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238655,,,,,,1.0,,6.0,,23 Oct 2020,,,IEEE,IEEE Magazines
2144,791,Front Cover,,,IEEE Software,25 Dec 2017,2018,35,1,c1,c1,"The theme articles in this issue address Software Safety and Security Risk Mitigation in Cyberphysical Systems and Actionable Analytics for Software Engineering. Other topics in the issue include modular architectures, DevOps, software standards, software bots, and requirements engineering research.",1937-4194,,10.1109/MS.2017.4541046,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239933,IEEE Software;Jan./Feb.;software safety and security;risk mitigation;cyber-physical systems;actionable analytics;software engineering;modular architectures;DevOps;software standards;software bots;requirements engineering;software development,,,,,,,,,25 Dec 2017,,,IEEE,IEEE Magazines
2145,792,Front Cover,,,IEEE Software,27 Sep 2018,2018,35,5,c1,c1,The articles in this issue address the 50th anniversary of software engineering. Other topics in the issue include software architecture and chaos engineering.,1937-4194,,10.1109/MS.2018.3571233,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474515,IEEE Software;September/October 2018;software architecture;chaos engineering;software engineering;software development,,,,,,,,,27 Sep 2018,,,IEEE,IEEE Magazines
2146,795,2017 Reviewers List*,,,IEEE Transactions on Software Engineering,8 Jan 2018,2018,44,1,100,102,Presents a list of reviewers who contributed to this publication in 2017.,1939-3520,,10.1109/TSE.2017.2775290,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249563,,IEEE publishing,,,,,,,,8 Jan 2018,,,IEEE,IEEE Journals
2147,796,Front Cover,,,IEEE Software,12 Mar 2018,2018,35,2,c1,c1,"The theme articles in this issue address release engineering. Other topics in the issue include cloud computing, agile development, software security, DevOps, software maintenance, software evolution, software architecture, software analytics, requirements engineering, continuous deployment, database management systems, and product development.",1937-4194,,10.1109/MS.2018.1661310,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314155,IEEE Software;release engineering;cloud computing;agile development;software security;DevOps;software maintenance;software evolution;software architecture;software analytics;requirements engineering;continuous deployment;database management systems;product development;software engineering;software development,,,,,,,,,12 Mar 2018,,,IEEE,IEEE Magazines
2148,797,Front Cover,,,IEEE Software,4 May 2018,2018,35,3,c1,c1,"The theme articles in this issue address microservices. Other topics in the issue include unit testing, WordPress, the Internet of Things, agile development, requirements engineering, and Java 9.",1937-4194,,10.1109/MS.2018.2141021,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354416,IEEE Software;May/June 2018;microservices;unit testing;WordPress;Internet of Things;IoT;agile development;requirements engineering;Java 9;software engineering;software development,,,,,,,,,4 May 2018,,,IEEE,IEEE Magazines
2149,798,Front Cover,,,IEEE Software,6 Jul 2018,2018,35,4,c1,c1,"The articles in this issue address process improvement. Other topics in the issue include software architecture, test-driven development, software testing, and blockchains.",1937-4194,,10.1109/MS.2018.2801558,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405625,IEEE Software;July/August 2018;process improvement;software architecture;test-driven development;software testing;blockchains;software engineering;software development,,,,,,,,,6 Jul 2018,,,IEEE,IEEE Magazines
2150,800,Are DevOps and Automation Our Next Silver Bullet?,I. Ozkaya,,IEEE Software,17 Jun 2019,2019,36,4,3,95,"Fred brooks, in his well-known classic The Mythical Man-Month, already told the software engineering industry in 1975 that there are no silver bullets in gaining an order-of-magnitude improvement in software productivity.1 He also observed that ""most of the big past gains in software productivity have come from removing artificial barriers that have made the accidental tasks inordinately hard, such as severe hardware constraints, awkward programming languages, lack of machine time."" The hope and goal of software development processes in orchestrating the essential and accidental software engineering and development tasks is precisely to remove artificial barriers to delivering better, faster, cheaper software to the users. Our next silver bullet seems to have emerged as automating repeatable, manual process tasks. While, on one hand, we debate how to scale agile, on the other, we run to DevOps, continuous integration, and continuous delivery tools to achieve the so-called orders of magnitude of productivity improvement.",1937-4194,,10.1109/MS.2019.2910943,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738081,,,software development management;software maintenance;software product lines,hardware constraints;awkward programming languages;software productivity;order-of-magnitude improvement;software engineering industry;Mythical Man-Month;fred brooks;productivity improvement;manual process tasks;automating repeatable process tasks;silver bullet;artificial barriers;accidental software engineering;software development processes,,,,10.0,,17 Jun 2019,,,IEEE,IEEE Magazines
2151,801,(Research) Insights for Serverless Application Engineering,J. C. Carver; B. Penzenstadler; J. Scheuner; M. Staron,"Computer Science, University of Alabama, Tuscaloosa, Alabama United States; Chalmers University of Technology, Gothenburg, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden",IEEE Software,23 Dec 2020,2021,38,1,123,125,Presents summaries of articles included in this issue of the publication.,1937-4194,,10.1109/MS.2020.3028659,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305894,,,,,,,,4.0,IEEE,23 Dec 2020,,,IEEE,IEEE Magazines
2152,802,The Social Developer: The Future of Software Development [Guest Editors' Introduction],T. Mens; M. Cataldo; D. Damian,"Computer Science, University of Mons, Belgium; Uber Advanced Technologies Group; Computer Science, University of Victoria",IEEE Software,14 Jan 2019,2019,36,1,11,14,"Contemporary Software Engineering has inevitably become much more social. Due to the size, complexity, and diversity of today's software systems, there is a need to interact across organizational, geographical, cultural, and socioeconomic boundaries. Large-scale software development now implies active user involvement and requires close cooperation and collaboration between team members and all types of development activities. Members of software projects across all roles must communicate and interact continuously with other project members as well as with a variety of stakeholders, such as users, analysts, suppliers, customers, and business partners. This theme issue aims to inform software engineering practitioners about current trends and recent advances in research and practice of sociotechnical analysis and support for large-scale software development.",1937-4194,,10.1109/MS.2018.2874316,F.R.S. - FNRS Belgique; F.R.S. - FNRS Belgique; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611456,,Special issues and sections;Software development management;Software development;Collaboration;Sociotechnical systems;Software engineering,,,,1.0,,9.0,,14 Jan 2019,,,IEEE,IEEE Magazines
2153,803,Ethics Is a Software Design Concern,I. Ozkaya,Carnegie Mellon Software Engineering Institute,IEEE Software,16 Apr 2019,2019,36,3,4,8,"The IEEE and Association for Computing Machinery (ACM) joint report ""Software Engineering Code of Ethics"" summarizes the responsibilities of software engineers as the following: ""Software engineers shall commit themselves to making the analysis, specification, design, development, testing and maintenance of software beneficial and respected profession.""",1937-4194,,10.1109/MS.2019.2902592,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693077,,,,,,2.0,,10.0,,16 Apr 2019,,,IEEE,IEEE Magazines
2154,804,Software Safety and Security Risk Mitigation in Cyber-physical Systems,M. Biro; A. Mashkoor; J. Sametinger; R. Seker,Software Competence Center Hagenberg; Software Competence Center Hagenberg; Johannes Kepler University Linz; Embry-Riddle Aeronautical University,IEEE Software,25 Dec 2017,2018,35,1,24,29,"Cyber-physical systems (CPSs) offer many opportunities but pose many challenges—especially regarding functional safety, cybersecurity, and their interplay, as well as the systems’ impact on society. Consequently, new methods and techniques are needed for CPS development and assurance. The articles in this theme issue aim to help address some of these challenges.",1937-4194,,10.1109/MS.2017.4541050,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239950,software safety;software security;risk mitigation;cyber-physical systems;action-oriented programming;AcOP;probabilistic threat estimation;industrial control systems;software engineering;software development,,,,,5.0,,17.0,,25 Dec 2017,,,IEEE,IEEE Magazines
2155,805,What Should a Software Engineer Know?,I. Ozkaya,Carnegie Mellon Software Engineering Institute,IEEE Software,20 Dec 2019,2020,37,1,3,6,"A Software Engineer applies the principles of engineering to the design, development, maintenance, testing, and evaluation of a softwareenabled system. While this fundamental understanding of what a software engineer does is commonly shared, the journey to understand what a software engineer should know evolves, mostly as a consequence of the rapid pace of technological changes.",1937-4194,,10.1109/MS.2019.2946668,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938103,,,,,,,,7.0,,20 Dec 2019,,,IEEE,IEEE Magazines
2156,806,"If it does not scale, it does not work!",I. Ozkaya,"Carnegie Mellon Software Engineering Institute, United States",IEEE Software,21 Feb 2019,2019,36,2,4,7,"The world runs on lots of software. For many businesses and domains, this results in more software elements to develop and maintain. The added software elements often make for greater software complexity, which leads, in turn, to increased need for coordination between multiple software teams that build, integrate, and test the software. This increasing complexity often aggravates the challenges of ""large-scale"" software. Achieving scalability means different things in different contexts. The Editor briefly reviews scale, discussed from three different perspectives: scope, people, and time. Scope is about capabilities in terms of added features, greater size, and increased complexity of the system the software serves. The category of people includes the scale of the development organization and the software users. The category of time relates to the expected life of the system. It is then noted that this issue of IEEE Software presents different perspectives of scale with two themes, thus viewing the topic of scale from the perspective of development as well as software property. Articles under the theme ""Large-Scale Agile Development"" look into scaling development teams in large projects and organizations using agile software development methods. Articles under the theme ""Building Long-Lived Adaptive Systems"" cover state-of-the-art developments related to automated adaptive approaches for engineering systems that stand the test of time.",1937-4194,,10.1109/MS.2018.2885991,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648253,,,,,,1.0,,8.0,,21 Feb 2019,,,IEEE,IEEE Magazines
2157,807,The Deployment View,I. Ozkaya,"Software Engineering, Carnegie Mellon University",IEEE Software,15 Apr 2020,2020,37,3,3,5,"The term DevOps grew out of conversations that Patrick Debois, a system administrator at the time, and Andrew Shafer, a software developer, were having in 2009 along with others sharing their frustrations in how difficult it was to move development to operations. They observed that the agility, automation, and communication barriers between development and operations teams were common across many organizations. The developers put the responsibility on operations and mismatches in the deployment environment. The operations teams assumed that the problems culminated from the implementation. The teams clearly lacked a common deployment and operations view of the system, one of the key aspects of any system's architecture.",1937-4194,,10.1109/MS.2020.2971573,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068374,,,,,,,,5.0,,15 Apr 2020,,,IEEE,IEEE Magazines
2158,808,Trends in Agile: From Operational to Strategic Agility [Practitioners' Digest],R. Prikladnicki; C. Lassenius; J. C. Carver,"Technology, Pontifical Catholic University of Rio Grande do Sul; Software Engineering, Aalto University; Computer Science, University of Alabama, United States",IEEE Software,14 Jan 2019,2019,36,1,95,97,"Reports on meetings and events that were part of the 2018 Agile Conference hat took place August 6-10 in San Diego, CA. ",1937-4194,,10.1109/MS.2018.2875649,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611452,,,,,,,,0.0,,14 Jan 2019,,,IEEE,IEEE Magazines
2159,809,"Mom, Where Are the Girls?",I. Ozkaya,"Software Engineering Institute, Carnegie Mellon, United States",IEEE Software,15 Feb 2021,2021,38,2,3,6,"During the fall semester of 2005, I was working hastily on the finishing touches of my Ph.D. dissertation at Carnegie Mellon University. That semester, I also was the teaching assistant for the Methods of Software Development graduate course taught by Dr. Mary Shaw and Dr. Jim Herbsleb. It was a busy time, with the challenges of finishing graduate school; getting ready for a new job; fulfilling responsibilities such as grading and helping students; and parenting my then three-and-a-half-year-old daughter. Methods of Software Development was a demanding course with a lot of reading and reflection assignments. Students took abundant advantage of the office hours. Those meetings always went better if I remembered the students' names, but with that was all going on, my brain did not always comply, so I had a hack. I had printed all of their photos and hung them right above my desk.",1937-4194,,10.1109/MS.2020.3044410,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354391,,,,,,,,4.0,IEEE,15 Feb 2021,,,IEEE,IEEE Magazines
2160,810,"Ignore, Refactor, or Rewrite",G. Fairbanks,Google,IEEE Software,21 Feb 2019,2019,36,2,133,136,"Most of the guidance applies to smaller chunks of code and decisions implemented in hours or days, not weeks or months. There were a great book on architecture scale refactoring with distilled wisdom and case studies of successes and failures. This article only touches on that but it covers some topics that augment the good advice you will find in Martin Fovvler's Refactoring book and Michael Feathers' Working Effectively with Legacy Code.",1937-4194,,10.1109/MS.2018.2880662,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648269,,Code refractoring;Encoding;Software engineering,software architecture;software maintenance,architecture scale refactoring;software refactoring,,,,6.0,,21 Feb 2019,,,IEEE,IEEE Magazines
2161,811,Computational Reproducibility: The Elephant in the Room,L. Hatton; M. van Genuchten,"Kingston University, London, United Kingdom; VitalHealth Software",IEEE Software,21 Feb 2019,2019,36,2,137,144,Examines the concept of computational reproducibility. Reports on the development of software programming and addresses the challenges of managing software development and developing reliability software update and maintenance procedures.,1937-4194,,10.1109/MS.2018.2883805,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648256,,Software engineering;Software reliability;Software maintenance,,,,,,16.0,,21 Feb 2019,,,IEEE,IEEE Magazines
2162,812,"Quality, Nontechnical Skills, Blind Programmers, and Deep Learning",J. Carver,,IEEE Software,21 Feb 2019,2019,36,2,127,136,"Reports from the 34th International Conference on Software Maintenance and Evolution, the 44th Euromicro Conference on Software Engineering and Advanced Applications, and the 12th International Symposium on Empirical Software Engineering and Measurement (ESEM). ",1937-4194,,10.1109/MS.2018.2883874,,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648271,,,,,,,,6.0,,21 Feb 2019,,,IEEE,IEEE Magazines
2163,813,Twenty Years of Open Source Software: From Skepticism to Mainstream,G. Robles; I. Steinmacher; P. Adams; C. Treude,"Universidad Rey Juan Carlos, Madrid, Spain; Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, United States; Wayfair; Computer Science, University of Adelaide, Australia",IEEE Software,23 Oct 2019,2019,36,6,12,15,"Open source software (OSS) has conquered the software world. You can see it nearly everywhere, from Internet infrastructure to mobile phones to the desktop. In addition to that, although many OSS practices were viewed with skepticism 20 years ago, several have become mainstream in software engineering today: from development tools such as Git to practices such as modern code reviews.",1937-4194,,10.1109/MS.2019.2933672,Regional Government of Madrid; Spanish Government; Australian Research Councils Discovery Early Career Researcher Award; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880574,,,,,,2.0,,0.0,,23 Oct 2019,,,IEEE,IEEE Magazines
2164,814,Agile Development at Scale: The Next Frontier,T. Dingsoeyr; D. Falessi; K. Power,"SINTEF Digital, Trondheim, Norway; California Polytechnic State University, San Luis Obispo; NA",IEEE Software,21 Feb 2019,2019,36,2,30,38,"Agile methods have transformed the way software is developed, emphasizing active end-user involvement, tolerance to change, and evolutionary delivery of products. The first special issue on agile development described the methods as focusing on feedback and change.<sup>1</sup> These methods have led to major changes in how software is developed. Scrum is now the most common framework for development in most countries, and other methods such as extreme programming (XP), elements of lean software development, and Kanban are widely used. What started as a bottom-up movement among software practitioners and consultants has been taken up by major international consulting companies who prescribe agile development, particularly for contexts where learning and innovation are key. Agile development methods have attracted interest primarily in software engineering<sup>1, 2</sup> but also in a number of other disciplines including information systems<sup>3</sup> and project management.<sup>4</sup>",1937-4194,,10.1109/MS.2018.2884884,Norges Forskningsråd; ,https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648272,,Special issues and sections;Agile software development;Software development management,,,,1.0,,28.0,,21 Feb 2019,,,IEEE,IEEE Magazines
