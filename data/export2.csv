"Document Title",Authors,"Author Affiliations","Publication Title",Date Added To Xplore,"Publication Year","Volume","Issue","Start Page","End Page","Abstract","ISSN",ISBNs,"DOI",Funding Information,PDF Link,"Author Keywords","IEEE Terms","INSPEC Controlled Terms","INSPEC Non-Controlled Terms","Mesh_Terms",Article Citation Count,Patent Citation Count,"Reference Count","License",Online Date,Issue Date,"Meeting Date","Publisher",Document Identifier
"A Progression Model of Software Engineering Goals, Challenges, and Practices in Start-Ups","E. Klotins; M. Unterkalmsteiner; P. Chatzipetrou; T. Gorschek; R. Prikladnicki; N. Tripathi; L. B. Pompermaier","Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; Department of Informatics, CERIS, Örebro University School of Business, Örebro, Sweden; Software Engineering Research Lab Sweden, Blekinge Institute of Technology, Karlskrona, Sweden; Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Sweden; M3S Research Unit, University of Oulu, Oulu, Finland; School of Technology, Pontifical Catholic University of Rio Grande do Sul, Porto Alegre, Brazil","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","498","521","Context: Software start-ups are emerging as suppliers of innovation and software-intensive products. However, traditional software engineering practices are not evaluated in the context, nor adopted to goals and challenges of start-ups. As a result, there is insufficient support for software engineering in the start-up context. Objective: We aim to collect data related to engineering goals, challenges, and practices in start-up companies to ascertain trends and patterns characterizing engineering work in start-ups. Such data allows researchers to understand better how goals and challenges are related to practices. This understanding can then inform future studies aimed at designing solutions addressing those goals and challenges. Besides, these trends and patterns can be useful for practitioners to make more informed decisions in their engineering practice. Method: We use a case survey method to gather first-hand, in-depth experiences from a large sample of software start-ups. We use open coding and cross-case analysis to describe and identify patterns, and corroborate the findings with statistical analysis. Results: We analyze 84 start-up cases and identify 16 goals, 9 challenges, and 16 engineering practices that are common among start-ups. We have mapped these goals, challenges, and practices to start-up life-cycle stages (inception, stabilization, growth, and maturity). Thus, creating the progression model guiding software engineering efforts in start-ups. Conclusions: We conclude that start-ups to a large extent face the same challenges and use the same practices as established companies. However, the primary software engineering challenge in start-ups is to evolve multiple process areas at once, with a little margin for serious errors.","1939-3520","","10.1109/TSE.2019.2900213","CNpq and FAPERGS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643804","Software start-up;software engineering practices;progression model","Software;Software engineering;Companies;Market opportunities;Requirements engineering;Analytical models","innovation management;organisational aspects;project management;software development management;software engineering;statistical analysis","start-up cases;primary software engineering challenge;software engineering efforts;engineering practices;start-up companies;traditional software engineering practices;software start-ups;software engineering goals","","1","","96","IEEE","17 Feb 2019","","","IEEE","IEEE Journals"
"A Comparison of Natural Language Understanding Platforms for Chatbots in Software Engineering","A. Abdellatif; K. Badran; D. Costa; E. Shihab","Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: ahmad.abdellatif87@gmail.com); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: badrankhaled97@gmail.com); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: diegoelias1@gmail.com); Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, H3G 1M8 (e-mail: emadshihab@gmail.com)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Chatbots are envisioned to dramatically change the future of Software Engineering, allowing practitioners to chat and inquire about their software projects and interact with different services using natural language. At the heart of every chatbot is a Natural Language Understanding (NLU) component that enables the chatbot to understand natural language input. Recently, many NLU platforms were provided to serve as an off-the-shelf NLU component for chatbots, however, selecting the best NLU for Software Engineering chatbots remains an open challenge. Therefore, in this paper, we evaluate four of the most commonly used NLUs, namely IBM Watson, Google Dialogflow, Rasa, and Microsoft LUIS to shed light on which NLU should be used in Software Engineering based chatbots. Specifically, we examine the NLUs' performance in classifying intents, confidence scores stability, and extracting entities. To evaluate the NLUs, we use two datasets that reflect two common tasks performed by Software Engineering practitioners, 1) the task of chatting with the chatbot to ask questions about software repositories 2) the task of asking development questions on Q&A forums (e.g., Stack Overflow). According to our findings, IBM Watson is the best performing NLU when considering the three aspects (intents classification, confidence scores, and entity extraction). However, the results from each individual aspect show that, in intents classification, IBM Watson performs the best with an F1-measure>84%, but in confidence scores, Rasa comes on top with a median confidence score higher than 0.91. Our results also show that all NLUs, except for Dialogflow, generally provide trustable confidence scores. For entity extraction, Microsoft LUIS and IBM Watson outperform other NLUs in the two SE tasks. Our results provide guidance to software engineering practitioners when deciding which NLU to use in their chatbots.","1939-3520","","10.1109/TSE.2021.3078384","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426404","Software Chatbots;Natural Language Understanding Platforms;Empirical Software Engineering","Chatbot;Task analysis;Software engineering;Software;Feature extraction;XML;Java","","","","","","","IEEE","7 May 2021","","","IEEE","IEEE Early Access Articles"
"A Method to Assess and Argue for Practical Significance in Software Engineering","R. Torkar; C. A. Furia; R. Feldt; F. Gomes de Oliveira Neto; L. Gren; P. Lenberg; N. A. Ernst","Software Engineering, University of Gothenburg, 3570 Goteborg, n7a, Sweden, (e-mail: richard.torkar@cse.gu.se); Informatics, USI, 27216 Lugano, Ticino, Switzerland, 6900 (e-mail: furiac@usi.ch); Software Engineering division, Chalmers University of Technology Department of Computer Science and Engineering, 541960 Goteborg, V'stra Gtaland, Sweden, (e-mail: robert.feldt@chalmers.se); Software Engineering, University of Gothenburg, 3570 Goteborg, n/a, Sweden, (e-mail: gomesf@chalmers.se); Software Engineering, Computer Science and Engineering, Gothenburg, Gothenburg, Sweden, SE-412 96 (e-mail: lucas.gren@cse.gu.se); Department of Computer Science of Engineering, Chalmers University, Gothenburg, V'stra Gtaland, Sweden, 42163 (e-mail: perle@chalmers.se); Computer Science, University of Victoria, 8205 Victoria, British Columbia, Canada, (e-mail: nernst@uvic.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","A key goal of empirical research in software engineering is to assess practical significance, which answers whether the observed effects of some compared treatments show a relevant difference in practice in realistic scenarios. Even though plenty of standard techniques exist to assess statistical significance, connecting it to practical significance is not straightforward or routinely done; indeed, only a few empirical studies in software engineering assess practical significance in a principled and systematic way. In this paper, we argue that Bayesian data analysis provides suitable tools to assess practical significance rigorously. We demonstrate our claims in a case study comparing different test techniques. The case study's data was previously analyzed (Afzal et al., 2015) using standard techniques focusing on statistical significance. Here, we build a multilevel model of the same data, which we fit and validate using Bayesian techniques. Our method is to apply cumulative prospect theory on top of the statistical model to quantitatively connect our statistical analysis output to a practically meaningful context. This is then the basis both for assessing and arguing for practical significance. Our study demonstrates that Bayesian analysis provides a technically rigorous yet practical framework for empirical software engineering. A substantial side effect is that any uncertainty in the underlying data will be propagated through the statistical model, and its effects on practical significance are made clear. Thus, in combination with cumulative prospect theory, Bayesian analysis supports seamlessly assessing practical significance in an empirical software engineering context, thus potentially clarifying and extending the relevance of research for practitioners.","1939-3520","","10.1109/TSE.2020.3048991","Marianne and Marcus Wallenberg Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9314270","practical significance;statistical significance;Bayesian analysis;empirical software engineering","Bayes methods;Data models;Software engineering;Statistical analysis;Analytical models;Testing;Decision making","","","","","","","CCBY","5 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Software Engineering for Machine-Learning Applications: The Road Ahead","F. Khomh; B. Adams; J. Cheng; M. Fokaefs; G. Antoniol",Polytechnique Montréal; Polytechnique Montréal; Polytechnique Montréal; Polytechnique Montréal; Polytechnique Montréal,"IEEE Software","27 Sep 2018","2018","35","5","81","84","The First Symposium on Software Engineering for Machine Learning Applications (SEMLA) aimed to create a space in which machine learning (ML) and software engineering (SE) experts could come together to discuss challenges, new insights, and practical ideas regarding the engineering of ML and AI-based systems. Key challenges discussed included the accuracy of systems built using ML and AI models, the testing of those systems, industrial applications of AI, and the rift between the ML and SE communities. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.3571224","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474484","First Symposium on Software Engineering for Machine Learning Applications;SEMLA;machine learning;artificial intelligence;AI;software engineering;SE;software development;Invited Content","Learning systems;Software engineering;Software systems;Software development;Machine learning;Artificial intelligence","artificial intelligence;learning (artificial intelligence);software engineering","AI-based systems;ML model;software engineering for machine learning applications;SEMLA;industrial applications","","7","","0","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Yesterday, Today, and Tomorrow: 50 Years of Software Engineering","M. Broy",Technische Universität München and Zentrum Digitalisierung.Bayern,"IEEE Software","27 Sep 2018","2018","35","5","38","43","In 2018, we're now 50 years after the famous groundbreaking conference on software engineering in Garmisch, organized by its chairman F.L. Bauer and his cochairs L. Bolliet and H.J. Helms. This conference introduced the notion and discipline of software engineering. This is a moment to look back at what we've achieved, what we haven't achieved, where we are today, and what challenges lie ahead. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290111138","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409912","software engineering;software development;history of software engineering","Software engineering;Programming;Computer architecture;Computer languages;Software systems","software engineering","software engineering;software crisis;computer hardware;software production","","","","11","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Closing the Gap Between Software Engineering Education and Industrial Needs","V. Garousi; G. Giray; E. Tuzun; C. Catal; M. Felderer","Software Engineering, Queen’s University Belfast, United Kingdom; NA; Bilkent University, Ankara, Turkey; Wageningen University; University of Innsbruck, Austria","IEEE Software","12 Feb 2020","2020","37","2","68","77","Many recent software engineering graduates often face difficulties when beginning their professional careers, due to misalignment of the skills learned in their university education with what is needed in industry. In this article, we report a literature review of the studies that have been done to make improvements on this issue.","1937-4194","","10.1109/MS.2018.2880823","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664487","Software engineering education;industry needs;important skills;knowledge gap;software engineering curriculum","Software engineering;Computer science education;Software engineering;Education courses;Knowledge engineering;Computer science;Information systems","computer science education;educational courses;educational institutions;engineering education;software engineering","university education;software engineering education;software engineering graduates;professional careers;industrial needs","","2","","14","","10 Mar 2019","","","IEEE","IEEE Magazines"
"Software Engineering’s Top Topics, Trends, and Researchers","G. Mathew; T. Menzies",North Carolina State University; North Carolina State University,"IEEE Software","27 Sep 2018","2018","35","5","88","93","For this theme issue on the 50th anniversary of software engineering (SE), Redirections offers an overview of the twists, turns, and numerous redirections seen over the years in the SE research literature. Nearly a dozen topics have dominated the past few decades of SE research-and these have been redirected many times. Some are gaining popularity, whereas others are becoming increasingly rare. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.3571230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474491","latent Dirichlet allocation;text mining;software engineering research;software engineering;software development;redirections","Text mining;Object oriented modeling;Market research;Software measurement;Software engineering","research and development;software engineering","SE research literature;software engineering","","1","","11","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Half a Century of Software Engineering Education: The CMU Exemplar","N. R. Mead; D. Garlan; M. Shaw",Carnegie Mellon University; Carnegie Mellon University; Carnegie Mellon University,"IEEE Software","27 Sep 2018","2018","35","5","25","31","From the aspirational title of the 1968 NATO conference, software engineering has evolved to a well-defined engineering discipline with strong educational underpinnings. The supporting educational foundation has grown from a few courses in programming languages and data structures, evolving through structured programming, correctness formalisms, and state machine abstractions to full curricula and degree programs. With this context in mind, the authors discuss the evolution of software engineering education and pedagogy, software engineering principles, and future needs, drawing specifically on their experience at Carnegie Mellon University. Reflecting on the software development profession today, they believe that formal software engineering education is needed at least as much as it was in earlier decades. However, it must address the increasing diversity of the developer community, and it must be an education based on the enduring principles that will last a lifetime. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290110743","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409913","software engineering education;software engineering history;software engineering practice;Carnegie Mellon University;Software Engineering Institute;software development;software engineering","Software engineering;History;Technology forecasting;Computer science","computer science education;data structures;educational courses;educational institutions;software engineering","degree programs;formal software engineering education;educational foundation;CMU exemplar;data structure;state machine abstraction;Carnegie Mellon University;programming languages course","","1","","16","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Software Engineering Research and Industry: A Symbiotic Relationship to Foster Impact","V. Basili; L. Briand; D. Bianculli; S. Nejati; F. Pastore; M. Sabetzadeh","University of Maryland, College Park; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg; University of Luxembourg","IEEE Software","27 Sep 2018","2018","35","5","44","49","Software engineering is not only an increasingly challenging endeavor that goes beyond the intellectual capabilities of any single individual engineer but also an intensely human one. Tools and methods to develop software are employed by engineers of varied backgrounds within a large variety of organizations and application domains. As a result, the variation in challenges and practices in system requirements, architecture, and quality assurance is staggering. Human, domain, and organizational factors define the context within which software engineering methodologies and technologies are to be applied and therefore the context that research needs to account for, if it is to be impactful. This article provides an assessment of the current challenges faced by software engineering research in achieving its potential, a description of the root causes of such challenges, and a proposal for the field to move forward and become more impactful through collaborative research and innovation between public research and industry. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290110216","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409904","software engineering research;empirical software engineering;collaborative research;context-driven research;software engineering;software development","Software engineering;Collaboration;Software development;Context modeling","DP industry;innovation management;organisational aspects;quality assurance;software engineering","software engineering methodologies;collaborative research;quality assurance;organizational factors;software engineering technologies;innovation;system requirements;software engineering industry","","1","","8","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Software Engineering for Internet of Things","M. Fahmideh; A. A. Abbasi; A. Behnaz; J. Grundy; W. Susilo","UTS, University of Technology Sydney Faculty of Engineering and Information Technology, 120558 Sydney, New South Wales, Australia, 2007 (e-mail: mehdi.fahmideh@gmail.com); Computer Science and Engineering, University of Hail, 48138 Hail, Hail, Saudi Arabia, (e-mail: ahmad.aakash@gmail.com); Computer science, University of New South Wales, 7800 Sydney, New South Wales, Australia, (e-mail: ali.behnaz@unsw.edu.au); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); School of Computing and IT, University of Wollongong, 8691 Wollongong, New South Wales, Australia, 2522 (e-mail: wsusilo@uow.edu.au)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Internet of Things based systems (IoT systems for short) are becoming increasingly popular across different industrial domains and their development is rapidly increasing to provide value-added services to end-users and citizens. Little research to date uncovers the core development process lifecycle needed for IoT systems, and thus software engineers find themselves unprepared and unfamiliar with this new genre of system development. To ameliorate this gap, we conducted a mixed quantitative and qualitative research study where we derived a conceptual process framework from the extant literature on IoT, through which 27 key tasks for incorporation into the development processes of IoT systems were identified. The framework was then validated by means of a survey of 127 IoT practitioners from 35 countries across 6 continents with 15 different industry backgrounds. Our research provides an understanding of the most important development process tasks and informs both software engineering practitioners and researchers of the challenges and recommendations related to the development of next-generation of IoT systems.","1939-3520","","10.1109/TSE.2021.3070692","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9398558","software engineering;software management;software development process;empirical software engineering;Internet of Things (IoT)","Software engineering;Task analysis;Software;Internet of Things;Systematics;Information technology;Hardware","","","","","","","IEEE","7 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Industry–Academia Collaboration in Software Engineering","J. C. Carver; R. Prikladnicki",University of Alabama; Pontifical Catholic University,"IEEE Software","27 Sep 2018","2018","35","5","120","124","This article aims to encourage more industry-academia collaborations by highlighting examples of successful collaborations. Through these examples, the authors hope to help practitioners and researchers understand the breadth of options available for such interactions. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.3571250","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474518","software architecture;automatic bug assignment;software quality;requirements-based testing;industry–academia collaboration;software development;software engineering;Practitioners’ Digest","Software engineering;Computer science education;Collaboration","software engineering","software engineering;industry-academia collaboration","","1","","","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Trends and Challenges for Software Engineering in the Mobile Domain","L. Baresi; W. G. Griswold; G. A. Lewis; M. Autili; I. Malavolta; C. Julien","Politecnico di Milano, Milano, Italy; Computer Science and Engineering, University of California, San Diego, La Jolla, California United States; Software Engineering Institute, Carnegie Mellon, Pittsburgh, Pennsylvania United States; University of L'Aquila, L'Aquila, Italy, Italy; Computer Science, Vrije Universiteit Amsterdam, Amsterdam, The Netherlands; Software Engineering, University of Texas at Austin, Austin, Texas United States","IEEE Software","23 Dec 2020","2021","38","1","88","96","Mobile computing is becoming a key aspect of our lives. This article builds on conversations held during the 2018 IEEE/ACM International Conference on Mobile Software Engineering and Systems, highlighting mobile computing's impact on software engineering practices, the transition from research to industry, and related areas.","1937-4194","","10.1109/MS.2020.2994306","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091517","Mobile computing;Software engineering;Android and beyond;Research and Industry","Software engineering;Smart phones;Software;Software tools;Mobile computing;Sensors","computer science education;mobile computing;software engineering","Mobile domain;Mobile Software Engineering;highlighting mobile computing;software engineering practices","","1","","20","IEEE","13 May 2020","","","IEEE","IEEE Magazines"
"Cognitive Biases in Software Engineering: A Systematic Mapping Study","R. Mohanani; I. Salman; B. Turhan; P. Rodríguez; P. Ralph","M3S Group, University of Oulu, Oulu, Finland; M3S Group, University of Oulu, Oulu, Finland; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; M3S Group, University of Oulu, Oulu, Finland; Department of Computer Science, University of Auckland, Auckland, New Zealand","IEEE Transactions on Software Engineering","10 Dec 2020","2020","46","12","1318","1339","One source of software project challenges and failures is the systematic errors introduced by human cognitive biases. Although extensively explored in cognitive psychology, investigations concerning cognitive biases have only recently gained popularity in software engineering research. This paper therefore systematically maps, aggregates and synthesizes the literature on cognitive biases in software engineering to generate a comprehensive body of knowledge, understand state-of-the-art research and provide guidelines for future research and practise. Focusing on bias antecedents, effects and mitigation techniques, we identified 65 articles (published between 1990 and 2016), which investigate 37 cognitive biases. Despite strong and increasing interest, the results reveal a scarcity of research on mitigation techniques and poor theoretical foundations in understanding and interpreting cognitive biases. Although bias-related research has generated many new insights in the software engineering community, specific bias mitigation techniques are still needed for software professionals to overcome the deleterious effects of cognitive biases on their work.","1939-3520","","10.1109/TSE.2018.2877759","Oulun Yliopisto; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8506423","Antecedents of cognitive bias;cognitive bias;debiasing;effects of cognitive bias;software engineering;systematic mapping","Cognition;Software engineering;Software project management","cognition;psychology;software engineering","systematic mapping study;software project challenges;human cognitive biases;cognitive psychology;software engineering research;bias antecedents;software engineering community;specific bias mitigation techniques;systematic errors","","1","","109","IEEE","24 Oct 2018","","","IEEE","IEEE Journals"
"A Systematic Review of Interaction in Search-Based Software Engineering","A. Ramírez; J. R. Romero; C. L. Simons","Department of Computer Science and Numerical Analysis, University of Córdoba, Córdoba, Spain; Department of Computer Science and Numerical Analysis, University of Córdoba, Córdoba, Spain; Department of Computer Science and Creative Technologies, University of the West of England, Bristol, United Kingdom","IEEE Transactions on Software Engineering","26 Aug 2019","2019","45","8","760","781","Search-Based Software Engineering (SBSE) has been successfully applied to automate a wide range of software development activities. Nevertheless, in those software engineering problems where human evaluation and preference are crucial, such insights have proved difficult to characterize in search, and solutions might not look natural when that is the expectation. In an attempt to address this, an increasing number of researchers have reported the incorporation of the 'human-in-the-loop' during search and interactive SBSE has attracted significant attention recently. However, reported results are fragmented over different development phases, and a great variety of novel interactive approaches and algorithmic techniques have emerged. To better integrate these results, we have performed a systematic literature review of interactive SBSE. From a total of 669 papers, 26 primary studies were identified. To enable their analysis, we formulated a classification scheme focused on four crucial aspects of interactive search, i.e., the problem formulation, search technique, interactive approach, and the empirical framework. Our intention is that the classification scheme affords a methodological approach for interactive SBSE. Lastly, as well as providing a detailed cross analysis, we identify and discuss some open issues and potential future trends for the research community.","1939-3520","","10.1109/TSE.2018.2803055","Spanish Ministry of Economy and Competitiveness; Spanish Ministry of Education; FEDER; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283568","Search-based software engineering;interaction;systematic literature review;optimization","Software;Software engineering;Search problems;Optimization;Systematics;Market research;Software metrics","interactive systems;reviews;search problems;software engineering","search-based software engineering;development phases;search technique;interactive search;systematic literature review;interactive approach;interactive SBSE;human evaluation;software engineering problems;software development activities","","12","","100","","6 Feb 2018","","","IEEE","IEEE Journals"
"A Survey on the Use of Computer Vision to Improve Software Engineering Tasks","M. Bajammal; A. Stocco; D. Mazinanian; A. Mesbah","Electrical and Computer Engineering, The University of British Columbia, 8166 Vancouver, British Columbia, Canada, (e-mail: bajammal@ece.ubc.ca); Department of Electrical and Computer Engineering, U. British Columbia, Vancouver, British Columbia, Canada, V6T 1Z4 (e-mail: andrea.stocco@usi.ch); Electrical and Computer Engineering, University of British Columbia Faculty of Applied Science, Vancouver, British Columbia, Canada, (e-mail: dmazinanian@ece.ubc.ca); Electrical and Computer Engineering, University of British Columbia, VANCOUVER, British Columbia, Canada, V6T1Z4 (e-mail: amesbah@ece.ubc.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software engineering (SE) research has traditionally revolved around engineering the source code. However, novel approaches that analyze software through computer vision have been increasingly adopted in SE. These approaches allow analyzing the software from a different complementary perspective other than the source code, and they are used to either complement existing source code-based methods, or to overcome their limitations. The goal of this manuscript is to survey the use of computer vision techniques in SE with the aim of assessing their potential in advancing the field of SE research. We examined an extensive body of literature from top-tier SE venues, as well as venues from closely related fields (machine learning, computer vision, and human-computer interaction). Our inclusion criteria targeted papers applying computer vision techniques that address problems related to any area of SE. We collected an initial pool of 2,716 papers, from which we obtained 66 final relevant papers covering a variety of SE areas. We analyzed what computer vision techniques have been adopted or designed, for what reasons, how they are used, what benefits they provide, and how they are evaluated. Our findings highlight that visual approaches have been adopted in a wide variety of SE tasks, predominantly for effectively tackling software analysis and testing challenges in the web and mobile domains. The results also show a rapid growth trend of the use of computer vision techniques in SE research.","1939-3520","","10.1109/TSE.2020.3032986","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9237151","Computer Vision;Software Engineering;Survey","Testing;Visualization;Software engineering;Computer vision;Software;Task analysis;Graphical user interfaces","","","","1","","","","22 Oct 2020","","","IEEE","IEEE Early Access Articles"
"App Store Effects on Software Engineering Practices","A. A. Al-Subaihin; F. Sarro; S. Black; L. Capra; M. Harman","University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","300","319","In this paper, we study the app store as a phenomenon from the developers' perspective to investigate the extent to which app stores affect software engineering tasks. Through developer interviews and questionnaires, we uncover findings that highlight and quantify the effects of three high-level app store themes: bridging the gap between developers and users, increasing market transparency and affecting mobile release management. Our findings have implications for testing, requirements engineering and mining software repositories research fields. These findings can help guide future research in supporting mobile app developers through a deeper understanding of the app store-developer interaction.","1939-3520","","10.1109/TSE.2019.2891715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606261","Empirical software engineering;mobile app development;app store analysis","Software engineering;Software;Interviews;Data mining;Testing;Data collection;Business","data mining;formal specification;mobile computing;software engineering","app store effects;software engineering practices;software engineering tasks;developer interviews;high-level app store themes;market transparency;affecting mobile release management;requirements engineering;mining software repositories research fields;mobile app developers;app store-developer interaction","","5","","100","IEEE","9 Jan 2019","","","IEEE","IEEE Journals"
"A Procedure and Guidelines for Analyzing Groups of Software Engineering Replications","A. Santos; S. Vegas; M. Oivo; N. Juristo","M-Group, University of Oulu, Oulu, Oulu Finland (e-mail: Adrian.Santos.Parrilla@oulu.fi); Languajes, computer systems and software engineering, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: svegas@fi.upm.es); Department of Information Processing Science, University of Oulu, Oulu, Oulu Finland 90014 (e-mail: Markku.Oivo@oulu.fi); Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: natalia@fi.upm.es)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Context: Researchers from different groups and institutions are collaborating on building groups of experiments by means of replication (i.e., conducting groups of replications). Disparate aggregation techniques are being applied to analyze groups of replications. The application of unsuitable techniques to aggregate replication results may undermine the potential of groups of replications to provide in-depth insights from experiment results. Objectives: Provide an analysis procedure with a set of embedded guidelines to aggregate software engineering (SE) replication results. Method: We compare the characteristics of groups of replications for SE and other mature experimental disciplines such as medicine and pharmacology. In view of their differences, the limitations with regard to the joint data analysis of groups of SE replications and the guidelines provided in mature experimental disciplines to analyze groups of replications, we build an analysis procedure with a set of embedded guidelines specifically tailored to the analysis of groups of SE replications. We apply the proposed analysis procedure to a representative group of SE replications to illustrate its use. Results: All the information contained within the raw data should be leveraged during the aggregation of replication results. The analysis procedure that we propose encourages the use of stratified individual participant data and aggregated data in tandem to analyze groups of SE replications. Conclusion: The aggregation techniques used to analyze groups of replications should be justified in research articles. This will increase the reliability and transparency of joint results. The proposed guidelines should ease this endeavor.","1939-3520","","10.1109/TSE.2019.2935720","Ministerio de Ciencia, Innovación y Universidades; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8805425","Replication;Statistical Analysis;Aggregated Data;Individual Participant Data;Narrative Synthesis","Guidelines;Reliability;Aggregates;Buildings;Data analysis;Biological system modeling;Software engineering","","","","","","","","19 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Software Engineering for Data Analytics","M. Kim","Computer Science, UCLA, Los Angeles, California United States","IEEE Software","19 Jun 2020","2020","37","4","36","42","We are at an inflection point where software engineering meets the data-centric world of big data, machine learning, and artificial intelligence. In this article, I summarize findings from studies of professional data scientists and discuss my perspectives on open research problems to improve data-centric software development.","1937-4194","","10.1109/MS.2020.2985775","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9056482","","Big Data;Software engineering;Data analysis;Debugging;Artificial intelligence;Software engineering;Software testing","Big Data;data analysis;learning (artificial intelligence);software engineering","inflection point;data analytics;software engineering;data-centric software development;professional data scientists;artificial intelligence;machine learning;Big Data","","1","","14","","3 Apr 2020","","","IEEE","IEEE Magazines"
"Applying Software Engineering Standards in Very Small Entities: From Startups to Grownups","C. Y. Laporte; M. Munoz; J. Mejia Miranda; R. V. O’Connor",École de technologie supérieure; Centro de Investigación en Matemáticas; Centro de Investigación en Matemáticas; Dublin City University,"IEEE Software","25 Dec 2017","2018","35","1","99","103","Very small entities (VSEs) are organizations with up to 25 people. The ISO/IEC 29110 series of standards and guides target VSEs with little or no experience or expertise in selecting the appropriate processes from lifecycle standards and tailoring them to a project's needs. This article gives an overview of ISO/IEC 29110, some examples of VSEs that have implemented it, and those implementations' results.","1937-4194","","10.1109/MS.2017.4541041","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239934","software engineering standards;ISO/IEC 29110;very small entities;software engineering;software development;Invited Content","IEC Standards;ISO Standards;Software engineering;Software development;Standards organizations","IEC standards;ISO standards;software development management;software process improvement;software standards","startups;grownups;VSEs;organizations;experience;appropriate processes;lifecycle standards;software engineering standards;very small entities;ISO-IEC 29110 series","","6","","9","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Impact of Affirmative Action on Female Computer Science/Software Engineering Undergraduate Enrollment","J. Simmonds; M. C. Bastarrica; N. Hitschfeld-Kahler","Computer Science, University of Chile, Santiago, 8370456, Chile; Computer Science, University of Chile, Santiago, 8370456, Chile; Computer Science, University of Chile, Santiago, 8370456, Chile","IEEE Software","15 Feb 2021","2021","38","2","32","37","Affirmative action in college admissions has been touted as a way to close the gender gap in science, technology, engineering, and mathematics programs. We report a study of one such program, where we discovered a positive effect on female enrollment and a smaller effect on a combined computer science and software engineering degree.","1937-4194","","10.1109/MS.2020.3044841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293108","","Software engineering;Market research;Conferences;STEM;Programming;Organizations","computer science education;educational courses;educational institutions;engineering education;further education;gender issues;software engineering","affirmative action;college admissions;gender gap;mathematics programs;female enrollment;combined computer science;software engineering degree","","","","15","IEEE","14 Dec 2020","","","IEEE","IEEE Magazines"
"Mining Treatment-Outcome Constructs from Sequential Software Engineering Data","M. Nayebi; G. Ruhe; T. Zimmermann","Ecole Polytechnique of Montreal, Montreal, QC, Canada; Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada; Microsoft Research, Redmond, WA, USA","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","393","411","Many investigations in empirical software engineering look at sequences of data resulting from development or management processes. In this paper, we propose an analytical approach called the Gandhi-Washington Method (GWM) to investigate the impact of recurring events in software projects. GWM takes an encoding of events and activities provided by a software analyst as input. It uses regular expressions to automatically condense and summarize information and infer treatments. Relating the treatments to the outcome through statistical tests, treatment-outcome constructs are automatically mined from the data. The output of GWM is a set of treatment-outcome constructs. Each treatment in the set of mined constructs is significantly different from the other treatments considering the impact on the outcome and/or is structurally different from other treatments considering the sequence of events. We describe GWM and classes of problems to which GWM can be applied. We demonstrate the applicability of this method for empirical studies on sequences of file editing, code ownership, and release cycle time.","1939-3520","","10.1109/TSE.2019.2892956","Natural Sciences and Engineering Research Council of Canada; Alberta Innovates - Technology Futures; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8620369","Pattern mining;mining software repositories;regular expressions;analytics;release cycle time patterns;code ownership","Software;Computer bugs;Encoding;Data mining;Software engineering;Testing;Itemsets","data mining;software engineering;statistical testing","sequential software engineering data;GWM;software projects;software analyst;Gandhi-Washington method;treatment-outcome constructs","","","","54","IEEE","20 Jan 2019","","","IEEE","IEEE Journals"
"Five Predictions for the Coming Decades of Software","M. Kersten",Tasktop,"IEEE Software","27 Sep 2018","2018","35","5","7","9","To help celebrate software engineering's 50th anniversary, department editor Mik Kersten considers how software engineering will evolve over the coming 50 years. His five predictions aren't intended to be precise; they aim to provide discussion topics for the shape of software engineering trends to come. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.3571232","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474514","Carlota Perez;artificial intelligence;AI;software engineering;software development;On DevOps","Technology forecasting;Software engineering","software engineering","software engineering trends;software engineering's 50th anniversary","","","","3","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Empirical Software Engineering, Predictive Models, and Product Lines","J. C. Carver; E. Santana de Almeida; R. Capilla; L. Minku; M. Torchiano; A. Valdezate",University of Alabama; Federal University of Bahia; Rey Juan Carlos University of Madrid; University of Leicester; Politecnico di Torino; Ibermatica,"IEEE Software","4 May 2018","2018","35","3","8","11","This issue’s column reports on presentations at the 11th International Symposium on Empirical Software Engineering and Measurement, 13th International Conference on Predictive Models and Data Analytics in Software Engineering, and 21st International Systems and Software Product Line Conference.","1937-4194","","10.1109/MS.2018.2141018","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354421","11th International Symposium on Empirical Software Engineering and Measurement;13th International Conference on Predictive Models and Data Analytics in Software Engineering;21st International Systems and Software Product Line Conference;empirical software engineering;predictive models;data analytics;software product lines;product line engineering;developer productivity;issue resolution;agile development;microservices;software engineering;software development;Practitioners’ Digest","","","","","","","","","4 May 2018","","","IEEE","IEEE Magazines"
"Software Engineering Antipatterns in Start-Ups","E. Klotins; M. Unterkalmsteiner; T. Gorschek","Software Engineering, Blekinge Institute of Technology; Free University of Bozen-Bolzano; Blekinge Institute of Technology","IEEE Software","21 Feb 2019","2019","36","2","118","126","Software start-up failures are often explained with poor business models, market issues, or insufficient funding. Inadequacies in software engineering could be a significant contributing factor to the high start-up failure rate and precede any marketing or business related challenges. We reveal three antipatterns associated with start-up progression phases.","1937-4194","","10.1109/MS.2018.227105530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356173","Software;Software Engineering;Requirements;specifications;Software quality;SQA;management;programming teams","Software engineering;Software development;Companies;Business;Investment","DP industry;electronic commerce;marketing;software engineering;uninterruptible power supplies","marketing;start-up progression phases;software engineering antipatterns;start-ups;poor business models;market issues;insufficient funding;significant contributing factor;high start-up failure rate","","2","","15","","8 May 2018","","","IEEE","IEEE Magazines"
"Does Distance Still Matter? Revisiting Collaborative Distributed Software Design","R. Jolak; A. Wortmann; M. Chaudron; B. Rumpe",Chalmers University of Technology and Gothenburg University; RWTH Aachen University; Chalmers University of Technology and Gothenburg University; RWTH Aachen University,"IEEE Software","29 Nov 2018","2018","35","6","40","47","Global software engineering requires supporting distributed collaboration for most software development activities. However, geographical distance challenges effective collaboration. Nowadays, we're witnessing significant advances in communication and collaboration technologies. So, researchers explored whether these advances enable effective remote collaboration. To that end, they studied the design activities of both colocated and distributed professional software designers. The findings are based on analysis of video recordings of design sessions and questionnaires. The researchers found that despite comprehensive technological improvements, distance still matters. To ensure effective distributed software design, designers must consider extra (nontechnical) details. This article is part of a theme issue on collaborative modeling.","1937-4194","","10.1109/MS.2018.290100920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409905","global software engineering;GSE;collaborative software design;collaborative software modeling;distributed software design;software design communication;software design decisions;software design reasoning;software models;interactive whiteboards;computer-supported cooperative work;CSCW;software engineering;software development","Collaborative software;Software design;Software engineering;Software development","groupware;software engineering","distributed software design;collaborative modeling;comprehensive technological improvements;questionnaires;design sessions;colocated distributed professional software designers;design activities;effective remote collaboration;geographical distance;software development activities;global software engineering;collaborative distributed software design","","2","","15","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Belief and Evidence: How Software Engineers Form Their Opinions","P. Devanbu; T. Zimmermann; C. Bird","University of California, Davis; Microsoft Research; Microsoft Research","IEEE Software","29 Nov 2018","2018","35","6","72","76","A study at Microsoft revealed how developers' opinions about software engineering truths can be subjectively based.","1937-4194","","10.1109/MS.2018.4321246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552655","evidence-based software engineering;software engineering;software development;Redirections","Software development;Software engineering","computer science education;software engineering","software engineers;opinions;Microsoft;developers;software engineering truths","","3","","8","","29 Nov 2018","","","IEEE","IEEE Magazines"
"A Conversation with Barry Boehm: Recollections from 50 Years of Software Engineering","H. Erdogmus; N. Medvidović",Carnegie Mellon University; University of Southern California,"IEEE Software","27 Sep 2018","2018","35","5","14","19","Barry Boehm speaks with IEEE Software about his experiences throughout the history of software engineering. This article is part of a theme issue on software engineerings 50th anniversary.","1937-4194","","10.1109/MS.2018.3571249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474492","history of software engineering;Barry Boehm;software development;software engineering","Software engineering;History","","","","","","6","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Toward Methodological Guidelines for Process Theories and Taxonomies in Software Engineering","P. Ralph","Department of Computer Science, University of Auckland, Auckland, New Zealand","IEEE Transactions on Software Engineering","16 Jul 2019","2019","45","7","712","735","Software engineering is increasingly concerned with theory because the foundational knowledge comprising theories provides a crucial counterpoint to the practical knowledge expressed through methods and techniques. Fortunately, much guidance is available for generating and evaluating theories for explaining why things happen (variance theories). Unfortunately, little guidance is available concerning theories for explaining how things happen (process theories), or theories for analyzing and understanding situations (taxonomies). This paper therefore attempts to clarify the nature and functions of process theories and taxonomies in software engineering research, and to synthesize methodological guidelines for their generation and evaluation. It further advances the key insight that most process theories are taxonomies with additional propositions, which helps inform their evaluation. The proposed methodological guidance has many benefits: it provides a concise summary of existing guidance from reference disciplines, it adapts techniques from reference disciplines to the software engineering context, and it promotes approaches that better facilitate scientific consensus.","1939-3520","","10.1109/TSE.2018.2796554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8267085","Research methodology;process theory;taxonomy;theory for analysis;theory for understanding;model;framework;guidelines;case study;grounded theory;questionnaire;experiment;action research","Taxonomy;Software;Software engineering;Guidelines;Measurement;Knowledge engineering;Organisms","software engineering","process theories;taxonomies;variance theories;software engineering context","","4","","146","","23 Jan 2018","","","IEEE","IEEE Journals"
"PerfJIT: Test-level Just-in-time Prediction for Performance Regression Introducing Commits","J. Chen; W. Shang; E. Shihab","Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 1M8 (e-mail: fu_chen@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: shang@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: eshihab@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Performance issues may compromise user experiences, increase the cost resources, and cause field failures. One of the most prevalent performance issues is performance regression. Due to the importance and challenges in performance regression detection, prior research proposes various automated approaches that detect performance regressions. However, performance regression detection is conducted after the system is built and deployed. Hence, large amounts of resources are still required to locate and fix performance regressions. In our paper, we propose an approach that automatically predicts whether a test would manifest performance regressions given a code commit. In particular, we extract both traditional metrics and performance-related metrics from the code changes that are associated with each test. For each commit, we build random forest classifiers that are trained from all prior commits to predict in this commit whether each test would manifest performance regression. We conduct case studies on three open-source systems (Hadoop, Cassandra and OpenJPA). Our results show that our approach can predict tests that manifest performance regressions in a commit with high AUC values (on average 0.86). Our approach can drastically reduce the testing time needed to detect performance regressions. In addition, we find that our approach could be used to detect the introduction of six out of nine real-life performance issues from the subject systems during our studied period. Finally, we find that traditional metrics that are associated with size and code change histories are the most important factors in our models. Our approach and the study results can be leveraged by practitioners to effectively cope with performance regressions in a timely and proactive manner.","1939-3520","","10.1109/TSE.2020.3023955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197704","performance regression;software performance;software quality;mining software repositories;empirical software engineering","Measurement;Predictive models;Software;Task analysis;Benchmark testing;Logistics","","","","","","","","15 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Impact of Discretization Noise of the Dependent variable on Machine Learning Classifiers in Software Engineering","G. K. Rajbahadur; S. Wang; Y. Kamei; A. E. Hassan","School of Computing, Queen's University, 4257 Kingston, Ontario Canada K7L 2N8 (e-mail: krishnan@cs.queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: shaowei@cs.queensu.ca); Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Fukuoka Japan 819-0395 (e-mail: kamei@ait.kyushu-u.ac.jp); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Researchers usually discretize a continuous dependent variable into two target classes by introducing an artificial discretization threshold (e.g., median). However, such discretization may introduce noise (i.e., discretization noise) due to ambiguous class loyalty of data points that are close to the artificial threshold. Previous studies do not provide a clear directive on the impact of discretization noise on the classifiers and how to handle such noise. In this paper, we propose a framework to help researchers and practitioners systematically estimate the impact of discretization noise on classifiers in terms of its impact on various performance measures and the interpretation of classifiers. Through a case study of 7 software engineering datasets, we find that: 1) discretization noise affects the different performance measures of a classifier differently for different datasets; 2) Though the interpretation of the classifiers are impacted by the discretization noise on the whole, the top 3 most important features are not affected by the discretization noise. Therefore, we suggest that practitioners and researchers use our framework to understand the impact of discretization noise on the performance of their built classifiers and estimate the exact amount of discretization noise to be discarded from the dataset to avoid the negative impact of such noise.","1939-3520","","10.1109/TSE.2019.2924371","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8744330","Discretization noise;Discretization;Classifiers;Feature Importance Analysis;Performance;Random Forest;Logistic Regression;Decision Trees;KNN","Software engineering;Computer bugs;Noise measurement;Software;Machine learning;Regression tree analysis;Logistics","","","","","","","","24 Jun 2019","","","IEEE","IEEE Early Access Articles"
"Software Maintenance and Evolution and Automated Software Engineering","J. C. Carver; A. Serebrenik",University of Alabama; Eindhoven University of Technology,"IEEE Software","12 Mar 2018","2018","35","2","102","104","This issue’s column reports on the 33rd International Conference on Software Maintenance and Evolution and 32nd International Conference on Automated Software Engineering. Topics include flaky tests, technical debt, QA bots, and regular expressions.","1937-4194","","10.1109/MS.2018.1661318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314151","33rd International Conference on Software Maintenance and Evolution;ICSME 17;32nd International Conference on Automated Software Engineering;ASE 17;software maintenance;software evolution;automated software engineering;flaky tests;technical debt;self-admitted technical debt;SATD;QA bots;regular expressions;regexes;software engineering;software development;Practitioners’ Digest","","","","","","","","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Broken External Links on Stack Overflow","J. Liu; X. Xia; D. Lo; H. Zhang; Y. Zou; A. E. Hassan; S. Li","College of Computer Science and Technology, Zhejiang University, 12377 Hangzhou, Zhejiang, China, (e-mail: jkliu@zju.edu.cn); Software Engineering Application Technology Lab, Huawei Technologies Co Ltd, 115371 Shenzhen, Guangdong, China, (e-mail: xin.xia@acm.org); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); School of Computing, Queen's University, Kingston, Ontario, Canada, K7M1B5 (e-mail: haoxiang.zhang@huawei.com); Electrical and Computer Enginereing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ying.zou@queensu.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: shan@zju.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Stack Overflow hosts 11,926,354 links that reference to the programming-related knowledge in third-party websites. The links that reference to the resources hosted outside the Stack Overflow websites extend the Stack Overflow knowledge base substantially. However, with the rapid development of programming-related knowledge, many resources hosted on the Internet are not available anymore. Based on our analysis of the Stack Overflow data that was released on Jun. 2, 2019, 14.2% of the links on Stack Overflow are broken links. The broken links on Stack Overflow can obstruct viewers from obtaining desired programming-related knowledge, and potentially damage the reputation of the Stack Overflow as viewers might regard the posts with broken links as obsolete. In this paper, we characterize the broken links on Stack Overflow. 63% of the broken links in questions are used to show examples, e.g., code examples. 80% of the broken links in answers are used to provide supporting information, e.g., explaining a certain concept and describing a step to solve a problem. Only 1.67% of the posts with broken links are highlighted as such by viewers in the posts' comments. Only 5.8% of the posts with broken links removed the broken links. Viewers cannot fully rely on the vote scores to detect broken links, as broken links are common across posts with different vote scores. The websites that host resources that can be maintained by their users are referenced by broken links the most on Stack Overflow -- a prominent example of such websites is GitHub. The posts and comments related to the web technologies, i.e., JavaScript, HTML, CSS, and jQuery, are associated with more broken links. Based on our findings, we shed lights for future directions and provide recommendations for practitioners and researchers.","1939-3520","","10.1109/TSE.2021.3086494","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447188","Empirical Software Engineering;Stack Overflow;Broken Link","Internet;Software engineering;Software;Knowledge engineering;Web search;Computer bugs;Tools","","","","","","","IEEE","4 Jun 2021","","","IEEE","IEEE Early Access Articles"
"The History of Software Engineering","G. Booch",NA,"IEEE Software","27 Sep 2018","2018","35","5","108","114","Grady Booch, one of UML's original authors, offers his perspective on the history of software engineering. This article is part of a theme issue on software engineering's 50th anniversary. The Web Extra, a version of the article with an expanded bibliography, is at https://extras.computer.org/extra/mso2018050108s1.pdf.","1937-4194","","10.1109/MS.2018.3571234","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474489","history of software engineering;software development;Grady Booch","Computers;Software engineering;Software development;Programming;History","history;Internet;software engineering;Unified Modeling Language","software engineering;Grady Booch;Web extra;bibliography;history;UML original authors","","5","","10","","27 Sep 2018","","","IEEE","IEEE Magazines"
"What the Errors Tell Us","M. H. Hamilton",Hamilton Technologies,"IEEE Software","27 Sep 2018","2018","35","5","32","37","Margaret Hamilton talks about her experiences over the last 60 years and how a “theory of errors” was derived from the errors made along the way. Its axioms of control led to the Universal Systems Language (USL) together with its automation and preventative paradigm, development-before-the-fact. The pressing issues haven't gone away, largely because the traditional paradigm continues in force. With a preventative paradigm, most errors aren't allowed into a system in the first place, just by the way the system is defined. Unlike a traditional approach, with a preventative approach the more reliable the system, the higher the productivity in its lifecycle. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290110447","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409915","preventative paradigm;ultrareliable software;nonprocedural languages;programming languages;dataflow languages;software engineering;operating systems;software development","Software engineering;Error analysis;Software development;Programming;Computer languages","software engineering;specification languages;systems engineering","Universal Systems Language;USL;preventative paradigm;preventative approach;productivity;software engineering","","","","12","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Software Analytics: What’s Next?","T. Menzies; T. Zimmermann",North Carolina State University; Microsoft Research,"IEEE Software","27 Sep 2018","2018","35","5","64","70","Knowing what factors control software projects is very useful because humans might not understand those factors. Developers sometimes develop their own ideas about good and bad software, on the basis of just a few past projects. Using software analytics, we can correct those misconceptions. Software analytics lets software engineers learn about AI techniques. Once they learn those techniques, they can build and ship innovative AI tools. That is, software analytics is the training ground for the next generation of AI-literate software engineers. This article is part of a special issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290111035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409908","software;software analytics;data mining;software development;software engineering","Software development;Artificial intelligence;5G mobile communication;Computer bugs;Software engineering;Data mining","artificial intelligence;project management;software engineering","software analytics;software projects;AI-literate software engineers;software engineering;AI techniques","","2","","41","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Collaborative Model-Driven Software Engineering: A Classification Framework and a Research Map","M. Franzago; D. D. Ruscio; I. Malavolta; H. Muccini","Department of Information Engineering, Computer Science and Mathematics (DISIM), University of L'Aquila, L'Aquila, AQ, Italy; Department of Information Engineering, Computer Science and Mathematics (DISIM), University of L'Aquila, L'Aquila, AQ, Italy; Department of Computer Science, Vrije Universiteit Amsterdam, Amsterdam, North Holland, HV, The Netherlands; Department of Information Engineering, Computer Science and Mathematics (DISIM), University of L'Aquila, L'Aquila, AQ, Italy","IEEE Transactions on Software Engineering","9 Dec 2018","2018","44","12","1146","1175","Context: Collaborative Model-Driven Software Engineering (MDSE) consists of methods and techniques where multiple stakeholders manage, collaborate, and are aware of each others' work on shared models. Objective: Collaborative MDSE is attracting research efforts from different areas, resulting in a variegated scientific body of knowledge. This study aims at identifying, classifying, and understanding existing collaborative MDSE approaches. Method: We designed and conducted a systematic mapping study. Starting from over 3,000 potentially relevant studies, we applied a rigorous selection procedure resulting in 106 selected papers, further clustered into 48 primary studies along a time span of 19 years. We rigorously defined and applied a classification framework and extracted key information from each selected study for subsequent analysis. Results: Our analysis revealed the following main fidings: (i) there is a growing scientific interest on collaborative MDSE in the last years; (ii) multi-view modeling, validation support, reuse, and branching are more rarely covered with respect to other aspects about collaborative MDSE; (iii) different primary studies focus differently on individual dimensions of collaborative MDSE (i.e., model management, collaboration, and communication); (iv) most approaches are language-specific, with a prominence of UML-based approaches; (v) few approaches support the interplay between synchronous and asynchronous collaboration. Conclusion: This study gives a solid foundation for classifying existing and future approaches for collaborative MDSE. Researchers and practitioners can use our results for identifying existing research/technical gaps to attack, better scoping their own contributions, or understanding existing ones.","1939-3520","","10.1109/TSE.2017.2755039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8047991","Collaborative MDSE;CoMDSE;C-MDSE;model-driven engineering;collaborative software engineering;CoSE;systematic mapping study","Collaboration;Analytical models;Software engineering;Stakeholders;Systematics","formal specification;groupware;Unified Modeling Language","asynchronous collaboration;Collaborative Model-Driven Software Engineering;classification framework;systematic mapping study;synchronous collaboration;primary studies;collaborative MDSE approaches;time 19.0 year","","5","","119","","21 Sep 2017","","","IEEE","IEEE Journals"
"Exploring Community Smells in Open-Source: An Automated Approach","D. A. Tamburri; F. Palomba; R. Kazman","Eindhoven University of Technology, Eindhoven, The Netherlands; University of Zurich, Zurich, Switzerland; University of Hawaii & SEI/CMU, Honolulu, Hawaii, USA","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","630","652","Software engineering is now more than ever a community effort. Its success often weighs on balancing distance, culture, global engineering practices and more. In this scenario many unforeseen socio-technical events may result into additional project cost or “social” debt, e.g., sudden, collective employee turnover. With industrial research we discovered community smells, that is, sub-optimal patterns across the organisational and social structure in a software development community that are precursors of such nasty socio-technical events. To understand the impact of community smells at large, in this paper we first introduce CodeFace4Smells, an automated approach able to identify four community smell types that reflect socio-technical issues that have been shown to be detrimental both the software engineering and organisational research fields. Then, we perform a large-scale empirical study involving over 100 years worth of releases and communication structures data of 60 open-source communities: we evaluate (i) their diffuseness, i.e., how much are they distributed in open-source, (ii) how developers perceive them, to understand whether practitioners recognize their presence and their negative effects in practice, and (iii) how community smells relate to existing socio-technical factors, with the aim of assessing the inter-relations between them. The key findings of our study highlight that community smells are highly diffused in open-source and are perceived by developers as relevant problems for the evolution of software communities. Moreover, a number of state-of-the-art socio-technical indicators (e.g., socio-technical congruence) can be used to monitor how healthy a community is and possibly avoid the emergence of social debt.","1939-3520","","10.1109/TSE.2019.2901490","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651329","Software organisational structures;software community smells;human aspects in software engineering;social software engineering;empirical software engineering;","Software engineering;Open source software;Organizational aspects;Social networking (online);Tools;Microstructure","project management;public domain software;socio-economic effects;software development management;team working","socio-technical factors;community smells;software communities;socio-technical congruence;automated approach;software engineering;global engineering practices;organisational structure;social structure;software development community;CodeFace4Smells;open-source communities;socio-technical issues;community smell types","","7","","84","IEEE","24 Feb 2019","","","IEEE","IEEE Journals"
"Grey Literature Versus Academic Literature in Software Engineering: A Call for Epistemological Analysis","V. Garousi; A. Rainer","Computer Science, Queen's University Belfast, Belfast, Belfast, United Kingdom of Great Britain and Northern Ireland; School of Electronics, Electrical Engineering and Computer Science (EEECS), Queen's University Belfast, Belfast, Belfast, United Kingdom of Great Britain and Northern Ireland","IEEE Software","","2020","PP","99","0","0","To learn about novel software engineering (SE) trends, where do you refer to? In order to document and disseminate their experience / knowledge, many SE practitioners prepare technical materials and share them online as blog posts, white papers and videos. Such materials are often called “grey literature” because they are not formally peer reviewed. By contrast, SE researchers write technical papers that are peer-reviewed and published as academic literature. We observe that, in general, these two communities mostly read literature that is only written by and published within their respective communities. This situation has led to a form of “knowledge divide” between the two communities that, we believe, hurts both communities. By characterizing and contrasting the two types of literature, grey and academic, we discuss how each literature can complement the other and can lead to a richer and more integrated knowledge exchange and dissemination in SE.","1937-4194","","10.1109/MS.2020.3022931","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190027","Grey literature;academic literature;information needs;evidence-based software engineering","Software testing;Industries;Software engineering;Software;Decision making;Collaboration","","","","","","","","9 Sep 2020","","","IEEE","IEEE Early Access Articles"
"The End to the Myth of Individual Programmer Productivity","W. R. Nichols","Software Engineering, Carnegie Mellon University","IEEE Software","16 Aug 2019","2019","36","5","71","75","One often-quoted truism in software engineering is that good programmers are ""much much better"" than bad programmers. The size of ""much much better"" is widely debated, but ranges such as 10 times more productive are often cited as conservative estimates. This article argues that such statements are misleading and miss numerous important effects. Based on the studies described later, it would appear that some programmers are not inherently exceedingly better than others.","1937-4194","","10.1109/MS.2019.2908576","Department of Defense; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8804291","","Productivity;Software engineering;Security;Programming profession","software engineering","individual programmer productivity;software engineering","","1","","14","","16 Aug 2019","","","IEEE","IEEE Magazines"
"The Importance of the Correlation in Crossover Experiments","B. A. Kitchenham; L. Madeyski; G. Scanniello; C. Gravino","School of Computing and Mathematics, Keele University, Newcastle-under-Lyme, Staffordshire, United Kingdom of Great Britain and Northern Ireland, (e-mail: b.a.kitchenham@keele.ac.uk); Department of Applied Informatics, Wroclaw University of Science and Technology, 49567 Wroclaw, Dolnoslaskie, Poland, (e-mail: lech.madeyski@pwr.edu.pl); Giuseppe Scanniello, Universita degli Studi della Basilicata, 19006 Potenza, PZ, Italy, 85100 (e-mail: giuseppe.scanniello@unibas.it); Department of Computer Science, University of Salerno, Salerno, Fisciano, Italy, 84084 (e-mail: gravino@unisa.it)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Context: In empirical software engineering, crossover designs are popular for experiments comparing software engineering techniques that must be undertaken by human participants. However, their value depends on the correlation (r) between the outcome measures on the same participants. Software engineering theory emphasizes the importance of individual skill differences, so we would expect the values of r to be relatively high. However, few researchers have reported the values of r. Goal: To investigate the values of r found in software engineering experiments. Method: We undertook simulation studies to investigate the theoretical and empirical properties of r. Then we investigated the values of r observed in 35 software engineering crossover experiments. Results: The level of r obtained by analysing our 35 crossover experiments was small. Estimates based on means, medians, and random effect analysis disagreed but were all between 0.2 and 0.3. As expected, our analyses found large variability among the individual r estimates for small sample sizes, but no indication that r estimates were larger for the experiments with larger sample sizes that exhibited smaller variability. Conclusions: Low observed r values cast doubts on the validity of crossover designs for software engineering experiments. However, if the cause of low r values relates to training limitations or toy tasks, this affects all Software Engineering (SE) experiments involving human participants. For all human-intensive SE experiments, we recommend more intensive training and then tracking the improvement of participants as they practice using specific techniques, before formally testing the effectiveness of the techniques.","1939-3520","","10.1109/TSE.2021.3070480","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395223","empirical software engineering;experiments;crossover experiments;crossover design;repeated measures correlation","Particle measurements;Atmospheric measurements;Correlation;Size measurement;Mathematical model;Time measurement;Software engineering","","","","","","","CCBY","5 Apr 2021","","","IEEE","IEEE Early Access Articles"
"What Makes a Great Manager of Software Engineers?","E. Kalliamvakou; C. Bird; T. Zimmermann; A. Begel; R. DeLine; D. M. German","Department of Computer Science, University of Victoria, Victoria, BC, Canada; Microsoft Corportation, Redmond, WA; Microsoft Corportation, Redmond, WA; Microsoft Corportation, Redmond, WA; Microsoft Corportation, Redmond, WA; Department of Computer Science, University of Victoria, Victoria, BC, Canada","IEEE Transactions on Software Engineering","8 Jan 2019","2019","45","1","87","106","Having great managers is as critical to success as having a good team or organization. In general, a great manager is seen as fuelling the team they manage, enabling it to use its full potential. Though software engineering research studies factors that may affect the performance and productivity of software engineers and teams (like tools and skills), it has overlooked the software engineering manager. The software industry's growth and change in the last decades is creating a need for a domain-specific view of management. On the one hand, experts are questioning how the abundant work in management applies to software engineering. On the other hand, practitioners are looking to researchers for evidence-based guidance on how to manage software teams. We conducted a mixed methods empirical study of software engineering management at Microsoft to investigate what manager attributes developers and engineering managers perceive important and why. We present a conceptual framework of manager attributes, and find that technical skills are not the sign of greatness for an engineering manager. Through statistical analysis we identify how engineers and managers relate in their views, and how software engineering differs from other knowledge work groups in its perceptions about what makes great managers. We present strategies for putting the attributes to use, discuss implications for research and practice, and offer avenues for further work.","1939-3520","","10.1109/TSE.2017.2768368","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8094304","software engineering management;empirical studies;software companies","Software engineering;Software;Organizations;Knowledge engineering;Productivity;Interviews;Psychology","software development management;software engineering;statistical analysis","software industry;software teams;software engineering management;manager attributes;evidence-based guidance;statistical analysis","","3","","108","","2 Nov 2017","","","IEEE","IEEE Journals"
"Successful Engagement of Practitioners and Software Engineering Researchers: Evidence From 26 International Industry–Academia Collaborative Projects","V. Garousi; D. C. Shepherd; K. Herkiloglu","Software Engineering, Queen’s University Belfast, Ireland; Virginia Commonwealth University, Virginia United States; HAVELSAN, Ankara, Turkey","IEEE Software","23 Oct 2020","2020","37","6","65","75","There has been a push to increase the practical relevance and impact of software engineering research. Although many practitioners and researchers agree that this change is desirable, thus far, only a few concrete actions have been taken by the community. In this article, we present our experiences with a large number of collaborative research projects that have had a practical (industrial) impact.","1937-4194","","10.1109/MS.2019.2914663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704922","Industry-academia collaborations;experience report;lessons learned;applied research","Industries;Collaboration;Software engineering;Companies;Software;Testing;Reflection","groupware;research and development;software engineering;software management","international industry-academia collaborative projects;software engineering researchers;collaborative research projects","","","","27","","2 May 2019","","","IEEE","IEEE Magazines"
"Software Engineering for Sustainability: Find the Leverage Points!","B. Penzenstadler; L. Duboc; C. C. Venters; S. Betz; N. Seyff; K. Wnuk; R. Chitchyan; S. M. Easterbrook; C. Becker","California State University, Long Beach; La Salle—University Ramon Llull; University of Huddersfield; Furtwangen University; University of Applied Sciences and Arts Northwestern Switzerland; Blekinge Institute of Technology; University of Bristol; University of Toronto; University of Toronto","IEEE Software","6 Jul 2018","2018","35","4","22","33","We as software engineers are responsible for the long-term consequences of the systems we design-including impacts on the wider environmental and societal sustainability. However, the field lacks analytical tools for understanding these potential impacts while designing a system or for identifying opportunities for using software to bring about broader societal transformations. This article explores how the concept of leverage points can be used to make sustainability issues more tangible in system design. The example of software for transportation systems illustrates how leverage points can help software engineers map out and investigate the wider system in which the software resides, such that we can use software as an effective tool for engineering a more sustainable world. This article is part of a theme issue on Process Improvement.","1937-4194","","10.1109/MS.2018.110154908","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254307","sustainability;leverage points;software engineering;software development","Sustainable development;Feedback loop;Software engineering;System analysis and design;Social implications of technology","software engineering;sustainable development","environmental sustainability;societal transformations;process improvement;sustainable world;wider system;transportation systems;system design;sustainability issues;societal sustainability;long-term consequences;software engineers;leverage points;software engineering","","7","","25","","11 Jan 2018","","","IEEE","IEEE Magazines"
"Bayesian Data Analysis in Empirical Software Engineering Research","C. A. Furia; R. Feldt; R. Torkar","Faculty of Informatics, USI, 27216 Lugano, TI Switzerland (e-mail: furiac@usi.ch); Department of Computer Science of Engineering, Chalmers University, Gothenburg, Västra Götaland Sweden (e-mail: robert.feldt@bth.se); Computer Science and Engineering, Chalmers tekniska hogskola, 11248 Goteborg, Vastra Gotaland Sweden (e-mail: richard.torkar@gmail.com)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Statistics comes in two main flavors: frequentist and Bayesian. For historical and technical reasons, frequentist statistics have traditionally dominated empirical data analysis, and certainly remain prevalent in empirical software engineering. This situation is unfortunate because frequentist statistics suffer from a number of shortcomings---such as lack of flexibility and results that are unintuitive and hard to interpret---that curtail their effectiveness when dealing with the heterogeneous data that is increasingly available for empirical analysis of software engineering practice. In this paper, we pinpoint these shortcomings, and present Bayesian data analysis techniques that provide tangible benefits---as they can provide clearer results that are simultaneously robust and nuanced. After a short, high-level introduction to the basic tools of Bayesian statistics, we present the reanalysis of two empirical studies on the effectiveness of automatically generated tests and the performance of programming languages, respectively. By contrasting the original frequentist analyses with our new Bayesian analyses, we demonstrate the concrete advantages of the latter. To conclude we advocate a more prominent role for Bayesian statistical techniques in empirical software engineering research and practice.","1939-3520","","10.1109/TSE.2019.2935974","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807222","Bayesian data analysis;statistical analysis;statistical hypothesis testing;empirical software engineering","Bayes methods;Software engineering;Testing;Data analysis;Machine learning;Statistical analysis;Software","","","","2","","","","20 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Search-Based Crash Reproduction and Its Impact on Debugging","M. Soltani; A. Panichella; A. van Deursen","Software Engineering Research Group, Delft University of Technology, Delft, Netherlands; Software Engineering Research Group, Delft University of Technology, Delft, Netherlands; Software Engineering Research Group, Delft University of Technology, Delft, Netherlands","IEEE Transactions on Software Engineering","10 Dec 2020","2020","46","12","1294","1317","Software systems fail. These failures are often reported to issue tracking systems, where they are prioritized and assigned to responsible developers to be investigated. When developers debug software, they need to reproduce the reported failure in order to verify whether their fix actually prevents the failure from happening again. Since manually reproducing each failure could be a complex task, several automated techniques have been proposed to tackle this problem. Despite showing advancements in this area, the proposed techniques showed various types of limitations. In this paper, we present EvoCrash, a new approach to automated crash reproduction based on a novel evolutionary algorithm, called Guided Genetic Algorithm (GGA). We report on our empirical study on using EvoCrash to reproduce 54 real-world crashes, as well as the results of a controlled experiment, involving human participants, to assess the impact of EvoCrash tests in debugging. Based on our results, EvoCrash outperforms state-of-the-art techniques in crash reproduction and uncovers failures that are undetected by classical coverage-based unit test generation tools. In addition, we observed that using EvoCrash helps developers provide fixes more often and take less time when debugging, compared to developers debugging and fixing code without using EvoCrash tests.","1939-3520","","10.1109/TSE.2018.2877664","EU; Fonds National de la Recherche Luxembourg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502801","Search-based software testing;genetic algorithms;automated crash reproduction;empirical software engineering","Debugging;Genetic algorithms;Software testing;Software engineering;Computer bugs","genetic algorithms;program debugging;program testing;public domain software;system recovery","software systems;responsible developers;reported failure;automated techniques;automated crash reproduction;evolutionary algorithm;real-world crashes;guided genetic algorithm;EvoCrash tests;classical coverage-based unit test generation tools;fixing code;developer debug software;developer debugging;tracking systems;GGA;human participants","","4","","85","IEEE","23 Oct 2018","","","IEEE","IEEE Journals"
"Human Values in Software Engineering: Contrasting Case Studies of Practice","W. Hussain; H. Perera; J. Whittle; A. Nurwidyantoro; R. Hoda; R. A. Shams; G. Oliver","Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: waqar.hussain@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: harsha.perera@monash.edu); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: jon.whittle@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: arif.nurwidyantoro@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail:rashina.hoda@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: rifat.shams@monash.edu); Faculty of IT, monash university, Melbourne, Victoria Australia (e-mail: Gillian.Oliver@monash.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The growing diffusion of software in society and its influence on people demands from its creators that their work carefully considers human values such as transparency, social responsibility, and equality. But how do software practitioners address human values in software engineering practice’ We interviewed 31 software practitioners from two organizations, each having a strong values framework, with the aim to understand: (a) practitioners’ perceptions of human values and their role in software engineering; (b)practices that practitioners use to address human values in software; and (c) challenges they face during this process. We report our findings from two contrasting case studies on how practitioners “engineer” values in their unique organizational settings. We found evidence that organizational culture significantly contributes to how values are addressed in software. We summarize recommendations from the practitioners to support proactive engineering of values-conscious software.","1939-3520","","10.1109/TSE.2020.3038802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261980","Engineering Human Values;Software Engineering;Human Values in Software Practice;Challenges in Human Values;Case Studies of Practice;Ethics;Responsible Innovations;Non-functional Requirements","Software;Software engineering;Privacy;Security;Companies;Human factors;Artificial intelligence","","","","","","","IEEE","17 Nov 2020","","","IEEE","IEEE Early Access Articles"
"Bridging the Gap: From Research to Practical Advice","C. L. Goues; C. Jaspan; I. Ozkaya; M. Shaw; K. T. Stolee",Carnegie Mellon University; Google; Carnegie Mellon University; Carnegie Mellon University; North Carolina State University,"IEEE Software","27 Sep 2018","2018","35","5","50","57","Software engineers must solve practical problems under deadline pressure. They rely on the best-codified knowledge available, turning to weaker results and their expert judgment when sound science is unavailable. Meanwhile, software engineering researchers seek fully validated results, resulting in a lag to practical guidance. To bridge this gap, research results should be systematically distilled into actionable guidance in a way that respects differences in strength and scope among the results. Starting with the practitioners' need for actionable guidance, this article reviews the evolution of software engineering research expectations, identifies types of results and their strengths, and draws on evidence-based medicine for a concrete example of deriving pragmatic guidance from mixed-strength research results. It advances a levels-of-evidence framework to allow researchers to clearly identify the strengths of their claims and the supporting evidence for their results and to work with practitioners to synthesize actionable recommendations from diverse types of evidence. This article is part of a special issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.3571235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474493","levels of evidence;evidence-based software engineering;evidence-based medicine;software engineering;computing profession;software development","Systematics;Decision making;Software engineering;Static analysis;Computer bugs","software engineering","software engineering research expectations;evidence-based medicine;pragmatic guidance;levels-of-evidence framework;actionable recommendations","","6","","17","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Code Vault","G. J. Holzmann",Nimble Research,"IEEE Software","27 Sep 2018","2018","35","5","85","87","So, what has changed since that first NATO software engineering conference in 1968? Depending on your point of view, nothing much has changed, or everything has changed. The part that didn't change much is that we still struggle with writing code that's robust enough to trust. The part that has changed dramatically is the performance of the hardware that runs our code. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.3571225","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474479","software errors;software technology;history of software engineering;software engineering;software development;Reliable Code","Error analysis;Software development;Software reliability;Random access memory;Computer bugs","software engineering","code vault;NATO software engineering conference;hardware performance","","","","3","","27 Sep 2018","","","IEEE","IEEE Magazines"
"A Wizard of Oz Study Simulating API Usage Dialogues with a Virtual Assistant","Z. Eberhart; A. Bansal; C. Mcmillan","Computer Science, University of Notre Dame, 6111 Notre Dame, Indiana, United States, (e-mail: zacharyeberhart@gmail.com); Computer Science, University of Notre Dame, 6111 Notre Dame, Indiana, United States, (e-mail: abansal1@nd.edu); Computer Science, University of Notre Dame, 6111 Notre Dame, Indiana, United States, (e-mail: cmc@nd.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Virtual Assistant technology is rapidly proliferating to improve productivity in a variety of tasks. While several virtual assistants for everyday tasks are well-known (e.g., Siri, Cortana, Alexa), assistants for specialty tasks such as software engineering are rarer. One key reason software engineering assistants are rare is that very few experimental datasets are available and suitable for training the AI that is the bedrock of current virtual assistants. In this paper, we present a set of Wizard of Oz experiments that we designed to build a dataset for creating a virtual assistant. Our target is a hypothetical virtual assistant for helping programmers use APIs. In our experiments, we recruited 30 professional programmers to complete programming tasks using two APIs. The programmers interacted with a simulated virtual assistant for help the programmers were not aware that the assistant was actually operated by human experts. We then annotated the dialogue acts in the corpus along four dimensions: illocutionary intent, API information type(s), backward-facing function, and traceability to specific API components. We observed a diverse range of interactions that will facilitate the development of dialogue strategies for virtual assistants for API usage.","1939-3520","","10.1109/TSE.2020.3040935","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272865","Intelligent agents;Discourse;Software/Software Engineering;Wizard of Oz (WoZ);Virtual Assistants","Task analysis;Software engineering;Training data;Annotations;Programming profession;Documentation;Navigation","","","","","","","IEEE","27 Nov 2020","","","IEEE","IEEE Early Access Articles"
"On Accelerating Source Code Analysis at Massive Scale","G. Upadhyaya; H. Rajan","Department of Computer Science, Iowa State University, Ames, IA; Department of Computer Science, Iowa State University, Ames, IA","IEEE Transactions on Software Engineering","17 Jul 2018","2018","44","7","669","688","Encouraged by the success of data-driven software engineering (SE) techniques that have found numerous applications e.g., in defect prediction, specification inference, the demand for mining and analyzing source code repositories at scale has significantly increased. However, analyzing source code at scale remains expensive to the extent that data-driven solutions to certain SE problems are beyond our reach today. Extant techniques have focused on leveraging distributed computing to solve this problem, but with a concomitant increase in computational resource needs. This work proposes a technique that reduces the amount of computation performed by the ultra-large-scale source code mining task, especially those that make use of control and data flow analyses. Our key idea is to analyze the mining task to identify and remove the irrelevant portions of the source code, prior to running the mining task. We show a realization of our insight for mining and analyzing massive collections of control flow graphs of source codes. Our evaluation using 16 classical control-/data-flow analyses that are typical components of mining tasks and 7 Million CFGs shows that our technique can achieve on average a 40 percent reduction in the task computation time. Our case studies demonstrates the applicability of our technique to massive scale source code mining tasks.","1939-3520","","10.1109/TSE.2018.2828848","US National Science Foundation (NSF); US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8344505","Source code analysis;mining software repositories;ultra-large-scale mining;data-driven software engineering","Task analysis;Data mining;Acceleration;Static analysis;Software engineering;Distributed computing;Software","data flow analysis;data mining;software engineering;source code (software)","control-flow analyses;ultralarge-scale source code mining task;source code repository analysis;massive scale source code mining tasks;task computation time;control flow graphs;data flow analyses;specification inference;defect prediction;data-driven software engineering techniques","","3","","34","","20 Apr 2018","","","IEEE","IEEE Journals"
"Does Reviewer Recommendation Help Developers?","V. Kovalenko; N. Tintarev; E. Pasynkov; C. Bird; A. Bacchelli","Software Engineering Research Group, Delft University of Technology, Delft, CD, The Netherlands; Web Information Systems Group, Delft University of Technology, Delft, CD, The Netherlands; JetBrains GmbH, Munich, Germany; Microsoft Research, Microsoft, Redmond, WA, USA; ZEST, University of Zürich, Zürich, Zürich, Switzerland","IEEE Transactions on Software Engineering","15 Jul 2020","2020","46","7","710","731","Selecting reviewers for code changes is a critical step for an efficient code review process. Recent studies propose automated reviewer recommendation algorithms to support developers in this task. However, the evaluation of recommendation algorithms, when done apart from their target systems and users (i.e., code review tools and change authors), leaves out important aspects: perception of recommendations, influence of recommendations on human choices, and their effect on user experience. This study is the first to evaluate a reviewer recommender in vivo. We compare historical reviewers and recommendations for over 21,000 code reviews performed with a deployed recommender in a company environment and set out to measure the influence of recommendations on users' choices, along with other performance metrics. Having found no evidence of influence, we turn to the users of the recommender. Through interviews and a survey we find that, though perceived as relevant, reviewer recommendations rarely provide additional value for the respondents. We confirm this finding with a larger study at another company. The confirmation of this finding brings up a case for more user-centric approaches to designing and evaluating the recommenders. Finally, we investigate information needs of developers during reviewer selection and discuss promising directions for the next generation of reviewer recommendation tools. Preprint: https://doi.org/10.5281/zenodo.1404814.","1939-3520","","10.1109/TSE.2018.2868367","Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453850","Code review;reviewer recommendation;empirical software engineering","Tools;Recommender systems;Companies;Measurement;Software;In vivo;Software engineering","recommender systems;review sites;software engineering;source code (software)","code review tools;user experience;historical reviewers;user-centric approaches;reviewer selection;reviewer recommendation tools;code review process;automated reviewer recommendation algorithms","","4","","74","IEEE","2 Sep 2018","","","IEEE","IEEE Journals"
"Which Commits Can Be CI Skipped?","R. Abdalkareem; S. Mujahid; E. Shihab; J. Rilling","Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Data-driven Analysis of Software (DAS) Lab, Concordia University, Montreal, QC, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","448","463","Continuous Integration (CI) frameworks such as Travis CI, automatically build and run tests whenever a new commit is submitted/pushed. Although there are many advantages in using CI, e.g., speeding up the release cycle and automating the test execution process, it has been noted that the CI process can take a very long time to complete. One of the possible reasons for such delays is the fact that some commits (e.g., changes to readme files) unnecessarily kick off the CI process. Therefore, the goal of this paper is to automate the process of determining which commits can be CI skipped. We start by examining the commits of 58 Java projects and identify commits that were explicitly CI skipped by developers. Based on the manual investigation of 1,813 explicitly CI skipped commits, we first devise an initial model of a CI skipped commit and use this model to propose a rule-based technique that automatically identifies commits that should be CI skipped. To evaluate the rule-based technique, we perform a study on unseen datasets extracted from ten projects and show that the devised rule-based technique is able to detect and label CI skip commits, achieving Areas Under the Curve (AUC) values between 0.56 and 0.98 (average of 0.73). Additionally, we show that, on average, our technique can reduce the number of commits that need to trigger the CI process by 18.16 percent. We also qualitatively triangulated our analysis on the importance of skipping the CI process through a survey with 40 developers. The survey results showed that 75 percent of the surveyed developers consider it to be nice, important or very important to have a technique that automatically flags CI skip commits. To operationalize our technique, we develop a publicly available prototype tool, called CI-Skipper, that can be integrated with any git repository and automatically mark commits that can be CI skipped.","1939-3520","","10.1109/TSE.2019.2897300","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8633335","Continuous integration;travis CI;build status;mining software repository","Java;Software;Prototypes;Tools;Virtual machining;Data collection;Manuals","Java;program testing;project management;public domain software;software engineering","AUC values;area under the curve;CI-Skipper;automatically flagged CI skip commits;Travis CI;continuous integration frameworks;rule-based technique","","4","","41","IEEE","3 Feb 2019","","","IEEE","IEEE Journals"
"A Theory of Value for Value-based Feature Selection in Software Engineering","P. Rodriguez; C. Urquhart; E. Mendes","Department of Information Processing Sciences, University of Oulu, Oulu, Oulu Finland 90014 (e-mail: pilar.rodriguez@oulu.fi); Business School, Manchester Metropolitan University, 5289 Manchester, Greater Manchester United Kingdom of Great Britain and Northern Ireland (e-mail: c.urquhart@mmu.ac.uk); Computer Science, Blekinge Tekniska Hogskola, 4206 Karlskrona, Blekinge Sweden 371 79 (e-mail: emilia.mendes@bth.se)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Value-Based Software Engineering stresses the role of value in software related decisions. In the context of feature selection, software features judged to provide higher value take priority in the development process. This paper focuses on what value means when selecting software features. Using grounded theory, we conducted and analyzed semi-structured interviews with 21 key stakeholders (decision-makers) from three software/software-intensive companies, within a context where value-based decision-making was already established. Our analysis led to the building of a theory of value for value-based feature selection that identifies the nature of value propositions considered by key stakeholders when selecting software features (i.e. decision-making criteria for deciding upon software features, as suggested by Boehm (2003)). We found that some value propositions were common to all three company cases (core value propositions), whereas others were dependent upon the context in which a company operates, and the characteristics of the product under development (specific value propositions). Moreover, value propositions vary according to the stakeholder group and the type of feature being assessed. Our study provides significant insight into value in the context of feature selection, and generates new concepts around value-based feature selection such as new value propositions.","1939-3520","","10.1109/TSE.2020.2989666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9088281","Value-based Software Engineering (VBSE);Value Proposition;Decision-making Criteria;Grounded-theory;Theory Development;Feature Selection;Release Planning;Requirements Engineering;Decision-making;Decision-making Theory;Software Value;Software Products;Software-intensive Systems","Software;Feature extraction;Stakeholders;Companies;Decision making;Software engineering;Planning","","","","","","","","6 May 2020","","","IEEE","IEEE Early Access Articles"
"How to Evaluate Solutions in Pareto-based Search-Based Software Engineering? A Critical Review and Methodological Guidance","M. Li; T. Chen; X. Yao","School of Computer Science, University of Birmingham, 1724 Birmingham, Birmingham United Kingdom of Great Britain and Northern Ireland (e-mail: M.Li.8@cs.bham.ac.uk); Department of Computer Science, Loughborough University, 5156 Loughborough, UK United Kingdom of Great Britain and Northern Ireland (e-mail: t.t.chen@lboro.ac.uk); Department of Computer Science and Engnieering, Southern University of Science and Technology, 255310 Shenzhen, Guangdong China (e-mail: xiny@sustc.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","With modern requirements, there is an increasing tendency of considering multiple objectives/criteria simultaneously in many Software Engineering (SE) scenarios. Such a multi-objective optimization scenario comes with an important issue - how to evaluate the outcome of optimization algorithms, which typically is a set of incomparable solutions (i.e., being Pareto nondominated to each other). This issue can be challenging for the SE community, particularly for practitioners of Search-Based SE (SBSE). On one hand, multi-objective optimization could still be relatively new to SE/SBSE researchers, who may not be able to identify the right evaluation methods for their problems. On the other hand, simply following the evaluation methods for general multi-objective optimization problems may not be appropriate for specific SBSE problems, especially when the problem nature or decision maker's preferences are explicitly/implicitly known. This has been well echoed in the literature by various inappropriate/inadequate selection and inaccurate/misleading use of evaluation methods. In this paper, we first carry out a systematic and critical review of quality evaluation for multi-objective optimization in SBSE. We survey 717 papers published between 2009 and 2019 from 36 venues in seven repositories, and select 95 prominent studies, through which we identify five important but overlooked issues in the area. We then conduct an in-depth analysis of quality evaluation indicators/methods and general situations in SBSE, which, together with the identified issues, enables us to codify a methodological guidance for selecting and using evaluation methods in different SBSE scenarios.","1939-3520","","10.1109/TSE.2020.3036108","University Key Laboratory of Guangdong Province; Guangdong Introducing Innovative and Enterpreneurial Teams; Guangdong Provincial Key Laboratory; Shenzhen Science and Technology Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252185","Search-based software engineering;multi-objective optimization;Pareto optimization;quality evaluation;quality indicators;preferences","Software engineering;Pareto optimization;Computer science;Systematics;Indexes;Licenses","","","","1","","","CCBY","9 Nov 2020","","","IEEE","IEEE Early Access Articles"
"50 Years of Software Engineering: Progress and Perils","C. Ebert",Vector Consulting Services,"IEEE Software","27 Sep 2018","2018","35","5","94","101","A survey of software professionals worldwide suggests the past, present, and future challenges of software engineering. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.3571228","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474504","software complexity;magic triangle;software crisis;agile development;digital transformation;software engineering;software development;software technology","Agile software development;Software development;Computer security;Complexity theory","software engineering","software engineering;software professionals;future challenges","","4","","5","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Breaking Type-Safety in Go: An Empirical Study on the Usage of the unsafe Package","D. E. Costa; S. Mujahid; R. Abdalkareem; E. Shihab","Department of Computer Science and Software Engineering (CSSE), Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: diego.costa@concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: s_mujahi@encs.concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 1M8 (e-mail: rab_abdu@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: eshihab@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","A decade after its first release, the Go programming language has become a major programming language in the development landscape. While praised for its clean syntax and C-like performance, Go also contains a strong static type-system that prevents arbitrary type casting and arbitrary memory access, making the language type-safe by design. However, to give developers the possibility of implementing low-level code, Go ships with a special package called unsafe that offers developers a way around the type-safety of Go programs. The package gives greater flexibility to developers but comes at a higher risk of runtime errors, chances of non-portability, and the loss of compatibility guarantees for future versions of Go. In this paper, we present the first large-scale study on the usage of the unsafe package in 2,438 popular Go projects. Our investigation shows that unsafe is used in 24% of Go projects, motivated primarily by communicating with operating systems and C code but is also commonly used as a source of performance optimization. Developers are willing to use unsafe to break language specifications (e.g., string immutability) for better performance and 6% of analyzed projects that use unsafe perform risky pointer conversions that can lead to program crashes and unexpected behavior. Furthermore, we report a series of real issues faced by projects that use unsafe, from crashing errors and non-deterministic behavior to having their deployment restricted from certain popular environments. Our findings can be used to understand how and why developers break type-safety in Go and help motivate further tools and language development that could make the usage of unsafe in Go even safer.","1939-3520","","10.1109/TSE.2021.3057720","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350178","Go language;unsafe;type safety;software packages;Empirical Study","Safety;Computer languages;Documentation;Computer crashes;Operating systems;Runtime;Java","","","","","","","IEEE","8 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Looking For Novelty in Search-based Software Product Line Testing","Y. Xiang; H. Huang; M. Li; S. Li; X. Yang","School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: gzhuxiang_yi@163.com); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: hhan@scut.edu.cn); School of Computer Science, University of Birmingham, 1724 Birmingham, Birmingham, United Kingdom of Great Britain and Northern Ireland, (e-mail: M.Li.8@cs.bham.ac.uk); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: chickl@qq.com); School of Software Engineering, South China University of Technology, 26467 Guangzhou, Guangdong, China, (e-mail: xwyang@scut.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Testing software product lines (SPLs) is difficult due to a huge number of possible products to be tested. Recently, there has been a growing interest in similarity-based testing of SPLs, where similarity is used as a surrogate metric for the t-wise coverage. In this context, one of the primary goals is to sample, by optimizing similarity metrics using search-based algorithms, a small subset of test cases (i.e., products) as dissimilar as possible, thus potentially making more t-wise combinations covered. Prior work has shown, by means of empirical studies, the great potential of current similarity-based testing approaches. However, the rationale of this testing technique deserves a more rigorous exploration. To this end, we perform correlation analyses to investigate how similarity metrics are correlated with the t-wise coverage. We find that similarity metrics generally have significantly positive correlations with the t-wise coverage. This well explains why similarity-based testing works, as the improvement on similarity metrics will potentially increase the t-wise coverage. Moreover, we explore, for the first time, the use of the novelty search (NS) algorithm for similarity-based SPL testing. The algorithm rewards “novel” individuals, i.e., those being different from individuals discovered previously, and this well matches the goal of similarity-based SPL testing. We find that the novelty score used in NS has (much) stronger positive correlations with the t-wise overage than previous approaches relying on a genetic algorithm (GA) with a similarity-based fitness function. Experimental results on 31 software product lines validate the superiority of NS over GA, as well as other state-of-the-art approaches, concerning both t-wise coverage and fault detection capacity. Finally, we investigate whether it is useful to combine two satisfiability solvers when generating new individuals in NS, and how the performance of NS is affected by its key parameters. In summary, looking for novelty provides a promising way of sampling diverse test cases for SPLs.","1939-3520","","10.1109/TSE.2021.3057853","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350184","Software product line testing;product sampling;novelty search;similarity-based testing;t-wise coverage;correlation analysis","Testing;Frequency modulation;Measurement;Software;Correlation;Software product lines;Fault detection","","","","","","","IEEE","8 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Studying Duplicate Logging Statements and Their Relationships with Code Clones","Z. Li; T. -H. P. Chen; J. Yang; W. Shang","Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: l_zhenha@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: jinqiuy@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Developers rely on software logs for a variety of tasks, such as debugging, testing, program comprehension, verification, and performance analysis. Despite the importance of logs, prior studies show that there is no industrial standard on how to write logging statements. In this paper, we focus on studying duplicate logging statements, which are logging statements that have the same static text message. Such duplications in the text message are potential indications of logging code smells, which may affect developers understanding of the dynamic view of the system. We manually studied over 4K duplicate logging statements and their surrounding code in five large-scale open source systems: Hadoop, CloudStack, Elasticsearch, Cassandra, and Flink. We uncovered five patterns of duplicate logging code smells. For each instance of the duplicate logging code smell, we further manually identify the potentially problematic (i.e., require fixes) and justifiable (i.e., do not require fixes) cases. Then, we contact developers to verify our manual study result. We integrated our manual study result and developers feedback into our automated static analysis tool, DLFinder, which automatically detects problematic duplicate logging code smells. We evaluated DLFinder on the five manually studied systems and three additional systems: Camel, Kafka and Wicket. In total, combining the results of DLFinder and our manual analysis, we reported 91 problematic duplicate logging code smell instances to developers and all of them have been fixed. We further study the relationship between duplicate logging statements, including the problematic instances of duplicate logging code smells, and code clones. We find that 83% of the duplicate logging code smell instances reside in cloned code, but 17% of them reside in micro-clones that are difficult to detect using automated clone detection tools. We also find that more than half of the duplicate logging statements reside in cloned code snippets, and a large portion of them reside in very short code blocks which may not be effectively detected by existing code clone detection tools. Our study shows that, in addition to general source code that implements the business logic, code clones may also result in bad logging practices that could increase maintenance difficulties.","1939-3520","","10.1109/TSE.2021.3060918","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9360483","log;code smell;duplicate log;code clone;static analysis;empirical study","Cloning;Manuals;Tools;Static analysis;Maintenance engineering;Java;Cloud computing","","","","","","","IEEE","22 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Logram: Efficient Log Parsing Using n-Gram Dictionaries","H. Dai; H. Li; C. S. Chen; W. Shang; T. Chen","Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: he_da@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, (e-mail: hengli@cs.queensu.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: c_chesha@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software systems usually record important runtime information in their logs. Logs help practitioners understand system runtime behaviors and diagnose field failures. As logs are usually very large in size, automated log analysis is needed to assist practitioners in their software operation and maintenance efforts. Typically, the first step of automated log analysis is log parsing, i.e.,converting unstructured raw logs into structured data. However, log parsing is challenging, because logs are produced by static templates in the source code (i.e., logging statements) yet the templates are usually inaccessible when parsing logs. Prior work proposed automated log parsing approaches that have achieved high accuracy. However, as the volume of logs grows rapidly in the era of cloud computing, efficiency becomes a major concern in log parsing. In this work, we propose an automated log parsing approach, Logram, which leverages-gram dictionaries to achieve efficient log parsing. We evaluated Logram on 16 public log datasets and compared Logram with five state-of-the-art log parsing approaches. We found that Logram achieves a higher parsing accuracy than the best existing approaches (i.e., at least 10% higher, on average) and also outperforms these approaches in efficiency (i.e., 1.8 to 5.1 times faster than the second-fastest approaches in terms of end-to-end parsing time). Furthermore, we deployed Logram on Spark and we found that Logram scales out efficiently with the number of Spark nodes (e.g., with near-linear scalability for some logs) without sacrificing parsing accuracy. In addition, we demonstrated that Logram can support effective online parsing of logs, achieving similar parsing results and efficiency to the offline mode.","1939-3520","","10.1109/TSE.2020.3007554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134790","Log parsing;Log analysis;N-gram","Dictionaries;Runtime;Data mining;Cows;Sparks;Software systems;Moon","","","","3","","","","7 Jul 2020","","","IEEE","IEEE Early Access Articles"
"“Sampling” as a Baseline Optimizer for Search-Based Software Engineering","J. Chen; V. Nair; R. Krishna; T. Menzies","Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC","IEEE Transactions on Software Engineering","12 Jun 2019","2019","45","6","597","614","Increasingly, Software Engineering (SE) researchers use search-based optimization techniques to solve SE problems with multiple conflicting objectives. These techniques often apply CPU-intensive evolutionary algorithms to explore generations of mutations to a population of candidate solutions. An alternative approach, proposed in this paper, is to start with a very large population and sample down to just the better solutions. We call this method “Sway”, short for “the sampling way”. This paper compares Sway versus state-of-the-art search-based SE tools using seven models: five software product line models; and two other software process control models (concerned with project management, effort estimation, and selection of requirements) during incremental agile development. For these models, the experiments of this paper show that Sway is competitive with corresponding state-of-the-art evolutionary algorithms while requiring orders of magnitude fewer evaluations. Considering the simplicity and effectiveness of Sway, we, therefore, propose this approach as a baseline method for search-based software engineering models, especially for models that are very slow to execute.","1939-3520","","10.1109/TSE.2018.2790925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249828","Search-based SE;sampling;evolutionary algorithms","Software engineering;Optimization;Software;Numerical models;Evolutionary computation;Estimation;Sociology","evolutionary computation;process control;search problems;software prototyping","baseline optimizer;CPU-intensive evolutionary algorithms;software product line models;software process control models;baseline method;search-based software engineering models;search-based optimization;evolutionary algorithms;SWAY;the sampling way;agile development","","2","","78","","8 Jan 2018","","","IEEE","IEEE Journals"
"How does Machine Learning Change Software Development Practices?","Z. Wan; X. Xia; D. Lo; G. C. Murphy","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: wanzhiyuan@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Adding an ability for a system to learn inherently adds non-determinism into the system. Given the rising popularity of incorporating machine learning into systems, we wondered how the addition alters software development practices. We performed a mixture of qualitative and quantitative studies with 14 interviewees and 342 survey respondents from 26 countries across four continents to elicit significant differences between the development of machine learning systems and the development of non-machine-learning systems. Our study uncovers significant differences in various aspects of software engineering (e.g., requirements, design, testing, and process) and work features (e.g., skill variety, problem solving and task identity). Based on our findings, we highlight future research directions and provide recommendations for practitioners.","1939-3520","","10.1109/TSE.2019.2937083","National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812912","Software engineering;machine learning;practitioner;empirical study","Software;Interviews;Data models;Machine learning;Testing;Task analysis;Software engineering","","","","2","","","","26 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Gender Differences in Personality Traits of Software Engineers","D. Russo; K. Stol","Department of Computer Science, Aalborg Universitet, 1004 Aalborg, Aalborg Denmark (e-mail: daniel.russo@cs.aau.dk); Computer Science, University College Cork, 8795 Cork, Cork Ireland (e-mail: klaas-jan.stol@lero.ie)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","There is a growing body of gender studies in software engineering to understand diversity and inclusion issues, as diversity is recognized to be a key issue to healthy teams and communities. A second factor often linked to team performance is personality, which has received far more attention. Very few studies, however, have focused on the intersection of these two fields. Hence, we set out to study gender differences in personality traits of software engineers. Through a survey study we collected personality data, using the HEXACO model, of 483 software engineers. The data were analyzed using a Bayesian independent sample t-test and network analysis. The results suggest that women score significantly higher in Openness to Experience, Honesty-Humility, and Emotionality than men. Further, men show higher psychopathic traits than women. Based on these findings, we develop a number of propositions that can guide future research.","1939-3520","","10.1109/TSE.2020.3003413","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9120355","Personality traits;Gender;Empirical software engineering;Bayesian statistics;Network analysis","Software;Software engineering;Instruments;Bayes methods;Sea measurements;Data models;Face","","","","1","","","","18 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Towards a Theory of Software Developer Job Satisfaction and Perceived Productivity","M. Storey; T. Zimmermann; C. Bird; J. Czerwonka; B. Murphy; E. Kalliamvakou","Computer Science, University of Victoria, Victoria, British Columbia Canada (e-mail: mstorey@uvic.ca); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Research, Microsoft Corporation, Redmond, Washington United States (e-mail: cabird@microsoft.com); TSE, Microsoft Corp, 6834 Redmond, Washington United States (e-mail: jacekcz@microsoft.com); Research, Microsoft, Cambridge, Cambridgeshire United Kingdom of Great Britain and Northern Ireland cb30fb (e-mail: bmurphy@microsoft.com); Computer Science, University of Victoria, Victoria, British Columbia Canada V8W 2Y2 (e-mail: ikaliam@uvic.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Developer satisfaction and work productivity are important considerations for software companies. Enhanced developer satisfaction may improve the attraction, retention and health of employees, while higher productivity should reduce costs and increase customer satis- faction through faster software improvements. Many researchers and companies assume that perceived productivity and job satisfaction are related and may be used as proxies for one another, but these claims are a current topic of debate. There are also many social and technical factors that may impact satisfaction and productivity, but which factors have the most impact is not clear, especially for specific development contexts. Through our research, we developed a theory articulating a bi-directional relationship between software developer job satisfaction and perceived productivity, and identified what additional social and technical factors, challenges and work context variables influence this relationship. The constructs and relationships in our theory were derived in part from related literature in software engineering and knowledge work, and we validated and extended these concepts through a rigorously designed survey instrument. We instantiate our theory with a large software company, which suggests a number of propositions about the relative impact of various factors and challenges on developer satisfaction and perceived productivity. Our survey instrument and analysis approach can be applied to other development settings, while our findings lead to concrete recommendations for practitioners and researchers.","1939-3520","","10.1109/TSE.2019.2944354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8851296","software engineering management;empirical studies;software companies;theory","Productivity;Software;Companies;Software engineering;Complexity theory;Psychology;Measurement","","","","1","","","","27 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Motivation and Satisfaction of Software Engineers","C. França; F. Q. B. da Silva; H. Sharp","Departamento de Computação of the Universidade Federal Rural de Pernambuco—UFRPE, Rua Dom Manoel de Medeiros, s/n, Dois Irmãos, Recife, PE, Brazil; Centro de Informática, Universidade Federal de Pernambuco–UFPE. Cidade Universitária, Recife, PE, Brazil; Centre for Research in Computing, The Open University, UK, Milton Keynes, Buckinghamshire, United Kingdom","IEEE Transactions on Software Engineering","12 Feb 2020","2020","46","2","118","140","Context: The proper management of people can help software organisations to achieve higher levels of success. However, the limited attention paid to the appropriate use of theories to underpin the research in this area leaves it unclear how to deal with human aspects of software engineers, such as motivation and satisfaction. Objectives: This article aims to expose what drives the motivation and satisfaction of software engineers at work. Methods: A multiple case study was conducted at four software organisations in Brazil. For 11 months, data was collected using semi-structured interviews, diary studies, and document analyses. Results: The Theory of Motivation and Satisfaction of Software Engineers (TMS-SE), presented in this article, combines elements from well established theories with new findings, and translates them into the software engineering context. Conclusion: The TMS-SE advances the understanding of people management in the software engineering field and presents a strong conceptual framework for future investigations in this area.","1939-3520","","10.1109/TSE.2018.2842201","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370133","Work motivation;job satisfaction;human resource management;software engineering","Software development management;Software engineering;Productivity;Organizational aspects;Human resource management;Human factors","human factors;human resource management;organisational aspects;software development management","software organisations;software engineers;software engineering context;software engineering field;theory of motivation and satisfaction of software engineers;people management","","2","","106","IEEE","31 May 2018","","","IEEE","IEEE Journals"
"Engineering Security Vulnerability Prevention, Detection, and Response","L. Williams; G. McGraw; S. Migues",North Carolina State University; Synopsys; Synopsys,"IEEE Software","27 Sep 2018","2018","35","5","76","80","Around the turn of the 21st century, practices began to emerge to guide teams toward engineering software to stop attackers and users from utilizing unintended functionality by violating the system designer's assumptions to cause a security breach. Yet, breaches are reported daily in the news in all domains-from the casual to the critical. The goal of this article is to help software engineers, software engineering educators, and security researchers understand opportunities for education and research through an analysis of current software security practices. The analysis is conducted on data on the use of a subset of 113 software security practices by 109 firms over 42 months, as reported in the Building Security In Maturity Model (BSIMM) Version 8 report. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290110854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409917","Building Security In Maturity Model;BSIMM;software security;cybersecurity;software engineering;software security practices;software development","Computer bugs;Software engineering;Computer security;Software development","security of data;software engineering","security breach;software security practices;Building Security In Maturity Model Version 8 report;engineering security vulnerability prevention","","4","","10","","11 Jul 2018","","","IEEE","IEEE Magazines"
"In Search of Socio-Technical Congruence: A Large-Scale Longitudinal Study","W. Mauerer; M. Joblin; D. A. A. Tamburri; C. Paradis; R. Kazman; S. Apel","Computer Science and Mathematics, Technical University of Applied Sciences Regensburg, Regensburg, Bavaria, Germany, 93058 (e-mail: wolfgang.mauerer@oth-regensburg.de); Corporate Research, Siemens AG, Munich, Bavaria, Germany, (e-mail: mitchell.joblin@siemens.com); Computer Science, Eindhoven University of Technology School of Innovation Sciences, 200734 Eindhoven, Noord-Brabant, Netherlands, (e-mail: dtamburri@acm.org); Department of Information and Computer Sciences, University of Hawaii, Honolulu, Hawaii, United States, (e-mail: cvas@hawaii.edu); Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii, United States, 96822 (e-mail: kazman@hawaii.edu); Saarland Informatics Campus, Saarland University, 9379 Saarbrcken, Saarland, Germany, (e-mail: apel@cs.uni-saarland.de)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","This paper describes a large-scale empirical study investigating the relevance of socio-technical congruence over key basic software quality metrics, namely, bugs and churn. That is, we explore whether alignment or misalignment of social communication structures and technical dependencies in large software projects influences software quality. To this end, we have defined a quantitative and operational notion of socio-technical congruence, which we call /socio-technical motif congruence/ (STMC). STMC is a measure of the degree to which developers working on the same file or on two related files, need to communicate. As socio-technical congruence is a complex and multi-faceted phenomenon, the interpretability of the results is one of our main concerns, so we have employed a careful mixed-methods statistical analysis. In particular, we provide analyses with similar techniques as employed by seminal work in the field to ensure comparability of our results with the existing body of work. The major result of our study, based on an analysis of 25 large open-source projects, is that STMC is /not/ related to project quality measures---software bugs and churn---in any temporal scenario. That is, we find no statistical relationship between the alignment of developer tasks and developer communications on one hand, and project outcomes on the other hand. We conclude that, wherefore congruence does matter as literature shows, then its measurable effect lies elsewhere.","1939-3520","","10.1109/TSE.2021.3082074","ECSEL; Deutsche Forschungsgemeinschaft; NSF; BayIntAn; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9436025","Socio-Technical Congruence;Human Factors in Software Engineering;Graph Analysis;Empirical Software Engineering;Socio-Technical Analysis;Quantitative Software Engineering;Mixed-Methods Research","Open source software;Computer bugs;Software quality;Measurement;Software architecture;Data models;Task analysis","","","","","","","CCBY","19 May 2021","","","IEEE","IEEE Early Access Articles"
"Empirically Evaluating the Effect of the Physics of Notations on Model Construction","M. El-Attar","Software Engineering Department, Alfaisal University, 101686 Riyadh, Riyadh, Saudi Arabia, 11533 (e-mail: melattar@alfaisal.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","In 2009, Moody introduced nine principles for evaluating, improving and designing cognitively effective notations called the Physics of Notations [49] motivating many research works ever since, being cited more than 1250 times at the time of writing this paper. Many research works have adopted the nine principles of the Physics of Notations to improve existing notations or devise new notations. Modeling is a two-step process that has the goal of communicating a mental concept by a model constructor (step one) to a model reader (step two). A subset of the research works utilizing the Physics of Notations have empirically validated the cognitive effectiveness of the new notations by their readers. However, there lacks any empirical evidence that investigates the effect of using Physics of Notations-enabled notations in model construction. This is a serious matter to be investigated as naturally model construction preludes model comprehension. Poorly constructed models can at best be poorly comprehended by its readers having dire consequences in downstream development activities. This paper reports on three different experiments that use software engineering professionals as subjects. The experiments investigate the effect of using notations that adhere to the Physics if Notations principles on model construction efforts. The results do not indicate an outright advantage for model constructors who utilize Physics of Notations-enabled notations in comparison to using their original versions of these notations.","1939-3520","","10.1109/TSE.2021.3060344","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357929","Physics of notations;feature diagrams;misuse case diagrams;UML statechart diagrams;subject-based experiment","Unified modeling language;Visualization;Physics;Semantics;Syntactics;Software;Software engineering","","","","","","","IEEE","18 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Software Module Clustering: An In-Depth Literature Analysis","Q. Alsarhan; B. S. Ahmed; M. Bures; K. Z. Zamli","Computer Science, University of Duhok, 113404 Duhok City, Duhok, Iraq, (e-mail: qusay.sarhan@uod.ac); Computer Science and Engineering, Ceske Vysoke Uceni Technicke v Praze, 48220 Praha, Prague, Czech Republic, 12135 (e-mail: bestoon82@gmail.com); Computer Science and Engineering, Ceske Vysoke Uceni Technicke v Praze, 48220 Praha, Prague, Czech Republic, (e-mail: buresm3@fel.cvut.cz); Faculty of Computer Systems & Software Engineering, Universiti Malaysia Pahang, 65240 Kuantan, Pahang, Malaysia, (e-mail: kamalz@ump.edu.my)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software module clustering is an unsupervised learning method used to cluster software entities (e.g., classes, modules, or files) of similar features. The obtained clusters may be used to study, analyze, and understand the structure and behavior of the software entities. Implementing software module clustering with optimal results is challenging. Accordingly, researchers have addressed many aspects of software module clustering in the last decade. Thus, it is essential to present research evidence that has been published in this area. In this study, 143 research papers that examined software module clustering from well-known literature databases were extensively reviewed to extract useful data. The obtained data were then used to answer several research questions regarding state-of-the-art clustering approaches, applications of clustering in software engineering, clustering process, clustering algorithms, and evaluation methods. Several research gaps and challenges in software module clustering are discussed in this paper to provide a useful reference for researchers in this field.","1939-3520","","10.1109/TSE.2020.3042553","Stiftelsen för Kunskaps- och Kompetensutveckling; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282200","Systematic literature study;software module clustering;clustering applications;clustering algorithms;clustering evaluation;clustering challenges","Software;Search problems;Data mining;Software engineering;Software algorithms;Clustering algorithms;Systematics","","","","","","","IEEE","4 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Hybrid Labels Are the New Measure!","M. Nayebi; S. J. Kabeer; G. Ruhe; C. Carlson; F. Chew",University of Calgary; University of Calgary; University of Calgary; Brightsquid Secure Communication; Brightsquid Secure Communication,"IEEE Software","25 Dec 2017","2018","35","1","54","57","Developing minimum viable products (MVPs) is critical for start-up companies to hit the market fast with an accepted level of performance. The US Food and Drug Administration mandates additional nonfunctional requirements in healthcare systems, meaning that the MVP should provide the best availability, privacy, and security. This critical demand is motivating companies to further rely on analytics to optimize the development process. In a collaborative project with Brightsquid, the authors provided a decision-support system based on analogical reasoning to assist in effort estimation, scoping, and assignment of change requests. This experience report proposes a new metric, change request labels, for better prediction. Using different methods for textual-similarity analysis, the authors found that the combination of machine-learning techniques with experts' manually added labels has the highest prediction accuracy. Better prediction of change impacts allows a company to optimize its resources and provide proper timing of releases to target MVPs. This article is part of a special issue on Actionable Analytics for Software Engineering.","1937-4194","","10.1109/MS.2017.4541048","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239937","software analytics;digital health;digital care;change impact analysis;software engineering;software development","Software engineering;Software development;Medical services;Digital systems;Resource management","case-based reasoning;decision support systems;health care;learning (artificial intelligence);medical computing;software engineering","hybrid labels;minimum viable products;MVP;healthcare systems;Brightsquid;decision-support system;analogical reasoning;change requests;metric change request labels;textual-similarity analysis;machine-learning techniques;change impacts;nonfunctional requirements;US Food and Drug Administration","","","","9","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Identifying Self-Admitted Technical Debts with Jitterbug: A Two-Step Approach","Z. Yu; F. M. Fahid; H. Tu; T. Menzies","Software Engineering, Rochester Institute of Technology, 6925 Rochester, New York United States (e-mail: zyu9@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: ffahid@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27606 (e-mail: hqtu@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Keeping track of and managing Self-Admitted Technical Debts (SATDs) are important to maintaining a healthy software project. This requires much time and effort from human experts to identify the SATDs manually. The current automated solutions do not have satisfactory precision and recall in identifying SATDs to fully automate the process. To solve the above problems, we propose a two-step framework called Jitterbug for identifying SATDs. Jitterbug first identifies the ""easy to find"" SATDs automatically with close to 100% precision using a novel pattern recognition technique. Subsequently, machine learning techniques are applied to assist human experts in manually identifying the remaining ""hard to find"" SATDs with reduced human effort. Our simulation studies on ten software projects show that Jitterbug can identify SATDs more efficiently (with less human effort) than the prior state-of-the-art methods.","1939-3520","","10.1109/TSE.2020.3031401","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9226105","Technical debt;software engineering;machine learning;pattern recognition","Software;Machine learning;Pattern recognition;Training;Computer hacking;Machine learning algorithms;Estimation","","","","","","","","15 Oct 2020","","","IEEE","IEEE Early Access Articles"
"A Study of C/C++ Code Weaknesses on Stack Overflow","H. Zhang; S. Wang; H. Li; T. -H. P. Chen; A. E. Hassan","Centre for Software Excellence, Huawei Technologies Co Ltd Canada, 538302 Markham, Ontario, Canada, (e-mail: hzhang@cs.queensu.ca); Computer Science, University of Manitoba, 8664 Winnipeg, Manitoba, Canada, (e-mail: shaoweiwang.2010@hotmail.com); School of Computing, Queen's University, Kingston, Ontario, Canada, (e-mail: heng.li@polymtl.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Stack Overflow hosts millions of solutions that aim to solve developers' programming issues. Stack Overflow becomes a code hosting website where developers actively share its code. However, code snippets on Stack Overflow may contain security vulnerabilities, and if shared carelessly, such snippets can introduce security problems in software systems. In this paper, we empirically study the prevalence of the <i>Common Weakness Enumeration</i> -- CWE, in code snippets of C/C++ related answers. We explore the characteristics of Code<sub>w</sub>, i.e., code snippets that have CWE instances, in terms of the types of weaknesses, the evolution of Code<sub>w</sub>, and who contributed such code snippets. We find that: 1) 36% (i.e., 32 out of 89) CWE types occurred in Code<sub>w</sub> on Stack Overflow. Particularly, CWE-119, i.e.,<i> improper restriction of operations within the bounds of a memory buffer</i>, is common in both answer code snippets and real-world software systems. Furthermore, the proportion of Code<sub>w</sub>, doubled from 2008 to 2018 after normalizing by the total number of C/C++ snippets in each year. 2) In general, code revisions are associated with a reduction in the number of code weaknesses. However, the majority of Code<sub>w</sub> had weaknesses introduced in the first version of the code, and these Code<sub>w</sub> were never revised since then. Only 7.5% of users who contributed C/C++ code snippets posted or edited code with weaknesses. Users contributed fewer code with CWE weakness when they were more active -- either revised more code snippets or had a higher reputation. We also find that some users tended to have the same CWE type repeatedly in their various code snippets. Our empirical study provides insights to users who share code snippets on Stack Overflow so that they are aware of the potential security issues. To understand the community feedback about improving code weaknesses by answer revisions, we also conduct a pilot user study and 62.5% of our suggested revisions are adopted by the community. Stack Overflow can perform CWE scanning for all the code that is hosted on its platform. Further research is needed to improve the quality of the crowdsourced knowledge on Stack Overflow.","1939-3520","","10.1109/TSE.2021.3058985","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359361","Code Security;C/C++;Empirical Software Engineering;Crowdsourced Knowledge Sharing and Management;Stack Overflow","Security;Programming;Software systems;History;Electronic mail;C++ languages;Indexes","","","","","","","IEEE","19 Feb 2021","","","IEEE","IEEE Early Access Articles"
"The Four Pillars of Research Software Engineering","J. Cohen; D. S. Katz; M. Barker; N. Chue Hong; R. Haines; C. Jay","Computing, Imperial College London, London, United Kingdom; National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign, Urbana, Illinois United States; Research Software Alliance, Cairns, Queensland, Australia; University of Edinburgh, Edinburgh, United Kingdom; Computer Science, The University of Manchester, Manchester, United Kingdom; Computer Science, University of Manchester, Manchester, United Kingdom","IEEE Software","23 Dec 2020","2021","38","1","97","105","We present four elements we believe are key to providing a comprehensive and sustainable support for research software engineering: software development, community, training, and policy. We also show how the wider developer community can learn from, and engage with, these activities.","1937-4194","","10.1109/MS.2020.2973362","Engineering and Physical Sciences Research Council; Division of Advanced Cyberinfrastructure; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994167","","Software engineering;Engineering profession;Sustainable development;Training;Software reliability","software engineering","research software engineering;comprehensive support;sustainable support;software development","","","","18","IEEE","11 Feb 2020","","","IEEE","IEEE Magazines"
"A Case for Human Values in Software Engineering","J. Whittle; M. A. Ferrario; W. Simm; W. Hussain","Data61, Monash University, Clayton, Victoria, Australia; Computing and Communications, Lancaster University, Lancaster, United Kingdom; Computng and Communications, Lancaster University, Lancaster, United Kingdom; Software, Monash University, Melbourne, Victoria, Australia","IEEE Software","23 Dec 2020","2021","38","1","106","113","This article argues that human values-such as responsibility, transparency, creativity, and equality-are heavily underrepresented in software engineering methods. Using experience with projects involving notfor-protorganizations, we explored how human values can be integrated into existing participatory agile practices.","1937-4194","","10.1109/MS.2019.2956701","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8917668","D.2.14 Human Factors in Software Design;H.1.2.b Human-centered computing;D.2.1 Requirements/Specifications","Software engineering;Stakeholders;Ethics;Software systems;Design methodology;Taxonomy","object-oriented programming;software engineering","human values;software engineering methods;responsibility value;transparency value;creativity value;equality value","","3","","12","IEEE","28 Nov 2019","","","IEEE","IEEE Magazines"
"Sentinel: A Hyper-Heuristic for the Generation of Mutant Reduction Strategies","G. Guizzo; F. Sarro; J. Krinke; S. R. Vergilio","Department of Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland WC1E 6BT (e-mail: g.guizzo@ucl.ac.uk); Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: j.krinke@ucl.ac.uk); Computer Science Department, Federal University of Parana, 28122 Curitiba, PR Brazil (e-mail: silvia@inf.ufpr.br)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Mutation testing is an effective approach to evaluate and strengthen software test suites, but its adoption is currently limited by the mutants' execution computational cost. Several strategies have been proposed to reduce this cost (a.k.a. mutation cost reduction strategies), however none of them has proven to be effective for all scenarios since they often need an ad-hoc manual selection and configuration depending on the software under test (SUT). In this paper, we propose a novel multi-objective evolutionary hyper-heuristic approach, dubbed Sentinel, to automate the generation of optimal cost reduction strategies for every new SUT. We evaluate Sentinel by carrying out a thorough empirical study involving 40 releases of 10 open-source real-world software systems and both baseline and state-of-the-art strategies as a benchmark for a total of 4,800 experiments, which results are evaluated with both quality indicators and statistical significance tests, following the most recent best practice in the literature. The results show that strategies generated by Sentinel outperform the baseline strategies in 95% of the cases always with large effect sizes, and they also obtain statistically significantly better results than state-of-the-art strategies in 88% of the cases with large effect sizes for 95% of them. Also, our study reveals that the mutation strategies generated by Sentinel for a given software version can be used without any loss in quality for subsequently developed versions in 95% of the cases. These results show that Sentinel is able to automatically generate mutation strategies that reduce mutation testing cost without affecting its testing effectiveness (i.e. mutation score), thus taking off from the tester's shoulders the burden of manually selecting and configuring strategies for each SUT.","1939-3520","","10.1109/TSE.2020.3002496","Coordenao de Aperfeioamento de Pessoal de Nvel Superior; European Research Council; Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9117067","Mutation Testing;Mutant Reduction;Software Testing;Grammatical Evolution;Hyper-Heuristic;Search Based Software Testing;Search Based Software Engineering","Testing;Maintenance engineering;Computational efficiency;Open source software;Software engineering;Search problems","","","","","","","","15 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Gender in Software Engineering","J. C. Carver; A. Serebrenik","Computer Science, University of Alabama, United States; Mathematics and Computer Science, Eindhoven University of Technology","IEEE Software","22 Oct 2019","2019","36","6","76","78","The topic of gender in software engineering received significant attention during the most recent International Conference on Software Engineering (ICSE). Papers related to gender appeared in the main research track, the Software Engineering in Society (SEIS) track, and the second Gender Equity (GE) workshop (https://sites.google.com/view/ge-icse2019). Three of the papers summarized in this column are coauthored by the column authors.","1937-4194","","10.1109/MS.2019.2934584","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880051","","Engineering profession;Software engineering;Gender issues","","","","","","6","","22 Oct 2019","","","IEEE","IEEE Magazines"
"Revisiting Test Impact Analysis in Continuous Testing From the Perspective of Code Dependencies","Z. Peng; T. -H. Chen; J. Yang","Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: zi_peng@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: jinqiuy@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","In continuous testing, developers execute automated test cases once or even several times per day to ensure the quality of the integrated code. Although continuous testing helps ensure the quality of the code and reduces maintenance effort, it also significantly increases test execution overhead. In this paper, we empirically evaluate the effectiveness of test impact analysis from the perspective of code dependencies in the continuous testing setting. We first applied test impact analysis to one year of software development history in 11 large-scale open-source systems. We found that even though the number of changed files is small in daily commits (median ranges from 3 to 28 files), around 50% or more of the test cases are still impacted and need to be executed. Motivated by our finding, we further studied the code dependencies between source code files and test cases, and among test cases. We found that 1) test cases often focus on testing the integrated behaviour of the systems and 15% of the test cases have dependencies with more than 20 source code files; 2) 18\% of the test cases have dependencies with other test cases, and test case inheritance is the most common cause of test case dependencies; and 3) we documented four dependency-related test smells that we uncovered in our manual study. Our study provides the first step towards studying and understanding the effectiveness of test impact analysis in the continuous testing setting and provides insights on improving test design and execution.","1939-3520","","10.1109/TSE.2020.3045914","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9303402","empirical study;test smells;continuous testing;test impact analysis","Testing;Software;Maintenance engineering;Manuals;Computer bugs;Automation;Tools","","","","","","","IEEE","22 Dec 2020","","","IEEE","IEEE Early Access Articles"
"On the Untriviality of Trivial Packages: An Empirical Study of npm JavaScript Packages","M. A. R. Chowdhury; R. Abdalkareem; E. Shihab; B. Adams","Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: m_wdhu@encs.concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 1M8 (e-mail: rab_abdu@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: eshihab@encs.concordia.ca); Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, Quebec, Canada, H3T 1J4 (e-mail: bram.adams@polymtl.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Nowadays, developing software would be unthinkable without the use of third-party packages. Although such code reuse helps to achieve rapid continuous delivery of software to end-users, blindly reusing code has its pitfalls. For example, prior work has investigated the rationale for using packages that implement simple functionalities, known as trivial packages (i.e., in terms of the code size and complexity). This prior work showed that although these trivial packages were simple, they were popular and prevalent in the npm ecosystem. This popularity and prevalence of trivial packages peaked our interest in questioning the ‘triviality of trivial packages’. To better understand and examine the triviality of trivial packages, we mine a large set of JavaScript projects that use trivial npm packages and evaluate their relative centrality. Specifically, we evaluate the triviality from two complementary points of view: based on project usage and ecosystem usage of these trivial packages. Our result shows that trivial packages are being used in central JavaScript files of a software project. Additionally, by analyzing all external package API calls in these JavaScript files, we found that a high percentage of these API calls are attributed to trivial packages. Therefore, these packages play a significant role in JavaScript files. Furthermore, in the package dependency network, we observed that 16.8% packages are trivial and in some cases removing a trivial package can impact approximately 29% of the ecosystem. Overall, our finding indicates that although smaller in size and complexity, trivial packages are highly depended on packages by JavaScript projects. Additionally, our study shows that although they might be called trivial, nothing about trivial packages is trivial.","1939-3520","","10.1109/TSE.2021.3068901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387131","Trivial Packages;npm ecosystem;Mining Software Repository","Ecosystems;Software development management;Complexity theory;Tools;Data mining;Software packages;Electronic mail","","","","","","","IEEE","25 Mar 2021","","","IEEE","IEEE Early Access Articles"
"A3: Assisting Android API Migrations Using Code Examples","M. Lamothe; W. Shang; T. P. Chen","Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: lamothe.max@gmail.com); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: shang@encs.concordia.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 2W1 (e-mail: peterc@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The fast-paced evolution of Android APIs has posed a challenging task for Android app developers. To leverage Androids frequently released APIs, developers must often spend considerable effort on API migrations. Prior research and Android official documentation typically provide enough information to guide developers in identifying the API calls that must be migrated and the corresponding API calls in an updated version of Android (what to migrate). However, API migration remains a challenging task since developers lack the knowledge of  $how$  to migrate the API calls. There exist code examples, such as Google Samples, that illustrate the usage of APIs. We posit that by analyzing the changes of API usage in code examples, we can learn API migration patterns to assist developers with API Migrations. In this paper, we propose an approach that learns API migration patterns from code examples, applies these patterns to the source code of Android apps for API migration, and presents the results to users as potential migration solutions. To evaluate our approach, we migrate API calls in open source Android apps by learning API migration patterns from code examples. We find that our approach can successfully learn API migration patterns and provide API migration assistance in 71 out of 80 cases. Our approach can either migrate API calls with little to no extra modifications needed or provide guidance to assist with the migrations. Through a user study, we find that adopting our approach can reduce the time spent on migrating APIs, on average, by 29%. Moreover, our interviews with app developers highlight the benefits of our approach when seeking API migrations. Our approach demonstrates the value of leveraging the knowledge contained in software repositories to facilitate API migrations.","1939-3520","","10.1109/TSE.2020.2988396","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9079197","API;software quality;mining software repositories;empirical software engineering","Task analysis;Documentation;Google;Software maintenance;Interviews;Indexes","","","","1","","","","27 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Nautilus: An Interactive Plug and Play Search Based Software Engineering Framework","T. Ferreira; S. R. Vergilio; M. Kessentini","DInf - Federal University of Paraná, UFPR, Curitiba, 80060-000 Parana, Brazil; Computer Science Department, Federal University of Parana - UFPR, Curitiba, 81531-970 Parana, Brazil; Computer Science, Missouri University of Science and Technology, Rolla, Missouri 65401 United States","IEEE Software","","2020","PP","99","0","0","Several Software Engineering problems are complex and encompass a great number of objectives to be handled. However, practitioners may face several challenges to adopt existing metaheuristic search for their problems due to the lack of background, or some difficult choices such as the change operators, and parameters tuning. Nautilus Framework allows practitioners developing and experimenting several multi- and many-objectives evolutionary algorithms guided (or not) by human participation in few steps with a minimum required background in coding and search-based algorithms. A case study illustrates its benefits, which can also be used to support the construction of AI solutions guided by human decisions.","1937-4194","","10.1109/MS.2020.3039694","Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior; Conselho Nacional de Desenvolvimento Científico e Tecnologico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9264666","preference and search based software engineering;many-objective optimization;plugin and play framework","Optimization;Software algorithms;Search problems;Software;Linear programming;Encoding;Visualization","","","","","","","","19 Nov 2020","","","IEEE","IEEE Early Access Articles"
"Graph Based Mining of Code Change Patterns from Version Control Commits","M. Janke; P. Mader","Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: mario.janke@tu-ilmenau.de); Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thoringen Germany (e-mail: patrick.maeder@tu-ilmenau.de)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Detailed knowledge of frequently recurring code changes can be beneficial for a variety of software engineering activities. For example, it is a key step to understand the process of software evolution, but is also necessary when developing more sophisticated code completion features predicting likely changes. Previous attempts on automatically finding such code change patterns were mainly based on frequent itemset mining, which essentially finds sets of edits occurring in close proximity. However, these approaches do not analyze the interplay among code elements, e.g., two code objects being named similarly, and thereby neglect great potential in identifying a number of meaningful patterns. We present a novel method for the automated mining of code change patterns from Git repositories that captures these context relations between individual edits. Our approach relies on a transformation of source code into a graph representation, while keeping relevant relations present. We then apply graph mining techniques to extract frequent subgraphs, which can be used for further analysis of development projects. We suggest multiple usage scenarios for the resulting pattern type. Additionally, we propose a transformation into CEP rules which allows for easier application, especially for event-based auto-completion recommenders or similar tools. For evaluation, we mined seven open-source code repositories. We present ten frequent change patterns occurring across these projects. We found these patterns to be meaningful, easy to interpret and mostly persistent across project borders. These ten patterns already cover about 13% of all file changes in the analyzed projects.","1939-3520","","10.1109/TSE.2020.3004892","Deutsche Forschungsgemeinschaft; German Ministry of Education and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9129812","Code Changes;Data Mining;Frequent Graph Mining;Auto-completion","Data mining;Pipelines;Itemsets;Tools;Optimization;Open source software","","","","","","","","30 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Is Your Software Valueless?","J. Whittle","Information Technology, Monash University","IEEE Software","16 Apr 2019","2019","36","3","112","115","Software development ignores human values. As a society, we rely on software systems that neither align with nor respect our core values, such as transparency, gender diversity, social justice, and personal integrity. The past 50 years of software engineering have focused on functionality, cost, safety, availability, and security. But what about broader human values (Figure 1) such as compassion, social responsibility, and justice? The way we design software fundamentally influences society, yet human values-which we would all claim to care about-have been a side concern in software engineering. (See ""Where Are the Values in Software?"").","1937-4194","","10.1109/MS.2019.2897397","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693084","","Software development management;Software engineering;Computer security;Ethics;Human computer interaction","ethical aspects;gender issues;human factors;organisational aspects;software engineering","software systems;core values;gender diversity;social justice;personal integrity;software engineering;broader human values;social responsibility;design software;software development;human values;valueless software;transparency;compassion;time 50.0 year","","4","","12","","16 Apr 2019","","","IEEE","IEEE Magazines"
"Secure Views for Collaborative Modeling","C. Debreceni; G. Bergmann; I. Ráth; D. Varró",MTA-BME Lendület Cyber-Physical Systems Research Group; MTA-BME Lendület Cyber-Physical Systems Research Group; Budapest University of Technology and Economics; McGill University,"IEEE Software","29 Nov 2018","2018","35","6","32","38","Model-based systems engineering necessitates effective collaboration between different collaborators, teams, and stakeholders. Traditional approaches used for managing concurrent code-based development don't naturally extend to collaborative modeling, which implies novel challenges. This article presents a collaborative-modeling framework that provides secure views with precisely defined model access to each collaborator, using rule-based access control policies. This article is part of a theme issue on collaborative modeling.","1937-4194","","10.1109/MS.2018.290101728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409907","MONDO;system architectures;integration and modeling;access controls;inter-enterprise collaboration;intra-enterprise collaboration;software engineering;software development","Access control;Software engineering;Software architecture;Load modeling;Collaborative software;Software development","authorisation;groupware;knowledge based systems;software engineering;systems engineering","model access;rule-based access control policies;secure views;collaborative-modeling framework;model-based systems engineering","","","","12","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Mythical Unit Test Coverage","V. Antinyan; J. Derehag; A. Sandberg; M. Staron",University of Gothenburg; Ericsson; Ericsson; University of Gothenburg,"IEEE Software","4 May 2018","2018","35","3","73","79","It is a continuous struggle to understand how much a product should be tested before its delivery to the market. Ericsson, as a global software development company, decided to evaluate the adequacy of the unit-test-coverage criterion that it had employed for years as a guide for sufficiency of testing. Naturally, one can think that if increasing coverage decreases the number of defects significantly, then coverage can be considered a criterion for test sufficiency. To test this hypothesis in practice, we investigated the relationship of unit-test-coverage measures and post-unit-test defects in a large commercial product of Ericsson. The results indicate that high unit-test coverage did not seem to be any tangible help in producing defect-free software.","1937-4194","","10.1109/MS.2017.3281318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354427","software development;unit test;test coverage;code complexity;software metrics;software testing;software engineering","Encoding;Complexity theory;Software engineering;Software metrics;Software testing","program testing;software engineering","Ericsson;global software development company;unit-test-coverage criterion;test sufficiency;unit-test-coverage measures;post-unit-test defects;commercial product;high unit-test coverage;defect-free software;mythical unit test coverage","","2","","13","","4 May 2018","","","IEEE","IEEE Magazines"
"User Involvement in Software Development: The Good, the Bad, and the Ugly","M. Bano; D. Zowghi; F. da Rimini",Swinburne University of Technology; University of Technology Sydney; University of Technology Sydney,"IEEE Software","29 Nov 2018","2018","35","6","8","11","Merely involving the users in software development won't guarantee system success. User involvement is a complex, multifaceted phenomenon with a good side, a bad side, and an ugly side. A better, deeper understanding of those sides can help project managers develop responsive strategies for increasing user involvement's effectiveness.","1937-4194","","10.1109/MS.2018.4321252","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552628","user involvement;user satisfaction;requirements analysis;software development;software engineering;software requirements","Software development;Software engineering;Quality of service;User interfaces","project management;software engineering","user involvement;software development;complex phenomenon;multifaceted phenomenon;bad side;ugly side;good side;project managers","","1","","10","","29 Nov 2018","","","IEEE","IEEE Magazines"
"The Unreasonable Effectiveness of Software Analytics","T. Menzies",North Carolina State University,"IEEE Software","12 Mar 2018","2018","35","2","96","98","In theory, software analytics shouldn't work because software project behavior shouldn't be predictable. However, it does. Why?","1937-4194","","10.1109/MS.2018.1661323","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314156","software analytics;software engineering;software development;Redirections","Software;Complexity theory;Software engineering;Scrum (Software development);Frequency selective surfaces;Task analysis;Software tools","software engineering","unreasonable effectiveness;software analytics;software project behavior","","4","","9","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Collaborative Modeling and Group Decision Making Using Chatbots in Social Networks","S. Pérez-Soler; E. Guerra; J. de Lara",Universidad Autónoma de Madrid; Universidad Autónoma de Madrid; Universidad Autónoma de Madrid,"IEEE Software","29 Nov 2018","2018","35","6","48","54","Modeling is used in the early phases of software and system development to discuss and explore problems, understand domains, and evaluate alternatives and comprehend their implications. In this setting, modeling is inherently collaborative because it involves stakeholders with different backgrounds and expertise, who cooperate to build solutions based on consensus. However, modeling tools typically provide unwieldy diagrammatic editors that might hamper the active involvement of domain experts and lack mechanisms to ease decision making. To tackle these issues, the proposed approach embeds modeling in social networks, so that the modeling interface is natural language that a chatbot interprets to derive an appropriate domain model. Social networks have intuitive built-in discussion mechanisms, while the use of natural language lowers the entry barrier to modeling for domain experts. Moreover, this approach facilitates choosing among modeling alternatives, using soft-consensus decision making. This approach is supported by the SOCIO tool, which works on social networks such as Telegram. This article is part of a theme issue on collaborative modeling.","1937-4194","","10.1109/MS.2018.290101511","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409918","collaborative modeling;social networks;chatbots;decision making;SOCIO;collaborative modeling;software engineering;software development","Collaborative software;Social network services;Biological system modeling;Decision making;Software engineering","decision making;groupware;natural language processing;social networking (online);software engineering","natural language;domain experts;modeling alternatives;soft-consensus decision making;social networks;collaborative modeling;chatbot;system development;modeling tools;active involvement;modeling interface;discussion mechanisms;group decision making;software development;domain model;embeds modeling;diagrammatic editors;Telegram;theme issue","","10","","11","","11 Jul 2018","","","IEEE","IEEE Magazines"
"""Lessons Must Be Learned""-But Are They?","L. Hatton; A. Rutkowski","Forensic Software Engineering, Kingston University; Management, Tilburg University","IEEE Software","17 Jun 2019","2019","36","4","91","95","Despite all the software systems we have seen, both in <;italic>IEEE Software's<;/italic> columns and through our professional experience, periodically, something happens in the world of software engineering that really takes us by surprise. The last time we were in this position was after the revelation of software ""cheats,"" that is, algorithms deliberately introduced into a system with the specific purpose of misleading the general public and certification agencies on the nature of system emissions.8 This time, we feel that we must comment on the equally startling revelations emerging about the interactions among software, management, and requirements in the sad case of the two Boeing 737 MAX crashes.","1937-4194","","10.1109/MS.2019.2909330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738154","","Aircraft;Safety;Software systems;Cetification;Training","software engineering","professional experience;software engineering;software cheats;certification agencies;system emissions;software systems;IEEE Software","","2","","19","","17 Jun 2019","","","IEEE","IEEE Magazines"
"The Rise and Evolution of Agile Software Development","R. Hoda; N. Salleh; J. Grundy",University of Auckland; International Islamic University Malaysia; Monash University,"IEEE Software","27 Sep 2018","2018","35","5","58","63","Agile software development has dominated the second half of the past 50 years of software engineering. Retrospectives, one of the most common agile practices, enables reflection on past performance, discussion of current progress, and charting forth directions for future improvement. Because of agile's burgeoning popularity as the software development model of choice and a significant research subdomain of software engineering, it demands a retrospective of its own. This article provides a historical overview of agile's main focus areas and a holistic synthesis of its trends, their evolution over the past two decades, agile's current status, and, forecast from these, agile's likely future. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290111318","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409911","agile;agile software development;software engineering;software development","Software engineering;Agile software development;Market research;Planning","software prototyping","agile software development;software engineering;common agile practices","","11","","8","","11 Jul 2018","","","IEEE","IEEE Magazines"
"The Five Laws of SE for AI","T. Menzies","RAISE, North Carolina State University, North Carolina United States","IEEE Software","20 Dec 2019","2020","37","1","81","85","It is time to talk about software engineering (SE) for artificial intelligence (AI). As shown in Figure 1, industry is becoming increasingly dependent on AI software. Clearly, AI is useful for SE. But what about the other way around? How important is SE for AI? Many thought leaders in the AI industry are asking how to better develop and maintain AI software (see Figure 2).","1937-4194","","10.1109/MS.2019.2954841","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938116","","Software engineering;Artificial intelligence;Software development management","artificial intelligence;software engineering","software engineering;artificial intelligence;AI software;AI industry","","4","","16","","20 Dec 2019","","","IEEE","IEEE Magazines"
"Data Science: Technologies for Better Software","C. Ebert; J. Heidrich; S. Martinez-Fernandez; A. Trendowicz","Vector Consulting Services; Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany; Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany; Data Engineering, Fraunhofer Institute for Experimental Software Engineering, Kaiserslautern, Germany","IEEE Software","22 Oct 2019","2019","36","6","66","72","Data science is mandatory in today's business to capitalize on achievements and assets. This specifically holds for modern software development, where data science facilitates analyzing product, process, and usage and thus managing evolution and performance. With the convergence of embedded and IT domains, such as the Internet of Things (IoT) and automotive systems, software systems are becoming more complex. Complexity has two faces. On one hand it means more functionality and fluid delivery models, thus offering markets more value, such as the ability to deliver a single-customer focus. Complexity, however, also means the growth of technical debt, which slows productivity and lowers quality. As software engineering generates ever larger and more varied data sets, such as feature usage, code analysis, test coverage, error logs, and maintenance data, companies face the challenge of unlocking the value of that data.","1937-4194","","10.1109/MS.2019.2933681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880036","","Software tools;Data science;Software measurement;Complexity theory;Analytical models","data handling;software engineering","modern software development;data science;software systems;fluid delivery models;software engineering","","1","","8","","22 Oct 2019","","","IEEE","IEEE Magazines"
"Healthy Code Reveals the Problem and Solution","G. Fairbanks","Software Engineering, Google","IEEE Software","15 Aug 2019","2019","36","5","76","79","Source code reveals abstractions from two places: the problem and the solution. It's easier to design and evolve a system when you understand each of them separately before you combine them in code. With skill, it's possible to separate those concerns in the code. Declarative understanding of the abstractions is the most useful and easy to convey. However, current software development processes rarely guide developers to do this.","1937-4194","","10.1109/MS.2019.2923860","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802316","","Source coding;Software engineering;Data structures;Programming;Software development management","software engineering;source code (software)","abstractions;healthy code;source code;software development processes;declarative understanding","","","","4","","15 Aug 2019","","","IEEE","IEEE Magazines"
"Deploying Software Team Analytics in a Multinational Organization","V. Augustine; J. Hudepohl; P. Marcinczak; W. Snipes",ABB; ABB; ABB; ABB,"IEEE Software","25 Dec 2017","2018","35","1","72","76","Implementing a software engineering analytics solution poses challenges and offers significant value for the globally distributed software development organization at ABB. Because software development activities in agile methodologies revolve around the team, ABB decided to implement an analytics solution focused on team metrics as part of its Software Development Improvement Program. Using key indicators focused around team improvement, researchers found that teams could manage their activities with metrics such as cycle time. Key lessons learned include paying attention to visual design and navigation and providing drill-down capabilities for the user. This article is part of a special issue on Actionable Analytics for Software Engineering.","1937-4194","","10.1109/MS.2017.4541044","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239945","software metrics;software quality;ABB;software engineering;software development management;software development","Software engineering;Software measurement;Data visualization;Software development","distributed processing;project management;software development management;software prototyping","actionable analytics;analytics solution;drill-down capabilities;navigation;visual design;key lessons;team improvement;key indicators;Software Development Improvement Program;team metrics;agile methodologies;software development activities;ABB;globally distributed software development organization;offers significant value;software engineering analytics solution;multinational organization;software team analytics","","","","13","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Competition-Based Crowdsourcing Software Development: A Multi-Method Study from a Customer Perspective","K. Stol; B. Caglayan; B. Fitzgerald","Department of Computer Science, University College Cork, Cork, Ireland; IBM Ireland, Dublin 4, Ireland; University of Limerick, Limerick, Ireland","IEEE Transactions on Software Engineering","13 Mar 2019","2019","45","3","237","260","Crowdsourcing is emerging as an alternative outsourcing strategy which is gaining increasing attention in the software engineering community. However, crowdsourcing software development involves complex tasks which differ significantly from the micro-tasks that can be found on crowdsourcing platforms such as Amazon Mechanical Turk which are much shorter in duration, are typically very simple, and do not involve any task interdependencies. To achieve the potential benefits of crowdsourcing in the software development context, companies need to understand how this strategy works, and what factors might affect crowd participation. We present a multi-method qualitative and quantitative theory-building research study. First, we derive a set of key concerns from the crowdsourcing literature as an initial analytical framework for an exploratory case study in a Fortune 500 company. We complement the case study findings with an analysis of 13,602 crowdsourcing competitions over a ten-year period on the very popular Topcoder crowdsourcing platform. Drawing from our empirical findings and the crowdsourcing literature, we propose a theoretical model of crowd interest and actual participation in crowdsourcing competitions. We evaluate this model using Structural Equation Modeling. Among the findings are that the level of prize and duration of competitions do not significantly increase crowd interest in competitions.","1939-3520","","10.1109/TSE.2017.2774297","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119867","Crowdsourcing;software engineering;multi-method study;case study;sample study","Crowdsourcing;Software;Outsourcing;Mathematical model;Companies","crowdsourcing;public domain software;software engineering;statistical analysis;ubiquitous computing","case study findings;popular Topcoder crowdsourcing platform;crowdsourcing literature;crowd interest;competition-based crowdsourcing software development;multimethod study;customer perspective;alternative outsourcing strategy;software engineering community;complex tasks;microtasks;crowdsourcing platforms;Amazon Mechanical Turk;task interdependencies;software development context;multimethod qualitative;quantitative theory-building research study;exploratory case study;crowdsourcing competitions","","7","","157","","24 Nov 2017","","","IEEE","IEEE Journals"
"Data Scientists in Software Teams: State of the Art and Challenges","M. Kim; T. Zimmermann; R. DeLine; A. Begel","University of California, Los Angeles, CA; One Microsoft Way, Redmond, WA; One Microsoft Way, Redmond, WA; One Microsoft Way, Redmond, WA","IEEE Transactions on Software Engineering","11 Nov 2018","2018","44","11","1024","1038","The demand for analyzing large scale telemetry, machine, and quality data is rapidly increasing in software industry. Data scientists are becoming popular within software teams, e.g., Facebook, LinkedIn and Microsoft are creating a new career path for data scientists. In this paper, we present a large-scale survey with 793 professional data scientists at Microsoft to understand their educational background, problem topics that they work on, tool usages, and activities. We cluster these data scientists based on the time spent for various activities and identify 9 distinct clusters of data scientists, and their corresponding characteristics. We also discuss the challenges that they face and the best practices they share with other data scientists. Our study finds several trends about data scientists in the software engineering context at Microsoft, and should inform managers on how to leverage data science capability effectively within their teams.","1939-3520","","10.1109/TSE.2017.2754374","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8046093","Data science;development roles;software engineering;industry","Data science;Tools;Sociology;Statistics;Software;Best practices;Interviews","information management;software engineering","professional data scientists;software teams;Microsoft;software engineering context","","15","","33","","19 Sep 2017","","","IEEE","IEEE Journals"
"SEthesaurus: WordNet in Software Engineering","X. Chen; C. Chen; D. Zhang; Z. Xing","School of Information Science and Technology, Nantong University, 66479 Nantong, Jiangsu China (e-mail: xchencs@ntu.edu.cn); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: chunyang.chen@monash.edu); School of Information Science and Technology, Nantong University, Nantong, jiangsu China (e-mail: dunnzhang0@gmail.com); College of Engineering and Computer Science, Australian National University, Canberra, Australian Capital Territory Australia (e-mail: zhenchang.xing@anu.edu.au)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Informal discussions on social platforms (e.g., Stack Overflow, CodeProject) have accumulated a large body of programming knowledge in the form of natural language text. Natural language process (NLP) techniques can be utilized to harvest this knowledge base for software engineering tasks. However, consistent vocabulary for a concept is essential to make an effective use of these NLP techniques. Unfortunately, the same concepts are often intentionally or accidentally mentioned in many different morphological forms (such as abbreviations, synonyms and misspellings) in informal discussions. Existing techniques to deal with such morphological forms are either designed for general English or mainly resort to domain-specific lexical rules. A thesaurus, which contains software-specific terms and commonly-used morphological forms, is desirable to perform normalization for software engineering text. However, constructing this thesaurus in a manual way is a challenge task. In this paper, we propose an automatic unsupervised approach to build such a thesaurus. In particular, we first identify software-specific terms by utilizing a software-specific corpus (e.g., Stack Overflow) and a general corpus (e.g., Wikipedia). Then we infer morphological forms of software-specific terms by combining distributed word semantics, domain-specific lexical rules and transformations. Finally, we perform graph analysis on morphological relations. We evaluate the coverage and accuracy of our constructed thesaurus against community-cumulated lists of software-specific terms, abbreviations and synonyms. We also manually examine the correctness of the identified abbreviations and synonyms in our thesaurus. We demonstrate the usefulness of our constructed thesaurus by developing three applications and also verify the generality of our approach in constructing thesauruses from data sources in other domains.","1939-3520","","10.1109/TSE.2019.2940439","the seed grant from Monash University; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827962","Software-specific Thesaurus;Natural Language Processing;Morphological Form;Word Embedding","Thesauri;Software engineering;Encyclopedias;Electronic publishing;Internet;Natural language processing","","","","5","","","","10 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Key Stakeholders’ Value Propositions for Feature Selection in Software-Intensive Products: An Industrial Case Study","P. Rodríguez; E. Mendes; B. Turhan","University of Oulu, Oulu, Finland; Blekinge Institute of Technology, Sweden; Monash University, Melbourne, VIC, Australia","IEEE Transactions on Software Engineering","10 Dec 2020","2020","46","12","1340","1363","Numerous software companies are adopting value-based decision making. However, what does value mean for key stakeholders making decisions? How do different stakeholder groups understand value? Without an explicit understanding of what value means, decisions are subject to ambiguity and vagueness, which are likely to bias them. This case study provides an in-depth analysis of key stakeholders' value propositions when selecting features for a large telecommunications company's software-intensive product. Stakeholders' value propositions were elicited via interviews, which were analyzed using Grounded Theory coding techniques (open and selective coding). Thirty-six value propositions were identified and classified into six dimensions: customer value, market competitiveness, economic value/profitability, cost efficiency, technology & architecture, and company strategy. Our results show that although propositions in the customer value dimension were those mentioned the most, the concept of value for feature selection encompasses a wide range of value propositions. Moreover, stakeholder groups focused on different and complementary value dimensions, calling to the importance of involving all key stakeholders in the decision making process. Although our results are particularly relevant to companies similar to the one described herein, they aim to generate a learning process on value-based feature selection for practitioners and researchers in general.","1939-3520","","10.1109/TSE.2018.2878031","Finnish Funding Agency for Technology and Innovation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8509148","Value-based software engineering (VBSE);feature selection;release planning;decision-making;value proposition;stakeholder analysis;key stakeholders;software-intensive systems;case study;grounded theory","Stakeholders;Software engineering;Feature extraction;Decision making;Economics","decision making;feature selection;profitability;software engineering","value-based decision making;stakeholder groups;open coding;selective coding;customer value dimension;complementary value dimensions;decision making process;value-based feature selection;key stakeholder value propositions;grounded theory coding techniques;telecommunications company software-intensive product;learning process","","4","","70","IEEE","25 Oct 2018","","","IEEE","IEEE Journals"
"The Pragmatic Architect Evolves","E. Woods; G. Fairbanks",Endava; Google,"IEEE Software","29 Nov 2018","2018","35","6","12","15","The software architect's role has changed in response to the changing demands of software engineering practice. Now, the Pragmatic Architect department is changing too. This installment looks back over the department's history to see how it has changed and considers the topics it should cover in the future.","1937-4194","","10.1109/MS.2018.4321235","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552622","software architecture;software development;software engineering;The Pragmatic Architect","Software architecture;Software development;Software engineering","software architecture","software architecture;Pragmatic Architect department;software engineering practice","","","","3","","29 Nov 2018","","","IEEE","IEEE Magazines"
"The Path to DevOps","E. Dörnenburg",ThoughtWorks,"IEEE Software","27 Sep 2018","2018","35","5","71","75","IT's role in the business world has changed dramatically over the past decades. New technologies and techniques let enterprises get much more out of IT, while increasingly sophisticated business models have pushed IT to investigate and deliver novel solutions. Agile development led the way, and now the DevOps and DesignOps movements are hitting the mainstream. IT in businesses is now entirely a team activity. While we still need experts with deep technical knowledge, we must focus on how to get people from all disciplines working together effectively. This article is part of a theme issue on software engineering's 50th anniversary.","1937-4194","","10.1109/MS.2018.290110337","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409919","DevOps;DesignOps;CycleTime;agile;agile development;software development;software engineering","5G mobile communication;Software engineering;Software development;Agile software development","commerce;software prototyping","DevOps;deep technical knowledge;business world;enterprises;agile development;DesignOps;software engineering","","4","","15","","11 Jul 2018","","","IEEE","IEEE Magazines"
"The Effectiveness of Supervised Machine Learning Algorithms in Predicting Software Refactoring","M. Aniche; E. Maziero; R. Durelli; V. Durelli","Software Engineering Research Group, Technische Universiteit Delft, 2860 Delft, South Holland, Netherlands, 2628CD (e-mail: mauricioaniche@gmail.com); -, Federal University of Lavras, 67739 Lavras, MG, Brazil, (e-mail: Erick.Maziero@ufla.br); -, Federal University of Lavras, 67739 Lavras, MG, Brazil, (e-mail: Rafael.Durelli@ufla.br); -, Federal University of So Joo del-Rei, 74383 Sao Joao del-Rei, MG, Brazil, (e-mail: durelli@ufsj.edu.br)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Refactoring is the process of changing the internal structure of software to improve its quality without modifying its external behavior. Empirical studies have repeatedly shown that refactoring has a positive impact on the understandability and maintainability of software systems. However, before carrying out refactoring activities, developers need to identify refactoring opportunities. Currently, refactoring opportunity identification heavily relies on developers' expertise and intuition. In this paper, we investigate the effectiveness of machine learning algorithms in predicting software refactorings. More specifically, we train six different machine learning algorithms (i.e., Logistic Regression, Naive Bayes, Support Vector Machine, Decision Trees, Random Forest, and Neural Network) with a dataset comprising over two million refactorings from 11,149 real-world projects from the Apache, F-Droid, and GitHub ecosystems. The resulting models predict 20 different refactorings at class, method, and variable-levels with an accuracy often higher than 90%. Our results show that (i) Random Forests are the best models for predicting software refactoring, (ii) process and ownership metrics seem to play a crucial role in the creation of better models, and (iii) models generalize well in different contexts.","1939-3520","","10.1109/TSE.2020.3021736","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186715","software engineering;software refactoring;machine learning for software engineering","Biological system modeling;Measurement;Tools;Software;Predictive models;Context modeling;Prediction algorithms","","","","","","","","4 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Managing Technical Debt in Database Normalization","M. Albarak; R. Bahsoon; I. Ozkaya; R. L. Nord","School of Computer Science, University of Birmingham, 1724 Birmingham, Birmingham United Kingdom of Great Britain and Northern Ireland (e-mail: mesh55@gmail.com); School of Computer Science, University of Birmingham, Birmingham, BIRMINGHAM United Kingdom of Great Britain and Northern Ireland b15 2TT (e-mail: r.bahsoon@cs.bham.ac.uk); Product Line Systems, Software Architecture Technology Initiative, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: ozkaya@sei.cmu.edu); n/a, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: rn@sei.cmu.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Database normalization is one of the main principles for designing relational databases, which is the most popular database model, with the objective of improving data and system qualities, such as performance. Refactoring the database for normalization can be costly, if the benefits of the exercise are not justified. Developers often ignore the normalization process due to the time and expertise it requires, introducing technical debt into the system. Technical debt is a metaphor that describes trade-offs between short-term goals and applying optimal design and development practices. We consider database normalization debts are likely to be incurred for tables below the fourth normal form. To manage the debt, we propose a multi-attribute analysis framework that makes a novel use of the Portfolio Theory and the TOPSIS method (Technique for Order of Preference by Similarity to Ideal Solution) to rank the candidate tables for normalization to the fourth normal form. The ranking is based on the tables estimated impact on data quality, performance, maintainability, and cost. The techniques are evaluated using an industrial case study of a database-backed web application for human resource management. The results show that the debt-aware approach can provide an informed justification for the inclusion of critical tables to be normalized, while reducing the effort and cost of normalization.","1939-3520","","10.1109/TSE.2020.3001339","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113328","Database Normalization;Multi-attribute analysis;Software Design;Technical Debt","Data integrity;Data models;Relational databases;Redundancy;Portfolios","","","","","","","","10 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Optimization of Software Release Planning Considering Architectural Dependencies, Cost, and Value","R. S. Sangwan; A. Negahban; R. L. Nord; I. Ozkaya","Engineering, Pennsylvania State University, 8082 Malvern, Pennsylvania United States (e-mail: rsangwan@psu.edu); Engineering, Pennsylvania State University, 8082 Malvern, Pennsylvania United States (e-mail: aun85@psu.edu); n/a, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: rn@sei.cmu.edu); Product Line Systems, Software Architecture Technology Initiative, Software Engineering Institute, Pittsburgh, Pennsylvania United States 15213 (e-mail: ozkaya@sei.cmu.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Within any incremental development paradigm, there exists a tension between the desire to deliver value to the customer early and the desire to reduce cost by avoiding architectural refactoring and rework in subsequent releases. What is lacking is an analytical framework that quantifies opportunities and risks of choosing one or the other of these strategies or a blend of the two. This paper demonstrates the use of design structure and domain mapping matrices for analyzing architectural dependencies and proposes an optimization-based decision-making technique to support effective release planning. The optimization models recommend the order in which architectural elements and features should be implemented across different releases so as to: (a) minimize rework cost; (b) maximize early value delivery; or, (c) optimize an integrated measure of cost and value. These analytic models can be applied earlier in the life cycle and, hence, provide timely information about the progress and changes that occur at each iteration.","1939-3520","","10.1109/TSE.2020.3020013","U.S. Department of Defense; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9178988","software release management and delivery;software architecture;nonlinear programming","Planning;Software;Computer architecture;Optimization;Electronic mail;Analytical models;Matrix decomposition","","","","","","","","27 Aug 2020","","","IEEE","IEEE Early Access Articles"
"MoMIT: Porting a JavaScript Interpreter on a Quarter Coin","R. Morales; R. Saborido; Y. Guéhéneuc","Departement of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: moar820326@gmail.com); Department of Computer Science, University of Malaga, Malaga, Andalucia Spain (e-mail: rsain@uma.es); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: yann-gael.gueheneuc@concordia.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The Internet of Things (IoT) is a network of physical, connected devices providing services through private networks and the Internet. The devices connect through the Internet to Web servers and other devices. One of the popular programming languages for communicating Web pages and Web apps is JavaScript (JS). Hence, the devices would benefit from JS apps. However, porting JS apps to the many IoT devices, e.g., System-on-a-Chip (SoCs) devices (e.g., Arduino Uno), is challenging because of their limited memory, storage, and CPU capabilities. Also, some devices may lack hardware/software capabilities for running JS apps ""as is"". Thus, we propose MoMIT, a multiobjective optimization approach to miniaturize JS apps to run on IoT devices. We implement MoMIT using three different search algorithms. We miniaturize a JS interpreter and measure the characteristics of 23 apps before/after applying MoMIT. We find reductions of code size, memory usage, and CPU time of 31%, 56%, and 36%, respectively (medians). We show that MoMIT allows apps to run on up to two additional devices in comparison to the original JS interpreter.","1939-3520","","10.1109/TSE.2020.2968061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966499","Internet of Things;Software Miniaturization;Multiobjective optimization;embedded devices;JavaScript;Evolutionary algorithms","Optimization;Software;Internet of Things;Computer languages;Tools;Companies;Hardware","","","","1","","","","22 Jan 2020","","","IEEE","IEEE Early Access Articles"
"Real World Scrum A Grounded Theory of Variations in Practice","Z. Masood; R. Hoda; K. Blincoe","Electrical, Computer, and Software Engineering, The University of Auckland, 1415 Auckland, Auckland New Zealand (e-mail: zmas690@aucklanduni.ac.nz); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: rashina@gmail.com); Electrical, Computer, and Software Engineering, University of Auckland, 1415 Auckland, Auckland New Zealand 1142 (e-mail: kelly.blincoe@gmail.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Scrum, the most popular agile method and project management framework, is widely reported to be used, adapted, misused, and abused in practice. However, not much is known about how Scrum actually works in practice, and critically, where, when, how and why it diverges from Scrum by the book. Through a Grounded Theory study involving semi-structured interviews of 45 participants from 30 companies and observations of five teams, we present our findings on how Scrum works in practice as compared to how it is presented in its formative books. We identify significant variations in these practices such as work breakdown, estimation, prioritization, assignment, the associated roles and artefacts, and discuss the underlying rationales driving the variations. Critically, we claim that not all variations are process misuse/abuse and propose a nuanced classification approach to understanding variations as standard, necessary, contextual, and clear deviations for successful use and adaptation of Scrum by the book in practice.","1939-3520","","10.1109/TSE.2020.3025317","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201058","Scrum;agile;Scrum by the book;Scrum In practice;variations;grounded theory","Scrum (Software development);Lead;Software;Project management;Interviews;Electric breakdown;Estimation","","","","1","","","","21 Sep 2020","","","IEEE","IEEE Early Access Articles"
"How Practitioners Perceive Automated Bug Report Management Techniques","W. Zou; D. Lo; Z. Chen; X. Xia; Y. Feng; B. Xu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing Shi, Jiangsu Sheng, China; School of Information Systems, Singapore Management University, Singapore; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing Shi, Jiangsu Sheng, China; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Department of Informatics, University of California, Irvine, Irvine, CA, USA; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing Shi, Jiangsu Sheng, China","IEEE Transactions on Software Engineering","13 Aug 2020","2020","46","8","836","862","Bug reports play an important role in the process of debugging and fixing bugs. To reduce the burden of bug report managers and facilitate the process of bug fixing, a great amount of software engineering research has been invested toward automated bug report management techniques. However, the verdict is still open whether such techniques are actually required and applicable outside the domain of theoretical research. To fill this gap, we conducted a survey among 327 practitioners to gain their insights into various categories of automated bug report management techniques. Specifically, we asked the respondents to rate the importance of such techniques and provide the rationale. To get deeper insights into practitioners' perspective, we conducted follow-up interviews with 25 interviewees selected from the survey respondents. Through the survey and the interviews, we gained a better understanding of the perceived usefulness (or its lack) of different categories of automated bug report management techniques. Based on our findings, we summarized some potential research directions in developing techniques to help developers better manage bug reports.","1939-3520","","10.1109/TSE.2018.2870414","National Natural Science Foundation of China; China Scholarship Council Scholarship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8466000","Bug report;developer perception","Computer bugs;Software;Software engineering;Bibliographies;Conferences;Interviews;Maintenance engineering","program debugging;software engineering","practitioner perspective;automated bug report management techniques;software engineering research;debugging;bug fixing","","3","","93","IEEE","14 Sep 2018","","","IEEE","IEEE Journals"
"Understanding Diverse Usage Patterns from Large-Scale Appstore-Service Profiles","X. Liu; H. Li; X. Lu; T. Xie; Q. Mei; F. Feng; H. Mei","Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; University of Illinois Urbana-Champaign, Champaign, IL; University of Michigan, Ann Arbor, MI; Wandoujia, Beijing, China; Beijing Institute of Technology","IEEE Transactions on Software Engineering","16 Apr 2018","2018","44","4","384","411","The prevalence of smart mobile devices has promoted the popularity of mobile applications (a.k.a. apps). Supporting mobility has become a promising trend in software engineering research. This article presents an empirical study of behavioral service profiles collected from millions of users whose devices are deployed with Wandoujia, a leading Android app-store service in China. The dataset of Wandoujia service profiles consists of two kinds of user behavioral data from using 0.28 million free Android apps, including (1) app management activities (i.e., downloading, updating, and uninstalling apps) from over 17 million unique users and (2) app network usage from over 6 million unique users. We explore multiple aspects of such behavioral data and present patterns of app usage. Based on the findings as well as derived knowledge, we also suggest some new open opportunities and challenges that can be explored by the research community, including app development, deployment, delivery, revenue, etc.","1939-3520","","10.1109/TSE.2017.2685387","National Basic Research Program (973) of China; Natural Science Foundation of China; National Science Foundation; National Science Foundation; MCubed; University of Michigan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7883939","Mobile apps;app store;user behavior analysis","Androids;Humanoid robots;Software;Biological system modeling;Mobile communication;Electronic mail;Software engineering","Android (operating system);mobile computing;public domain software;software engineering","Wandoujia service profiles;user behavioral data;app usage;app development;diverse usage patterns;large-scale appstore-service profiles;smart mobile devices;mobile applications;software engineering research;behavioral service profiles;leading Android app-store service;free Android apps;app management activities;app network usage","","4","","68","","21 Mar 2017","","","IEEE","IEEE Journals"
"Stability in Software Engineering: Survey of the State-of-the-Art and Research Directions","M. Salama; R. Bahsoon; P. Lago","School of Computer Science, University of Birmingham, Birmingham, West Middlands United Kingdom of Great Britain and Northern Ireland (e-mail: m.salama@cs.bham.ac.uk); School of Computer Science, University of Birmingham, Birmingham, West Middlands United Kingdom of Great Britain and Northern Ireland (e-mail: r.bahsoon@cs.bham.ac.uk); Department of Computer Science, VU University Amsterdam, Amsterdam, NL Netherlands 1081HV (e-mail: p.lago@vu.nl)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","With the increasing dependence on software systems, their longevity is becoming a pressing need. Stability is envisioned as a primary property to achieve longevity. Stability has been defined and treated in many different ways in the literature. We conduct a systematic literature review to analyse the state-of-the-art related to stability as a software property. We formulate a taxonomy for characterising the notion, analyse the definitions found in the literature, and present research studies dealing with stability. Also, as architecture is one of the software artefacts with profound effects throughout the software lifecycle, we focus on software engineering practices for realising architectural stability. The analysis results show a wide variation in dimensions when dealing with stability. The state-of-the-art indicates the need for a shift towards a multi-dimensional concept that could cope with runtime dynamics and emerging software paradigms. More research efforts should be directed toward the identified gaps. The presented taxonomy and analysis of the literature aim to help the research community in consolidating the existing research efforts and deriving future developments.","1939-3520","","10.1109/TSE.2019.2925616","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747478","software architecture;longevity;quality;stability;architecture design;architecture evaluation;architectural stability","Stability criteria;Software engineering;Computer architecture;Software systems;Taxonomy","","","","1","","","","27 Jun 2019","","","IEEE","IEEE Early Access Articles"
"On Scheduling Constraint Abstraction for Multi-Threaded Program Verification","L. Yin; W. Dong; W. Liu; J. Wang","Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, Hunan, China; Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, Hunan, China; Laboratory of Software Engineering for Complex Systems, School of Computer, National University of Defense Technology, Changsha, Hunan, China; Laboratory of Software Engineering for Complex Systems, State Key Laboratory of High Performance Computing, School of Computer, National University of Defense Technology, Changsha, Hunan, China","IEEE Transactions on Software Engineering","14 May 2020","2020","46","5","549","565","Bounded model checking is among the most efficient techniques for the automated verification of concurrent programs. However, due to the nondeterministic thread interleavings, a large and complex formula is usually required to give an exact encoding of all possible behaviors, which significantly limits the scalability. Observing that the large formula is usually dominated by the exact encoding of the scheduling constraint, this paper proposes a novel scheduling constraint based abstraction refinement method for multi-threaded C program verification. Our method is both efficient in practice and complete in theory, which is challenging for existing techniques. To achieve this, we first proposed an effective and powerful technique which works well for nearly all benchmarks we evaluated. We have proposed the notion of Event Order Graph (EOG), and have devised two graph-based algorithms over EOG for counterexample validation and refinement generation, which can often obtain a small yet effective refinement constraint. Then, to ensure completeness, our method was enhanced with two constraint-based algorithms for counterexample validation and refinement generation. Experimental results on SV-COMP 2017 benchmarks and two real-world server systems indicate that our method is promising and significantly outperforms the state-of-the-art tools.","1939-3520","","10.1109/TSE.2018.2864122","National Natural Science Foundation of China; National Key R&D program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428438","Multi-threaded program;bounded model checking;scheduling constraint;event order graph","Instruction sets;Electrooculography;Encoding;Concurrent computing;Programming;Model checking;Tools","graph theory;multi-threading;program diagnostics;program verification;scheduling","multithreaded program verification;bounded model checking;automated verification;concurrent programs;nondeterministic thread interleavings;complex formula;exact encoding;multithreaded C program verification;event order graph;EOG;graph-based algorithms;refinement generation;constraint-based algorithms;refinement constraint;scheduling constraint based abstraction refinement","","3","","45","IEEE","7 Aug 2018","","","IEEE","IEEE Journals"
"Inputs from Hell Learning Input Distributions for Grammar-Based Test Generation","E. Soremekun; E. Pavese; N. Havrikov; L. Grunske; A. Zeller","Software Engineering Chair, CISPA - Helmholtz Center for Information Security, 535167 Saarbrucken, Saarland Germany (e-mail: ezekiel.soremekun@cispa.saarland); Software Engineering, Humboldt-Universitat zu Berlin, 9373 Berlin, Berlin Germany (e-mail: epavese@gmail.com); Software Engineering Chair, CISPA - Helmholtz Center for Information Security, 535167 Saarbrucken, Saarland Germany (e-mail: nikolas.havrikov@cispa.saarland); Software Engineering, Humboldt-Universitat zu Berlin, 9373 Berlin, Berlin Germany 10099 (e-mail: grunske@informatik.hu-berlin.de); Software Engineering Chair, CISPA - Helmholtz Center for Information Security, 535167 Saarbrucken, Saarland Germany (e-mail: zeller@cispa.saarland)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Grammars can serve as producers for structured test inputs that are syntactically correct by construction. A probabilistic grammar assigns probabilities to individual productions, thus controlling the distribution of input elements. Using the grammars as input parsers, we show how to learn input distributions from input samples, allowing to create inputs that are similar to the sample; by inverting the probabilities, we can create inputs that are dissimilar to the sample. This allows for three test generation strategies: 1) Common inputs by learning from common inputs, we can create inputs that are similar to the sample; this is useful for regression testing. 2) Uncommon inputs learning from common inputs and inverting probabilities yields inputs that are strongly dissimilar to the sample; this is useful for completing a test suite with inputs from hell that test uncommon features, yet are syntactically valid. 3) Failure-inducing inputs learning from inputs that caused failures in the past gives us inputs that share similar features and thus also have a high chance of triggering bugs; this is useful for testing the completeness of fixes. Our evaluation on three common input formats (JSON, JavaScript, CSS) shows the effectiveness of these approaches. Results show that common inputs reproduced 96% of the methods induced by the samples. In contrast, for almost all subjects (95%), the uncommon inputs covered significantly different methods from the samples. Learning from failure-inducing samples reproduced all exceptions (100%) triggered by the failure-inducing samples and discovered new exceptions not found in any of the samples learned from.","1939-3520","","10.1109/TSE.2020.3013716","Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9154602","test case generation;probabilistic grammars;input samples","Grammar;Production;Probabilistic logic;Computer bugs;Software;Test pattern generators","","","","","","","","3 Aug 2020","","","IEEE","IEEE Early Access Articles"
"LogAssist: Assisting Log Analysis Through Log Summarization","S. Locke; H. Li; T. -H. P. Chen; W. Shang; W. Liu","Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: s_loc@encs.concordia.ca); Computer Engineering and Software Engineering, Polytechnique Montreal, 5596 Montreal, Quebec, Canada, H3T 1J4 (e-mail: heng.li@polymtl.ca); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca); Department of Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: w_liu201@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Logs contain valuable information about the runtime behaviors of software systems. Thus, practitioners rely on logs for various tasks such as debugging, system comprehension, and anomaly detection. However, due to the unstructured nature and large size of logs, there are several challenges that practitioners face with log analysis. In this paper, we propose a novel approach called LogAssist that tackles these challenges and assists practitioners with log analysis. LogAssist provides an organized and concise view of logs by first grouping logs into event sequences (i.e., workflows), which better illustrate the system runtime execution paths. Then, LogAssist compresses the log events in workflows by hiding consecutive events and applying n-gram modeling to identify common event sequences. We evaluated LogAssist on the logs that are generated by two open-source and one enterprise system. We find that LogAssist can reduce the number of log events that practitioners need to investigate by up to 99%. Through a user study with 19 participants, we also find that LogAssist can assist practitioners by reducing the needed time on log analysis tasks by an average of 40%. The participants also rated LogAssist an average of 4.53 out of 5 for improving their experiences of performing log analysis. Finally, we document our experiences and lessons learned from developing and adopting LogAssist in practice. We believe that LogAssist and our reported experiences may lay the basis for future analysis and interactive exploration on logs.","1939-3520","","10.1109/TSE.2021.3083715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9442364","Log analysis;log compression;n-gram modeling;log abstraction;workflow characterization;log reduction","Task analysis;Runtime;Tools;Testing;Faces;Anomaly detection;Software systems","","","","","","","IEEE","26 May 2021","","","IEEE","IEEE Early Access Articles"
"The Offshoring Elephant in the Room: Turnover","D. Smite; R. van Solingen; P. Chatzipetrou","Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; Global Software Engineering, Delft University of Technology, Delft, The Netherlands; Informatics, Orebro University, Sweden","IEEE Software","15 Apr 2020","2020","37","3","54","62","Staffing software projects with engineers from inexpensive locations has become commonplace. However, distributed development remains practically challenging because of recurring problems, e.g., decreased productivity, low quality, and high, unforeseen costs. Although it is often overlooked, one of the main underlying reasons for these challenges is high employee turnover. This might be especially noticeable in developing countries with strong economic growth such as India. This article examines turnover of Indian software engineers and introduces strategies to address it.","1937-4194","","10.1109/MS.2018.2886179","Stiftelsen for Kunskaps- och Kompetensutveckling; Stiftelsen for Kunskaps- och Kompetensutveckling; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664169","Offshoring;Global software engineering;Global software development;Turnover;Attrition;Hidden costs","Project management;Software development management;Productivity;Collaboration;Economics;Employment;Personnel","DP industry;labour resources;personnel;planning;recruitment;software engineering","high employee turnover;strong economic growth;Indian software engineers;unforeseen costs;decreased productivity;distributed development;inexpensive locations;staffing software projects;offshoring elephant","","","","15","","10 Mar 2019","","","IEEE","IEEE Magazines"
"Software Bots","C. Lebeuf; M. Storey; A. Zagalsky",University of Victoria; University of Victoria; University of Victoria,"IEEE Software","25 Dec 2017","2018","35","1","18","23","Although the development and widespread adoption of software bots has occurred in just a few years, bots have taken on many diverse tasks and roles. This article discusses current bot technology and presents a practical case study on how to use bots in software engineering.","1937-4194","","10.1109/MS.2017.4541027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239928","software bots;bots;chatbots;Slack;software engineering;software development;Software Technology","Software development;Graphical user interfaces;Bot (Internet);Software engineering","software agents;software engineering","current bot technology;software engineering;software bots","","20","","11","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Dealing with Non-Functional Requirements in Model-Driven Development: A Survey","D. Ameller; X. Franch; C. Gómez; S. Martínez-Fernández; J. Araújo; S. Biffl; J. Cabot; V. Cortellessa; D. M. Fernández; A. Moreira; H. Muccini; A. Vallecillo; M. Wimmer; V. Amaral; W. Böhm; H. Bruneliere; L. Burgueño; M. Goulão; S. Teufl; L. Berardinelli","Universitat Politècnica de Catalunya, Barcelona, Spain; Departament de Enginyeria de Serveis i Sistemes de Informació, Universitat Politècnica de Catalunya, Barcelona, Spain; Service and Information System Engineering, Universitat Politècnica de Catalunya, Barcelona, Spain; Data Engineering, Fraunhofer IESE, Kaiserslautern, Germany; Department of Informatics, Universidade Nova de Lisboa, Caparica, Portugal; Department of Software Engineering, Technische Universitat Wien, Vienna, Austria; IN3-UOC, Institucio Catalana de Recerca i Estudis Avancats, Barcelona, Spain; Dipartimento di Informatica, Universita’ dell’Aquila, L’Aquila, Italy; Technische Universität München, Garching, Gemany; Department of Informatics, Universidade Nova de Lisboa, Caparica, Portugal; DISIM, University of L’Aquila, L’Aquila, Italy; Lenguajes y Ciencias de la Computación, Universidad de Malaga, Malaga, Spain; Computer Science, Vienna University of Technology, Vienna, Austria; Department of Informatics, Universidade Nova de Lisboa, Caparica, Portugal; Technische Universität München, Garching, Gemany; NaoMod Team, IMT Atlantique Bretagne - Pays de Loire, Brest, Nantes-France; Lenguajes y Ciencias de la Computación, Universidad de Malaga, Malaga, Spain; Faculdade de Ciencias e Tecnologia, Universidade Nova de Lisboa, Caparica, Portugal; Technische Universität München, Garching, Gemany; Department of Software Engineering, Technische Universitat Wien, Vienna, Austria","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","818","835","Context: Managing Non-Functional Requirements (NFRs) in software projects is challenging, and projects that adopt Model-Driven Development (MDD) are no exception. Although several methods and techniques have been proposed to face this challenge, there is still little evidence on how NFRs are handled in MDD by practitioners. Knowing more about the state of the practice may help researchers to steer their research and practitioners to improve their daily work. Objective: In this paper, we present our findings from an interview-based survey conducted with practitioners working in 18 different companies from 6 European countries. From a practitioner's point of view, the paper shows what barriers and benefits the management of NFRs as part of the MDD process can bring to companies, how NFRs are supported by MDD approaches, and which strategies are followed when (some) types of NFRs are not supported by MDD approaches. Results: Our study shows that practitioners perceive MDD adoption as a complex process with little to no tool support for NFRs, reporting productivity and maintainability as the types of NFRs expected to be supported when MDD is adopted. But in general, companies adapt MDD to deal with NFRs. When NFRs are not supported, the generated code is sometimes changed manually, thus compromising the maintainability of the software developed. However, the interviewed practitioners claim that the benefits of using MDD outweight the extra effort required by these manual adaptations. Conclusion: Overall, the results indicate that it is important for practitioners to handle `NFRs in MDD, but further research is necessary in order to lower the barrier for supporting a broad spectrum of NFRs with MDD. Still, much conceptual and tool implementation work seems to be necessary to lower the barrier of integrating the broad spectrum of NFRs in practice.","1939-3520","","10.1109/TSE.2019.2904476","NOVA LINCS Research Laboratory; Spanish projects; Austrian Federal Ministry for Digital, Business and Enterprise; Österreichische Nationalstiftung für Forschung, Technologie und Entwicklung; ECSEL (Electronic Component Systems for European Leadership Joint Undertaking) project named MegaM@Rt2; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8665968","Model-driven development;non-functional requirements;quality requirements;requirements engineering;survey","Unified modeling language;Software;Companies;Productivity;Software engineering;Security;Analytical models","","","","7","","72","IEEE","12 Mar 2019","","","IEEE","IEEE Journals"
"Asymmetric Release Planning: Compromising Satisfaction against Dissatisfaction","M. Nayebi; G. Ruhe","Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada; Software Engineering Decision Support Laboratory, University of Calgary, Calgary, AB, Canada","IEEE Transactions on Software Engineering","17 Sep 2019","2019","45","9","839","857","Maximizing satisfaction from offering features as part of the upcoming release(s) is different from minimizing dissatisfaction gained from not offering features. This asymmetric behavior has never been utilized for product release planning. We study Asymmetric Release Planning (ARP) by accommodating asymmetric feature evaluation. We formulated and solved ARP as a bi-criteria optimization problem. In its essence, it is the search for optimized trade-offs between maximum stakeholder satisfaction and minimum dissatisfaction. Different techniques including a continuous variant of Kano analysis are available to predict the impact on satisfaction and dissatisfaction with a product release from offering or not offering a feature. As a proof of concept,we validated the proposed solution approach called Satisfaction-Dissatisfaction Optimizer (SDO) via a real-world case study project. From running three replications with varying effort capacities, we demonstrate that SDO generates optimized trade-off solutions being (i) of a different value profile and different structure, (ii) superior to the application of random search and heuristics in terms of quality and completeness, and (iii) superior to the usage of manually generated solutions generated from managers of the case study company. A survey with 20 stakeholders evaluated the applicability and usefulness of the generated results.","1939-3520","","10.1109/TSE.2018.2810895","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307259","Release planning;bi-objective optimization;stakeholder satisfaction;stakeholder dissatisfaction;case study;empirical evaluation","Planning;Stakeholders;Software engineering;Software;Streaming media;Mathematical model;Optimization","optimisation;pattern classification","offering features;asymmetric behavior;product release planning;ARP;asymmetric feature evaluation;maximum stakeholder satisfaction;minimum dissatisfaction;optimized trade-off solutions;different value profile;upcoming release;asymmetric release planning;bicriteria optimization problem;satisfaction-dissatisfaction optimizer;random search","","1","","79","","6 Mar 2018","","","IEEE","IEEE Journals"
"AI in Software Engineering at Facebook","J. Bader; S. Kim; F. Luan; S. Chandra; E. Meijer","Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States; Facebook, Facebook Inc., Menlo Park, California 94025 United States","IEEE Software","","2021","PP","99","0","0","We address the question: How can AI help software engineers better do their jobs and advance the state of the practice? Our perspective comes from building and integrating AI-based techniques in Facebook’s developer infrastructure over the past two years. In this article, we describe three productivity tools that we have built that learn patterns from software artifacts: code search using natural language, code recommendation, and automatic bug fixing. We also present a broader picture of how machine learning can bring insights to virtually all stages of the software lifecycle.","1937-4194","","10.1109/MS.2021.3061664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9360852","","Social networking (online);Tools;Training;Licenses;Data mining;Software engineering;Software development management","","","","","","","CCBYNCND","23 Feb 2021","","","IEEE","IEEE Early Access Articles"
"The Diversity Crisis of Software Engineering for Artificial Intelligence","B. Adams; F. Khomh","Maintenance, Construction, and Intelligence of Software, Polytechnique Montreal, Canada; Software Analytics and Technology, Polytechnique Montreal, Canada","IEEE Software","21 Aug 2020","2020","37","5","104","108","Artificial Intelligence (AI) is experiencing a ""diversity crisis.""1 Several reports1-3 have shown how the breakthrough of modern AI has not yet been able to improve on existing diversity challenges regarding gender, race, geography, and other factors, neither for the end users of those products nor the companies and organizations building them. Plenty of examples have surfaced in which biased data engineering practices or existing data sets led to incorrect, painful, or sometimes even harmful consequences for unassuming end users.4 The problem is that ruling out such biases is not straightforward due to the sheer number of different bias types.5 To have a chance to eliminate as many biases as possible, most of the experts agree that the teams and organizations building AI products should be made more diverse.1-3 This harkens back to Linus' law6 for open source development (""given enough eyeballs, all bugs are shallow"") but applied to the development process of AI products.","1937-4194","","10.1109/MS.2020.2975075","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173624","","Companies;Software engineering;Machine learning;Artificial intelligence;Google;Industries","","","","","","16","","21 Aug 2020","","","IEEE","IEEE Magazines"
"Designing Corporate Hackathons With a Purpose: The Future of Software Development","E. P. P. Pe-Than; A. Nolte; A. Filippova; C. Bird; S. Scallen; J. D. Herbsleb","Software Research, Carnegie Mellon University, Pittsburg, Pennsylvania United States; Computer Science, University of Tartu; GitHub; Empirical Software Engineering, Microsoft Research; Principal Design, Microsoft Garage; Software Research, Carnegie Mellon University, Pittsburg, Pennsylvania United States","IEEE Software","14 Jan 2019","2019","36","1","15","22","Based on our empirical studies of 10 hackathons held by scientific communities, a corporation, and universities as well as the review of published literature, we discuss that hackathons can be organized around goals such as enriching social networks, facilitating collaborative learning, and workforce development. We also discuss design choices that can scaffold the organization of hackathons and their tradeoffs. Design choices include identifying a suitable mixture of attendee skills, the selection process for projects and teams, and whether to hold a competitive or collaborative event. Hackathons can achieve multiple goals if designed carefully.","1937-4194","","10.1109/MS.2018.290110547","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409916","computing milieux;Computers and Society;organizational impacts;computer-supported collaborative work;Software;Software Engineering;human factors in software design;Information Technology and Systems;Information Interfaces and Representation (HCI);group and organization interfaces;collaborative computing;management of computing and information systems;software management;software development;services computing;services lifecycle;key factors in services lifecycle;innovation and technology","Software development management;Social netwowrk services;Agile software development;Collaborative work;Software engineering;Information and communication technology","computer crime;hobby computing;social aspects of automation;social networking (online);software engineering","corporate hackathons;software development;empirical studies;scientific communities;published literature;social networks;collaborative learning;workforce development;design choices;attendee skills","","4","","14","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Effects of Mindfulness on Conceptual Modeling Performance: a Series of Experiments","B. Bernardez; A. Duran Toro; J. A. Parejo Maestre; N. Juristo; A. Ruiz-Cortes","Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: beat@us.es); Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: amador@us.es); Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: japarejo@us.es); Escuela Tcnica Superior de Ingenieros Informticos, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: natalia@fi.upm.es); Lenguajes y Sistemas Informticos, Universidad de Sevilla, 16778 Sevilla, Andaluca Spain (e-mail: aruiz@us.es)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Context. Mindfulness is a meditation technique whose main goal is keeping the mind calm and educating attention by focusing only on one thing at a time, usually breathing. The reported benefits of its continued practice can be of interest for Software Engineering students and practitioners, especially in tasks like conceptual modeling, in which concentration and clearness of mind are crucial. Goal. In order to evaluate whether Software Engineering students enhance their conceptual modeling performance after several weeks of mindfulness practice, a series of three controlled experiments were carried out at the University of Seville during three consecutive academic years (2013—2016) involving 130 students. Method. In all the experiments, the subjects were divided into two groups. While the experimental group practiced mindfulness, the control group was trained in public speaking as a placebo treatment. All the subjects developed two conceptual models based on a transcript of an interview, one before and another one after the treatment. The results were compared in terms of conceptual modeling quality (measured as effectiveness, i.e. the percentage of model elements correctly identified) and productivity (measured as efficiency, i.e. the number of model elements correctly identified per unit of time). Results. The statistically significant results of the series of experiments revealed that the subjects who practiced mindfulness developed slightly better conceptual models (their quality was 8.16% higher) and they did it faster (they were 46.67% more productive) than the control group, even if they did not have a previous interest in meditation. Conclusions. The practice of mindfulness improves the performance of Software Engineering students in conceptual modeling, especially their productivity. Nevertheless, more experimentation is needed in order to confirm the outcomes in other Software Engineering tasks and populations.","1939-3520","","10.1109/TSE.2020.2991699","European Commission FEDER and the Spanish Government; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9084263","Mindfulness;Conceptual Modeling;Experiment Replication;Family of Experiments;Software Engineering Education","Software engineering;Education;Task analysis;Productivity;Stress;Focusing;Public speaking","","","","","","","","1 May 2020","","","IEEE","IEEE Early Access Articles"
"$\mathcal K$K-Branching UIO Sequences for Partially Specified Observable Non-Deterministic FSMs","K. El-Fakih; R. M. Hierons; U. C. Türker","Computer Science and Engineering, American University of Sharjah, Sharjah, United Arab Emirates; Computer Science, The University of Sheffield, Sheffield, United Kingdom; Computer Engineering, Gebze Technical University, Kocaeli, Turkey","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","1029","1040","In black-box testing, test sequences may be constructed from systems modelled as deterministic finite-state machines (DFSMs) or, more generally, observable non-deterministic finite state machines (ONFSMs). Test sequences usually contain state identification sequences, with unique input output sequences (UIOs) often being used with DFSMs. This paper extends the notion of UIOs to ONFSMs. One challenge is that, as a result of non-determinism, the application of an input sequence can lead to exponentially many expected output sequences. To address this scalability problem, we introduce ${\mathcal K}$K-UIOs: UIOs that lead to at most ${\mathcal K}$K output sequences from states of $M$M. We show that checking ${\mathcal K}$K-UIO existence is PSPACE-Complete if the problem is suitably bounded; otherwise it is in EXPSPACE and PSPACE-Hard. We provide a massively parallel algorithm for constructing ${\mathcal K}$K-UIOs and the results of experiments on randomly generated and real FSM specifications. The proposed algorithm was able to construct UIOs in cases where the existing UIO generation algorithm could not and was able to construct UIOs from FSMs with 38K states and 400K transitions.","1939-3520","","10.1109/TSE.2019.2911076","AUS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691615","Software engineering/software/program verification;software engineering/testing and debugging;software engineering/test design;finite state machine;unique input output sequence generation;general purpose graphics processing units","Testing;Object oriented modeling;Software algorithms;Software;Integrated circuit modeling;Scalability;Parallel algorithms","","","","","","47","IEEE","14 Apr 2019","","","IEEE","IEEE Journals"
"Reactive Auto-completion of Modeling Activities","P. Mäder; T. Kuschke; M. Janke","Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: patrick.maeder@tu-ilmenau.de); Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: tobias.kuschke@tu-ilmenau.de); Software Engineering for Safety-Critical Systems Group, Technische Universitat Ilmenau, 26559 Ilmenau, Thuringia Germany (e-mail: mario.janke@tu-ilmenau.de)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Assisting and automating software engineering tasks is a state-of-the-art way to support stakeholders of development projects. A common assistance function of IDEs is the auto-completion of source code. Assistance functions, such as auto-completion, are almost entirely missing in modeling tools though auto-completion in general gains continuously more importance in software development. We analyze a user's performed editing operations in order to anticipate modeling activities and to recommend appropriate auto-completions for them. Editing operations are captured as events and modeling activities are defined as complex event patterns, facilitating the matching by complex-event-processing. The approach provides adapted auto-completions reactively upon each editing operation of the user. We implemented the RapMOD prototype as add-in for the modeling tool Sparx Enterprise ArchitectTM . A controlled user experiment with 37 participants performing modeling tasks demonstrated the approach's potential to reduce modeling effort significantly. Users having auto-completions available for a modeling scenario performed the task 27% faster, needed to perform 56% less actions, and perceived the task 29% less difficult.","1939-3520","","10.1109/TSE.2019.2924886","Thuringer Aufbaubank; Bundesministerium fur Bildung und Forschung; Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745532","Auto-completion;modeling activity;complex-event-processing;CEP;activity recognition;pattern matching;recommender","Unified modeling language;Tools;Task analysis;Computational modeling;Adaptation models;Analytical models;Engines","","","","","","","","25 Jun 2019","","","IEEE","IEEE Early Access Articles"
"An Empirical Study on Heterogeneous Defect Prediction Approaches","H. Chen; X. Jing; Z. Li; D. Wu; Y. Peng; Z. Huang","School of Computer, Wuhan University, Wuhan City, Hubei Province China (e-mail: hwc_zzu@126.com); State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan City, Hubei Province China 430072 (e-mail: jingxy_2000@126.com); State Key Laboratory of Software Engineering, School of Computer, Wuhan University, Wuhan, Hubei China (e-mail: lzq115@163.com); State Key Laboratory of Software Engineering, School of Computer, Wuhan University, 12390 Wuhan, Hubei China (e-mail: htuwudi@sina.com); School of Computer, Wuhan University, Wuhan City, Hubei Province China (e-mail: hbyspy2008@qq.com); School of Computer, Wuhan University, 12390 Wuhan, Hubei China (e-mail: huang_906@126.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software defect prediction has always been a hot research topic in the field of software engineering owing to its capability of allocating limited resources reasonably. Compared with cross-project defect prediction (CPDP), heterogeneous defect prediction (HDP) further relaxes the limitation of defect data used for prediction, permitting different metric sets to be contained in the source and target projects. However, there is still a lack of a holistic understanding of existing HDP studies due to different evaluation strategies and experimental settings. In this paper, we provide an empirical study on HDP approaches. We review the research status systematically and compare the HDP approaches proposed from 2014 to June 2018. Furthermore, we also investigate the feasibility of HDP approaches in CPDP. Through extensive experiments on 30 projects from five datasets, we have the following findings: (1) metric transformation-based HDP approaches usually result in better prediction effects, while metric selection-based approaches have better interpretability. Overall, the HDP approach proposed by Li et al. (CTKCCA) currently has the best performance. (2) Handling class imbalance problems can boost the prediction effects, but the improvements are usually limited. In addition, utilizing mixed project data cannot improve the performance of HDP approaches consistently since the label information in the target project is not used effectively. (3) HDP approaches are feasible for cross-project defect prediction in which the source and target projects have the same metric set.","1939-3520","","10.1109/TSE.2020.2968520","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8964460","Heterogeneous defect prediction;cross-project;empirical study;metric selection;metric transformation","Measurement;NASA;Predictive models;Data models;Software;Libraries;Buildings","","","","1","","","","22 Jan 2020","","","IEEE","IEEE Early Access Articles"
"Utilizing Automatic Query Reformulations as Genetic Operations to Improve Feature Location in Software Models","F. Pérez; T. Ziadi; C. Cetina","SVIT Research Group, Universidad San Jorge, Zaragoza, Zaragoza Spain (e-mail: mfperez@usj.es); LIP6, Sorbonne Université, 27063 Paris, Île-de-France France (e-mail: tewfik.ziadi@lip6.fr); SVIT Research Group, Universidad San Jorge, Zaragoza, Zaragoza Spain (e-mail: ccetina@usj.es)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","In the combination of Model-Driven Engineering (MDE) and Search-Based Software Engineering (SBSE), genetic operations are one of the key ingredients. Our work proposes a novel adaptation of automatic query reformulations as genetic operations that leverage the latent semantics of software models (the cornerstone artefact of MDE). We analyze the impact of these reformulation operations in a real-world industrial case study of feature location in models. As baselines, we use: 1) the widespread single-point crossover plus random mutation; and 2) mask crossover plus random mutation, which is the best performer for feature location in models. We also perform a statistical analysis to provide quantitative evidence of the impact of the results and to show that this impact is significant. Our reformulation operations improve the results of the best baseline by 37.73% in recall and 14.08% in precision. These results are relevant for the task of feature location in models (one of the main activities performed during software maintenance and evolution). Furthermore, given that the only requirement to apply our approach is term availability in models, our work opens a new research direction to improve more tasks in MDE such as bug location or requirements traceability.","1939-3520","","10.1109/TSE.2020.3000520","Ministerio de Economa y Competitividad; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9110751","Model-Driven Engineering;Search-Based Software Engineering;Automatic Query Reformulations","Genetics;Adaptation models;Task analysis;Software;Semantics;Evolutionary computation;Analytical models","","","","","","","","8 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Software Development Analytics for Xen: Why and How","D. Izquierdo; J. M. Gonzalez-Barahona; L. Kurth; G. Robles",Bitergia; Universidad Rey Juan Carlos; Citrix; Universidad Rey Juan Carlos,"IEEE Software","16 Apr 2019","2019","36","3","28","32","Xen is one of the most popular virtualization technologies. Several IT companies collect and publish metrics, helping the ecosystem to be more self-aware of their development processes. Thus, ecosystem participants make informed decisions, monitor their effects, and improve their coordination.","1937-4194","","10.1109/MS.2018.290101357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409914","Software;Software Engineering;Software maintenance;Software management;Management of Computing and Information Systems;computing Mil;Software Engineering;metrics;measurement;process metrics","Software development management;Ecosystems;Virtualization;Software measurement;Object recognition;Ecosystems","software engineering;virtual machines;virtualisation","software development analytics;xen;virtualization technologies;IT companies","","","","6","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Interacto: A Modern User Interaction Processing Model","A. Blouin; J. -M. Jezequel","DiverSE, IRISA/Inria, Rennes, ile et vilaine, France, (e-mail: Arnaud.Blouin@irisa.fr); DiverSE, IRISA-University of Rennes, Rennes, France, France, (e-mail: jezequel@irisa.fr)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Since most software systems provide their users with interactive features, building user interfaces (UI) is one of the core software engineering tasks. It consists in designing, implementing and testing ever more sophisticated and versatile ways for users to interact with software systems, and safely connecting these interactions with commands querying or modifying their state. However, most UI frameworks still rely on a low level model, the bare bone UI event processing model. This model was suitable for the rather simple UIs of the early 80s (menus, buttons, keyboards, mouse clicks), but now exhibits major software engineering flaws for modern, highly interactive UIs. These flaws include lack of separation of concerns, weak modularity and thus low reusability of code for advanced interactions, as well as low testability. To mitigate these flaws, we propose Interacto as a high level user interaction processing model. By reifying the concept of user interaction, Interacto makes it easy to design, implement and test modular and reusable advanced user interactions, and to connect them to commands with built-in undo/redo support. To demonstrate its applicability and generality, we briefly present two open source implementations of Interacto for Java/JavaFX and TypeScript/Angular. We evaluate Interacto interest (1) on a real world case study, where it has been used since 2013, and with (2) a controlled experiment with 44 master students, comparing it with traditionnal UI frameworks.","1939-3520","","10.1109/TSE.2021.3083321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440800","user interface;user interaction;UI event processing;separation of concerns;undo/redo","Mice;Software systems;Object oriented modeling;Encoding;Standards;Software engineering;Process control","","","","","","","IEEE","25 May 2021","","","IEEE","IEEE Early Access Articles"
"On the Introduction of Automatic Program Repair in Bloomberg","S. Kirbas; E. Windels; O. McBello; K. Kells; M. Pagano; R. Szalanski; V. Nowack; E. Winter; S. Counsell; D. Bowes; T. Hall; S. Haraldsson; J. Woodward","Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Software Engineering, Bloomberg LP, New York, New York United States; Software Engineering, Bloomberg LP, New York, New York United States; Software Engineering, Bloomberg LP UK, London, London, United Kingdom of Great Britain and Northern Ireland; Computer Science, Queen Mary University of London, London, London, United Kingdom of Great Britain and Northern Ireland; School of Computng and Communications, Lancaster University, Lancaster, Lancashire, United Kingdom of Great Britain and Northern Ireland; Computer Science, Brunel University, Greater London, UB8 3PH London, United Kingdom of Great Britain and Northern Ireland; School of Computing and Communication, Lancaster University School of Computing and Communications, Lancaster, Lancashire, United Kingdom of Great Britain and Northern Ireland; Computing & Communications, Lancaster University, Lancaster, LA1 4WA Lancashire, United Kingdom of Great Britain and Northern Ireland; Computer Science, University of Stirling, Stirling, Stirling, United Kingdom of Great Britain and Northern Ireland; Computer Science, Queen Mary University of London, London, London, United Kingdom of Great Britain and Northern Ireland","IEEE Software","","2021","PP","99","0","0","A key to the success of Automatic Program Repair techniques is how easily they can be used in an industrial setting. In this article, we describe a collaboration by a team from four UK-based universities with Bloomberg (London) in implementing automatic, high-quality ﬁxes to its code base. We explain the motivation for adopting APR, the mechanics of the prototype tool that was built, and the practicalities of integrating APR into existing systems.","1937-4194","","10.1109/MS.2021.3071086","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9395171","","Software;Tools;Computer bugs;Maintenance engineering;Industries;Computer architecture;Social networking (online)","","","","","","","IEEE","5 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Continuously Managing NFRs: Opportunities and Challenges in Practice","C. Werner; Z. S. Li; D. Lowlind; O. Elazhary; N. A. Ernst; D. Damian","Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: colinwerner@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: zanelib1@gmail.com); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: dereklowlind@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: omazhary@uvic.ca); Computer Science, University of Victoria, 8205 Victoria, British Columbia, Canada, (e-mail: nernst@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8W 3P6 (e-mail: damian.daniela@gmail.com)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Non-functional requirements (NFR), which include performance, availability, and maintainability, are vitally important to overall software quality. However, research has shown NFRs are, in practice, poorly defined and difficult to verify. Continuous software engineering practices, which extend agile practices, emphasize fast paced, automated, and rapid release of software that poses additional challenges to handling NFRs. In this multi-case study we empirically investigated how three organizations, for which NFRs are paramount to their business survival, manage NFRs in their continuous practices. We describe four practices these companies use to manage NFRs, such as offloading NFRs to cloud providers or the use of metrics and continuous monitoring, both of which enable almost real-time feedback on managing the NFRs. However, managing NFRs comes at a costas we also identified a number of challenges these organizations face while managing NFRs in their continuous software engineering practices. For example, the organizations in our study were able to realize an NFR by strategically and heavily investing in configuration management and infrastructure as code, in order to offload the responsibility of NFRs; however, this offloading implied potential loss of control. Our discussion and key research implications show the opportunities, trade-offs, and importance of the unique give-and-take relationship between continuous software engineering and NFRs.","1939-3520","","10.1109/TSE.2021.3066330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380710","non-functional requirements;continuous software engineering","Organizations;Software;Software engineering;Testing;Tools;Requirements engineering;Interviews","","","","1","","","IEEE","17 Mar 2021","","","IEEE","IEEE Early Access Articles"
"What Leads to a Confirmatory or Disconfirmatory Behaviour of Software Testers?","I. Salman; P. Rodriguez; B. Turhan; A. Tosun; A. Gureller","M3S, Oulun Yliopisto Teknillinen Tiedekunta, 101225 Oulu, Northern Ostrobothnia Finland 90014 (e-mail: iflaah.salman@oulu.fi); Department of Languages, Computer Systems and Software Engineering, Universidad Politecnica de Madrid, 16771 Madrid, Comunidad de Madrid Spain (e-mail: pilar.rodriguez@upm.es); FIT, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: turhanb@computer.org); Faculty of Computer and Informatics Engineering, Istanbul Technical University, Istanbul, Istanbul Turkey (e-mail: tosunay@itu.edu.tr); Research NAP, Ericsson, Istanbul, Istanbul Turkey (e-mail: arda.gureller@ericsson.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Background: The existing literature in software engineering reports adverse effects of confirmation bias on software testing. Confirmation bias among software testers leads to confirmatory behaviour, which is designing or executing relatively more specification consistent test cases (confirmatory behaviour) than specification inconsistent test cases (disconfirmatory behaviour). Objective: We aim to explore the antecedents to confirmatory and disconfirmatory behaviour of software testers. Furthermore, we aim to understand why and how those antecedents lead to (dis)confirmatory behaviour. Method: We follow grounded theory method for the analyses of the data collected through semi-structured interviews with twelve software testers. Results: We identified twenty antecedents to (dis)confirmatory behaviour, and classified them in nine categories. Experience and Time are the two major categories. Experience is a disconfirmatory category, which also determines which behaviour (confirmatory or disconfirmatory) occurs first among software testers, as an effect of other antecedents. Time Pressure is a confirmatory antecedent of the Time category. It also contributes to the confirmatory effects of antecedents of other categories. Conclusion: The disconfirmatory antecedents, especially that belong to the testing process, e.g., test suite reviews by project team members, may help circumvent the deleterious effects of confirmation bias in software testing. If a team's resources permit, the designing and execution of a test suite could be divided among the test team members, as different perspectives of testers may help to detect more errors. The results of our study are based on a single context where dedicated testing teams focus on higher levels of testing. The study's scope does not account for the testing performed by developers. Future work includes exploring other contexts to extend our results.","1939-3520","","10.1109/TSE.2020.3019892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9179007","Software Testing;Cognitive Biases;Confirmation Bias;Grounded Theory;Interviews","Software;Software testing;Interviews;Electronic mail;Companies;Decision making","","","","","","","","27 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Ubiquitous Requirements Engineering: A Paradigm Shift That Affects Everyone","K. Villela; E. C. Groen; J. Doerr","Fraunhofer Institute for Experimental Software Engineering IESE; Fraunhofer Institute for Experimental Software Engineering IESE; Information Systems, Fraunhofer Institute for Experimental Software Engineering IESE","IEEE Software","21 Feb 2019","2019","36","2","8","12","In recent years, we have witnessed profound changes in business and society. The use of digital technologies has brought about disruptive changes in every domain, changes that are widely known as the ""digital transformation."" Systems are growing increasingly interconnected and complex with cyberphysical systems even sensing and actuating in the physical world. Typical computer, tablet, and smartphone users include anyone from children to the elderly. A single software product can now easily reach audiences of millions with unprecedented opportunities to obtain feedback.","1937-4194","","10.1109/MS.2018.2883876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648266","","Ecosystems;Software;Companies;Stakeholders;Requirements engineering;Software engineering","formal specification;language translation;smart phones","cyberphysical systems;physical world;typical computer;smartphone users;single software product;ubiquitous requirements engineering;paradigm shift;profound changes;digital technologies;disruptive changes;digital transformation","","","","7","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Finding Trends in Software Research","G. Mathew; A. Agrawal; T. Menzies","Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: george.meg91@gmail.com); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: aagrawa8@ncsu.edu); Lane Department of Computer Science and Electrical Engineering, West Virginia University, Morgantown, West Virginia United States 26501 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2018","PP","99","1","1","This paper explores the structure of research papers in software engineering. Using text mining, we study 35,391 software engineering (SE) papers from 34 leading SE venues over the last 25 years. These venues were divided, nearly evenly, between conferences and journals. An important aspect of this analysis is that it is fully automated and repeatable. To achieve that automation, we used topic modeling (with LDA) to mine 10 topics that represent much of the structure of contemporary SE. The 10 topics presented here should not be ""set in stone"" as the only topics worthy of study in SE. Rather our goal is to report that (a) text mining methods can detect large scale trends within our community; (b) those topic change with time; so (c) it is important to have automatic agents that can update our understanding of our community whenever new data arrives.","1939-3520","","10.1109/TSE.2018.2870388","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8465996","Software Engineering;Bibliometrics;Topic Modeling;Text Mining","Software engineering;Conferences;Software;Analytical models;Data models;Predictive models;Testing","","","","","","","","14 Sep 2018","","","IEEE","IEEE Early Access Articles"
"Behavioral Science and Diversity in Software Engineering","J. C. Carver; H. Muccini; B. Penzenstadler; R. Prikladnicki; A. Serebrenik; T. Zimmermann","Computer Science, University of Alabama, Tuscaloosa, Alabama 35487 United States; Information Engineering, University of L’Aquila, L’Aquila, 67100, Italy; Chalmers University of Technology, Gothenburg, 412 96, Sweden; Technology and Innovation, University of Rio Grande do Sul, Porto Alegre, RS 90619-900, Brazil; Eindhoven University of Technology, Eindhoven, 5600MB, The Netherlands; Microsoft, Redmond, Washington 98052 United States","IEEE Software","15 Feb 2021","2021","38","2","107","112","The “Practioners' Digest” department in this issue of IEEE Software covers two topics: the behavioral science of software engineering and diversity in software engineering (this issue’s theme) and includes papers from the 42nd International Conference on Software Engineering (ICSE20), 2019 IEEE International Conference on Software Maintenance and Evolution (ICSME19), 13th International Workshop on Cooperative and Human Aspects of Software Engineering (CHASE20), Empirical Software Engineering and Measurement 2020 (ESEM20), and Association for Computing Machinery Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE20). Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in this article, please send me and the authors of the paper(s) a note about your experiences.","1937-4194","","10.1109/MS.2020.3042683","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354400","","Software engineering;Meetings","","","","","","9","IEEE","15 Feb 2021","","","IEEE","IEEE Magazines"
"A Machine Learning Approach to Improve the Detection of CI Skip Commits","R. Abdalkareem; S. Mujahid; E. Shihab","Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 1M8 (e-mail: rab_abdu@encs.concordia.ca); Department of Computer Science & Software Engineering, Concordia University, 5618 Montreal, Quebec Canada (e-mail: suhaibmujahid@gmail.com); Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: eshihab@encs.concordia.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Continuous integration (CI) frameworks, such as Travis CI, are growing in popularity, encouraged by market trends towards speeding up the release cycle and building higher-quality software. A key facilitator of CI is to automatically build and run tests whenever a new commit is submitted/pushed. Despite the many advantages of using CI, it is known that the CI process can take a very long time to complete. One of the core causes for such delays is the fact that some commits (e.g., cosmetic changes) unnecessarily kick off the CI process. Therefore, the main goal of this paper is to automate the process of determining which commits can be CI skipped through the use of machine learning techniques. We first extracted 23 features from historical data of ten software repositories. Second, we conduct a study on the detection of CI skip commits using machine learning, where we built a decision tree classifier. We then examine the accuracy of using the decision tree in detecting CI skip commits. Our results show that the decision tree can identify CI skip commits with an average AUC equal to 0.89. Furthermore, the top node analysis shows that the number of developers who changed the modified files, the CI-Skip rules, and commit message are the most important features to detect CI skip commits. Finally, we investigate the generalizability of identifying CI skip commits through applying cross-project validation, and our results show that the general classifier achieves an average 0.74 of AUC values.","1939-3520","","10.1109/TSE.2020.2967380","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961089","Continuous Integration;Travis CI;Build Status;Machine Learning","Machine learning;Decision trees;Feature extraction;Software;Message systems;Documentation;Buildings","","","","3","","","","16 Jan 2020","","","IEEE","IEEE Early Access Articles"
"CrySL: An Extensible Approach to Validating the Correct Usage of Cryptographic APIs","S. Krüger; J. Späth; K. Ali; E. Bodden; M. Mezini","Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, North Rhine-Westphalia Germany (e-mail: stefan.krueger@uni-paderborn.de); Software Engineering and Security, Fraunhofer IEM, Paderborn, North Rhine-Westphalia Germany (e-mail: johannes.spaeth@iem.fraunhofer.de); Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada T6G 2R3 (e-mail: karim.ali@ualberta.ca); Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, NRW Germany (e-mail: eric.bodden@uni-paderborn.de); Computer Science, Darmstadt University of Technology, Darmstadt, Hessen Germany 64289 (e-mail: mezini@informatik.tu-darmstadt.de)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Various studies have empirically shown that the majority of Java and Android applications misuse cryptographic libraries, causing devastating breaches of data security. It is crucial to detect such misuses early in the development process. To detect cryptography misuses, one must define secure uses first, a process mastered primarily by cryptography experts but not by developers. In this paper, we present CrySL, a specification language for bridging the cognitive gap between cryptography experts and developers. CrySL enables cryptography experts to specify the secure usage of the cryptographic libraries they provide. We have implemented a compiler that translates such CrySL specification into a context-sensitive and flow-sensitive demand-driven static analysis. The analysis then helps developers by automatically checking a given Java or Android app for compliance with the CrySL-encoded rules. We have designed an extensive CrySL rule set for the Java Cryptography Architecture (JCA), and empirically evaluated it by analyzing 10,000 current Android apps and all 204,788 current Java software artefacts on Maven Central. Our results show that misuse of cryptographic APIs is still widespread, with 95% of apps and 63% of Maven artefacts containing at least one misuse. Our easily extensible CrySL rule set covers more violations than previous special-purpose tools that contain hard-coded rules, while still offering a more precise analysis.","1939-3520","","10.1109/TSE.2019.2948910","Oracle; Heinz-Nixdorf Foundation; Fraunhofer-Gesellschaft; Deutsche Forschungsgemeinschaft; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880510","cryptography;domain-specific language;static analysis","Java;Encryption;Static analysis;Tools;Ciphers;Semantics","","","","1","","","","23 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Taking the Middle Path: Learning About Security Through Online Social Interaction","T. Lopez; T. T. Tun; A. K. Bandara; M. Levine; B. Nuseibeh; H. Sharp","The Open University, Milton Keynes, United Kingdom; The Open University, Milton Keynes, United Kingdom; Software Engineering, The Open University, Milton Keynes, United Kingdom; Psychology, Lancaster University, Lancashire, United Kingdom; Computing, The Open University, Milton Keynes, United Kingdom; Software Engineering, The Open University, Milton Keynes, United Kingdom","IEEE Software","20 Dec 2019","2020","37","1","25","30","Integrating security into software development involves more than learning principles or applying techniques. Security can be integrated into software development practice by following a middle path, through which developers draw together knowledge received through training and software development techniques.","1937-4194","","10.1109/MS.2019.2945300","National Cyber Security Centre; Engineering and Physical Sciences Research Council; Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854988","Social learning techniques;support for security;software construction","Security;Software development management;Task analysis;Encoding;Best practices;Programming;Social networking (online)","computer aided instruction;computer science education;security of data;social networking (online);software engineering","online social interaction;learning principles;software development;training;cybersecurity","","","","16","","2 Oct 2019","","","IEEE","IEEE Magazines"
"Is 40 the New 60? How Popular Media Portrays the Employability of Older Software Developers","S. Baltes; G. Park; A. Serebrenik","QAware Gmb, Germany; Software Engineering, Itility B.V.; Software Engineering, Eindhoven University of Technology, Eindhoven, The Netherlands","IEEE Software","23 Oct 2020","2020","37","6","26","31","We studied the public discourse around age and software development, focusing on the United States. This work was designed to build awareness among decision makers in software projects to help them anticipate and mitigate challenges that their older employees may face.","1937-4194","","10.1109/MS.2020.3014178","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157881","","Software;Media;Computer hacking;Industries;Face;Engineering profession;Companies","decision making;organisational aspects;personnel;project management;software engineering","popular media portrays;employability;older software developers;software development;United States;software projects;older employees;decision making","","","","19","","4 Aug 2020","","","IEEE","IEEE Magazines"
"On the Relationship Between the Developer's Perceptible Race and Ethnicity and the Evaluation of Contributions in OSS","R. Nadri; G. Rodriguezperez; M. Nagappan","Computer Science, University of Waterloo Faculty of Mathematics, 153521 Waterloo, Ontario, Canada, (e-mail: rnadri@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: gema.rodriguez-perez@uwaterloo.ca); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: mei.nagappan@uwaterloo.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Context: Open Source Software (OSS) projects are typically the result of collective efforts performed by developers with different backgrounds. Although the quality of developers contributions should be the only factor influencing the evaluation of the contributions to OSS projects, recent studies have shown that diversity issues are correlated with the acceptance or rejection of developers contributions. Objective: This paper assists this emerging state-of-the-art body on diversity research with the first empirical study that analyzes how developers perceptible race and ethnicity relates to the evaluation of the contributions in OSS. We also want to create awareness of the racial and ethnic diversity in OSS projects. Methodology: We performed a large-scale quantitative study of OSS projects in GitHub. We extracted the developers perceptible race and ethnicity from their names in GitHub using the Name-Prism tool and applied regression modeling of contributions (i.e, pull requests) data from GHTorrent and GitHub. Results: We observed that (1) among the developers whose perceptible race and ethnicity was captured by the tool, only 16.56% were perceptible as Non-White developers; (2) contributions from perceptible White developers have about 6-10% higher odds of being accepted when compared to contributions from perceptible Non-White developers; and (3) submitters with perceptible non-white races and ethnicities are more likely to get their pull requests accepted when the integrator is estimated to be from their same race and ethnicity rather than when the integrator is estimated to be White. Conclusion: Our initial analysis shows a low number of Non-White developers participating in OSS. Furthermore, the results from our regression analysis lead us to believe that there may exist differences between the evaluation of the contributions from different perceptible races and ethnicities. Thus, our findings reinforce the need for further studies on racial and ethnic diversity in software engineering to foster healthier OSS communities.","1939-3520","","10.1109/TSE.2021.3073773","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9406372","","Software development management;Cultural differences;Tools;Software engineering;Open source software;Psychology;Gender issues","","","","","","","IEEE","16 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Learning From Mistakes: Machine Learning Enhanced Human Expert Effort Estimates","F. Sarro; R. Moussa; A. Petrozziello; M. Harman","Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: rebecca.moussa.18@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: a.petrozziello@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","In this paper, we introduce a novel approach to predictive modeling for software engineering, named Learning From Mistakes (LFM). The core idea underlying our proposal is to automatically learn from past estimation errors made by human experts, in order to predict the characteristics of their future misestimates, therefore resulting in improved future estimates. We show the feasibility of LFM by investigating whether it is possible to predict the type, severity and magnitude of errors made by human experts when estimating the development effort of software projects, and whether it is possible to use these predictions to enhance future estimations. To this end we conduct a thorough empirical study investigating 402 maintenance and new development industrial software projects. The results of our study reveal that the type, severity and magnitude of errors are all, indeed, predictable. Moreover, we find that by exploiting these predictions, we can obtain significantly better estimates than those provided by random guessing, human experts and traditional machine learners in 31 out of the 36 cases considered (86%), with large and very large effect sizes in the majority of these cases (81%). This empirical evidence opens the door to the development of techniques that use the power of machine learning, coupled with the observation that human errors are predictable, to support engineers in estimation tasks rather than replacing them with machine-provided estimates.","1939-3520","","10.1109/TSE.2020.3040793","European Research Council Advanced Fellowship Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9272884","Software Effort Estimation;Estimate errors;Human expert estimates;Human Bias;Human-competitive results","Software;Predictive models;Companies;Software engineering;Estimation error;Task analysis;Software measurement","","","","","","","IEEE","27 Nov 2020","","","IEEE","IEEE Early Access Articles"
"The Effects of Human Aspects on the Requirements Engineering Process: A Systematic Literature Review","D. Hidellaarachchi; J. Grundy; R. Hoda; K. Madampe","Software Systems and Cybersecurity, Monash University, 2541 Clayton, Victoria, Australia, 3800 (e-mail: dulajidinupama@gmail.com); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, 3800 (e-mail: rashina@gmail.com); Software Systems and Cybersecurity, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: kashumi.madampe@monash.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Requirements Engineering (RE) requires the collaboration of various roles in SE, such as requirements engineers, stakeholders and other developers, and it is thus a very highly human dependent process in software engineering (SE). Identifying how ""human aspects"" such as personality, motivation, emotions, communication, gender, culture and geographic distribution might impact on the RE process would assist us in better supporting successful RE. The main objective of this paper is to systematically review primary studies that have investigated the effects of various human aspects on the RE process. We wanted to identify if any critical human aspects have been found, and what might be the relationships between different human aspects impacting the RE process. A systematic literature review (SLR) was conducted and identified 474 initial primary research studies. These were eventually filtered down to 73 relevant, high-quality primary studies. No primary study to date was found to focus on identifying what are the most influential human aspects on the RE process. Among the studied human aspects, the effects of communication have been considered in many studies of RE. Other human aspects such as personality, motivation and gender have mainly been investigated to date in relation to more general SE studies that include RE as one phase. Findings show that studying more than one human aspect together is beneficial, as this reveals relationships between various human aspects and how they together impact the RE process. However, the majority of these studied combinations of human aspects are unique. From 56.2% of studies that identified the effects of human aspects on RE, 39% identified the positive impact, 32% negative, 27% identified both impacts whereas 2% mentioned that there was no impact. This implies that a variety of human aspects positively or negatively affects the RE process and a well-defined theoretical analysis on the effects of different human aspects on RE remains to be defined and practically evaluated. The findings of this SLR help researchers who are investigating the impact of various human aspects on the RE process by identifying well-studied research areas, and highlight new areas that should be focused on in future research.","1939-3520","","10.1109/TSE.2021.3051898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325916","Systematic Literature Review;human aspects;human-centric issues;requirements engineering","Software;Systematics;Software engineering;Bibliographies;Stakeholders;Meteorology;Taxonomy","","","","","","","IEEE","15 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Need for Sleep: The Impact of a Night of Sleep Deprivation on Novice Developers’ Performance","D. Fucci; G. Scanniello; S. Romano; N. Juristo","HITeC, University of Hamburg, Hamburg, Germany; DiMIE, University of Basilicata, Potenza, Italy; DiMIE, University of Basilicata, Potenza, Italy; Technical University of Madrid, Madrid, Spain","IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","1","19","We present a quasi-experiment to investigate whether, and to what extent, sleep deprivation impacts the performance of novice software developers using the agile practice of test-first development (TFD). We recruited 45 undergraduates, and asked them to tackle a programming task. Among the participants, 23 agreed to stay awake the night before carrying out the task, while 22 slept normally. We analyzed the quality (i.e., the functional correctness) of the implementations delivered by the participants in both groups, their engagement in writing source code (i.e., the amount of activities performed in the IDE while tackling the programming task) and ability to apply TFD (i.e., the extent to which a participant is able to apply this practice). By comparing the two groups of participants, we found that a single night of sleep deprivation leads to a reduction of 50 percent in the quality of the implementations. There is notable evidence that the developers' engagement and their prowess to apply TFD are negatively impacted. Our results also show that sleep-deprived developers make more fixes to syntactic mistakes in the source code. We conclude that sleep deprivation has possibly disruptive effects on software development activities. The results open opportunities for improving developers' performance by integrating the study of sleep with other psycho-physiological factors in which the software engineering research community has recently taken an interest in.","1939-3520","","10.1109/TSE.2018.2834900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8357494","Sleep deprivation;psycho-physiological factors;test-first development","Sleep;Software;Task analysis;Biomedical monitoring;Software engineering;Programming;Functional magnetic resonance imaging","computer aided instruction;computer science education;sleep;software engineering","source code;sleep deprivation;software development activities;novice software developers;TFD;programming task;sleep-deprived developers","","2","","103","IEEE","10 May 2018","","","IEEE","IEEE Journals"
"Experimental evaluation of test-driven development with interns working on a real industrial project","B. K. Papis; K. Grochowski; K. Subzda; K. Sijko","SWE, Google Inc, 93176 Warsaw, Mazowieckie, Poland, 00-113 (e-mail: bartoszkp@gmail.com); The Institute of Computer Science, Politechnika Warszawska, 49566 Warszawa, mazowieckie, Poland, (e-mail: Konrad.Grochowski@pw.edu.pl); Katedra Metrologii Elektronicznej i Fotonicznej, Politechnika Wroclawska Wydzial Elektroniki, 325847 Wroclaw, dolnolskie, Poland, (e-mail: kamil.subzda@gmail.com); R&D, Transition Technologies, Warsaw, mazowieckie, Poland, (e-mail: kamil@sijko.pl)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Context: There is still little evidence on differences between Test-Driven Development and Test-Last Development, especially for real-world projects, so their impact on code/test quality is an ongoing research trend. An empirical comparison is presented, with 19 participants working on an industrial project developed for an energy market software company, implementing real-world requirements for one of the company's customers. Objective: Examine the impact of TDD and TLD on quality of the code and the tests. The aim is to evaluate if there is a significant difference in external code quality and test quality between these techniques. Method: The experiment is based on a randomized within-subjects block design, with participants working for three months on the same requirements using different techniques, changed from week to week, within three different competence blocks: Intermediate, Novice and Mixed. The resulting code was verified for process conformance. The participants developed only business logic and were separated from infrastructural concerns. A separate group of code repositories was used to work without unit tests, to verify that the requirements were not too easy for the participants. Also, it was analysed if there is any difference between the code created by shared efforts of developers with different competences and the code created by participants isolated in the competence blocks. The resulting implementations had LOC order of magnitude of 10k. Results: Statistically significant advantage of TDD in terms of external code quality (1.8 fewer bugs) and test quality (5 percentage points higher) than TLD. Additionally, TDD narrows the gap in code coverage between developers from different competence blocks. At the same time, TDD proved to have a considerable entry barrier and was hard to follow strictly, especially by Novices. Still, no significant difference w.r.t. code coverage has been observed between the Intermediate and the Novice developers - as opposed to TLD, which was easier to follow. Lastly, isolating the Intermediate developers from the Novices had significant impact on the code quality. Conclusion:TDD is a recommended technique for software projects with a long horizon or when it is critical to minimize the number of bugs and achieve high code coverage.","1939-3520","","10.1109/TSE.2020.3027522","Transition Technologies S.A.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207972","Empirical software engineering;Iterative test last development;Test driven development","Software;Companies;Testing;Writing;Programming;Market research","","","","","","","CCBY","28 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Measuring the Impact of Code Dependencies on Software Architecture Recovery Techniques","T. Lutellier; D. Chollak; J. Garcia; L. Tan; D. Rayside; N. Medvidović; R. Kroeger","University of Waterloo, Waterloo, ON, Canada; University of Waterloo, Waterloo, ON, Canada; University of California, Irvine, CA; University of Waterloo, Waterloo, ON, Canada; University of Waterloo, Waterloo, ON, Canada; University of Southern California, Los Angeles, CA; Google Inc., Mountain View, CA","IEEE Transactions on Software Engineering","12 Feb 2018","2018","44","2","159","181","Many techniques have been proposed to automatically recover software architectures from software implementations. A thorough comparison among the recovery techniques is needed to understand their effectiveness and applicability. This study improves on previous studies in two ways. First, we study the impact of leveraging accurate symbol dependencies on the accuracy of architecture recovery techniques. In addition, we evaluate other factors of the input dependencies such as the level of granularity and the dynamic-bindings graph construction. Second, we recovered the architecture of a large system, Chromium, that was not available previously. Obtaining the ground-truth architecture of Chromium involved two years of collaboration with its developers. As part of this work, we developed a new submodule-based technique to recover preliminary versions of ground-truth architectures. The results of our evaluation of nine architecture recovery techniques and their variants suggest that (1) using accurate symbol dependencies has a major influence on recovery quality, and (2) more accurate recovery techniques are needed. Our results show that some of the studied architecture recovery techniques scale to very large systems, whereas others do not.","1939-3520","","10.1109/TSE.2017.2671865","Natural Sciences and Engineering Research Council of Canada; Google Faculty Research Award; Ontario Ministry of Research and Innovation; U.S. National Science Foundation; Infosys Technologies, Ltd.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7859416","Software architecture;empirical software engineering;maintenance and evolution;program comprehension","Computer architecture;Software architecture;Software;Heuristic algorithms;Chromium;Software algorithms;Manuals","software architecture;software quality;system recovery","symbol dependencies;accurate recovery techniques;recovery quality;submodule-based technique;ground-truth architecture;input dependencies;software implementations;software architectures;software architecture recovery techniques;code dependencies","","11","","72","","20 Feb 2017","","","IEEE","IEEE Journals"
"Enabling Decision and Objective Space Exploration for Interactive Multi-Objective Refactoring","S. Rebai; V. Alizadeh; M. Kessentini; H. Fehri; R. Kazman","Computer and Information Science, Regents of the University of Michigan, 507697 Dearborn, Michigan United States (e-mail: srebal@umich.edu); CIS Department, University of Michigan, Dearborn, Michigan United States (e-mail: alizadeh@umich.edu); CIS, University of Michigan Dearborn, 14711 Dearborn, Michigan United States (e-mail: marouane@umich.edu); CIS, University of Michigan Dearborn, 14711 Dearborn, Michigan United States (e-mail: houcemf@umich.edu); Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii United States 96822 (e-mail: kazman@hawaii.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Due to the conflicting nature of quality measures, there are always multiple refactoring options to fix quality issues. Thus, interaction with developers is critical to inject their preferences. While several interactive techniques have been proposed, developers still need to examine large numbers of possible refactorings, which makes the interaction time-consuming. Furthermore, existing interactive tools are limited to the ""objective space"" to show developers the impacts of refactorings on quality attributes. However, the ""decision space"" is also important since developers may want to focus on specific code locations. In this paper, we propose an interactive approach that enables developers to pinpoint their preference simultaneously in the objective (quality metrics) and decision (code location) spaces. Developers may be interested in looking at refactoring strategies that can improve a specific quality attribute, such as extendibility (objective space), but they are related to different code locations (decision space). A plethora of solutions is generated at first using multi-objective search that tries to find the possible trade-offs between quality objectives. Then, an unsupervised learning algorithm clusters the trade-off solutions based on their quality metrics, and another clustering algorithm is applied to each cluster of the objective space to identify solutions related to different code locations. The objective and decision spaces can now be explored more efficiently by the developer, who can give feedback on a smaller number of solutions. This feedback is then used to generate constraints for the optimization process, to focus on the developer's regions of interest in both the decision and objective spaces. The manual validation of selected refactoring solutions by developers confirms that our approach outperforms state of the art refactoring techniques.","1939-3520","","10.1109/TSE.2020.3024814","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200705","Search based software engineering;refactoring;multi-objective search;clustering","Tools;Clustering algorithms;Measurement;Search problems;Manuals;Software;Space exploration","","","","","","","","18 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Approximate Oracles and Synergy in Software Energy Search Spaces","B. R. Bruce; J. Petke; M. Harman; E. T. Barr","University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom","IEEE Transactions on Software Engineering","12 Nov 2019","2019","45","11","1150","1169","Reducing the energy consumption of software systems through optimisation techniques such as genetic improvement is gaining interest. However, efficient and effective improvement of software systems requires a better understanding of the code-change search space. One important choice practitioners have is whether to preserve the system's original output or permit approximation, with each scenario having its own search space characteristics. When output preservation is a hard constraint, we report that the maximum energy reduction achievable by the modification operators is 2.69 percent (0.76 percent on average). By contrast, this figure increases dramatically to 95.60 percent (33.90 percent on average) when approximation is permitted, indicating the critical importance of approximate output quality assessment for code optimisation. We investigate synergy, a phenomenon that occurs when simultaneously applied source code modifications produce an effect greater than their individual sum. Our results reveal that 12.0 percent of all joint code modifications produced such a synergistic effect, though 38.5 percent produce an antagonistic interaction in which simultaneously applied modifications are less effective than when applied individually. This highlights the need for more advanced search-based techniques.","1939-3520","","10.1109/TSE.2018.2827066","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338061","Search-based software engineering;search space;energy consumption;genetic improvement;synergy;antagonism;oracle;approximation","Energy consumption;Energy measurement;Software systems;Optimization;Aggregates;Genetics","optimisation;power aware computing;search problems;software engineering","optimisation techniques;genetic improvement;software systems;code-change search space;search space characteristics;output preservation;hard constraint;maximum energy reduction;modification operators;approximate output quality assessment;code optimisation;source code modifications;joint code modifications;synergistic effect;advanced search-based techniques;approximate oracles;software energy search spaces;energy consumption","","4","","63","","16 Apr 2018","","","IEEE","IEEE Journals"
"How Developers Diagnose Potential Security Vulnerabilities with a Static Analysis Tool","J. Smith; B. Johnson; E. Murphy-Hill; B. Chu; H. R. Lipford","North Carolina State University, Raleigh, NC; University of Massachusetts Amherst, Amherst, MA; North Carolina State University, Raleigh, NC; University of North Carolina at Charlotte, Charlotte, NC; University of North Carolina at Charlotte, Charlotte, NC","IEEE Transactions on Software Engineering","18 Sep 2019","2019","45","9","877","897","While using security tools to resolve security defects, software developers must apply considerable effort. Success depends on a developer's ability to interact with tools, ask the right questions, and make strategic decisions. To build better security tools and subsequently help developers resolve defects more accurately and efficiently, we studied the defect resolution process-from the questions developers ask to their strategies for answering them. In this paper, we report on an exploratory study with novice and experienced software developers. We equipped them with Find Security Bugs, a security-oriented static analysis tool, and observed their interactions with security vulnerabilities in an open-source system that they had previously contributed to. We found that they asked questions not only about security vulnerabilities, associated attacks, and fixes, but also questions about the software itself, the social ecosystem that built the software, and related resources and tools. We describe the strategic successes and failures we observed and how future tools can leverage our findings to encourage better strategies.","1939-3520","","10.1109/TSE.2018.2810116","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8303758","Software engineering;human factors;security;software tools;programming environments","Tools;Task analysis;Software;Static analysis;Computer bugs;SQL injection","program debugging;program diagnostics;security of data;software engineering;software maintenance","security tools;questions developers;experienced software developers;Security Bugs;security-oriented static analysis tool;security defects;potential Security vulnerabilities;defect resolution process;open-source system;social ecosystem","","4","","65","","27 Feb 2018","","","IEEE","IEEE Journals"
"Managing Programmers, with Ron Lichty","N. Black",Sleeperbot,"IEEE Software","25 Dec 2017","2018","35","1","117","120","Veteran software manager Ron Lichty joins Nate Black to share his insights on managing software engineers. Nate and Ron delve into what about this is hard, how to grow as a manager, and what makes highly performing teams.","1937-4194","","10.1109/MS.2017.4541030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239929","programming managers;software teams;software development;Ron Lichty;Nate Black;software engineering;Software Engineering Radio","Collaboration;Software engineering;Engineering profession;Programming profession;Databases;Training","","","","","","","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Using K-core Decomposition on Class Dependency Networks to Improve Bug Prediction Model's Practical Performance","Y. Qu; Q. Zheng; J. Chi; Y. Jin; A. He; D. Cui; H. Zhang; T. Liu","Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; School of Computer Science, Xi'an University of Posts and Telecommunications, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","348","366","In recent years, Complex Network theory and graph algorithms have been proved to be effective in predicting software bugs. On the other hand, as a widely-used algorithm in Complex Network theory, k-core decomposition has been used in software engineering domain to identify key classes. Intuitively, key classes are more likely to be buggy since they participate in more functions or have more interactions and dependencies. However, there is no existing research uses k-core decomposition to analyze software bugs. To fill this gap, we first use k-core decomposition on Class Dependency Networks to analyze software bug distribution from a new perspective. An interesting and widely existed tendency is observed: for classes in k-cores with larger k values, there is a stronger possibility for them to be buggy. Based on this observation, we then propose a simple but effective equation named as top-core which improves the order of classes in the suspicious class list produced by effort-aware bug prediction models. Based on an empirical study on 18 open-source Java systems, we show that the bug prediction models' performances are significantly improved in 85.2 percent experiments in the cross-validation scenario and in 80.95 percent experiments in the forward-release scenario, after using top-core. The models' average performances are improved by 11.5 and 12.6 percent, respectively. It is concluded that the proposed top-core equation can help the testers or code reviewers locate the real bugs more quickly and easily in software bug prediction practices.","1939-3520","","10.1109/TSE.2019.2892959","National Key Research and Development Program of China; National Natural Science Foundation of China; Ministry of Education Innovation Research Team; Shaanxi Province postdoctoral research project funding; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611396","Bug prediction;software defects;complex network;class dependency network;effort-aware bug prediction","Computer bugs;Software;Mathematical model;Predictive models;Complex networks;Prediction algorithms;Software algorithms","complex networks;graph theory;Java;network theory (graphs);program debugging;public domain software;software engineering;software maintenance","class dependency networks;complex network theory;software bug distribution;software engineering domain;software bugs;bug prediction model;k-core decomposition;software bug prediction practices;top-core equation;effort-aware bug prediction models;suspicious class list;efficiency 85.2 percent;efficiency 80.95 percent;efficiency 12.6 percent;efficiency 11.5 percent","","","","66","IEEE","13 Jan 2019","","","IEEE","IEEE Journals"
"A Templating System to Generate Provenance","L. Moreau; B. V. Batlajery; T. D. Huynh; D. Michaelides; H. Packer","Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom; Department of Electronics and Computer Science, University of Southampton, Southampton, United Kingdom","IEEE Transactions on Software Engineering","12 Feb 2018","2018","44","2","103","121","PROV-TEMPLATEIS a declarative approach that enables designers and programmers to design and generate provenance compatible with the PROV standard of the World Wide Web Consortium. Designers specify the topology of the provenance to be generated by composing templates, which are provenance graphs containing variables, acting as placeholders for values. Programmers write programs that log values and package them up in sets of bindings, a data structure associating variables and values. An expansion algorithm generates instantiated provenance from templates and sets of bindings in any of the serialisation formats supported by PROV. A quantitative evaluation shows that sets of bindings have a size that is typically 40 percent of that of expanded provenance templates and that the expansion algorithm is suitably tractable, operating in fractions of milliseconds for the type of templates surveyed in the article. Furthermore, the approach shows four significant software engineering benefits: separation of responsibilities, provenance maintenance, potential runtime checks and static analysis, and provenance consumption. The article gathers quantitative data and qualitative benefits descriptions from four different applications making use of PROV-TEMPLATE. The system is implemented and released in the open-source library ProvToolbox for provenance processing.","1939-3520","","10.1109/TSE.2017.2659745","EPSRC SOCIAM; ORCHID; FP7 SmartSociety; ESRC eBook; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7909036","Provenance;prov;provenance generation;template","Electronic publishing;Instruments;Standards;Maintenance engineering;Runtime;Libraries;Automobiles","data structures;graph theory;Internet;software engineering;software maintenance","data structure;PROV-TEMPLATE;provenance generation;open-source library ProvToolbox;software engineering;templating system;provenance processing;quantitative data;provenance consumption;provenance maintenance;expanded provenance templates;expansion algorithm;provenance graphs;World Wide Web Consortium;PROV standard","","6","","64","CCBY","24 Apr 2017","","","IEEE","IEEE Journals"
"What Predicts Software Developers’ Productivity?","E. Murphy-Hill; C. Jaspan; C. Sadowski; D. Shepherd; M. Phillips; C. Winter; A. Knight; E. Smith; M. Jorde","Developer Infrastructure, Google Inc., Sunnyvale, CA, USA; Developer Infrastructure, Google Inc., Sunnyvale, CA, USA; Chrome, Google Inc., Mountain View, CA, USA; ISS SWE, ABB, Inc., Raleigh, NC, USA; Research & Development, National Instruments Corp., Austin, TX, USA; Waymo, Mountain View, CA, USA; Developer Infrastructure, Google Inc., Sunnyvale, CA, USA; Bloomberg, Bloomberg LP, New York, NY, USA; Developer Infrastructure, Google Inc., Sunnyvale, CA, USA","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","582","594","Organizations have a variety of options to help their software developers become their most productive selves, from modifying office layouts, to investing in better tools, to cleaning up the source code. But which options will have the biggest impact? Drawing from the literature in software engineering and industrial/organizational psychology to identify factors that correlate with productivity, we designed a survey that asked 622 developers across 3 companies about these productivity factors and about self-rated productivity. Our results suggest that the factors that most strongly correlate with self-rated productivity were non-technical factors, such as job enthusiasm, peer support for new ideas, and receiving useful feedback about job performance. Compared to other knowledge workers, our results also suggest that software developers' self-rated productivity is more strongly related to task variety and ability to work remotely.","1939-3520","","10.1109/TSE.2019.2900308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643844","Productivity factors;software engineers;knowledge workers","Productivity;Software;Companies;Google;Tools;Task analysis;Time measurement","DP industry;employee welfare;industrial psychology;organisational aspects;personnel;productivity;software engineering;teleworking","task variety;remote work;job performance feedback;peer support;job enthusiasm;organizational psychology;industrial psychology;software developer productivity prediction;software engineering;source code;office layouts;nontechnical factors;self-rated productivity;productivity factors","","1","","48","IEEE","19 Feb 2019","","","IEEE","IEEE Journals"
"Automating Intention Mining","Q. Huang; X. Xia; D. Lo; G. C. Murphy","College of Computer Science and Technology, Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Information Systems, Singapore Management University, Singapore; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Software Engineering","14 Oct 2020","2020","46","10","1098","1119","Developers frequently discuss aspects of the systems they are developing online. The comments they post to discussions form a rich information source about the system. Intention mining, a process introduced by Di Sorbo et al., classifies sentences in developer discussions to enable further analysis. As one example of use, intention mining has been used to help build various recommenders for software developers. The technique introduced by Di Sorbo et al. to categorize sentences is based on linguistic patterns derived from two projects. The limited number of data sources used in this earlier work introduces questions about the comprehensiveness of intention categories and whether the linguistic patterns used to identify the categories are generalizable to developer discussion recorded in other kinds of software artifacts (e.g., issue reports). To assess the comprehensiveness of the previously identified intention categories and the generalizability of the linguistic patterns for category identification, we manually created a new dataset, categorizing 5,408 sentences from issue reports of four projects in GitHub. Based on this manual effort, we refined the previous categories. We assess Di Sorbo et al.'s patterns on this dataset, finding that the accuracy rate achieved is low (0.31). To address the deficiencies of Di Sorbo et al.'s patterns, we propose and investigate a convolution neural network (CNN)-based approach to automatically classify sentences into different categories of intentions. Our approach optimizes CNN by integrating batch normalization to accelerate the training speed, and an automatic hyperparameter tuning approach to tune appropriate hyperparameters of CNN. Our approach achieves an accuracy of 0.84 on the new dataset, improving Di Sorbo et al.'s approach by 171 percent. We also apply our approach to improve an automated software engineering task, in which we use our proposed approach to rectify misclassified issue reports, thus reducing the bias introduced by such data to other studies. A case study on four open source projects with 2,076 issue reports shows that our approach achieves an average AUC score of 0.687, which improves other baselines by at least 16 percent.","1939-3520","","10.1109/TSE.2018.2876340","National Key Research and Development Program of China; NSFC Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493285","Deep Learning;Intention;Issue Report;Empirical Study","Taxonomy;Linguistics;Data mining;Tuning;Computer bugs;Software;Training","computational linguistics;convolutional neural nets;data mining;pattern classification;software engineering","intention mining;software developers;linguistic patterns;software artifacts;category identification;CNN;automatic hyperparameter tuning;software engineering;convolution neural network;sentence classification","","6","","90","IEEE","16 Oct 2018","","","IEEE","IEEE Journals"
"Analyzing Families of Experiments in SE: A Systematic Mapping Study","A. Santos; O. Gómez; N. Juristo","M3S (M-Group), ITEE University of Oulu, Oulu, Finland; Escuela Superior Politécnica de Chimborazo Riobamba, Chimborazo, Ecuador; Escuela Técnica Superior de Ingenieros Informáticos, Campus Montegancedo, Universidad Politécnica de Madrid, Boadilla del Monte, Spain","IEEE Transactions on Software Engineering","14 May 2020","2020","46","5","566","583","Context: Families of experiments (i.e., groups of experiments with the same goal) are on the rise in Software Engineering (SE). Selecting unsuitable aggregation techniques to analyze families may undermine their potential to provide in-depth insights from experiments' results. Objectives: Identifying the techniques used to aggregate experiments' results within families in SE. Raising awareness of the importance of applying suitable aggregation techniques to reach reliable conclusions within families. Method: We conduct a systematic mapping study (SMS) to identify the aggregation techniques used to analyze families of experiments in SE. We outline the advantages and disadvantages of each aggregation technique according to mature experimental disciplines such as medicine and pharmacology. We provide preliminary recommendations to analyze and report families of experiments in view of families' common limitations with regard to joint data analysis. Results: Several aggregation techniques have been used to analyze SE families of experiments, including Narrative synthesis, Aggregated Data (AD), Individual Participant Data (IPD) mega-trial or stratified, and Aggregation of p-values. The rationale used to select aggregation techniques is rarely discussed within families. Families of experiments are commonly analyzed with unsuitable aggregation techniques according to the literature of mature experimental disciplines. Conclusion: Data analysis' reporting practices should be improved to increase the reliability and transparency of joint results. AD and IPD stratified appear to be suitable to analyze SE families of experiments.","1939-3520","","10.1109/TSE.2018.2864633","Ministerio de Ciencia e Innovación; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8430603","Family of experiments;meta-analysis;narrative synthesis;IPD;AD","Systematics;Data aggregation;Reliability;Data analysis","data analysis;software engineering","systematic mapping study;aggregation technique;SE families;software engineering;SMS;narrative synthesis;aggregated data;individual participant data;p-values","","2","","121","IEEE","9 Aug 2018","","","IEEE","IEEE Journals"
"How Do Users Revise Answers on Technical Q&A Websites? A Case Study on Stack Overflow","S. Wang; T. -H. Chen; A. E. Hassan","School of the Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; School of the Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","17 Sep 2020","2020","46","9","1024","1038","To ensure the quality of its shared knowledge, Stack Overflow encourages users to revise answers through a badge system, which is based on quantitative measures (e.g., a badge is awarded after revising more than 500 answers). Prior studies show that badges can positively steer the user behavior on Stack Overflow (e.g., increasing user participation). However, little is known whether revision-related badges have a negative impact on the quality of revisions since some studies show that certain users may game incentive systems to gain rewards. In this study, we analyze 3,871,966 revision records that are collected from 2,377,692 Stack Overflow answers. We find that: 1) Users performed a much larger than usual revisions on the badge-awarding days compared to normal days; 25% of the users did not make any more revisions once they received their first revision-related badge. 2) Performing more revisions than usual in a single day increased the likelihood of such revisions being rolled back (e.g., due to undesired or incorrect revisions). 3) Users were more likely to perform text and small revisions if they performed many revisions in a single day. Our findings are concurred by the Stack Overflow community, and they highlight the need for changes to the current badge system in order to provide a better balance between the quality and quantity of revisions.","1939-3520","","10.1109/TSE.2018.2874470","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485395","Stack overflow;incentive system;badge;answer revision","Atmospheric measurements;Particle measurements;Games;Indexes;Knowledge engineering;Software;Computer science","question answering (information retrieval);software engineering;Web sites","user behavior;user participation;revision-related badge;Stack Overflow answers;usual revisions;badge-awarding days;undesired revisions;incorrect revisions;Stack Overflow community;current badge system;revision records","","4","","44","IEEE","7 Oct 2018","","","IEEE","IEEE Journals"
"Metamorphic Relations for Enhancing System Understanding and Use","Z. Q. Zhou; L. Sun; T. Y. Chen; D. Towey","Institute of Cybersecurity and Cryptology, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Institute of Cybersecurity and Cryptology, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Department of Computer Science and Software Engineering, Swinburne University of Technology, Hawthorn, VIC, Australia; School of Computer Science, University of Nottingham Ningbo China, Ningbo, Zhejiang, China","IEEE Transactions on Software Engineering","14 Oct 2020","2020","46","10","1120","1154","Modern information technology paradigms, such as online services and off-the-shelf products, often involve a wide variety of users with different or even conflicting objectives. Every software output may satisfy some users, but may also fail to satisfy others. Furthermore, users often do not know the internal working mechanisms of the systems. This situation is quite different from bespoke software, where developers and users typically know each other. This paper proposes an approach to help users to better understand the software that they use, and thereby more easily achieve their objectives-even when they do not fully understand how the system is implemented. Our approach borrows the concept of metamorphic relations from the field of metamorphic testing (MT), using it in an innovative way that extends beyond MT. We also propose a “symmetry” metamorphic relation pattern and a “change direction” metamorphic relation input pattern that can be used to derive multiple concrete metamorphic relations. Empirical studies reveal previously unknown failures in some of the most popular applications in the world, and show how our approach can help users to better understand and better use the systems. The empirical results provide strong evidence of the simplicity, applicability, and effectiveness of our methodology.","1939-3520","","10.1109/TSE.2018.2876433","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493260","Metamorphic exploration;symmetry;metamorphic testing;metamorphic relation;metamorphic relation pattern;metamorphic relation input pattern;change direction;oracle problem;user experience;user countermeasure;software validation","Software testing;Information technology;Electronic mail;Software systems;Software maintenance","program testing;software engineering","system understanding;software output;metamorphic testing;MT;symmetry metamorphic relation pattern;change direction metamorphic relation input pattern;multiple concrete metamorphic relations;system usage","","10","","95","IEEE","16 Oct 2018","","","IEEE","IEEE Journals"
"Harsh Sinha on Product Management","B. Reinero",MongoDB,"IEEE Software","12 Mar 2018","2018","35","2","105","108","Software Engineering Radio host Bryan Reinero talks with Harsh Sinha about product management, particularly for software engineers. http://www.se-radio.net/2017/10/se-radio-episode-307-harsh-sinha-on-product-management/ is an audio recording of this episode of Software Engineering Radio.","1937-4194","","10.1109/MS.2018.1661314","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314170","Harsh Sinha;product management;product managers;conversion funnel;software engineering;software development","Software engineering;Software development management;Software measurement;Interviews;Software product lines","","","","","","","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Automatic Feature Learning for Predicting Vulnerable Software Components","H. K. Dam; T. Tran; T. Pham; S. W. Ng; J. Grundy; A. Ghose","Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; School of Information Technology, Deakin University, Waurn Ponds, Victoria, Australia; School of Information Technology, Deakin University, Waurn Ponds, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia; Faculty of Information Technology, Monash University, Clayton, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, Wollongong, NSW, Australia","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","67","85","Code flaws or vulnerabilities are prevalent in software systems and can potentially cause a variety of problems including deadlock, hacking, information loss and system failure. A variety of approaches have been developed to try and detect the most likely locations of such code vulnerabilities in large code bases. Most of them rely on manually designing code features (e.g., complexity metrics or frequencies of code tokens) that represent the characteristics of the potentially problematic code to locate. However, all suffer from challenges in sufficiently capturing both semantic and syntactic representation of source code, an important capability for building accurate prediction models. In this paper, we describe a new approach, built upon the powerful deep learning Long Short Term Memory model, to automatically learn both semantic and syntactic features of code. Our evaluation on 18 Android applications and the Firefox application demonstrates that the prediction power obtained from our learned features is better than what is achieved by state of the art vulnerability prediction models, for both within-project prediction and cross-project prediction.","1939-3520","","10.1109/TSE.2018.2881961","Samsung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540022","Software vulnerability prediction;mining software engineering repositories;empirical software engineering","Semantics;Software systems;Predictive models;Security;Feature extraction;System recovery","data mining;feature extraction;learning (artificial intelligence);public domain software;security of data","prediction power;art vulnerability prediction models;within-project prediction;cross-project prediction;automatic feature learning;predicting vulnerable software components;software systems;information loss;system failure;code vulnerabilities;code bases;code features;complexity metrics;code tokens;potentially problematic code;semantic representation;syntactic representation;source code;important capability;accurate prediction models;powerful deep learning Long Short Term Memory model","","4","","61","IEEE","18 Nov 2018","","","IEEE","IEEE Journals"
"Predicting Delivery Capability in Iterative Software Development","M. Choetkiertikul; H. K. Dam; T. Tran; A. Ghose; J. Grundy","Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, NSW, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, NSW, Australia; School of Information Technology, Deakin University, Victoria, Australia; Faculty of Engineering and Information Sciences, School of Computing and Information Technology, University of Wollongong, NSW, Australia; School of Information Technology, Deakin University, Victoria, Australia","IEEE Transactions on Software Engineering","12 Jun 2018","2018","44","6","551","573","Iterative software development has become widely practiced in industry. Since modern software projects require fast, incremental delivery for every iteration of software development, it is essential to monitor the execution of an iteration, and foresee a capability to deliver quality products as the iteration progresses. This paper presents a novel, data-driven approach to providing automated support for project managers and other decision makers in predicting delivery capability for an ongoing iteration. Our approach leverages a history of project iterations and associated issues, and in particular, we extract characteristics of previous iterations and their issues in the form of features. In addition, our approach characterizes an iteration using a novel combination of techniques including feature aggregation statistics, automatic feature learning using the Bag-of-Words approach, and graph-based complexity measures. An extensive evaluation of the technique on five large open source projects demonstrates that our predictive models outperform three common baseline methods in Normalized Mean Absolute Error and are highly accurate in predicting the outcome of an ongoing iteration.","1939-3520","","10.1109/TSE.2017.2693989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898472","Mining software engineering repositories;empirical software engineering;iterative software development","Software;Feature extraction;Predictive models;Data mining;Complexity theory;Iterative methods;Agile software development","graph theory;learning (artificial intelligence);project management;software development management;software prototyping;software quality","iterative software development;incremental delivery;data-driven approach;project iterations;open source projects;delivery capability;software projects;feature aggregation statistics;automatic feature learning;Bag-of-Words;graph-based complexity;Normalized Mean Absolute Error","","5","","88","","12 Apr 2017","","","IEEE","IEEE Journals"
"An Empirical Study of Obsolete Answers on Stack Overflow","H. Zhang; S. Wang; T. -H. Chen; Y. Zou; A. E. Hassan","Software Analysis and Intelligence Lab (SAIL), Queen’s University, Kingston, ON, Canada; Software Analysis and Intelligence Lab (SAIL), Queen’s University, Kingston, ON, Canada; Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Department of Electrical and Computer Engineering, Queen’s University, Kingston, ON, Canada; Software Analysis and Intelligence Lab (SAIL), Queen’s University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","850","862","Stack Overflow accumulates an enormous amount of software engineering knowledge. However, as time passes, certain knowledge in answers may become obsolete. Such obsolete answers, if not identified or documented clearly, may mislead answer seekers and cause unexpected problems (e.g., using an out-dated security protocol). In this paper, we investigate how the knowledge in answers becomes obsolete and identify the characteristics of such obsolete answers. We find that: 1) More than half of the obsolete answers (58.4 percent) were probably already obsolete when they were first posted. 2) When an obsolete answer is observed, only a small proportion (20.5 percent) of such answers are ever updated. 3) Answers to questions in certain tags (e.g., node.js, ajax, android, and objective-c) are more likely to become obsolete. Our findings suggest that Stack Overflow should develop mechanisms to encourage the whole community to maintain answers (to avoid obsolete answers) and answer seekers are encouraged to carefully go through all information (e.g., comments) in answer threads.","1939-3520","","10.1109/TSE.2019.2906315","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669958","Q&A website;stack overflow;obsolete knowledge;knowledge sharing","Aging;Knowledge engineering;Message systems;Google;Computer languages;Software engineering;Security","","","","6","","39","IEEE","19 Mar 2019","","","IEEE","IEEE Journals"
"Explaining Static Analysis with Rule Graphs","L. Nguyen Quang Do; E. Bodden","Computer Science, Universitat Paderborn, 26578 Paderborn, North Rhine-Westphalia Germany (e-mail: lisa.nqd@gmail.com); Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, NRW Germany 33102 (e-mail: eric.bodden@uni-paderborn.de)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","As static data-flow analysis becomes able to report increasingly complex bugs, using an evergrowing set of complex internal rules encoded into flow functions, the analysis tools themselves grow more and more complex. In result, for users to be able to effectively use those tools on specific codebases, they require special configurations—a task which in industry is typically performed by individual developers or dedicated teams. To efficiently use and configure static analysis tools, developers need to build a certain understanding of the analysis' rules, i.e., how the underlying analyses interpret the analyzed code and their reasoning for reporting certain warnings. In this article, we explore how to assist developers in understanding the analysis' warnings, and finding weaknesses in the analysis' rules. To this end, we introduce the concept of rule graphs that expose to the developer selected information about the internal rules of data-flow analyses. We have implemented rule graphs on top of a taint analysis, and show how the graphs can support the abovementioned tasks. Our user study and empirical evaluation show that using rule graphs helps developers understand analysis warnings more accurately than using simple warning traces, and that rule graphs can help developers identify causes for false positives in analysis rules.","1939-3520","","10.1109/TSE.2020.2999534","NRW Research Training Group on Human Centered Systems Security; Heinz Nixdorf Foundation; Bundesministerium fr Bildung und Forschung; Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106860","Program analysis;Data-flow analysis;Rule graphs;Analysis configuration;Explainability;Usability","Static analysis;Tools;SQL injection;Task analysis;Computer bugs;Cognition;Usability","","","","","","","","2 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Improving State-of-the-art Compression Techniques for Log Management Tools","K. Yao; M. Sayagh; W. Shang; A. E. Hassan","School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: kundi@cs.queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: msayagh@cs.queensu.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec, Canada, (e-mail: shang@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Log data records important runtime information about the running of a software system for different purposes including performance assurance, capacity planning, and anomaly detection. Log management tools such as ELK Stack and Splunk are widely adopted to manage and leverage log data in order to assist DevOps in real-time log analytics and decision making. To enable fast queries and to save storage space, such tools split log data into small blocks (e.g., 16KB), then index and compress each block separately. Previous log compression studies focus on improving the compression of either large-sized log files or log streams, without considering improving the compression of small log blocks (the actual compression need by modern log management tools). The evaluation of four state-of-the-art compression approaches (e.g., Logzip, a variation of Logzip by pre-extracting log templates named Logzip-E, LogArchive and Cowic) indicates that these approaches do not perform well on small log blocks. In fact, the compressed blocks that are preprocessed using Logzip, Logzip-E, LogArchive or Cowic are even larger (on median 1.3 times, 1.5 times, 0.2 times or 6.6 times) than the compressed blocks without any preprocessing. Hence, we propose an approach named LogBlock to preprocess small log blocks before compressing them with a general compressor such as gzip, deflate and lz4, which are widely adopted by log management tools. Logblock reduces the repetitiveness of logs by preprocessing the log headers and rearranging the log content leading to an improved compression ratio for a log file. Our evaluation on 16 log files shows that, for 16KB to 128KB block sizes, the compressed blocks by LogBlock are on median 5% to 21% smaller than the same compressed blocks without preprocessing (outperforming the state-of-the-art compression approaches). LogBlock achieves both a higher compression ratio (a median of 1.7 to 8.4 times, 1.9 to 10.0 times, 1.3 to 1.9 times and 6.2 to 11.4 times) and a faster compression speed (a median of 30.8 to 49.7 times, 42.6 to 53.8 times, 4.5 to 6.0 times and 2.5 to 4.0 times) than Logzip, Logzip-E, LogArchive and Cowic. LogBlock can help improve the storage efficiency of log management tools.","1939-3520","","10.1109/TSE.2021.3069958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392377","Software log compression;Software logging;Log management tools F","Tools;Indexes;IP networks;Software systems;Runtime;Monitoring;Message systems","","","","","","","IEEE","31 Mar 2021","","","IEEE","IEEE Early Access Articles"
"How do Practitioners Perceive the Relevance of Requirements Engineering Research?","X. Franch; D. Mendez; A. Vogelsang; R. Heldal; E. Knauss; M. Oriol; G. Travassos; J. C. Carver; T. Zimmermann","Departament de Enginyeria de Serveis i Sistemes de Informaci? (ESSI), Universitat Polit?cnica de Catalunya, 16767 Barcelona, Catalunya, Spain, (e-mail: franch@essi.upc.edu); Software Engineering Research Lab, Blekinge Institute of Technology, 4206 Karlskrona, Blekinge, Sweden, (e-mail: daniel.mendez@bth.se); Daimler Center for Automotive IT Innovations, Technische Universitat Berlin, 26524 Berlin, Berlin, Germany, (e-mail: vogelsang@cs.uni-koeln.de); Department of Computer science, Electrical engineering and Mathematical sciences, Western Norway University of Applied Sciences, 1657 Bergen, Hordaland, Norway, (e-mail: rohe@hvl.no); Computer Science and Engineering, Chalmers tekniska hogskola Campus Lindholmen, 101171 Goteborg, Sweden, Sweden, (e-mail: eric.knauss@cse.gu.se); ESSI, Universitat Polit?cnica de Catalunya, 16767 Barcelona, Catalunya, Spain, (e-mail: moriol@essi.upc.edu); Instituto Alberto Luiz Coimbra de P?s-Gradua??o e Pesquisa de Engenharia, Federal University of Rio de Janeiro, 28125 Rio de Janeiro, RJ, Brazil, (e-mail: bht@cos.ufjr.br); Computer Science, University of Alabama, Tuscaloosa, Alabama, United States, 35487 (e-mail: carver@cs.ua.edu); Research, Microsoft Corporation, Redmond, Washington, United States, 98052 (e-mail: tzimmer@microsoft.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Context: The relevance of Requirements Engineering (RE) research to practitioners is vital for a long-term dissemination of research results to everyday practice. Some authors have speculated about a mismatch between research and practice in the RE discipline. However, there is not much evidence to support or refute this perception. Objective: This paper presents the results of a study aimed at gathering evidence from practitioners about their perception of the relevance of RE research and at understanding the factors that influence that perception. Method: We conducted a questionnaire-based survey of industry practitioners with expertise in RE. The participants rated the perceived relevance of 435 scientific papers presented at five top RE-related conferences. Results: The 153 participants provided a total of 2,164 ratings. The practitioners rated RE research as essential or worthwhile in a majority of cases. However, the percentage of non-positive ratings is still higher than we would like. Among the factors that affect the perception of relevance are the paper?s links to industry, the research method used, and respondents? roles. The reasons for positive perceptions were primarily related to the relevance of the problem and the soundness of the solution, while the causes for negative perceptions were more varied. The respondents also provided suggestions for future research, including topics researchers have studied for decades, like elicitation or requirement quality criteria. Conclusions: The study is valuable for both researchers and practitioners. Researchers can use the reasons respondents gave for positive and negative perceptions and the suggested research topics to help make their research more appealing to practitioners and thus more prone to industry adoption. Practitioners can benefit from the overall view of contemporary RE research by learning about research topics that they may not be familiar with, and compare their perception with those of their colleagues to self-assess their positioning towards more academic research.","1939-3520","","10.1109/TSE.2020.3042747","Ministerio de Ciencia e Innovación; Conselho Nacional de Desenvolvimento Científico e Tecnológico; KKS Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282205","Requirements Engineering;Survey;Impact of Research;Practitioners' Perception","Industries;Protocols;Requirements engineering;Buildings;Tools;Testing;Task analysis","","","","","","","IEEE","4 Dec 2020","","","IEEE","IEEE Early Access Articles"
"ModGuard: Identifying Integrity &Confidentiality Violations in Java Modules","A. Dann; B. Hermann; E. Bodden","Heinz Nixdorf Institut, Universitat Paderborn, 26578 Paderborn, NRW Germany (e-mail: andreas.dann@uni-paderborn.de); Heinz Nixdorf Institut, Universitat Paderborn, 26578 Paderborn, NRW Germany (e-mail: ben.hermann@uni-paderborn.de); Software Engineering, Universitat Paderborn Fakultat fur Elektrotechnik Informatik und Mathematik, 232601 Paderborn, NRW Germany 33102 (e-mail: eric.bodden@uni-paderborn.de)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","With version 9, Java has been given the new module system Jigsaw. Major goals were to simplify maintainability of the JDK and improve its security by encapsulating modules' internal types. While the module system successfully limits the visibility of internal types, it does not prevent sensitive data from escaping. Since the module system reasons about types only, objects are allowed to escape even if that module declares the type as internal. Finding such unintended escapes is important, as they may violate a module's integrity and confidentiality, but is a complex task as it requires one to reason about pointers and type hierarchy. We thus present ModGuard, a novel static analysis based on Doop which complements the Java module system with an analysis to automatically identify instances that escape their declaring module. Along with ModGuard we contribute a complete formal definition of a module's entrypoints, i.e., the method implementations that a module actually allows other modules to directly invoke. We further make available a novel micro-benchmark suite Mic9Bench to show the effectiveness but also current shortcomings of ModGuard, and to enable comparative studies in the future. Finally, we describe a case study that we conducted using Apache Tomcat, which shows that a migration of applications towards Jigsaw modules does not prevent sensitive instances from escaping, yet also shows that ModGuard is an effective aid in identifying integrity and confidentiality violations of sensitive instances.","1939-3520","","10.1109/TSE.2019.2931331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778721","Java 9;Jigsaw;Module Systems;Security;Static Escape Analysis;Doop;Soot","Java;Security;Cognition;Static analysis;Encapsulation;Manuals;Benchmark testing","","","","","","","","29 Jul 2019","","","IEEE","IEEE Early Access Articles"
"RefactoringMiner 2.0","N. Tsantalis; A. Ketkar; D. Dig","Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada H3G 1M8 (e-mail: nikolaos.tsantalis@concordia.ca); Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: ketkara@oregonstate.edu); Computer Science, University of Colorado Boulder, 1877 Boulder, Colorado United States (e-mail: digd@eecs.oregonstate.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Refactoring detection is crucial for a variety of applications and tasks: (i) empirical studies about code evolution, (ii) tools for library API migration, (iii) code reviews and change comprehension. However, recent research has questioned the accuracy of the state-of-the-art refactoring mining tools, which poses threats to the reliability of the detected refactorings. Moreover, the majority of refactoring mining tools depend on code similarity thresholds. Finding universal threshold values that can work well for all projects, regardless of their architectural style, application domain, and development practices is extremely challenging. Therefore, in a previous work [1], we introduced the first refactoring mining tool that does not require any code similarity thresholds to operate. In this work, we extend our tool to support low-level refactorings that take place within the body of methods. To evaluate our tool, we created one of the most accurate, complete, and representative refactoring oracles to date, including 7,223 true instances for 40 different refactoring types detected by one (minimum) up to six (maximum) different tools, and validated by one up to four refactoring experts. Our evaluation showed that our approach achieves the highest average precision (99.6%) and recall (94%) among all competitive tools, and on median is 2.6 times faster than the second faster competitive tool.","1939-3520","","10.1109/TSE.2020.3007722","Division of Computing and Communication Foundations; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136878","Refactoring Mining;Refactoring Oracle;Precision;Recall;Execution time;Git;Commit","Tools;Open source software;Software systems;Task analysis;Libraries;Syntactics;Maintenance engineering","","","","4","","","","8 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Efficient execution of ATL model transformations using static analysis and parallelism","J. Sanchez Cuadrado; L. Burgueno; M. Wimmer; A. Vallecillo","Informtica y Sistemas, University of Murcia, Murcia, Murcia Spain 30100 (e-mail: jesusc@um.es); Lenguajes y Ciencias de la Computacin, Universidad de Mlaga, Mlaga, Mlaga Spain 29071 (e-mail: lburguenoc@uoc.edu); Software Engineering, Johannes Kepler Universitat Linz, 27266 Linz, n/a Austria (e-mail: manuel.wimmer@jku.at); Lenguajes y Ciencias de la Computacin, Universidad de Malaga, 16752 Spain, Malaga Spain 29071 (e-mail: av@lcc.uma.es)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Although model transformations are considered to be the heart and soul of Model Driven Engineering (MDE), there are still several challenges that need to be addressed to unleash their full potential in industrial settings. Among other shortcomings, their performance and scalability remain unsatisfactory for dealing with large models, making their wide adoption difficult in practice. This paper presents A2L, a compiler for the parallel execution of ATL model transformations, which produces efficient code that can use existing multicore computer architectures, and applies effective optimizations at the transformation level using static analysis. We have evaluated its performance in both sequential and multi-threaded modes obtaining significant speedups with respect to current ATL implementations. In particular, we obtain speedups between 2.32x and 38.28x for the A2L sequential version, and between 2.40x and 245.83x when A2L is executed in parallel, with expected average speedups of 8.59x and 22.42x, respectively.","1939-3520","","10.1109/TSE.2020.3011388","Ministerio de Ciencia e Innovacin; Austrian Federal Ministry for Digital and Economic Affairs National Foundation for Research Technology and Development FWF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9146715","Model transformation;MDE;ATL;Performance;Scalability;Parallelization","Unified modeling language;Analytical models;Engines;Java;Scalability;Static analysis;Biological system modeling","","","","","","","","23 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Change-Patterns Mapping: A Boosting Way for Change Impact Analysis","Y. Huang; J. Jiang; X. Luo; X. Chen; Z. Zheng; N. Jia; G. Huang","School of Software Engineering, Sun Yat-sen University, Guangzhou, GuangDong, China, (e-mail: huangyjn@gmail.com); School of Data and Computer Science, School of Data and Computer Science, Sun Yat-sen University, Guangzhou 510006, China., Guangzhou, Guangdong, China, (e-mail: exinpie@163.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); the School of Communication and Design, Sun Yat-sen University, Guangzhou, Guangdong, China, 510000 (e-mail: chenxp8@mail.sysu.edu.cn); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong, China, (e-mail: zibinzheng@yeah.net); School of Management Science and Engineering, Hebei GEO University, 12410 Shijiazhuang, Hebei, China, (e-mail: jianan_0101@163.com); Computer Science, School of EECS, Beijing, Beijing, China, 100871 (e-mail: hg@pku.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Change impact analysis (CIA) is a specialized process of program comprehension that investigates the ripple effects of a code change in a software system. In this paper, we present a boosting way for change impact analysis via mapping the historical change-patterns to current CIA task in a cross-project scenario. The change-patterns reflect the coupling dependencies between changed entities in a change set. A traditional CIA tool (such as ImpactMiner) outputs an initial impact set for a starting entity. To boost the traditional CIA tool, our approach retrieves an equivalent entity from various historical change sets for the starting entity. Then, the change-patterns between the equivalent entity and the rest of entities in the change set are mapped to the CIA task at hand. For current CIA task, if an entity in the initial impact set involves the similar change-pattern with the starting entity when comparing with the mapped change-pattern, we will reward the impacted confidence of the entity. Accuracy improvements are observed in the experiments when applying our boosting method to three famous CIA tools, i.e., ImpactMiner, JRipples and ROSE.","1939-3520","","10.1109/TSE.2021.3059481","China Postdoctoral Science Foundation; Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; Guangdong Basic and Applied Basic Research Foundation; Key-Area Research and Development Program of Guangdong Province; Hong Kong RGC Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354949","Change Impact Analysis;Change-Patterns;Coupling Dependency;Boosting Method","Software;Task analysis;Tools;Couplings;Boosting;Software systems;Licenses","","","","","","","CCBYNCND","16 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Enhancement of Mutation Testing via Fuzzy Clustering and Multi-population Genetic Algorithm","X. Dang; D. Gong; X. Yao; T. Tian; H. Liu","School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu, China, (e-mail: dangpaper@163.com); School of Information and Electrical Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu, China, (e-mail: dwgong@vip.163.com); School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu, China, (e-mail: yaoxj@cumt.edu.cn); School of Computer Science and Technology, Shandong Jianzhu University, 105835 Jinan, Shandong, China, (e-mail: tian_tiantian@126.com); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria, Australia, (e-mail: hliu@swin.edu.au)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Mutation testing, a fundamental software testing technique, which is a typical way to evaluate the adequacy of test data. In mutation testing, a set of mutants are generated by seeding the different classes of faults into a program under test. Test data shall be generated in the way that as many mutants can be killed as possible. Thanks to numerous tools to implement mutation testing for different languages, a huge amount of mutants are normally generated even for small-sized programs. However, a large number of mutants not only leads to a high cost of mutation testing, but also make the corresponding test data generation a non-trivial task. In this paper, we make use of intelligent technologies to improve the effectiveness and efficiency of mutation testing from two perspectives. A machine learning technique, namely fuzzy clustering, is applied to categorize mutants into different clusters. Then, a multi-population genetic algorithm via individual sharing is employed to generate test data for killing the mutants in different clusters in parallel when the problem of test data generation as an optimization one. A comprehensive framework, termed as FUZGENMUT, is thus developed to implement the proposed techniques. The experiments based on nine programs of various sizes show that fuzzy clustering can help to reduce the cost of mutation testing effectively, and that the multi-population genetic algorithm improves the efficiency of test data generation while delivering the high mutant-killing capability. The results clearly indicate the huge potential of using intelligent technologies to enhance the efficacy and thus the practicality of mutation testing.","1939-3520","","10.1109/TSE.2021.3052987","National Natural Science Foundation of China; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9328619","mutation testing;fuzzy clustering;mutation clustering;test data generation;multi-population genetic algorithm (MGA)","Testing;Genetic algorithms;Sorting;Clustering algorithms;Syntactics;Statistics;Sociology","","","","","","","IEEE","19 Jan 2021","","","IEEE","IEEE Early Access Articles"
"DPWord2Vec: Better Representation of Design Patterns in Semantics","D. Liu; H. Jiang; X. Li; Z. Ren; L. Qiao; Z. Ding","School of Software, Dalian University of Technology, 12399 Dalian, Liaoning China (e-mail: dongliu@mail.dlut.edu.cn); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: jianghe@dlut.edu.cn); School of Software, Dalian university of technology Dalian, Dalian, Liaoning China 116621 (e-mail: li1989@mail.dlut.edu.cn); School of Software, Dalian university of technology, Dalian, Liaoning China (e-mail: zren@dlut.edu.cn); On-board Computer Center, Beijing Institute of Control Engineering, 154569 Beijing, Beijing China (e-mail: qosman@163.com); Center of Math Computing and Software Engineering, Zhejiang Sci-Tech University, Hangzhou, Zhejiang China (e-mail: zouhuading@hotmail.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","With the plain text descriptions of design patterns, developers could better learn and understand the definitions and usage scenarios of design patterns. To facilitate the automatic usage of these descriptions, e.g., recommending design patterns by free-text queries, design patterns and natural languages should be adequately associated. Existing studies usually use texts in design pattern books as the representations of design patterns to calculate similarities with the queries. However, this way is problematic. Lots of information of design patterns may be absent from design pattern books and many words would be out of vocabulary due to the content limitation of these books. To overcome these issues, a more comprehensive method should be constructed to estimate the relatedness between design patterns and natural language words. Motivated by Word2Vec, in this study, we propose DPWord2Vec that embeds design patterns and natural language words into vectors simultaneously. We first build a corpus containing more than 400 thousand documents extracted from design pattern books, Wikipedia, and Stack Overflow. Next, we redefine the concept of context window to associate design patterns with words. Then, the design pattern and word vector representations are learnt by leveraging an advanced word embedding method. The learnt design pattern and word vectors can be universally used in textual description based design pattern tasks. An evaluation shows that DPWord2Vec outperforms the baseline algorithms by 17.1%-96.5% in measuring the similarities between design patterns and words in terms of Spearman's rank correlation coefficient. Moreover, we adopt DPWord2Vec on two typical design pattern tasks. In the design pattern tag recommendation task, the DPWord2Vec based method outperforms two state-of-the-art algorithms by 6.6% and 32.7% respectively when considering Recall@10. In the design pattern selection task, DPWord2Vec improves the existing methods by 6.5%-70.7% in terms of MRR.","1939-3520","","10.1109/TSE.2020.3017336","National Natural Science Foundation of China; National Key Research and Development Plan of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9170909","Design Pattern;Word Embedding;Word2Vec;Semantic Similarity;Tag Recommendation;Design Pattern Selection","Natural languages;Task analysis;Semantics;Windows;Vocabulary;Software design","","","","","","","","18 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Theoretical and Empirical Analyses of the Effectiveness of Metamorphic Relation Composition","K. Qiu; Z. Zheng; T. Chen; P. Poon","School of Automation Science and Electrical Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: qiukun@buaa.edu.cn); School of Automation Science and Electrical Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: zhengz@buaa.edu.cn); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Melbourne, Victoria Australia (e-mail: tychen@swin.edu.au); School of Engineering and Technology, Central Queensland University, 6939 Melbourne, Victoria Australia (e-mail: p.poon@cqu.edu.au)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Metamorphic Relations (MRs) play a key role in determining the fault detection capability of Metamorphic Testing (MT). As human judgement is required for MR identification, systematic MR generation has long been an important research area in MT. Additionally, due to the extra program executions required for follow-up test cases, some concerns have been raised about MT cost-effectiveness. Consequently, the reduction in testing costs associated with MT has become another important issue to be addressed. MR composition can address both of these problems. This technique can automatically generate new MRs by composing existing ones, thereby reducing the number of follow-up test cases. Despite this advantage, previous studies on MR composition have empirically shown that some composite MRs have lower fault detection capability than their corresponding component MRs. To investigate this issue, we performed theoretical and empirical analyses to identify what characteristics component MRs should possess so that their corresponding composite MR has at least the same fault detection capability as the component MRs do. We have also derived a convenient, but effective guideline so that the fault detection capability of MT will most likely not be reduced after composition.","1939-3520","","10.1109/TSE.2020.3009698","Technical Foundation Project of Ministry of Industry and Information Technology of China; National Natural Science Foundation of China; Equipment Preliminary R and D Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144441","Metamorphic testing;metamorphic relation;metamorphic relation composition;test oracle;fault detection","Testing;Fault detection;Software;Guidelines;Systematics;Australia;Companies","","","","1","","","","20 Jul 2020","","","IEEE","IEEE Early Access Articles"
"What Flows through a Software Value Stream?","M. Kersten",Tasktop,"IEEE Software","6 Jul 2018","2018","35","4","8","11","Most enterprise IT organizations don't have a well-defined productivity measure for what flows through their software production process. No clear consensus exists from academia or industry thought leaders on what constitutes software development productivity. Organizations know it when they see it-for example, through products that drive market adoption faster than others. But correlating development activities to those results has been more of an opaque art than a disciplined activity. To define productivity in a value stream, we must first define what flows.","1937-4194","","10.1109/MS.2018.2801538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405621","software delivery value stream;software delivery;software value stream;lean software development;agile software development;DevOps;flow units;features;defects;technical debt;risk;Scaled Agile Framework;SAFe;Information Technology Infrastructure Library;ITIL;software development tools;software development;software engineering;On DevOps","Software product lines;Computer security;Production management;Production systems;Task analysis;Performance evaluation","organisational aspects;productivity;software engineering","software value stream;software production process;software development productivity;enterprise IT organizations;productivity measure","","1","","10","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Recent Progress in Software Security","E. Amoroso",TAG Cyber,"IEEE Software","12 Mar 2018","2018","35","2","11","13","To reduce cybersecurity risk in software, the security community has widely adopted an approach involving a collage of techniques, tools, and methods, each addressing some aspect of the threat implications of bad code. This article briefly surveys recent progress in each element of this combined approach, including the pros and cons for reducing cybersecurity risk.","1937-4194","","10.1109/MS.2018.1661316","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314164","software security;malware;malware detection;software process maturity;software review;software scanning;DevOps;runtime application self-protection;RASP;software development;software engineering;Invited Content","Computer security;Malware;Software reliability;Runtime;Computer bugs","security of data;software engineering","software security;cybersecurity risk;security community;threat implications;bad code","","2","","1","","12 Mar 2018","","","IEEE","IEEE Magazines"
"A Theoretical and Empirical Study of Diversity-Aware Mutation Adequacy Criterion","D. Shin; S. Yoo; D. Bae","KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea; KAIST, Daejeon, Republic of Korea","IEEE Transactions on Software Engineering","14 Oct 2018","2018","44","10","914","931","Diversity has been widely studied in software testing as a guidance towards effective sampling of test inputs in the vast space of possible program behaviors. However, diversity has received relatively little attention in mutation testing. The traditional mutation adequacy criterion is a one-dimensional measure of the total number of killed mutants. We propose a novel, diversity-aware mutation adequacy criterion called distinguishing mutation adequacy criterion, which is fully satisfied when each of the considered mutants can be identified by the set of tests that kill it, thereby encouraging inclusion of more diverse range of tests. This paper presents the formal definition of the distinguishing mutation adequacy and its score. Subsequently, an empirical study investigates the relationship among distinguishing mutation score, fault detection capability, and test suite size. The results show that the distinguishing mutation adequacy criterion detects 1.33 times more unseen faults than the traditional mutation adequacy criterion, at the cost of a 1.56 times increase in test suite size, for adequate test suites that fully satisfies the criteria. The results show a better picture for inadequate test suites; on average, 8.63 times more unseen faults are detected at the cost of a 3.14 times increase in test suite size.","1939-3520","","10.1109/TSE.2017.2732347","Information & communications Technology Promotion (IITP); Korea government (MSIP); Software R&D for Model-based Analysis and Verification of Higher-order Large Complex System; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7994647","Mutation testing;test adequacy criteria;diversity","Fault detection;Software engineering;Software testing;Correlation;Indexes;Subspace constraints","fault diagnosis;program testing;software engineering","empirical study;diversity-aware mutation adequacy criterion;software testing;test inputs;mutation testing;distinguishing mutation score;distinguishing mutation adequacy criterion;adequate test suites;inadequate test suites;theoretical study;program behaviors;killed mutants;fault detection capability","","3","","58","","27 Jul 2017","","","IEEE","IEEE Journals"
"Expanding Queries for Code Search Using Semantically Related API Class-names","F. Zhang; H. Niu; I. Keivanloo; Y. Zou","Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","11 Nov 2018","2018","44","11","1070","1082","When encountering unfamiliar programming tasks (e.g., connecting to a database), there is a need to seek potential working code examples. Instead of using code search engines, software developers usually post related programming questions on online Q&A forums (e.g., Stack Overflow). One possible reason is that existing code search engines would return effective code examples only if a query contains identifiers (e.g., class or method names). In other words, existing code search engines do not handle natural-language queries well (e.g., a description of a programming task). However, developers may not know the appropriate identifiers at the time of the search. As the demand of searching code examples is increasing, it is of significant interest to enhance code search engines. We conjecture that expanding natural-language queries with their semantically related identifiers has a great potential to enhance code search engines. In this paper, we propose an automated approach to find identifiers (in particular API class-names) that are semantically related to a given natural-language query. We evaluate the effectiveness of our approach using 74 queries on a corpus of 23,677,216 code snippets that are extracted from 24,666 open source Java projects. The results show that our approach can effectively recommend semantically related API class-names to expand the original natural-language queries. For instance, our approach successfully retrieves relevant code examples in the top 10 retrieved results for 76 percent of 74 queries, while it is 36 percent when using the original natural-language query; and the median rank of the first relevant code example is increased from 22 to 7.","1939-3520","","10.1109/TSE.2017.2750682","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8031055","Query expansion;code search;neural network language model;API class-name","Search engines;Programming;Java;Software engineering;IEEE transactions;Software;Joining processes","application program interfaces;Internet;natural language processing;query processing;search engines;software engineering","semantically related API class-names;natural-language query;code search engines;online Q&A forums;software developers","","5","","46","","11 Sep 2017","","","IEEE","IEEE Journals"
"Automatically Exploring Tradeoffs Between Software Output Fidelity and Energy Costs","J. Dorn; J. Lacomis; W. Weimer; S. Forrest","Department of Computer Science, University of Virginia, Charlottesville, VA; Department of Computer Science, University of Virginia, Charlottesville, VA; Department of Computer Science, University of Virginia, Charlottesville, VA; Arizona State University, Tempe, AZ","IEEE Transactions on Software Engineering","13 Mar 2019","2019","45","3","219","236","Data centers account for a significant fraction of global energy consumption and represent a growing business cost. Most current approaches to reducing energy use in data centers treat it as a hardware, compiler, or scheduling problem. This article focuses instead on the software level, showing how to reduce the energy used by programs when they execute. By combining insights from search-based software engineering, mutational robustness, profile-guided optimization, and approximate computing, the Producing Green Applications Using Genetic Exploration (PowerGAUGE) algorithm finds variants of individual programs that use less energy than the original. We apply hardware, software, and statistical techniques to manage the complexity of accurately assigning physical energy measurements to particular processes. In addition, our approach allows, but does not require, relaxing output quality requirements to achieve greater non-functional improvements. PowerGAUGE optimizations are validated using physical performance measurements. Experimental results on PARSEC benchmarks and two larger programs show average energy reductions of 14% when requiring the preservation of original output quality and 41% when allowing for human-acceptable levels of error.","1939-3520","","10.1109/TSE.2017.2775634","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8118155","Power optimization;search-based software engineering;genetic algorithms;profile-guided optimization;optimizing noisy functions;accurate energy measurement","Energy consumption;Optimization;Hardware;Genetic algorithms;Software;Energy measurement","computer centres;energy conservation;energy consumption;genetic algorithms;optimisation;program compilers;scheduling;software quality;statistical analysis","tradeoffs;software output fidelity;data centers;global energy consumption;compiler;scheduling problem;software level;search-based software engineering;profile-guided optimization;approximate computing;statistical techniques;physical energy measurements;PowerGAUGE optimizations;physical performance measurements;business cost;energy reductions;genetic exploration;producing green applications;energy costs;PARSEC benchmarks","","1","","63","","22 Nov 2017","","","IEEE","IEEE Journals"
"Reading Answers on Stack Overflow: Not Enough!","H. Zhang; S. Wang; T. Chen; A. E. Hassan","School of Computing, Queen's University, Kingston, Ontario Canada K7M1B5 (e-mail: hzhang@cs.queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: wang@cse.msstate.edu); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec Canada H3G 2W1 (e-mail: peterc@encs.concordia.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Stack Overflow is one of the most active communities for developers to share their programming knowledge. Answers posted on Stack Overflow help developers solve issues during software development. In addition to posting answers, users can also post comments to further discuss their associated answers. As of Aug 2017, there are 32.3 million comments that are associated with answers, forming a large collection of crowdsourced repository of knowledge on top of the commonly-studied Stack Overflow answers. In this study, we wish to understand how the commenting activities contribute to the crowdsourced knowledge. We investigate what users discuss in comments, and analyze the characteristics of the commenting dynamics, (i.e., the timing of commenting activities and the roles of commenters). We find that: 1) the majority of comments are informative and thus can enhance their associated answers from a diverse range of perspectives. However, some comments contain content that is discouraged by Stack Overflow. 2) The majority of commenting activities occur after the acceptance of an answer. More than half of the comments are fast responses occurring within one day of the creation of an answer, while later comments tend to be more informative. Most comments are rarely integrated back into their associated answers, even though such comments are informative. 3) Insiders (i.e., users who posted questions/answers before posting a comment in a question thread) post the majority of comments within one month, and outsiders (i.e., users who never posted any question/answer before posting a comment) post the majority of comments after one month. Inexperienced users tend to raise limitations and concerns while experienced users tend to enhance the answer through commenting. Our study provides insights into the commenting activities in terms of their content, timing, and the individuals who perform the commenting. For the purpose of long-term knowledge maintenance and effective information retrieval for developers, we also provide actionable suggestions to encourage Stack Overflow users/engineers/moderators to leverage our insights for enhancing the current Stack Overflow commenting system for improving the maintenance and organization of the crowdsourced knowledge.","1939-3520","","10.1109/TSE.2019.2954319","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8906075","Crowdsourced Knowledge Sharing and Management;Stack Overflow;Commenting;Empirical Software Engineering","Programming;Software;Guidelines;Maintenance engineering;Knowledge discovery;Timing","","","","1","","","","19 Nov 2019","","","IEEE","IEEE Early Access Articles"
"What do package dependencies tell us about semantic versioning?","A. Decan; T. Mens","Software Engineering Lab, University of Mons, Mons, Hainaut Belgium (e-mail: alexandre.decan@umons.ac.be); Institut d'Informatique, Université de Mons, Mons, Hainaut Belgium 7000 (e-mail: tom.mens@umons.ac.be)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The semantic versioning (semver) policy is commonly accepted by open source package management systems to inform whether new releases of software packages introduce possibly backward incompatible changes. Maintainers depending on such packages can use this information to avoid or reduce the risk of breaking changes in their own packages by specifying version constraints on their dependencies. Depending on the amount of control a package maintainer desires to have over her package dependencies, these constraints can range from very permissive to very restrictive. This article empirically compares semver compliance of four software packaging ecosystems (Cargo, npm, Packagist and Rubygems), and studies how this compliance evolves over time. We explore to what extent ecosystem-specific characteristics or policies influence the degree of compliance. We also propose an evaluation based on the ""wisdom of the crowds"" principle to help package maintainers decide which type of version constraints they should impose on their dependencies.","1939-3520","","10.1109/TSE.2019.2918315","FWO-Vlaanderen and F.R.S.-FNRS; FRQ-FNRS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721084","D.2 Software Engineering;D.2.7 Distribution, Maintenance, and Enhancement;D.2.7.g Maintainability;D.2.7.n Version control;D.2.8 Metrics/Measurement;D.2.13 Reusable Software;D.2.13.b Reusable libraries;D.2.16 Configuration Management;D.2.16.f Software release management and delivery","Ecosystems;Software;Semantics;Packaging;Libraries;Java;Computer bugs","","","","5","","","","23 May 2019","","","IEEE","IEEE Early Access Articles"
"From Voice of Evidence to Redirections","R. Prikladnicki; T. Menzies",Pontifícia Universidade Católica do Rio Grande do Sul; North Carolina State University,"IEEE Software","25 Dec 2017","2018","35","1","11","13","The Voice of Experience department is being relaunched as Redirections, which will focus on the surprises in software engineering.","1937-4194","","10.1109/MS.2017.4541053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239930","Voice of Evidence;Redirections;software engineering;software development","Software engineering;Software development","","","","1","","6","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Tammy Bütow on Chaos Engineering","E. Salinas",Microsoft,"IEEE Software","27 Sep 2018","2018","35","5","125","128","Software Engineering Radio host Edaena Salinas talks with Tammy Bütow of Gremlin on chaos engineering. The excerpt here covers Tammy’s background in failure testing, the nature of failure injection, what we can learn from chaos experiments, how to work through failure scenarios to harden your infrastructure, and their value in training operations staff. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2018.3571246","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474498","chaos engineering;Tammy Bütow;software engineering;software development","Chaos;Reliability engineering;Servers;Software engineering;Software development","","","","","","0","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Natural Language Processing for Requirements Engineering: The Best Is Yet to Come","F. Dalpiaz; A. Ferrari; X. Franch; C. Palomares",Utrecht University; CNR-ISTI; Universitat Politècnica de Catalunya; Universitat Politècnica de Catalunya,"IEEE Software","27 Sep 2018","2018","35","5","115","119","As part of the growing interest in natural language processing for requirements engineering (RE), RE researchers, computational linguists, and industry practitioners met at the First Workshop on Natural Language Processing for Requirements Engineering (NLP4RE 18). This article summarizes the workshop and presents an overview of the discussion held on the field’s future. This article is part of a theme issue on software engineering’s 50th anniversary.","1937-4194","","10.1109/MS.2018.3571242","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474507","natural language processing;NLP;requirements engineering;NLP4RE;software requirements;software engineering;software development","Software development;Task analysis;Natural language processing;Software engineering;Requirements engineering","","","","8","","5","","27 Sep 2018","","","IEEE","IEEE Magazines"
"How Software Developers Mitigate their Errors when Developing Code","B. Nagaria; T. Hall","Department of Computer Science, Brunel University London, 3890 London, Uxbridge, United Kingdom of Great Britain and Northern Ireland, UB8 3PH (e-mail: bhaveet.nagaria@brunel.ac.uk); School of Computing and Communication, Lancaster University, 4396 Bailrigg, Lancaster, United Kingdom of Great Britain and Northern Ireland, (e-mail: tracy.hall@lancaster.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Code remains largely hand-made by humans and, as such, writing code is prone to error. Many previous studies have focused on the technical reasons for these errors and provided developers with increasingly sophisticated tools. Few studies have looked in detail at why code errors have been made from a human perspective. We use Human Error Theory to frame our exploratory study and use semi-structured interviews to uncover a preliminary understanding of the errors developers make while coding. We look particularly at the Skill-Based (SB) errors reported by 27 professional software developers. We found that the complexity of the development environment is one of the most frequently reported reasons for errors. Maintaining concentration and focus on a particular task also underpins many developer errors. We found that developers struggle with effective mitigation strategies for their errors, reporting strategies largely based on improving their own willpower to concentrate better on coding tasks. We discuss how using Reason's Swiss Cheese model may help reduce errors during software development. This model ensures that layers of tool, process and management mitigation are in place to prevent developer errors from causing system failures.","1939-3520","","10.1109/TSE.2020.3040554","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9271926","Human error;human factors;software development","Software;Task analysis;Encoding;Psychology;Interviews;Software engineering;Footwear","","","","","","","IEEE","25 Nov 2020","","","IEEE","IEEE Early Access Articles"
"The impact of feature importance methods on the interpretation of defect classifiers","G. K. Rajbahadur; S. Wang; G. Ansaldi; Y. Kamei; A. E. Hassan","School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, K7L 2N8 (e-mail: krishnan@cs.queensu.ca); Computer Science, University of Manitoba, 8664 Winnipeg, Manitoba, Canada, (e-mail: shaoweiwang.2010@hotmail.com); School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: gustavo@cs.queensu.ca); Graduate School and Faculty of Information Science and Electrical Engineering, Kyushu University, Fukuoka, Fukuoka, Japan, 819-0395 (e-mail: kamei@ait.kyushu-u.ac.jp); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Classifier specific (CS) and classifier agnostic (CA) feature importance methods are widely used (often interchangeably) by prior studies to derive feature importance ranks from a defect classifier. However, different feature importance methods are likely to compute different feature importance ranks even for the same dataset and classifier. Hence such interchangeable use of feature importance methods can lead to conclusion instabilities unless there is a strong agreement among different methods. Therefore, in this paper, we evaluate the agreement between the feature importance ranks associated with the studied classifiers through a case study of 18 software projects and six commonly used classifiers. We find that: 1) The computed feature importance ranks by CA and CS methods do not always strongly agree with each other. 2) The computed feature importance ranks by the studied CA methods exhibit a strong agreement including the features reported at top-1 and top-3 ranks for a given dataset and classifier, while even the commonly used CS methods yield vastly different feature importance ranks. Such findings raise concerns about the stability of conclusions across replicated studies. We further observe that the commonly used defect datasets are rife with feature interactions and these feature interactions impact the computed feature importance ranks of the CS methods (not the CA methods). We demonstrate that removing these feature interactions, even with simple methods like CFS improves agreement between the computed feature importance ranks of CA and CS methods. In light of our findings, we provide guidelines for stakeholders and practitioners when performing model interpretation and directions for future research, e.g., future research is needed to investigate the impact of advanced feature interaction removal methods on computed feature importance ranks of different CS methods.","1939-3520","","10.1109/TSE.2021.3056941","JSPS KAKENHI Japan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347823","Model interpretation;Model Agnostic interpretation;Built-in interpretation;Feature Importance Analysis;Variable Importance 3","Software engineering;Computational modeling;Internet;Software quality;Predictive models;Neural networks;Logistics","","","","","","","IEEE","4 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Predicting Defective Lines Using a Model-Agnostic Technique","S. Wattanakriengkrai; P. Thongtanunam; C. Tantithamthavorn; H. Hata; K. Matsumoto","Information Science, Nara Institute of Science and Technology, 12708 Ikoma, Nara Japan (e-mail: wattanakri.supatsara.ws3@is.naist.jp); School of Computing and Information System, The University of Melbourne, Melbourne, Victoria Australia (e-mail: patanamon.t@unimelb.edu.au); Information Technology, Monash University, 2541 Clayton, Victoria Australia 3800 (e-mail: chakkrit@monash.edu); Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Nara Japan 630-0192 (e-mail: hata@is.naist.jp); Information Systems, Nara Institute of Science and Technology, Information Systems, Ikomashi, Naraken Japan (e-mail: matumoto@is.naist.jp)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Defect prediction models are proposed to help a team prioritize source code areas files that need Software Quality Assurance (SQA) based on the likelihood of having defects. However, developers may waste their unnecessary effort on the whole file while only a small fraction of its source code lines are defective. Indeed, we find that as little as 1%-3% of lines of a file are defective. Hence, in this work, we propose a novel framework (called LINE-DP) to identify defective lines using a model-agnostic technique, i.e., an Explainable AI technique that provides information why the model makes such a prediction. Broadly speaking, our LINE-DP first builds a file-level defect model using code token features. Then, our LINE-DP uses a state-of-the-art model-agnostic technique (i.e., LIME) to identify risky tokens, i.e., code tokens that lead the file-level defect model to predict that the file will be defective. Then, the lines that contain risky tokens are predicted as defective lines. Through a case study of 32 releases of nine Java open source systems, our evaluation results show that our LINE-DP achieves an average recall of 0.61, a false alarm rate of 0.47, a top 20%LOC recall of 0.27, and an initial false alarm of 16, which are statistically better than six baseline approaches. Our evaluation shows that our LINE-DP requires an average computation time of 10 seconds including model construction and defective identification time. In addition, we find that 63% of defective lines that can be identified by our LINE-DP are related to common defects (e.g., argument change, condition change). These results suggest that our LINE-DP can effectively identify defective lines that contain common defects while requiring a smaller amount of inspection effort and a manageable computation cost. The contribution of this paper builds an important step towards line-level defect prediction by leveraging a model-agnostic technique.","1939-3520","","10.1109/TSE.2020.3023177","Australian Research Councils Discovery Early Career Researcher Award DECRA; Japan Society for the Promotion of Science; Monash-FIT Early Career Researcher Seed Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9193975","Software Quality Assurance;Line-level Defect Prediction","Predictive models;Computational modeling;Software quality;Software systems;Pipelines;Software engineering","","","","2","","","CCBY","10 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Software Batch Testing to Save Build Test Resources and to Reduce Feedback Time","M. J. Beheshtian; A. Bavand; P. Rigby","CSE, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: s_ehesht@encs.concordia.ca); CSE, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: amirhossein.bavand@gmail.com); CSE, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: peter.rigby@concordia.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Testing is expensive and batching tests has the potential to reduce test costs. The continuous integration strategy of testing each commit or change individually helps to quickly identify faults but leads to a maximal number of test executions. Large companies that have a massive number of commits, e.g., Google and Facebook, or have expensive test infrastructure, e.g., Ericsson, must batch changes together to reduce the number of total test runs. For example, if eight builds are batched together and there is no failure, then we have tested eight builds with one execution saving seven executions. However, when a failure occurs it is not immediately clear which build is the cause of the failure. A bisection is run to isolate the failing build, i.e. the culprit build. In our eight builds example, a failure will require an additional 6 executions, resulting in a saving of one execution. In this work, we re-evaluate batching approaches developed in industry on large open source projects using Travis CI. We also introduce novel batching approaches. In total, we evaluate six approaches. We find that compared to the TestAll baseline, on average, the approaches reduce the number of build test executions across projects by 46%, 48%, 50%, 44%, and 49% for BatchBisect, Batch4, BatchStop4, RiskTopN, and RiskBatch, respectively. The greatest reduction in executions is BatchStop4 at 50%. However, the simple approach of Batch4 does not require bisection and achieves a reduction of 48%. In a larger sample of projects, we find that a project's failure rate is strongly correlated with execution savings. Using Batch4, 85% of projects see savings. All projects that have build failures less than 40% of the time will benefit from batching. In terms of feedback time, compared to TestAll, we find that BatchBisect, Batch2, Batch4, BatchStop4 all reduce the average feedback time by 33%, 16%, 32%, and 37%. Simple batching saves not only resources but also reduces feedback time without introducing any slip-throughs and without changing the test run order. We release our scripts and data for replication [1] and the GitHub integration of the BatchBuilder tool for developers [2].","1939-3520","","10.1109/TSE.2021.3070269","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392370","Software Testing;Batch Testing;Continuous Integration and Deployment;Bisection;Pool Testing;Reducing Testing Cost;Risk Modelling","Testing;Internet;Software engineering;Tools;Resource management;Software development management;Social networking (online)","","","","","","","IEEE","31 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Version Control Systems: An Information Foraging Perspective","S. Srinivasa Ragavan; M. Codoban; D. Piorkowski; D. Dig; M. Burnett","School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: srinivas@eecs.oregonstate.edu); Tools for Software Engineers, Microsoft, Redmond, Washington United States (e-mail: micodoba@microsoft.com); AI, IBM Research, Yorktown Heights, New York United States (e-mail: david.piorkowski@ibm.com); School of EECS, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: digd@eecs.oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon United States 97331 (e-mail: burnett@eecs.oregonstate.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Version Control Systems (VCS) are an important source of information for developers. This calls for a principled understanding of developers' information seeking in VCS-both for improving existing tools and for understanding requirements for new tools. Our prior work investigated empirically how and why developers seek information in VCS: in this paper, we complement and enrich our prior findings by reanalyzing the data via a theory's lens. Using the lens of Information Foraging Theory (IFT), we present new insights not revealed by the prior empirical work. First, while looking for specific information, participants' foraging behaviors were consistent with other foraging situations in SE; therefore, prior research on IFT-based SE tool design can be leveraged for VCS. Second, in change awareness foraging, participants consumed similar diets, but in subtly different ways than in other situations; this calls for further investigations into change awareness foraging. Third, while committing changes, participants attempted to enable future foragers, but the competing needs of different foraging situations led to tensions that participants failed to balance: this opens up a new avenue for research at the intersection of IFT and SE, namely, creating forageable information. Finally, the results of using an IFT lens on these data provides some evidence as to IFT's scoping and utility for the version control domain.","1939-3520","","10.1109/TSE.2019.2931296","Division of Computing and Communication Foundations; National Science Foundation; Defense Advanced Research Projects Agency; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778723","Human factors in software desgin;Software engineering;Version control","Tools;Control systems;Software;Software engineering;Computer bugs;Animals;Lenses","","","","","","","","29 Jul 2019","","","IEEE","IEEE Early Access Articles"
"Incentivizing Deep Fixes in Software Economies","M. Rao; D. F. Bacon; D. C. Parkes; M. I. Seltzer","John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA; Google; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA; John A. Paulson School of Engineering and Applied Sciences, Harvard University, Cambridge, MA","IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","51","70","An important question in a software economy is how to incentivize deep rather than shallow fixes. A deep fix corrects the root cause of a bug instead of suppressing the symptoms. This paper initiates the study of the problem of incentive design for open workflows in fixing code. We model the dynamics of the software ecosystem and introduce subsumption mechanisms. These mechanisms only make use of externally observable information in determining payments and promote competition between workers. We use a mean field equilibrium methodology to evaluate the performance of these mechanisms, demonstrating in simulation that subsumption mechanisms perform robustly across various environment configurations and satisfy important criteria for market design.","1939-3520","","10.1109/TSE.2018.2842188","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8384304","Market design;mean field equilibrium;software engineering;payment mechanisms","Computer bugs;Task analysis;Ecosystems;Open source software;Testing;Software engineering","game theory;socio-economic effects;software development management","mean field equilibrium methodology;subsumption mechanisms;software economy;open workflows;software ecosystem;externally observable information","","1","","63","IEEE","13 Jun 2018","","","IEEE","IEEE Journals"
"The Effect of Work Environments on Productivity and Satisfaction of Software Engineers","B. Johnson; T. Zimmermann; C. Bird","Massachusetts Amherst, Amherst, MA, USA; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","736","757","The physical work environment of software engineers can have various effects on their satisfaction and the ability to get the work done. To better understand the factors of the environment that affect productivity and satisfaction of software engineers, we explored different work environments at Microsoft. We used a mixed-methods, multiple stage research design with a total of 1,159 participants: two surveys with 297 and 843 responses respectively and interviews with 19 employees. We found several factors that were considered as important for work environments: personalization, social norms and signals, room composition and atmosphere, work-related environment affordances, work area and furniture, and productivity strategies. We built statistical models for satisfaction with the work environment and perceived productivity of software engineers and compared them to models for employees in the Program Management, IT Operations, Marketing, and Business Program & Operations disciplines. In the satisfaction models, the ability to work privately with no interruptions and the ability to communicate with the team and leads were important factors among all disciplines. In the productivity models, the overall satisfaction with the work environment and the ability to work privately with no interruptions were important factors among all disciplines. For software engineers, another important factor for perceived productivity was the ability to communicate with the team and leads. We found that private offices were linked to higher perceived productivity across all disciplines.","1939-3520","","10.1109/TSE.2019.2903053","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658138","Productivity;satisfaction;physical environments;work environments;software engineering;program management;IT operations;marketing;business program & operations","Software;Productivity;Organizations;Software engineering;Interviews;Collaboration;Knowledge engineering","","","","2","","134","IEEE","4 Mar 2019","","","IEEE","IEEE Journals"
"Love, Joy, Anger, Sadness, Fear, and Surprise: SE Needs Special Kinds of AI: A Case Study on Text Mining and SE","N. Novielli; F. Calefato; F. Lanubile","University of Bari, Italy; University of Bari, Italy; University of Bari, Italy","IEEE Software","15 Apr 2020","2020","37","3","86","91","Artificial-intelligence (AI) tools are often applied to software engineering (SE) tasks using their “off-the-shelf” configurations. But is that wise? Perhaps not. In this column, researchers from the University of Bari show how AI gets much better when it is tuned to the particulars of SE.","1937-4194","","10.1109/MS.2020.2968557","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068371","","Software tools;Artificial intelligence;Sentiment analysis;Training data;Software development management;Data models","data mining;human factors;software engineering;text analysis","artificial-intelligence;software engineering tasks;SE;off-the-shelf configurations;AI;special kinds;text mining;University of Bari","","","","6","","15 Apr 2020","","","IEEE","IEEE Magazines"
"OpenStack Gender Diversity Report","D. Izquierdo; N. Huesman; A. Serebrenik; G. Robles","Bitergia; Diversity and Inclusion, Open Source Software Project; Software Evolution, Eindhoven University of Technology; Universidad Rey Juan Carlos, Spain","IEEE Software","14 Jan 2019","2019","36","1","28","33","When it comes to gender, the field of software engineering is heavily skewed toward men; multiple studies show that the gender situation in the open source arena is even more lopsided.","1937-4194","","10.1109/MS.2018.2874322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491276","gender diversity;open source software;openstack foundation;diversity and inclusion","Agile software development;Gender issues;Companies;Software development management;Cultural differences;Open source software","gender issues;public domain software;software engineering","OpenStack gender diversity report;software engineering;gender situation;open source arena","","5","","12","","14 Oct 2018","","","IEEE","IEEE Magazines"
"METRIC+: A Metamorphic Relation Identification Technique Based on Input plus Output Domains","C. Sun; A. Fu; P. Poon; X. Xie; H. Liu; T. Y. Chen","Department of Computer Science and Technology, University of Science and Technology Beijing, 12507 Beijing, Beijing China (e-mail: casun@ustb.edu.cn); Department of Computer Science and Technology, University of Science and Technology Beijing, 12507 Beijing, Beijing China (e-mail: anfu@xs.ustb.edu.cn); School of Engineering and Technology, Central Queensland University, 6939 Rockhampton, Queensland Australia (e-mail: p.poon@cqu.edu.au); School of Computer Science, Wuhan University, 12390 Wuhan, Hubei China (e-mail: xxie@whu.edu.cn); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: hliu@swin.edu.au); Department of Computer Science and Software Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: tychen@swin.edu.au)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Metamorphic testing is well known for its ability to alleviate the oracle problem in software testing. The main idea of metamorphic testing is to test a software system by checking whether each identified metamorphic relation (MR) holds among several executions. In this regard, identifying MRs is an essential task in metamorphic testing. In view of the importance of this identification task, METRIC (METamorphic Relation Identification based on Category-choice framework) was developed to help software testers identify MRs from a given set of complete test frames. However, during MR identification, METRIC primarily focuses on the input domain without sufficient attention given to the output domain, thereby hindering the effectiveness of METRIC. Inspired by this problem, we have extended METRIC into METRIC+ by incorporating the information derived from the output domain for MR identification. A tool implementing METRIC+ has also been developed. Two rounds of experiments, involving four real-life specifications, have been conducted to evaluate the effectiveness and efficiency of METRIC+. The results have confirmed that METRIC+ is highly effective and efficient in MR identification. Additional experiments have been performed to compare the fault detection capability of the MRs generated by METRIC+ and those by μMT (another MR identification technique). The comparison results have confirmed that the MRs generated by METRIC+ are highly effective in fault detection.","1939-3520","","10.1109/TSE.2019.2934848","National Natural Science Foundation of China; Chinese Aeronautical Establishment; Beijing Natural Science Foundation of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807231","Metamorphic testing;metamorphic relation;category-choice framework;fault detection effectiveness","Measurement;Testing;Software systems;Fault detection;Task analysis;Tools","","","","3","","","CCBY","20 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Formulating Criticality-Based Cost-Effective Fault Tolerance Strategies for Multi-Tenant Service-Based Systems","Y. Wang; Q. He; D. Ye; Y. Yang","State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; State Key Laboratory of Software Engineering, Wuhan University, Wuhan, China; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Vic, Australia; School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Vic, Australia","IEEE Transactions on Software Engineering","13 Mar 2018","2018","44","3","291","307","The proliferation of cloud computing has fueled the rapid growth of multi-tenant service-based systems (SBSs), which serve multiple tenants simultaneously by composing existing services in the form of business processes. In a distributed and volatile operating environment, runtime anomalies may occur to the component services of an SBS and cause end-to-end quality violations. Engineering multi-tenant SBSs that can quickly handle runtime anomalies cost effectively has become a significant challenge. Different approaches have been proposed to formulate fault tolerance strategies for engineering SBSs. However, none of the existing approaches has sufficiently considered the service criticality based on multi-tenancy where multiple tenants share the same SBS instance with different multi-dimensional quality preferences. In this paper, we propose Criticality-based Fault Tolerance for Multi-Tenant SBSs (CFT4MTS), a novel approach that formulates cost-effective fault tolerance strategies for multi-tenant SBSs by providing redundancy for the critical component services. First, the criticality of each component service is evaluated based on its multi-dimensional quality and multiple tenants sharing the component service with differentiated quality preferences. Then, the fault tolerance problem is modelled as an Integer Programming problem to identify the optimal fault tolerance strategy. The experimental results show that, compared with three existing representative approaches, CFT4MTS can alleviate degradation in the quality of multi-tenant SBSs in a much more effective and efficient way.","1939-3520","","10.1109/TSE.2017.2681667","Australian Research Council Discovery; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7876832","Cloud computing;criticality;fault tolerance;multi-tenancy;redundancy;service-based system","Fault tolerant systems;Streaming media;Runtime;Redundancy;Cloud computing;Business","cloud computing;integer programming;service-oriented architecture;software fault tolerance","optimal fault tolerance;criticality-based cost-effective fault tolerance;multi-tenant service-based systems;multidimensional quality preferences;cloud computing;Criticality-based Fault Tolerance for Multi-Tenant SBSs;CFT4MTS;end-to-end quality violations;runtime anomalies cost;service criticality;multitenancy;critical component services;Integer Programming problem","","7","","46","","13 Mar 2017","","","IEEE","IEEE Journals"
"Spotify Guilds: How to Succeed With Knowledge Sharing in Large-Scale Agile Organizations","D. Smite; N. B. Moe; G. Levinta; M. Floryan","Software Engineering, Blekinge Institute of Technology, Karlskrona, Sweden; SINTEF, Trondheim, Norway; Spotify, Stockholm, Sweden; Spotify, Stockholm, Sweden","IEEE Software","21 Feb 2019","2019","36","2","51","57","The new generation of software companies has revolutionized the way companies are designed. While bottom-up governance and team autonomy improve motivation, performance, and innovation, managing agile development at scale is a challenge. We describe how Spotify cultivates guilds to help the company share knowledge, align, and make collective decisions.","1937-4194","","10.1109/MS.2018.2886178","Swedish Knowledge Foundation; Research Council of Norway; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648260","","Information sharing;Agile software development;Standardization;Software development;Task analysis","knowledge management;project management;software development management;software engineering;software prototyping;team working","Spotify guilds;knowledge sharing;large-scale agile organizations;software companies;agile development;company share knowledge","","1","","5","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Reducing Software Developer Human Errors by Improving Situation Awareness","B. Nagaria; T. Hall","Brunel University London, London, United Kingdom; Software Engineering, Lancaster University, Lancaster, United Kingdom","IEEE Software","23 Oct 2020","2020","37","6","32","37","Software development is prone to errors, which are partially related to losing situation awareness. We recommend that developers know their own weaknesses, use cognitive training to manage those weaknesses, simplify their working environment, and communicate carefully with external stakeholders.","1937-4194","","10.1109/MS.2020.3014223","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157860","","Training;Software;Task analysis;Complexity theory;Syntactics;Stakeholders;Tools","cognition;risk analysis;software engineering","software developer human errors;software development;situation awareness;cognitive training;working environment;external stakeholders","","","","15","","4 Aug 2020","","","IEEE","IEEE Magazines"
"Software-Intensive Product Engineering in Start-Ups: A Taxonomy","E. Klotins; M. Unterkalmsteiner; T. Gorschek",Blekinge Institute of Technology; Blekinge Institute of Technology; Blekinge Institute of Technology,"IEEE Software","6 Jul 2018","2018","35","4","44","52","Software start-ups are new companies aiming to launch an innovative product to mass markets fast with minimal resources. However, most start-ups fail before realizing their potential. Poor software engineering, among other factors, could be a significant contributor to the challenges that start-ups experience. Little is known about the engineering context in start-up companies. On the surface, start-ups are characterized by uncertainty, high risk, and minimal resources. However, such a characterization isn't granular enough to support identification of specific engineering challenges and to devise start-up-specific engineering practices. The first step toward an understanding of software engineering in start-ups is the definition of a Start-Up Context Map-a taxonomy of engineering practices, environment factors, and goals influencing the engineering process. This map aims to support further research on the field and serve as an engineering decision support tool for start-ups. This article is part of a theme issue on Process Improvement.","1937-4194","","10.1109/MS.2018.2801548","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405630","software-intensive product engineering;product engineering;Start-Up Context Map;start-ups;software engineering;software development","Software engineering;Market research;Context modeling;Market opportunities;Business;Software development management","decision support systems;DP industry;DP management;innovation management;project management;software development management;software process improvement","software-intensive product engineering;software start-ups;start-ups experience;start-up-specific engineering practices;software engineering;Start-Up Context Map;decision support tool;taxonomy;environmental factors;process improvement","","1","","26","","6 Jul 2018","","","IEEE","IEEE Magazines"
"An Empirical Study of Model-Agnostic Techniques for Defect Prediction Models","J. Jiarpakdee; C. Tantithamthavorn; H. K. Dam; J. Grundy","Faculty of Information Technology, Monash University, Clayton, Victoria Australia 3800 (e-mail: jirayus.jiarpakdee@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: chakkrit@monash.edu); School of Computer Science and Software Engineering, University of Wollongong, Wollongong, New South Wales Australia 2522 (e-mail: hoa@uow.edu.au); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software analytics have empowered software organisations to support a wide range of improved decision-making and policy-making. However, such predictions made by software analytics to date have not been explained and justified. Specifically, current defect prediction models still fail to explain why models make such a prediction and fail to uphold the privacy laws in terms of the requirement to explain any decision made by an algorithm. In this paper, we empirically evaluate three model-agnostic techniques, i.e., two state-of-the-art Local Interpretability Model-agnostic Explanations technique (LIME) and BreakDown techniques, and our improvement of LIME with Hyper Parameter Optimisation (LIME-HPO). Through a case study of 32 highly-curated defect datasets that span across 9 open-source software systems, we conclude that (1) model-agnostic techniques are needed to explain individual predictions of defect models; (2) instance explanations generated by model-agnostic techniques are mostly overlapping (but not exactly the same) with the global explanation of defect models and reliable when they are re-generated; (3) model-agnostic techniques take less than a minute to generate instance explanations; and (4) more than half of the practitioners perceive that the contrastive explanations are necessary and useful to understand the predictions of defect models. Since the implementation of the studied model-agnostic techniques is available in both Python and R, we recommend model-agnostic techniques be used in the future.","1939-3520","","10.1109/TSE.2020.2982385","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9044387","Explainable Software Analytics;Software Quality Assurance;Defect Prediction Models;Model-Agnostic Techniques","Predictive models;Software;Analytical models;Software algorithms;Prediction algorithms;Electric breakdown;Software engineering","","","","5","","","","23 Mar 2020","","","IEEE","IEEE Early Access Articles"
"LegacyPro—A DNA-Inspired Method for Identifying Process Legacies in Software Development Organizations","M. Ochodek; M. Staron; W. Meding; J. Bosch","Poznan University of Technology, Poznan, Poland; Software Engineering, University of Gothenburg, Gothenburg, Sweden; Ericsson, Gothenburg, Sweden, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden","IEEE Software","26 Oct 2020","2020","37","6","76","85","This article presents a novel method for determining the factual adoption of new processes in software R&D organizations. We use a DNA-inspired analysis (motifs) to categorize parts and find similarities between projects using defect-inflow profiles.","1937-4194","","10.1109/MS.2020.2971894","Software Center www.software-center.se; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8984294","Software metrics;process transformation;process improvement;SimSAX","Software;Time series analysis;Testing;Companies;DNA;Transforms","organisational aspects;research and development;software development management;software engineering;software maintenance","software development organizations;LegacyPro-A DNA-inspired method;software R&D organizations","","","","8","","5 Feb 2020","","","IEEE","IEEE Magazines"
"Strategies for Competing in the Automotive Industry's Software Ecosystem: Standards and Bottlenecks","Y. Lichtenstein; S. Dujmovic; C. Baden-Fuller","Cass Business School, University of London, United Kingdom; Robert Bosch GmbH; Cass Business School, University of London, United Kingdom","IEEE Software","16 Apr 2019","2019","36","3","45","49","The automotive industry includes many actors engaged in software. This article focuses on the controlling position of car manufacturers in the automotive software ecosystem and suggests three strategies for software innovators: contesting, cooperating, and circumventing.","1937-4194","","10.1109/MS.2018.290105946","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409906","Computer Systems Organization;Communication;Networking and Information Technology;mobile computing;services computing;services lifecycle;service-oriented business models;application services and standards;industry-specific standards;general;case studies in industry","Software development management;Ecosystems;Automotive engineering;Software engineering;Ecosystems;Manufacturing processes","automobile industry;automobiles;automotive engineering;production engineering computing;software engineering","bottlenecks;car manufacturers;standards;automotive industry software ecosystem","","","","13","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Who Can Maintain This Code?: Assessing the Effectiveness of Repository-Mining Techniques for Identifying Software Maintainers","G. Avelino; L. Passos; F. Petrillo; M. T. Valente","Federal University of Piaui, Brazil; Software Engineering, Quantstamp Technologies, United States; Concordia University, United States; Computer Science, Federal University of Minas Gerais, Brazil","IEEE Software","22 Oct 2019","2019","36","6","34","42","In large and complex systems, identifying developers capable of maintaining a piece of code is an essential task. Repository-mining techniques can help by providing some level of automation; however, whether such techniques effectively identify skilled software maintainers is still unclear.","1937-4194","","10.1109/MS.2018.185140155","Fundação de Amparo à Pesquisa do Estado de Minas Gerais; Conselho Nacional de Desenvolvimento Científico e Tecnológico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8328969","Software;software engineering;management;programming teams;maintenance management;distribution, maintenance, and enhancement;software engineering","History;Object recognition;Open source software;Task analysis;Linear regression;Data mining","data mining;software maintenance","repository-mining techniques;skilled software maintainers","","1","","10","","30 Mar 2018","","","IEEE","IEEE Magazines"
"Expert Perspectives on AI","A. D. Carleton; E. Harper; M. R. Lyu; S. Eldh; T. Xie; T. Menzies","Software Engineering, Carnegie Mellon University; Software Engineering, Carnegie Mellon University; Computer Science and Engineering, The Chinese University of Hong Kong; Ericsson AB, Stockholm, Sweden; Computer Science and Technology, Peking University, China; North Carolina State University","IEEE Software","19 Jun 2020","2020","37","4","87","94","IEEE Software: With the rapid changes occurring in the fields of artificial intelligence (AI) and machine learning (ML), what areas do you think are the most important to focus on right now, especially in relation to software engineering?","1937-4194","","10.1109/MS.2020.2987673","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121622","","Artificial intelligence;Software engineering;Industries;Task analysis;Magnetic heads;Software algorithms","","","","","","0","","19 Jun 2020","","","IEEE","IEEE Magazines"
"Naming the Pain in Developing Scientific Software","I. Wiese; I. Polato; G. Pinto","Computing, Federal University of Technology???Parana, Parana, Curitiba, Brazil; Computing, Federal University of Technology???Parana, Parana, Curitiba, Brazil; Computer Science, Federal University of Para, Para, Brazil","IEEE Software","19 Jun 2020","2020","37","4","75","82","The scientific software community's lack of computer science background and software engineering training takes a toll on scientists who need to develop software. We built a taxonomy of 2,110 reported problems and grouped them into three major axes: technical-related, socialrelated, and scientific-related problems.","1937-4194","","10.1109/MS.2019.2899838","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664473","Scientific Software Developers;Pain points;Survey","Documentation;Programming;Software packages;Software engineering;Encoding","computer based training;computer science education;public domain software;software engineering","scientific software development;scientific software community;computer science;software engineering training;online learning platforms","","1","","12","","10 Mar 2019","","","IEEE","IEEE Magazines"
"INTERO: An Interoperability Model for Large Systems","R. Spalazzese; P. Pelliccione; U. Eklund","Computer Science and Media Technology, Malmo University; Computer Science and Engineering, Chalmers University of Technology; Computer Science, Malmo University","IEEE Software","15 Apr 2020","2020","37","3","38","45","The INTERO (interoperability) model helps organizations manage and improve interoperability among their large, evolving software systems. They can analyze a specific interoperability problem, conceive strategies to enhance interoperability, and reevaluate the problem to determine whether interoperability has improved.","1937-4194","","10.1109/MS.2017.265100723","Software Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950888","D Software/Software Engineering;D.2 Software Engineering;D.2.12 Interoperability;D.2.2 Design Tools and Techniques;H Information Technology and Systems;H.1 Models and Principles","Interoperability;Large-scale systems;Software engineering;Standards;Protocols;Software development management","business data processing;open systems","evolving software systems;interoperability problem;interoperability model;INTERO model;large systems","","","","14","","16 Jun 2017","","","IEEE","IEEE Magazines"
"AngularJS Performance: A Survey Study","M. Ramos; M. T. Valente; R. Terra",Federal University of Minas Gerais; Federal University of Minas Gerais; Federal University of Lavras,"IEEE Software","12 Mar 2018","2018","35","2","72","79","AngularJS is a popular JavaScript framework based on the model-view-controller pattern to construct single-page web apps. Researchers surveyed 95 professional developers regarding the performance problems of AngularJS applications. They determined the common practices the developers followed to avoid the problems (for example, using third-party or custom components), the problems' general causes (for example, inadequate application architectures), and the problems' technical causes (for example, unnecessary processing in the digest cycle, which is the internal computation that automatically updates the view with changes detected in the model).","1937-4194","","10.1109/MS.2017.265100610","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950843","AngularJS;development experience;software performance;software development;software engineering;web apps","Software reliability;Object recognition;Computer architecture;Performance evaluation;Mobile handsets;Software development management;Computer applications;Internet;Software engineering","Internet;Java;software performance evaluation","AngularJS performance;performance problems;AngularJS applications;custom components;JavaScript framework;model-view-controller pattern;single-page Web apps","","","","11","","16 Jun 2017","","","IEEE","IEEE Magazines"
"Correct, Efficient, and Tailored: The Future of Build Systems","G. Maudoux; K. Mens",Université catholique de Louvain; Université catholique de Louvain,"IEEE Software","12 Mar 2018","2018","35","2","32","37","Build systems are used in every nontrivial software project. They contain knowledge of how software is built and provide tools to get it built as fast as possible. While being central to day-to-day productivity, they sometimes fail to deliver their promise of being correct, efficient, and tailored. This situation gets aggravated with huge code bases and fast-paced continuous-integration pipelines. This article surveys state-of-the-art techniques and algorithms that relegate the occasional inconsistent build, slow execution times, and boilerplate makefiles to another age. This article is part of a special issue on release engineering.","1937-4194","","10.1109/MS.2018.111095025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255774","build systems;release engineering;incremental builds;Bazel;Gradle;namespacing;sandboxing;DAG;directed acyclic graphs;software engineering;software development","Software tools;Object recognition;Software product lines;Product life cycle management;Software engineering","pipeline processing;software maintenance;software metrics","build systems;nontrivial software project;day-to-day productivity;huge code bases;occasional inconsistent build;fast-paced continuous-integration pipelines;boilerplate makefiles;release engineering","","1","","19","","12 Jan 2018","","","IEEE","IEEE Magazines"
"Software Structures: A Careful Look","D. Lorge Parnas",McMaster University and the University of Limerick,"IEEE Software","29 Nov 2018","2018","35","6","68","71","In the half century since Edsger Dijkstra published “The Structure of the `THE'-Multiprogramming System,” it has become clear that the ability to design a software system's structure is at least as important as the ability to design efficient algorithms or write code in a particular programming language. Although the word “structure” appeared in the paper's title and was used seven more times, Dijkstra never defined the term. Closer examination revealed that he was discussing at least three distinct structures. His failure to define “structure,” or to clearly distinguish the structures that were important in his software, has led many to confuse those structures. This article aims to clarify what those structures are, their differences, and each one's importance.","1937-4194","","10.1109/MS.2018.4321239","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552620","module;program;component;process;software structures;uses;part-of;gives-work-to;Edsger Dijkstra;THE operating system;software engineering;software development;Reliable Code","Software engineering;Operating systems;Software development;Codes","multiprogramming;programming languages","software structures;Edsger Dijkstra;THE-Multiprogramming System;software system;particular programming language;word structure;closer examination;distinct structures","","2","","7","","29 Nov 2018","","","IEEE","IEEE Magazines"
"Modular Architectures Make You Agile in the Long Run","D. Sturtevant",Silverthread,"IEEE Software","25 Dec 2017","2018","35","1","104","108","Researchers have developed ways to think about, visualize, and measure software modularity and its erosion objectively and quantifiably. Using these techniques, you'll be able to determine whether your software is modular and identify complexity hotspots in your code that warrant further investigation.","1937-4194","","10.1109/MS.2017.4541034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239949","software architecture;agile programming;Design Structure Matrices;DevOps;software development;software engineering;On DevOps","Computer architecture;Complexity theory;Software engineering;Cognitive science;Visualization;Productivity","software architecture;software prototyping","software erosion;software modularity;modular architectures","","1","","8","","25 Dec 2017","","","IEEE","IEEE Magazines"
"What Do We (Really) Know about Test-Driven Development?","I. Karac; B. Turhan",University of Oulu; Brunel University,"IEEE Software","6 Jul 2018","2018","35","4","81","85","Test-driven development (TDD) involves more than just testing before coding. This article examines how (and whether) TDD has lived up to its promises. Test-driven development (TDD) is one of the most controversial agile practices in terms of its impact on software quality and programmer productivity.","1937-4194","","10.1109/MS.2018.2801554","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405634","test-driven development;TDD;test-first;test-last;software development;software engineering","Productivity;Task analysis;Systematics;Software engineering;Testing;Software quality","program testing;software quality","test-driven development;TDD","","","","18","","6 Jul 2018","","","IEEE","IEEE Magazines"
"The Software Architect and DevOps","L. Bass",Carnegie Mellon University,"IEEE Software","25 Dec 2017","2018","35","1","8","10","DevOps practices deal with such things as the velocity of releases, how fast incidents are handled, and the enforcement of organizationally specified security practices. All these are critical for success in today's environment, and the architect is critical for success in adopting DevOps practices. This instalment of the Pragmatic Architect explains why.","1937-4194","","10.1109/MS.2017.4541051","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239924","software architect;software architecture;DevOps;continuous deployment;continuous delivery;traceability;software engineering;software development;The Pragmatic Architect","Software architecture;Software engineering;Software development;Computer security","security of data;software architecture;software development management;software quality","DevOps practices;fast incidents;software architect;Pragmatic Architect;organizationally specified security practices","","7","","4","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Agility, Risk, and Uncertainty, Part 1: Designing an Agile Architecture","M. Waterman",Specialised Architecture Services,"IEEE Software","12 Mar 2018","2018","35","2","99","101","Software architects in agile environments face the dilemma of determining how much effort goes into architecting up front, before development starts. This is an issue that agile methodologies and frameworks don't address and that's becoming more critical as agile development gets used for a wider range of problems. This article is the first of two that discuss findings of recent research based on the experiences of 44 agile practitioners, to help shed light on the problem.","1937-4194","","10.1109/MS.2018.1661335","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314169","agile development;agile architecture;software architecture;software development;software engineering;The Pragmatic Architect","Computer architecture;Agile software development;Decision making;Pragmatics;Software development management;Software engineering;Software architecture","software architecture;software prototyping","agile architecture;software architects;agile environments;agile methodologies;agile development","","2","","3","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Software Refactoring for System Modernization","B. M. Santos; I. G. de Guzmán; V. V. de Camargo; M. Piattini; C. Ebert",Federal University of São Carlos; Universidad de Castilla-La Mancha; Federal University of São Carlos; Universidad de Castilla-La Mancha; Vector Consulting Services,"IEEE Software","29 Nov 2018","2018","35","6","62","67","Unlike their authors, software systems tend to live much longer than was ever intended or thought possible. Companies thus must modernize their software systems to keep them productive in new environments with new technology, within acceptable levels of costs. Refactoring tools can help with this process.","1937-4194","","10.1109/MS.2018.4321236","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552634","Architecture-Driven Modernization;ADM;legacy systems;Knowledge Discovery Metamodel;KDM;software tools;refactoring;refactoring tools;software engineering;software development;Software Technology","Software architecture;Software development;Software engineering;Knowledge discovery;Software tools","software maintenance;software tools","system modernization;software refactoring;refactoring tools;software systems","","","","5","","29 Nov 2018","","","IEEE","IEEE Magazines"
"Ends and Means","G. J. Holzmann",Nimble Research,"IEEE Software","25 Dec 2017","2018","35","1","14","17","Even the smallest coding mistake can cause huge problems when it slips by testing. Finding it can be difficult, and retesting the fixed system can be expensive, but this certainly isn't true for every type of problem. A defect found and fixed during coding is a fairly routine occurrence and not costlier than a defect found and fixed during design. Quite the opposite is usually true.","1937-4194","","10.1109/MS.2017.4541029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239938","software defects;root cause analysis;software development;software engineering;Reliable Code","Software engineering;Encoding;Software testing;Software reliability;Software measurement","program debugging;program testing","coding mistake;bug fixing;defect fixing;software testing","","","","3","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Using Microservices for Legacy Software Modernization","H. Knoche; W. Hasselbring",Kiel University; Kiel University,"IEEE Software","4 May 2018","2018","35","3","44","49","Microservices are commonly known as an architecture for building scalable applications running in the cloud. However, they also promise high maintainability due to smaller code bases and strong component separation, making them an interesting option for software modernization. This article presents a migration process to decompose an existing application into microservices, and presents experiences from applying this process in an ongoing legacy modernization project.","1937-4194","","10.1109/MS.2018.2141035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354422","microservices;web services;services modernization;software development;software engineering","Databases;Java;Software engineering;Computer architecture;Software development;Service computing;Web services","cloud computing;software maintenance","microservices;legacy software modernization;scalable applications;smaller code bases;migration process;legacy modernization project","","16","1","13","","4 May 2018","","","IEEE","IEEE Magazines"
"To Transform to Have Agility, Dont Do a Capital A, Capital T Agile Transformation","J. Smart",Barclays,"IEEE Software","29 Nov 2018","2018","35","6","56","60","This article presents antipatterns (and the corresponding patterns) based on the author's experience implementing agility at Barclays. In recent years, enterprise -wide DevOps and agile at scale have surged. Compared to nearly 30 years of ""lightweight methodologies"" for team -level software development, this is a new field. DevOps emerged as a term in 2009, with scaled agile frameworks coming out comparatively recently: SAFe (Scaled Agile Framework) in 2011, Disciplined Agile in 2012, and LeSS (Large Scale Scrum) in 2013. However, relatively little research is available about these frameworks' effectiveness in practice, especially on an enterprise scale.","1937-4194","","10.1109/MS.2018.4321245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552621","agile transformation;agile development;agility;Barclays;DevOps;software engineering;software development;On DevOps","Software engineering;Software development;Agile software development","DP industry;project management;software development management;software prototyping;team working","agile transformation;enterprise-wide DevOps;team-level software development;agile frameworks;SAFe;Scaled Agile Framework;antipatterns","","1","","14","","29 Nov 2018","","","IEEE","IEEE Magazines"
"Collaborative-Design Conflicts: Costs and Solutions","J. y. Bang; Y. Brun; N. Medvidović",Kakao Corporation; University of Massachusetts Amherst; University of Southern California,"IEEE Software","29 Nov 2018","2018","35","6","25","31","Collaborative design exposes software architects to the risk of making conflicting modeling changes that either can't be merged or, when merged, violate consistency rules, nonfunctional requirements, or other system constraints. Such design conflicts are common and incur a high cost, including having to redo and abandon work. Proactive conflict detection can alleviate this risk. This article motivates the need for design conflict detection, describes the benefits of such detection to practitioners, and identifies requirements for building detection tools. In particular, FLAME is a collaborative-design framework that efficiently and continuously detects design conflicts. This article is part of a theme issue on collaborative modeling.","1937-4194","","10.1109/MS.2018.290110057","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409920","proactive conflict detection;design;FLAME;Framework for Logging and Analyzing Modeling Events;software architecture;collaborative modeling;collaborative design;software development;software engineering","Collaboration;Analytical models;Software architecture;Collaborative software;Software development;Computational modeling;Software engineering","configuration management;groupware;product design;software architecture;source code (software)","software architects;consistency rules;nonfunctional requirements;proactive conflict detection;design conflict detection;collaborative modeling;collaborative-design conflicts;FLAME","","","","13","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Supporting Requirements-Engineering Research That Industry Needs: The NaPiRE Initiative","D. M. Fernández",Technical University of Munich,"IEEE Software","25 Dec 2017","2018","35","1","112","116","The NaPiRE (Naming the Pain in Requirements Engineering) initiative aims to tackle the problem of conducting the requirements-engineering research that industry needs.","1937-4194","","10.1109/MS.2017.4541045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239923","NaPiRE;Naming the Pain in Requirements Engineering;requirements engineering;software engineering;software development;agile software development","Software engineering;Software development;Requirements engineering;Information retrieval;Search problems","formal specification;formal verification","Naming the Pain in Requirements Engineering;NaPiRE Initiative;requirements-engineering research","","3","","8","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Reconsidering Whether GOTO Is Harmful","M. Nagappan",University of Waterloo,"IEEE Software","4 May 2018","2018","35","3","93","95","Is it always bad to use GOTO statements? An empirical analysis of open source C projects on GitHub suggests otherwise.","1937-4194","","10.1109/MS.2018.2141020","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354436","GOTO;GitHub;Edsger Dijkstra;software development;software engineering;Redirections","Open source software;Software engineering;Programming profession;Software reliability;Blogs","program control structures;public domain software","GOTO statements;empirical analysis;open source C projects;GitHub","","","","3","","4 May 2018","","","IEEE","IEEE Magazines"
"Making Sense of Agile Methods","B. Meyer",Politecnico di Milano and Innopolis University,"IEEE Software","12 Mar 2018","2018","35","2","91","94","Bertrand Meyer runs agile methods and practices through his personal friend-or-foe test. He also offers his experiences and opinions about the hype, ugly, good, and even brilliant aspects of agile development.","1937-4194","","10.1109/MS.2018.1661325","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314168","agile development;Extreme Programming;XP;Scrum;pair programming;user stories;refactoring;branching;software development;software engineering;Insights","Software development management;Agile software development;Software engineering;Task analysis","cultural aspects;social aspects of automation;software prototyping","Bertrand Meyer;agile methods;opinions;ugly aspects;agile development;personal friend-or-foe test;good aspects;brilliant aspects","","3","","10","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Continuous Experimentation: Challenges, Implementation Techniques, and Current Research","G. Schermann; J. Cito; P. Leitner",University of Zurich; University of Zurich; Chalmers University of Technology,"IEEE Software","12 Mar 2018","2018","35","2","26","31","Continuous experimentation is an up-and-coming technique for requirements engineering and testing, particularly for web-based systems. On the basis of a practitioner survey, this article gives an overview of challenges, implementation techniques, and current research in the field. This article is part of a theme issue on release engineering.","1937-4194","","10.1109/MS.2018.111094748","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255793","release engineering;continuous experimentation;feature toggles;traffic routing;regression-driven experiments;business-driven experiments;software development;software engineering","Software engineering;Routing;Software testing;Data science;Computer architecture;Software product lines;Product life cycle management","formal specification;Internet;program testing;systems analysis","requirements engineering;Web-based systems","","8","","10","","12 Jan 2018","","","IEEE","IEEE Magazines"
"The Interplay of Sampling and Machine Learning for Software Performance Prediction","C. Kaltenecker; A. Grebhahn; N. Siegmund; S. Apel","Software Engineering, Saarland University, Saarbrucken, Saarland, Germany; Big Data Engineering, University of Passau, Berlin, Germany; Software Systems, Leipzig University, Germany; Software Engineering, Saarland University, Saarbrucken, Saarland, Germany","IEEE Software","19 Jun 2020","2020","37","4","58","66","Artificial intelligence has gained considerable momentum in software engineering, but there are major challenges that make this domain special. We review recent advances, raise awareness of the distinctiveness of software configuration spaces, and provide practical guidelines for modeling, predicting, and optimizing performance.","1937-4194","","10.1109/MS.2020.2987024","Deutsche Forschungsgemeinschaft; Bundesministerium f??r Bildung und Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9062326","Configuration Management;Metrics/Measurement;Domain Engineering;Machine Learning;Modeling and Prediction","Machine learning;Software systems;Predictive models;Encryption;Computational modeling","learning (artificial intelligence);software performance evaluation","software performance prediction;artificial intelligence;software engineering;software configuration spaces;machine learning","","5","","19","","9 Apr 2020","","","IEEE","IEEE Magazines"
"The Connection Between Burnout and Personality Types in Software Developers","E. Mellblom; I. Arason; L. Gren; R. Torkar","Carmenta Geospatial Technologies, Gothenburg, Sweden; Software Engineering and Management, Gothenburg University, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden; Chalmers University of Technology, Gothenburg, Sweden","IEEE Software","15 Aug 2019","2019","36","5","57","64","This article examines the connection between the five-factor model personality traits and burnout in software developers and aims to validate generalizations of findings in other fields.","1937-4194","","10.1109/MS.2019.2924769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8745484","Burnout;personality;five factor model,;software developers","Software development management;Stress;Software engineering;Sentiment analysis;Emotion recognition;Personnel","human factors;software development management","burnout;personality types;software developers;five-factor model personality traits","","1","","19","","25 Jun 2019","","","IEEE","IEEE Magazines"
"DevOps and Organisational Performance: The Fallacy of Chasing Maturity","C. Marnewick; J. Langerman","Applied Information Systems, University of Johannesburg College of Business and Economics, Auckland Park, Gauteng, South Africa; Academy of Computer Science and Software Engineering, University of Johannesburg, Auckland Park, Gauteng, South Africa","IEEE Software","","2020","PP","99","0","0","Maturity models are perceived as aiding organizations to perform better. This is also true of DevOps maturity models. The question is whether DevOps maturity models also improve organisational performance. A case study approach was used to determine the impact of DevOps maturity on organisational performance. The results indicate that although maturity models improve DevOps processes, they in themselves do not improve organisational performance. Organisations need to use DevOps maturity models in association with other drivers such as scaling agile and a change in organisational culture to improve performance. This article contributes to the current debate on the value of DevOps maturity models and provides alternative insights.","1937-4194","","10.1109/MS.2020.3023298","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9190017","","Stability analysis;Throughput;Software;Measurement;Business;Analytical models;Software engineering","","","","","","","","9 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Scale Your Team Horizontally","G. Fairbanks","Software Engineering, Google","IEEE Software","17 Jun 2019","2019","36","4","88","90","Not long ago, when your company became successful, you bought a bigger computer to run your software. We called this scaling vertically. Today, that is less common, in part because we have gotten quite good at scaling horizontally so when your company becomes successful, it buys more of the same-sized computers.","1937-4194","","10.1109/MS.2019.2909766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738150","","Planning;Software engineering;Team working;Organizational aspects","team working","same-sized computers;vertical scaling;horizontal scaling","","","","4","","17 Jun 2019","","","IEEE","IEEE Magazines"
"Software Components","G. J. Holzmann",Nimble Research,"IEEE Software","4 May 2018","2018","35","3","80","82","Software components have come a long way since Doug McIlroy first called for them in 1968.","1937-4194","","10.1109/MS.2018.2141034","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354432","software components;Doug McIlroy;software development;software engineering;Reliable Code","Software development;Standards;Encoding;Software reliability;Computer bugs","software reusability","software components;software engineering;software design;mass-produced software parts","","","","4","","4 May 2018","","","IEEE","IEEE Magazines"
"A Comprehensive Investigation of the Role of Imbalanced Learning for Software Defect Prediction","Q. Song; Y. Guo; M. Shepperd","Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Department of Computer Science & Technology, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Department of Computer Science, Brunel University, Uxbridge, Middlesex, United Kingdom","IEEE Transactions on Software Engineering","10 Dec 2019","2019","45","12","1253","1269","Context: Software defect prediction (SDP) is an important challenge in the field of software engineering, hence much research work has been conducted, most notably through the use of machine learning algorithms. However, class-imbalance typified by few defective components and many non-defective ones is a common occurrence causing difficulties for these methods. Imbalanced learning aims to deal with this problem and has recently been deployed by some researchers, unfortunately with inconsistent results. Objective: We conduct a comprehensive experiment to explore (a) the basic characteristics of this problem; (b) the effect of imbalanced learning and its interactions with (i) data imbalance, (ii) type of classifier, (iii) input metrics and (iv) imbalanced learning method. Method: We systematically evaluate 27 data sets, 7 classifiers, 7 types of input metrics and 17 imbalanced learning methods (including doing nothing) using an experimental design that enables exploration of interactions between these factors and individual imbalanced learning algorithms. This yields 27 × 7 × 7 × 17 = 22491 results. The Matthews correlation coefficient (MCC) is used as an unbiased performance measure (unlike the more widely used F1 and AUC measures). Results: (a) we found a large majority (87 percent) of 106 public domain data sets exhibit moderate or low level of imbalance (imbalance ratio <; 10; median = 3.94); (b) anything other than low levels of imbalance clearly harm the performance of traditional learning for SDP; (c) imbalanced learning is more effective on the data sets with moderate or higher imbalance, however negative results are always possible; (d) type of classifier has most impact on the improvement in classification performance followed by the imbalanced learning method itself. Type of input metrics is not influential. (e) only 52% of the combinations of Imbalanced Learner and Classifier have a significant positive effect. Conclusion: This paper offers two practical guidelines. First, imbalanced learning should only be considered for moderate or highly imbalanced SDP data sets. Second, the appropriate combination of imbalanced method and classifier needs to be carefully chosen to ameliorate the imbalanced learning problem for SDP. In contrast, the indiscriminate application of imbalanced learning can be harmful.","1939-3520","","10.1109/TSE.2018.2836442","National Natural Science Foundation of China; Brunel University London; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359087","Software defect prediction;bug prediction;imbalanced learning;imbalance ratio;effect size","Software measurement;Boosting;Machine learning algorithms;Bagging;Computer bugs","learning (artificial intelligence);pattern classification;program diagnostics;sampling methods;software engineering","software defect prediction;machine learning algorithms;input metrics;imbalanced learning method;individual imbalanced learning algorithms;traditional learning;moderate imbalanced SDP data sets;highly imbalanced SDP data sets;imbalanced learning problem","","19","","92","IEEE","15 May 2018","","","IEEE","IEEE Journals"
"Fault Analysis and Debugging of Microservice Systems: Industrial Survey, Benchmark System, and Empirical Study","X. Zhou; X. Peng; T. Xie; J. Sun; C. Ji; W. Li; D. Ding","School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; University of Illinois at Urbana-Champaign, Urbana, IL, USA; Singapore University of Technology and Design, Singapore; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China; School of Computer Science, Shanghai Key Laboratory of Data Science, and Shanghai Institute of Intelligent Electronics & Systems, Fudan University, Shanghai, China","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","243","260","The complexity and dynamism of microservice systems pose unique challenges to a variety of software engineering tasks such as fault analysis and debugging. In spite of the prevalence and importance of microservices in industry, there is limited research on the fault analysis and debugging of microservice systems. To fill this gap, we conduct an industrial survey to learn typical faults of microservice systems, current practice of debugging, and the challenges faced by developers in practice. We then develop a medium-size benchmark microservice system (being the largest and most complex open source microservice system within our knowledge) and replicate 22 industrial fault cases on it. Based on the benchmark system and the replicated fault cases, we conduct an empirical study to investigate the effectiveness of existing industrial debugging practices and whether they can be further improved by introducing the state-of-the-art tracing and visualization techniques for distributed systems. The results show that the current industrial practices of microservice debugging can be improved by employing proper tracing and visualization techniques and strategies. Our findings also suggest that there is a strong need for more intelligent trace analysis and visualization, e.g., by combining trace visualization and improved fault localization, and employing data-driven and learning-based recommendation for guided visual exploration and comparison of traces.","1939-3520","","10.1109/TSE.2018.2887384","National Key Research and Development Program of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8580420","Microservices;fault localization;tracing;visualization;debugging","Debugging;Benchmark testing;Companies;Computer architecture;Visualization;Industries;Runtime","data visualisation;fault diagnosis;learning (artificial intelligence);program debugging;program testing;software architecture;software engineering;software fault tolerance","22 industrial fault cases;most complex open source microservice system;largest source microservice system;medium-size benchmark microservice system;typical faults;fault analysis;benchmark system;industrial survey;microservice systems;microservice debugging;current industrial practices;distributed systems;industrial debugging practices;replicated fault cases","","16","","67","IEEE","18 Dec 2018","","","IEEE","IEEE Journals"
"Quotes from IEEE Software History","Ž. Obrenović",Software Improvement Group,"IEEE Software","27 Sep 2018","2018","35","5","10","13","This alternative view of IEEE Software history presents quotes organized in conversations. Each conversation pairs a quote from the magazine’s early days (1984–1990) with a more contemporary quote, with at least 20 years between the two. The aim is to illustrate that some key ideas and topics are classic and have value even decades later. Additional pairs of quotes are available in the Web Extra at https://extras.computer.org/extra/mso2018050010s1.pdf. This article is part of a theme issue on software engineering’s 50th anniversary.","1937-4194","","10.1109/MS.2018.3571243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474517","IEEE Software;software engineering;software development;Conversations with the Past","IEEE publishing;History","","","","","","","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Nicolai Parlog on Java 9 Modules","N. Black",Sleeperbot,"IEEE Software","4 May 2018","2018","35","3","101","104","In this excerpt from a Software Engineering Radio episode, Nick Black talks with Nicolai Parlog about Java 9—specifically, the why and how of the module system.","1937-4194","","10.1109/MS.2018.2141025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354430","Nicolai Parlog;Java 9;JAR;Java archives;Java Platform Module System;JPMS;Java modules;Software Engineering Radio;software engineering;software development","Java;Runtime;Interviews;Software development","","","","1","","","","4 May 2018","","","IEEE","IEEE Magazines"
"Automatic Identification and Classification of Software Development Video Tutorial Fragments","L. Ponzanelli; G. Bavota; A. Mocci; R. Oliveto; M. D. Penta; S. Haiduc; B. Russo; M. Lanza","Università della Svizzera italiana (USI), Lugano, 6900, Switzerland; Università della Svizzera italiana (USI), Lugano, 6900, Switzerland; Università della Svizzera italiana (USI), Lugano, 6900, Switzerland; University of Molise, Pesche (IS), Campobasso, Italy; University of Sannio, Benevento, Italy; Florida State University, Tallahassee, FL; Free University of Bozen-Bolzano, Bolzano, Italy; Università della Svizzera italiana (USI), Lugano, 6900, Switzerland","IEEE Transactions on Software Engineering","21 May 2019","2019","45","5","464","488","Software development video tutorials have seen a steep increase in popularity in recent years. Their main advantage is that they thoroughly illustrate how certain technologies, programming languages, etc. are to be used. However, they come with a caveat: there is currently little support for searching and browsing their content. This makes it difficult to quickly find the useful parts in a longer video, as the only options are watching the entire video, leading to wasted time, or fast-forwarding through it, leading to missed information. We present an approach to mine video tutorials found on the web and enable developers to query their contents as opposed to just their metadata. The video tutorials are processed and split into coherent fragments, such that only relevant fragments are returned in response to a query. Moreover, fragments are automatically classified according to their purpose, such as introducing theoretical concepts, explaining code implementation steps, or dealing with errors. This allows developers to set filters in their search to target a specific type of video fragment they are interested in. In addition, the video fragments in CodeTube are complemented with information from other sources, such as Stack Overflow discussions, giving more context and useful information for understanding the concepts.","1939-3520","","10.1109/TSE.2017.2779479","Swiss National Science foundation; Swiss National Science foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8128506","Recommender systems;mining unstructured data;video tutorials","Tutorials;Java;Software;YouTube;Indexes;Androids;Humanoid robots","computer aided instruction;data mining;Internet;meta data;pattern classification;query processing;software engineering;video signal processing","CodeTube;video tutorials mining;video fragment;software development video tutorials;automatic identification","","4","","77","","4 Dec 2017","","","IEEE","IEEE Journals"
"Microtask Programming","T. D. LaToza; A. Di Lecce; F. Ricci; W. B. Towne; A. van der Hoek","Department of Computer Science, George Mason University, Fairfax, VA; Cuebiq Srl, Milano, Italy; Bosch Rexroth, Milan, Italy; Carnegie Mellon University, Pittsburgh, PA; Department of Informatics, University of California, Irvine, Irvine, CA","IEEE Transactions on Software Engineering","13 Nov 2019","2019","45","11","1106","1124","Traditional forms of Crowdsourcing such as open source software development harness crowd contributions to democratize the creation of software. However, potential contributors must first overcome joining barriers forcing casually committed contributors to spend days or weeks onboarding and thereby reducing participation. To more effectively harness potential contributions from the crowd, we propose a method for programming in which work occurs entirely through microtasks, offering contributors short, self-contained tasks such as implementing part of a function or updating a call site invoking a function to match a change made to the function. In microtask programming, microtasks involve changes to a single artifact, are automatically generated as necessary by the system, and nurture quality through iteration. A study examining the feasibility of microtask programming to create small programs found that developers were able to complete 1008 microtasks, onboard and submit their first microtask in less than 15 minutes, complete all types of microtasks in less than 5 minutes on average, and create 490 lines of code and 149 unit tests. The results demonstrate the potential feasibility as well as revealing a number of important challenges to address to successfully scale microtask programming to larger and more complex programs.","1939-3520","","10.1109/TSE.2018.2823327","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8331909","Programming environments;management","Programming;Task analysis;Crowdsourcing;Programming environments;Public domain software;Collaborative software","groupware;public domain software;software engineering","open source software development;potential contributors;potential contributions;microtask programming;complex programs;crowd contributions","","2","","49","","5 Apr 2018","","","IEEE","IEEE Journals"
"Mining Fix Patterns for FindBugs Violations","K. Liu; D. Kim; T. F. Bissyandé; S. Yoo; Y. Le Traon","Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; School of Computing, KAIST, Daejeon, Republic of Korea; Interdisciplinary Centre for Security, Reliability and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","165","188","Several static analysis tools, such as Splint or FindBugs, have been proposed to the software development community to help detect security vulnerabilities or bad programming practices. However, the adoption of these tools is hindered by their high false positive rates. If the false positive rate is too high, developers may get acclimated to violation reports from these tools, causing concrete and severe bugs being overlooked. Fortunately, some violations are actually addressed and resolved by developers. We claim that those violations that are recurrently fixed are likely to be true positives, and an automated approach can learn to repair similar unseen violations. However, there is lack of a systematic way to investigate the distributions on existing violations and fixed ones in the wild, that can provide insights into prioritizing violations for developers, and an effective way to mine code and fix patterns which can help developers easily understand the reasons of leading violations and how to fix them. In this paper, we first collect and track a large number of fixed and unfixed violations across revisions of software. The empirical analyses reveal that there are discrepancies in the distributions of violations that are detected and those that are fixed, in terms of occurrences, spread and categories, which can provide insights into prioritizing violations. To automatically identify patterns in violations and their fixes, we propose an approach that utilizes convolutional neural networks to learn features and clustering to regroup similar instances. We then evaluate the usefulness of the identified fix patterns by applying them to unfixed violations. The results show that developers will accept and merge a majority (69/116) of fixes generated from the inferred fix patterns. It is also noteworthy that the yielded patterns are applicable to four real bugs in the Defects4J major benchmark for software testing and automated repair.","1939-3520","","10.1109/TSE.2018.2884955","Fonds National de la Recherche Luxembourg; National Research Foundation of Korea; Ministry of Science, ICT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565907","Fix pattern;pattern mining;program repair;findbugs violation;unsupervised learning","Tools;Static analysis;Computer bugs;Maintenance engineering;Software;Java;Security","data mining;inference mechanisms;learning (artificial intelligence);neural nets;program debugging;program diagnostics;program testing;public domain software;security of data;software engineering;software maintenance;software quality","FindBugs violations;static analysis tools;software development community;high false positive rates;false positive rate;violation reports;similar unseen violations;prioritizing violations;leading violations;unfixed violations;fixes;identified fix patterns;inferred fix patterns;mining fix patterns","","3","","108","IEEE","6 Dec 2018","","","IEEE","IEEE Journals"
"Control-Theoretical Software Adaptation: A Systematic Literature Review","S. Shevtsov; M. Berekmeri; D. Weyns; M. Maggio","Linnaeus University, Växjö, Sweden; Grenoble Institute of Technology, Grenoble, France; Katholieke Universiteit Leuven, Leuven, Belgium; Lund University, Lund, Sweden","IEEE Transactions on Software Engineering","13 Aug 2018","2018","44","8","784","810","Modern software applications are subject to uncertain operating conditions, such as dynamics in the availability of services and variations of system goals. Consequently, runtime changes cannot be ignored, but often cannot be predicted at design time. Control theory has been identified as a principled way of addressing runtime changes and it has been applied successfully to modify the structure and behavior of software applications. Most of the times, however, the adaptation targeted the resources that the software has available for execution (CPU, storage, etc.) more than the software application itself. This paper investigates the research efforts that have been conducted to make software adaptable by modifying the software rather than the resource allocated to its execution. This paper aims to identify: the focus of research on control-theoretical software adaptation; how software is modeled and what control mechanisms are used to adapt software; what software qualities and controller guarantees are considered. To that end, we performed a systematic literature review in which we extracted data from 42 primary studies selected from 1,512 papers that resulted from an automatic search. The results of our investigation show that even though the behavior of software is considered non-linear, research efforts use linear models to represent it, with some success. Also, the control strategies that are most often considered are classic control, mostly in the form of Proportional and Integral controllers, and Model Predictive Control. The paper also discusses sensing and actuating strategies that are prominent for software adaptation and the (often neglected) proof of formal properties. Finally, we distill open challenges for control-theoretical software adaptation.","1939-3520","","10.1109/TSE.2017.2704579","Assurances for Decentralized Self-Adaptive Systems Vetenskapsradet Sweden; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7929422","Self-adaptive software;control theory;software adaptation","Software;Control theory;Adaptation models;Runtime;Bibliographies;Mathematical model;Knowledge based systems","predictive control;resource allocation;reverse engineering;software engineering;software performance evaluation;software quality","control-theoretical software adaptation;systematic literature review;modern software applications;runtime changes;software application;software adaptable;software qualities;model predictive control","","5","","116","","16 May 2017","","","IEEE","IEEE Journals"
"Predicting Future Developer Behavior in the IDE Using Topic Models","K. Damevski; H. Chen; D. C. Shepherd; N. A. Kraft; L. Pollock","Department of Computer Science, Virginia Commonwealth University, Richmond, VA; Department of Computer and Information Science, University of New York, Brooklyn, NY; ABB Corporate Research, Raleigh, NC; ABB Corporate Research, Raleigh, NC; Department of Computer and Information Sciences, University of Delaware, Newark, DE","IEEE Transactions on Software Engineering","11 Nov 2018","2018","44","11","1100","1111","While early software command recommender systems drew negative user reaction, recent studies show that users of unusually complex applications will accept and utilize command recommendations. Given this new interest, more than a decade after first attempts, both the recommendation generation (backend) and the user experience (frontend) should be revisited. In this work, we focus on recommendation generation. One shortcoming of existing command recommenders is that algorithms focus primarily on mirroring the short-term past,-i.e., assuming that a developer who is currently debugging will continue to debug endlessly. We propose an approach to improve on the state of the art by modeling future task context to make better recommendations to developers. That is, the approach can predict that a developer who is currently debugging may continue to debug OR may edit their program. To predict future development commands, we applied Temporal Latent Dirichlet Allocation, a topic model used primarily for natural language, to software development interaction data (i.e., command streams). We evaluated this approach on two large interaction datasets for two different IDEs, Microsoft Visual Studio and ABB Robot Studio. Our evaluation shows that this is a promising approach for both predicting future IDE commands and producing empirically-interpretable observations.","1939-3520","","10.1109/TSE.2017.2748134","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8024001","Command recommendation systems;IDE interaction data","Natural languages;Data models;Analytical models;Predictive models;Visualization;Adaptation models;Data analysis","program debugging;recommender systems;software engineering","future developer behavior;early software command recommender systems;negative user reaction;unusually complex applications;command recommendations;recommendation generation;user experience;command recommenders;future task context;debug OR;future development commands;software development interaction data;predicting future IDE commands;empirically-interpretable observations","","6","","33","","1 Sep 2017","","","IEEE","IEEE Journals"
"A Study of Bug Resolution Characteristics in Popular Programming Languages","J. Zhang; F. Li; D. Hao; M. Wang; H. Tang; L. Zhang; M. Harman","Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: jie.zhang@ucl.ac.uk); Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: lifeng2014@pku.edu.cn); EECS,Peking University, Institute of Software, Beijing, Beijing China 100871 (e-mail: haodan@pku.edu.cn); Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: meng.wang@bristol.ac.uk); Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: tanghaoth90@pku.edu.cn); EECS,Peking University, Institute of Software, Beijing, Beijing China (e-mail: zhanglucs@pku.edu.cn); CS, Facebook London, 507852 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: mark.harman@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Bug resolution is an essential part of software development. The impact of programming language on bug resolution has been a topic of much debate. Taking Python as an example, some hold the view that bugs in the language are easy to handle because its code is easy to read and understand, while others believe that the absence of static typing leads to more bug-handling effort. This paper presents the first large-scale study that investigates the connection between programming language and bug resolution characteristics. It follows the recent trend of empirical scientific reformulation of long-standing, but hitherto anecdotal, `great debates' about the influence of programming language and paradigm on software engineering concerns. We analyse bug resolution data from over 70 million SLOC drawn from 3 million commits to 600 GitHub projects in 10 languages. The results suggest that statistically significant differences in resolution time and patch size exist between different languages and language categories. In particular, Java bug resolution consumes less elapsed time from raise to resolve, while Ruby consumes more. We also found that patches tend to touch significantly more files for strongly typed and for static languages (as one might expect given the need to maintain type annotations). However, despite this apparent extra effort, we found evidence for a significantly lower elapsed resolution time for bug resolution committed to projects constructed from statically typed languages. This finding sheds further empirical light on the debate about the importance of static typing. Indeed, more generally, we found no evidence for any correlation between bug-resolution time and size (lines or files touched), nor any evidence for correlation with other potential confounding factors, such as problem features (e.g., size, age, and commit number) and target domain.","1939-3520","","10.1109/TSE.2019.2961897","Royal Society IES; Newton Advanced Fellowships; National Natural Science Foundation of China; ERC advanced grant; the National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8941305","program language;bug resolution;empirical study","Computer bugs;Software engineering;Java;Correlation;Software;Data mining","","","","","","","CCBY","24 Dec 2019","","","IEEE","IEEE Early Access Articles"
"A Comparison of Program Comprehension Strategies by Blind and Sighted Programmers","A. Armaly; P. Rodeghero; C. McMillan","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN","IEEE Transactions on Software Engineering","13 Aug 2018","2018","44","8","712","724","Programmers who are blind use a screen reader to speak source code one word at a time, as though the code were text. This process of reading is in stark contrast to sighted programmers, who skim source code rapidly with their eyes. At present, it is not known whether the difference in these processes has effects on the program comprehension gained from reading code. These effects are important because they could reduce both the usefulness of accessibility tools and the generalizability of software engineering studies to persons with low vision. In this paper, we present an empirical study comparing the program comprehension of blind and sighted programmers. We found that both blind and sighted programmers prioritize reading method signatures over other areas of code. Both groups obtained an equal and high degree of comprehension, despite the different reading processes.","1939-3520","","10.1109/TSE.2017.2729548","National Science Foundation Graduate Research Fellowship Program; US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987041","Program comprehension;accessibility technology;blindness","Tools;Software;Blindness;Navigation;Programming profession;Software engineering","programming environments;public domain software;software prototyping;source code (software)","source code;sighted programmers;program comprehension strategies;reading processes;stark;program comprehension;reading method signature","","2","","46","","20 Jul 2017","","","IEEE","IEEE Journals"
"Property Satisfiability Analysis for Product Lines of Modelling Languages","E. Guerra; J. de Lara; M. Chechik; R. Salay","Computer Science, Universidad Autnoma de Madrid, Madrid, Madrid Spain (e-mail: esther.guerra@uam.es); Ingeniera Informtica, Universidad Autnoma de Madrid, Madrid, Madrid Spain 28049 (e-mail: juan.delara@uam.es); Department of Computer Science, University of Toronto, Toronto, Ontario Canada M5S2E4 (e-mail: chechik@cs.toronto.edu); Computer Science, University of Toronto, 7938 Toronto, Ontario Canada M5S 3G4 (e-mail: rsalay@cs.toronto.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software engineering uses models throughout most phases of the development process. Models are defined using modelling languages. To make these languages applicable to a wider set of scenarios and customizable to specific needs, researchers have proposed using product lines to specify modelling language variants. However, there is currently a lack of efficient techniques for ensuring correctness with respect to properties of the models accepted by a set of language variants. This may prevent detecting problematic combinations of language variants that produce undesired effects at the model level. To attack this problem, we first present a classification of instantiability properties for language product lines. Then, we propose a novel approach to lifting the satisfiability checking of model properties of individual language variants, to the product line level. Finally, we report on an implementation of our proposal in the Merlin tool, and demonstrate the efficiency gains of our lifted analysis method compared to an enumerative analysis of each individual language variant.","1939-3520","","10.1109/TSE.2020.2989506","Ministerio de Ciencia y Tecnologa; Consejera de Educacin Juventud y Deporte Comunidad de Madrid; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9076306","Model-Driven Engineering;Software Language Engineering;Product Lines;Meta-Modelling;OCL;Model Finding","Unified modeling language;Analytical models;Petri nets;Syntactics;Tools;Programmable logic arrays;Software engineering","","","","","","","","22 Apr 2020","","","IEEE","IEEE Early Access Articles"
"A Multi-Study Investigation into Dead Code","S. Romano; C. Vendome; G. Scanniello; D. Poshyvanyk","University of Basilicata, Potenza, PZ, Italy; College of William and Mary, Williamsburg, VA; University of Basilicata, Potenza, PZ, Italy; College of William and Mary, Williamsburg, VA","IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","71","99","Dead code is a bad smell and it appears to be widespread in open-source and commercial software systems. Surprisingly, dead code has received very little empirical attention from the software engineering research community. In this paper, we present a multi-study investigation with an overarching goal to study, from the perspective of researchers and developers, when and why developers introduce dead code, howthey perceive and cope with it, and whether dead code is harmful. To this end, we conducted semi-structured interviews with software professionals and four experiments at the University of Basilicata and the College of William & Mary. The results suggest that it is worth studying dead code not only in the maintenance and evolution phases, where our results suggest that dead code is harmful, but also in the design and implementation phases. Our results motivate future work to develop techniques for detecting and removing dead code and suggest that developers should avoid this smell.","1939-3520","","10.1109/TSE.2018.2842781","NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8370748","Dead code;unreachable code;unused code;bad smell;empirical investigation;multi-study","Software systems;Maintenance engineering;Software engineering;Interviews;Tools;Open source software","software maintenance","dead code;multistudy investigation;bad smell;commercial software systems;open-source software systems","","4","","51","IEEE","1 Jun 2018","","","IEEE","IEEE Journals"
"A Study of Call Graph Construction for JVM-Hosted Languages","K. Ali; X. Lai; Z. Luo; O. Lhotak; J. Dolby; F. Tip","Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada T6G 2R3 (e-mail: karim.ali@ualberta.ca); N/A, Google, Waterloo, Ontario Canada (e-mail: xlai@google.com); N/A, Microsoft Corp, 6834 Redmond, Washington United States (e-mail: zhaoyi.luo@microsoft.com); David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, Ontario Canada (e-mail: olhotak@uwaterloo.ca); Software Technology, IBM T.J. Watson Research Center, Yorktown Heights, New York United States 10598 (e-mail: dolby@us.ibm.com); Khoury College of Computer Sciences, Northeastern University, Boston, Massachusetts United States (e-mail: f.tip@northeastern.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Call graphs have many applications in software engineering, including bug-finding, security analysis, and code navigation in IDEs. However, the construction of call graphs requires significant investment in program analysis infrastructure. An increasing number of programming languages compile to the Java Virtual Machine (JVM), and program analysis frameworks such as WALA and SOOT support a broad range of program analysis algorithms by analyzing JVM bytecode. This approach has been shown to work well when applied to bytecode produced from Java code. In this paper, we show that it also works well for diverse other JVM-hosted languages: dynamically-typed functional Scheme, statically-typed object-oriented Scala, and polymorphic functional OCaml. Effectively, we get call graph construction for these languages for free, using existing analysis infrastructure for Java, with only minor challenges to soundness. This, in turn, suggests that bytecode-based analysis could serve as an implementation vehicle for bug-finding, security analysis, and IDE features for these languages. We present qualitative and quantitative analyses of the soundness and precision of call graphs constructed from JVM bytecodes for these languages, and also for Groovy, Clojure, Python, and Ruby. However, we also show that implementation details matter greatly. In particular, the JVM-hosted implementations of Groovy, Clojure, Python, and Ruby produce very unsound call graphs, due to the pervasive use of reflection, invokedynamic instructions, and run-time code generation. Interestingly, the dynamic translation schemes employed by these languages, which result in unsound static call graphs, tend to be correlated with poor performance at run time.","1939-3520","","10.1109/TSE.2019.2956925","Natural Sciences and Engineering Research Council of Canada; Office of Naval Research; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8944149","Call graphs;static analysis;JVM;compilation;Scheme;Scala;OCaml;Groovy;Clojure;Python;Ruby","Java;Static analysis;Python;Security;Vehicle dynamics;Software engineering","","","","2","","","CCBY","27 Dec 2019","","","IEEE","IEEE Early Access Articles"
"How to ""DODGE"" Complex Software Analytics","A. Agrawal; W. Fu; D. Chen; X. Shen; T. Menzies","Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: aagrawa8@ncsu.edu); Department of Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: wfu@ncsu.edu); Computer Science, Facebook Inc, 342996 Menlo Park, California United States (e-mail: dchen20@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: xshen5@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Machine learning techniques applied to software engineering tasks can be improved by hyperparameter optimization, i.e., automatic tools that find good settings for a learner's control parameters. We show that such hyperparameter optimization can be unnecessarily slow, particularly when the optimizers waste time exploring ""redundant tunings"", i.e., pairs of tunings which lead to indistinguishable results. By ignoring redundant tunings, DODGE, a tuning tool, runs orders of magnitude faster, while also generating learners with more accurate predictions than seen in prior state-of-the-art approaches.","1939-3520","","10.1109/TSE.2019.2945020","Directorate for Computer and Information Science and Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854183","Software analytics;hyperparameter optimization;defect prediction;text mining","Tuning;Text mining;Software;Task analysis;Optimization;Software engineering;Tools","","","","5","","","","1 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Requirements, Politics, or Individualism: What Drives the Success of COVID-19 Contact-Tracing Apps?","M. Bano; D. Zowghi; C. Arora","Software Engineering, Deakin University, Australia; Software Engineering, University of Technology Sydney, Australia; Software Engineering, Deakin University, Australia","IEEE Software","23 Dec 2020","2021","38","1","7","12","The year 2020 brought us the global pandemic of COVID-19, which is not just a health crisis but a disruption to the fabric of society around the world. With no vaccine yet approved, other measures have been taken all over the world related to lockdowns, social distancing, and contact tracing to quarantine the infected individuals and suppress community transmission. The numerous challenges presented by this novel coronavirus, such as the incubation period, various symptoms, and asymptomatic superspreaders, have exacerbated the challenges of manual contact tracing.","1937-4194","","10.1109/MS.2020.3029311","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305893","","COVID-19;Pandemics;Government","diseases;epidemics;medical information systems;microorganisms;politics","COVID-19 contact-tracing apps;global pandemic;health crisis;social distancing;infected individuals;manual contact tracing;politics;individualism;community transmission suppression;asymptomatic superspreaders","","1","","10","IEEE","23 Dec 2020","","","IEEE","IEEE Magazines"
"Hybrid Software Development Approaches in Practice: A European Perspective","M. Kuhrmann; P. Diebold; J. Munch; P. Tell; K. Trektere; F. McCaffery; V. Garousi; M. Felderer; O. Linssen; E. Hanser; C. R. Prause","Applied Software Systems Engineering, Clausthal University of Technology; Bagilstein GmbH; Software Engineering, Reutlingen University; Computer Science, IT University of Copenhagen; Regulated Software, Dundalk Institute of Technology; Regulated Software, Dundalk Institute of Technology; Software Engineering, Wageningen University; Computer Science, University of Innsbruck; FOM University of Applied Sciences for Economics and Management; Software Engineering, Baden-Wuerttemberg Cooperative State University; Software Quality Assurance, German Aerospace Center Space Administration","IEEE Software","17 Jun 2019","2019","36","4","20","31","The surveyed companies applied hybrid development approaches to specific projects even when company-wide policies for process usage existed. These approaches emerged from the evolution of different work practices and were consistently used regardless of company size or industry sector.","1937-4194","","10.1109/MS.2018.110161245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254323","computing milieux;management of computing and information systems;software management;software process;software development method;software development practice;agile practices;traditional development approach;hybrid development approach","Software development;Software development management;Software process;Agile software development;Organizational aspects","organisational aspects;software development management","company-wide policies;process usage;hybrid software development approaches;hybrid development approaches;work practices;European perspective","","3","","15","","11 Jan 2018","","","IEEE","IEEE Magazines"
"An Overview and Comparison of Technical Debt Measurement Tools","P. C. Avgeriou; D. Taibi; A. Ampatzoglou; F. Arcelli Fontana; T. Besker; A. Chatzigeorgiou; V. Lenarduzzi; A. Martini; A. Moschou; I. Pigazzini; N. Saarimaki; D. D. Sas; S. S. de Toledo; A. A. Tsintzira","Department of Mathematics and Computing Science, University of Groningen, Groningen, 9747 AG groningen, Netherlands; Faculty of Information Technology and Communication Sciences, Tampere University, Tampere, Pirkanmaa, Finland; Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece; DISCo, University of Milano Bicocca, Milano, 20126 Milano, Italy; Software Engineering , Computer Science and Engineering,, Göteborg, Göteborg, Sweden; Applied Informatics, University of Macedonia, Thessaloniki, 540 06 Thessaloniki, Greece; Department of Computing, Tampere University, Tampere, Pirkanmaa, Finland; Programming and Software Engineering, University of Oslo, Oslo, 0373 Oslo, Norway; Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece; Department of Informatics, Systems and Communications, University of Milan–Bicocca, Milano, Lombardia, Italy; Department of Computing, Tampere University, Tampere, Pirkanmaa, Finland; Bernoulli Instititute For Mathematics, Computer Science, and Artificial Intelligence, University of Groningen, Groningen, 9700 AB Groningen, Netherlands; Programming and Software Engineering, University of Oslo, Oslo, Oslo, Norway; Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece","IEEE Software","19 Apr 2021","2021","38","3","61","71","Different tools adopt different terms, metrics, and ways to identify and measure technical debt. We attempt to clarify the situation by comparing the features and popularity of technical debt measurement tools and analyzing the existing empirical evidence on their validity.","1937-4194","","10.1109/MS.2020.3024958","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200792","Technical Debt;Tools;Source Code Analysis;Software Quality","Economics;Google;Software quality;Software measurement","","","","2","","12","IEEE","18 Sep 2020","","","IEEE","IEEE Magazines"
"Metamorphic Testing: Testing the Untestable","S. Segura; D. Towey; Z. Q. Zhou; T. Y. Chen","Software Engineering, University of Seville, Spain; Computer Science, University of Nottingham, Ningbo, China; Software Engineering, University of Wollongong, Australia; Software Engineering, Swinburne University of Technology, Australia","IEEE Software","15 Apr 2020","2020","37","3","46","53","What if we could know that a program is buggy, even if we could not tell whether or not its observed output is correct? Metamorphic testing provides this ability. This article explains the basics of the technique.","1937-4194","","10.1109/MS.2018.2875968","Australian Research Council; Operational Programme FEDER Andalusia and the Spanish Government; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573811","Software testing;metamorphic testing;oracle problem;test case generation","Search engines;Programming;Australia;Program processors;Software testing","program debugging;program testing","metamorphic testing;observed output;buggy program","","8","","21","","12 Dec 2018","","","IEEE","IEEE Magazines"
"Requirements Engineering Tools: An Evaluation","J. M. Carrillo de Gea; C. Ebert; M. Hosni; A. Vizcaíno; J. Nicolás; J. L. Fernández-Alemán","Software Engineering Research Group, Faculty of Computer Science, University of Murcia, Spain; Vector Consulting Services; MOSI Research Team, High School of Arts and Crafts Meknes, Moulay Ismail University; Alarcos Research Group, Institute of Information Technologies & Systems, Escuela Superior de Inform, University of Castilla-La Mancha, Spain; Software Engineering Research Group, Faculty of Computer Science, University of Murcia, Spain; Software Engineering Research Group, Faculty of Computer Science, University of Murcia, Spain","IEEE Software","19 Apr 2021","2021","38","3","17","24","""If you don't know where you are going, any road will get you there."" Alice from Alice in Wonderland was told this obvious piece of wisdom when she asked for directions. We all know this wisdom from navigating through the fog of insufficient requirements when working on projects. Clear goals can be achieved; unclear goals are sure to be missed. Requirements engineering (RE) is the disciplined and systematic approach (i.e., ""engineering"") for elicitation, documentation, analysis, agreement, verification, and management of requirements while considering market, technical, and economic goals. ""Disciplined"" is about culture, and ""systematic"" demands process and tools, which is our focus here.","1937-4194","","10.1109/MS.2021.3058394","Consejeria de Educacion Cultura y Deportes de la Junta de Comunidades de Castilla La Mancha y Fondo Europeo de Desarrollo Regional FEDER; Ministerio de Ciencia Innovacion y Universidades y Fondo Europeo de Desarrollo Regional FEDER; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408308","","Software tools;Collaboration;Distributed databases;Stakeholders;Software as a service;Scalability","","","","","","8","IEEE","19 Apr 2021","","","IEEE","IEEE Magazines"
"Improving Vulnerability Inspection Efficiency Using Active Learning","Z. Yu; C. Theisen; L. Williams; T. Menzies","Computer science, North Carolina State University, 6798 Raleigh, North Carolina United States (e-mail: zyu9@ncsu.edu); Security, Microsoft Research, 214606 Redmond, Washington United States (e-mail: crtheise@ncsu.edu); Computer Science, North Carolina State University, Raleigh, North Carolina United States 27695-8206 (e-mail: williams@csc.ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Software engineers can find vulnerabilities with less effort if they are directed towards code that might contain more vulnerabilities. HARMLESS is an incremental support vector machine tool that builds a vulnerability prediction model from the source code inspected to date, then suggests what source code files should be inspected next. In this way, HARMLESS can reduce the time and effort required to achieve some desired level of recall for finding vulnerabilities. The tool also provides feedback on when to stop (at that desired level of recall) while at the same time, correcting human errors by double-checking suspicious files. This paper evaluates HARMLESS on Mozilla Firefox vulnerability data. HARMLESS found 80, 90, 95, 99% of the vulnerabilities by inspecting 10, 16, 20, 34% of the source code files. When targeting 90, 95, 99% recall, HARMLESS could stop after inspecting 23, 30, 47% of the source code files. Even when human reviewers fail to identify half of the vulnerabilities (50% false negative rate), HARMLESS could detect 96% of the missing vulnerabilities by double-checking half of the inspected files. Our results serve to highlight the very steep cost of protecting software from vulnerabilities (in our case study that cost is, for example, the human effort of inspecting $28,750 \times 20\% = 5,750$ source code files to identify 95% of the vulnerabilities). While this result could benefit the mission-critical projects where human resources are available for inspecting thousands of source code files, the research challenge for future work is how to further reduce that cost. The conclusion of this paper discusses various ways that goal might be achieved.","1939-3520","","10.1109/TSE.2019.2949275","Division of Computing and Communication Foundations; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883076","Active learning;security;vulnerabilities;software engineering;error correction","Inspection;Software;Tools;Security;Predictive models;Error correction;NIST","","","","3","","","","25 Oct 2019","","","IEEE","IEEE Early Access Articles"
"The Impact of Automated Parameter Optimization on Defect Prediction Models","C. Tantithamthavorn; S. McIntosh; A. E. Hassan; K. Matsumoto","University of Adelaide, Adelaide, SA, Australia; Department of Electrical and Computer Engineering, McGill University, Montréal, Quebec, Canada; Queen's University, Kingston, Ontario, Canada; Nara Institute of Science and Technology, Ikoma, Takayamacho, Japa","IEEE Transactions on Software Engineering","16 Jul 2019","2019","45","7","683","711","Defect prediction models-classifiers that identify defect-prone software modules-have configurable parameters that control their characteristics (e.g., the number of trees in a random forest). Recent studies show that these classifiers underperform when default settings are used. In this paper, we study the impact of automated parameter optimization on defect prediction models. Through a case study of 18 datasets, we find that automated parameter optimization: (1) improves AUC performance by up to 40 percentage points; (2) yields classifiers that are at least as stable as those trained using default settings; (3) substantially shifts the importance ranking of variables, with as few as 28 percent of the top-ranked variables in optimized classifiers also being top-ranked in non-optimized classifiers; (4) yields optimized settings for 17 of the 20 most sensitive parameters that transfer among datasets without a statistically significant drop in performance; and (5) adds less than 30 minutes of additional computation to 12 of the 26 studied classification techniques. While widely-used classification techniques like random forest and support vector machines are not optimization-sensitive, traditionally overlooked techniques like C5.0 and neural networks can actually outperform widely-used techniques after optimization is applied. This highlights the importance of exploring the parameter space when using parameter-sensitive classification techniques.","1939-3520","","10.1109/TSE.2018.2794977","JSPS Program for Advancing Strategic International Networks to Accelerate the Circulation of Talented Researchers; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8263202","Software defect prediction;search-based software engineering;experimental design;classification techniques;parameter optimization;grid search;random search;genetic algorithm;differential evolution","Optimization;Predictive models;Computational modeling;Software;Neural networks;Computational efficiency;Power system stability","optimisation;pattern classification;random forests;software quality;support vector machines","automated parameter optimization;random forest;nonoptimized classifiers;optimized settings;20 most sensitive parameters;parameter space;parameter-sensitive classification techniques;defect prediction models;defect-prone software modules;support vector machines","","12","","154","","18 Jan 2018","","","IEEE","IEEE Journals"
"Revisiting the Performance Evaluation of Automated Approaches for the Retrieval of Duplicate Issue Reports","M. S. Rakha; C. Bezemer; A. E. Hassan","Queen's University, Kingston, ON, Canada; Queen's University, Kingston, ON, Canada; Queen's University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","9 Dec 2018","2018","44","12","1245","1268","Issue tracking systems (ITSs), such as Bugzilla, are commonly used to track reported bugs, improvements and change requests for a software project. To avoid wasting developer resources on previously-reported (i.e., duplicate) issues, it is necessary to identify such duplicates as soon as they are reported. Several automated approaches have been proposed for retrieving duplicate reports, i.e., identifying the duplicate of a new issue report in a list of $n$  candidates. These approaches rely on leveraging the textual, categorical, and contextual information in previously-reported issues to decide whether a newly-reported issue has previously been reported. In general, these approaches are evaluated using data that spans a relatively short period of time (i.e., the classical evaluation). However, in this paper, we show that the classical evaluation tends to overestimate the performance of automated approaches for retrieving duplicate issue reports. Instead, we propose a realistic evaluation using all the reports that are available in the ITS of a software project. We conduct experiments in which we evaluate two popular approaches for retrieving duplicate issues (BM25F and REP) using the classical and realistic evaluations. We find that for the issue tracking data of the Mozilla foundation, the Eclipse foundation and OpenOffice, the realistic evaluation shows that previously proposed approaches perform considerably lower than previously reported using the classical evaluation. As a result, we conclude that the reported performance of approaches for retrieving duplicate issue reports is significantly overestimated in literature. In order to improve the performance of the automated retrieval of duplicate issue reports, we propose to leverage the resolution field of issue reports. Our experiments show that a relative improvement in the performance of a median of 7-21.5 percent and a maximum of 19-60 percent can be achieved by leveraging the resolution field of issue reports for the automated retrieval of duplicates.","1939-3520","","10.1109/TSE.2017.2755005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8048025","Text analysis;software engineering;performance evaluation","Text analysis;Computer bugs;Frequency measurement;Performance evaluation;Manuals;Ports (Computers)","","","","9","","36","","21 Sep 2017","","","IEEE","IEEE Journals"
"A Controlled Experiment with Novice Developers on the Impact of Task Description Granularity on Software Quality in Test-Driven Development","E. I. Karac; B. Turhan; N. Juristo","M3S, Oulun Yliopisto, 6370 Oulu, N/A Finland (e-mail: itir.karac@oulu.fi); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: turhanb@computer.org); Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politecnica de Madrid Facultad de Informatica, 170631 Boadilla del Monte, Comunidad de Madrid Spain (e-mail: natalia@fi.upm.es)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Background: Test-Driven Development (TDD) is an iterative software development process characterized by test-code-refactor cycle. TDD recommends that developers work on small and manageable tasks at each iteration. However, the ability to break tasks into small work items effectively is a learned skill that improves with experience. In experimental studies of TDD, the granularity of task descriptions is an overlooked factor. In particular, providing a more granular task description in terms of a set of sub-tasks versus providing a coarser-grained, generic description. Objective: We aim to investigate the impact of task description granularity on the outcome of TDD, as implemented by novice developers, with respect to software quality, as measured by functional correctness and functional completeness. Method: We conducted a one-factor crossover experiment with 48 graduate students in an academic environment. Each participant applied TDD and implemented two tasks, where one of the tasks was presented using a more granular task description. Resulting artifacts were evaluated with acceptance tests to assess functional correctness and functional completeness. Linear mixed-effects models (LMM) were used for analysis. Results: Software quality improved significantly when participants applied TDD using more granular task descriptions. The effect of task description granularity is statistically significant and had a medium to large effect size. Moreover, the task was found to be a significant predictor of software quality which is an interesting result (because two tasks used in the experiment were considered to be of similar complexity). Conclusion: For novice TDD practitioners, the outcome of TDD is highly coupled with the ability to break down the task into smaller parts. For researchers, task selection and task description granularity requires more attention in the design of TDD experiments. Task description granularity should be taken into account in secondary studies. Further comparative studies are needed to investigate whether task descriptions affect other development processes similarly.","1939-3520","","10.1109/TSE.2019.2920377","Luonnontieteiden ja Tekniikan Tutkimuksen Toimikunta; Ministerio de Ciencia e Innovación; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8727972","Test-driven development;programming task description;controlled experiment;empirical software engineering;crossover experiment;software quality;requirement granularity","Task analysis;Software quality;Productivity;Process control;Atmospheric measurements;Particle measurements","","","","1","","","","3 Jun 2019","","","IEEE","IEEE Early Access Articles"
"The Adoption of JavaScript Linters in Practice: A Case Study on ESLint","K. F. Tómasdóttir; M. Aniche; A. Van Deursen","Delft University of Technology, Delft, CDThe Netherlands; Delft University of Technology, Delft, CDThe Netherlands; Delft University of Technology, Delft, CDThe Netherlands","IEEE Transactions on Software Engineering","13 Aug 2020","2020","46","8","863","891","A linter is a static analysis tool that warns software developers about possible code errors or violations to coding standards. By using such a tool, errors can be surfaced early in the development process when they are cheaper to fix. For a linter to be successful, it is important to understand the needs and challenges of developers when using a linter. In this paper, we examine developers' perceptions on JavaScript linters. We study why and how developers use linters along with the challenges they face while using such tools. For this purpose we perform a case study on ESLint, the most popular JavaScript linter. We collect data with three different methods where we interviewed 15 developers from well-known open source projects, analyzed over 9,500 ESLint configuration files, and surveyed 337 developers from the JavaScript community. Our results provide practitioners with reasons for using linters in their JavaScript projects as well as several configuration strategies and their advantages. We also provide a list of linter rules that are often enabled and disabled, which can be interpreted as the most important rules to reason about when configuring linters. Finally, we propose several feature suggestions for tool makers and future work for researchers.","1939-3520","","10.1109/TSE.2018.2871058","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468105","Static analysis tools;linters;eslint;javascript linters;ASATs;empirical software engineering","Tools;Static analysis;Interviews;Encoding;Standards;Software;Face","authoring languages;program diagnostics","linter rules;static analysis tool;code errors;JavaScript linters;ESLint configuration files;coding standards","","3","","101","IEEE","19 Sep 2018","","","IEEE","IEEE Journals"
"EARMO: An Energy-Aware Refactoring Approach for Mobile Apps","R. Morales; R. Saborido; F. Khomh; F. Chicano; G. Antoniol","Polytechynique Montéal, Montreal, QC, Canada; Polytechynique Montéal, Montreal, QC, Canada; Polytechynique Montéal, Montreal, QC, Canada; University of Málaga, Málaga, Spain; Polytechynique Montéal, Montreal, QC, Canada","IEEE Transactions on Software Engineering","9 Dec 2018","2018","44","12","1176","1206","The energy consumption of mobile apps is a trending topic and researchers are actively investigating the role of coding practices on energy consumption. Recent studies suggest that design choices can conflict with energy consumption. Therefore, it is important to take into account energy consumption when evolving the design of a mobile app. In this paper, we analyze the impact of eight type of anti-patterns on a testbed of 20 android apps extracted from F-Droid. We propose EARMO, a novel anti-pattern correction approach that accounts for energy consumption when refactoring mobile anti-patterns. We evaluate EARMO using three multiobjective search-based algorithms. The obtained results show that EARMO can generate refactoring recommendations in less than a minute, and remove a median of 84 percent of anti-patterns. Moreover, EARMO extended the battery life of a mobile phone by up to 29 minutes when running in isolation a refactored multimedia app with default settings (no Wi-Fi, no location services, and minimum screen brightness). Finally, we conducted a qualitative study with developers of our studied apps, to assess the refactoring recommendations made by EARMO. Developers found 68 percent of refactorings suggested by EARMO to be very relevant.","1939-3520","","10.1109/TSE.2017.2757486","Natural Sciences and Engineering Research Council of Canada (NSERC); Consejo Nacional de Ciencia y Tecnología, México; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052533","Software maintenance;refactoring;anti-patterns;mobile apps;energy consumption;search-based software engineering","Mobile communication;Energy consumption;Software;Androids;Humanoid robots;Energy measurement;Software maintenance","Android (operating system);mobile computing;power aware computing;search problems;smart phones;software maintenance","EARMO;energy-aware refactoring approach;refactoring recommendations;mobile phone;energy consumption;mobile apps;Android apps;antipattern correction approach;mobile antipatterns;F-Droid;multiobjective search-based algorithms","","17","","96","","28 Sep 2017","","","IEEE","IEEE Journals"
"Relations Between Effort Estimates, Skill Indicators, and Measured Programming Skill","M. Jorgensen; G. R. Bergersen; K. Liestol","Simula Metropolitan Center for Digital Engineering and Oslo Metropolitan University, Oslo Norway (e-mail: magnej@simula.no); University of Oslo, Norway (e-mail: gunnab@ifi.uio.no); University of Oslo, Norway (e-mail: knut@ifi.uio.no)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","There are large skill differences among software developers, and clients and managers will benefit from being able to identify those with better skill. This study examines the relations between low effort estimates, and other commonly used skill indicators, and measured programming skill. One hundred and four professional software developers were recruited. After skill-related information was collected, they were asked to estimate the effort for four larger and five smaller programming tasks. Finally, they completed a programming skill test. The lowest and most over-optimistic effort estimates for the larger tasks were given by those with the lowest programming skill, which is in accordance with the well-known Dunning-Kruger effect. For the smaller tasks, however, those with the lowest programming skill had the highest and most over-pessimistic estimates. The other programming skill indicators, such as length of experience, company assessed skill and self-assessed skill, were only moderately correlated with measured skill and not particularly useful in guiding developer skill identification. A practical implication is that for larger and more complex tasks, the use of low effort estimates and commonly used skill indicators as selection criteria leads to a substantial risk of selecting among the least skilled developers.","1939-3520","","10.1109/TSE.2020.2973638","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999628","D.2.9.b Cost estimation;D.2.1.d Management;D.2.0 Software engineering;D.2.0b Software psychology","Task analysis;Software;Companies;Programming profession;Estimation;Java","","","","","","","","14 Feb 2020","","","IEEE","IEEE Early Access Articles"
"Requirements Engineering for Safety-Critical Systems: An Interview Study with Industry Practitioners","L. E. G. Martins; T. Gorschek","Institute of Science and Technology, Federal University of São Paulo, São José dos Campos, Brazil; School of Computing, Blekinge Institute of Technology, Karlskrona, Sweden","IEEE Transactions on Software Engineering","16 Apr 2020","2020","46","4","346","361","We have conducted in-depth interviews with experienced practitioners in the Safety-Critical Systems (SCS) domain in order to investigate several aspects related to requirements specification and safety analysis for SCS. We interviewed 19 practitioners from eleven SCS companies in different domains with the intention of verifying which approaches they use day-to-day, and what their perceptions are in relation to the approaches used to elicit, analyze, specify and validate safety requirements. The aim of this study is to obtain an in-depth understanding of how requirements engineering is carried out in companies that develop SCS.","1939-3520","","10.1109/TSE.2018.2854716","Federal University of São Paulo; Conselho Nacional de Desenvolvimento Científico e Tecnológico; The Knowledge Foundation in Sweden; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409284","Requirements;specification;software and system safety;requirements engineering;safety critical systems;software engineering;SCS","Safety;Companies;Requirements engineering;Software;Certification;Interviews;Unified modeling language","formal specification;safety;safety-critical software;systems analysis","requirements specification;safety-critical systems domain;experienced practitioners;in-depth interviews;industry practitioners;requirements engineering;safety requirements;day-to-day;safety analysis","","5","","52","IEEE","10 Jul 2018","","","IEEE","IEEE Journals"
"Integrating Technical Debt Management and Software Quality Management Processes: A Normative Framework and Field Tests","N. Ramasubbu; C. F. Kemerer","University of Pittsburgh, Pittsburgh, PA; University of Pittsburgh, Pittsburgh, PA","IEEE Transactions on Software Engineering","13 Mar 2019","2019","45","3","285","300","Despite the increasing awareness of the importance of managing technical debt in software product development, systematic processes for implementing technical debt management in software production have not been readily available. In this paper we report on the development and field tests of a normative process framework that systematically incorporates steps for managing technical debt in commercial software production. The framework integrates processes required for technical debt management with existing software quality management processes prescribed by the project management body of knowledge (PMBOK), and it contributes to the further development of software-specific extensions to the PMBOK. We partnered with three commercial software product development organizations to implement the framework in real-world software production settings. All three organizations, irrespective of their varying software process maturity levels, were able to adopt the proposed framework and integrate the prescribed technical debt management processes with their existing software quality management processes. Our longitudinal observations and case-study interviews indicate that the organizations were able to accrue economic benefits from the adoption and use of the integrated framework.","1939-3520","","10.1109/TSE.2017.2774832","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114229","Technical debt;software quality;software maintenance;software engineering economics;cost of quality;software product development;software process;software extension to PMBOK;case study","Software quality;Business;Economics;Product development;Tools;Systematics","economics;product development;project management;quality management;software development management;software quality","field tests;normative process framework;commercial software production;software process maturity levels;software production settings;software quality management processes;technical debt management processes;project management body of knowledge;commercial software product development organizations;software-specific extensions","","6","","49","","17 Nov 2017","","","IEEE","IEEE Journals"
"An Interactive and Dynamic Search-Based Approach to Software Refactoring Recommendations","V. Alizadeh; M. Kessentini; M. W. Mkaouer; M. Ocinneide; A. Ouni; Y. Cai","University of Michigan, Dearborn, MI, USA; University of Michigan, Dearborn, MI, USA; Rochester Institute of Technology, Rochester, NY, USA; University College Dublin, Dublin 4, Ireland; ETS, Montreal, QC, Canada; Drexel University, Philadelphia, PA, USA","IEEE Transactions on Software Engineering","17 Sep 2020","2020","46","9","932","961","Successful software products evolve through a process of continual change. However, this process may weaken the design of the software and make it unnecessarily complex, leading to significantly reduced productivity and increased fault-proneness. Refactoring improves the software design while preserving overall functionality and behavior, and is an important technique in managing the growing complexity of software systems. Most of the existing work on software refactoring uses either an entirely manual or a fully automated approach. Manual refactoring is time-consuming, error-prone and unsuitable for large-scale, radical refactoring. On the other hand, fully automated refactoring yields a static list of refactorings which, when applied, leads to a new and often hard to comprehend design. Furthermore, it is difficult to merge these refactorings with other changes performed in parallel by developers. In this paper, we propose a refactoring recommendation approach that dynamically adapts and interactively suggests refactorings to developers and takes their feedback into consideration. Our approach uses NSGA-II to find a set of good refactoring solutions that improve software quality while minimizing the deviation from the initial design. These refactoring solutions are then analyzed to extract interesting common features between them such as the frequently occurring refactorings in the best non-dominated solutions. Based on this analysis, the refactorings are ranked and suggested to the developer in an interactive fashion as a sequence of transformations. The developer can approve, modify or reject each of the recommended refactorings, and this feedback is then used to update the proposed rankings of recommended refactorings. After a number of introduced code changes and interactions with the developer, the interactive NSGA-II algorithm is executed again on the new modified system to repair the set of refactoring solutions based on the new changes and the feedback received from the developer. We evaluated our approach on a set of eight open source systems and two industrial projects provided by an industrial partner. Statistical analysis of our experiments shows that our dynamic interactive refactoring approach performed significantly better than four existing search-based refactoring techniques and one fully-automated refactoring tool not based on heuristic search.","1939-3520","","10.1109/TSE.2018.2872711","Ford Motor Company; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477161","Search-based software engineering;Refactoring;interactive optimization;software quality","Manuals;Tools;Software quality;Maintenance engineering;Optimization;Electronic mail","genetic algorithms;search problems;software maintenance;software quality;software tools;statistical analysis","software refactoring recommendations;software products;software design;software systems;manual refactoring;software quality;dynamic interactive refactoring approach;search-based refactoring;interactive search-based approach;dynamic search-based approach;interactive NSGA-II algorithm;statistical analysis","","1","","62","IEEE","30 Sep 2018","","","IEEE","IEEE Journals"
"The Impact of Code Review on Architectural Changes","M. Paixao; J. Krinke; D. Han; C. Ragkhitwetsagul; M. Harman","State University of Ceara, Fortaleza, CE, Brazil; Centre for Research in Search, Testing and Evolution (CREST), University College London, London, United Kingdom; Centre for Research in Search, Testing and Evolution (CREST), University College London, London, United Kingdom; Faculty of Information and Communication Technology, Mahidol University, Salaya, Nakhon Pathom, Thailand; Centre for Research in Search, Testing and Evolution (CREST), University College London, London, United Kingdom","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","1041","1059","Although considered one of the most important decisions in the software development lifecycle, empirical evidence on how developers perform and perceive architectural changes remains scarce. Architectural decisions have far-reaching consequences yet, we know relatively little about the level of developers’ awareness of their changes’ impact on the software’s architecture. We also know little about whether architecture-related discussions between developers lead to better architectural changes. To provide a better understanding of these questions, we use the code review data from 7 open source systems to investigate developers’ intent and awareness when performing changes alongside the evolution of the changes during the reviewing process. We extracted the code base of 18,400 reviews and 51,889 revisions. 4,171 of the reviews have changes in their computed architectural metrics, and 731 present significant changes to the architecture. We manually inspected all reviews that caused significant changes and found that developers are discussing the impact of their changes on the architectural structure in only 31% of the cases, suggesting a lack of awareness. Moreover, we noticed that in 73% of the cases in which developers provided architectural feedback during code review, the comments were addressed, where the final merged revision tended to exhibit higher architectural improvement than reviews in which the system’s structure is not discussed.","1939-3520","","10.1109/TSE.2019.2912113","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8697147","Software architecture;code reviews;empirical software engineering","Computer architecture;Couplings;Software systems;Measurement;Software architecture;Agriculture;Java","","","","3","","59","IEEE","23 Apr 2019","","","IEEE","IEEE Journals"
"Uncovering the Benefits and Challenges of Continuous Integration Practices","O. Elazhary; C. Werner; Z. S. Li; D. Lowlind; N. A. Ernst; M. -A. Storey","Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8P 5C2 (e-mail: omazhary@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8P 5C2 (e-mail: colinwerner@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: zanelib1@gmail.com); Computer Science, University of Victoria, Victoria, British Columbia, Canada, (e-mail: dereklowlind@uvic.ca); Computer Science, University of Victoria, 8205 Victoria, British Columbia, Canada, (e-mail: nernst@uvic.ca); Computer Science, University of Victoria, Victoria, British Columbia, Canada, V8P 3W6 (e-mail: mstorey@uvic.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","In 2006, Fowler and Foemmel defined ten core Continuous Integration (CI) practices that could increase the speed of software development feedback cycles and improve software quality. Since then, these practices have been widely adopted by industry and subsequent research has shown they improve software quality. However, there is poor understanding of how organizations implement these practices, of the benefits developers perceive they bring, and of the challenges developers and organizations experience in implementing them. In this paper, we discuss a multiple-case study of three small- to medium-sized companies using the recommended suite of ten CI practices. Using interviews and activity log mining, we learned that these practices are broadly implemented but how they are implemented varies depending on their perceived benefits, the context of the project, and the CI tools used by the organization. We also discovered that CI practices can create new constraints on the software process that hurt feedback cycle time. For researchers, we show that how CI is implemented varies, and thus studying CI (for example, using data mining) requires understanding these differences as important context for research studies. For practitioners, our findings reveal in-depth insights on the possible benefits and challenges from using the ten practices, and how project context matters.","1939-3520","","10.1109/TSE.2021.3064953","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9374092","Software engineering;automation;continuous integration;continuous software development","Tools;Software;Companies;Built-in self-test;Software quality;Complexity theory;Computer bugs","","","","1","","","IEEE","9 Mar 2021","","","IEEE","IEEE Early Access Articles"
"An Integrated Approach for Effective Injection Vulnerability Analysis of Web Applications Through Security Slicing and Hybrid Constraint Solving","J. Thomé; L. K. Shar; D. Bianculli; L. Briand","Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg; Interdisciplinary Centre for Security, Reliability, and Trust (SnT), University of Luxembourg, Kennedy, Luxembourg","IEEE Transactions on Software Engineering","12 Feb 2020","2020","46","2","163","195","Malicious users can attack Web applications by exploiting injection vulnerabilities in the source code. This work addresses the challenge of detecting injection vulnerabilities in the server-side code of Java Web applications in a scalable and effective way. We propose an integrated approach that seamlessly combines security slicing with hybrid constraint solving; the latter orchestrates automata-based solving with meta-heuristic search. We use static analysis to extract minimal program slices relevant to security from Web programs and to generate attack conditions. We then apply hybrid constraint solving to determine the satisfiability of attack conditions and thus detect vulnerabilities. The experimental results, using a benchmark comprising a set of diverse and representative Web applications/services as well as security benchmark applications, show that our approach (implemented in the JOACO tool) is significantly more effective at detecting injection vulnerabilities than state-of-the-art approaches, achieving 98 percent recall, without producing any false alarm. We also compared the constraint solving module of our approach with state-of-the-art constraint solvers, using six different benchmark suites; our approach correctly solved the highest number of constraints (665 out of 672), without producing any incorrect result, and was the one with the least number of time-out/failing cases. In both scenarios, the execution time was practically acceptable, given the offline nature of vulnerability detection.","1939-3520","","10.1109/TSE.2018.2844343","Qatar National Research Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8373739","Vulnerability detection;constraint solving;static analysis;search-based software engineering","Security;Benchmark testing;Tools;Explosions;Java;Static analysis;Reliability","constraint handling;Internet;Java;program slicing;search problems;security of data","security slicing;hybrid constraint solving;injection vulnerabilities;source code;Java Web applications;minimal program slices;Web programs;attack conditions;security benchmark applications;constraint solving module;constraint solvers;vulnerability detection;injection vulnerability analysis;efficiency 98.0 percent","","","","100","IEEE","6 Jun 2018","","","IEEE","IEEE Journals"
"Engineering Trustworthy Self-Adaptive Software with Dynamic Assurance Cases","R. Calinescu; D. Weyns; S. Gerasimou; M. U. Iftikhar; I. Habli; T. Kelly","Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, Katholieke Universiteit Leuven, Leuven, Belgium; Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, Linnaeus University, Växjö, Sweden; Department of Computer Science, University of York, York, United Kingdom; Department of Computer Science, University of York, York, United Kingdom","IEEE Transactions on Software Engineering","11 Nov 2018","2018","44","11","1039","1069","Building on concepts drawn from control theory, self-adaptive software handles environmental and internal uncertainties by dynamically adjusting its architecture and parameters in response to events such as workload changes and component failures. Self-adaptive software is increasingly expected to meet strict functional and non-functional requirements in applications from areas as diverse as manufacturing, healthcare and finance. To address this need, we introduce a methodology for the systematic ENgineering of TRUstworthy Self-adaptive sofTware (ENTRUST). ENTRUST uses a combination of (1) design-time and runtime modelling and verification, and (2) industry-adopted assurance processes to develop trustworthy self-adaptive software and assurance cases arguing the suitability of the software for its intended application. To evaluate the effectiveness of our methodology, we present a tool-supported instance of ENTRUST and its use to develop proof-of-concept self-adaptive software for embedded and service-based systems from the oceanic monitoring and e-finance domains, respectively. The experimental results show that ENTRUST can be used to engineer self-adaptive software systems in different application domains and to generate dynamic assurance cases for these systems.","1939-3520","","10.1109/TSE.2017.2738640","Defence Science and Technology Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8008800","Self-adaptive software systems;software engineering methodology;assurance evidence;assurance cases","Software systems;Control systems;Runtime;Monitoring;Computer architecture;Adaptive systems","embedded systems;formal verification;software architecture;trusted computing","self-adaptive software handles;nonfunctional requirements;ENTRUST;industry-adopted assurance processes;engineering trustworthy;control theory;engineering of trustworthy self-adaptive software systems;service-based systems;oceanic monitoring;e-finance domains;embedded software;software architecture","","28","","132","","11 Aug 2017","","","IEEE","IEEE Journals"
"Studying the Impact of Noises in Build Breakage Data","T. A. Ghaleb; D. Alencar da Costa; Y. Zou; A. E. Hassan","School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: taher.a.ghaleb@gmail.com); Information Science, University of Otago, 2495 Dunedin, 9054 New Zealand (e-mail: daniel.calencar@gmail.com); Electrical and Computer Engineering, Queen's University, 4257 Kingston, Ontario Canada (e-mail: ying.zou@queensu.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Much research has investigated the common reasons for build breakages. However, prior research has paid little attention to builds that may break due to reasons that are unlikely to be related to development activities. For example, Continuous Integration(CI) builds may break due to timeout or connection errors while generating the build. Such kinds of build breakages potentially introduce noises to build breakage data. Not considering such noises may lead to misleading results when studying CI builds. In this paper, we propose three criteria to identify build breakages that can potentially introduce noises to build breakage data. We apply these criteria to a dataset of 350,246 builds from153 GitHub projects that are linked with Travis CI. Our results reveal that 33% of the build breakages are due to environmental factors (e.g., errors in CI servers), 29% are due to (unfixed) errors in previous builds, and 9% are due to build jobs that were later deemed by developers as noisy (there is an overlap of 17% between these three types of breakages). We measure the impact of noises in build breakage data on modeling build breakages. We observe that models that use uncleaned build breakage data can lead to misleading associations between build breakages and development activities (e.g., the role of developer). However, such associations could not be observed after eliminating noisy build breakages. Moreover, we replicate a prior study that investigates the association between build breakages and development activities using data from 14 GitHub projects. We observe that some observations reported by the prior study (e.g., pull requests cause more breakages) do not hold after eliminating the noises from build breakage data.","1939-3520","","10.1109/TSE.2019.2941880","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839858","Continuous Integration;CI build breakages;Noisy data;Mining software repositories;Empirical software engineering","Noise measurement;Data models;Software;Environmental factors;Servers;Indexes","","","","","","","","16 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Within-Project Defect Prediction of Infrastructure-as-Code Using Product and Process Metrics","S. Dalla Palma; D. Di Nucci; F. Palomba; D. A. Tamburri","Jheronimus Academy of Data Science, Tilburg University, 7899 's-Hertogenbosch, Noord-Brabant, Netherlands, (e-mail: s.dallapalma@uvt.nl); Jheronimus Academy of Data Science, Tilburg University, 7899 's-Hertogenbosch, Noord-Brabant, Netherlands, (e-mail: d.dinucci@uvt.nl); Department of Computer Science, Universita degli Studi di Salerno, 19028 Fisciano, Campania, Italy, (e-mail: fpalomba@unisa.it); Computer Science, University of Technology Eindhoven, 3169 Eindhoven, Noord-Brabant, Netherlands, (e-mail: d.a.tamburri@tue.nl)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Infrastructure-as-code (IaC) is the DevOps practice enabling management and provisioning of infrastructure through the definition of machine-readable files, hereinafter referred to as IaC scripts. Similarly to other source code artefacts, these files may contain defects that can preclude their correct functioning. In this paper, we aim at assessing the role of product and process metrics when predicting defective IaC scripts. We propose a fully integrated machine-learning framework for IaC Defect Prediction, that allows for repository crawling, metrics collection, model building, and evaluation. To evaluate it, we analyzed 104 projects and employed five machine-learning classifiers to compare their performance in flagging suspicious defective IaC scripts. The key results of the study report Random Forest as the best-performing model, with a median AUC-PR of 0.93 and MCC of 0.80. Furthermore, at least for the collected projects, product metrics identify defective IaC scripts more accurately than process metrics. Our findings put a baseline for investigating IaC Defect Prediction and the relationship between the product and process metrics, and IaC scripts' quality.","1939-3520","","10.1109/TSE.2021.3051492","Horizon 2020 Framework Programme; Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321740","Infrastructure-as-code;Defect Prediction;Empirical Software Engineering","Measurement;Software;Predictive models;Machine learning;Radon;Cloud computing;Task analysis","","","","","","","CCBY","13 Jan 2021","","","IEEE","IEEE Early Access Articles"
"The Assessor's Dilemma: Improving Bug Repair via Empirical Game Theory","C. Gavidia-Calderon; F. Sarro; M. Harman; E. T. Barr","Computer Science, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: cgavidiac@gmail.com); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland WC1E 6B (e-mail: f.sarro@ucl.ac.uk); CS, Facebook London, 507852 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: mark.harman@ucl.ac.uk); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland WC1E 6BT (e-mail: e.barr@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Priority inflation occurs when a QA engineer or a project manager requesting a feature inflates the priority of their task so that developers deliver the fix or the new functionality faster. We survey developers and show that priority inflation occurs and misallocates developer time. We are the first to apply empirical game-theoretic analysis (EGTA) to a software engineering problem, specifically priority inflation. First, we extract prioritization strategies from 42,620 issues from Apache's JIRA, then use TaskAssessor, our EGTA-based modelling approach, to confirm conventional wisdom and show that the common process of a QA engineer assigning priority labels is susceptible to priority inflation. We then show that the common mitigation strategy of having a bug triage team assigning priorities does not resolve priority inflation and slows development. We then use mechanism design to devise assessor-throttling, a new, lightweight prioritization process, immune to priority inflation. We show that assessor-throttling resolves 97% of high priority tasks, 69% better than simply relying on those filing tasks to assign their priorities. Finally, we present TheFed, a browser extension for Chrome that supports assessor-throttling.","1939-3520","","10.1109/TSE.2019.2944608","Dynamic Adaptive Automated Software Engineering Programme Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852726","Software Process;Game Theory;Bug Report;Priority Inflation","Task analysis;Computer bugs;Logic gates;Games;Nash equilibrium;Software","","","","","","","","30 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Watch out for Extrinsic Bugs! A Case Study of their Impact in Just-In-Time Bug Prediction Models on the OpenStack project","G. Rodriguezperez; M. Nagappan; G. Robles","Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: gema.rodriguez-perez@uwaterloo.ca); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: mei.nagappan@uwaterloo.ca); Sistemas Telematicos y Computacion, Universidad Rey Juan Carlos, 16776 Madrid, Madrid, Spain, (e-mail: grex@gsyc.urjc.es)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Intrinsic bugs are bugs for which a bug-introducing change can be identified in the version control system of a software. In contrast, extrinsic bugs are caused by external changes to a software, such as errors in external APIs; thereby they do not have an explicit bug-introducing change in the version control system. Although most previous research literature has assumed that all bugs are of intrinsic nature, in a previous study, we show that not all bugs are intrinsic. This paper shows an example of how considering extrinsic bugs can affect software engineering research. Specifically, we study the impact of extrinsic bugs in Just-In-Time bug prediction by partially replicating a recent study by McIntosh and Kamei on JIT models. These models are trained using properties of earlier bug-introducing changes. Since extrinsic bugs do not have bug-introducing changes in the version control system, we manually curate McIntosh and Kamei's dataset to distinguish between intrinsic and extrinsic bugs. Then, we address their original research questions, this time removing extrinsic bugs, to study whether bug-introducing changes are a moving target in Just-In-Time bug prediction. Finally, we study whether characteristics of intrinsic and extrinsic bugs are different. Our results show that intrinsic and extrinsic bugs are of different nature. When removing extrinsic bugs the performance is different up to 16 % Area Under the Curve points. This indicates that our JIT models obtain a more accurate representation of the real world. We conclude that extrinsic bugs negatively impact Just-In-Time models. Furthermore, we offer evidence that extrinsic bugs should be further investigated, as they can significantly impact how software engineers understand bugs.","1939-3520","","10.1109/TSE.2020.3021380","Ministerio de Economa Industria y Competitividad Gobierno de Espaa; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9185031","Bugs;Extrinsic Bugs;Intrinsic Bugs;Mislabeled Bugs;Bug-introducing changes;Just-In-Time;Bug Prediction","Computer bugs;Predictive models;Software;Data models;Control systems;Analytical models;Context modeling","","","","","","","","2 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Multi-Objective Software Effort Estimation: A Replication Study","V. Tawosi; F. Sarro; A. Petrozziello; M. Harman","Computer Science, University College London, 4919 London, London,City of, United Kingdom of Great Britain and Northern Ireland, WC1E 6BT (e-mail: vali.tawosi@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: a.petrozziello@ucl.ac.uk); CS, Facebook London, 507852 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Replication studies increase our confidence in previous results when the findings are similar each time, and help mature our knowledge by addressing both internal and external validity aspects. However, these studies are still rare in certain software engineering fields. In this paper, we replicate and extend a previous study, which denotes the current state-of-the-art for multi-objective software effort estimation, namely CoGEE. We investigate the original research questions with an independent implementation and the inclusion of a more robust baseline (LP4EE), carried out by the first author, who was not involved in the original study. Through this replication, we strengthen both the internal and external validity of the original study. We also answer two new research questions investigating the effectiveness of CoGEE by using four additional evolutionary algorithms (i.e., IBEA, MOCell, NSGA-III, SPEA2) and a well-known Java framework for evolutionary computation, namely JMetal (rather than the previously used R software), which allows us to strengthen the external validity of the original study. The results of our replication confirm that: (1) CoGEE outperforms both baseline and state-of-the-art benchmarks statistically significantly (p < 0.001); (2) CoGEEs multi-objective nature makes it able to reach such a good performance; (3) CoGEEs estimation errors lie within claimed industrial human-expert-based thresholds. Moreover, our new results show that the effectiveness of CoGEE is generally not limited to nor dependent on the choice of the multi-objective algorithm. Using CoGEE with either NSGA-II, NSGA-III, or MOCell produces human competitive results in less than a minute. The Java version of CoGEE has decreased the running time by over 99.8% with respect to its R counterpart. We have made publicly available the Java code of CoGEE to ease its adoption, as well as, the data used in this study in order to allow for future replication and extension of our work.","1939-3520","","10.1109/TSE.2021.3083360","European Research Council Advanced Fellowship Grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9440773","Software effort estimation;multi-objective evolutionary algorithm;confidence interval;estimates uncertainty","Estimation;Software;Predictive models;Prediction algorithms;Evolutionary computation;Java;Software measurement","","","","","","","IEEE","25 May 2021","","","IEEE","IEEE Early Access Articles"
"DiffTech: Differencing Similar Technologies from Crowd-Scale Comparison Discussions","H. Wang; C. Chen; Z. Xing; J. Grundy","Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: freddie.wanah@gmail.com); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: chunyang.chen@monash.edu); College of Engineering & Computer Science, Australian National University, 2219 Canberra, Australian Capital Territory, Australia, (e-mail: zhenchang.xing@anu.edu.au); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Developers use different technologies for many software development tasks. However, when faced with several technologies with comparable functionalities, it is not easy to select the most appropriate one, as trial and error comparisons among such technologies are time-consuming. Instead, developers can resort to expert articles, read official documents or ask questions in Q&A sites. However, it still remains difficult to get a comprehensive comparison as online information is often fragmented or contradictory. To overcome these limitations, we propose the DiffTech system that exploits crowdsourced discussions from Stack Overflow, and assists technology comparison with an informative summary of different aspects. We first build a large database of comparable technologies in software engineering by mining tags in Stack Overflow. We then locate comparative sentences about comparable technologies with natural language processing methods. We further mine prominent comparison aspects by clustering similar comparative sentences and representing each cluster with its keywords and aggregate the overall opinion towards the comparable technologies. Our evaluation demonstrates both the accuracy and usefulness of our model, and we have implemented our approach as a practical website for public use.","1939-3520","","10.1109/TSE.2021.3059885","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9356217","comparing and differencing similar technology;Stack Overflow;natural language processing;NLP","Libraries;Tools;Natural language processing;Aggregates;Task analysis;Tagging;Data mining","","","","","","","IEEE","17 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Requirements of API Documentation: A Case Study into Computer Vision Services","A. Cummaudo; R. Vasa; J. Grundy; M. Abdelrazek","Applied Artificial Intelligence Institute, Deakin University, 2104 Geelong, Victoria, Australia, (e-mail: ca@deakin.edu.au); Applied Artificial Intelligence Institute, Deakin University, 2104 Geelong, Victoria, Australia, (e-mail: rajesh.vasa@deakin.edu.au); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: john.grundy@monash.edu); School of Information Technology, Deakin University, 2104 Geelong, Victoria, Australia, (e-mail: mohamed.abdelrazek@deakin.edu.au)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Using cloud-based computer vision services is gaining traction, where developers access AI-powered components through familiar RESTful APIs, not needing to orchestrate large training and inference infrastructures or curate/label training datasets. However, while these APIs seem familiar to use, their non-deterministic run-time behaviour and evolution is not adequately communicated to developers. Therefore, improving these services' API documentation is paramount-more extensive documentation facilitates the development process of intelligent software. In a prior study, we extracted 34 API documentation artefacts from 21 seminal works, devising a taxonomy of five key requirements to produce quality API documentation. We extend this study in two ways. Firstly, by surveying 104 developers of varying experience to understand what API documentation artefacts are of most value to practitioners. Secondly, identifying which of these highly-valued artefacts are or are not well-documented through a case study in the emerging computer vision service domain. We identify: (i) several gaps in the software engineering literature, where aspects of API documentation understanding is/is not extensively investigated; and (ii) where industry vendors (in contrast) document artefacts to better serve their end-developers. We provide a set of recommendations to enhance intelligent software documentation for both vendors and the wider research community.","1939-3520","","10.1109/TSE.2020.3047088","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307242","Intelligent Web Services and Semantic Web;Code Documentation;Computer Vision","Documentation;Taxonomy;Computer vision;Usability;Guidelines;Measurement;Tools","","","","","","","","24 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Measuring Program Comprehension: A Large-Scale Field Study with Professionals","X. Xia; L. Bao; D. Lo; Z. Xing; A. E. Hassan; S. Li","Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China; Singapore Management University, Singapore; Australian National University, Canberra, ACT, Australia; Queen’s University, Kingston, ON, Canada; Zhejiang University, Hangzhou, China","IEEE Transactions on Software Engineering","14 Oct 2018","2018","44","10","951","976","During software development and maintenance, developers spend a considerable amount of time on program comprehension activities. Previous studies show that program comprehension takes up as much as half of a developer's time. However, most of these studies are performed in a controlled setting, or with a small number of participants, and investigate the program comprehension activities only within the IDEs. However, developers' program comprehension activities go well beyond their IDE interactions. In this paper, we extend our ActivitySpace framework to collect and analyze Human-Computer Interaction (HCI) data across many applications (not just the IDEs). We follow Minelli et al.'s approach to assign developers' activities into four categories: navigation, editing, comprehension, and other. We then measure the comprehension time by calculating the time that developers spend on program comprehension, e.g., inspecting console and breakpoints in IDE, or reading and understanding tutorials in web browsers. Using this approach, we can perform a more realistic investigation of program comprehension activities, through a field study of program comprehension in practice across a total of seven real projects, on 78 professional developers, and amounting to 3,148 working hours. Our study leverages interaction data that is collected across many applications by the developers. Our study finds that on average developers spend ~58 percent of their time on program comprehension activities, and that they frequently use web browsers and document editors to perform program comprehension activities. We also investigate the impact of programming language, developers' experience, and project phase on the time that is spent on program comprehension, and we find senior developers spend significantly less percentages of time on program comprehension than junior developers. Our study also highlights the importance of several research directions needed to reduce program comprehension time, e.g., building automatic detection and improvement of low quality code and documentation, construction of software-engineering-specific search engines, designing better IDEs that help developers navigate code and browse information more efficiently, etc.","1939-3520","","10.1109/TSE.2017.2734091","National Natural Science Foundation of China; National Key Technology R&D Program; Ministry of Science and Technology of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7997917","Program comprehension;field study;inference model","Navigation;Software;Time measurement;Browsers;Maintenance engineering;Programming;Debugging","human computer interaction;Internet;program compilers;reverse engineering;search engines;software maintenance","program comprehension activities;program comprehension time;developers time;software development;software maintenance;IDE interactions;ActivitySpace framework;human computer interaction;Web browsers;programming language;project phase;software-engineering;search engines","","15","","63","","31 Jul 2017","","","IEEE","IEEE Journals"
"On the Understandability of Temporal Properties Formalized in Linear Temporal Logic, Property Specification Patterns and Event Processing Language","C. Czepa; U. Zdun","Faculty of Computer Science, Research Group Software Architecture, University of Vienna, Vienna, Austria; Faculty of Computer Science, Research Group Software Architecture, University of Vienna, Vienna, Austria","IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","100","112","Temporal properties are important in a wide variety of domains for different purposes. For example, they can be used to avoid architectural drift in software engineering orto support the regulatory compliance of business processes. In this work, we study the understandability of three majortemporal property representations: (1) LinearTemporal Logic (LTL) is a formal and well-established logic that offers temporal operators to describe temporal properties; (2) Property Specification Patterns (PSP) are a collection of recurring temporal properties that abstract underlying formal and technical representations; (3) Event Processing Language (EPL) can be used for runtime monitoring of event streams using Complex Event Processing. We conducted two controlled experiments with 216 participants in total to study the understandability of those approaches using a completely randomized design with one alternative per experimental unit. We hypothesized that PSP, as a highly abstracting pattern language, is easier to understand than LTL and EPL, and that EPL, due to separation of concerns (as one or more queries can be used to explicitly define the truth value change that an observed event pattern causes), is easier to understand than LTL. We found evidence supporting our hypotheses which was statistically significant and reproducible.","1939-3520","","10.1109/TSE.2018.2859926","Austrian Research Promotion Agency; Austrian Science Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419310","Controlled experiment;understandability;temporal property;linear temporal logic;property specification patterns;complex event processing;event processing language","Software;Computer science;Guidelines;Industries;Software architecture;Cognition","formal specification;formal verification;pattern recognition;temporal logic","temporal properties;linear temporal Logic;business processes;complex event processing;property specification patterns;event processing language;software engineering","","1","","71","IEEE","25 Jul 2018","","","IEEE","IEEE Journals"
"Just-In-Time Defect Identification and Localization: A Two-Phase Framework","M. Yan; X. Xia; Y. Fan; A. E. Hassan; D. Lo; S. Li","School of Big Data and Software Engineering, Chongqing University, 47913 Chongqing, Sichuan China (e-mail: mengy@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: yrfan@zju.edu.cn); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: shan@zju.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Defect localization aims to locate buggy program elements (e.g., buggy files, methods or lines of code) based on defect symptoms, e.g., bug reports or program spectrum. However, when we receive the defect symptoms, the defect has been exposed and negative impacts have been introduced. Thus, one challenging task is: whether we can locate buggy program prior to appearance of the defect symptom at an early time (e.g., when buggy program elements are being checked-in). We refer to this type of defect localization as “Just-In-Time (JIT) Defect localization”. Although many prior studies have proposed various JIT defect identification methods to identify whether a new change is buggy, these prior methods do not locate the suspicious positions. Thus, JIT defect localization is the next step of JIT defect identification (i.e., after a buggy change is identified, suspicious source code lines are located). To address this problem, we propose a two-phase framework, i.e., JIT defect identification and JIT defect localization. Given a new change, JIT defect identification will identify it as buggy change or clean change first. If a new change is identified as buggy, JIT defect localization will rank the source code lines introduced by the new change according to their suspiciousness scores. The source code lines ranked at the top of the list are estimated as the defect location. For JIT defect identification phase, we use 14 change-level features to build a classifier by following existing approach. For JIT defect localization phase, we propose a JIT defect localization approach that leverages software naturalness with the N-gram model. To evaluate the proposed framework, we conduct an empirical study on 14 open source projects with a total of 177,250 changes. The results show that software naturalness is effective for our JIT defect localization. Our model achieves a reasonable performance, and outperforms the two baselines (i.e., random guess and a static bug finder (i.e., PMD)) by a substantial margin in terms of four ranking measures.","1939-3520","","10.1109/TSE.2020.2978819","China Postdoctoral Science Foundation; Australian Research Councils Discovery Early Career Researcher Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9026802","Defect Localization;Just-in-Time;Defect Identification;Software Naturalness","Software;Computer bugs;Task analysis;History;Fans;Computer science","","","","2","","","","6 Mar 2020","","","IEEE","IEEE Early Access Articles"
"Automatically ‘Verifying’ Discrete-Time Complex Systems through Learning, Abstraction and Refinement","J. Wang; J. Sun; S. Qin; C. Jegourel","College of Computer Science and Software Engineering, Shenzhen University, Shenzhen, China; Singapore University of Technology and Design, Singapore; School of Computing, Media and the Arts, Teesside University, Middlesbrough, United Kingdom; Singapore University of Technology and Design, Singapore","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","189","203","Precisely modeling complex systems like cyber-physical systems is challenging, which often renders model-based system verification techniques like model checking infeasible. To overcome this challenge, we propose a method called LAR to automatically `verify' such complex systems through a combination of learning, abstraction and refinement from a set of system log traces. We assume that log traces and sampling frequency are adequate to capture `enough' behaviour of the system. Given a safety property and the concrete system log traces as input, LAR automatically learns and refines system models, and produces two kinds of outputs. One is a counterexample with a bounded probability of being spurious. The other is a probabilistic model based on which the given property is `verified'. The model can be viewed as a proof obligation, i.e., the property is verified if the model is correct. It can also be used for subsequent system analysis activities like runtime monitoring or model-based testing. Our method has been implemented as a self-contained software toolkit. The evaluation on multiple benchmark systems as well as a real-world water treatment system shows promising results.","1939-3520","","10.1109/TSE.2018.2886898","National Natural Science Foundation of China; Science and Technology Foundation of Shenzhen City; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576657","Verification;model learning;abstraction refinement;cyber-physical system","Probabilistic logic;Model checking;Analytical models;Safety;Complex systems;System analysis and design","computational complexity;distributed processing;formal verification;large-scale systems;learning (artificial intelligence);probability;program verification","real-world water treatment system;multiple benchmark systems;subsequent system analysis activities;given property;probabilistic model;system models;concrete system;safety property;log traces;abstraction;automatically verify such complex systems;LAR;model-based system verification techniques;cyber-physical systems;discrete-time complex systems","","1","","59","IEEE","14 Dec 2018","","","IEEE","IEEE Journals"
"Quantitative Verification for Monitoring Event-Streaming Systems","G. Su; L. Liu; M. Zhang; D. Rosenblum","School of Computing and Information Technology, University of Wollongong, 8691 Wollongong, New South Wales Australia (e-mail: guoxin@uow.edu.au); School of Software Engineering, Chongqing University, 47913 Chongqing, Chongqing China (e-mail: dcsliuli@cqu.edu.cn); School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: minjie@uow.edu.au); School of Computing, National University of Singapore, Singapore, Singapore Singapore (e-mail: david@comp.nus.edu.sg)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","High-performance data streaming technologies are increasingly adopted in IT companies to support the integration of heterogeneous and possibly distributed service systems and applications. Compared with the traditional message queuing middleware, a streaming platform enables the implementation of event-streaming systems (ESS) which include not only complex queues but also applications that transform and react to the streams of data. By analysing the centralised data streams, one can evaluate the Quality-of-Service for other systems and components that produce or consume the streams. We consider the exploitation of probabilistic model checking as a performance monitoring technique for ESS systems. Probabilistic model checking is a mature, powerful verification technique with successful application in performance analysis. However, an ESS system may contain quantitative parameters that are determined by event streams observed in a certain period of time. In this paper, we present a novel theoretical framework called QV4M (meaning “quantitative verification for monitoring”) for ESS system monitoring based on two recent methods of probabilistic model checking. Our framework QV4M assumes the parameters in a probabilistic system model as random variables and infers the statistical confidence of a probabilistic model checking output. We present two case studies as an empirical evaluation of QV4M.","1939-3520","","10.1109/TSE.2020.2996033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097462","Discrete-time Markov chain;event stream;parametric model checking;performance monitoring;probabilistic model checking;statistical inference","Task analysis;Probabilistic logic;Model checking;Measurement;Monitoring;Pipelines;Computational modeling","","","","","","","","20 May 2020","","","IEEE","IEEE Early Access Articles"
"Investigating the Impact of Development Task on External Quality in Test-Driven Development: An Industry Experiment","A. Tosun; O. Dieste; S. Vegas; D. Pfahl; K. Rungi; N. Juristo","Computer Engineering, Istanbul Technical University, Istanbul, Istanbul Turkey 34469 (e-mail: tosunay@itu.edu.tr); Lenguajes y Sistemas Informaticos e Ingenieria de Software, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: odieste@fi.upm.es); Languajes, computer systems and software engineering, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: svegas@fi.upm.es); Institute of Computer Science, University of Tartu, Tartu, Tartu Estonia (e-mail: dietmar.pfahl@ut.ee); IT, Testlio, Oulu, Oulu Finland (e-mail: kerli.rungi@gmail.com); Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politecnica de Madrid, Boadilla del Monte, Madrid Spain 28660 (e-mail: natalia@fi.upm.es)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Reviews on test-driven development (TDD) studies suggest that the conflicting results reported in the literature are due to unobserved factors, such as the tasks used in the experiments, and highlight that there are very few industry experiments conducted with professionals. The goal of this study is to investigate the impact of a new factor, the chosen task, and the development approach on external quality in an industrial experiment setting with 17 professionals. The participants are junior to senior developers in programming with Java, beginner to novice in unit testing, JUnit, and they have no prior experience in TDD. The experimental design is a $2 \times 2$ cross-over, i.e., we use two tasks for each of the two approaches, namely TDD and incremental test-last development (ITLD). Our results reveal that both development approach and task are significant factors with regards to the external quality achieved by the participants. More specifically, the participants produce higher quality code during ITLD in which splitting user stories into subtasks, coding, and testing activities are followed, compared to TDD. The results also indicate that the participants produce higher quality code during the implementation of Bowling Score Keeper, compared to that of Mars Rover API, although they perceived both tasks as of similar complexity. An interaction between the development approach and task could not be observed in this experiment. We conclude that variables that have not been explored so often, such as the extent to which the task is specified in terms of smaller subtasks, and developers' unit testing experience might be critical factors in TDD experiments. The real-world appliance of TDD and its implications on external quality still remain to be challenging unless these uncontrolled and unconsidered factors are further investigated by researchers in both academic and industrial settings.","1939-3520","","10.1109/TSE.2019.2949811","Ministerio de Ciencia e Innovación; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8884172","Test-driven development;industry experiment;experimental task;incremental test-last development;external quality","Task analysis;Industries;Bibliographies;Productivity;Programming profession;Organizations","","","","1","","","","28 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Choosing Component Origins for Software Intensive Systems: In-House, COTS, OSS or Outsourcing?—A Case Survey","K. Petersen; D. Badampudi; S. M. A. Shah; K. Wnuk; T. Gorschek; E. Papatheocharous; J. Axelsson; S. Sentilles; I. Crnkovic; A. Cicchetti","Department of Software Engineering, Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; SICS Swedish ICT AB, Kista, Sweden; Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; Blekinge Institute of Technology, Campus Gräsvik, Karlskrona, Sweden; SICS Swedish ICT AB, Kista, Sweden; SICS Swedish ICT AB, Kista, Sweden; Mälardalen University, Västerås, Sweden; Chalmers, Gothenberg, Sweden; Mälardalen University, Västerås, Sweden","IEEE Transactions on Software Engineering","13 Mar 2018","2018","44","3","237","261","The choice of which software component to use influences the success of a software system. Only a few empirical studies investigate how the choice of components is conducted in industrial practice. This is important to understand to tailor research solutions to the needs of the industry. Existing studies focus on the choice for off-the-shelf (OTS) components. It is, however, also important to understand the implications of the choice of alternative component sourcing options (CSOs), such as outsourcing versus the use of OTS. Previous research has shown that the choice has major implications on the development process as well as on the ability to evolve the system. The objective of this study is to explore how decision making took place in industry to choose among CSOs. Overall, 22 industrial cases have been studied through a case survey. The results show that the solutions specifically for CSO decisions are deterministic and based on optimization approaches. The non-deterministic solutions proposed for architectural group decision making appear to suit the CSO decision making in industry better. Interestingly, the final decision was perceived negatively in nine cases and positively in seven cases, while in the remaining cases it was perceived as neither positive nor negative.","1939-3520","","10.1109/TSE.2017.2677909","ORION project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7870688","Decision making;in-house;COTS;OSS;outsourcing","Decision making;Outsourcing;Companies;Computer architecture;Software;Industries","decision making;object-oriented programming;outsourcing;software architecture","CSO decision making;software intensive systems;COTS;OSS;Outsourcing;software component;software system;tailor research solutions;off-the-shelf components;OTS;alternative component sourcing options;CSOs;CSO decisions;nondeterministic solutions;architectural group decision;component origins;architectural group decision making","","9","","67","","3 Mar 2017","","","IEEE","IEEE Journals"
"Enabling Mutant Generation for Open- and Closed-Source Android Apps","C. Escobar-Velásquez; M. Linares-Vásquez; G. Bavota; M. Tufano; K. P. Moran; M. Di Penta; C. Vendome; C. Bernal-Cárdenas; D. Poshyvanyk","Systems aned Computing Engineering, Universidad de los Andes Facultad de Ingenieria, 428452 Bogota, Bogot Colombia (e-mail: ca.escobar2434@uniandes.edu.co); Systems Engineering and Computing, Universidad de los Andes, 27991 Bogota, Bogota Colombia (e-mail: m.linaresv@uniandes.edu.co); Faculty of Informatics, Universita della Svizzera Italiana, 27216 Lugano, Lugano Switzerland 6904 (e-mail: gabriele.bavota@usi.ch); Computer Science, College of William and Mary, 8604 Williamsburg, Virginia United States (e-mail: mtufano@email.wm.edu); Computer Science, College of William & Mary, Williamsburg, Virginia United States 23185 (e-mail: kpmoran@cs.wm.edu); Dept. of Engineering, University of Sannio, Benevento, _ Italy 82100 (e-mail: dipenta@unisannio.it); Department of Computer Science & Software Engineering, Miami University, 6403 Oxford, Ohio United States (e-mail: vendomcg@miamioh.edu); Computer Science, College of William and Mary, 8604 Williamsburg, Virginia United States (e-mail: cebernal@cs.wm.edu); Computer Science, William and Mary, Williamsburg, Virginia United States 23188 (e-mail: denys@cs.wm.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Mutation testing has been widely used to assess the fault-detection effectiveness of a test suite, as well as to guide test case generation or prioritization. Empirical studies have shown that, while mutants are generally representative of real faults, an effective application of mutation testing requires “traditional” operators designed for programming languages to be augmented with operators specific to an application domain and/or technology. The case for Android apps is not an exception. Therefore, in this paper we describe the process we followed to create (i) a taxonomy of mutation operations and, (ii) two tools, MDroid+ and MutAPK for mutant generation of Android apps. To this end, we systematically devise a taxonomy of 262 types of Android faults grouped in 14 categories by manually analyzing 2,023 software artifacts from different sources (e.g., bug reports, commits). Then, we identified a set of 38 mutation operators, and implemented them in two tools, the first enabling mutant generation at the source code level, and the second designed to perform mutations at APK level. The rationale for having a dual-approach is based on the fact that source code is not always available when conducting mutation testing. Thus, mutation testing for APKs enables new scenarios in which researchers/practitioners only have access to APK files. The taxonomy, proposed operators, and tools have been evaluated in terms of the number of non-compilable, trivial, equivalent, and duplicate mutants generated and their capacity to represent real faults in Android apps as compared to other well-known mutation tools.","1939-3520","","10.1109/TSE.2020.2982638","National Science Foundation; Google Latin America; Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9052435","Mutation Testing;Fault taxonomy;Mutation Operators;Android","Testing;Tools;Taxonomy;Mobile applications;Computer bugs;Java;Software","","","","","","","","1 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Why My App Crashes Understanding and Benchmarking Framework-specific Exceptions of Android apps","T. Su; L. Fan; S. Chen; Y. Liu; L. Xu; G. Pu; Z. Su","Department of Computer Science, ETH Zurich Department of Computer Science, 31018 Zurich, Zrich Switzerland 8092 (e-mail: krave_su@163.com); School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: ecnujanefan@gmail.com); School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: ecnuchensen@gmail.com); School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore Singapore (e-mail: yangliu@ntu.edu.sg); Computer Science, New York University Shanghai, 447103 Shanghai, Shanghai China (e-mail: lihua.xu@nyu.edu); School of Software Engineering, East China Normal University, Shanghai, Shanghai China (e-mail: ggpu@sei.ecnu.edu.cn); Computer Science, ETH Zurich Department of Computer Science, 31018 Zurich, ZH Switzerland (e-mail: su@cs.ucdavis.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Mobile apps have become ubiquitous. Ensuring their correctness and reliability is important. However, many apps still suffer from occasional to frequent crashes, weakening their competitive edge. Large-scale, deep analyses of the characteristics of real-world app crashes can provide useful insights to both developers and researchers. However, such studies are difficult and yet to be carried out --- this work fills this gap. We collected 16,245 and 8,760 unique exceptions from 2,486 open-source and 3,230 commercial Android apps, respectively, and observed that the exceptions thrown from Android framework (termed ""framework-specific exceptions"") account for the majority. With one-year effort, we (1) extensively investigated these framework-specific exceptions, and (2) further conducted an online survey of 135 professional app developers about how they analyze, test, reproduce and fix these exceptions. Specifically, we aim to understand the framework-specific exceptions from several perspectives: (i) their characteristics (e.g., manifestation locations, fault taxonomy), (ii) the developers' testing practices, (iii) existing bug detection techniques' effectiveness, (iv) their reproducibility and (v) bug fixes. To enable follow-up research (e.g., bug understanding, detection, localization and repairing), we further systematically constructed, DroidDefects, the first comprehensive and largest benchmark of Android app exception bugs. This benchmark contains 33 reproducible exceptions (with test cases, stack traces, faulty and fixed app versions, bug types, etc.), and 3,696 ground-truth exceptions (real faults manifested by automated testing tools), which cover the apps with different complexities and diverse exception types. Based on our findings, we also built two prototype tools: Stoat+, an optimized dynamic testing tool, which quickly uncovered three previously-unknown, fixed crashes in Gmail and Google+; ExLocator, an exception localization tool, which can locate the root causes of specific exception types. Our dataset, benchmark and tools are publicly available on https://github.com/tingsu/droiddefects.","1939-3520","","10.1109/TSE.2020.3013438","Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9153947","Mobile applications;Android applications;empirical study;exception analysis;software testing;bug reproducibility","Computer bugs;Tools;Androids;Humanoid robots;Benchmark testing","","","","3","","","","31 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Automatic Detection and Update Suggestion for Outdated API Names in Documentation","S. Lee; R. Wu; S. -C. Cheung; S. Kang","Department of Aerospace and Software Engineering and with the Department of Informatics, Gyeongsang National University, Jinju, Jinju-daero, Republic of Korea; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Hong Kong, China; School of Computing, KAIST, Daejeon, Republic of Korea","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","653","675","Application programming interfaces (APIs) continually evolve to meet ever-changing user needs, and documentation provides an authoritative reference for their usage. However, API documentation is commonly outdated because nearly all of the associated updates are performed manually. Such outdated documentation, especially with regard to API names, causes major software development issues. In this paper, we propose a method for automatically updating outdated API names in API documentation. Our insight is that API updates in documentation can be derived from API implementation changes between code revisions. To evaluate the proposed method, we applied it to four open source projects. Our evaluation results show that our method, FreshDoc, detects outdated API names in API documentation with 48 percent higher accuracy than the existing state-of-the-art methods do. Moreover, when we checked the updates suggested by FreshDoc against the developers’ manual updates in the revised documentation, FreshDoc detected 82 percent of the outdated names. When we reported 40 outdated API names found by FreshDoc via issue tracking systems, developers accepted 75 percent of the suggestions. These evaluation results indicate that FreshDoc can be used as a practical method for the detection and updating of API names in the associated documentation.","1939-3520","","10.1109/TSE.2019.2901459","National Research Foundation of Korea; Ministry of Science, ICT; Hong Kong RGC/GRF; MSRA Collaborative Research Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651318","Application programming interfaces;documentation;history;software maintenance","Documentation;Computer bugs;Tools;History;Libraries;Software systems","","","","1","","80","IEEE","24 Feb 2019","","","IEEE","IEEE Journals"
"A Qualitative Study of the Benefits and Costs of Logging from Developers' Perspectives","H. Li; W. Shang; B. Adams; M. Sayagh; A. E. Hassan","School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: hengli@cs.queensu.ca); Department of Computer Science and Software Engineering, Concordia University, Montreal, Quebec Canada (e-mail: shang@encs.concordia.ca); Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, Quebec Canada H3T 1J4 (e-mail: bram.adams@polymtl.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: msayagh@cs.queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software developers insert logging statements in their source code to collect important runtime information of software systems. In practice, logging appropriately is a challenge for developers. Prior studies aimed to improve logging by proactively inserting logging statements in certain code snippets or by learning where to log from existing logging code. However, there exists no work that systematically studies developers' logging considerations, i.e., the benefits and costs of logging from developers' perspectives. Without understanding developers' logging considerations, automated approaches for logging decisions are based primarily on researchers' intuition which may not be convincing to developers. In order to fill the gap between developers' logging considerations and researchers' intuition, we performed a qualitative study that combines a survey of 66 developers and a case study of 223 logging-related issue reports. The findings of our qualitative study draw a comprehensive picture of the benefits and costs of logging from developers' perspectives. We observe that developers consider a wide range of logging benefits and costs, while most of the uncovered benefits and costs have never been observed nor discussed in prior work. We also observe that developers use ad hoc strategies to balance the benefits and costs of logging. Developers need to be fully aware of the benefits and costs of logging, in order to better benefit from logging (e.g., leveraging logging to enable users to solve problems by themselves) and avoid unnecessary negative impact (e.g., exposing users' sensitive information). Future research needs to consider such a wide range of logging benefits and costs when developing automated logging strategies. Our findings also inspire opportunities for researchers and logging library providers to help developers balance the benefits and costs of logging, for example, to support different log levels for different parts of a logging statement, or to help developers estimate and reduce the negative impact of logging statements.","1939-3520","","10.1109/TSE.2020.2970422","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8976297","software logging;issue reports;developer survey;qualitative analysis","Runtime;Libraries;Tools;Software systems;Standards;Computational modeling","","","","2","","","","30 Jan 2020","","","IEEE","IEEE Early Access Articles"
"Empirical Effort and Schedule Estimation Models for Agile Processes in the US DoD","W. Rosa; B. K. Clark; R. Madachy; B. Boehm","NCCA, Department of Navy, Arlington, Virginia, United States, (e-mail: wilymar04@cox.net); Software Metrics, Inc., Software Metrics, Inc., Haymarket, Virginia, United States, (e-mail: brad@software-metrics.com); Systems Engineering Department, Naval Postgraduate School, San Diego, California, United States, 92104 (e-mail: rjmadach@nps.edu); USC Center for Software Engineering, USC, Santa Monica, California, United States, (e-mail: boehm@usc.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Estimating the cost and schedule of agile software projects is critical at an early phase to establish baseline budgets and schedules for the selection of competitive bidders. The challenge is that common agile sizing measures such as story points and user stories are not practical for early estimation as these are often reported after contract award in DoD. This study provides a set of effort and schedule estimation models for agile projects using a sizing measure that is available before proposal evaluation based on data from 36 DoD agile projects. The results suggest that initial software requirements, defined as the sum of functions and external interfaces, is an effective sizing measure for early estimation of effort and schedule of agile projects. The models accuracy improves when application domain groups and peak staff are added as inputs.","1939-3520","","10.1109/TSE.2021.3080666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9432729","Agile software processes;Cost estimation;Requirements/Specification;Software acquisition;Software process;Time estimation","Software;US Department of Defense;Schedules;Estimation;Contracts;Unified modeling language;Agile software development","","","","","","","IEEE","17 May 2021","","","IEEE","IEEE Early Access Articles"
"UniDoSA: The Unified Specification and Detection of Service Antipatterns","F. Palma; N. Moha; Y. Guéhéneuc","Department of Computer Science and Media Technology, Linnaeus University, Kalmar, Sweden; Department of Computer Science, University of Québec in Montréal, Montréal, Quebec, Canada; Department of Computing and Software Engineering, Polytechnique Montréal, Montréal, Canada","IEEE Transactions on Software Engineering","16 Oct 2019","2019","45","10","1024","1053","Service-based Systems (SBSs) are developed on top of diverse Service-Oriented Architecture (SOA) technologies or architectural styles. Like any other complex systems, SBSs face both functional and non-functional changes at the design or implementation-level. Such changes may degrade the design quality and quality of service (QoS) of the services in SBSs by introducing poor solutions-service antipatterns. The presence of service antipatterns in SBSs may hinder the future maintenance and evolution of SBSs. Assessing the quality of design and QoS of SBSs through the detection of service antipatterns may ease their maintenance and evolution. However, the current literature lacks a unified approach for modelling and evaluating the design of SBSs in term of design quality and QoS. To address this lack, this paper presents a meta-model unifying the three main service technologies: REST, SCA, and SOAP. Using the meta-model, it describes a unified approach, UniDoSA (Unified Specification and Detection of Service Antipatterns), supported by a framework, SOFA (Service Oriented Framework for Antipatterns), for modelling and evaluating the design quality and QoS of SBSs. We apply and validate UniDoSA on: (1) 18 RESTful APIs, (2) two SCA systems with more than 150 services, and (3) more than 120 SOAP Web services. With a high precision and recall, the detection results provide evidence of the presence of service antipatterns in SBSs, which calls for future studies of their impact on QoS.","1939-3520","","10.1109/TSE.2018.2819180","Natural Sciences and Engineering Research Council of Canada; Canada Chairs; FRQ-NT; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8325321","Antipatterns;service-based systems;REST;SCA;SOAP;web services;specification;detection;quality of service;design;software maintenance and evolution","Simple object access protocol;Quality of service;Service-oriented architecture;Maintenance engineering;DSL","application program interfaces;formal specification;quality of service;service-oriented architecture;software maintenance;software quality;Web services","Unified Specification;SOAP Web services;Service-based Systems;service-oriented architecture;SBS;UniDoSA;service antipattern detection;service oriented framework for antipatterns;SOFA;SCA;quality of service;QoS;RESTful API","","1","","69","","26 Mar 2018","","","IEEE","IEEE Journals"
"The Art, Science, and Engineering of Fuzzing: A Survey","V. J. M. Manès; H. Han; C. Han; S. K. Cha; M. Egele; E. J. Schwartz; M. Woo","Computer Science, KAIST, 34968 Daejeon, Yuseong-gu Korea (the Republic of) (e-mail: valentinmanes@outlook.fr); Computer Science, KAIST, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: yungseok.han@kaist.ac.kr); N/A, Naver, Daejeon, Daejeon Korea (the Republic of) (e-mail: cwhan.tunz@navercorp.com); Computer Scienece, KAIST, Daejeon, Yusung-gu Korea (the Republic of) 34141 (e-mail: sangkilc@kaist.ac.kr); Electrical & Computer Engineering, Boston University, Boston, Massachusetts United States (e-mail: megele@bu.edu); Software Engineering Institute, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: edmcman@cmu.edu); Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: pooh@cmu.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Among the many software testing techniques available today, fuzzing has remained highly popular due to its conceptual simplicity, its low barrier to deployment, and its vast amount of empirical evidence in discovering real-world software vulnerabilities. At a high level, fuzzing refers to a process of repeatedly running a program with generated inputs that may be syntactically or semantically malformed. While researchers and practitioners alike have invested a large and diverse effort towards improving fuzzing in recent years, this surge of work has also made it difficult to gain a comprehensive and coherent view of fuzzing. To help preserve and bring coherence to the vast literature of fuzzing, this paper presents a unified, general-purpose model of fuzzing together with a taxonomy of the current fuzzing literature. We methodically explore the design decisions at every stage of our model fuzzer by surveying the related literature and innovations in the art, science, and engineering that make modern-day fuzzers effective.","1939-3520","","10.1109/TSE.2019.2946563","Siemens; Institute of Information communications Technology Planning Evaluation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8863940","software security;automated software testing;fuzzing;fuzz testing","Fuzzing;Security;Computer bugs;Terminology","","","","11","","","","11 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Pathidea: Improving Information Retrieval-Based Bug Localization by Re-Constructing Execution Paths Using Logs","A. R. Chen; T. -H. P. Chen; S. Wang","Gina Cody School of Engineering and Computer Science, Concordia University, 5618 Montreal, Quebec, Canada, (e-mail: archen94@gmail.com); Computer Science and Software Engineering, Concordia University, 5618 Montreal, Quebec, Canada, H3G 2W1 (e-mail: peterc@encs.concordia.ca); Computer Science, University of Manitoba, 8664 Winnipeg, Manitoba, Canada, R3T 2N2 (e-mail: shaoweiwang.2010@hotmail.com)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","To assist developers with debugging and analyzing bug reports, researchers have proposed information retrieval-based bug localization (IRBL) approaches. IRBL approaches leverage the textual information in bug reports as queries to generate a ranked list of potential buggy files that may need further investigation. Although IRBL approaches have shown promising results, most prior research only leverages the textual information that is visible in bug reports, such as bug description or title. However, in addition to the textual description of the bug, developers also often attach logs in bug reports. Logs provide important information that can be used to re-construct the system execution paths when an issue happens and assist developers with debugging. In this paper, we propose an IRBL approach, Pathidea, which leverages logs in bug reports to re-construct execution paths and helps improve the results of bug localization. Pathidea uses static analysis to create a file-level call graph, and re-constructs the call paths from the reported logs. We evaluate Pathidea on eight open source systems, with a total of 1,273 bug reports that contain logs. We find that Pathidea achieves a high recall (up to 51.9% for Top@5). On average, Pathidea achieves an improvement that varies from 8% to 21% and 5% to 21% over BRTracer in terms of Mean Average Precision (MAP) and Mean Reciprocal Rank (MRR) across studied systems, respectively. Moreover, we find that the re-constructed execution paths can also complement other IRBL approaches by providing a 10% and 8% improvement in terms of MAP and MRR, respectively. Finally, we conduct a parameter sensitivity analysis and provide recommendations on setting the parameter values when applying Pathidea.","1939-3520","","10.1109/TSE.2021.3071473","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397337","bug localization;log;bug report;information retrieval","Computer bugs;Location awareness;Debugging;Static analysis;Information retrieval;History;Tools","","","","","","","IEEE","6 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Automating Change-Level Self-Admitted Technical Debt Determination","M. Yan; X. Xia; E. Shihab; D. Lo; J. Yin; X. Yang","Zhejiang University, Hangzhou, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; Data-driven Analysis of Software (DAS) Lab, Department of Computer Science and Software Engineering, Concordia University, Montreal, QC, Canada; Singapore Management University, Singapore; Zhejiang University, Hangzhou, China; Zhejiang University, Hangzhou, China","IEEE Transactions on Software Engineering","10 Dec 2019","2019","45","12","1211","1229","Technical debt (TD) is a metaphor to describe the situation where developers introduce suboptimal solutions during software development to achieve short-term goals that may affect the long-term software quality. Prior studies proposed different techniques to identify TD, such as identifying TD through code smells or by analyzing source code comments. Technical debt identified using comments is known as Self-Admitted Technical Debt (SATD) and refers to TD that is introduced intentionally. Compared with TD identified by code metrics or code smells, SATD is more reliable since it is admitted by developers using comments. Thus far, all of the state-of-the-art approaches identify SATD at the file-level. In essence, they identify whether a file has SATD or not. However, all of the SATD is introduced through software changes. Previous studies that identify SATD at the file-level in isolation cannot describe the TD context related to multiple files. Therefore, it is beneficial to identify the SATD once a change is being made. We refer to this type of TD identification as “Change-level SATD Determination”, which determines whether or not a change introduces SATD. Identifying SATD at the change-level can help to manage and control TD by understanding the TD context through tracing the introducing changes. To build a change-level SATD Determination model, we first identify TD from source code comments in source code files of all versions. Second, we label the changes that first introduce the SATD comments as TD-introducing changes. Third, we build the determination model by extracting 25 features from software changes that are divided into three dimensions, namely diffusion, history and message, respectively. To evaluate the effectiveness of our proposed model, we perform an empirical study on 7 open source projects containing a total of 100,011 software changes. The experimental results show that our model achieves a promising and better performance than four baselines in terms of AUC and cost-effectiveness (i.e., percentage of TD-introducing changes identified when inspecting 20 percent of changed LOC). On average across the 7 experimental projects, our model achieves AUC of 0.82, cost-effectiveness of 0.80, which is a significant improvement over the comparison baselines used. In addition, we found that “Diffusion” is the most discriminative dimension among the three dimensions of features for determining TD-introducing changes.","1939-3520","","10.1109/TSE.2018.2831232","National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8352718","Technical debt;software change;change-level determination;self-admitted technical debt","Feature extraction;Java;Labeling;Software quality","project management;public domain software;software maintenance;software management;software metrics;software quality","long-term software quality;source code comments;source code files;software changes;SATD determination model;self-admitted technical debt determination;efficiency 20.0 percent","","6","","77","IEEE","30 Apr 2018","","","IEEE","IEEE Journals"
"An Empirical Validation of Oracle Improvement","G. Jahangirova; D. Clark; M. Harman; P. Tonella","Software Engineering, Fondazione Bruno Kessler, 18466 Trento, Trento Italy (e-mail: g.jahangirova@gmail.com); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: david.clark@ucl.ac.uk); CS, UCL, London, London United Kingdom of Great Britain and Northern Ireland WC1E 6BT (e-mail: mark.harman@ucl.ac.uk); Informatics, Universitá della Svizzera Italiana (USI), Lugano, Ticino Switzerland (e-mail: paolo.tonella@usi.ch)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","We propose a human-in-the-loop approach for oracle improvement and analyse whether the proposed oracle improvement process is helping developers to create better oracles. For this, we conducted two human studies with 68 participants overall: an oracle assessment study and an oracle improvement study. Our results show that developers exhibit poor performance (29% accuracy) when manually assessing whether an assertion oracle contains a false positive, a false negative or none of the two. This shows that automated detection of these oracle deficiencies is beneficial for the users. Our tool OASIs (Oracle ASsessment and Improvement) helps developers produce assertions with higher quality. Participants who used OASIs in the improvement study were able to achieve 33% of full and 67% of partial correctness as opposed to participants without the tool who achieved only 21% of full and 43% of partial correctness.","1939-3520","","10.1109/TSE.2019.2934409","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8794642","Oracle Problem;Test Oracle;Oracle Assessment;Oracle Improvement;Human Study;Test Case Generation;Mutation Testing","Tools;Standards;Generators;Indexes;Software testing;Software","","","","1","","","","12 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Machine Learning Testing: Survey, Landscapes and Horizons","J. M. Zhang; M. Harman; L. Ma; Y. Liu","CREST, University College London, United Kingdom. Mark Harman is also with Facebook London (e-mail: jie.zhang@ucl.ac.uk); CREST, University College London, United Kingdom. Mark Harman is also with Facebook London (e-mail: mark.harman@ucl.ac.uk); Kyushu University, Japan (e-mail: malei.2005@gmail.com); Nanyang Technological University, Singapore (e-mail: yangliu@ntu.edu.sg)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","This paper provides a comprehensive survey of Machine Learning Testing (ML testing) research. It covers 138 papers on testing properties (e.g., correctness, robustness, and fairness), testing components (e.g., the data, learning program, and framework), testing workflow (e.g., test generation and test evaluation), and application scenarios (e.g., autonomous driving, machine translation). The paper also analyses trends concerning datasets, research trends, and research focus, concluding with research challenges and promising research directions in machine learning testing.","1939-3520","","10.1109/TSE.2019.2962027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000651","machine learning;software testing;deep neural network","Machine learning;Software testing;Software engineering;Training data;Data models;Robustness","","","","31","","","","17 Feb 2020","","","IEEE","IEEE Early Access Articles"
"Specialising Software for Different Downstream Applications Using Genetic Improvement and Code Transplantation","J. Petke; M. Harman; W. B. Langdon; W. Weimer","University College London, London, United Kingdom; University College London, London, United Kingdom; University College London, London, United Kingdom; University of Virginia, Charlottesville, VA","IEEE Transactions on Software Engineering","12 Jun 2018","2018","44","6","574","594","Genetic improvement uses automated search to find improved versions of existing software. Genetic improvement has previously been concerned with improving a system with respect to all possible usage scenarios. In this paper, we show how genetic improvement can also be used to achieve specialisation to a specific set of usage scenarios. We use genetic improvement to evolve faster versions of a C++ program, a Boolean satisfiability solver called MiniSAT, specialising it for three different applications, each with their own characteristics. Our specialised solvers achieve between 4 and 36 percent execution time improvement, which is commensurate with efficiency gains achievable using human expert optimisation for the general solver. We also use genetic improvement to evolve faster versions of an image processing tool called ImageMagick, utilising code from GraphicsMagick, another image processing tool which was forked from it. We specialise the format conversion functionality to greyscale images and colour images only. Our specialised versions achieve up to 3 percent execution time improvement.","1939-3520","","10.1109/TSE.2017.2702606","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7962212","Genetic improvement;GI;code transplants;code specialisation;SAT;ImageMagick;GraphicsMagick","Software;Software engineering;Image processing;C++ languages;Genetic programming;Optimization","Boolean algebra;C++ language;computability;genetic algorithms;image colour analysis;source code (software)","genetic improvement;execution time improvement;code transplantation;C++ program;Boolean satisfiability solver;MiniSAT;software specialisation;downstream application;image processing tool;ImageMagick;GraphicsMagick;greyscale images;colour images","","4","","97","","29 Jun 2017","","","IEEE","IEEE Journals"
"Output Sampling for Output Diversity in Automatic Unit Test Generation","H. Menéndez Benito; M. Boreale; D. Gorla; D. Clark","Computer Science, Middlesex University, 4907 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: h.menendez@mdx.ac.uk); Computer Science, University of Florence, 9300 Firenze, Toscana Italy (e-mail: michele.boreale@unifi.it); Dept. of Computer Science, University of Rome Sapienza, 00100 Roma, Italy (e-mail: gorla@di.uniroma1.it); Computer Science, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: david.clark@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Diverse test sets are able to expose bugs that test sets generated with structural coverage techniques cannot discover. Input-diverse test set generators have been shown to be effective for this, but also have limitations: e.g., they need to be complemented with semantic information derived from the Software Under Test. We demonstrate how to drive the test set generation process with semantic information in the form of output diversity. We present the first totally automatic output sampling for output diversity unit test set generation tool, called OutGen. OutGen transforms a program into an SMT formula in bit-vector arithmetic. It then applies universal hashing in order to generate an output-based diverse set of inputs. The result offers significant diversity improvements when measured as a high output uniqueness count. It achieves this by ensuring that the test set's output probability distribution is uniform, i.e. highly diverse. The use of output sampling, as opposed to any of input sampling, CBMC, CAVM, behaviour diversity or random testing improves mutation score and bug detection by up to 4150% and 963% respectively on programs drawn from three different corpora: the R-project, SIR and CodeFlaws. OutGen test sets achieve an average mutation score of up to 92%, and 70% of the test sets detect the defect. Moreover, OutGen is the only automatic unit test generation tool that is able to detect bugs on the real number C functions from the R-project.","1939-3520","","10.1109/TSE.2020.2987377","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068446","Unit Testing;Output Sampling;Output Diversity;SMT Solver;OutGen","Computer bugs;Tools;Semantics;Generators;Software engineering;Test pattern generators","","","","","","","","15 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Platform-Independent Dynamic Taint Analysis for JavaScript","R. Karim; F. Tip; A. Sochůrková; K. Sen","Samsung Research America, Mountain View, CA, USA; College of Computer and Information Science, Northeastern University, Boston, MA, USA; Avast, Prague, Czechia; University of California at Berkeley, Berkeley, CA, USA","IEEE Transactions on Software Engineering","10 Dec 2020","2020","46","12","1364","1379","Previous approaches to dynamic taint analysis for JavaScript are implemented directly in a browser or JavaScript engine, limiting their applicability to a single platform and requiring ongoing maintenance as platforms evolve, or they require nontrivial program transformations. We present an approach that relies on instrumentation to encode taint propagation as instructions for an abstract machine. Our approach has two key advantages: it is platform-independent and can be used with any existing JavaScript engine, and it can track taint on primitive values without requiring the introduction of wrapper objects. Furthermore, our technique enables multiple deployment scenarios by varying when and where the generated instructions are executed and it supports indirect taint sources, i.e., situations where taint enters an application via arguments passed to dynamically registered event-listener functions. We implemented the technique for the ECMAScript 5 language in a tool called Ichnaea, and evaluated it on 22 NPM modules containing several types of injection vulnerabilities, including 4 modules containing vulnerabilities that were not previously discovered and reported. On these modules, run-time overheads range from 3.17x to 38.42x, which is significantly better than a previous transformation-based technique. We also report on a case study that shows how Ichnaea can be used to detect privacy leaks in a Tizen web application for the Samsung Gear S2 smart watch.","1939-3520","","10.1109/TSE.2018.2878020","Czech Technical University; European Research Council; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8511058","Taint analysis;dynamic analysis;JavaScript;platform-independent;instrumentation","Java;Instruments;Browsers;Software engineering;Privacy;Data privacy","authoring languages;data privacy;Internet;program compilers;wearable computers","platform-independent dynamic taint analysis;nontrivial program transformations;taint propagation;abstract machine;JavaScript engine;multiple deployment scenarios;dynamically registered event-listener functions;Tizen Web application;ECMAScript 5 language;Ichnaea;privacy leaks detection;wrapper objects;Samsung Gear S2 smart watch;NPM modules","","3","","39","IEEE","26 Oct 2018","","","IEEE","IEEE Journals"
"Effects of Personality Traits on Pull Request Acceptance","R. N. Iyer; S. A. Yun; M. Nagappan; J. Hoey","David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: r3iyer@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: alex.yun@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: mei.nagappan@uwaterloo.ca); David R. Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: jhoey@cs.uwaterloo.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","In this paper, we examine the influence of personality traits of developers on the pull request evaluation process in GitHub. We first replicate Tsay et al.'s work that examined the influence of social factors (e.g., ‘social distance’) and technical factors (e.g., test file inclusion) for evaluating contributions, and then extend it with personality-based factors. In particular, we extract the Big Five personality traits (Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) of developers from their online digital footprints, such as pull request comments. We analyze the personality traits of 16,935 active developers from 1,860 projects and compare their relative importance to other non-personality factors from past research, in the pull request evaluation process. We find that pull requests from authors (requesters) who are more open and conscientious, but less extroverted, have a higher chance of approval. Furthermore, pull requests that are closed by developers (closers) who are more conscientious, extroverted, and neurotic, have a higher likelihood of acceptance. The larger the difference in personality traits between the requester and the closer, the more positive effect it has on pull request acceptance. Finally, although the effect of personality traits is significant and comparable to technical factors, we find that social factors are still more influential on the likelihood of pull request acceptance.","1939-3520","","10.1109/TSE.2019.2960357","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8935389","pull request;GitHub;online collaborative environments;open source systems;personality;Big Five;five-factor model","Psychology;Social factors;Software engineering;Task analysis;Dictionaries;Robots;Software","","","","1","","","","17 Dec 2019","","","IEEE","IEEE Early Access Articles"
"Characterizing Crowds to Better Optimize Worker Recommendation in Crowdsourced Testing","J. Wang; S. Wang; J. Chen; T. Menzies; Q. Cui; M. Xie; Q. Wang","Institute of Software, Chinese Academy of Sciences, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing China 100190 (e-mail: junjie@nfs.iscas.ac.cn); Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, Ontario Canada N2L 3G1 (e-mail: song.wang@uwaterloo.ca); Computer science, North Carolina State University, 6798 Raleigh, North Carolina United States 27695 (e-mail: jchen37@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org); Data, Bytedance Inc., Beijing, Beijing China (e-mail: cuiqiang1225@gmail.com); CBG, Huawei Technologies Co Ltd, 115371 Beijing, Beijing China (e-mail: 0520shui@163.com); Institute of Software, Chinese Academy of Sciences, Beijing, Beijing China 100190 (e-mail: wq@itechs.iscas.ac.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Crowdsourced testing is an emerging trend, in which test tasks are entrusted to the online crowd workers. Typically, a crowdsourced test task aims to detect as many bugs as possible within a limited budget. However not all crowd workers are equally skilled at finding bugs; Inappropriate workers may miss bugs, or report duplicate bugs, while hiring them requires nontrivial budget. Therefore, it is of great value to recommend a set of appropriate crowd workers for a test task so that more software bugs can be detected with fewer workers. This paper first presents a new characterization of crowd workers and characterizes them with testing context, capability, and domain knowledge. Based on the characterization, we then propose Multi-Objective Crowd wOrker recoMmendation approach (MOCOM), which aims at recommending a minimum number of crowd workers who could detect the maximum number of bugs for a crowdsourced testing task. Specifically, MOCOM recommends crowd workers by maximizing the bug detection probability of workers, the relevance with the test task, the diversity of workers, and minimizing the test cost. We experimentally evaluate MOCOM on 532 test tasks, and results show that MOCOM significantly outperforms five commonly-used and state-of-the-art baselines. Furthermore, MOCOM can reduce duplicate reports and recommend workers with high relevance and larger bug detection probability; because of this it can find more bugs with fewer workers.","1939-3520","","10.1109/TSE.2019.2918520","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721154","Crowdsourced testing;Crowd worker recommendation;Multi-objective optimization","Task analysis;Computer bugs;Testing;Software;Videos;Software engineering;Optimization","","","","1","","","","23 May 2019","","","IEEE","IEEE Early Access Articles"
"Whence to Learn? Transferring Knowledge in Configurable Systems using BEETLE","R. Krishna; V. Nair; P. Jamshidi; T. Menzies","Computer Science, Columbia University, 5798 New York, New York United States (e-mail: i.m.ralk@gmail.com); Computer Science, NC State University, 6798 Raleigh, North Carolina United States (e-mail: vivekaxl@gmail.com); Computer Science and Engineering, University of South Carolina, Columbia, South Carolina United States (e-mail: pjamshid@cse.sc.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","As software systems grow in complexity and the space of possible configurations increases exponentially, finding the near-optimal configuration of a software system becomes challenging. Recent approaches address this challenge by learning performance models based on a sample set of configurations. However, collecting enough sample configurations can be very expensive since each such sample requires configuring, compiling, and executing the entire system using a complex test suite. When learning on new data is too expensive, it is possible to use Transfer Learning to “transfer” old lessons to the new context. Traditional transfer learning has a number of challenges, specifically, (a) learning from excessive data takes excessive time, and (b) the performance of the models built via transfer can deteriorate as a result of learning from a poor source. To resolve these problems, we propose a novel transfer learning framework called BEETLE, which is a “bellwether”-based transfer learner that focuses on identifying and learning from the most relevant source from amongst the old data. This paper evaluates BEETLE with 57 different software configuration problems based on five software systems (a video encoder, an SAT solver, a SQL database, a high-performance C-compiler, and a streaming data analytics tool). In each of these cases, BEETLE found configurations that are as good as or better than those found by other state-of-the-art transfer learners while requiring only a fraction 1/7th of the measurements needed by those other methods. Based on these results, we say that BEETLE is a new high-water mark in optimally configuring software.","1939-3520","","10.1109/TSE.2020.2983927","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9050841","Performance Optimization;SBSE;Transfer Learning;Bellwether","Optimization;Software systems;Data collection;Tools;Computer science;Software engineering","","","","","","","","30 Mar 2020","","","IEEE","IEEE Early Access Articles"
"User Review-Based Change File Localization for Mobile Applications","Y. Zhou; Y. Su; T. Chen; Z. Huang; H. C. Gall; S. Panichella","Dept. of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China 211106 (e-mail: zhouyu@nuaa.edu.cn); Dept. of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: suyanqi@nuaa.edu.cn); Department of Computer Science and Information Systems, Birkbeck University of London, 4894 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: taolue@dcs.bbk.ac.uk); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu China (e-mail: zqhuang@nuaa.edu.cn); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: gall@ifi.uzh.ch); School of Engineering, Zurcher Hochschule fur Angewandte Wissenschaften, 30944 Winterthur, Zurich Switzerland 8400 (e-mail: panc@zhaw.ch)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","In the current mobile app development, novel and emerging DevOps practices (e.g., Continuous Delivery, Integration, and user feedback analysis) and tools are becoming more widespread. For instance, the integration of user feedback (provided in the form of user reviews) in the software release cycle represents a valuable asset for the maintenance and evolution of mobile apps. To fully make use of these assets, it is highly desirable for developers to establish semantic links between the user reviews and the software artefacts to be changed (e.g., source code and documentation), and thus to localize the potential files to change for addressing the user feedback. In this paper, we propose RISING (Reviews Integration via claSsification, clusterIng, and linkiNG), an automated approach to support the continuous integration of user feedback via classification, clustering, and linking of user reviews. RISING leverages domain-specific constraint information and semi-supervised learning to group user reviews into multiple fine-grained clusters concerning similar users' requests. Then, by combining the textual information from both commit messages and source code, it automatically localizes potential change files to accommodate the users' requests. Our empirical studies demonstrate that the proposed approach outperforms the state-of-the-art baseline work in terms of clustering and localization accuracy, and thus produces more reliable results.","1939-3520","","10.1109/TSE.2020.2967383","ARC Discovery Project; UK EPSRC grant; NSFC grant; National Key R and D Program of China; SNF Project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8961125","User review;Mobile apps;Information retrieval;Change File Localization","Software;Mobile applications;Testing;Tools;Maintenance engineering;Reliability;Software engineering","","","","","","","","16 Jan 2020","","","IEEE","IEEE Early Access Articles"
"Combining Code and Requirements Coverage with Execution Cost for Test Suite Reduction","A. Marchetto; G. Scanniello; A. Susi","NA; University of Basilicata, Potenza, Italy; Fondazione Bruno Kessler, Trento, Italy","IEEE Transactions on Software Engineering","16 Apr 2019","2019","45","4","363","390","Test suites tend to become large and complex after software evolution iterations, thus increasing effort and cost to execute regression testing. In this context, test suite reduction approaches could be applied to identify subsets of original test suites that preserve the capability of satisfying testing requirements and revealing faults. In this paper, we propose Multi-Objective test suites REduction (named MORE+): a three-dimension approach for test suite reduction. The first dimension is the structural one and concerns the information on how test cases in a suite exercise the under-test application. The second dimension is functional and concerns how test cases exercise business application requirements. The third dimension is the cost and concerns the time to execute test cases. We define MORE+ as a multi-objective approach that reduces test suites so maximizing their capability in revealing faults according to the three considered dimensions. We have compared MORE+ with seven baseline approaches on 20 Java applications. Results showed, in particular, the effectiveness of MORE+ in reducing test suites with respect to these baselines, i.e., significantly more faults are revealed with test suites reduced by applying MORE+.","1939-3520","","10.1109/TSE.2017.2777831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8120000","Multi-objective approach;regression testing;testing;test suite reduction","Testing;Software;Business;Java;Space exploration;Large scale integration;Software engineering","Java;program testing;regression analysis;software fault tolerance;software maintenance","test cases;suite exercise;under-test application;regression testing;original test suites;MultiObjective test suites REduction","","4","","79","","27 Nov 2017","","","IEEE","IEEE Journals"
"Beyond Technical Aspects: How Do Community Smells Influence the Intensity of Code Smells?","F. Palomba; D. Andrew Tamburri; F. Arcelli Fontana; R. Oliveto; A. Zaidman; A. Serebrenik","University of Zürich, Zürich, Switzerland; Eindhoven University of Technology, Eindhoven, AZ, The Netherlands; University of Milano Bicocca, Milano, Italy; University of Molise, Campobasso, Italy; Delft Unversity of Technology, Delft, CD, The Netherlands; Eindhoven University of Technology, Eindhoven, AZ, The Netherlands","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","108","129","Code smells are poor implementation choices applied by developers during software evolution that often lead to critical flaws or failure. Much in the same way, community smells reflect the presence of organizational and socio-technical issues within a software community that may lead to additional project costs. Recent empirical studies provide evidence that community smells are often-if not always-connected to circumstances such as code smells. In this paper we look deeper into this connection by conducting a mixed-methods empirical study of 117 releases from 9 open-source systems. The qualitative and quantitative sides of our mixed-methods study were run in parallel and assume a mutually-confirmative connotation. On the one hand, we survey 162 developers of the 9 considered systems to investigate whether developers perceive relationship between community smells and the code smells found in those projects. On the other hand, we perform a fine-grained analysis into the 117 releases of our dataset to measure the extent to which community smells impact code smell intensity (i.e., criticality). We then propose a code smell intensity prediction model that relies on both technical and community-related aspects. The results of both sides of our mixed-methods study lead to one conclusion: community-related factors contribute to the intensity of code smells. This conclusion supports the joint use of community and code smells detection as a mechanism for the joint management of technical and social problems around software development communities.","1939-3520","","10.1109/TSE.2018.2883603","Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8546762","Code smells;organizational structure;community smells;mixed-methods study","Predictive models;Software engineering;Open source software;Convergence;Tools;Feature extraction","consumer behaviour;organisational aspects;public domain software;software maintenance;software management;software metrics;software quality","code smells;community smells;socio-technical issues;software community;recent empirical studies;mixed-methods empirical study;mixed-methods study;impact code smell intensity;code smell intensity prediction model;community-related aspects;community-related factors;software development communities","","9","","144","IEEE","27 Nov 2018","","","IEEE","IEEE Journals"
"Methodological Principles for Reproducible Performance Evaluation in Cloud Computing","A. V. Papadopoulos; L. Versluis; A. Bauer; N. Herbst; J. Von Kistowski; A. Ali-eldin; C. Abad; J. N. Amaral; P. Tůma; A. Iosup","IDT, Maladalen University, 8177 Vasteras, Vasteras Sweden (e-mail: alessandro.papadopoulos@mdh.se); Computer Science, Vrije Universiteit Amsterdam, 1190 Amsterdam, Noord-Holland Netherlands (e-mail: l.f.d.versluis@vu.nl); Computer Science, Julius-Maximilians-Universitat Wurzburg, 9190 Würzburg, Bavaria Germany (e-mail: andre.bauer@uni-wuerzburg.de); Computer Science, Julius-Maximilians-Universitat Wurzburg, 9190 Würzburg, Bavaria Germany 97070 (e-mail: nikolas.herbst@uni-wuerzburg.de); Computer Science, Julius-Maximilians-Universitat Wurzburg, 9190 Würzburg, Bavaria Germany (e-mail: joakim.kistowski@uni-wuerzburg.de); Department of Computing Science, Umea University, 8075 Umea, Umea Sweden (e-mail: ahmeda@cs.umu.se); Computer Science, Escuela Superior Politecnica del Litoral, 27883 Guayaquil, Guayas Ecuador (e-mail: cabad@fiec.espol.edu.ec); Department of Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada (e-mail: jamaral@ualberta.ca); Department of Distributed and Dependable Systems, Charles University, 37740 Prague, Prague Czech Republic (e-mail: petr.tuma@d3s.mff.cuni.cz); Computer Science, Vrije Universiteit Amsterdam, 1190 Amsterdam, Noord-Holland Netherlands (e-mail: A.Iosup@vu.nl)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The rapid adoption and the diversification of cloud computing technology exacerbate the importance of a sound experimental methodology for this domain. This work investigates how to measure and report performance in the cloud, and how well the cloud research community is already doing it. We propose a set of eight important methodological principles that combine best-practices from nearby fields with concepts applicable only to clouds, and with new ideas about the time-accuracy trade-off. We show how these principles are applicable using a practical use-case experiment. To this end, we analyze the ability of the newly released SPEC Cloud IaaS benchmark to follow the principles, and showcase real-world experimental studies in common cloud environments that meet the principles. Last, we report on a systematic literature review including top conferences and journals in the field, from 2012 to 2017, analyzing if the practice of reporting cloud performance measurements follows the proposed eight principles. Worryingly, this systematic survey and the subsequent two-round human reviews, reveal that few of the published studies follow the eight experimental principles. We conclude that, although these important principles are simple and basic, the cloud community is yet to adopt them broadly to deliver sound measurement of cloud environments.","1939-3520","","10.1109/TSE.2019.2927908","Stiftelsen för Kunskaps- och Kompetensutveckling; Deutsche Forschungsgemeinschaft; Nederlandse Organisatie voor Wetenschappelijk Onderzoek; H2020 Marie Sklodowska-Curie Actions; Vetenskapsradet; Stiftelsen for Strategisk Forskning; Google; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8758926","Experimental evaluation;observation study;experimentation","Cloud computing;Performance evaluation;Benchmark testing;Systematics;Computer performance;Software engineering","","","","6","","","","10 Jul 2019","","","IEEE","IEEE Early Access Articles"
"Bellwethers: A Baseline Method for Transfer Learning","R. Krishna; T. Menzies","Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science, North Carolina State University, Raleigh, NC","IEEE Transactions on Software Engineering","12 Nov 2019","2019","45","11","1081","1105","Software analytics builds quality prediction models for software projects. Experience shows that (a) the more projects studied, the more varied are the conclusions; and (b) project managers lose faith in the results of software analytics if those results keep changing. To reduce this conclusion instability, we propose the use of “bellwethers”: given N projects from a community the bellwether is the project whose data yields the best predictions on all others. The bellwethers offer a way to mitigate conclusion instability because conclusions about a community are stable as long as this bellwether continues as the best oracle. Bellwethers are also simple to discover (just wrap a for-loop around standard data miners). When compared to other transfer learning methods (TCA+, transfer Naive Bayes, value cognitive boosting), using just the bellwether data to construct a simple transfer learner yields comparable predictions. Further, bellwethers appear in many SE tasks such as defect prediction, effort estimation, and bad smell detection. We hence recommend using bellwethers as a baseline method for transfer learning against which future work should be compared.","1939-3520","","10.1109/TSE.2018.2821670","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329264","Transfer learning;defect prediction;bad smells;issue close time;effort estimation;prediction","Estimation;Software;Software engineering;Task analysis;Benchmark testing;Complexity theory;Analytical models","learning (artificial intelligence);project management;software maintenance;software quality","software analytics;quality prediction models;software projects;transfer learning methods;bellwether data","","6","","154","","2 Apr 2018","","","IEEE","IEEE Journals"
"Specification Patterns for Robotic Missions","C. Menghi; C. Tsigkanos; P. Pelliccione; C. Ghezzi; T. Berger","SnT - Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: claudio.menghi@uni.lu); Distibuted Systems Group, TU Vienna, Vienna, Vienna Austria (e-mail: christos.tsigkanos@polimi.it); Department of Computer Science, University of L'Aquila, L'Aquila, aq Italy (e-mail: patrizio.pelliccione@univaq.it); Dip. di Elettronica e Informazione, Politecnico Milano, Milano, Italy Italy 20133 (e-mail: carlo.ghezzi@polimi.it); Department of Computer Science and Engineering, Chalmers | University of Gothenburg, Gothenburg, Gothenburg Sweden (e-mail: thorsten.berger@chalmers.se)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Mobile and general-purpose robots increasingly support our everyday life, requiring dependable robotics control software. Creating such software mainly amounts to implementing their complex behaviors known as missions. Recognizing this need, a large number of domain-specific specification languages has been proposed. These, in addition to traditional logical languages, allow the use of formally specified missions for synthesis, verification, simulation or guiding implementation. For instance, the logical language LTL is commonly used by experts to specify missions as an input for planners, which synthesize the behavior a robot should have. Unfortunately, domain-specific languages are usually tied to specific robot models, while logical languages such as LTL are difficult to use by non-experts. We present a catalog of 22 mission specification patterns for mobile robots, together with tooling for instantiating, composing, and compiling the patterns to create mission specifications. The patterns provide solutions for recurrent specification problems, each of which detailing the usage intent, known uses, relationships to other patterns, and-most importantly-a template mission specification in temporal logic. Our tooling produces specifications expressed in the temporal logics LTL and CTL to be used by planners, simulators or model checkers. The patterns originate from 245 realistic textual mission requirements extracted from the robotics literature, and they are evaluated upon a total of 441 real-world mission requirements and 1251 mission specifications. Five of these reflect scenarios we defined with two well-known industrial partners developing human-size robots. We validated our patterns' correctness with simulators and two different types of real robots.","1939-3520","","10.1109/TSE.2019.2945329","Université du Luxembourg; H2020 European Research Council; H2020 LEIT Information and Communication Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859226","","Software;Service robots;Natural languages;Software engineering;Tools;Task analysis","","","","5","","","","4 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Software Development Process Ambidexterity and Project Performance: A Coordination Cost-Effectiveness View","K. Werder; Y. Li; A. Maedche; B. Ramesh","University of Cologne, Cologne, Germany; University of Mannheim, Mannheim, Germany; Institute of Information Systems and Marketing (IISM), Karlsruhe Institute of Technology (KIT), Karlsruhe, Germany; Department of Computer Information Systems, Robinson College of Business, Georgia State University, Atlanta","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","836","849","Software development process ambidexterity (SDPA) is the ability to demonstrate both process alignment and process adaptability simultaneously. Realizing process ambidexterity has recently been suggested as an effective approach to improving the performance of software development (SD) projects. To understand the mechanisms underlying the effects of ambidexterity, we focus in this study on the mediating effects of coordination, one of the most important activity in SD projects. Specifically, we hypothesize a mediating effect of coordination costs and coordination effectiveness on the relationship between SDPA and project performance. We conducted a quantitative study involving 104 SD projects across 10 firms to test the model. The results strongly suggest that the positive relationship between SDPA and project performance is negatively mediated by coordination costs and positively mediated by coordination effectiveness. We validate our research model with a case study in an organization employing several hundred IT professionals and derive several practical implications on this basis.","1939-3520","","10.1109/TSE.2019.2904571","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8665932","Ambidexterity;coordination;coordination cost;cost-effectiveness;project performance;software development","Software;Organizations;Technological innovation;Information systems;Sensors;Software engineering","","","","","","110","IEEE","12 Mar 2019","","","IEEE","IEEE Journals"
"Reusing Solutions Modulo Theories","A. Aquino; G. Denaro; M. Pezzè","Università della Svizzera italiana (USI), Lugano, Switzerland; Università di Milano - Bicocca, Milano, Italy; Università della Svizzera italiana (USI), Lugano, Switzerland","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","948","968","In this paper we propose an approach for reusing formula solutions to reduce the impact of Satisfiability Modulo Theories (SMT) solvers on the scalability of symbolic program analysis. SMT solvers can efficiently handle huge expressions in relevant logic theories, but they still represent a main bottleneck to the scalability of symbolic analyses, like symbolic execution and symbolic model checking. Reusing proofs of formulas solved during former analysis sessions can reduce the amount of invocations of SMT solvers, thus mitigating the impact of SMT solvers on symbolic program analysis. Early approaches to reuse formula solutions exploit equivalence and inclusion relations among structurally similar formulas, and are strongly tighten to the specific target logics. In this paper, we present an original approach that reuses both satisfiability and unsatisfiability proofs shared among many formulas beyond only equivalent or related-by-implication formulas. Our approach straightforwardly generalises across multiple logics. It is based on the original concept of distance between formulas, which heuristically approximates the likelihood of formulas to share either satisfiability or unsatisfiability proofs. We show the efficiency and the generalisability of our approach, by instantiating the underlying distance function for formulas that belong to most popular logic theories handled by current SMT solvers, and confirm the effectiveness of the approach, by reporting experimental results on over nine millions formulas from five logic theories.","1939-3520","","10.1109/TSE.2019.2898199","Swiss SNF; Italian MIUR PRIN project GAUSS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8681653","Symbolic program analysis;symbolic execution;SMT solver;solution reuse","Scalability;Software engineering;Prototypes;Terminology;Model checking;Indexes","","","","1","","33","OAPA","4 Apr 2019","","","IEEE","IEEE Journals"
"Recommending API Function Calls and Code Snippets to Support Software Development","P. T. Nguyen; J. Di Rocco; C. Di Sipio; D. Di Ruscio; M. Di Penta","Department of Computer Science, Information Engineering and Mathematics, University of L'Aquila Department of Information Engineering Computer Science and Mathematics, 220003 L'Aquila, L'Aquila, Italy, (e-mail: phuong.nguyen@univaq.it); DISIM, Universit degli Studi dell'Aquila, 9303 L'AQUILA, AQ, Italy, 67100 (e-mail: juri.dirocco@univaq.it); Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Universit degli Studi dell'Aquila, Italy, AQ, Italy, (e-mail: claudio.disipio@univaq.it); Department of Information Engineering Computer Science and Mathematics, University of L'Aquila, L'Aquila, AQ, Italy, 67100 (e-mail: davide.diruscio@univaq.it); Dept. of Engineering, University of Sannio, Benevento, _, Italy, 82100 (e-mail: dipenta@unisannio.it)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Software development activity has reached a high degree of complexity, guided by the heterogeneity of the components, data sources, and tasks. The proliferation of open-source software (OSS) repositories has stressed the need to reuse available software artifacts efciently. To this aim, it is necessary to explore approaches to mine data from software repositories and leverage it to produce helpful recommendations. We designed and implemented FOCUS as a novel approach to provide developers with API calls and source code while they are programming. The system works on the basis of a context-aware collaborative ltering technique to extract API usages from OSS projects. In this work, we show the suitability of FOCUS for Android programming by evaluating it on a dataset of 2,600 mobile apps. The empirical evaluation results show that our approach outperforms two state-of-the-art API recommenders, UP-Miner and PAM, in terms of prediction accuracy. We also point out that there is no signicant relationship between the categories for apps dened in Google Play and their API usages. Finally, we show that participants of a user study positively perceive the API and source code recommended by FOCUS as relevant to the current development context.","1939-3520","","10.1109/TSE.2021.3059907","H2020 LEIT Information and Communication Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9359479","Recommender Systems;API Calls;Source Code Recommendations;Android Programming","Recommender systems;Libraries;Tools;Data mining;Task analysis;Software engineering;Documentation","","","","","","","IEEE","19 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Migrating a Software Factory to Design Thinking: Paying Attention to People and Mind-Sets","N. Mahe; B. Adams; J. Marsan; M. Templier; S. Bissonnette","Design Thinking Montreal, Montreal, Quebec, Canada; Maintenance, Construction, and Intelligence of Software, Polytechnique Montreal, Montreal, Quebec, Canada; Centre de recherche en technologies de l’information et affaires, Universite Laval, Quebec City, Quebec, Canada; Information Systems, Universite Laval, Quebec City, Quebec, Canada; Proaction Technologies, Montreal, Quebec, Canada","IEEE Software","11 Feb 2020","2020","37","2","32","40","Design thinking (DT) has found its way into software engineering, promising better requirements elicitation, customer relations, and cohesion within the development team. We report on Proaction Technologies' migration toward DT and evaluate the process through interviews with employees and clients.","1937-4194","","10.1109/MS.2019.2958646","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8928978","","Software development management;Prototypes;Companies;Production facilities;Biological system modeling","personnel;software engineering","proaction technologies migration;customer relations;requirements elicitation;software engineering;design thinking;software factory;development team","","","","15","","8 Dec 2019","","","IEEE","IEEE Magazines"
"Exercising Power in Software Ecosystems","C. Alves; G. Valença; X. Franch","Universidade Federal de Pernambuco, Recife, Brazil; Universidade Federal Rural de Pernambuco, Recife, Brazil; Universitat Politècnica de Catalunya, Barcelona, Spain","IEEE Software","16 Apr 2019","2019","36","3","50","54","Companies in a software ecosystem must understand which power capabilities drive cooperation or generate conflicts. In this article, we analyze how power influences the relationships among companies in ecosystems formed by small-to-medium enterprises as well as in platform ecosystems governed by large keystones.","1937-4194","","10.1109/MS.2018.290101618","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409909","Software;Software Engineering;Software Engineering;Management;organizational management and coordination;computing Milieux;Management of Computing and Information Systems;Software management;services computing;enterprise modeling and management;general;dynamics of services ecosystem;inter-enterprise collaboration;services value chain collaboration;services composition;services computing;strategic information systems planning;project and people management management of computing and information","Ecosystems;Software development management;Object recognition;Customer relationship management;System integration","innovation management;organisational aspects;small-to-medium enterprises","software ecosystem;power capabilities;platform ecosystems;small-to-medium enterprises","","","","11","","11 Jul 2018","","","IEEE","IEEE Magazines"
"User Engagement in the Era of Hybrid Agile Methodology","K. Schmitz; R. Mahapatra; S. Nerur","Georgia State University, United States; University of Texas at Arlington, United States; Information Systems, University of Texas at Arlington, United States","IEEE Software","17 Jun 2019","2019","36","4","32","40","Contemporary software development and implementation projects are increasingly adopting agile methods by tailoring and blending agile techniques into a traditional project framework. Common tailoring methods employed by project teams emphasize flexibility to embrace local project context.","1937-4194","","10.1109/MS.2018.290100623","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409910","agile software development;hybrid project methods;Software development;Software management;Management of Computing and Information Systems;Computing Mil;Software;Software Engineering;Software Engineering;Management;programming teams;project management and collaboration;service-oriented business consulting;service-oriented consulting","Training data;Information exchange;Green products;Software testing;Software development;Couplings","software development management;software prototyping","user engagement;hybrid agile methodology;agile methods;agile techniques;traditional project framework;project teams;local project context;contemporary software development","","","","15","","11 Jul 2018","","","IEEE","IEEE Magazines"
"Toward Analysis and Bug Finding in JavaScript Web Applications in the Wild","S. Ryu; J. Park; J. Park","Computing, Korea Advanced Institute of Science and Technology; Computing, Korea Advanced Institute of Science and Technology; Computing, Korea Advanced Institute of Science and Technology","IEEE Software","16 Apr 2019","2019","36","3","74","82","We present our journey to analyze and find bugs in JavaScript web applications in the wild. We describe technical challenges in analyzing them and our solutions to address the challenges via a series of open source analysis frameworks, the scalable analysis framework for ECMAScript (SAFE) family.","1937-4194","","10.1109/MS.2018.110113408","National Research Foundation of Korea; Institute for Information and Communications Technology Promotion; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254305","program analysis;semantics of programming languages;logics and meanings of programs;theory of computat;software;software engineering;software engineering;testing and debugging","Computer bugs;Browsers;Object recognition;Java;Electronic publishing;Computer applications","Internet;Java;program debugging;public domain software","bug finding;JavaScript web applications;technical challenges;open source analysis frameworks;scalable analysis framework;ECMAScript family;SAFE","","","","35","","11 Jan 2018","","","IEEE","IEEE Magazines"
"Refactoring Inspection Support for Manual Refactoring Edits","E. L. G. Alves; M. Song; T. Massoni; P. D. L. Machado; M. Kim","Computer Science Department, Federal University of Campina Grande, Campina Grande, Brazil; Computer Science Department, The University of Nebraska at Omaha, Omaha, NE; Computer Science Department, Universidade Federal de Campina Grande, Campina Grande, PB, Brazil; Systems and Computing Department, Federal University of Campina Grande, Campina Grande, Brazil; Computer Science Department, University of California, Los Angeles, CA","IEEE Transactions on Software Engineering","16 Apr 2018","2018","44","4","365","383","Refactoring is commonly performed manually, supported by regression testing, which serves as a safety net to provide confidence on the edits performed. However, inadequate test suites may prevent developers from initiating or performing refactorings. We propose RefDistiller, a static analysis approach to support the inspection of manual refactorings. It combines two techniques. First, it applies predefined templates to identify potential missed edits during manual refactoring. Second, it leverages an automated refactoring engine to identify extra edits that might be incorrect. RefDistiller also helps determine the root cause of detected anomalies. In our evaluation, RefDistiller identifies 97 percent of seeded anomalies, of which 24 percent are not detected by generated test suites. Compared to running existing regression test suites, it detects 22 times more anomalies, with 94 percent precision on average. In a study with 15 professional developers, the participants inspected problematic refactorings with RefDistiller versus testing only. With RefDistiller, participants located 90 percent of the seeded anomalies, while they located only 13 percent with testing. The results show RefDistiller can help check the correctness of manual refactorings.","1939-3520","","10.1109/TSE.2017.2679742","National Science Foundation; Google Faculty Award; National Institute of Science and Technology for Software Engineering; CNPq/Brasil; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874212","Refactoring;refactoring anomalies;code inspection","Manuals;Inspection;Testing;Computer bugs;Transforms;Engines;Detectors","program diagnostics;program testing;regression analysis;software maintenance","RefDistiller;seeded anomalies;refactoring inspection support;manual refactoring edits;regression testing;inadequate test suites;potential missed edits;automated refactoring engine;extra edits;generated test suites;running existing regression test suites;problematic refactorings","","3","","49","","8 Mar 2017","","","IEEE","IEEE Journals"
"Predictive Mutation Testing","J. Zhang; L. Zhang; M. Harman; D. Hao; Y. Jia; L. Zhang","Institute of Software, EECS, Peking University, Beijing, China; Department of Computer Science, University of Texas at Dallas, Richardson, TX; University College London, London, United Kingdom; Institute of Software, EECS, Peking University, Beijing, China; University College London, London, United Kingdom; Institute of Software, EECS, Peking University, Beijing, China","IEEE Transactions on Software Engineering","17 Sep 2019","2019","45","9","898","918","Test suites play a key role in ensuring software quality. A good test suite may detect more faults than a poor-quality one. Mutation testing is a powerful methodology for evaluating the fault-detection ability of test suites. In mutation testing, a large number of mutants may be generated and need to be executed against the test suite under evaluation to check how many mutants the test suite is able to detect, as well as the kind of mutants that the current test suite fails to detect. Consequently, although highly effective, mutation testing is widely recognized to be also computationally expensive, inhibiting wider uptake. To alleviate this efficiency concern, we propose Predictive Mutation Testing (PMT): the first approach to predicting mutation testing results without executing mutants. In particular, PMT constructs a classification model, based on a series of features related to mutants and tests, and uses the model to predict whether a mutant would be killed or remain alive without executing it. PMT has been evaluated on 163 real-world projects under two application scenarios (cross-version and cross-project). The experimental results demonstrate that PMT improves the efficiency of mutation testing by up to 151.4X while incurring only a small accuracy loss. It achieves above 0.80 AUC values for the majority of projects, indicating a good tradeoff between the efficiency and effectiveness of predictive mutation testing. Also, PMT is shown to perform well on different tools and tests, be robust in the presence of imbalanced data, and have high predictability (over 60 percent confidence) when predicting the execution results of the majority of mutants.","1939-3520","","10.1109/TSE.2018.2809496","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; NSF; EPSRC grant DAASE Dynamic Adaptive Automated Software Engineering; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8304576","PMT;mutation testing;machine learning;binary classification","Predictive models;Pattern classification;Software testing;Sensitivity analysis;Software quality;Machine learning","pattern classification;program testing;sensitivity analysis;software quality","predictive mutation testing;good test suite;PMT;mutation testing results;software quality;fault-detection ability;classification model;AUC values;imbalanced data","","18","","105","","28 Feb 2018","","","IEEE","IEEE Journals"
"Detecting Overly Strong Preconditions in Refactoring Engines","M. Mongiovi; R. Gheyi; G. Soares; M. Ribeiro; P. Borba; L. Teixeira","Department of Computing and Systems, Federal University of Campina Grande, Campina Grande, PB, Brazil; Department of Computing and Systems, Federal University of Campina Grande, Campina Grande, PB, Brazil; Department of Computing and Systems, Federal University of Campina Grande, Campina Grande, PB, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Informatics Center, Federal University of Pernambuco, Recife, PE, Brazil; Informatics Center, Federal University of Pernambuco, Recife, PE, Brazil","IEEE Transactions on Software Engineering","14 May 2018","2018","44","5","429","452","Refactoring engines may have overly strong preconditions preventing developers from applying useful transformations. We find that 32 percent of the Eclipse and JRRT test suites are concerned with detecting overly strong preconditions. In general, developers manually write test cases, which is costly and error prone. Our previous technique detects overly strong preconditions using differential testing. However, it needs at least two refactoring engines. In this work, we propose a technique to detect overly strong preconditions in refactoring engines without needing reference implementations. We automatically generate programs and attempt to refactor them. For each rejected transformation, we attempt to apply it again after disabling the preconditions that lead the refactoring engine to reject the transformation. If it applies a behavior preserving transformation, we consider the disabled preconditions overly strong. We evaluate 10 refactorings of Eclipse and JRRT by generating 154,040 programs. We find 15 overly strong preconditions in Eclipse and 15 in JRRT. Our technique detects 11 bugs that our previous technique cannot detect while missing 5 bugs. We evaluate the technique by replacing the programs generated by JDolly with the input programs of Eclipse and JRRT test suites. Our technique detects 14 overly strong preconditions in Eclipse and 4 in JRRT.","1939-3520","","10.1109/TSE.2017.2693982","National Institute of Science and Technology for Software Engineering (INES); CNPq; CAPES; FACEPE; FAPEAL PPGs; DEVASSES; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898404","Refactoring;overly strong preconditions;automated testing;program generation","Engines;Computer bugs;Databases;Testing;Java;Electronic mail;Usability","automatic programming;C language;Java;object-oriented programming;program debugging;program testing;software maintenance","JRRT test suites;refactoring engine;overly strong preconditions;Eclipse;differential testing;rejected transformation;JDolly","","2","","53","","12 Apr 2017","","","IEEE","IEEE Journals"
"Creating Rich and Representative Personas by Discovering Affordances","M. Mesgari; C. Okoli; A. O. de Guinea","Loyola Marymount University, CA, U.S.A; Université Côte d'Azur, Paris, France; Department of Strategy and Information Systems, Universidad de Deusto, Bilbo, Bizkaia, Spain","IEEE Transactions on Software Engineering","16 Oct 2019","2019","45","10","967","983","During the last decade, information system designers have used the persona technique to put user needs and preferences at the center of all development decisions. Persona development teams draw on qualitative data, quantitative data or a combination of both to develop personas that are representative of the target users. Despite the benefits of both approaches, qualitative methods are limited by the cognitive capabilities of the experts, whereas quantitative methods lack contextual richness. To gain the advantages of both approaches, this article suggests a mixed qualitative-quantitative approach to create user personas based on the patterns of the affordances they actualize rather than merely the actions they take. It enriches personas by referring to the purposes fulfilled through affordance actualizations, and it grounds personas in readily available objective log data. This study illustrates the practical value of the proposed methodology by empirically creating personas based on real user data. Furthermore, it demonstrates its value by having practitioners compare the suggested method to that of qualitative-only and quantitative-only methods.","1939-3520","","10.1109/TSE.2018.2826537","Concordia University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8337801","Personas;affordances;mixed qualitative and quantitative methods;user modeling;interview;card sorting;cluster analysis;systems design and implementation;design and evaluation of IT infrastructure;questionnaire surveys","Software;Maintenance engineering;Task analysis;Aging;Interviews;Human computer interaction","formal specification;human computer interaction;information systems;user centred design","persona development teams;qualitative data;quantitative data;cognitive capabilities;user personas;information system designers;human-computer interaction;user-centered design;software engineering;requirements engineering;persona creation","","","","64","","13 Apr 2018","","","IEEE","IEEE Journals"
"Group-Development Psychology Training: The Perceived Effects on Agile Software-Development Teams","L. Gren; A. Goldman; C. Jacobsson","Software Engineering, Chalmers University of Technology, Gothenburg, Sweden; Computer Science, University of Sao Paulo, Sao Paulo, Brazil; Psychology, University of Gothenburg, Gothenburg, Sweden","IEEE Software","15 Apr 2020","2020","37","3","63","69","Research has shown that the maturity of small workgroups, from a psychological perspective, is intimately connected to team agility. This study showed a perceived positive effect of training agile teams in group developmental psychology. We therefore see huge potential in training agile teams in this topic since the positive effects might span over the entire software development organization.","1937-4194","","10.1109/MS.2019.2955675","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8911247","group development;group dynamics;agile teams;behavioral software engineering;psychology","Psychology;Training;Companies;Teamwork;Agile software development","project management;psychology;software development management;software prototyping;team working","group developmental psychology;training agile teams;software development organization;group-development psychology training;agile software-development teams;psychological perspective;perceived positive effect;team agility","","","","16","","25 Nov 2019","","","IEEE","IEEE Magazines"
"Actionable Analytics for Strategic Maintenance of Critical Software: An Industry Experience Report","D. Port; B. Taber",University of Hawaii at Manoa; Jet Propulsion Laboratory,"IEEE Software","25 Dec 2017","2018","35","1","58","63","NASA has been successfully sustaining the continuous operation of its critical navigation software systems for over 12 years. To accomplish this, NASA scientists must continuously monitor their process, report on current system quality, forecast maintenance effort, and sustain required staffing levels. This report presents some examples of the use of a robust software metrics and analytics program that enables actionable strategic maintenance management of a critical system (Monte) in a timely, economical, and risk-controlled fashion. This article is part of a special issue on Actionable Analytics for Software Engineering.","1937-4194","","10.1109/MS.2017.4541055","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239926","software maintenance;critical systems;reliability;software analytics;Monte;navigation systems;NASA;software engineering;software development","Computer bugs;Software maintenance;Biological system modeling;Data models;Analytical models","aerospace computing;software maintenance;software metrics","industry experience report;critical navigation software systems;NASA scientists;maintenance effort;robust software metrics;actionable strategic maintenance management;actionable analytics","","","","2","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Using Analytics to Guide Improvement during an Agile–DevOps Transformation","B. Snyder; B. Curtis",Fannie Mae; CAST,"IEEE Software","25 Dec 2017","2018","35","1","78","83","Over the past three years, Fannie Mae IT has transformed from a traditional waterfall organization to a lean culture enabled by agile methods and DevOps. Software analytics were used to guide improvements and evaluate progress. Project-level analytics enabled agile teams to improve structural quality and evaluate their practices as they delivered greater functionality over shrinking delivery intervals. Aggregated enterprise metrics displayed an average 38 percent improvement in structural quality, with some applications achieving 48 percent to 70 percent gains. These quality improvements accompanied a 28 percent increase in productivity. The frequency of releases shrank from cycles of nine to 18 months, down to releases every couple of one- to two-month sprints. The article discusses examples of how analytics were used, along with challenges in selecting measures and implementing analytics in an agile-DevOps transformation. This article is part of a special issue on Actionable Analytics for Software Engineering.","1937-4194","","10.1109/MS.2017.4541032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239932","software measurement;software quality;software productivity;software analytics;DevOps;agile transformation;agile development;software development;software engineering","Productivity;Software measurement;Monitoring;Portfolios;Software testing","software development management;software metrics;software prototyping;systems analysis","lean culture;agile methods;agile teams;aggregated enterprise metrics;software analytics;actionable analytics;agile-DevOps transformation;project-level analytics;structural quality improvement","","1","","9","","25 Dec 2017","","","IEEE","IEEE Magazines"
"How Robust Is Your Development Team?","L. Xiao; Z. Yu; B. Chen; X. Wang",Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology; Stevens Institute of Technology,"IEEE Software","25 Dec 2017","2018","35","1","64","71","Given the collaborative nature of software development, a robust team is a necessity for project success in both commercial and open source environments. That is, in the event of developers' absence due to various reasons, how could it potentially disrupt a team's routine operations? This article offers an automatic approach to intuitively visualize development team hierarchy, quantify overall team robustness, and identify the point (developers) of risk for team robustness. An investigation of six Apache open source projects has shown its effectiveness. This article is part of a special issue on Actionable Analytics for Software Engineering.","1937-4194","","10.1109/MS.2017.4541052","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239942","software collaboration;social network;information loss;team robustness;mining software repository;software development;software engineering","Software development;Collaboration;Visualization;Loss measurement;Data mining","public domain software;software development management;team working","software development;project success;commercial source environments;open source environments;development team hierarchy;team robustness;Apache open source projects","","","","10","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Contrasting Big Bang With Continuous Integration Through Defect Reports","N. Mellegard; H. Burden; D. Levin; K. Lind; A. Magazinius","RISE Viktoria, Gothenburg, Sweden; RISE Viktoria, Gothenburg, Sweden; Volvo Car Corporation, Sweden; HiMinds Goteborg AB, Sweden; RISE Viktoria, Gothenburg, Sweden","IEEE Software","15 Apr 2020","2020","37","3","14","20","Continuous integration promises ea rlier defect detection, quality improvements, and more customer value delivered faster. In this case study, we examined development of software for the advanced safety and driver support component of a Swedish vehicle manufacturer in two consecutive projects.","1937-4194","","10.1109/MS.2018.2880822","Vinnova; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8573886","Software Engineering Process;Process measurement;Process metrics","Software development management;Software quality;Companies;Automobiles;Software engineering;Manufacturing processes","automobile industry;customer services;production engineering computing;software development management","driver support component;consecutive projects;Swedish vehicle manufacturer;advanced safety;customer value;quality improvements;defect detection;defect reports;continuous integration;contrasting big bang","","1","","12","","12 Dec 2018","","","IEEE","IEEE Magazines"
"Digital Transformation","C. Ebert; C. H. C. Duarte",Vector Consulting Services; National Bank of Social and Economic Development,"IEEE Software","6 Jul 2018","2018","35","4","16","21","This instalment of the Software Technology department discusses how the digital transformation is affecting software technology and the software industry.","1937-4194","","10.1109/MS.2018.2801537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405624","digital transformation;systems engineering;disruptive technology;software development;software engineering;Software Technology","Software development;Production planning;Production systems;Productivity;Digital systems;Software engineering","","","","8","","9","","6 Jul 2018","","","IEEE","IEEE Magazines"
"The Effort Savings from Using NLP to Classify Equivalent Requirements","D. Falessi; G. Cantone","California Polytechnic State University, San Luis Obispo, California United States; University of Rome Tor Vergata, Italy","IEEE Software","14 Jan 2019","2019","36","1","48","55","When Considering What and how to reuse, one must understand the differences and similarities of the systems being developed; this activity is part of the domain analysis. Among the several ways to perform domain analysis, identifying equivalent requirements (that is, the common elements in the domain) is scalable and noninvasive, and it supports the consolidation of requirements.","1937-4194","","10.1109/MS.2018.2874620","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491267","Empirical software engineering;Requirements consolidation;NLP technique","Natural language processing;Software reliability;Reliability engineering;Software measurement;Software engineering;Classification","natural language processing;software reusability;software tools","NLP;equivalent requirements;domain analysis;requirements consolidation","","","","13","","14 Oct 2018","","","IEEE","IEEE Magazines"
"From Incident to Insight: Incident Responders and Software Innovation","R. Biddle; J. M. Brown; S. Greenspan","Computer Science, Carleton University; Computer Science, Carleton University; CA Technologies","IEEE Software","14 Jan 2019","2019","36","1","56","62","Over The Last decade, new software processes have appeared that emphasize collaboration among people involved in creating successful software. For example, agile methods stress collaboration between development teams and business clients, 1 and DevOps emphasizes better collaboration between development teams and deployment teams.","1937-4194","","10.1109/MS.2017.442103917","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186462","Software;software engineering;design;methodologies;computing milieux;Computers and Society;organizational impacts;computer-supported collaborative work","Collaborative work;Software engineering;Software development management;Social implications of technology;Sociotechnical systems;Organizations","software development management;software prototyping","development teams;software processes;agile methods;software innovation;incident responders;business clients;deployment teams","","","","16","","11 Dec 2017","","","IEEE","IEEE Magazines"
"On the Definition of Microservice Bad Smells","D. Taibi; V. Lenarduzzi",Tampere University of Technology; Tampere University of Technology,"IEEE Software","4 May 2018","2018","35","3","56","62","Code smells and architectural smells (also called bad smells) are symptoms of poor design that can hinder code understandability and decrease maintainability. Several bad smells have been defined in the literature for both generic architectures and specific architectures. However, cloud-native applications based on microservices can be affected by other types of issues. In order to identify a set of microservice-specific bad smells, researchers collected evidence of bad practices by interviewing 72 developers with experience in developing systems based on microservices. Then, they classified the bad practices into a catalog of 11 microservice-specific bad smells frequently considered harmful by practitioners. The results can be used by practitioners and researchers as a guideline to avoid experiencing the same difficult situations in the systems they develop.","1937-4194","","10.1109/MS.2018.2141031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354414","microservice;antipattern;anti-pattern;code smell;architectural smell;bad smell;cloud computing;software development;software engineering","Interviews;Logic gates;Service computing;Software engineering;Software architecture;Cloud computing;Software development","cloud computing;public domain software;software architecture;software quality","microservice bad smells;architectural smells;code understandability;generic architectures;specific architectures;cloud-native applications;microservice-specific bad smells","","21","","18","","4 May 2018","","","IEEE","IEEE Magazines"
"Challenges of Domain-Driven Microservice Design: A Model-Driven Perspective","F. Rademacher; J. Sorgalla; S. Sachweh",Dortmund University of Applied Sciences and Arts; Dortmund University of Applied Sciences and Arts; Dortmund University of Applied Sciences and Arts,"IEEE Software","4 May 2018","2018","35","3","36","43","Domain-driven design (DDD) is a model-driven methodology to capture relevant domain knowledge for software design. It provides the means to isolate domain concepts and identify concept relationships. This makes DDD particularly appropriate for designing microservice architectures, because functional microservices focus on realizing distinct business capabilities. This article explores the challenges of domain-driven microservice design and presents ways to cope with them based on model-driven development.","1937-4194","","10.1109/MS.2018.2141028","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354426","microservices;domain-driven design;DDD;model-driven development;MDD;microservice architecture;service engineering;domain-specific architectures;modeling of computer architecture;software engineering;software development","Unified modeling language;Context modeling;Software engineering;Logic gates;Service computing;Software architecture","formal specification;object-oriented programming;software architecture","domain-driven design;software design;domain concepts;microservice design;domain knowledge;domain-driven microservice design;microservice architecture design;model-driven development;functional microservices;model-driven methodology","","14","","7","","4 May 2018","","","IEEE","IEEE Magazines"
"Process Improvement Archaeology: What Led Us Here, and What’s Next?","M. Unterkalmsteiner; T. Gorschek",Blekinge Institute of Technology; Blekinge Institute of Technology,"IEEE Software","6 Jul 2018","2018","35","4","53","61","While in every organization corporate culture and history change over time, intentional efforts to identify performance problems are of particular interest when trying to understand the current state of an organization. The results of past improvement initiatives can shed light on the evolution of an organization and represent, with the advantage of perfect hindsight, a learning opportunity for future process improvements. The opportunity to test this premise occurred in an applied research collaboration with the Swedish Transport Administration, the government agency responsible for the planning, implementation, and maintenance of long-term rail, road, shipping, and aviation infrastructure in Sweden. This article is part of a theme issue on Process Improvement.","1937-4194","","10.1109/MS.2018.227110005","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356179","process implementation and change;requirements engineering;process improvement;Process Improvement Archaeology;Swedish Transport Administration;software development;software engineering","Requirements engineering;Software engineering;Process planning;Systematics;Rail transportation;Software development management;Aerospace engineering","business data processing;formal specification;organisational aspects","learning opportunity;applied research collaboration;Swedish Transport Administration;requirements engineering;government agency;process improvement archaeology;corporate culture","","1","","15","","8 May 2018","","","IEEE","IEEE Magazines"
"Leveraging Software-Defined Networking for Incident Response in Industrial Control Systems","A. F. Murillo Piedrahita; V. Gaur; J. Giraldo; Á. A. Cárdenas; S. J. Rueda",Universidad de los Andes; University of Texas at Dallas; University of Texas at Dallas; University of Texas at Dallas; Universidad de los Andes,"IEEE Software","25 Dec 2017","2018","35","1","44","50","In the past decade, the security of industrial control systems has emerged as a research priority in order to safeguard our critical infrastructures. A large number of research efforts have focused on intrusion detection in industrial networks; however, few of them discuss what to do after an intrusion has been detected. Because the safety of most of these control systems is time sensitive, we need new research on automatic incident response. This article shows how software-defined networks and network function virtualization can facilitate automatic incident response to a variety of attacks against industrial networks. It also presents a prototype of an incident-response solution that detects and responds automatically to sensor attacks and controller attacks. This work shows the promise that cloud-enabled software-defined networks and virtual infrastructures hold as a way to provide novel defense-in-depth solutions for industrial systems. This article is part of a special issue on Software Safety and Security Risk Mitigation in Cyber-physical Systems.","1937-4194","","10.1109/MS.2017.4541054","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239925","software-defined networking;software-defined networks;network function virtualization;SDN;NFV;industrial control systems;incident response;cyber-physical systems;cybersecurity;software safety;software security;software engineering;software development","Sensors;Integrated circuits;Software defined networking;Software development;Computer security;Software engineering;Cyber-physical systems","cloud computing;computer network security;control engineering computing;industrial control;production engineering computing;software defined networking;virtualisation","incident-response solution;industrial systems;Cyber-physical Systems;industrial control systems;critical infrastructures;intrusion detection;industrial networks;automatic incident response;network function virtualization;software safety;software-defined networking","","10","","10","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Migrating Enterprise Legacy Source Code to Microservices: On Multitenancy, Statefulness, and Data Consistency","A. Furda; C. Fidge; O. Zimmermann; W. Kelly; A. Barros","Queensland University of Technology; Queensland University of Technology; University of Applied Sciences of Eastern Switzerland, Rapperswil; Queensland University of Technology; Queensland University of Technology","IEEE Software","4 May 2018","2018","35","3","63","72","Microservice migration is a promising technique to incrementally modernize monolithic legacy enterprise applications and enable them to exploit the benefits of cloud-computing environments. This article elaborates on three challenges of microservice migration: multitenancy, statefulness, and data consistency. The authors show how to identify each of these challenges in legacy code and explain refactoring and architectural pattern-based migration techniques relevant to microservice architectures. They explain how multitenancy enables microservices to be utilized by different organizations with distinctive requirements, why statefulness affects both the availability and reliability of a microservice system, and why data consistency challenges are encountered when migrating legacy code that operates on a centralized data repository to microservices operating on decentralized data repositories. They also explain the interdependencies between multitenancy, statefulness, and data consistency.","1937-4194","","10.1109/MS.2017.440134612","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186442","microservices;multitenancy;refactoring;architectural patterns;statefulness;data consistency;software development;software engineering","Databases;User interfaces;Object recognition;Logic gates;Cloud computing;Service computing;Software engineering","business data processing;cloud computing;software architecture;software maintenance","migrating enterprise legacy source code;microservice migration;monolithic legacy enterprise applications;cloud-computing environments;refactoring pattern-based migration techniques;architectural pattern-based migration techniques;microservice architectures;microservice system;data consistency challenges;migrating legacy code;decentralized data repositories","","5","","20","","11 Dec 2017","","","IEEE","IEEE Magazines"
"Context-aware Personalized Crowdtesting Task Recommendation","J. Wang; Y. Yang; S. Wang; C. Chen; D. Wang; Q. Wang","Institute of Software, Chinese Academy of Sciences, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, 100190 (e-mail: junjie@iscas.ac.cn); School of Systems and Enterprises, Stevens Institute of Technology, 33694 Hoboken, New Jersey, United States, (e-mail: yyang4@stevens.edu); Department of Electrical Engineering and Computer Science, York University, 7991 Toronto, Ontario, Canada, (e-mail: wangsong@eecs.yorku.ca); Faculty of Information Technology, Monash University, Melbourne, Victoria, Australia, 3800 (e-mail: chunyang.chen@monash.edu); Institute of Software, Chinese Academy of Sciences, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing, China, (e-mail: dandan@iscas.ac.cn); Institute of Software, Chinese Academy of Sciences, Beijing, Beijing, China, 100190 (e-mail: wq@itechs.iscas.ac.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Crowdsourced software testing (short for crowdtesting) is a special type of crowdsourcing. It requires that crowdworkers master appropriate skill-sets and commit significant effort for completing a task. Abundant uncertainty may arise during a crowdtesting process due to imperfect information between the task requester and crowdworkers. For example, a worker frequently chooses tasks in an ad hoc manner in crowdtesting context, and an inappropriate task selection may lead to the worker's failing to detect any bugs, and significant testing effort unpaid and wasted. Recent studies have explored methods for supporting task requesters to make informed decisions on task pricing, worker recommendation, and so on. Unfortunately, very few study offers decision making support from the crowdworkers' perspectives. We motivate this study through a pilot study, revealing the large portion (74\%) of unpaid crowdworkers' effort due to the inappropriate task choice. Drawn from our previous work on context-aware crowdworker recommendations, we advocate a more effective alternative to manual task selection would be to provide contextualized and personalized task recommendation considering the diverse distribution of worker preference and expertise, with objectives to increase their winning chances and to potentially reduce the frequency of unpaid crowd work. This paper proposes a context-aware personalized task recommendation approach PTRec, consisting of a testing context model and a learning-based task recommendation model to aid dynamic worker decision in selecting crowdtesting tasks. The testing context model is constructed in two perspectives, i.e., process context and resource context, to capture the in-process progress-oriented information and crowdworkers' characteristics respectively. Built on top of this context model, the learning-based task recommendation model extracts 60 features automatically, and employs random forest learner to generate dynamic and personalized task recommendation which matches workers' expertise and interest. The evaluation is conducted on 636 crowdtesting tasks involving 2,404 crowdworkers from one of the largest crowdtesting platforms, and results show the potential in recommending proper tasks to workers so as to improve bug detection efficiency and increase their monetary earnings.","1939-3520","","10.1109/TSE.2021.3081171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9435104","Crowdsourced testing;Task recommendation;Testing context model","Task analysis;Computer bugs;Testing;Context modeling;Feature extraction;Crowdsourcing;Videos","","","","","","","IEEE","18 May 2021","","","IEEE","IEEE Early Access Articles"
"CBUA: A probabilistic, predictive, and practical approach for evaluating test suite effectiveness","P. Zhang; Y. Li; W. Ma; Y. Yang; L. Chen; H. Lu; Y. Zhou; B. Xu","State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: DZ1833034@smail.nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: yanhuili@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: wwyma@smail.nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: yangyibiao@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: lchen@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: 32493172@qq.com); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: zhouyuming@nju.edu.cn); bwxu@nju.edu.cn, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: bwxu@nju.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Knowing the effectiveness of a test suite is essential for many activities such as guiding the generation of new test cases and assessing the test adequacy of code. Mutation testing is a commonly used defect injection technique for evaluating the effectiveness of a test suite. However, it is usually computationally expensive, as a large number of mutants (buggy versions) are needed to be generated from a production code under test and executed against the test suite. In order to reduce the expensive testing cost, recent studies proposed to use supervised models to predict the effectiveness of a test suite without executing the test suite against the mutants. Nonetheless, the training of such a supervised model requires labeled data, which still depends on the costly mutant execution. Furthermore, existing models are based on traditional supervised learning techniques, which assumes that the training and testing data come from the same distribution. But, in practice, software systems are subject to considerable concept drifts, i.e. the same distribution assumption usually does not hold. This can lead to inaccurate predictions of a learned supervised model on the target code as time progresses. To tackle these problems, in this paper, we propose a Coverage-Based Unsupervised Approach (CBUA) for evaluating the effectiveness of a test suite. The whole process only requires a one-time execution of the test suite against the target production code, without involving any mutant execution and any training data. CBUA can ensure the score monotonicity property (i.e. adding test cases to a test suite does not decrease its mutation score), which may be violated by a supervised approach. The experimental results show that CBUA is very competitive to the state-of-the-art supervised approaches in terms of the prediction accuracy. Since CBUA is an easy-to-implement model with a low cost, we suggest that it should be used as a baseline approach for comparison when any novel prediction approach is proposed in future studies.","1939-3520","","10.1109/TSE.2020.3010361","the National Key R and D Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144443","Effectiveness;test suites;coverage;unsupervised model;mutation testing","Testing;Predictive models;Production;Data models;Computational modeling;Training;Training data","","","","","","","","20 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Sequential Model Optimization for Software Effort Estimation","T. Xia; R. Shu; X. Shen; T. Menzies","computer science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: txia4@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, 27695 (e-mail: rshu@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: xshen5@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Many methods have been proposed to estimate how much effort is required to build and maintain software. Much of that research tries to recommend a single method - an approach that makes the dubious assumption that one method can handle the diversity of software project data. To address that drawback, we apply a configuration technique called “ROME” (Rapid Optimizing Methods for Estimation), which uses sequential model-based optimization (SMO) to find what configuration settings of effort estimation techniques work best for a particular data set. We test this method using data from 1161 classic waterfall projects and 120 contemporary projects (from GitHub). In terms of magnitude of relative error and standardized accuracy, we find that ROME achieves better performance than the state-of-the-art methods for both classic and contemporary projects. In addition, we conclude that we should not recommend one method for estimation. Rather, it is better to search through a wide range of different methods to find what works best for the local data. To the best of our knowledge, this is the largest effort estimation experiment yet attempted and the only one to test its methods on classic and contemporary projects.","1939-3520","","10.1109/TSE.2020.3047072","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9307246","Effort Estimation;COCOMO;Hyperparameter Tuning;Regression Trees;Sequential Model Optimization","Estimation;Software;Tools;Optimization;Data models;Task analysis;Mathematical model","","","","","","","IEEE","24 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Active Learning of Discriminative Subgraph Patterns for API Misuse Detection","H. J. Kang; D. Lo","School of Information Systems, Singapore Management University, 54756 Singapore, Singapore, Singapore, (e-mail: hjkang.2018@phdcs.smu.edu.sg); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","A common cause of bugs and vulnerabilities are the violations of usage constraints associated with Application Programming Interfaces (APIs). API misuses are common in software projects, and while there have been techniques proposed to detect such misuses, studies have shown that they fail to reliably detect misuses while reporting many false positives. One limitation of prior work is the inability to reliably identify correct patterns of usage. Many approaches confuse a usage pattern's frequency for correctness. Due to the variety of alternative usage patterns that may be uncommon but correct, anomaly detection-based techniques have limited success in identifying misuses. We address these challenges and propose ALP (Actively Learned Patterns), reformulating API misuse detection as a classication problem. After representing programs as graphs, ALP mines discriminative subgraphs. While still incorporating frequency information, through limited human supervision, we reduce the reliance on the assumption relating frequency and correctness. The principles of active learning are incorporated to shift human attention away from the most frequent patterns. Instead, ALP samples informative and representative examples while minimizing labeling effort. In our empirical evaluation, ALP substantially outperforms prior approaches on both MUBench, an API Misuse benchmark, and a new dataset that we constructed from real-world software projects.","1939-3520","","10.1109/TSE.2021.3069978","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9392340","API-Misuse Detection;Discriminative Subgraph Mining;Graph Classification;Active Learning","Detectors;Software development management;Java;Tools;Software;Computer bugs;Ciphers","","","","","","","IEEE","31 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Dominoes: An Interactive Exploratory Data Analysis tool for Software Relationships","J. R. da Silva Junior; D. P. Campagna; E. Clua; A. Sarma; L. G. P. Murta","Computing, Instituto Federal do Rio de Janeiro, Rio de Janeiro, Rio de Janeiro Brazil (e-mail: jose.junior@ifrj.edu.br); Computing Institute, Universidade Federal Fluminense, Niteri, Rio de Janeiro Brazil (e-mail: dprett@ic.uff.br); Computing Institute, Universidade Federal Fluminense, 28110 Niteroi, Rio de Janeiro Brazil (e-mail: esteban@ic.uff.br); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States 97331 (e-mail: anita.sarma@oregonstate.edu); Computer Science, Universidade Federal Fluminense, Niteri, RJ Brazil 24210-240 (e-mail: leomurta@ic.uff.br)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Project comprehension questions, such as “which modified artifacts can affect my work” and “how can I identify the developers who should be assigned to a given task” are difficult to answer, require an analysis of the project and its data, are context specific, and cannot always be pre-defined. Current research approaches are restricted to post hoc analyses over software repositories. Very few interactive exploratory tools exist because the large amount of data that need to be analyzed prohibits its exploration at interactive rates. Moreover, such analyses typically require the user to create complex scripts or queries to extract the desired information from data. Here we present Dominoes, a tool for interactive data exploration aimed at end users (i.e., project managers or developers). Dominoes allows users to interact with different types and units of data to investigate project relationships and view intermediate results as charts, tables, and graphs. Additionally, it allows users to save the derived data as well as their exploration paths for later use. In a scenario-based evaluation study, participants achieved a success rate of 86% in their explorations, with a mean time of 7.25 minutes for answering a set of (project) exploration questions.","1939-3520","","10.1109/TSE.2020.2988241","Fundao Carlos Chagas Filho de Amparo Pesquisa do Estado do Rio de Janeiro; National Science Foundation; Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico; Coordenao de Aperfeioamento de Pessoal de Nvel Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072287","Design Tools and Techniques;Interactive data exploration and discovery;Evaluation/methodology","Tiles;Data mining;Graphics processing units;Tools;Feature extraction","","","","","","","","20 Apr 2020","","","IEEE","IEEE Early Access Articles"
"A fast clustering algorithm for modularization of large-scale software systems","N. Teymourian; H. Izadkhah; A. Isazadeh","Department of Computer Science, University of Tabriz, 56947 Tabriz, East Azerbaijan, Iran (the Islamic Republic of), (e-mail: nvd.teymourian@gmail.com); Department of Computer Science, University of Tabriz, Tabriz, Esat Azarbijan, Iran (the Islamic Republic of), (e-mail: habib_eizadkhah@yahoo.com); Department of Computer Science, University of Tabriz, Tabriz, East Azerbaijan, Iran (the Islamic Republic of), (e-mail: isazadeh@tabrizu.ac.ir)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","A software system evolves overtime to meet the needs of users. Understanding a program is the most important step to apply new requirements. Clustering techniques by dividing a program into small and meaningful parts make it possible to understand the program. In general, clustering algorithms are classified into two categories: hierarchical and non-hierarchical algorithms (such as search-based approaches). While clustering problems generally tend to be NP-hard, search-based algorithms produce acceptable clustering, but have time and space constraints and hence they are inefficient in large-scale software systems. Most algorithms currently used in software clustering fields do not scale well when applied to large and very large applications. In this paper, we present a new and fast clustering algorithm, named FCA, that can overcome space and time constraints of existing algorithms by performing operations on the dependency matrix and extracting other matrices based on a set of features. The experimental results on ten small-sized applications, ten folders with different functionalities from Mozilla Firefox, a large-sized application (namely ITK), and a very large-sized application (namely Chromium) demonstrate that the proposed algorithm achieves higher quality modularization compared with hierarchical algorithms. It can also compete with search-based algorithms and a clustering algorithm based on subsystem patterns. But the running time of the proposed algorithm is much shorter than that of the hierarchical and non-hierarchical algorithms. The source code of the proposed algorithm can be accessed at https://github.com/SoftwareMaintenanceLab.","1939-3520","","10.1109/TSE.2020.3022212","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9187267","Software clustering;Software modularization;Software maintenance;Software comprehension;Architecture recovery","Clustering algorithms;Software algorithms;Search problems;Software systems;Semantics;Software architecture","","","","","","","","7 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Comparing Block-based Programming Models for Two-armed Robots","N. Ritschel; V. Kovalenko; R. Holmes; R. Garcia; D. C. Shepherd","Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: ritschel@cs.ubc.ca); Computer Science, Delft University of Technology, 2860 Delft, Zuid-Holland Netherlands (e-mail: v.v.kovalenko@tudelft.nl); Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: rtholmes@cs.ubc.ca); Computer Science, The University of British Columbia, 8166 Vancouver, British Columbia Canada (e-mail: rxg@cs.ubc.ca); Department of Computer Science, Virginia Commonwealth University, 6889 Richmond, Virginia United States (e-mail: shepherdd@vcu.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Modern industrial robots can work alongside human workers and coordinate with other robots. This means they can perform complex tasks, but doing so requires complex programming. Therefore, robots are typically programmed by experts, but there are not enough to meet the growing demand for robots. To reduce the need for experts, researchers have tried to make robot programming accessible to factory workers without programming experience. However, none of that previous work supports coordinating multiple robot arms that work on the same task. In this paper we present four block-based programming language designs that enable end-users to program two-armed robots. We analyze the benefits and trade-offs of each design on expressiveness and user cognition, and evaluate the designs based on a survey of 273 professional participants of whom 110 had no previous programming experience. We further present an interactive experiment based on a prototype implementation of the design we deem best. This experiment confirmed that novices can successfully use our prototype to complete realistic robotics tasks. This work contributes to making coordinated programming of robots accessible to end-users. It further explores how visual programming elements can make traditionally challenging programming tasks more beginner-friendly.","1939-3520","","10.1109/TSE.2020.3027255","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9207834","Programming environments;User interfaces;Robot programming;Parallel programming","Robot kinematics;Programming profession;Visualization;Task analysis;Manipulators","","","","","","","","28 Sep 2020","","","IEEE","IEEE Early Access Articles"
"PackerGrind: An Adaptive Unpacking System for Android Apps","L. Xue; H. Zhou; X. Luo; L. Yu; D. Wu; Y. Zhou; X. Ma","Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong China (e-mail: cslxue@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: sunmoonsky0001@gmail.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxluo@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: yulele08@gmail.com); College of Information Sciences and Technology, Penn State University, University Park, Pennsylvania United States 16802 (e-mail: dwu@ist.psu.edu); Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: yajin_zhou@zju.edu.cn); School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, Shaanxi China (e-mail: ma.xjtu@qq.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","App developers are increasingly using packing services (or packers) to protect their code against being reverse engineered or modified. However, such packing techniques are also leveraged by the malicious developers to prevent the malware from being analyzed and detected by the static malware analysis and detection systems. Though there are already studies on unpacking packed Android apps, they usually leverage the manual reverse engineered packing behaviors to unpack apps packed by the specific packers and cannot be applied to the evolving and new packers. In this paper, we propose a novel unpacking approach with the capacity of adaptively unpacking the evolving and newly encountered packers. Also, we develop a new system, named PackerGrind, based on this adaptive approach for unpacking Android packers. The evaluation with real packed apps demonstrates that PackerGrind can successfully reveal packers? protection mechanisms, effectively handle their evolution and recover Dex files with low overhead.","1939-3520","","10.1109/TSE.2020.2996433","Zhejiang Key RD; Leading Innovative and Entrepreneur Team Introduction Program of Zhejiang; Office of Naval Research; Hong Kong RGC Project; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9098088","","Androids;Humanoid robots;Runtime;Subspace constraints;Open area test sites;Tools;Monitoring","","","","1","","","","21 May 2020","","","IEEE","IEEE Early Access Articles"
"DEFECTCHECKER: Automated Smart Contract Defect Detection by Analyzing EVM Bytecode","J. Chen; X. Xia; D. Lo; J. Grundy; X. Luo; T. Chen","Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3168 (e-mail: Jiachi.Chen@monash.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: brokendragon@uestc.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Smart contracts are Turing-complete programs running on the blockchain. They are immutable and cannot be modified, even when bugs are detected. Therefore, ensuring smart contracts are bug-free and well-designed before deploying them to the blockchain is extremely important. A contract defect is an error, flaw or fault in a smart contract that causes it to produce an incorrect or unexpected result, or to behave in unintended ways. Detecting and removing contract defects can avoid potential bugs and make programs more robust. Our previous work defined 20 contract defects for smart contracts and divided them into five impact levels. According to our classification, contract defects with seriousness level between 1-3 can lead to unwanted behaviors, e.g., a contract being controlled by attackers. In this paper, we propose DefectChecker, a symbolic execution-based approach and tool to detect eight contract defects that can cause unwanted behaviors of smart contracts on the Ethereum blockchain platform. DefectChecker can detect contract defects from smart contracts' bytecode. We compare DefectChecker with key previous works, including Oyente, Mythril and Securify by using an open-source dataset. Our experimental results show that DefectChecker performs much better than these tools in terms of both speed and accuracy. We also applied DefectChecker to 165,621 distinct smart contracts on the Ethereum platform. We found that 25,815 of these smart contracts contain at least one of the contract defects that belongs to impact level 1-3, including some real-world attacks.","1939-3520","","10.1109/TSE.2021.3054928","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9337195","Smart Contracts;Ethereum;Contract Defects Detection;Bytecode Analyze;Symbolic Execution","Smart contracts;Blockchain;Tools;Computer bugs;Computer hacking;Virtual machining;Organizations","","","","","","","IEEE","27 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Scrutinizing Implementations of Smart Home Integrations","K. Mahadewa; K. Wang; G. Bai; L. Shi; Y. Liu; J. S. Dong; Z. Liang","Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: kulani41@comp.nus.edu.sg); Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: dcswaka@nus.edu.sg); School of Information Technology and Electrical Engineering, University of Queensland, 1974 Brisbane, Queensland Australia (e-mail: baiguangdong@gmail.com); Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: shiling@comp.nus.edu.sg); Blockchain Platform, Ant Financial, Hanzhou, Zhejiang China (e-mail: yan.emma.liu@gmail.com); Department of Computer Science, School of Computing, Singapore, Singapore Singapore (e-mail: dcsdjs@nus.edu.sg); Computer Science, National University of Singapore, Singapore, Singapore Singapore 117417 (e-mail: liangzk@comp.nus.edu.sg)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","A key feature of the booming smart home is the integration of a wide assortment of technologies, including various standards, proprietary communication protocols and heterogeneous platforms. Due to customization, unsatisfied assumptions and incompatibility in the integration, critical security vulnerabilities are likely to be introduced by the integration. Hence, this work addresses the security problems in smart home systems from an integration perspective, as a complement to numerous studies that focus on the analysis of individual technologies. We propose HOMESCAN, an approach that examines the security of the implementations of smart home systems. It extracts the abstract specification of application-layer protocols and internal behaviors of entities, so that it is able to conduct an end-to-end security analysis against various attack models. Applying HOMESCAN on three extensively-used smart home systems, we have found twelve non-trivial security vulnerabilities, which may lead to unauthorized remote control and credential leakage.","1939-3520","","10.1109/TSE.2019.2960690","National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8936860","","Security;Smart homes;Zigbee;Protocols;Authentication;Java;Wireless fidelity","","","","","","","","19 Dec 2019","","","IEEE","IEEE Early Access Articles"
"Automatic Generation of Acceptance Test Cases from Use Case Specifications: an NLP-based Approach","C. Wang; F. Pastore; A. Goknil; L. Briand","SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: wangchunhui@me.com); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: fabrizio.pastore@uni.lu); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg (e-mail: ardagoknil@gmail.com); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg Luxembourg 2721 (e-mail: lionel.briand@uni.lu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Acceptance testing is a validation activity performed to ensure the conformance of software systems with respect to their functional requirements. In safety critical systems, it plays a crucial role since it is enforced by software standards, which mandate that each requirement be validated by such testing in a clearly traceable manner. Test engineers need to identify all the representative test execution scenarios from requirements, determine the runtime conditions that trigger these scenarios, and finally provide the input data that satisfy these conditions. Given that requirements specifications are typically large and often provided in natural language (e.g., use case specifications), the generation of acceptance test cases tends to be expensive and error-prone. In this paper, we present Use Case Modeling for System-level, Acceptance Tests Generation (UMTG), an approach that supports the generation of executable, system-level, acceptance test cases from requirements specifications in natural language, with the goal of reducing the manual effort required to generate test cases and ensuring requirements coverage. More specifically, UMTG automates the generation of acceptance test cases based on use case specifications and a domain model for the system under test, which are commonly produced in many development environments. Unlike existing approaches, it does not impose strong restrictions on the expressiveness of use case specifications. We rely on recent advances in natural language processing to automatically identify test scenarios and to generate formal constraints that capture conditions triggering the execution of the scenarios, thus enabling the generation of test data. In two industrial case studies, UMTG automatically and correctly translated 95% of the use case specification steps into formal constraints required for test data generation; furthermore, it generated test cases that exercise not only all the test scenarios manually implemented by experts, but also some critical scenarios not previously considered.","1939-3520","","10.1109/TSE.2020.2998503","H2020 European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103626","System Test Case Generation;Use Case Specifications;Natural Language Processing;Semantic Role Labeling","Unified modeling language;Natural language processing;Embedded systems;Test pattern generators;Semantics","","","","","","","","29 May 2020","","","IEEE","IEEE Early Access Articles"
"TkT: Automatic Inference of Timed and Extended Pushdown Automata","F. Pastore; D. Micucci; M. Guzman; L. Mariani","SnT, University of Luxembourg, Luxembourg, LU Luxembourg (e-mail: fabrizio.pastore@uni.lu); Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Milano Italy 20126 (e-mail: daniela.micucci@unimib.it); Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Milano Italy (e-mail: michell.guzman@unimib.it); Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Milano Italy 20126 (e-mail: mariani@disco.unimib.it)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","To mitigate the cost of manually producing and maintaining models capturing software specifications, specification mining techniques can be exploited to automatically derive up-to-date models that faithfully represent the behavior of software systems. So far, specification mining solutions focused on extracting information about the functional behavior of the system, especially in the form of models that represent the ordering of the operations. Well-known examples are finite state models capturing the usage protocol of software interfaces and temporal rules specifying relations among system events. Although the functional behavior of a software system is a primary aspect of concern, there are several other non-functional characteristics that must be typically addressed jointly with the functional behavior of a software system. Efficiency is one of the most relevant characteristics. In fact, an application delivering the right functionalities inefficiently has a big chance to not satisfy the expectation of its users. Interestingly, the timing behavior is strongly dependent on the functional behavior of a software system. For instance, the timing of an operation depends on the functional complexity and size of the computation that is performed. Consequently, models that combine the functional and timing behaviors, as well as their dependencies, are extremely important to precisely reason on the behavior of software systems. In this paper, we address the challenge of generating models that capture both the functional and timing behavior of a software system from execution traces. The result is the Timed k-Tail (TkT) specification mining technique, which can mine finite state models that capture such an interplay: the functional behavior is represented by the possible order of the events accepted by the transitions, while the timing behavior is represented through clocks and clock constraints of different nature associated with transitions. Our empirical evaluation with several libraries and applications show that TkT can generate accurate models, capable of supporting the identification of timing anomalies due to overloaded environment and performance faults. Furthermore, our study shows that TkT outperforms state-of-the-art techniques in terms of scalability and accuracy of the mined models.","1939-3520","","10.1109/TSE.2020.2998527","H2020 European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9103630","Specification mining;dynamic analysis;trace analysis;model inference;timed automata;performance analysis","Automata;Clocks;Software systems;Timing;Data mining;Computational modeling","","","","","","","","29 May 2020","","","IEEE","IEEE Early Access Articles"
"An Empirical Study of Release Note Production and Usage in Practice","T. Bi; X. Xia; D. Lo; J. Grundy; T. Zimmermann","Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, (e-mail: tingting.bi@monash.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria, Australia, 3800 (e-mail: john.grundy@monash.edu); Research, Microsoft Corporation, Redmond, Washington, United States, 98052 (e-mail: tzimmer@microsoft.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The release note is one of the most important software artifacts that serves as a bridge for communication among stakeholders. Release notes contain a set of crucial information, such as descriptions of enhancements, improvements, potential issues, development, evolution, testing, and maintenance of projects throughout the whole development lifestyle. A comprehensive understanding of what makes a good release note and how to write one for different stakeholders would be highly beneficial. However, in practice, the release note is often neglected by stakeholders and has not to date been systematically investigated by researchers. In this paper, we conduct a mixed methods study to investigate the use of release notes in practice. We first conducted a large-scale empirical study of 32,425 release notes from 1,000 GitHub projects to understand current contents and information found in real-world release notes. We then performed interviews with 15 practitioners and an online survey with 314 respondents to investigate how key stakeholders perceive release notes. From the analysis of these data, we summarized eight categories of information that are normally documented in release notes in GitHub projects. We found that stakeholders consider that well-formed release notes have a positive impact on software development, such as software evolution. We concluded 28 statements grouped into eight topics based on stakeholders' opinions. There exist significant discrepancies between different stakeholders on how release notes should be written and used. Our study provides new insights on release notes and facilitates stakeholders to better take advantage of them during software development.","1939-3520","","10.1109/TSE.2020.3038881","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9263357","Release Note;Software Documentation;Empirical Study","Software;Production;Software development management;Stakeholders;Feature extraction;Testing;Task analysis","","","","","","","","18 Nov 2020","","","IEEE","IEEE Early Access Articles"
"Revisiting Supervised and Unsupervised Methods for Effort-Aware Cross-Project Defect Prediction","C. Ni; X. Xia; D. Lo; X. Chen; Q. Gu","School of Software Technology, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: jacknichao920209@gmail.com); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Information Science and Technology, Nantong University, 66479 Nantong, jiangsu China 226019 (e-mail: xchencs@ntu.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: quq@nju.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Cross-project defect prediction (CPDP), aiming to apply defect prediction models built on source projects to a target project, has been an active research topic. A variety of supervised CPDP methods and some simple unsupervised CPDP methods have been proposed. In a recent study, Zhou et al. found that simple unsupervised CPDP methods (i.e., ManualDown and ManualUp) have a prediction performance comparable or even superior to complex supervised CPDP methods. Therefore, they suggested that the ManualDown should be treated as the baseline when considering non-effort-aware performance measures (NPMs) and the ManualUp should be treated as the baseline when considering effort-aware performance measures (EPMs) in future CPDP studies. However, in that work, these unsupervised methods are only compared with existing supervised CPDP methods in terms of one or two NPMs and the prediction results of baselines are directly collected from the primary literature. Besides, the comparison has not considered other recently proposed EPMs, which consider context switches and developer fatigue due to initial false alarms. These limitations may not give a holistic comparison between the supervised methods and unsupervised methods. In this paper, we aim to revisit Zhou et al.'s study. To the best of our knowledge, we are the first to make a comparison between the existing supervised CPDP methods and the unsupervised methods proposed by Zhou et al. in the same experimental setting, considering both NPMs and EPMs. We also propose an improved supervised CPDP method EASC and make a further comparison between this method and the unsupervised methods. According to the results on 82 projects in terms of 12 performance measures, we find that when considering NPMs, EASC can achieve similar results with the unsupervised method ManualDown without statistically significant difference in most cases. However, when considering EPMs, our proposed supervised method EASC can statistically significantly outperform the unsupervised method ManualUp with a large improvement in terms of Cliff's delta in most cases. Therefore, the supervised CPDP methods are more promising than the unsupervised method in practical application scenarios, since the limitation of testing resource and the impact on developers cannot be ignored in these scenarios.","1939-3520","","10.1109/TSE.2020.3001739","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9115238","Defect prediction;cross-project;supervised model;unsupervised model","Manuals;Predictive models;Atmospheric measurements;Particle measurements;Data models;Software;Testing","","","","1","","","","11 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Data Quality Matters: A Case Study on Data Label Correctness for Security Bug Report Prediction","X. Wu; W. Zheng; X. Xia; D. Lo","School of Cyberspace Security, Northwestern Polytechnical University, 26487 Xi'an, Shaanxi, China, (e-mail: wuxiaoxue00@gmail.com); School of Software, Northwestern Polytechnical University, 26487 Xi'an, Shannxi, China, (e-mail: wzheng@nwpu.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria, Australia, 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","In the research of mining software repositories, we need to label a large amount of data to construct a predictive model. The correctness of the labels will affect the performance of a model substantially. However, limited studies have been performed to investigate the impact of mislabeled instances on a predictive model. To bridge the gap, in this work, we perform a case study on the security bug report (SBR) prediction. We found five publicly available datasets for SBR prediction contains many mislabeled instances, which lead to the poor performance of SBR prediction models of recent studies (e.g., the work of Peters et al. and Shu et al.). Furthermore, it might mislead the research direction of SBR prediction. In this paper, we first improve the label correctness of these five datasets by manually analyzing each bug report, and we find 749 SBRs, which are originally mislabeled as Non-SBRs (NSBRs). We then evaluate the impacts of datasets label correctness by comparing the performance of the classification models on both the noisy (i.e., before our correction) and the clean (i.e., after our correction) datasets. The results show that the cleaned datasets result in improvement in the performance of classification models. The performance of the approaches proposed by Peters et al. and Shu et al. on the clean datasets is much better than on the noisy datasets. Furthermore, with the clean datasets, the simple text classification models could significantly outperform the security keywords-matrix-based approaches applied by Peters et al. and Shu et al.","1939-3520","","10.1109/TSE.2021.3063727","Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University; Key Laboratory of Advanced Perception and Intelligent Control of High-end Equipment Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371393","Security bug report prediction;data quality;label correctness","Computer bugs;Noise measurement;Predictive models;Security;Chromium;Tuning;Data models","","","","","","","IEEE","5 Mar 2021","","","IEEE","IEEE Early Access Articles"
"The Impact of Data Merging on the Interpretation of Cross-Project Just-In-Time Defect Models","D. Lin; C. Tantithamthavorn; A. E. Hassan","Centre for Software Excellence, Huawei Technologies Co Ltd Canada, 538302 Kingston, Ontario, Canada, (e-mail: dayi.lin@huawei.com); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: chakkrit@monash.edu); School of Computing, Queen's University, Kingston, Ontario, Canada, (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Just-In-Time (JIT) defect models are classification models that identify the code commits that are likely to introduce defects. Cross-project JIT models have been introduced to address the suboptimal performance of JIT models when historical data is limited. However, many studies built cross-project JIT models using a pool of mixed data from multiple projects (i.e., data merging)---assuming that the properties of defect-introducing commits of a project are similar to that of the other projects, which is likely not true. In this paper, we set out to investigate the interpretation of JIT defect models that are built from individual project data and a pool of mixed project data with and without consideration of project-level variances. Through a case study of 20 datasets of open source projects, we found that (1) the interpretation of JIT models that are built from individual projects varies among projects; and (2) the project-level variances cannot be captured by a JIT model that is trained from a pool of mixed data from multiple projects without considering project-level variances (i.e., a global JIT model). On the other hand, a mixed-effect JIT model that considers project-level variances represents the different interpretations better, without sacrificing performance, especially when the contexts of projects are considered. The results hold for different mixed-effect learning algorithms. When the goal is to derive sound interpretation of cross-project JIT models, we suggest that practitioners and researchers should opt to use a mixed-effect modelling approach that considers individual projects and contexts.","1939-3520","","10.1109/TSE.2021.3073920","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9408228","Just-In-Time Defect Prediction;Data Merging;Mixed-Effect Model;Cross-Project Defect Prediction","Context modeling;Data models;Predictive models;Measurement;Training;Merging;Planning","","","","","","","IEEE","19 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Erratum to “Accurate and Scalable Cross-Architecture Cross-OS Binary Code Search With Emulation”","Y. Xue; Z. Xu; M. Chandramohan; Y. Liu","University of Science of Technology of China, Hefei, Anhui, China; Nanyang Technological University, Singapore, Singapore; Nanyang Technological University, Singapore, Singapore; Nanyang Technological University, Singapore, Singapore","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","1088","1088","Presents corrections to author information for the above named paper.","1939-3520","","10.1109/TSE.2021.3069529","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9430780","","Emulation;Binary codes","","","","","","1","IEEE","13 May 2021","","","IEEE","IEEE Journals"
"Execution of Partial State Machine Models","M. Bagherzadeh; N. Kahani; K. Jahed; J. Dingel","School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: mojtaba@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario Canada (e-mail: kahani@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario Canada (e-mail: jahed@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario Canada (e-mail: dingel@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The iterative and incremental nature of software development using models typically makes a model of a system incomplete (i.e., partial) until a more advanced and complete stage of development is reached. Existing model execution approaches (interpretation of models or code generation) do not support the execution of partial models. Supporting the execution of partial models at the early stages of software development allows early detection of defects, which can be fixed more easily and at a lower cost. This paper proposes a conceptual framework for the execution of partial models, which consists of three steps: static analysis, automatic refinement, and input-driven execution. First, a static analysis that respects the execution semantics of models is applied to detect problematic elements of models that cause problems for the execution. Second, using model transformation techniques, the models are refined automatically, mainly by adding decision points where missing information can be supplied. Third, refined models are executed, and when the execution reaches the decision points, it uses inputs obtained either interactively or by a script that captures how to deal with partial elements. We created an execution engine called PMExec for the execution of partial models of UML-RT (i.e., a modeling language for the development of soft real-time systems) that embodies our proposed framework. We evaluated PMExec based on several use-cases that show that the static analysis, refinement, and application of user input can be carried out with reasonable performance and that the overhead of approach, which is mostly due to the refinement and the increase in model complexity it causes, is manageable. We also discuss the properties of the refinement formally and show how the refinement preserves the original behaviors of the model.","1939-3520","","10.1109/TSE.2020.3008850","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139402","MDD;Model-level Debugging;Partial Models;Incomplete Models;Model Execution","Tools;Analytical models;Unified modeling language;Context modeling;Static analysis;Real-time systems;Debugging","","","","","","","","13 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Boosting API Recommendation with Implicit Feedback","Y. Zhou; X. Yang; T. Chen; Z. Huang; X. Ma; H. C. Gall","Dept. of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu, China, 211106 (e-mail: zhouyu@nuaa.edu.cn); College of Computer Science, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu, China, (e-mail: xy_yang@nuaa.edu.cn); Department of Computer Science and Information Systems, Birkbeck University of London, 4894 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: taolue.chen@surrey.ac.uk); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu, China, (e-mail: zqhuang@nuaa.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China, (e-mail: xxm@nju.edu.cn); Department of Informatics, University of Zurich, Zurich, Zurich, Switzerland, 8050 (e-mail: gall@ifi.uzh.ch)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Developers often need to use appropriate APIs to program efciently, but it is usually a difcult task to identify the exact one they need from a vast list of candidates. To ease the burden, a multitude of API recommendation approaches have been proposed. However, most of the currently available API recommenders do not support the effective integration of user feedback into the recommendation loop. In this paper, we propose a framework, BRAID (Boosting RecommendAtion with Implicit FeeDback), which leverages learning-to-rank and active learning techniques to boost recommendation performance. By exploiting user feedback information, we train a learning-to-rank model to re-rank the recommendation results. In addition, we speed up the feedback learning process with active learning. Existing query-based API recommendation approaches can be plugged into BRAID. We select three state-of-the-art API recommendation approaches as baselines to demonstrate the performance enhancement of BRAID measured by Hit@k (Top-k), MAP, and MRR. Empirical experiments show that, with acceptable overheads, the recommendation performance improves steadily and substantially with the increasing percentage of feedback data, comparing with the baselines.","1939-3520","","10.1109/TSE.2021.3053111","the Natural Science Foundation of Jiangsu Province; Birkbeck BEI School Project; National Key Research and Development Program of China; National Natural Science Foundation of China; Guangdong Science and Technology Department grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9329198","API recommendation;learning to rank;active learning;natural language processing","Task analysis;Software;Feature extraction;Training;Programming;History;Engines","","","","","","","IEEE","20 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Flexible Combinatorial Interaction Testing","H. Mercan; A. Javeed; C. Yilmaz","Computer sciences and engineering, Sabanci Universitesi, 52991 Istanbul, Istanbul Turkey 34956 (e-mail: hanefimercan@sabanciuniv.edu); Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Istanbul Turkey 34956 (e-mail: ajaveed@sabanciuniv.edu); Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Tuzla Turkey 34956 (e-mail: cyilmaz@sabanciuniv.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","We present Flexible Combinatorial Interaction Testing (F-CIT), which aims to improve the flexibility of combinatorial interaction testing (CIT) by eliminating the necessity of developing specialized constructors for CIT problems that cannot be efficiently and effectively addressed by the existing CIT constructors. F-CIT expresses the entities to be covered and the space of valid test cases, from which the samples are drawn to obtain full coverage, as constraints. Computing an F-CIT object (i.e., a set of test cases obtaining full coverage under a given coverage criterion) then turns into an interesting constraint solving problem, which we call cov-CSP. cov-CSP aims to divide the constraints, each representing an entity to be covered, into a minimum number of satisfiable clusters, such that a solution for a cluster represents a test case and the collection of all the test cases generated (one per cluster) constitutes an F-CIT object, covering each required entity at least once. To solve the cov-CSP problem, thus to compute F-CIT objects, we first present two constructors. One of these constructors attempts to cover as many entities as possible in a cluster before generating a test case, whereas the other constructor generates a test case first and then marks all the entities accommodated by this test case as covered. We then use these constructors to evaluate F-CIT in three studies, each of which addresses a different CIT problem. In the first study, we develop structure-based F-CIT objects to obtain decision coverage-adequate test suites. In the second study, we develop order-based F-CIT objects, which enhance a number of existing order-based coverage criteria by taking the reachability constraints imposed by graph-based models directly into account when computing interaction test suites. In the third study, we develop usage-based F-CIT objects to address the scenarios, in which standard covering arrays are not desirable due to their sizes, by choosing the entities to be covered based on their usage statistics collected from the field. We also carry out user studies to further evaluate F-CIT. The results of these studies suggest that F-CIT is more flexible than the existing CIT approaches.","1939-3520","","10.1109/TSE.2020.3010317","Türkiye Bilimsel ve Teknolojik Araştirma Kurumu; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9144457","Combinatorial interaction testing;covering arrays;sequence covering arrays;constraint solving;structural coverage;coverage criteria","Testing;Standards;Software;Computational modeling;Computers;Electronic mail;Tools","","","","1","","","","20 Jul 2020","","","IEEE","IEEE Early Access Articles"
"A Compositional Approach for Complex Event Pattern Modeling and Transformation to Colored Petri Nets with Black Sequencing Transitions","V. V. Valero; G. Diaz-Descalzo; J. Boubeta-Puig; H. Macia; E. Brazalez-Segovia","Computing Science, Universidad de Castilla-La Mancha, 16733 Albacete, Castilla-La Mancha, Spain, (e-mail: Valentin.valero@uclm.es); Computer Science, Universidad de Castilla-La Mancha - Campus de Albacete, 73073 Albacete, Albacete, Spain, 02071 (e-mail: gregorio.diaz@uclm.es); Computer Science and Engineering, Universidad de Cdiz, 16727 Cadiz, Andaluca, Spain, (e-mail: juan.boubeta@uca.es); Mathematics, Universidad de Castilla-La Mancha, 16733 Albacete, Castilla-La Mancha, Spain, (e-mail: hermenegilda.macia@uclm.es); Computer Science, University of Castilla-La Mancha, 16733 Albacete, Albacete, Spain, 02071 (e-mail: Enrique.Brazalez@uclm.es)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Prioritized Colored Petri Nets (PCPNs) are a well-known extension of plain Petri nets in which transitions can have priorities and the tokens on the places carry data information. In this paper, we propose an extension of the PCPN model with black sequencing transitions (BPCPN). This extension allows us to easily model the ordered firing of the same transition using an ordered set of tokens on one of its precondition places. Black sequencing transitions are then presented as a shorthand notation in order to model the processing of a flow of events, represented by one of their precondition places. We then show how black sequencing transitions can be encoded into PCPNs, and their application to model Complex Event Processing (CEP), defining a compositional approach to translate some of the most relevant event pattern operators. We have developed MEdit4CEP-BPCPN, an extension of the MEdit4CEP tool, to provide tool support for this novel technique, thus allowing end users to easily define event patterns and obtain an automatic translation into BPCPNs. This can, in turn, be transformed into a corresponding PCPN, and then be immediately used in CPN Tools. Finally, a health case study concerning the monitoring of pregnant women is considered to illustrate how the event patterns are created and how the BPCPN and PCPN models are obtained by using the MEdit4CEP-BPCPN tool.","1939-3520","","10.1109/TSE.2021.3065584","Universidad de Castilla-La Mancha; Junta de Comunidades de Castilla-La Mancha; Ministerio de Ciencia Innovacin y Universidades; European Regional Development Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9376633","Colored Petri Nets;CEP;EPL;Compositional Modeling;Model-Driven Development","Analytical models;Tools;Semantics;Petri nets;Sequential analysis;Syntactics;Image color analysis","","","","","","","CCBY","11 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Deep Learning Based Program Generation from Requirements Text: Are We There Yet?","H. Liu; M. Shen; J. Zhu; N. Niu; G. Li; L. Zhang","Computer Science and Technology, Software Lab, Beijing, Beijing China 100081 (e-mail: liuhui2005@gmail.com); Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 3120181025@bit.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: zhujiaqi@bit.edu.cn); EECS, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: nan.niu@uc.edu); Software Institute, Peking University, Beijing, Beijing China (e-mail: lige@pku.edu.cn); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","To release developers from time-consuming software development, many approaches have been proposed to generate source code automatically according to software requirements. With significant advances in deep learning and natural language processing, deep learning-based approaches are proposed to generate source code from natural language descriptions. The key insight is that given a large corpus of software requirements and their corresponding implementations, advanced deep learning techniques may learn how to translate software requirements into source code that fulfill such requirements. Although such approaches are reported to be highly accurate, they are evaluated on datasets that are rather small, lack of diversity, and significantly different from real-world software requirements. To this end, we build a large scale dataset that is composed of longer requirements as well as validated implementations. We evaluate the state-of-the-art approaches on this new dataset, and the results suggest that their performance on our dataset is significantly lower than that on existing datasets concerning the common metrics, i.e. BLEU. Evaluation results also suggest that the generated programs often contain syntactic and semantical errors, and none of them can pass even a single predefined test case. Further analysis reveals that the state-of-the-art approaches learn little from software requirements, and most of the successfully generated statements are popular statements in the training programs. Based on this finding, we propose a popularity-based approach that always generates the most popular statements in training programs regardless of the input (software requirements). Evaluation results suggest that none of the state-of-the-art approaches can outperform this simple statistics-based approach. As a conclusion, deep learning-based program generation requires significant improvement in the future, and our dataset may serve as a basis for future research in this direction.","1939-3520","","10.1109/TSE.2020.3018481","National Natural Science Foundation of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173704","Software Requirements;Code Generation;Deep Learning;Data Set","Software;Unified modeling language;Object oriented modeling;Syntactics;Tools;DSL;Deep learning","","","","","","","","21 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Algorithmic Profiling for Real-World Complexity Problems","B. Qin; T. Tu; Z. Liu; T. Yu; L. Song","School of Cyberspace Security, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China, (e-mail: bobbqqin@bupt.edu.cn); State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China, (e-mail: tutengfei.kevin@bupt.edu.cn); College of Information Sciences and Technology, The Pennsylvania State University, 8082 University Park, Pennsylvania, United States, (e-mail: zxl381@psu.edu); Computer Science, University of Kentucky, 4530 Lexington, Kentucky, United States, (e-mail: tyu@cs.uky.edu); College of Information Sciences and Technology, The Pennsylvania State University, 8082 University Park, Pennsylvania, United States, (e-mail: songlh@ist.psu.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Complexity problems are a common type of performance issues, caused by algorithmic inefficiency. Algorithmic profiling aims to automatically attribute execution complexity to an executed code construct. It can identify code constructs in superlinear complexity to facilitate performance optimizations and debugging. However, existing algorithmic profiling techniques suffer from several severe limitations, missing the opportunity to be deployed in production environment and failing to effectively pinpoint root causes for performance failures caused by complexity problems. In this paper, we design a tool, ComAir, which can effectively conduct algorithmic profiling in production environment. We propose several novel instrumentation methods to significantly lower runtime overhead and enable the production-run usage. We also design an effective ranking mechanism to help developers identify root causes of performance failures due to complexity problems. Our experimental results show that ComAir can effectively identify root causes and generate accurate profiling results in production environment, while incurring a negligible runtime overhead","1939-3520","","10.1109/TSE.2021.3067652","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9382886","Algorithmic complexity;program analysis","Complexity theory;Computer bugs;Production;Tools;Runtime;Software;Instruments","","","","","","","IEEE","22 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Quantifying, Characterizing, and Mitigating Flakily Covered Program Elements","S. V. Vaidhyam Subramanian; S. McIntosh; B. Adams","Electrical and Computer Engineering, McGill University, 5620 Montreal, Quebec Canada (e-mail: shivashree.vaidhyamsubramanian@mail.mcgill.ca); David R. Cheriton School of Computing, University of Waterloo, 8430 Waterloo, Ontario Canada (e-mail: shane.mcintosh@uwaterloo.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: bram.adams@polymtl.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Code coverage measures the degree to which source code elements (e.g., statements, branches) are invoked during testing. Despite growing evidence that coverage is a problematic measurement, it is often used to make decisions about where testing effort should be invested. For example, using coverage as a guide, tests should be written to invoke the non-covered program elements. At their core, coverage measurements assume that invocation of a program element during any test is equally valuable. Yet in reality, some tests are more robust than others. As a concrete instance of this, we posit in this paper that program elements that are only covered by flaky tests, i.e., tests with non-deterministic behaviour, are also worthy of investment of additional testing effort. In this paper, we set out to quantify, characterize, and mitigate ""flakily covered"" program elements (i.e., those elements that are only covered by flaky tests). To that end, we perform an empirical study of three large software systems from the OpenStack community. In terms of quantification, we find that systems are disproportionately impacted by flakily covered statements with 5% and 10% of the covered statements in Nova and Neutron being flakily covered, respectively, while < 1% of Cinder statements are flakily covered. In terms of characterization, we find that incidences of flakily covered statements could not be well explained by solely using code characteristics, such as dispersion, ownership, and development activity. In terms of mitigation, we propose GreedyFlake - a test effort prioritization algorithm to maximize return on investment when tackling the problem of flakily covered program elements. We find that GreedyFlake outperforms baseline approaches by at least eight percentage points of Area Under the Cost Effectiveness Curve.","1939-3520","","10.1109/TSE.2020.3010045","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9143477","Code coverage;Software testing;Flaky tests","Testing;Neutrons;Software;Logic gates;Data mining;Robustness","","","","","","","","17 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Automated Classification of Overfitting Patches with Statically Extracted Code Features","H. Ye; J. Gu; M. Martinez; T. Durieux; M. Monperrus","TCS, KTH Royal Institute of Technology School of Computer Science and Communication, 156318 Stockholm, Stockholm, Sweden, (e-mail: heye@kth.se); TCS, KTH Royal Institute of Technology School of Computer Science and Communication, 156318 Stockholm, Stockholm, Sweden, (e-mail: jiagu@kth.se); Informatique, Universite de Valenciennes et du Hainaut-Cambresis Antenne de Maubeuge, 244686 Maubeuge, Nord, France, (e-mail: matias.martinez@univ-valenciennes.fr); TCS, KTH, 7655 Stockholm, Stockholm, Sweden, 100 44 (e-mail: thomas@durieux.me); EECS - TCS, KTH Royal Institute of Technology, Stockholm, Stockholm, Sweden, 10044 (e-mail: martin.monperrus@csc.kth.se)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Automatic program repair (APR) aims to reduce the cost of manually fixing software defects. However, APR suffers from generating a multitude of overfitting patches, those patches that fail to correctly repair the defect beyond making the tests pass. This paper presents a novel overfitting patch detection system called ODS to assess the correctness of APR patches. ODS first statically compares a patched program and a buggy program in order to extract code features at the abstract syntax tree (AST) level. Then, ODS uses supervised learning with the captured code features and patch correctness labels to automatically learn a probabilistic model. The learned ODS model can then finally be applied to classify new and unseen program repair patches. We conduct a large-scale experiment to evaluate the effectiveness of ODS on patch correctness classification based on 10,302 patches from Defects4J, Bugs.jar and Bears benchmarks. The empirical evaluation shows that ODS is able to correctly classify 71.9% of program repair patches from 26 projects, which improves the state-of-the-art. ODS is applicable in practice and can be employed as a post-processing procedure to classify the patches generated by different APR systems.","1939-3520","","10.1109/TSE.2021.3071750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9399306","Automatic program repair;Patch assessment;Overfitting patch;Code features","Feature extraction;Maintenance engineering;Training;Tools;Syntactics;Software;Predictive models","","","","","","","IEEE","8 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Automatic Test Case and Test Oracle Generation based on Functional Scenarios in Formal Specifications for Conformance Testing","S. Liu; S. Nakajima","Computer Science, Hosei University, Koganei-shi, Tokyo Japan (e-mail: sliu@hiroshima-u.ac.jp); Information and Society Research, National Institute of Informatics, Japan, Tokyo, Tokyo Japan (e-mail: nkjm@nii.ac.jp)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Testing a program to confirm whether it consistently implements its requirements specification is a necessary but time-consuming activity in software development. Automatic testing based on specifications can significantly alleviate the workload and cost, but faces a challenge of how to ensure that both the user's concerns in the specification and possible execution paths in the program are all covered. In this paper, we describe a new method, called ""Vibration-Method"" or simply ""V-Method"", for automatic generation of test cases and test oracle from model-based formal specifications, aiming to address this challenge. The proposed method is suitable for testing information systems in which rich data types are used. Supporting the principle of ""divide and conquer"", the method provides a specific technique for generating test cases based on functional scenarios defined in the specification, test case generation criteria, automatic test case generation algorithms, and a well-defined mechanism for deriving test oracle. We elaborate on the method by discussing how initial test cases can be automatically generated, how additional necessary test cases are produced using the ""vibration"" technique, and how a test oracle can be automatically derived for a group of test cases. We also describe a controlled experiment to evaluate the effectiveness of the method and discuss the important issues in relation to the performance and applicability of the method.","1939-3520","","10.1109/TSE.2020.2999884","JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108630","Specification-based testing;Black-box testing;Functional testing;Model-based testing;Automatic testing","Software;Vibrations;Input variables;Conformance testing;Automatic testing;Information systems","","","","1","","","","4 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Mining Similar Methods for Test Adaptation","D. Sondhi; M. Jobanputra; D. Rani; S. Purandare; S. Sharma; R. Purandare","CSE, Indraprastha Institute of Information Technology Delhi, 243095 New Delhi, Delhi, India, (e-mail: devikas@iiitd.ac.in); Computer Science, IIITD, 243095 New Delhi, Delhi, India, 110020 (e-mail: mayankjobanputra@gmail.com); Computer Science and Engineering, Gandhi Institute For Technological Advancement, 209150 Bhubaneswar, Odisha, India, 752054 (e-mail: ranidivya063@gmail.com); Computer Science and Engineering, Indraprastha Institute of Information Technology Delhi, 243095 New Delhi, Delhi, India, 110020 (e-mail: salil.purandare@gmail.com); Computer Science Engineering, International Institute of Information Technology Bhubaneswar, 267396 Bhubaneswar, Odisha, India, 751003 (e-mail: phs.sakshi@gmail.com); Computer Science and Engineering, Indraprastha Institute of Information Technology, 243095 New Delhi, Delhi, India, (e-mail: purandare@iiitd.ac.in)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Developers may choose to implement a library despite the existence of similar libraries, considering factors such as computational performance, language or platform dependency, accuracy, convenience, and completeness of an API. As a result, GitHub hosts several library projects that have overlaps in their functionalities. These overlaps have been of interest to developers from the perspective of code reuse or the preference of one implementation over the other. Through an empirical study, we explore the extent and nature of existence of these similarities in the library functions. We have further studied whether the similarity of functions across different libraries and their associated test suites can be leveraged to reveal defects in one another. We see scope for effectively using the mining of test suites from the perspective of revealing defects in a program or its documentation. Another noteworthy observation made in the study is that similar functions may exist across libraries implemented in the same language as well as in different languages. Identifying the challenges that lie in building a testing tool, we automate the entire process in Metallicus, a test mining and recommendation tool. Metallicus returns a test suite for the given input of a query function and a template for its test suite. On a dataset of query functions taken from libraries implemented in Java or Python, Metallicus revealed 46 defects.","1939-3520","","10.1109/TSE.2021.3057163","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9347715","Test suites;mining;software testing;function similarity","Libraries;Testing;Tools;Software development management;Python;Documentation;Open source software","","","","","","","IEEE","4 Feb 2021","","","IEEE","IEEE Early Access Articles"
"On the Value of Oversampling for Deep Learning in Software Defect Prediction","R. Yedida; T. Menzies","Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: ryedida@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","One truism of deep learning is that the automatic feature engineering (seen in the first layers of those networks) excuses data scientists from performing tedious manual feature engineering prior to running DL. For the specific case of deep learning for defect prediction, we show that that truism is false. Specifically, when we pre-process data with a novel oversampling technique called fuzzy sampling, as part of a larger pipeline called GHOST (Goal-oriented Hyper-parameter Optimization for Scalable Training), then we can do significantly better than the prior DL state of the art in 14/20 defect data sets. Our approach yields state-of-the-art results significantly faster deep learners. These results present a cogent case for the use of oversampling prior to applying deep learning on software defect prediction datasets.","1939-3520","","10.1109/TSE.2021.3079841","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9429914","defect prediction;oversampling;class imbalance;neural networks","Deep learning;Tuning;Predictive models;Standards;Prediction algorithms;Training;Tools","","","","","","","IEEE","12 May 2021","","","IEEE","IEEE Early Access Articles"
"Automated Expansion of Abbreviations Based on Semantic Relation and Transfer Expansion","Y. Jiang; H. Liu; J. Jin; L. Zhang","Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, China China (e-mail: 2990094974@qq.com); School of Computer Science and Technology, Beijing Institute of Technology, Beijing, Beijing China 100081 (e-mail: liuhui08@bit.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: jinjiahao1993@gmail.com); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Although the negative impact of abbreviations in source code is well-recognized, abbreviations are common for various reasons. To this end, a number of approaches have been proposed to expand abbreviations in identifiers. However, such approaches are either inaccurate or confined to specific identifiers. To this end, in this paper, we propose a generic and accurate approach to expand identifier abbreviations by leveraging both semantic relation and transfer expansion. One of the key insight of the approach is that abbreviations in the name of software entity e have great chance to find their full terms in names of software entities that are semantically related to e. Consequently, the proposed approach builds a knowledge graph to represent such entities and their relationships with e, and searches the graph for full terms. Another key insight is that literally identical abbreviations within the same application are likely (but not necessary) to have identical expansions, and thus the semantics-based expansion in one place may be transferred to other places. To investigate when abbreviation expansion could be transferred safely, we conduct a case study on three open-source applications. The results suggest that a significant part (75%) of expansions could be transferred among lexically identical abbreviations within the same application. However, the risk of transfer varies according to various factors, e.g., length of abbreviations, physical distance between abbreviations, and semantic relations between abbreviations. Based on these findings, we design nine heuristics for transfer expansion, and propose a learning based approach to prioritize both transfer heuristics and semantic-based expansion heuristics. Evaluation results on nine open-source applications suggest that the proposed approach significantly improves the state of the art, improving recall from 29% to 89% and precision from 39% to 92%.","1939-3520","","10.1109/TSE.2020.2995736","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9096573","Abbreviation;Expansion;Transfer;Context;Quality","Semantics;Dictionaries;Manuals;Internet;Open source software;Encyclopedias","","","","","","","","19 May 2020","","","IEEE","IEEE Early Access Articles"
"Corrections to “Automatic and Accurate Expansion of Abbreviations in Parameters”","Y. Jiang; H. Liu; J. Zhu; L. Zhang","School of Computer Science and Technology, Beijing Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijing Institute of Technology, Beijing, P.R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, P.R. China","IEEE Transactions on Software Engineering","17 Sep 2020","2020","46","9","1039","1039","Presents corrections to author information in the above named paper.","1939-3520","","10.1109/TSE.2020.3015699","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9199188","","Computer science;Software","","","","","","1","IEEE","17 Sep 2020","","","IEEE","IEEE Journals"
"SigRec: Automatic Recovery of Function Signatures in Smart Contracts","T. Chen; Z. Li; X. Luo; X. Wang; T. Wang; Z. He; K. Fang; Y. Zhang; H. Zhu; H. Li; Y. Cheng; X. -s. Zhang","Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: brokendragon@uestc.edu.cn); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: gforiq@qq.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); School of Informatics and Computer Science Department, Indiana University at Bloomington, Bloomington, Indiana, United States, 47406 (e-mail: xw7@indiana.edu); College of Information Sciences and Technology, Pennsylvania State University, 8082 University Park, Pennsylvania, United States, (e-mail: inbox.ting@gmail.com); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: ecjgvmhc@gmail.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: fangkezhao@126.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: 2235285714@qq.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: 568991738@qq.com); computer science, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: hongweili@uestc.edu.cn); Blockchain, Ant Group, China., Jiangshu, Zhejiang, China, (e-mail: xiaoge.cy@antgroup.com); School of Computer Science & Engineering, University of Electronic Science and Technology of China, Chengdu, Sichuan, China, (e-mail: johnsonzxs@uestc.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Millions of smart contracts have been deployed onto Ethereum for providing various services, which can be invoked through their functions. For this purpose, the caller needs to know the function signature of a callee, which includes its function id and parameter types. Such signatures are critical to many applications focusing on smart contracts, e.g., reverse engineering, fuzzing, attack detection, and profiling. Unfortunately, it is challenging to recover the function signatures from contract bytecode, since neither debug information nor type information is present in the bytecode. To address this issue, prior approaches rely on source code, or a collection of known signatures from incomplete databases or incomplete heuristic rules, which, however, are far from adequate and cannot cope with the rapid growth of new contracts. In this paper, we propose a novel solution that leverages how functions are handled by Ethereum virtual machine (EVM) to automatically recover function signatures. In particular, we exploit how smart contracts determine the functions to be invoked to locate and extract function ids, and propose a new approach named type-aware symbolic execution (TASE) that utilizes the semantics of EVM operations on parameters to identify the number and the types of parameters.Moreover, we develop SigRec, a new tool for recovering function signatures from contract bytecode without the need of source code and function signature databases. The extensive experimental results show that SigRec outperforms all existing tools, achieving an unprecedented 98.9% accuracy within 0.07 seconds. We further demonstrate that the recovered function signatures are useful in attack detection, fuzzing and reverse engineering of EVM bytecode.","1939-3520","","10.1109/TSE.2021.3078342","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9426396","smart contract;function signature;Ethereum;automatic recovery;type-aware symbolic execution","Smart contracts;Databases;Reverse engineering;Semantics;Lenses;Layout;Tools","","","","","","","IEEE","7 May 2021","","","IEEE","IEEE Early Access Articles"
"A Methodology for Analyzing Uptake of SoftwareTechnologies Among Developers","Y. Ma; A. Mockus; R. Zaretzki; B. Bichescu; R. Bradley","EECS, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: yma28@vols.utk.edu); Avaya Labs Research, Avaya Labs, Basking Ridge, New Jersey United States 07920 (e-mail: audris@utk.edu); Business Analytics and Statistics, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: russell.zaretzki@gmail.com); Business Analytics and Statistics, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: bbichescu@utk.edu); Supply Chain Management, University of Tennessee Knoxville, 4292 Knoxville, Tennessee United States (e-mail: rbradley@utk.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Motivation: The question of what combination of attributes drives the adoption of a particular software technology is critical to developers. It determines both those technologies that receive wide support from the community and those which may be abandoned, thus rendering developers' investments worthless. Aim and Context: We model software technology adoption by developers and provide insights on specific technology attributes that are associated with better visibility among alternative technologies. Thus, our findings have practical value for developers seeking to increase the adoption rate of their products. Approach: We leverage social contagion theory and statistical modeling to identify, define, and test empirically measures that are likely to affect software adoption. More specifically, we leverage a large collection of open source repositories to construct a software dependency chain for a specific set of R language source-code files. We formulate logistic regression models, where developers' software library choices are modeled, to investigate the combination of technological attributes that drive adoption among competing data frame (a core concept for a data science languages) implementations in the R language: tidy and data.table. To describe each technology, we quantify key project attributes that might affect adoption (e.g., response times to raised issues, overall deployments, number of open defects, knowledge base) and also characteristics of developers making the selection (performance needs, scale, and their social network). Results: We find that a quick response to raised issues, a larger number of overall deployments, and a larger number of high-score StackExchange questions are associated with higher adoption. Decision makers tend to adopt the technology that is closer to them in the technical dependency network and in author collaborations networks while meeting their performance needs. To gauge the generalizability of the proposed methodology, we investigate the spread of two popular web JavaScript frameworks Angular and React, and discuss the results. Future work: We hope that our methodology encompassing social contagion that captures both rational and irrational preferences and the elucidation of key measures from large collections of version control data provides a general path toward increasing visibility, driving better informed decisions, and producing more sustainable and widely adopted software.","1939-3520","","10.1109/TSE.2020.2993758","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091014","choice models;social contagion;technology adoption;library migration;software supply chain","Software;Supply chains;Technological innovation;Software measurement;Data models;Time factors;Libraries","","","","","","","","11 May 2020","","","IEEE","IEEE Early Access Articles"
"Studying the Association between Bountysource Bounties and the Issue-addressing Likelihood of GitHub Issue Reports","J. Zhou; S. Wang; C. Bezemer; Y. Zou; A. E. Hassan","School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: jzhou@cs.queensu.ca); Department of Computer Science and Engineering, Mississippi State University, 5547 Mississippi State, Mississippi United States (e-mail: wang@cse.msstate.edu); Department of Electrical and Computer Engineering, University of Alberta, Edmonton, Alberta Canada (e-mail: bezemer@ualberta.ca); Electrical and Computer Enginereing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ying.zou@queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Due to the voluntary nature of open source software, it can be hard to find a developer to work on a particular task. For example, some issue reports may be too cumbersome and unexciting for someone to volunteer to do them, yet these issue reports may be of high priority to the success of a project. To provide an incentive for implementing such issue reports, one can propose a monetary reward, i.e., a bounty, to the developer who completes that particular task. In this paper, we study bounties in open source projects on GitHub to better understand how bounties can be leveraged to evolve such projects in terms of addressing issue reports. We investigated 5,445 bounties for GitHub projects. These bounties were proposed through the Bountysource platform with a total bounty value of 406,425. We find that 1) in general, the timing of proposing bounties is the most important factor that is associated with the likelihood of an issue being addressed. More specifically, issue reports are more likely to be addressed if they are for projects in which bounties are used more frequently and if they are proposed earlier. 2) The bounty value of an issue report is the most important factor that is associated with the issue-addressing likelihood in the projects in which no bounties were used before. 3) There is a risk of wasting money for backers who invest money on long-standing issue reports.","1939-3520","","10.1109/TSE.2020.2974469","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9000923","Software evolution;open source software;Bountysource;bounties;GitHub","Security;Open source software;Task analysis;Timing;Computer bugs;Indexes","","","","","","","","17 Feb 2020","","","IEEE","IEEE Early Access Articles"
"CTOS: Compiler Testing for Optimization Sequences of LLVM","H. Jiang; Z. Zhou; Z. Ren; J. Zhang; X. Li","School of Software, Dalian University of Technology, Dalian, Liaoning, China, 116621 (e-mail: jianghe@dlut.edu.cn); School of Software, Dalian University of Technology, 12399 Dalian, Liaoning, China, (e-mail: cszide@gmail.com); School of Software, Dalian University of Technology, 12399 Dalian, Liaoning, China, (e-mail: zren@dlut.edu.cn); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu, China, (e-mail: jxzhang@nuaa.edu.cn); the SnT Centre for Security, Reliability and Trust, University of Luxembourg, 81872 Luxembourg, Luxembourg, Luxembourg, (e-mail: xiaochen.li@uni.lu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Optimization sequences are often employed in compilers to improve the performance of programs, but may trigger critical compiler bugs, e.g., compiler crashes. Although many methods have been developed to automatically test compilers, no systematic work has been conducted to detect compiler bugs when applying arbitrary optimization sequences. To resolve this problem, two main challenges need to be addressed, namely the acquisition of representative optimization sequences and the selection of representative testing programs, due to the enormous number of optimization sequences and testing programs. In this study, we propose CTOS, a novel compiler testing method based on differential testing, for detecting compiler bugs caused by optimization sequences of LLVM. CTOS firstly leverages the technique Doc2Vec to transform optimization sequences into vectors to capture the information of optimizations and their orders simultaneously. Secondly, a method based on the region graph and call relationships is developed in CTOS to construct the vector representations of testing programssuch that the semantics and the structure information of programs can be captured simultaneously. Then, with the vector representations of optimization sequences and testing programs, a centroid based selection scheme is proposed to address the above two challenges. Finally, CTOS takes in the representative optimization sequences and testing programs as inputs, and tests each testing program with all the representative optimization sequences. If there is an output that is different from the majority of others of a given testing program, then the corresponding optimization sequence is deemed to trigger a compiler bug. Our evaluation demonstrates that CTOS significantly outperforms the baselines by up to 24.76% 45.56% in terms of the bug-finding capability on average. Within seven month evaluations on LLVM, we have reported 104 valid bugs within 5 types, of which 21 have been confirmed or fixed. Most of those bugs are crash bugs (57) and wrong code bugs (24). 47 unique optimizations are identified to be faulty and 15 of them are loop related optimizations.","1939-3520","","10.1109/TSE.2021.3058671","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9353261","Compiler testing;Optimization sequences;LLVM;Program representation;Software testing","Optimization;Computer bugs;Testing;Program processors;Systematics;Electromagnetic interference;Software","","","","","","","IEEE","11 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Will Dependency Conflicts Affect My Program's Semantics","Y. Wang; R. Wu; C. Wang; M. Wen; Y. Liu; S. C. Cheung; H. Yu; C. Xu; Z. -l. Zhu","Software college, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: wangying@swc.neu.edu.cn); Department of Cyber Space Security, Xiamen University, 12466 Xiamen, Fujian, China, (e-mail: wurongxin@xmu.edu.cn); Software College, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: wangc_neu@163.com); Cyber Science and Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei, China, 430074 (e-mail: mwenaa@hust.edu.cn); Computer Science and Engineering, Southern University of Science and Technology, 255310 Shenzhen, Guangdong, China, (e-mail: liuyp1@sustech.edu.cn); Department of Computer Science and Engineering, Hong Kong University of Science and Technology, 58207 Kowloon, Hong Kong, China, (e-mail: scc@cse.ust.hk); Software College, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: yuhai@mail.neu.edu.cn); Department of Computer Science and Engineering, Nanjing University, 12581 Nanjing, Jiangsu, China, (e-mail: changxu@nju.edu.cn); Software College, Northeastern University, 1848 Shenyang, Liaoning, China, (e-mail: ZHUZhiLiang_NEU@163.com)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Java projects are often built on top of various third-party libraries. If multiple versions of a library exist on the classpath, JVM will only load one version and shadow the others, which we refer to as dependency conflicts. This would give rise to semantic conflict (SC) issues, if the library APIs referenced by a project have identical method signatures but inconsistent semantics across the loaded and shadowed versions of libraries. SC issues are difficult for developers to diagnose in practice, since understanding them typically requires domain knowledge. Although adapting the existing test generation technique for dependency conflict issues, Riddle, to detect SC issues is feasible, its effectiveness is greatly compromised. This is mainly because Riddle randomly generates test inputs, while the SC issues typically require specific arguments in the tests to be exposed. To address that, we conducted an empirical study of 316 real SC issues to understand the characteristics of such specific arguments in the test cases that can capture the SC issues. Inspired by our empirical findings, we propose an automated testing technique Sensor, which synthesizes test cases using ingredients from the project under test to trigger inconsistent behaviors of the APIs with the same signatures in conflicting library versions. Our evaluation results show that Sensor is effective and useful: it achieved a Precision of 0.898 and a Recall of 0.725 on open-source projects and a Precision of 0.821 on industrial projects; it detected 306 semantic conflict issues in 50 projects, 70.4% of which had been confirmed as real bugs, and 84.2% of the confirmed issues have been fixed quickly.","1939-3520","","10.1109/TSE.2021.3057767","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9350237","Third-party Libraries;Test Generation;Empirical Study","Libraries;Semantics;Testing;Open source software;Runtime;Java;Computer science","","","","","","","IEEE","8 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Chatbot4QR: Interactive Query Refinement for Technical Question Retrieval","N. Zhang; Q. Huang; X. Xia; Y. Zou; D. Lo; Z. Xing","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: nengzhang@zju.edu.cn); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: tkdsheep@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); Electrical and Computer Enginereing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ying.zou@queensu.ca); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: zhenchang.xing@anu.edu.au)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Technical Q&A sites (e.g., Stack Overflow(SO)) are important resources for developers to search for knowledge about technical problems. Search engines provided in Q&A sites and information retrieval approaches have limited capabilities to retrieve relevant questions when queries are imprecisely specified, such as missing important technical details (e.g., the user's preferred programming languages). Although many automatic query expansion approaches have been proposed to improve the quality of queries by expanding queries with relevant terms, the information missed is not identified. Moreover, without user involvement, the existing query expansion approaches may introduce unexpected terms and lead to undesired results. In this paper, we propose an interactive query refinement approach for question retrieval, named Chatbot4QR, which assists users in recognizing and clarifying technical details missed in queries and thus retrieve more relevant questions for users. Chatbot4QR automatically detects missing technical details in a query and generates several clarification questions (CQs) to interact with the user to capture their overlooked technical details. To ensure the accuracy of CQs, we design a heuristic-based approach for CQ generation after building two kinds of technical knowledge bases: a manually categorized result of 1,841 technical tags in SO and the multiple version-frequency information of the tags. We collect 1.88 million SO questions as the repository for question retrieval. To evaluate Chatbot4QR, we conduct six user studies with 25 participants on 50 experimental queries. The results show that: (1)On average 60.8% of the CQs generated for a query are useful for helping the participants recognize missing technical details; (2)Chatbot4QR can rapidly respond to the participants after receiving a query within ~1.3 seconds; (3)The refined queries contribute to retrieving more relevant SO questions than nine baseline approaches. For more than 70% of the participants who have preferred techniques on the query tasks, Chatbot4QR significantly outperforms the state-of-the-art word embedding-based retrieval approach with an improvement of at least 54.6% in terms of Pre@k and NDCG@k; and (4)For 48%-88% of the assigned query tasks, the participants obtain more desired results after interacting with Chatbot4QR than directly searching from Web search engines (e.g., the SO search engine and Google) using the original queries.","1939-3520","","10.1109/TSE.2020.3016006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9165927","Interactive Query Refinement;Chatbot;Question Retrieval;Stack Overflow","Search engines;Web search;Java;Task analysis;Engines;Databases","","","","1","","","","12 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Are You Still Working on This An Empirical Study on Pull Request Abandonment","Z. Li; Y. Yu; T. Wang; G. Yin; S. Li; H. Wang","Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: lizhixing15@nudt.edu.cn); computer science, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: yuyue@nudt.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: taowang2005@nudt.edu.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: yingang@nudt.edu.cn); computer science, National University of Defense Technology, Changsha, Hunan, China, (e-mail: shanshanli@nudt.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan, China, (e-mail: hmwang@nudt.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","The great success of numerous community-based open source software (OSS) is based on volunteers continuously submitting contributions, but ensuring sustainability is a persistent challenge in OSS communities. Although the motivations behind and barriers to OSS contributors' joining and retention have been extensively studied, the impacts of, reasons for and solutions to contribution abandonment at the individual level have not been well studied, especially for pull-based development. To bridge this gap, we present an empirical study on pull request abandonment based on a sizable dataset. We manually examine 321 abandoned pull requests on GitHub and then quantify the manual observations by surveying 710 OSS developers. We find that while the lack of integrators' responsiveness, the lack of contributors' time and interest remain the main reasons that deter contributors from participation, limitations during the processes of patch updating and consensus reaching can also cause abandonment. We also show the significant impacts of pull request abandonment on project management and maintenance. Moreover, we elucidate the strategies used by project integrators to cope with abandoned pull requests and highlight the need for a practical handover mechanism. We discuss the actionable suggestions and implications for OSS practitioners and tool builders, which can help to upgrade the infrastructure and optimize the mechanisms of OSS communities.","1939-3520","","10.1109/TSE.2021.3053403","National Grand RD Plan; National Natural ScienceFoundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9332267","Pull Request Abandonment;Pull-based Development;Open Source Software","Tools;Collaboration;Sustainable development;Open source software;Manuals;Maintenance engineering;Computer bugs","","","","","","","IEEE","21 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Reuse of Similarly Behaving Software through Polymorphism-Inspired Variability Mechanisms","I. Reinhartz-Berger; A. Zamansky","Information Systems, University of Haifa, Haifa, Israel Israel 31905 (e-mail: iris@is.haifa.ac.il); Department of Information Systems, University of Haifa, Haifa, Haefa Israel (e-mail: annazam@is.haifa.ac.il)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","In many cases, software artifacts share similarity across projects and development teams. However, often this similarity is only partially reflected on the level of design and implementation, and therefore the possibilities for its detection are limited in current variability analysis, clone detection, and application search approaches. In this paper, we propose a method for identification and comparison of similarly behaving software. The method, supported by a prototype tool, analyzes the behavioral similarity of object-oriented code artifacts based on shallow (behavior interface) and deep (behavior transformation) descriptions of the exhibited operations. It further recommends on suitable mechanisms inspired by the notion of polymorphism in order to guide and support current and future reuse. The approach was evaluated on two data-sets, obtained following two different scenarios: clone-and-own and independent development by different teams.","1939-3520","","10.1109/TSE.2020.3001512","ISRAEL SCIENCE FOUNDATION; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113764","Variability;Reuse;Code Clones;Polymorphism;Software Product Line Engineering","Cloning;Software;Measurement;Software product lines;Java;Object oriented modeling;Tools","","","","","","","","10 Jun 2020","","","IEEE","IEEE Early Access Articles"
"ConEx: Efficient Exploration of Big-Data System Configurations for Better Performance","R. Krishna; C. Tang; K. Sullivan; B. Ray","Computer Science, Columbia University, 5798 New York, New York, United States, (e-mail: i.m.ralk@gmail.com); Research and Development, Microsoft Corp, 6834 Redmond, Washington, United States, (e-mail: ct4ew@virginia.edu); Computer Science, University of Virginia, Charlottesville, Virginia, United States, (e-mail: sullivan@virginia.edu); Computer Science, Columbia University, New York, New York, United States, (e-mail: rayb@cs.columbia.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Configuration space complexity makes the big-data software systems hard to configure well. Consider Hadoop, with over nine hundred parameters, developers often just use the default configurations provided with Hadoop distributions. The opportunity costs in lost performance are significant. Popular learning-based approaches to auto-tune software does not scale well for big-data systems because of the high cost of collecting training data. We present a new method based on a combination of Evolutionary Markov Chain Monte Carlo (EMCMC)} sampling and cost reduction techniques tofind better-performing configurations for big data systems. For cost reduction, we developed and experimentally tested and validated two approaches: using scaled-up big data jobs as proxies for the objective function for larger jobs and using a dynamic job similarity measure to infer that results obtained for one kind of big data problem will work well for similar problems. Our experimental results suggest that our approach promises to improve the performance of big data systems significantly and that it outperforms competing approaches based on random sampling, basic genetic algorithms (GA), and predictive model learning. Our experimental results support the conclusion that our approach strongly demonstrates the potential toimprove the performance of big data systems significantly and frugally.","1939-3520","","10.1109/TSE.2020.3007560","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9134972","Performance Optimization;MCMC;SBSE;Machine Learning","Big Data;Software systems;Machine learning;Markov processes;Monte Carlo methods;Predictive models","","","","","","","","7 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Efficient Parametric Model Checking Using Domain Knowledge","R. Calinescu; C. A. Paterson; K. Johnson","Computer Science, University of York, York, North Yorkshire United Kingdom of Great Britain and Northern Ireland (e-mail: radu.calinescu@york.ac.uk); Computer Science, University of York, York, North Yorkshire United Kingdom of Great Britain and Northern Ireland YO10 5GH (e-mail: colin.paterson@york.ac.uk); School of Computer and Mathematical Sciences, Auckland University of Technology, 1410 Auckland, Auckland New Zealand (e-mail: kenneth.johnson@aut.ac.nz)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","We introduce an efficient parametric model checking (ePMC) method for the analysis of reliability, performance and other quality-of-service (QoS) properties of software systems. ePMC speeds up the analysis of parametric Markov chains modelling the behaviour of software by exploiting domain-specific modelling patterns for the software components (e.g., patterns modelling the invocation of functionally-equivalent services used to jointly implement the same operation within service-based systems, or the deployment of the components of multi-tier software systems across multiple servers). To this end, ePMC precomputes closed-form expressions for key QoS properties of such patterns, and uses these expressions in the analysis of whole-system models. To evaluate ePMC, we show that its application to service-based systems and multi-tier software architectures reduces the analysis time by several orders of magnitude compared to current parametric model checking methods.","1939-3520","","10.1109/TSE.2019.2912958","Assuring Autonomy International Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8698796","Parametric model checking;Markov models;model abstraction;probabilistic model checking;quality of service","Markov processes;Quality of service;Analytical models;Unified modeling language;Software;Probabilistic logic;Parametric statistics","","","","1","","","","25 Apr 2019","","","IEEE","IEEE Early Access Articles"
"Legion: Massively Composing Rankers for Improved Bug Localization at Adobe","D. Jarman; J. Berry; R. Smith; F. Thung; D. Lo","Analytics, Adobe, Lehi, Utah, United States, (e-mail: djarman@adobe.com); Analytics, Adobe, Lehi, Utah, United States, (e-mail: berry@adobe.com); Analytics, Adobe, Lehi, Utah, United States, (e-mail: rilsmith@adobe.com); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, (e-mail: ferdiant.2013@smu.edu.sg); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Studies have estimated that, in industrial settings, developers spend between 30% and 90% of their time fixing bugs. As such, tools that assist in identifying the location of bugs provide value by reducing debugging costs. One such tool is BugLocator. This study initially aimed to determine if developers working on the Adobe Analytics product could use BugLocator. The initial results show that BugLocator achieves a similar accuracy on 5 of 7 Adobe Analytics repositories and on open-source projects. However, these results do not meet the minimum applicability requirement deemed necessary by Adobe Analytics developers prior to possible adoption. Thus, we consequently examine how BugLocator can achieve the targeted accuracy with two extensions: (1) adding more data corpora, and (2) massively composing individual rankers consisting of augmented BugLocator instances trained on various combinations of corpora and parameter configurations with a Random Forest model. We refer to our final extension as Legion. On average, applying Legion to Adobe Analytics repositories results in at least one buggy file ranked in the top-10 recommendations 76.8% of the time for customer-reported bugs across all 7 repositories. This represents a substantial improvement over BugLocator of 36.4%, and satisfies the minimum applicability requirement. Additionally, our extensions boost Mean Average Precision by 107.7%, Mean Reciprocal Rank by 86.1%, Top 1 by 143.4% and Top 5 by 58.1%.","1939-3520","","10.1109/TSE.2021.3075215","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9415126","bug localization;information retrieval;bug reports;data augmentation;ranker composition;industrial study F","Computer bugs;Location awareness;Tools;Debugging;Random forests;Programming;Information retrieval","","","","","","","IEEE","23 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Defect Reduction Planning (using TimeLIME)","K. Peng; T. Menzies","Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: kpeng@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Software comes in releases. An implausible change to software is something that has never been changed in prior releases. When planning how to reduce defects, it is better to use plausible changes, i.e., changes with some precedence in the prior releases. To demonstrate these points, this paper compares several defect reduction planning tools. LIME is a local sensitivity analysis tool that can report the fewest changes needed to alter the classification of some code module (e.g., from ""defective"" to ""non-defective""). TimeLIME is a new tool, introduced in this paper, that improves LIME by restricting its plans to just those attributes which change the most within a project. In this study, we compared the performance of LIME and TimeLIME and several other defect reduction planning algorithms. The generated plans were assessed via (a) the similarity scores between the proposed code changes and the real code changes made by developers; and (b) the improvement scores seen within projects that followed the plans. For nine project trails, we found that TimeLIME outperformed all other algorithms (in 8 out of 9 trials). Hence, we strongly recommend using past releases as a source of knowledge for computing fixes for new releases (using TimeLIME). Apart from these specific results about planning defect reductions and TimeLIME, the more general point of this paper is that our community should be more careful about using off-the-shelf AI tools, without first applying SE knowledge. In this case study, it was not difficult to augment a standard AI algorithm with SE knowledge (that past releases are a good source of knowledge for planning defect reductions). As shown here, once that SE knowledge is applied, this can result in dramatically better systems.","1939-3520","","10.1109/TSE.2021.3062968","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9371412","Software analytics;Defect Prediction;Defect Reduction;Plausibility Analysis;Interpretable AI","Software;Planning;Measurement;Tools;Software quality;Software algorithms;Couplings","","","","","","","IEEE","5 Mar 2021","","","IEEE","IEEE Early Access Articles"
"How Different is Test Case Prioritization for Open and Closed Source Projects","X. Ling; R. Agrawal; T. Menzies","Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: xling4@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: ragrawa3@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Improved test case prioritization means that software developers can detect and fix more software faults sooner than usual. But is there one ""best"" prioritization algorithm Or do different kinds of projects deserve special kinds of prioritization To answer these questions, this paper applies nine prioritization schemes to 31 projects that range from (a) highly rated open-source Github projects to (b) computational science software to (c) a closed-source project. We find that prioritization approaches that work best for open-source projects are can work worst for the closed-source project (and vice versa). From these experiments, we conclude that (a) it is ill-advised to always apply one prioritization scheme to all projects since (b) prioritization requires tuning to different project types.","1939-3520","","10.1109/TSE.2021.3063220","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9367020","software testing;regression testing;test case prioritization;open-source software","Testing;Software;Open source software;Software development management;Measurement;Software algorithms;History","","","","","","","IEEE","2 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Evaluating Automatic Program Repair Capabilities to Repair API Misuses","M. Kechagia; S. Mechtaev; F. Sarro; M. Harman","Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: m.kechagia@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mechtaev@live.com); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); CS, Facebook London, 507852 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","API misuses are well-known causes of software crashes and security vulnerabilities. However, their detection and repair is challenging given that the correct usages of (third-party) APIs might be obscure to the developers of client programs. This paper presents the first empirical study to assess the ability of existing automated bug repair tools to repair API misuses, which is a class of bugs previously unexplored. Our study examines and compares 14 Java test-suite-based repair tools (11 proposed before 2018, and three afterwards) on a manually curated benchmark (APIREPBENCH) consisting of 101 API misuses. We develop an extensible execution framework (APIARTY) to automatically execute multiple repair tools. Our results show that the repair tools are able to generate patches for 28% of the API misuses considered. While the 11 less recent tools are generally fast (the median execution time of the repair attempts is 3.87 minutes and the mean execution time is 30.79 minutes), the three most recent are less efficient (i.e., 98% slower) than their predecessors. The tools generate patches for API misuses that mostly belong to the categories of missing null check, missing value, missing exception, and missing call. Most of the patches generated by all tools are plausible (65%), but only few of these patches are semantically correct to human patches (25%). Our findings suggest that the design of future repair tools should support the localisation of complex bugs, including different categories of API misuses, handling of timeout issues, and ability to configure large software projects. Both APIREPBENCH and APIARTY have been made publicly available for other researchers to evaluate the capabilities of repair tools on detecting and fixing API misuses.","1939-3520","","10.1109/TSE.2021.3067156","European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381596","Automatic Program Repair;Application Programming Interfaces;API Misuses;Bug Benchmarks","Tools;Maintenance engineering;Computer bugs;Benchmark testing;Software;Java;Security","","","","","","","IEEE","18 Mar 2021","","","IEEE","IEEE Early Access Articles"
"ATOM: Commit Message Generation Based on Abstract Syntax Tree and Hybrid Ranking","S. Liu; C. Gao; S. Chen; N. Lun Yiu; Y. Liu","SCSE, Nanyang Technological University, 54761 Singapore, Singapore Singapore (e-mail: shangqingliu666@gmail.com); Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong Hong Kong (e-mail: gcyydxf@gmail.com); School of Computer Science and Engineering, Nanyang Technological University, 54761 Singapore, Singapore Singapore 639798 (e-mail: ecnuchensen@gmail.com); Computer Science and Engineering, The Chinese University of Hong Kong, Hong Kong, Hong Kong Hong Kong (e-mail: lynie8@cse.cuhk.edu); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: yangliu@ntu.edu.sg)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Commit messages record code changes (e.g., feature modifications and bug repairs) in natural language, and are useful for program comprehension. Due to the frequent updates of software and time cost, developers are generally unmotivated to write commit messages for code changes. Therefore, automating the message writing process is necessitated. Previous studies on commit message generation have been benefited from generation models or retrieval models, but the code structure of changed code, i.e., AST, which can be important for capturing code semantics, has not been explicitly involved. Moreover, although generation models have the advantages of synthesizing commit messages for new code changes, they are not easy to bridge the semantic gap between code and natural languages which could be mitigated by retrieval models. In this paper, we propose a novel commit message generation model, named ATOM, which explicitly incorporates the abstract syntax tree for representing code changes and integrates both retrieved and generated messages through hybrid ranking. Specifically, the hybrid ranking module can prioritize the most accurate message from both retrieved and generated messages regarding one code change. We evaluate the proposed model ATOM on our dataset crawled from 56 popular Java repositories. Experimental results demonstrate that ATOM increases the state-of-the-art models by 30.72% in terms of BLEU-4 (an accuracy measure that is widely used to evaluate text generation systems). Qualitative analysis also demonstrates the effectiveness of ATOM in generating accurate code commit messages.","1939-3520","","10.1109/TSE.2020.3038681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261989","Commit Message Generation;Code Changes;Abstract Syntax Tree","Syntactics;Semantics;Atomic measurements;Hybrid power systems;Benchmark testing;Writing;Java","","","","","","","","17 Nov 2020","","","IEEE","IEEE Early Access Articles"
"How Gender-biased Tools Shape Newcomer Experiences in OSS Projects","S. H. Padala; C. J. Mendez; L. F. Dias; I. Steinmacher; Z. Steine Hanson; C. Hilderbrand; A. Horvath; C. Hill; L. D. Simpson; M. Burnett; M. Gerosa; A. Sarma","School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: padalah@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: mendezc@oregonstate.edu); Computer Science, University of Sao Paulo, Sao Paulo, Sao Paulo Brazil (e-mail: fronchettiemail@gmail.com); School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, Arizona United States 860110001 (e-mail: Igor.Steinmacher@nau.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: steinehz@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States 97330 (e-mail: minic@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: horvatha@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: hillchar@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: simpsolo@oregonstate.edu); School of Electrical Engineering and Computer Science, Oregon State University, Corvallis, Oregon United States 97331 (e-mail: burnett@eecs.oregonstate.edu); School of Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, Arizona United States (e-mail: Marco.Gerosa@nau.edu); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States 97331 (e-mail: anita.sarma@oregonstate.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Previous research has revealed that newcomer women are disproportionately affected by gender-biased barriers in open source software (OSS) projects. However, this research has focused mainly on social/cultural factors, neglecting the software tools and infrastructure. To shed light on how OSS tools and infrastructure might factor into OSS barriers to entry, we conducted two studies: (1) a field study with five teams of software professionals, who worked through five use cases to analyze the tools and infrastructure used in their OSS projects; and (2) a diary study with 22 newcomers (9 women and 13 men) to investigate whether the barriers matched the ones identified by the software professionals. The field study produced a bleak result: software professionals found gender biases in 73% of all the newcomer barriers they identified. Further, the diary study confirmed these results: Women newcomers encountered gender biases in 63% of barriers they faced. Fortunately, many the kinds of barriers and biases revealed in these studies could potentially be ameliorated through changes to the OSS software environments and tool.","1939-3520","","10.1109/TSE.2020.2984173","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9055190","","Tools;Problem-solving;Open source software;Documentation;Cultural differences;Productivity","","","","3","","","","2 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Reinforcement Learning for Test Case Prioritization","M. Bagherzadeh; N. Kahani; L. Briand","School of Computing, Queen's University, 4257 Kingston, Ontario, Canada, (e-mail: mojtaba@cs.queensu.ca); School of Computing, Queens University, Canada, Kingston, Ontario, Canada, (e-mail: kahani@cs.queensu.ca); SnT Centre, University of Luxembourg, Luxembourg, Luxembourg, Luxembourg, 2721 (e-mail: lionel.briand@uni.lu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Continuous Integration (CI) significantly reduces integration problems, speeds up development time, and shortens release time. However, it also introduces new challenges for quality assurance activities, including regression testing, which is the focus of this work. Though various approaches for test case prioritization have shown to be very promising in the context of regression testing, specific techniques must be designed to deal with the dynamic nature and timing constraints of CI. Recently, Reinforcement Learning (RL) has shown great potential in various challenging scenarios that require continuous adaptation, such as game playing, real-time ads bidding, and recommender systems. Inspired by this line of work and building on initial efforts in supporting test case prioritization with RL techniques, we perform here a comprehensive investigation of RL-based test case prioritization in a CI context. To this end, taking test case prioritization as a ranking problem, we model the sequential interactions between the CI environment and a test case prioritization agent as an RL problem, using three alternative ranking models. We then rely on carefully selected and tailored state-of-the-art RL techniques to automatically and continuously learn a test case prioritization strategy, whose objective is to be as close as possible to the optimal one. Our extensive experimental analysis shows that the best RL solutions provide a significant accuracy improvement over previous RL-based work, with prioritization strategies getting close to being optimal, thus paving the way for using RL to prioritize test cases in a CI context.","1939-3520","","10.1109/TSE.2021.3070549","Canadian Network for Research and Innovation in Machining Technology Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394799","Continuous Integration;CI;Reinforcement Learning;Test Prioritization","Testing;History;Training;Reinforcement learning;Software systems;Adaptation models;Software algorithms","","","","","","","IEEE","2 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Forecasting Architectural Decay from Evolutionary History","J. Garcia; E. Kouroshfar; N. Ghorbani; S. Malek","Institute for Software Research, Univ. of California, Irvine, Irvine, California, United States, (e-mail: joshug4@uci.edu); Not Applicable, Amazon.com Inc, 110288 Seattle, Washington, United States, (e-mail: ekouroshfar@gmail.com); Institute for Software Research, Univ. of California, Irvine, Irvine, California, United States, (e-mail: negargh@uci.edu); Informatics, University of California Irvine, Irvine, California, United States, 92697 (e-mail: malek@uci.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","As a software system evolves, its architecture tends to decay, leading to the occurrence of architectural elements that become resistant to maintenance or prone to defects. To address this problem, engineers can significantly benefit from determining which architectural elements will decay before that decay actually occurs. Forecasting decay allows engineers to take steps to prevent decay, such as focusing maintenance resources on the architectural elements most likely to decay. To that end, we construct novel models that predict the quality of an architectural element by utilizing multiple architectural views (both structural and semantic) and architectural metrics as features for prediction. We conduct an empirical study using our prediction models on 38 versions of five systems. Our findings show that we can predict low architectural quality, i.e., architectural decay, with high performanceeven for cases of decay that suddenly occur in an architectural module. We further report the factors that best predict architectural quality.","1939-3520","","10.1109/TSE.2021.3060068","Division of Computer and Network Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9357984","software architecture;prediction model;architectural smell;architectural decay","Measurement;Predictive models;Software;Computer architecture;Maintenance engineering;Semantics;Software systems","","","","","","","IEEE","18 Feb 2021","","","IEEE","IEEE Early Access Articles"
"POMP++: Facilitating Postmortem Program Diagnosis with Value-set Analysis","D. Mu; Y. Du; J. Xu; J. Xu; X. Xing; B. Mao; P. Liu","Computer Science and Technology, Nanjing University, 12581 Nanjing, jiangsu China (e-mail: dzm77@ist.psu.edu); Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: duyunlan@smail.nju.edu.cn); Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: jianhao_xu@smail.nju.edu.cn); Department of Computer Science, Stevens Institute of Technology Charles V Schaefer Jr School of Engineering and Science, 200807 Hoboken, New Jersey United States (e-mail: jxu69@stevens.edu); College of Information Sciences and Technology, Pennsylvania State University, 8082 University Park, Pennsylvania United States (e-mail: xxing@ist.psu.edu); Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: maobing@nju.edu.cn); College of IST, Penn State, University Park, Pennsylvania United States 16802 (e-mail: pliu@ist.psu.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","With the emergence of hardware-assisted processor tracing, execution traces can be logged with lower runtime overhead and integrated into the core dump. In comparison with an ordinary core dump, such a new post-crash artifact provides software developers and security analysts with more clues to a program crash. However, existing works only rely on the resolved runtime information, which leads to limitation in data flow recovery within long execution traces. In this work, we propose POMP++, an automated tool to facilitate the analysis of post-crash artifacts. More specifically, POMP++ introduces a reverse execution mechanism to construct the data flow that a program followed prior to its crash. Furthermore, POMP++ utilizes Value-set Analysis, which helps to verify memory alias relation, to improve the ability of data flow recovery. With the restored data flow, POMP++ then performs backward taint analysis and highlights program statements that actually contribute to the crash. We have implemented POMP++ for Linux system on x86-32 platform, and tested it against various crashes resulting from 31 distinct real-world security vulnerabilities. The evaluation shows that, our work can pinpoint the root causes in 29 cases, increase the amount of recovered memory addresses by 12% and reduce the execution time by 60% compared with existing reverse execution. In short, POMP++ can accurately and efficiently pinpoint program statements that truly contribute to the crashes, making failure diagnosis significantly convenient.","1939-3520","","10.1109/TSE.2019.2939528","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823943","Postmortem Program Diagnosis;Failure Diagnosis;Reverse Execution;Value-set Analysis","Computer crashes;Software;Security;Core dumps;Registers;Runtime;Tools","","","","","","","","4 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Holistic Combination of Structural and Textual Code Information for Context based API Recommendation","C. Chen; X. Peng; Z. Xing; J. Sun; X. Wang; Y. Zhao; W. Zhao","School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, 201203 (e-mail: 15110240004@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: pengxin@fudan.edu.cn); Research School of Computer Science, Australian National University, 2219 ACTON, Australian Capital Territory, Australia, 2601 (e-mail: zhenchang.xing@anu.edu.au); SIS, Singapore Management University, 54756 Singapore, Singapore, Singapore, 689867 (e-mail: junsun@smu.edu.sg); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: 18212010029@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: 17212010079@fudan.edu.cn); School of Computer Science, Fudan University, 12478 Shanghai, Shanghai, China, (e-mail: wyzhao@fudan.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Context based API recommendation is an important way to help developers find the needed APIs effectively and efficiently. For effective API recommendation, we need not only a joint view of both structural and textual code information, but also a holistic view of correlated API usage in control and data flow graph as a whole. Unfortunately, existing API recommendation methods exploit structural or textual code information separately. In this work, we propose a novel API recommendation approach called APIRec-CST (API Recommendation by Combining Structural and Textual code information). APIRec-CST is a deep learning model that combines the API usage with the text information in the source code based on an API Context Graph Network and a Code Token Network that simultaneously learn structural and textual features for API recommendation. We apply APIRec-CST to train a model for JDK library based on 1,914 open-source Java projects and evaluate the accuracy and MRR (Mean Reciprocal Rank) of API recommendation with another 6 open-source projects. The results show that our approach achieves respectively a top-1, top-5, top-10 accuracy and MRR of 60.3%, 81.5%, 87.7% and 69.4%, and significantly outperforms an existing graph-based statistical approach and a tree-based deep learning approach for API recommendation. A further analysis shows that textual code information makes sense and improves the accuracy and MRR. The sensitivity analysis shows that the top-k accuracy and MRR of APIRec-CST are insensitive to the number of APIs to be recommended in a hole. We also conduct a user study in which two groups of students are asked to finish 6 programming tasks with or without our APIRec-CST plugin. The results show that APIRec-CST can help the students to finish the tasks faster and more accurately and the feedback on the usability is overwhelmingly positive.","1939-3520","","10.1109/TSE.2021.3074309","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9409670","API;recommendation;deep learning;data flow;control flow;text","Semantics;Deep learning;Data models;Context modeling;Computational modeling;Task analysis;Token networks","","","","","","","IEEE","20 Apr 2021","","","IEEE","IEEE Early Access Articles"
"On the costs and profit of software defect prediction","S. Herbold","Institute for Computer Science, Georg-August-Universität Güttingen, Güttingen, Lower Saxony Germany 37077 (e-mail: herbold@cs.uni-goettingen.de)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Defect prediction can be a powerful tool to guide the use of quality assurance resources. However, while lots of research covered methods for defect prediction as well as methodological aspects of defect prediction research, the actual cost saving potential of defect prediction is still unclear. Within this article, we close this research gap and formulate a cost model for software defect prediction. We derive mathematically provable boundary conditions that must be fulfilled by defect prediction models such that there is a positive profit when the defect prediction model is used. Our cost model includes aspects like the costs for quality assurance, the costs of post-release defects, the possibility that quality assurance fails to reveal predicted defects, and the relationship between software artifacts and defects. We initialize the cost model using different assumptions, perform experiments to show trends of the behavior of costs on real projects. Our results show that the unrealistic assumption that defects only affect a single software artifact, which is a standard practice in the defect prediction literature, leads to inaccurate cost estimations. Moreover, the results indicate that thresholds for machine learning metrics are also not suited to define success criteria for software defect prediction.","1939-3520","","10.1109/TSE.2019.2957794","Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924628","Defect prediction;costs;return on investment","Predictive models;Software;Quality assurance;Measurement;Mathematical model;Machine learning;Computational modeling","","","","1","","","","5 Dec 2019","","","IEEE","IEEE Early Access Articles"
"An Empirical Study of Type-Related Defects in Python Projects","F. Khan; B. Chen; D. Varro; S. Mcintosh","Electrical and Computer Engineering, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: faizan.khan3@mail.mcgill.ca); Electrical and Computer Engineering, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: boqi.chen@mail.mcgill.ca); Dept. of Measurement and Information Systems, Budapest University of Technology and Economics, Budapest, N/A, Hungary, H-1117 (e-mail: daniel.varro@mcgill.ca); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, N2L 3G1 (e-mail: shane.mcintosh@uwaterloo.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","In recent years, Python has experienced explosive growth in adoption, particularly among open source projects. While Python's dynamically-typed nature provides developers with powerful programming abstractions, that same dynamic type system allows for type-related defects to accumulate in code bases. To aid in the early detection of type-related defects, type annotations were introduced into the Python ecosystem (i.e., PEP-484) and static type checkers like mypy have appeared on the market. While applying a type checker like mypy can in theory help to catch type-related defects before they impact users, little is known about the real impact of adopting a type checker to reveal defects in Python projects. In this paper, we study the extent to which Python projects benefit from such type checking features. For this purpose, we mine the issue tracking and version control repositories of 210 Python projects on GitHub. Inspired by the work of Gao et al. on type-related defects in JavaScript, we add type annotations to test whether detects an error that would have helped developers to avoid real defects. We observe that 15% of the defects could have been prevented by mypy. Moreover, we find that there is no significant difference between the experience level of developers committing type-related defects and the experience of developers committing defects that are not type-related. In addition, a manual analysis of the anti-patterns that most commonly lead to type-checking faults reveals that the redefinition of Python references, dynamic attribute initialization and incorrectly handled Null objects are the most common causes of type-related faults. Since our study is conducted on fixed public defects that have gone through code reviews and multiple test cycles, these results represent a lower bound on the benefits of adopting a type checker. Therefore, we recommend incorporating a static type checker like mypy into the development workflow, as not only will it prevent type-related defects but also mitigate certain anti-patterns during development.","1939-3520","","10.1109/TSE.2021.3082068","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9436020","Software Defects;Static Type Checkers;Dynamic Type Systems;Empirical Study","Python;Annotations;Tools;Task analysis;Ecosystems;Software systems;Software measurement","","","","","","","IEEE","19 May 2021","","","IEEE","IEEE Early Access Articles"
"Can Clean New Code reduce Technical Debt Density","G. Digkas; A. N. Chatzigeorgiou; A. Ampatzoglou; P. C. Avgeriou","Institute of Mathematics and Computer Science, University of Groningen, 3647 Groningen, Groningen, Netherlands, (e-mail: g.digkas@rug.nl); Applied Informatics, University of Macedonia, Thessaloniki, Thessaloniki, Greece, 54006 (e-mail: achat@uom.gr); Applied Informatics, University of Macedonia, 68999 Thessaloniki, Thessaloniki, Greece, 56728 (e-mail: apostolos.ampatzoglou@gmail.com); Department of Mathematics and Computing Science, University of Groningen, Groningen, groningen, Netherlands, 9747 AG (e-mail: paris.avgeriou@gmail.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","While technical debt grows in absolute numbers as software systems evolve over time, the density of technical debt (technical debt divided by lines of code) is reduced in some cases. This can be explained by either the application of refactorings or the development of new artifacts with limited Technical Debt. In this paper we explore the second explanation, by investigating the relation between the amount of Technical Debt in new code and the evolution of Technical Debt in the system. To this end, we compare the Technical Debt Density of new code with existing code, and we investigate which of the three major types of code changes (additions, deletions and modifications) is primarily responsible for changes in the evolution of Technical Debt density. Furthermore, we study whether there is a relation between code quality practices and the “cleanness” of new code. To obtain the required data, we have performed a large-scale case study on twenty-seven open-source software projects by the Apache Software Foundation, analyzing 66,661 classes and 56,890 commits. The results suggest that writing “clean” (or at least “cleaner”) new code can be an efficient strategy for reducing Technical Debt Density, and thus preventing software decay over time. The findings also suggest that projects adopting an explicit policy for quality improvement, e.g. through discussions on code quality in board meetings, are associated with a higher frequency of cleaner new code commits. Therefore, we champion the establishment of processes that monitor the density of Technical Debt of new code to control the accumulation of Technical Debt in a software system.","1939-3520","","10.1109/TSE.2020.3032557","H2020 European Institute of Innovation and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9234106","technical debt;refactoring;clean code;case study","Open source software;Writing;Logic gates;Market research;Monitoring;Maintenance engineering","","","","1","","","","20 Oct 2020","","","IEEE","IEEE Early Access Articles"
"Formal Verification of Masking Countermeasures for Arithmetic Programs","G. Pengfei; X. Hongyi; P. Sun; J. Zhang; F. Song; T. Chen","School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: gaopf@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: xiehy@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: sunpu@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China (e-mail: zhangjun@shanghaitech.edu.cn); School of Information Science and Technology, ShanghaiTech University, 387433 Shanghai, Shanghai China 201210 (e-mail: songfu@shanghaitech.edu.cn); Department of Computer Science and Information Systems, Birkbeck University of London, 4894 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: taolue.chen@surrey.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Cryptographic algorithms are widely used to protect data privacy in many aspects of daily lives. Unfortunately, programs implementing cryptographic algorithms may be vulnerable to practical power side-channel attacks, which may infer private data via statistical analysis. To thwart these attacks, several masking schemes have been proposed, giving rise to effective countermeasures for reducing the statistical correlation between private data and power consumptions. However, programs that rely on secure masking schemes are not secure a priori. Indeed, designing effective masking programs is a labor intensive and error-prone task. Although some techniques have been proposed for formally verifying masking countermeasures and for quantifying masking strength, they are currently limited to Boolean programs and suffer from low accuracy. In this work, we propose an approach for formally verifying masking countermeasures of arithmetic programs. Our approach is more accurate for arithmetic programs and more scalable for Boolean programs comparing to the existing approaches. It is essentially a synergistic integration of type inference and model-counting based methods, armed with domain specific heuristics. The type inference system allows a fast deduction of leakage-freeness of most intermediate computations, the model-counting based methods accounts for completeness, namely, to eliminate spurious flaws, and the heuristics facilitate both type inference and model-counting based reasoning, which improve scalability and efficiency in practice. In case that the program does contain leakage, we provide a method to quantify its masking strength. A distuiguished feature of our type sytem lies in its support of compositonal reasoning when verifying programs with procedure calls, so the need of inlining procedures can be significantly reduced. We have implemented our methods in a verification tool QMVERIF which has been extensively evaluated on cryptographic benchmarks including full AES, DES and MAC-Keccak. The experimental results demonstrate the effectiveness and efficiency of our approach, especially for compositional reasoning. In particular, our tool is able to automatically prove leakage-freeness of arithmetic programs for which only manual proofs exist so far; it is also significantly faster than the state-of-the-art tools: EasyCrypt on common arithmetic programs, QMSINFER, SC Sniffer and maskVerif on Boolean programs.","1939-3520","","10.1109/TSE.2020.3008852","Engineering and Physical Sciences Research Council; Natural Science Foundation of Guangdong Province; Guangdong Science and Technology Department; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9139284","","Cryptography;Tools;Computational modeling;Software algorithms;Power demand;Cognition","","","","1","","","","13 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Simpler Hyperparameter Optimization for Software Analytics: Why, How, When","A. Agrawal; X. Yang; R. Agrawal; R. Yedida; X. Shen; T. Menzies","Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: aagrawa8@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: xyang37@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, (e-mail: ragrawa3@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina, United States, (e-mail: ryedida@ncsu.edu); Computer Science, North Carolina State University, Raleigh, North Carolina, United States, 27695 (e-mail: xshen5@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina, United States, 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","How can we make software analytics simpler and faster One method is to match the complexity of analysis to the intrinsic complexity of the data being explored. For example, hyperparameter optimizers find the control settings for data miners that improve the predictions generated via software analytics. Sometimes, very fast hyperparameter optimization can be achieved by ‘`DODGE-ing’'; i.e. simply steering way from settings that lead to similar conclusions. But when is it wise to use that simple approach and when must we use more complex (and much slower) optimizers To answer this, we applied hyperparameter optimization to 120 SE data sets that explored bad smell detection, predicting Github issue close time, bug report analysis, defect prediction, and dozens of other non-SE problems. We find that the simple DODGE works best for data sets with low ‘`intrinsic dimensionality’' (around 3) and very poorly for higher-dimensional data (around 8). Nearly all the SE data seen here was intrinsically low-dimensional, indicating that DODGE is applicable for many SE analytics tasks.","1939-3520","","10.1109/TSE.2021.3073242","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9405415","software analytics;hyperparameter optimization;defect prediction;bad smell detection;issue close time;bug reports F","Software;Optimization;Clustering algorithms;Text mining;Measurement;Computer bugs;Task analysis","","","","","","","IEEE","15 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Authors’ Reply to “Comments on ‘Researcher Bias: The Use of Machine Learning in Software Defect Prediction’”","M. Shepperd; T. Hall; D. Bowes","Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; Department of Computer Science, Brunel University London, Uxbridge, United Kingdom; University of Hertfordshire, Hatfield, United Kingdom","IEEE Transactions on Software Engineering","11 Nov 2018","2018","44","11","1129","1131","In 2014 we published a meta-analysis of software defect prediction studies [1] . This suggested that the most important factor in determining results was Research Group, i.e., who conducts the experiment is more important than the classifier algorithms being investigated. A recent re-analysis [2] sought to argue that the effect is less strong than originally claimed since there is a relationship between Research Group and Dataset. In this response we show (i) the re-analysis is based on a small (21 percent) subset of our original data, (ii) using the same re-analysis approach with a larger subset shows that Research Group is more important than type of Classifier and (iii) however the data are analysed there is compelling evidence that who conducts the research has an effect on the results. This means that the problem of researcher bias remains. Addressing it should be seen as a matter of priority amongst those of us who conduct and publish experiments comparing the performance of competing software defect prediction systems.","1939-3520","","10.1109/TSE.2017.2731308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990255","Software quality assurance;defect prediction;researcher bias","Software;NASA;Measurement;Analysis of variance;Data models;Predictive models;Analytical models","learning (artificial intelligence);pattern classification;program diagnostics","researcher bias;machine learning;meta-analysis;classifier algorithms;re-analysis approach;software defect prediction systems;research group","","1","","5","","24 Jul 2017","","","IEEE","IEEE Journals"
"Why Do Software Developers Use Static Analysis Tools? A User-Centered Study of Developer Needs and Motivations","L. Nguyen Quang Do; J. Wright; K. Ali","Computer Science, Universitat Paderborn, 26578 Paderborn, North Rhine-Westphalia Germany (e-mail: lisa.nqd@gmail.com); Department of Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada (e-mail: james.wright@ualberta.ca); Computing Science, University of Alberta, 3158 Edmonton, Alberta Canada (e-mail: karim.ali@ualberta.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","As increasingly complex software is developed every day, a growing number of companies use static analysis tools to reason about program properties ranging from simple coding style rules to more advanced software bugs, to multi-tier security vulnerabilities. While increasingly complex analyses are created, developer support must also be updated to ensure that the tools are used to their best potential. Past research in the usability of static analysis tools has primarily focused on usability issues encountered by software developers, and the causes of those issues in analysis tools. In this article, we adopt a more user-centered approach, and aim at understanding why software developers use analysis tools, which decisions they make when using those tools, what they look for when making those decisions, and the motivation behind their strategies. This approach allows us to derive new tool requirements that closely support software developers (e.g., systems for recommending warnings to fix that take developer knowledge into account), and also open novel avenues for further static-analysis research such as collaborative user interfaces for analysis warnings.","1939-3520","","10.1109/TSE.2020.3004525","Natural Sciences and Engineering Research Council of Canada; Bundesministerium fr Bildung und Forschung; Deutsche Forschungsgemeinschaft; Canadian Institute for Advanced Research; NRW Research Training Group on Human Centered Systems Security; Heinz Nixdorf Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9124719","Program analysis;Development tools;Integrated environments;Graphical environments;Usability","Tools;Static analysis;Usability;Industries;Computer bugs;Security","","","","","","","","24 Jun 2020","","","IEEE","IEEE Early Access Articles"
"A Survey on the Adoption of Patterns for Engineering Software for the Cloud","T. Sousa; H. S. Ferreira; F. F. Correia","Department of Engineering and Informatics, University of Porto Faculty of Engineering, 112048 Porto, Porto, Portugal, 4200-465 (e-mail: tiagoboldt@gmail.com); Engenharia Informtica, University of Porto Faculty of Engineering, 112048 Porto, Porto, Portugal, 4200-465 (e-mail: hugo.sereno@fe.up.pt); Department of Informatics Engineering, University of Porto Faculty of Engineering, 112048 Porto, Porto, Portugal, 4200-465 (e-mail: filipe.correia@fe.up.pt)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","This work takes as a starting point a collection of patterns for engineering software for the cloud and tries to find how they are regarded and adopted by professionals. Existing literature assessed the adoption of cloud computing with a focus on business and technological aspects and fall short in grasping a holistic view of the underlying approaches. Other authors delved into how independent patterns can be discovered (mined) and verified, but do not provide insights on their adoption. We investigate (1) their relevance for professional software developers, (2) the extent to which product and company characteristics influence their adoption, and (3) how adopting some patterns might correlate with the likelihood of adopting others. For this purpose, we surveyed practitioners using an online questionnaire (n = 102). Among other findings, we conclude that most companies use these patterns, with the overwhelming majority (97%) using at least one. We observe that the mean pattern adoption tends to increase as companies mature, namely when varying the product operation complexity, active monthly users, and company size. Finally, we search for correlations in the adoption of specific patterns and attempt to infer causation among them, further hinting on how some practices are dependent or influence the adoption of others. We conclude that there are patterns of practices adoption that best correlates with a specific company and product characteristics, as well as relationships between the patterns that were not covered by the original pattern language and which might deserve further investigation.","1939-3520","","10.1109/TSE.2021.3052177","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9325940","cloud-computing;patterns;pattern adoption;software architecture;microservices;community survey","Cloud computing;Software;Companies;Monitoring;Industries;Containers;Scalability","","","","","","","IEEE","15 Jan 2021","","","IEEE","IEEE Early Access Articles"
"What's Wrong With My Benchmark Results? Studying Bad Practices in JMH Benchmarks","D. E. Damasceno Costa; C. Bezemer; P. Leitner; A. Andrzejak","Institute of Computer Science, Ruprecht Karls Universitat Heidelberg, 9144 Heidelberg, Baden Wurttemberg Germany 69120 (e-mail: diego.costa@informatik.uni-heidelberg.de); School of Computing, Queen\'s University, Kingston, Ontario Canada (e-mail: bezemer@cs.queensu.ca); Computer Science and Engineering, Chalmers | University of Gothenburg, Gothenburg, Gothenburg Sweden (e-mail: philipp.leitner@chalmers.se); Institute of Computer Science, University of Heidelberg, Heidelberg, Baden-Wurttemberg Germany 69120 (e-mail: artur.andrzejak@informatik.uni-heidelberg.de)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Microbenchmarking frameworks, such as Java's Microbenchmark Harness (JMH), allow developers to write fine-grained performance test suites at the method or statement level. However, due to the complexities of the Java Virtual Machine, developers often struggle with writing expressive JMH benchmarks which accurately represent the performance of such methods or statements. In this paper, we empirically study bad practices of JMH benchmarks. We present a tool that leverages static analysis to identify 5 bad JMH practices. Our empirical study of 123 open source Java-based systems shows that each of these 5 bad practices are prevalent in open source software. Further, we conduct several experiments to quantify the impact of each bad practice in multiple case studies, and find that bad practices often significantly impact the benchmark results. To validate our experimental results, we constructed patches that fix the identified bad practices for six of the studied open source projects, of which five were merged into the main branch of the project. In this paper, we show that developers struggle with accurate Java microbenchmarking, and provide several recommendations to developers of microbenchmarking frameworks on how to improve future versions of their framework.","1939-3520","","10.1109/TSE.2019.2925345","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8747433","Performance testing;microbenchmarking;JMH;bad practices;static analysis","Benchmark testing;Java;Optimization;Tools;Writing;Static analysis","","","","","","","","27 Jun 2019","","","IEEE","IEEE Early Access Articles"
"Automated Test Case Generation as a Many-Objective Optimisation Problem with Dynamic Selection of the Targets","A. Panichella; F. M. Kifetew; P. Tonella","SnT, University of Luxembourg, Luxembourg, Esch-sur-Alzette, Luxembourg; Fondazione Bruno Kessler, Trento, Italy; Fondazione Bruno Kessler, Trento, Italy","IEEE Transactions on Software Engineering","12 Feb 2018","2018","44","2","122","158","The test case generation is intrinsically a multi-objective problem, since the goal is covering multiple test targets (e.g., branches). Existing search-based approaches either consider one target at a time or aggregate all targets into a single fitness function (whole-suite approach). Multi and many-objective optimisation algorithms (MOAs) have never been applied to this problem, because existing algorithms do not scale to the number of coverage objectives that are typically found in real-world software. In addition, the final goal for MOAs is to find alternative trade-off solutions in the objective space, while in test generation the interesting solutions are only those test cases covering one or more uncovered targets. In this paper, we present Dynamic Many-Objective Sorting Algorithm (DynaMOSA), a novel many-objective solver specifically designed to address the test case generation problem in the context of coverage testing. DynaMOSA extends our previous many-objective technique Many-Objective Sorting Algorithm (MOSA) with dynamic selection of the coverage targets based on the control dependency hierarchy. Such extension makes the approach more effective and efficient in case of limited search budget. We carried out an empirical study on 346 Java classes using three coverage criteria (i.e., statement, branch, and strong mutation coverage) to assess the performance of DynaMOSA with respect to the whole-suite approach (WS), its archive-based variant (WSA) and MOSA. The results show that DynaMOSA outperforms WSA in 28 percent of the classes for branch coverage (+8 percent more coverage on average) and in 27 percent of the classes for mutation coverage (+11 percent more killed mutants on average). It outperforms WS in 51 percent of the classes for statement coverage, leading to +11 percent more coverage on average. Moreover, DynaMOSA outperforms its predecessor MOSA for all the three coverage criteria in 19 percent of the classes with +8 percent more code coverage on average.","1939-3520","","10.1109/TSE.2017.2663435","Fonds National de la Recherche Luxembourg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7840029","Evolutionary testing;many-objective optimisation;automatic test case generation","Heuristic algorithms;Optimization;Testing;Software algorithms;Algorithm design and analysis;Sorting;Genetic algorithms","optimisation;program testing;search problems;sorting","dynamic target selection;Many-Objective Sorting Algorithm;search-based approaches;test sequence;test input data;branch coverage;many-objective solver;MOAs;many-objective optimisation algorithms;multiple test targets;multiobjective problem;Many-Objective optimisation problem;automated test case generation;DynaMOSA","","29","","59","","2 Feb 2017","","","IEEE","IEEE Journals"
"Grammar Based Directed Testing of Machine Learning Systems","S. S. Udeshi; S. Chattopadhyay","ISTD, Singapore University of Technology and Design, 233793 Singapore, Singapore Singapore (e-mail: sakshi_udeshi@mymail.sutd.edu.sg); ISTD, Singapore University of Technology and Design, 233793 Singapore, Singapore Singapore 487372 (e-mail: sudipta_chattopadhyay@sutd.edu.sg)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The massive progress of machine learning has seen its application over a variety of domains in the past decade. But how do we develop a systematic, scalable and modular strategy to validate machine-learning systems? We present, to the best of our knowledge, the first approach, which provides a systematic test framework for machine-learning systems that accepts grammar-based inputs. Our OGMA approach automatically discovers erroneous behaviours in classifiers and leverages these erroneous behaviours to improve the respective models. OGMA leverages inherent robustness properties present in any well trained machine-learning model to direct test generation and thus, implementing a scalable test generation methodology. To evaluate our OGMA approach, we have tested it on three real world natural language processing (NLP) classifiers. We have found thousands of erroneous behaviours in these systems. We also compare OGMA with a random test generation approach and observe that OGMA is more effective than such random test generation by up to 489%.","1939-3520","","10.1109/TSE.2019.2953066","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8907363","","Machine learning;Grammar;Robustness;Systematics;Test pattern generators;Natural language processing","","","","1","","","","20 Nov 2019","","","IEEE","IEEE Early Access Articles"
"Clustering Crowdsourced Test Reports of Mobile Applications Using Image Understanding","D. Liu; Y. Feng; X. Zhang; J. Jones; Z. Chen","School of Computer Science and Technology, Soochow University, 12582 Suzhou, Jiangsu China (e-mail: dliu0721@stu.suda.edu.cn); Department of Informatics, University of California Irvine, 8788 Irvine, California United States (e-mail: yang.feng@uci.edu); School of Computer Science and Technology, Soochow University, 12582 Suzhou, Jiangsu China (e-mail: xfzhang@suda.edu.cn); Informatics, University of California, Irvine, Irvine, California United States 92697-3440 (e-mail: jajones@uci.edu); State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, Jiangsu China 210093 (e-mail: zychen@nju.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Crowdsourced testing has been widely used to improve software quality as it can detect various bugs and simulate real usage scenarios. Crowdsourced workers perform tasks on crowdsourcing platforms and present their experiences as test reports, which naturally generates an overwhelming number of test reports. Therefore, inspecting these reports becomes a time-consuming yet inevitable task. In recent years, many text-based prioritization and clustering techniques have been proposed to address this challenge. However, in mobile testing, test reports often consist of only short test descriptions but rich screenshots. Compared with the uncertainty of textual information, well-defined screenshots can often adequately express the mobile application's activity views. In this paper, by employing image-understanding techniques, we propose an approach for clustering crowdsourced test reports of mobile applications based on both textual and image features to assist the inspection procedure. We employ Spatial Pyramid Matching (SPM) to measure the similarity of the screenshots and use the natural-language-processing techniques to compute the textual distance of test reports. To validate our approach, we conducted an experiment on 6 industrial crowdsourced projects that contain more than 1600 test reports and 1400 screenshots. The results show that our approach is capable of outperforming the baselines by up to 37% regarding the APFD metric. Further, we analyze the parameter sensitivity of our approach and discuss the settings for different application scenarios.","1939-3520","","10.1109/TSE.2020.3017514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174926","Crowdsourced Testing;Mobile Testing;Test Report Processing","Testing;Task analysis;Mobile applications;Computer bugs;Software;Mars;Mobile handsets","","","","","","","","24 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Detecting Software Security Vulnerabilities via Requirements Dependency Analysis","W. Wang; F. Dumont; N. Niu; G. Horton","Electrical Engineering and Computer Science, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: wang2wt@mail.uc.edu); EECS, University of Cincinnati, Cincinnati, Ohio United States (e-mail: dumontfn@mail.uc.edu); EECS, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: nan.niu@uc.edu); UC Libraries, University of Cincinnati, Cincinnati, Ohio United States 45221 (e-mail: glen.horton@uc.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Cyber attacks targeting software applications have a tremendous impact on our daily life. For example, attackers have utilized vulnerabilities of web applications to steal and gain unauthorized use of sensitive data stored in these systems. Previous studies indicate that security testing is highly precise, and therefore is widely applied to validate individual security requirements. However, dependencies between security requirements may cause additional vulnerabilities. Manual dependency detection faces scalability challenges, e.g., a previous study shows that the pairwise dependency analysis of 40 requirements would take around 12 hours. In this paper, we present a novel approach which integrates the interdependency among high-level security requirements, such as those documented in policies, regulations, and standards. We then use automated requirements tracing methods to identify product-level security requirements and their dependencies. Our manual analysis of HIPAA and FIPS 200 leads to the identification of five types of high-level security requirements dependencies, which further inform the automated tracing methods and guide the designs of system-level security tests. Experimental results on five projects in healthcare and education domains show the significant recall improvements at 81%. Our case study on a deployed production system uncovers four previously unknown vulnerabilities by using the detected requirements dependencies as test paths, demonstrating our approach's value in connecting requirements engineering with security testing.","1939-3520","","10.1109/TSE.2020.3030745","Division of Computing and Communication Foundations; Ohio Cyber Range; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9222252","Security requirements;requirements dependency management;requirements traceability;vulnerability discovery","Security;Software;Testing;Manuals;Static analysis;Regulation;Scalability","","","","","","","","13 Oct 2020","","","IEEE","IEEE Early Access Articles"
"Conditional Quantitative Program Analysis","M. Gerrard; M. Borges; M. Dwyer; A. Fillieri","Computer Science, University of Virginia, 2358 Charlottesville, Virginia United States (e-mail: mjg6v@virginia.edu); Computing, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: m.borges@imperial.ac.uk); Computer Science, University of Virginia, Charlottesville, Virginia United States (e-mail: matthewbdwyer@virginia.edu); Department of Computing, Imperial College London, 4615 London, London United Kingdom of Great Britain and Northern Ireland SW7 2AZ (e-mail: a.filieri@imperial.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Standards for certifying safety-critical systems have evolved to permit the inclusion of evidence generated by program analysis and verification techniques. The past decade has witnessed the development of several program analyses that are capable of computing guarantees on bounds for the probability of failure. This paper develops a novel program analysis framework, CQA, that combines evidence from different underlying analyses to compute bounds on failure probability. It reports on an evaluation of different CQA-enabled analyses and implementations of state-of-the-art quantitative analyses to evaluate their relative strengths and weaknesses. To conduct this evaluation, we filter an existing verification benchmark to reflect certification evidence generation challenges. Our evaluation across the resulting set of 136 C programs, totaling more than 385k SLOC, each with a probability of failure below $10^4$, demonstrates how CQA extends the state-of-the-art. The CQA infrastructure, including tools, subjects, and generated data is publicly available at bitbucket.org/mgerrard/cqa.","1939-3520","","10.1109/TSE.2020.3016778","National Science Foundation; DARPA ARCOS; U.S. Army Research Office; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9167482","program analysis;model counting;symbolic execution;conditional analysis;software reliability;software certification","Safety;Standards;Static analysis;Software;Reliability;Benchmark testing","","","","","","","","14 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Pegasus: Performance Engineering for Software Applications Targeting HPC Systems","P. Pinto; J. Bispo; J. Cardoso; J. G. Barbosa; D. Gadioli; G. Palermo; J. Martinovic; M. Golasowski; K. Slaninova; R. Cmar; C. SILVANO","FEUP, Universidade do Porto Faculdade de Engenharia, 112048 Porto, Porto Portugal 4200-465 (e-mail: p.pinto@fe.up.pt); FEUP, Universidade do Porto Faculdade de Engenharia, 112048 Porto, Porto Portugal (e-mail: jbispo@fe.up.pt); FEUP, Universidade do Porto Faculdade de Engenharia, 112048 Porto, Porto Portugal (e-mail: jmpc@fe.up.pt); Engenharia Informtica, Faculdade de Engenharia da Universidade do Porto, Porto, Porto Portugal 4200-465 (e-mail: jbarbosa@fe.up.pt); Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Milano Italy (e-mail: davide.gadioli@polimi.it); Dipartimento di Elettronica e Informazione, Politecnico di Milano, Milano, Milano Italy (e-mail: gianluca.palermo@polimi.it); IT4Innovation, Vysoka Skola Banska-Technicka Univerzita Ostrava, 48278 Ostrava, Moravia Czech Republic (e-mail: jan.martinovic@vsb.cz); IT4Innovations, Vysoka Skola Banska-Technicka Univerzita Ostrava, 48278 Ostrava, Moravia Czech Republic (e-mail: martin.golasowski@vsb.cz); IT4Innovation, Vysoka Skola Banska-Technicka Univerzita Ostrava, 48278 Ostrava, Moravia Czech Republic (e-mail: katerina.slaninova@vsb.cz); -, Sygic, Bratislava, Bratislava Slovakia (e-mail: rcmar@sygic.com); Dipartimento di Elettronica, Informazion, Politecnico di Milano, MILANO, MILANO Italy (e-mail: cristina.silvano@polimi.it)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Developing and optimizing software applications for high performance and energy efficiency is a very challenging task, even when considering a single target machine. For instance, optimizing for multicore-based computing systems requires in-depth knowledge about programming languages, application programming interfaces, compilers, performance tuning tools, and computer architecture and organization. Many of the tasks of performance engineering methodologies require manual efforts and the use of different tools not always part of an integrated toolchain. This paper presents Pegasus, a performance engineering approach supported by a framework that consists of a source-to-source compiler, controlled and guided by strategies programmed in a Domain-Specific Language, and an autotuner. Pegasus is a holistic and versatile approach spanning various decision layers composing the software stack, and exploiting the system capabilities and workloads effectively through the use of runtime autotuning. The Pegasus approach helps developers by automating tasks regarding the efficient implementation of software applications in multicore computing systems. These tasks focus on application analysis, profiling, code transformations, and the integration of runtime autotuning. Pegasus allows developers to program their strategies or to automatically apply existing strategies to software applications in order to ensure the compliance of non-functional requirements, such as performance and energy efficiency. We show how to apply Pegasus and demonstrate its applicability and effectiveness in a complex case study, which includes tasks from a smart navigation system.","1939-3520","","10.1109/TSE.2020.3001257","H2020 Future and Emerging Technologies; Fundao para a Cincia e a Tecnologia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9113456","","Task analysis;Software;Tools;Runtime;Tuning;Power demand;Libraries","","","","","","","","10 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Corrections to “Detecting Bugs by Discovering Expectations and Their Violations”","P. Bian; B. Liang; Y. Zhang; C. Yang; W. Shi; Y. Cai","School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; School of Information, Renmin University of China, Beijing, China; State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","113","113","In the above named work (ibid., vol. 45, no. 10, pp. 984???1001, Oct. 2019), the corresponding author should have been listed as Bin Liang. The footnote information is corrected here.","1939-3520","","10.1109/TSE.2019.2958750","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952832","","Computer bugs;Computer science;Software;Libraries","","","","","","1","IEEE","8 Jan 2020","","","IEEE","IEEE Journals"
"GUI-Guided Test Script Repair for Mobile Apps","M. Pan; T. Xu; Y. Pei; Z. Li; T. Zhang; X. Li","State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: mxp@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: dz1633014@smail.nju.edu.cn); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: maximilian.pei@gmail.com); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: mg1733033@smail.nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: ztluck@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: lxd@nju.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Graphical User Interface (GUI) testing is widely used to test mobile apps. As mobile apps are frequently updated and need repeated testing, to reduce the test cost, their test cases are often coded as scripts to enable automated execution using test harnesses/tools. When those mobile apps evolve, many of the test scripts, however, may become broken due to changes made to the app GUIs. While it is desirable that the broken scripts get repaired, doing it manually can be preventively expensive if the number of tests need repairing is large. We propose in this paper a novel approach named METER to repairing broken GUI test scripts automatically when mobile apps evolve. METER leverages computer vision techniques to infer GUI changes between two versions of a mobile app and uses the inferred changes to guide the repair of GUI test scripts. Since METER only relies on screenshots to repair GUI tests, it is applicable to apps targeting open or closed source mobile platforms. In experiments conducted on 22 Android apps and 6 iOS apps, repairs produced by METER helped preserve 63.7% and 38.8% of all the test actions broken by the GUI changes, respectively.","1939-3520","","10.1109/TSE.2020.3007664","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9136844","","Meters;Graphical user interfaces;Mobile applications;Maintenance engineering;Testing;Tools;Computer vision","","","","","","","","8 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Control and Discovery of Environment Behaviour","M. Keegan; V. A. Braberman; N. D'Ippolito; N. Piterman; S. Uchitel","FCEN, Universidad de Buenos Aires, 28196 Buenos Aires, Buenos Aires, Argentina, (e-mail: maukeegan1@gmail.com); FCEN, Universidad de Buenos Aires, CONICET-ICC, 28196 Buenos Aires, Buenos Aires, Argentina, (e-mail: victor.braberman@gmail.com); FCEN, Universidad de Buenos Aires, CONICET-ICC, Buenos Aires, Argentina, (e-mail: ndippolito@dc.uba.ar); University of Gothenburg and the University of Leicester (e-mail: nir.piterman@gmail.com); FCEN, Universidad de Buenos Aires, CONICET-ICC and also with Imperial College London 28196 Buenos Aires, CABA, Argentina, (e-mail: suchitel@dc.uba.ar)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","An important ability of self-adaptive systems is to be able to autonomously understand the environment in which they operate and use this knowledge to control the environment behaviour in such a way that system goals are achieved. How can this be achieved when the environment is unknown? Two phase solutions that require a full discovery of environment behaviour before computing a strategy that can guarantee the goals or report the non-existence of such a strategy (i.e., unrealisability) are impractical as the environment may exhibit adversarial behaviour to avoid full discovery. In this paper we formalise a control and discovery problem for reactive system environments. In our approach a strategy must be produced that will, for every environment, guarantee that unrealisablity will be correctly concluded or system goals will be achieved by controlling the environment behaviour. We present a solution applicable to environments characterisable as labeled transition systems (LTS). We use modal transition systems (MTS) to represent partial knowledge of environment behaviour, and rely on MTS controller synthesis to make exploration decisions. Each decision either contributes more knowledge about the environment's behaviour or contributes to achieving the system goals. We present an implementation restricted to GR(1) goals and show its viability.","1939-3520","","10.1109/TSE.2020.3044532","Fondo para la Investigación Científica y Tecnológica; Secretaria de Ciencia y Tecnica Universidad de Buenos Aires; H2020 European Research Council; Consejo Nacional de Investigaciones Científicas y Técnicas; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9293408","Adaptive systems;reactive systems;discrete event controllers;environment control and discovery","Protocols;Learning automata;Testing;Sensors;Process control;Knowledge engineering;Internet","","","","","","","IEEE","14 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Heuristic and Neural Network based Prediction of Project-Specific API Member Access","L. Jiang; H. Liu; H. Jiang; L. Zhang; H. Mei","School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: jianglin17@bit.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, Beijing, Beijing China 100081 (e-mail: liuhui08@bit.edu.cn); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: hejiang@ieee.org); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: meihong@bit.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Code completion is to predict the rest of a statement a developer is typing. Although advanced code completion approaches have greatly improved the accuracy of code completion in modern IDEs, it remains challenging to predict project-specific API method invocations or field accesses because little knowledge about such elements could be learned in advance. To this end, in this paper we propose an accurate approach called HeeNAMA to suggesting the next project-specific API member access. HeeNAMA focuses on a specific but common case of code completion: suggesting the following member access whenever a project-specific API instance is followed by a dot on the right hand side of an assignment. By focusing on such a specific case, HeeNAMA can take full advantages of the context of the code completion, including the type of the left hand side expression of the assignment, the identifier on the left hand side, the type of the base instance, and similar assignments typed in before. All such information together enables highly accurate code completion. Given an incomplete assignment, HeeNAMA generates the initial candidate set according to the type of the base instance, and excludes those candidates that are not type compatible with the left hand side of the assignment. If the enclosing project contains assignments highly similar to the incomplete assignment, it makes suggestions based on such assignments. Otherwise, it selects the one from the initial candidate set that has the greatest lexical similarity with the left hand side of the assignment. Finally, it employs a neural network to filter out risky predictions, which guarantees high precision. Evaluation results on open-source applications suggest that compared to the state-of-the-art approaches and the state-of-the-practice tools HeeNAMA improves precision and recall by 70.68% and 25.23%, relatively.","1939-3520","","10.1109/TSE.2020.3017794","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9171589","Code Completion;Non-API;Deep Learning;Heuristic;LSTM","Hidden Markov models;Neural networks;Computational modeling;Open source software;Java;Data mining;Tools","","","","","","","","19 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Redundancy, Context, and Preference: An Empirical Study of Duplicate Pull Requests in OSS Projects","Z. Li; Y. Yu; M. Zhou; T. Wang; G. Yin; L. Lan; H. Wang","College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: lizhixing15@nudt.edu.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: yuyue@nudt.edu.cn); School of Electronics Engineering and Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: zhmh@pku.edu.cn); College of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: taowang2005@nudt.edu.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: yingang@nudt.edu.cn); AI Team, Peng Cheng Laboratory, Shenzhen, Guangdong China (e-mail: long.lan@pcl.ac.cn); Colledge of Computer, National University of Defense Technology, 58294 Changsha, Hunan China (e-mail: hmwang@nudt.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","OSS projects are being developed by globally distributed contributors, who often collaborate through the pull-based model today. While this model lowers the barrier to entry for OSS developers by synthesizing, automating and optimizing the contribution process, coordination among an increasing number of contributors remains as a challenge due to the asynchronous and self-organized nature of distributed development. In particular, duplicate contributions, where multiple different contributors unintentionally submit duplicate pull requests to achieve the same goal, are an elusive problem that may waste effort in automated testing, code review and software maintenance. While the issue of duplicate pull requests has been highlighted, to what extent duplicate pull requests affect the development in OSS communities has not been well investigated. In this paper, we conduct a mixed-approach study to bridge this gap. Based on a comprehensive dataset constructed from 26 popular GitHub projects, we obtain the following findings: (a) Duplicate pull requests result in redundant human and computing resources, exerting a significant impact on the contribution and evaluation process. (b) Contributors' inappropriate working patterns and the drawbacks of their collaborating environment might result in duplicate pull requests. (c) Compared to non-duplicate pull requests, duplicate pull requests have significantly different features, e.g., being submitted by inexperienced contributors, being fixing bugs, touching cold files, and solving tracked issues. (d) Integrators choosing between duplicate pull requests prefer to accept those with early submission time, accurate and high-quality implementation, broad coverage, test code, high maturity, deep discussion, and active response. Finally, actionable suggestions and implications are proposed for OSS practitioners.","1939-3520","","10.1109/TSE.2020.3018726","National Grand RD Plan; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9174755","Duplicate pull requests;pull-based development model;distributed collaboration;social coding","Collaboration;Computer bugs;Tools;Cloning;Synchronization;Testing;Encoding","","","","","","","","24 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Smart Greybox Fuzzing","V. Pham; M. Boehme; A. E. Santosa; A. R. Caciulescu; A. Roychoudhury","Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: thuanpv.nus@gmail.com); Faculty of Information Technology, Monash University, Clayton, Victoria Australia (e-mail: marcel.boehme@monash.edu); School of Information Technology, The University of Sydney, The University of Sydney, New South Wales Australia 2006 (e-mail: santosa_1999@yahoo.com); CS, Universitatea Politehnica din Bucuresti, 195061 Singapore, Bucharest Singapore (e-mail: alexandru.razvan.c@gmail.com); Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: abhik@comp.nus.edu.sg)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Coverage-based greybox fuzzing (CGF) is one of the most successful approaches for automated vulnerability detection. Given a seed file (as a sequence of bits), a CGF randomly flips, deletes or copies some bits to generate new files. CGF iteratively constructs (and fuzzes) a seed corpus by retaining those generated files which enhance coverage. However, random bitflips are unlikely to produce valid files (or valid chunks in files), for applications processing complex file formats. In this work, we introduce smart greybox fuzzing (SGF) which leverages a high-level structural representation of the seed file to generate new files. We define innovative mutation operators that work on the virtual file structure rather than on the bit level which allows SGF to explore completely new input domains while maintaining file validity. We introduce a novel validity-based power schedule that enables SGF to spend more time generating files that are more likely to pass the parsing stage of the program, which can expose vulnerabilities much deeper in the processing logic. Our evaluation demonstrates the effectiveness of SGF. On several libraries that parse complex chunk-based files, our tool AFLSMART achieves substantially more branch coverage (up to 87% improvement), and exposes more vulnerabilities than baseline AFL. Our tool AFLSMART has discovered 42 zero-day vulnerabilities in widely-used, well-tested tools and libraries; so far 17 CVEs were assigned.","1939-3520","","10.1109/TSE.2019.2941681","National Research Foundation Singapore; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8839290","vulnerability detection;smart fuzzing;automated testing;file format;grammar;input structure","Fuzzing;Computer bugs;Libraries;Tools;Dictionaries;Open area test sites;Schedules","","","","9","","","","16 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Probabilistic Preference Planning Problem for Markov Decision Processes","M. Li; A. Turrini; E. M. Hahn; Z. She; L. Zhang","School of Mathematics and System Sciences, Beihang University, 12633 Beijing, Beijing China (e-mail: meilun.li@buaa.edu.cn); State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing China (e-mail: turrini@ios.ac.cn); The School of Electronics, Electrical Engineering and Computer Science, Queen's University Belfast, 1596 Belfast, Belfast United Kingdom of Great Britain and Northern Ireland (e-mail: e.hahn@qub.ac.uk); School of Mathematics and Systems Science, Beihang University, 12633 Beijing, Beijing China (e-mail: zhikun.she@buaa.edu.cn); State Key Laboratory of Computer Science, Institute of Software Chinese Academy of Sciences, 53036 Beijing, Beijing China (e-mail: zhanglj@ios.ac.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The classical planning problem aims to find a sequence of permitted actions leading a system to a designed state, i.e., to achieve the system's task. However, in many realistic cases we also have requirements on how to complete the task, indicating that some behaviors and situations are more preferred than others. In this paper, we present the probabilistic preference-based planning problem (P4) for Markov decision processes, where the preferences are defined based on an enriched probabilistic LTL-style logic. We first recall P4Solver, an SMT-based planner computing the preferred plan by reducing the problem to a quadratic programming one previously developed to solve P4. To improve computational efficiency and scalability, we then introduce a new encoding of the probabilistic preference-based planning problem as a multi-objective model checking one, and propose the corresponding planner P4SolverMO. We illustrate the efficacy of both planners on some selected case studies to show that the model checking-based algorithm is considerably more efficient than the quadratic-programming-based one.","1939-3520","","10.1109/TSE.2020.3024215","National Natural Science Foundation of China; Natural Science Foundation of Beijing Municipality; Guangdong Science and Technology Department; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9197644","Planning;Markov Decision Processes;preference;quadratic programming;multi-objective model checking","Planning;Robots;Markov processes;Probabilistic logic;Model checking;Task analysis;Software","","","","","","","","15 Sep 2020","","","IEEE","IEEE Early Access Articles"
"An Empirical Study of C++ Vulnerabilities in Crowd-Sourced Code Examples","M. Verdi; A. Sami; J. Akhondali; F. Khomh; G. Uddin; A. Karami Motlagh","CSE and IT, Shiraz University, 37551 Shiraz, Fars Iran (the Islamic Republic of) (e-mail: m.verdi@shirazu.ac.ir); CSE and IT, Shiraz University, Shiraz, Fars Iran, Islamic Republic of 7134851154 (e-mail: sami@shirazu.ac.ir); CSE and IT, Shiraz University, 37551 Shiraz, Fars Iran (the Islamic Republic of) (e-mail: jafar.akhondali@yahoo.com); Electrical and Computer Engineering, Polytechnique Montral, 5596 Montreal, Quebec Canada (e-mail: foutse.khomh@polymtl.ca); Schulich School of Engineering, Electrical and Computer Engineering, University of Calgary, Calgary, Quebec Canada (e-mail: giasu@cs.mcgill.ca); CSE and IT, Shiraz University, 37551 Shiraz, Fars Iran (the Islamic Republic of) (e-mail: alireza.karami.m@gmail.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software developers share programming solutions in Q&A sites like Stack Overflow, Stack Exchange, Android forum, and so on. The reuse of crowd-sourced code snippets can facilitate rapid prototyping. However, recent research shows that the shared code snippets may be of low quality and can even contain vulnerabilities. This paper aims to understand the nature and the prevalence of security vulnerabilities in crowd-sourced code examples. To achieve this goal, we investigate security vulnerabilities in the C++ code snippets shared on Stack Overflow over a period of 10 years. In collaborative sessions involving multiple human coders, we manually assessed each code snippet for security vulnerabilities following CWE (Common Weakness Enumeration) guidelines. From the 72,483 reviewed code snippets used in at least one project hosted on GitHub, we found a total of 99 vulnerable code snippets categorized into31 types. Many of the investigated code snippets are still not corrected on Stack Overflow. The 99 vulnerable code snippets found in Stack Overflow were reused in a total of 2859 GitHub projects. To help improve the quality of code snippets shared on Stack Overflow,we developed a browser extension that allows Stack Overflow users to be notified for vulnerabilities in code snippets when they see them on the platform.","1939-3520","","10.1109/TSE.2020.3023664","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195034","Stack Overflow;Software Security;C++;SOTorrent;Vulnerability Migration;GitHub;Vulnerability Evolution","Security;C++ languages;Androids;Humanoid robots;Tools;Open source software","","","","","","","","11 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Integrating an Ensemble Surrogate Model's Estimation into Test data Generation","B. Sun; D. Gong; T. Tian; X. Yao","School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: baicaisun@gmail.com); School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: dwgong@vip.163.com); School of Computer Science and Technology, Shandong Jianzhu University, 105835 Jinan, Shandong China (e-mail: tian_tiantian@126.com); School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: yaoxj@cumt.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","For the path coverage testing of a Message-Passing Interface (MPI) program, test data generation based on an evolutionary optimization algorithm (EOA) has been widely known. However, during the use of the above technique, it is necessary to evaluate the fitness of each evolutionary individual by executing the program, which is generally computationally expensive. In order to reduce the computational cost, this paper proposes a method of integrating an ensemble surrogate model's estimation into the process of generating test data. The proposed method first produces a number of test inputs using an EOA, and forms a training set together with their real fitness. Then, this paper trains an ensemble surrogate model (ESM) based on the training set, which is employed to estimate the fitness of each individual. Finally, a small number of individuals with good estimations are selected to further execute the program, so as to have their real fitness for the subsequent evolution. This paper applies the proposed method to seven benchmark MPI programs, which is compared with several state-of-the-art approaches. The experimental results show that the proposed method can generate test data with significantly low computational cost.","1939-3520","","10.1109/TSE.2020.3019406","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9177064","MPI program;path coverage testing;evolutionary optimization algorithm;ensemble surrogate model;test data","Testing;Estimation;Data models;Optimization;Computational efficiency;Training;Sun","","","","","","","","25 Aug 2020","","","IEEE","IEEE Early Access Articles"
"The Relevance of Classic Fuzz Testing: Have We Solved This One?","B. Miller; M. Zhang; E. Heymann","Computer Sciences, University of Wisconsin-Madison, 5228 Madison, Wisconsin, United States, 53706 (e-mail: bart@cs.wisc.edu); Computer Sciences, University of Wisconsin-Madison, 5228 Madison, Wisconsin, United States, (e-mail: mzhang464@wisc.edu); Computer Sciences, University of Wisconsin-Madison, 5228 Madison, Wisconsin, United States, (e-mail: elisa@cs.wisc.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","As fuzz testing has passed its 30th anniversary, and in the face of the incredible progress in fuzz testing techniques and tools, the question arises if the classic, basic fuzz technique is still useful and applicable? In that tradition, we have updated the basic fuzz tools and testing scripts and applied them to a large collection of Unix utilities on Linux, FreeBSD, and MacOS. As before, our failure criteria was whether the program crashed or hung. We found that 9 crash or hang out of 74 utilities on Linux, 15 out of 78 utilities on FreeBSD, and 12 out of 76 utilities on MacOS. A total of 24 different utilities failed across the three platforms. We note that these failure rates are somewhat higher than our in previous 1995, 2000, and 2006 studies of the reliability of command line utilities. In the basic fuzz tradition, we debugged each failed utility and categorized the causes the failures. Classic categories of failures, such as pointer and array errors and not checking return codes, were still broadly present in the current results. In addition, we found a couple of new categories of failures appearing. We present examples of these failures to illustrate the programming practices that allowed them to happen. As a side note, we tested the limited number of utilities available in a modern programming language (Rust) and found them to be of no better reliability than the standard ones.","1939-3520","","10.1109/TSE.2020.3047766","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9309406","Testing and Debugging;Testing tools","Tools;Testing;Software;Operating systems;Fuzzing;Software reliability;Linux","","","","","","","IEEE","28 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Codee: A Tensor Embedding Scheme for Binary Code Search","J. Yang; C. Fu; X. -Y. Liu; H. Yin; P. Zhou","School of Cyber Science and Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei, China, (e-mail: d201780841@hust.edu.cn); School of Cyber Science and Engineering, Huazhong University of Science and Technology, Wu Han, Hu Bei Province, China, (e-mail: fucai@hust.edu.cn); Electrical Engineering, Columbia University, 5798 New York, New York, United States, (e-mail: xl2427@columbia.edu); Computer Science and Engineering, University of California Riverside Bourns College of Engineering, 117248 Riverside, California, United States, 92521-0144 (e-mail: heng@cs.ucr.edu); School of Electronic Information and Communications, Huazhong University of Science and Technology, wuhan, Hubei, China, (e-mail: panzhou@hust.edu.cn)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Given a target binary function, the binary code search retrieves top-K similar functions in the repository, and similar functions represent that they are compiled from the same source codes. Searching binary code is particularly challenging due to large variations of compiler tool-chains and options and CPU architectures, as well as thousands of binary codes. Furthermore, there are some pivotal issues in current binary code search schemes, including inaccurate text-based or token-based analysis, slow graph matching, or complex deep learning processes. In this paper, we present an unsupervised tensor embedding scheme, \textbf{Codee}, to carry out code search efficiently and accurately at the binary function level. First, we use an NLP-based neural network to generate the semantic-aware token embedding. Second, we propose an efficient basic block embedding generation algorithm based on the network representation learning model. We learn both the semantic information of instructions and the control flow structural information to generate the basic block embedding. Then we use all basic block embeddings in a function to obtain a variable-length function feature vector. Third, we build a tensor to generate function embeddings based on the tensor singular value decomposition, which compresses the variable-length vectors into short fixed-length vectors to facilitate efficient search afterward. We further propose a dynamic tensor compression algorithm to incrementally update the function embedding database. Finally, we use the local sensitive hash method to find the top-K similar matching functions in the repository. Compared with state-of-the-art cross-optimization-level code search schemes, such as Asm2Vec and DeepBinDiff, our scheme achieves higher average search accuracy, shorter feature vectors, and faster feature generation performance using four datasets, OpenSSL, Coreutils, libgmp and libcurl. Compared with other cross-platform and cross-optimization-level code search schemes, such as Gemini, Safe, the average recall of our method also outperforms others.","1939-3520","","10.1109/TSE.2021.3056139","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9345532","Function feature extraction;tensor embedding;code search;tSVD","Binary codes;Tensors;Feature extraction;Semantics;Search problems;Task analysis;Data models","","","","","","","IEEE","2 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Formal Equivalence Checking for Mobile Malware Detection and Family Classification","F. Mercaldo; A. Santone","IIT, Istituto di Informatica e Telematica Consiglio Nazionale delle Ricerche, 215080 Pisa, Italy, Italy, 56124 (e-mail: francesco.mercaldo@iit.cnr.it); Dipartimento di Bioscienze e Territorio, Universit del Molise, Pesche, Isernia, Italy, (e-mail: antonella.santone@unimol.it)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Several techniques to overcome the weaknesses of the current signature based detection approaches adopted by free and commercial anti-malware were proposed by industrial and research communities. These techniques are mainly supervised machine learning based, requiring optimal class balance to generate good predictive models. In this paper, we propose a method to infer mobile application maliciousness by detecting the belonging family, exploiting formal equivalence checking. We introduce a set of heuristics to reduce the number of mobile application comparisons and we define a metric reflecting the application maliciousness. Real-world experiments on 35 Android malware families (ranging from 2010 to 2018) confirm the effectiveness of the proposed method in mobile malware detection and family identification.","1939-3520","","10.1109/TSE.2021.3067061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9381654","Equivalence Checking;Formal Methods;Android;Malware;Security","Malware;Operating systems;Machine learning;Training;Tools;Smart phones;Automata","","","","","","","IEEE","18 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Generating Unit Tests for Documentation","M. Nassif; A. Hernandez; A. Sridharan; M. P. Robillard","School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: mnassif@cs.mcgill.ca); School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: alexa.hernandez@mail.mcgill.ca); School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: ashvitha.sridharan@mail.mcgill.ca); School of Computer Science, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: martin@cs.mcgill.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Software projects capture redundant information in various kinds of artifacts, as specifications from the source code are also tested and documented. Such redundancy provides an opportunity to reduce development effort by supporting the joint generation of different types of artifact. We introduce a tool-supported technique, called DScribe, that allows developers to combine unit tests and documentation templates, and to invoke those templates to generate documentation and unit tests. DScribe supports the detection and replacement of outdated documentation, and the use of templates can encourage extensive test suites with a consistent style. Our evaluation of 835 specifications revealed that 85% were not tested or correctly documented, and DScribe could be used to automatically generate 97% of the tests and documentation. An additional study revealed that tests generated by DScribe are more focused and readable than those written by human testers or generated by state-of-the-art automated techniques.","1939-3520","","10.1109/TSE.2021.3087087","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9447988","Code documentation;Testing;Testing tools;Test generation;Maintainability;Specification management","Documentation;Testing;Skeleton;Java;Software;Redundancy;Libraries","","","","","","","IEEE","7 Jun 2021","","","IEEE","IEEE Early Access Articles"
"CODIT: Code Editing with Tree-Based Neural Models","S. Chakraborty; Y. Ding; M. Allamanis; B. Ray","Computer Science, Columbia University, 5798 New York, New York United States (e-mail: saikatc@cs.columbia.edu); Computer Science, Columbia University, 5798 New York, New York United States (e-mail: yangruibo.ding@columbia.edu); Machine Intelligence and Perception, Microsoft Research Ltd, 10438 Cambridge, Cambridgeshire United Kingdom of Great Britain and Northern Ireland CB1 2FB (e-mail: miallama@microsoft.com); Computer Science, Columbia University, New York, New York United States (e-mail: rayb@cs.columbia.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The way developers edit day-to-day code tends to be repetitive, often using existing code elements. Many researchers have tried to automate repetitive code changes by learning from specific change templates which are applied to limited scope. The advancement of deep neural networks and the availability of vast open-source evolutionary data opens up the possibility of automatically learning those templates from the wild. However, deep neural network based modeling for code changes and code in general introduces some specific problems that needs specific attention from research community. For instance, compared to natural language, source code vocabulary can be significantly larger. Further, good changes in code do not break its syntactic structure. Thus, deploying state-of-the-art neural network models without adapting the methods to the source code domain yields sub-optimal results. To this end, we propose a novel tree-based neural network system to model source code changes and learn code change patterns from the wild. Specifically, we propose a tree-based neural machine translation model to learn the probability distribution of changes in code. We realize our model with a change suggestion engine, CODIT, and train the model with more than 30k real-world changes and evaluate it on 6k patches. Our evaluation shows the effectiveness of CODIT in learning and suggesting patches. CODIT can also learn specific bug fix pattern from bug fixing patches and can fix 27 bugs out of 75 one line bugs in Defects4J.","1939-3520","","10.1109/TSE.2020.3020502","NSF CNS; NSF CCF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9181462","","Computer bugs;Predictive models;Reactive power;Probability distribution;Syntactics;Neural networks;Adaptation models","","","","1","","","","31 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Eyes on Code: A Study on Developers Code Navigation Strategies","Z. Sharafi; I. Bertram; M. Flanagan; W. Weimer","Computer Science and Engineering, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: zohrehsh@umich.edu); Computer Science and Engineering, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: ianbtr@umich.edu); Computer Science and Engineering, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: mflanag@umich.edu); Computer Science and Engineering, University of Michigan, Ann Arbor, Michigan United States (e-mail: weimerw@umich.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","What code navigation strategies do developers use and what mechanisms do they employ to find relevant information Do their strategies evolve over the course of longer tasks Answers to these questions can provide insight to educators and software tool designers to support a wide variety of programmers as they tackle increasingly-complex software systems. However, little research to date has measured developers' code navigation strategies in ecologically-valid settings or analyzed how strategies progressed throughout a maintenance task. We propose a novel experimental design that more accurately represents the software maintenance process in terms of software complexity and IDE interactions. Using this framework, we conduct an eye-tracking study (n=36) of realistic bug-fixing tasks, dynamically and empirically identifying relevant code areas. We introduce a three-phase model to characterize developers' navigation behavior supported by statistical variations in eye movements over time. We also propose quantifiable notion of ``thrashing'' with the code as a navigation activity. We find that thrashing is associated with lower effectiveness. Our results confirm that the relevance of various code elements changes over time, and that our proposed three-phase model is capable of capturing these significant changes. We discuss our findings and their implications for tool designers, educators, and the research community.","1939-3520","","10.1109/TSE.2020.3032064","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9229106","Code navigation;Eye tracking;Human factors;Software maintenance","Navigation;Task analysis;Computer bugs;Tools;Maintenance engineering;Software;Switches","","","","","","","","19 Oct 2020","","","IEEE","IEEE Early Access Articles"
"Deprecation of packages and releases in software ecosystems: A case study on npm","F. R. Cogo; G. A. Oliva; A. E. Hassan","Centre for Software Excellence, Huawei Technologies Co Ltd Canada, 538302 Kingston, Ontario, Canada, (e-mail: filipe.cogo@gmail.com); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 2N8 (e-mail: golivax@gmail.com); School of Computing, Queen's University, Kingston, Ontario, Canada, K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Deprecation is used by developers to discourage the usage of certain features of a software system. Prior studies have focused on the deprecation of source code features, such as API methods. With the advent of software ecosystems, package managers started to allow developers to deprecate higher-level features, such as package releases. This study examines how the deprecation mechanism offered by the npm package manager is used to deprecate releases that are published in the ecosystem. We propose two research questions. In our first RQ, we examine how often package releases are deprecated in npm, ultimately revealing the importance of a deprecation mechanism to the package manager. We found that the proportion of packages that have at least one deprecated release is 3.7% and that 66% of such packages have deprecated all their releases, preventing client packages to migrate from a deprecated to a replacement release. Also, 31% of the partially deprecated packages do not have any replacement release. In addition, we investigate the content of the deprecation messages and identify five rationales behind the deprecation of releases, namely: withdrawal, supersession, defect, test, and incompatibility. In our second RQ, we examine how client packages adopt deprecated releases. We found that, at the time of our data collection, 27% of all client packages directly adopt at least one deprecated release and that 54% of all client packages transitively adopt at least one deprecated release. The direct adoption of deprecated releases is highly skewed, with the top 40 popular deprecated releases accounting for more than half of all deprecated releases adoption. As a discussion that derives from our findings, we highlight the rudimentary aspect of the deprecation mechanism employed by npm and recommend a set of improvements to this mechanism. These recommendations aim at supporting client packages in detecting deprecated releases, understanding their impact, and coping with them.","1939-3520","","10.1109/TSE.2021.3055123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9351569","Software ecosystem;Deprecation;Release deprecation;Dependency;npm;JavaScript;Nodejs","Ecosystems;Software;Semantics;Computer bugs;Software systems;Organizations;Optimized production technology","","","","","","","IEEE","9 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Vuln4Real: A Methodology for Counting Actually Vulnerable Dependencies","I. Pashchenko; H. Plate; S. E. Ponta; A. Sabetta; F. Massacci","Information Engineering and Computer Science, University of Trento, 19034 Trento, TN, Italy, (e-mail: ivan.pashchenko@unitn.it); SAP Security Research, SAP Labs France, Mougins, Alpes-Maritimes, France, 06250 (e-mail: henrik.plate@sap.com); SAP Security Research, SAP Labs France, MOUGINS CEDEX, PACA, France, (e-mail: serena.ponta@sap.com); SAP Security Research, SAP Labs France, Mougins, PACA, France, (e-mail: antonino.sabetta@sap.com); DISIl'Informazione, University of Trento, 19034 Trento, Trentino-Alto Adige, Italy, (e-mail: fabio.massacci@unitn.it)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Vulnerable dependencies are a known problem in today's free open-source software ecosystems because FOSS libraries are highly interconnected, and developers do not always update their dependencies. Our paper proposes Vuln4Real, the methodology for counting actually vulnerable dependencies, that addresses the over-inflation problem of academic and industrial approaches for reporting vulnerable dependencies in FOSS software, and therefore, caters to the needs of industrial practice for correct allocation of development and audit resources. To understand the industrial impact of a more precise methodology, we considered the 500 most popular FOSS Java libraries used by SAP in its own software. Our analysis included 25767 distinct library instances in Maven. We found that the proposed methodology has visible impacts on both ecosystem view and the individual library developer view of the situation of software dependencies: Vuln4Real significantly reduces the number of false alerts for deployed code (dependencies wrongly flagged as vulnerable), provides meaningful insights on the exposure to third-parties (and hence vulnerabilities) of a library, and automatically predicts when dependency maintenance starts lagging, so it may not receive updates for arising issues.","1939-3520","","10.1109/TSE.2020.3025443","H2020 LEIT Information and Communication Technologies; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201023","Vulnerable Dependency;Free Open Source Software;Mining Software Repositories","Libraries;Ecosystems;Security;Open source software;Java;Tools","","","","4","","","","21 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Automatic Detection, Validation and Repair of Race Conditions in Interrupt-Driven Embedded Software","Y. WANG; F. Gao; L. Wang; T. Yu; J. Zhao; X. Li","State Key Laboratory of Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: yuwang_cs@smail.nju.edu.cn); State Key Laboratory of Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: fjgao@smail.nju.edu.cn); State Key Laboratory of Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: lzwang@nju.edu.cn); Computer Science, University of Kentucky, Lexington, Kentucky United States 40506 (e-mail: tyu@cs.uky.edu); State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: zhaojh@nju.edu.cn); State Key Laboratory of Novel Software Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: lxd@nju.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Interrupt-driven programs are widely deployed in safety-critical embedded systems to perform hardware and resource dependent data operation tasks. The frequent use of interrupts in these systems can cause race conditions to occur due to interactions between application tasks and interrupt handlers (or two interrupt handlers). Numerous program analysis and testing techniques have been proposed to detect races in multithreaded programs. Little work, however, has addressed race condition problems related to hardware interrupts. In this paper, we present SDRacer, an automated framework that can detect, validate and repair race conditions in interrupt-driven embedded software. It uses a combination of static analysis and symbolic execution to generate input data for exercising the potential races. It then employs virtual platforms to dynamically validate these races by forcing the interrupts to occur at the potential racing points. Finally, it provides repair candidates to eliminate the detected races. We evaluate SDRacer on nine real-world embedded programs written in C language. The results show that SDRacer can precisely detect and successfully fix race conditions.","1939-3520","","10.1109/TSE.2020.2989171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072666","Embedded Software;Interrupts;Race Condition;Software Testing;Repair Suggestion","Task analysis;Maintenance engineering;Hardware;Embedded systems;Concurrent computing;Testing;Embedded software","","","","1","","","","20 Apr 2020","","","IEEE","IEEE Early Access Articles"
"A Systematical Study on Application Performance Management Libraries for Apps","Y. Tang; H. Wang; X. Zhan; X. Luo; Y. Zhou; H. Zhou; Q. Yan; Y. Sui; J. W. Keung","Department of Computing, ShanghaiTech University, 387433 Shanghai, Pudong, China, (e-mail: csytang@comp.polyu.edu.hk); School of Computer Science, Beijing University of Posts and Telecommunications, 12472 Beijing, Beijing, China, (e-mail: haoyuwang@bupt.edu.cn); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: chichoxian@gmail.com); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: csxluo@comp.polyu.edu.hk); Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China, (e-mail: yajin_zhou@zju.edu.cn); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong, Hong Kong, (e-mail: sunmoonsky0001@gmail.com); Computer Science and Engineering, Michigan State University, 3078 East Lansing, Michigan, United States, (e-mail: qyan@msu.edu); Faculty of Engineering and Information Technology, UTS, Sydney, New South Wales, Australia, (e-mail: yulei.sui@uts.edu.au); Department of Computer Science, City University of Hong Kong, Kowloon, Kowloon Tong, Hong Kong, KLN (e-mail: Jacky.Keung@cityu.edu.hk)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Being able to automatically detect the performance issues in apps will significantly improve their quality as well as having a positive influence on user satisfaction. Although app developers have been exploiting application performance management (APM)tools to capture these potential performance issues, most of them do not fully understand the internals of these APM tools and the effect on their apps, such as security risks, etc. To fill this gap, in this paper, we conduct the first systematic study on APMs for apps by scrutinizing 25 widely-used APMs for Android apps and develop a framework named APMHunter for exploring the usage of APMs inAndroid apps. Using APMHunter, we conduct a large-scale empirical study on 500,000 Android apps to explore the usage patterns ofAPMs and discover the potential misuses of APMs. We obtain two major findings: 1) some APMs still employ deprecated permissions and approaches, which leads to APM malfunction as expected; 2) inappropriate APMs utilization will cause privacy leakages. Thus, our study suggests that both APM vendors and developers should design and use APMs scrupulously","1939-3520","","10.1109/TSE.2021.3077654","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9424465","","","","","","","","","IEEE","5 May 2021","","","IEEE","IEEE Early Access Articles"
"XPro: a Model to Explain the Limited Adoption and Implementation of Experimentation in Software Startups","J. Melegati; H. Edison; X. Wang","Faculty of Computer Science, Free University of Bozen-Bolzano, 18956 Bolzano, BZ, Italy, (e-mail: jmelegatigoncalves@unibz.it); Business Information Systems, National University of Ireland Galway, 8799 Galway, Galway, Ireland, (e-mail: henry.edison@nuigalway.ie); Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Bozen-Bolzano, Italy, (e-mail: xiaofeng.wang@unibz.it)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software startups develop innovative, software-intensive products or services. Such innovativeness translates into uncertainty regarding a matching need for a product from potential customers, representing a possible determinant reason for startup failure. Research has shown that experimentation, an approach based on the use of experiments to guide several aspects of software development, could improve these companies' success rate by fostering the evaluation of assumptions about customers' needs before developing a full-fledged product. Nevertheless, software startups are not using experimentation as expected. In this study, we investigated the reasons behind such a mismatch between theory and practice. To achieve it, we performed a qualitative survey study of 106 failed software startups. We built the eXperimentation Progression model (XPro), demonstrating that the effective adoption and implementation of experimentation is a staged process: first, teams should be aware of experimentation, then they need to develop an intention to experiment, perform the experiments, analyze the results, and finally act based on the obtained learning. Based on the XPro model, we further identified 25 inhibitors that prevent a team from progressing along the stages properly. Our findings inform researchers of how to develop practices and techniques to improve experimentation adoption in software startups. Practitioners could learn various factors that could lead to their startup failure so they could take action to avoid them.","1939-3520","","10.1109/TSE.2020.3042610","Science Foundation Ireland; H2020 Marie Skłodowska-Curie Actions; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9282188","software startups;experimentation;experiment-driven software development;startups","Software;Business;Technological innovation;Companies;Inhibitors;Uncertainty;Testing","","","","","","","IEEE","4 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Inferring Bug Signatures to Detect Real Bugs","H. Zhong; X. Wang; H. Mei","Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China 200240 (e-mail: zhonghao@sjtu.edu.cn); Computer Science, University of Texas at San Antonio, San Antonio, Texas United States 78249 (e-mail: xiaoyin.wang@utsa.edu); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: meih@sjtu.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Due to the complexity and variety of programs, it is difficult to manually enumerate all bug patterns, especially for those related to API usages or project-specific rules. With the rapid development of software, many past bug fixes accumulate in software version histories. These bug fixes contain valuable samples of illegal coding practices. The gap between existing bug samples and well-defined bug patterns motivates our research. In the literature, researchers have explored techniques on learning bug signatures from existing bugs, and a bug signature is defined as a set of program elements explaining the cause/effect of the bug. However, due to various limitations, existing approaches cannot analyze past bug fixes in large scale, and to the best of our knowledge, no previously unknown bugs were ever reported by their work. The major challenge to automatically analyze past bug fixes is that, bug-inducing inputs are typically not recorded, and many bug fixes are partial programs that have compilation errors. As a result, for most bugs in the version history, it is infeasible to reproduce them for dynamic analysis or to feed buggy/fixed code directly into static analysis tools which mostly depend on compilable complete programs. In this paper, we propose an approach, called DEPA, that extracts bug signatures based on accurate partial-code analysis of bug fixes. With its support, we conduct the first large scale evaluation on 6,048 past bug fixes collected from four popular Apache projects. In particular, we use DEPA to infer bug signatures from these fixes, and to check the latest versions of the four projects with the inferred bug signatures. Our results show that DEPA detected 27 unique previously unknown bugs in total, including at least one bug from each project. These bugs are not detected by their developers nor other researchers. Among them, three of our reported bugs are already confirmed and repaired by their developers. Furthermore, our results show that the state-of-the-art tools detected only two of our found bugs, and our filtering techniques improve our precision from 25.5% to 51.5%.","1939-3520","","10.1109/TSE.2020.2996975","National Key RD Program of China; NSF SHF; HRD-C- SPECC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9099449","bug fix;bug signature;partial code analysis","Computer bugs;Tools;Benchmark testing;Software;Manuals;History;Sun","","","","1","","","","25 May 2020","","","IEEE","IEEE Early Access Articles"
"Engineering Impacts of Anonymous Author Code Review: A Field Experiment","E. Murphy-Hill; J. Dicker; M. M. Hodges; C. D. Egelman; C. Jaspan; L. Cheng; E. Kammer; B. Holtz; M. Jorde; A. Knight; C. Green","Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: emersonm@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: jdicker@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: hodgesm@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: cegelman@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: ciera@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: lancheng@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: eakammer@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: benholtz@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: majorde@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: aknight@google.com); Core Systems, Google Inc, 93176 Mountain View, California, United States, (e-mail: colling@google.com)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Code review is a powerful technique to ensure high quality software and spread knowledge of best coding practices between engineers. Unfortunately, code reviewers may have biases about authors of the code they are reviewing, which can lead to inequitable experiences and outcomes. In principle, anonymous author code review can reduce the impact of such biases by withholding an author's identity from a reviewer. In this paper, to understand the engineering effects of using author anonymous code review in a practical setting, we applied the technique to 5217 code reviews performed by 300 software engineers at Google. Our results suggest that during anonymous author code review, reviewers can frequently guess authors identities; that focus is reduced on reviewer-author power dynamics; and that the practice poses a barrier to offline, high-bandwidth conversations. Based on our findings, we recommend that those who choose to implement anonymous author code review should reveal the time zone of the author by default, have a break-the-glass option for revealing author identity, and reveal author identity directly after the review.","1939-3520","","10.1109/TSE.2021.3061527","Google; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9361116","code review;unbiasing","Internet;Browsers;Tools;Software development management;Software;Particle measurements;Licenses","","","","","","","CCBY","23 Feb 2021","","","IEEE","IEEE Early Access Articles"
"The Effect of Feature Characteristics on the Performance of Feature Location Techniques","A. Razzaq; A. Ventresque; R. Koschke; A. De Lucia; J. Buckley","LERO, University of Limerick, 8808 Limerick, limerick, Ireland, V94 T9PX (e-mail: abdul.razzaq@lero.ie); School of Computer Science, University College Dublin, 8797 Dublin, Dublin, Ireland, (e-mail: anthony.ventresque@ucd.ie); Arbeitsgruppe Softwaretechnik, University of Bremen, 9168 Bremen, Bremen, Germany, (e-mail: koschke@uni-bremen.de); Dipartimento di Matematica e Informatica, Universit di Salerno, Fisciano, Salerno, Italy, 84084 (e-mail: adelucia@unisa.it); CSIS, University of Limerick, Limerick, Limerick, Ireland, none (e-mail: jim.buckley@ul.ie)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Feature Location (FL) is a core software maintenance activity that aims to locate observable functionalities in the source code. Given its key role in software change, a vast array of Feature Location Techniques (FLTs) have been proposed but, as more and more FLTs are introduced, the selection of an appropriate FLT is an increasingly difficult problem. One consideration is the characteristics of the features being sought. For example, in the code associated with the feature, programmers may have named identifiers consistently, and with meaningful naming conventions, or not, and this may impact on the suitability of different FLTs. The suggestion that such characteristics matter has implicit support in the literature: An analysis of existing FLT empirical studies reveals that the system under study can often have a stronger impact on FLT performance than differing FLTs themselves. To understand this interaction between feature characteristics and FLTs better, this paper proposes a suite of feature-characteristic metrics that are hypothesized to control FLTs performance, holistically across FLTs and impacting on individual FLTs to different degrees. To evaluate the suite, a controlled experiment is performed, using 878 features, to probe the relationship between the metrics and the performance of four FTL techniques: three commonly-used techniques and one state-of-the-art technique. The evaluation is performed using four commonly used evaluation measures and extended by employing 41 other established source-code metrics as extraneous variables. Results of the empirical evaluation suggest that the feature-metric suite presented impacts FLT performance holistically, and impacts different FLTs to different degrees. Thus, this paper moves towards the more standard selection of appropriate FLTs, with respect to the prominent feature characteristics in the software systems under study, and more rigorous consideration of the features selected to compare FLTs.","1939-3520","","10.1109/TSE.2021.3049735","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9316225","Feature Location;Bug Localization;Software Maintenance;Software Recommendation;Software Characteristics","Measurement;Feature extraction;Software maintenance;Task analysis;Software systems;Gold;Standards","","","","","","","IEEE","6 Jan 2021","","","IEEE","IEEE Early Access Articles"
"Magnifier: A Compositional Analysis Approach for Autonomous Traffic Control","M. Bagheri; M. Sirjani; E. Khamespanah; C. Baier; A. Movaghar","Computer Engineering, Sharif University of Technology, 68260 Tehran, Tehran, Iran (the Islamic Republic of), (e-mail: mbagheri@ce.sharif.edu); School of Innovation, Design and Engineering, Malardalen University, Vsters, Vsters, Sweden, (e-mail: marjan.sirjani@mdh.se); School of Electrical and Computer Engineering, University of Tehran, 48425 Tehran, Tehran, Iran (the Islamic Republic of), (e-mail: e.khamespanah@ut.ac.ir); Computer Science, Technische Universitt Dresden, Dresden, Saxony, Germany, (e-mail: Christel.Baier@tu-dresden.de); Computer Engineering, Sharif University of Technology, Tehran, Tehran, Iran (the Islamic Republic of), 14588-89694 (e-mail: movaghar@sharif.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Autonomous traffic control systems are large-scale systems with critical goals. To satisfy expected properties, these systems adapt themselves to possible changes in their environment and in the system itself. The adaptation may result in further changes propagated throughout the system. For each change and its consequent adaptation, assuring the satisfaction of properties of the system at runtime is important. A prominent approach to assure the correct behavior of these systems is verification at runtime, which has strict time and memory limitations. To tackle these limitations, we propose Magnifier, an iterative, incremental, and compositional verification approach that operates on an actor-based model where actors are grouped in components, and components are augmented with a coordinator. The Magnifier idea is zooming on the area (component) affected by a change and verifying the correctness of properties of interest of the system after adapting the component to the change. Magnifier checks if the change is propagating, and if that is the case, then it zooms out to perform adaptation on a larger area to contain the change. The process is iterative and incremental, and considers areas affected by the change one by one. In Magnifier, we use the Coordinated Adaptive Actor model (CoodAA) for traffic control systems. We present a formal semantics for CoodAA as a network of Timed Input-Output Automata (TIOAs), and prove the correctness of our compositional reasoning. We implement our approach in Ptolemy II. The results of our experiments indicate that the proposed approach improves the verification time and the memory consumption compared to the non-compositional approach.","1939-3520","","10.1109/TSE.2021.3069192","Self-Adaptive Actors: SEADA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9388903","Self-adaptive Systems;Model@Runtime;Compositional Verification;Track-based Traffic Control Systems;Ptolemy II","Adaptation models;Control systems;Runtime;Tracking;Semantics;Iterative methods;Computer science","","","","","","","IEEE","29 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Quality of Automated Program Repair on Real-World Defects","M. Motwani; M. Soto; Y. Brun; R. Just; C. Le Goues","College of Information and Computer Sciences, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: mmotwani@cs.umass.edu); School of Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: msotogon@cs.cmu.edu); College of Information and Computer Sciences, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: brun@cs.umass.edu); Paul G. Allen School of Computer Science & Engineering, University of Washington, 7284 Seattle, Washington United States (e-mail: rjust@cs.washington.edu); School of Computer Science, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: clegoues@cs.cmu.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Automated program repair is a promising approach to reducing the costs of manual debugging and increasing software quality. However, recent studies have shown that automated program repair techniques can be prone to producing patches of low quality, overfitting to the set of tests provided to the repair technique, and failing to generalize to the intended specification. This paper rigorously explores this phenomenon on real-world Java programs, analyzing the effectiveness of four well-known repair techniques, GenProg, Par, SimFix, and TrpAutoRepair, on defects made by the projects' developers during their regular development process. We find that: (1) When applied to real-world Java code, automated program repair techniques produce patches for between 10.6% and 19.0% of the defects, which is less frequent than when applied to C code. (2) The produced patches often overfit to the provided test suite, with only between 13.8% and 46.1% of the patches passing an independent set of tests. (3) Test suite size has an extremely small but significant effect on the quality of the patches, with larger test suites producing higher-quality patches, though, surprisingly, higher-coverage test suites correlate with lower-quality patches. (4) The number of tests that a buggy program fails has a small but statistically significant positive effect on the quality of the produced patches. (5) Test suite provenance, whether the test suite is written by a human or automatically generated, has a significant effect on the quality of the patches, with developer-written tests typically producing higher-quality patches. And (6) the patches exhibit insufficient diversity to improve quality through some method of combining multiple patches. We develop JaRFly, an open-source framework for implementing techniques for automatic search-based improvement of Java programs. Our study uses JaRFly to faithfully reimplement GenProg and TrpAutoRepair to work on Java code, and makes the first public release of an implementation of Par. Unlike prior work, our study carefully controls for confounding factors and produces a methodology, as well as a dataset of automatically-generated test suites, for objectively evaluating the quality of Java repair techniques on real-world defects.","1939-3520","","10.1109/TSE.2020.2998785","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9104918","Automated program repair;patch quality;objective quality measure;Java;GenProg;Par;TrpAutoRepair;Defects4J","Maintenance engineering;Java;Contracts;Manuals;Diversity reception;Inspection;Software quality","","","","1","","","","1 Jun 2020","","","IEEE","IEEE Early Access Articles"
"A Survey on Adaptive Random Testing","R. Huang; W. Sun; Y. Xu; H. Chen; D. Towey; X. Xia","Jiangsu Key Laboratory of Security Technology for Industrial Cyberspace, Jiangsu University, 12676 Zhenjiang, Jiangsu China (e-mail: rbhuang@ujs.edu.cn); School of Computer Science and Communication Engineering, Jiangsu University, Zhenjiang, Jiangsu China (e-mail: 3140608036@stmail.ujs.edu.cn); School of Computer Science and Communication Engineering, Jiangsu Univeristy, Zhenjiang, Jiangsu China (e-mail: 1361570668@qq.com); School of Computer Science and Communication Engineering, Jiangsu Univeristy, Zhenjiang, Jiangsu China (e-mail: 1048953124@qq.com); Division of Computer Science, University of Nottingham Ningbo China, Ningbo, Zhejiang China 315100 (e-mail: dave.towey@nottingham.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Random testing (RT) is a well-studied testing method that has been widely applied to the testing of many applications, including embedded software systems, SQL database systems, and Android applications. Adaptive random testing (ART) aims to enhance RT's failure-detection ability by more evenly spreading the test cases over the input domain. Since its introduction in 2001, there have been many contributions to the development of ART, including various approaches, implementations, assessment and evaluation methods, and applications. This paper provides a comprehensive survey on ART, classifying techniques, summarizing application areas, and analyzing experimental evaluations. This paper also addresses some misconceptions about ART, and identifies open research challenges to be further investigated in the future work.","1939-3520","","10.1109/TSE.2019.2942921","National Natural Science Foundation of China; China Postdoctoral Science Foundation; Young Backbone Teacher Cultivation Project of Jiangsu University; Senior Personnel Scientific Research Foundation of Jiangsu University; Postgraduate Research and Practice Innovation Program of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8846002","Adaptive random testing;random testing;survey","Subspace constraints;Testing;Libraries;Software;Power capacitors;Strips;Art","","","","5","","","","23 Sep 2019","","","IEEE","IEEE Early Access Articles"
"SOSRepair: Expressive Semantic Search for Real-World Program Repair","A. Afzal; M. Motwani; K. Stolee; Y. Brun; C. Le Goues","Institute for Software Research, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: afsoona@cs.cmu.edu); College of Information and Computer Science, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: mmotwani@cs.umass.edu); Computer Science, North Carolina State University, Raleigh, North Carolina United States 27695-8206 (e-mail: ktstolee@ncsu.edu); College of Information and Computer Science, University of Massachusetts Amherst, 14707 Amherst, Massachusetts United States (e-mail: brun@cs.umass.edu); Institue for Software Research, Carnegie Mellon University, Pittsburgh, Pennsylvania United States 15213 (e-mail: clegoues@cs.cmu.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Automated program repair holds the potential to significantly reduce software maintenance effort and cost. However, recent studies have shown that it often produces low-quality patches that repair some but break other functionality. We hypothesize that producing patches by replacing likely faulty regions of code with semantically-similar code fragments, and doing so at a higher level of granularity than prior approaches can better capture abstraction and the intended specification, and can improve repair quality. We create SOSRepair, an automated program repair technique that uses semantic code search to replace candidate buggy code regions with behaviorally-similar (but not identical) code written by humans. SOSRepair is the first such technique to scale to real-world defects in real-world systems. On a subset of the ManyBugs benchmark of such defects, SOSRepair produces patches for 22 (34%) of the 65 defects, including 3, 5, and 6 defects for which previous state-of-the-art techniques Angelix, Prophet, and GenProg do not, respectively. On these 22 defects, SOSRepair produces more patches (9, 41%) that pass all independent tests than the prior techniques. We demonstrate a relationship between patch granularity and the ability to produce patches that pass all independent tests. We then show that fault localization precision is a key factor in SOSRepair's success. Manually improving fault localization allows SOSRepair to patch 23 (35%) defects, of which 16 (70%) pass all independent tests. We conclude that (1) higher-granularity, semantic-based patches can improve patch quality, (2) semantic search is promising for producing high-quality real-world defect repairs, (3) research in fault localization can significantly improve the quality of program repair techniques, and (4) semi-automated approaches in which developers suggest fix locations may produce high-quality patches.","1939-3520","","10.1109/TSE.2019.2944914","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8854217","Automated program repair;semantic code search;patch quality;program repair quality;SOSRepair","Maintenance engineering;Semantic search;Encoding;Benchmark testing;Computer bugs;Software","","","","2","","","","1 Oct 2019","","","IEEE","IEEE Early Access Articles"
"CloudRaid: Detecting Distributed Concurrency Bugs via Log-Mining and Enhancement","J. Lu; C. Liu; F. Li; L. Li; X. Feng; J. Xue","State Key Laboratories of Computer Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: lujie@ict.ac.cn); State Key Laboratories of Computer Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: liuchen17z@ict.ac.cn); Key Laboratory of Network Assessment Technology, Chinese Academy of Sciences, Beijing Key Laboratory of Network Security and Protection Technology, Institute of Information Engineering Chinese Academy of Sciences, 306628 Beijing, Beijing China (e-mail: lifeng@iie.ac.cn); State Key Laboratories of Computer Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: lianli@Ict.ac.cn); Key Lab. of Computer System and Architecture, Institute of Computing Technology Chinese Academy of Sciences, 53035 Beijing, Beijing China (e-mail: fxb@ict.ac.cn); School of Computer Science and Engineering, University of New South Wales, 7800 Sydney, New South Wales Australia (e-mail: j.xue@unsw.edu.au)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Cloud systems suffer from distributed concurrency bugs, which often lead to data loss and service outage. This paper presents CLOUDRAID, a new automatical tool for finding distributed concurrency bugs efficiently and effectively. Distributed concurrency bugs are notoriously difficult to find as they are triggered by untimely interaction among nodes, i.e., unexpected message orderings. To detect concurrency bugs in cloud systems efficiently and effectively, CLOUDRAID analyzes and tests automatically only the message orderings that are likely to expose errors. Specifically, CLOUDRAID mines the logs from previous executions to uncover the message orderings that are feasible but inadequately tested. In addition, we also propose a log enhancing technique to introduce new logs automatically in the system being tested. These extra logs added improve further the effectiveness of CLOUDRAID without introducing any noticeable performance overhead. Our log-based approach makes it well-suited for live systems. We have applied CLOUDRAID to analyze six representative distributed systems: Apache Hadoop2/Yarn, HBase, HDFS, Cassandra, Zookeeper, and Flink. CLOUDRAID has succeeded in testing 60 different versions of these six systems (10 versions per system) in 35 hours, uncovering 31 concurrency bugs, including nine new bugs that have never been reported before. For these nine new bugs detected, which have all been confirmed by their original developers, three are critical and have already been fixed.","1939-3520","","10.1109/TSE.2020.2999364","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9106854","Distributed Systems;Concurrency Bugs;Bug Detection;Cloud Computing","Computer bugs;Concurrent computing;Cloud computing;Task analysis;Runtime;Message systems;Tools","","","","","","","","2 Jun 2020","","","IEEE","IEEE Early Access Articles"
"One-Click Formal Methods","J. Backes; P. Bolignano; B. Cook; A. Gacek; K. S. Luckow; N. Rungta; M. Schaef; C. Schlesinger; R. Tanash; C. Varming; M. Whalen","Inspector, Amazon Web Services, United States; Software Engineering, Amazon Web Services, United States; University College London, United Kingdom; Automated Reasoning, Amazon Web Services, United States; Automated Reasoning, Amazon Web Services, United States; Formal Services, Amazon Web Services, United States; Software Engineering, Amazon Web Services, United States; Applied Science, Amazon Web Services, United States; Amazon Security Hub, Amazon Web Services, United States; Automated Reasoning, Amazon Web Services, United States; Proof Platforms, Amazon Web Services, United States","IEEE Software","22 Oct 2019","2019","36","6","61","65","Formal methods are mathematically based approaches for specifying, building, and reasoning about software. Despite 50 years of research and development, formal methods have had only limited impact in industry. While we have seen success in such domains as microprocessor design and aerospace (e.g., proofs of security properties for helicopter control systems1), we have not seen wide adoption of formal methods for large and complex systems, such as web services, industrial automation, or enterprise support software.","1937-4194","","10.1109/MS.2019.2930609","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880058","","Cloud computing;Software tools;Databases;Cognition;Web services;Access control","formal specification;reasoning about programs","one-click formal methods;microprocessor design;Web services;industrial automation;enterprise support software","","4","","4","","22 Oct 2019","","","IEEE","IEEE Magazines"
"Gender Diversity and Community Smells: Insights From the Trenches","G. Catolino; F. Palomba; D. A. Tamburri; A. Serebrenik; F. Ferrucci","University of Salerno, Italy; Software Engineering, University of Salerno, Italy; Jheronimus Academy of Data Science, The Netherlands; Software Evolution, Eindhoven University of Technology, Eindhoven, The Netherlands; Software Engineering, University of Salerno, Italy","IEEE Software","20 Dec 2019","2020","37","1","10","16","Given growing attention to gender diversity in software development teams, we asked practitioners if it was a useful tool to mitigate undesirable communication patterns. While many participants didn't consider gender diversity useful in this context, those who did were motivated by their own professional experience.","1937-4194","","10.1109/MS.2019.2944594","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8852638","Gender Diversity;Survey;Community Smell","Software development management;Gender issues","gender issues;software development management;team working","community smells;gender diversity;communication patterns;software development teams","","2","","16","","30 Sep 2019","","","IEEE","IEEE Magazines"
"Metamorphic Robustness Testing: Exposing Hidden Defects in Citation Statistics and Journal Impact Factors","Z. Q. Zhou; T. H. Tse; M. Witheridge","School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: zhiquan@uow.edu.au); Department of Computer Science, The University of Hong Kong, Hong Kong, Hong Kong Hong Kong Hong Kong (e-mail: thtse@cs.hku.hk); School of Computing and Information Technology, University of Wollongong, Wollongong, New South Wales Australia (e-mail: mw204@uowmail.edu.au)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","We propose a robustness testing approach for software systems that process large amounts of data. Our method uses metamorphic relations to check software output for erroneous input in the absence of a tangible test oracle. We use this technique to test two major citation database systems: Scopus and the Web of Science. We report a surprising finding that the inclusion of hyphens in paper titles impedes citation counts, and that this is a result of the lack of robustness of the citation database systems in handling hyphenated paper titles. Our results are valid for the entire literature as well as for individual fields such as chemistry. We further find a strong and significant negative correlation between the journal impact factor (JIF) of IEEE Transactions on Software Engineering (TSE) and the percentage of hyphenated paper titles published in TSE. Similar results are found for ACM Transactions on Software Engineering and Methodology. A software engineering field-wide study reveals that the higher JIF-ranked journals are publishing a lower percentage of papers with hyphenated titles. Our results challenge the common belief that citation counts and JIFs are reliable measures of the impact of papers and journals, as they can be distorted simply by the presence of hyphens in paper titles.","1939-3520","","10.1109/TSE.2019.2915065","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708940","Metamorphic robustness testing;metamorphic testing;negative testing;fault-based testing;software robustness;oracle problem;citation count;journal impact factor;Scopus;Web of Science;Google Scholar;verification and validation","Robustness;Database systems;Software;Fuzzing;Google","","","","2","","","","7 May 2019","","","IEEE","IEEE Early Access Articles"
"Evaluating Essential and Accidental Code Complexity Triggers by Practitioners’ Perception","V. Antinyan","Software Quality, Volvo Cars, Gothenburg, Sweden","IEEE Software","23 Oct 2020","2020","37","6","86","93","Code complexity determines the difficulty of understanding code. Survey results show that many elements influence complexity, most of which are accidental and can be removed. Meanwhile, several elements captured by the traditional complexity metrics have a small influence on complexity. Code complexity has been one of the most researched subjects in software engineering and one of the most measured properties of software.","1937-4194","","10.1109/MS.2020.2976072","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9007382","Code complexity;software metrics;code quality;maintainability;code readability","Complexity theory;Bars;Software;Task analysis;Software measurement;Software engineering","software maintenance;software metrics","code complexity;complexity metrics;software engineering","","","","17","","24 Feb 2020","","","IEEE","IEEE Magazines"
"Validation of Autonomous Systems","C. Ebert; M. Weyrich","Vector Consulting Services; Industrial Automation and Software Engineering, University of Stuttgart, Germany","IEEE Software","15 Aug 2019","2019","36","5","15","23","Society today depends on autonomous systems, such as intelligent service systems, self-driving trains, and remote surgeries.1 The ultimate validation of the Turing test is that we often do not recognize autonomous systems. This growing usage poses many challenges, such as how to provide transparency, which rules or learning patterns are applied in a complex situation, and if these rules are the right ones. Validation is the key challenge, of which we will provide an overview in this article.","1937-4194","","10.1109/MS.2019.2921037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802868","","Autonomous systems;Software engineering;Intelligent systems;Safety;Computational modeling;Performance evaluation","artificial intelligence","autonomous systems;Turing test validation","","1","","7","","15 Aug 2019","","","IEEE","IEEE Magazines"
"Relationships Between Project Size, Agile Practices, and Successful Software Development: Results and Analysis","M. Jorgensen","IT Management, SimulaMet, Oslo, Norway","IEEE Software","21 Feb 2019","2019","36","2","39","43","Large-scale software development succeeds more often when using agile methods. Flexible scope, frequent deliveries to production, a high degree of requirement changes and more competent providers are possible reasons.","1937-4194","","10.1109/MS.2018.2884863","Prosjekt Norge; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648276","","Software development management;Contracts;Frequency measurement;Project management;Organizations;Data collection","project management;software development management;software engineering;software prototyping","successful software development;large-scale software development;agile methods;flexible scope;frequent deliveries;requirement changes;project size;agile practices","","8","","6","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Successfully Governing Software Ecosystems: Competence Profiles of Partnership Managers","T. Kude; T. Huber; J. Dibbern","ESSEC Business School, France; ESSEC Business School; Information Systems, University of Bern, Switzerland","IEEE Software","16 Apr 2019","2019","36","3","39","44","The emergence of software platforms and ecosystems has led platform owners to create the role of the partnership manager. However, it is unclear what the required competences for this new role are. We derive two competence profiles of partnership managers.","1937-4194","","10.1109/MS.2018.2874553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501932","Software ecosystems;partnership manager;competence profile;platform governance;arm’s length governance;dyadic governance","Ecosystems;Software development management;Collaboration;Engineering management","software engineering","competence profiles;software ecosystems;partnership managers","","","","14","","21 Oct 2018","","","IEEE","IEEE Magazines"
"Building Resource Adaptive Software Systems","S. Neema; R. Parikh; S. Jagannathan","Information Innovation Office, Defense Advanced Research Projects Agency, Arlington, Virginia United States; Information Innovation Office, Defense Advanced Research Projects Agency, Arlington, Virginia United States; Computer Science, Purdue University, West Lafayette, Indiana 47906 United States","IEEE Software","21 Feb 2019","2019","36","2","103","109","The Defense Advanced Research Projects Agency (DARPA) Building Resource Adaptive Software Systems (BRASS) program is an ambitious effort to improve the resilience and longevity of complex software systems. Its vision seeks a principled integration of adaptive reasoning into all aspects of the software design cycle.","1937-4194","","10.1109/MS.2018.2886831","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648261","","Ecosystems;Software systems;Biological system modeling;Adaptive systems;Computer architecture","software architecture;software engineering","Defense Advanced Research Projects Agency Building Resource Adaptive Software Systems program;complex software systems;adaptive reasoning;software design cycle;DARPA;BRASS","","1","","9","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Gender Differences in Public Code Contributions: A 50-Year Perspective","S. Zacchiroli","Computer Science, Universite de Paris, Paris, 75013, France","IEEE Software","15 Feb 2021","2021","38","2","45","50","We study the gender of commits authors over 120 million projects and a period of 50 years. Commits by female authors remain low overall but are growing steadily, providing hope of a more gender-balanced future for collaborative software development.","1937-4194","","10.1109/MS.2020.3038765","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9261329","","Gender issues;Market research;Electric breakdown;Statistics;Software development management;Sociology","gender issues;groupware;software engineering","gender differences;public code contributions;female authors;gender-balanced future;collaborative software development","","2","","15","IEEE","17 Nov 2020","","","IEEE","IEEE Magazines"
"Dual-Track Development","T. Sedano; P. Ralph; C. Peraire","VMware, Inc., Palo Alto, California United States; Computer Science, Dalhousie University, Halifax, Nova Scotia, Canada; Electrical and Computer Engineering, Carnegie Mellon University, Moffett Field, California United States","IEEE Software","23 Oct 2020","2020","37","6","58","64","The best way to design good products (human-centered design) assumes a ""waterfall"" process, which is incompatible with agile methods.","1937-4194","","10.1109/MS.2020.3013274","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9152985","","Buildings;Stakeholders;Usability;Encoding;Interviews","software engineering;user centred design","dual-track development;human-centered design;software product design;waterfall process","","","","15","IEEE","31 Jul 2020","","","IEEE","IEEE Magazines"
"The Impact of Software on Eyecare in India","V. Venkataswamy; B. Seetharam",Drishti; Drishti,"IEEE Software","19 Jun 2020","2020","37","4","99","106","India has a population of 1.3 billion. Over the last decade, it has had record economic growth and reductions in poverty and infant mortality as well as an increase in life expectancy. India has managed to build industries in the areas of pharmaceutical and biotechnology manufacturing and software products with services. India is mostly rural, with more than 65-70% of its population living in vast hinterlands. The need to deliver health-care services in the last mile of every village and to every citizen is a challenge. Of the 1.2 million healthcare workers, 59.2%1 serve 27.8% of the urban population, whereas 40.8% of health-care workers serve 72.2% of the rural population.","1937-4194","","10.1109/MS.2020.2985789","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121628","","Power transmission lines;Ice thickness;Temperature sensors;Bragg gratings;Transmission line measurements;Monitoring","biotechnology;eye;health care;software engineering","India;economic growth;infant mortality;biotechnology manufacturing;software products;health-care services;urban population;rural population;software impact;eyecare","","1","","5","","19 Jun 2020","","","IEEE","IEEE Magazines"
"Analyzing and Managing Complex Software Ecosystems: A Framework to Understand Value in Information Systems","W. Vorraber; M. Mueller; S. Voessner; W. Slany","Engineering and Business Informatics, Graz University of Technology; Software Technology, Graz University of Technology; Engineering and Business Informatics, Graz University of Technology; Software Technology, Graz University of Technology","IEEE Software","16 Apr 2019","2019","36","3","55","60","Managing complex software ecosystems, such as free open source software projects, is crucial for software-producing organizations. We present a framework that helps visualize complex ecosystem settings, gain insights on value engines, and describe relationships between the ecosystem partners.","1937-4194","","10.1109/MS.2018.290100810","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8409423","services computing;enterprise modeling and management;general;dynamics of services ecosystem;computing milieux;management of computing and information systems;project and people management","Ecosystems;Visualization;Software development management;Object recognition;Stakeholders","information systems;public domain software;software engineering","complex software ecosystems;free open source software projects;software-producing organizations;information systems","","","","15","","10 Jul 2018","","","IEEE","IEEE Magazines"
"Controlling the Controllers: What Software People Can Learn From Control Theory","B. Selic","Malina Software Corp., Canada","IEEE Software","23 Oct 2020","2020","37","6","99","103","The author states that AUDIT was an embarrassing admission of defeat, reflecting a development team resigned to the poor quality of their code. It dawned on him much later that the AUDIT program was simply an example of the very ancient feedback control loop pattern. In his experience, there is little awareness of the importance and complexity of the task of controlling software among software developers.","1937-4194","","10.1109/MS.2020.3006970","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238664","","Control theory;Computer bugs;Feedback control;Control systems;Force;Software systems","software engineering","software people;control theory;AUDIT program;software control;software developers;feedback control loop pattern","","","","6","","23 Oct 2020","","","IEEE","IEEE Magazines"
"Information Needs: Lessons for Programming Tools","T. D. LaToza","Computer Science, George Mason University, Fairfax, Virginia United States","IEEE Software","23 Oct 2020","2020","37","6","52","57","Why is programming sometimes so frustrating and annoying and other times so fast and painless? This article surveys a few of the important lessons emerging from studies of programming and the new programming tools they motivate.","1937-4194","","10.1109/MS.2020.3014343","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9157879","","Tools;Programming profession;Navigation;Task analysis;Debugging;Psychology","computer science education;information needs;software engineering","programming tools;frustrating times;annoying times;important lessons;information needs","","","","14","","4 Aug 2020","","","IEEE","IEEE Magazines"
"Highlights from ICSE 2019: Software Security and Mobile App Energy Consumption","J. C. Carver; L. L. Minku","Computer Science, University of Alabama; Computer Science, University of Birmingham","IEEE Software","15 Aug 2019","2019","36","5","29","31","This issue's ""Practitioners' Digest"" department reports on the 2019 International Conference on Software Engineering (ICSE). We focus on two emerging themes: security and energy issues for mobile apps. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in this article, please send me and the author(s) of the article a note about your experiences.","1937-4194","","10.1109/MS.2019.2922457","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802626","","Computer security;Energy consumption;Energy management;Software testing;Software engineering","","","","","","6","","15 Aug 2019","","","IEEE","IEEE Magazines"
"From Monolithic to Microservices: An Experience Report from the Banking Domain","A. Bucchiarone; N. Dragoni; S. Dustdar; S. T. Larsen; M. Mazzara",Fondazione Bruno Kessler; Technical University of Denmark and Örebro University; TU Wien; Danske Bank; Innopolis University,"IEEE Software","4 May 2018","2018","35","3","50","55","Microservices have seen their popularity blossoming with an explosion of concrete applications in real-life software. Several companies are currently involved in a major refactoring of their back-end systems in order to improve scalability. This article presents an experience report of a real-world case study, from the banking domain, in order to demonstrate how scalability is positively affected by reimplementing a monolithic architecture into microservices. The case study is based on the FX Core system for converting from one currency to another. FX Core is a mission-critical system of Danske Bank, the largest bank in Denmark and one of the leading financial institutions in Northern Europe.","1937-4194","","10.1109/MS.2018.2141026","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354415","microservices;software architecture;scalability;software development;software engineering;Danske Bank;FX Core","Computer architecture;Service computing;Service-oriented architecture;Databases;Banking;Software development","bank data processing;software architecture","banking domain;microservices;concrete applications;real-life software;refactoring;back-end systems;scalability;monolithic architecture;FX Core system;mission-critical system;Danske Bank;Northern Europe","","15","1","13","","4 May 2018","","","IEEE","IEEE Magazines"
"A Taxonomy of IoT Client Architectures","A. Taivalsaari; T. Mikkonen",Nokia Technologies; University of Helsinki,"IEEE Software","4 May 2018","2018","35","3","83","88","This article defines a taxonomy of software architecture options, derived from industry projects, for Internet of Things (IoT) devices, from the most limited sensing devices to high-end devices featuring fully fledged OSs and developer frameworks. A plethora of architecture options exists for IoT devices, offering very different levels of software development capabilities. These capabilities can significantly affect IoT systems' end-to-end architecture and topology.","1937-4194","","10.1109/MS.2018.2141019","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354417","IoT;Internet of Things;IoT devices;Programmable World;software architecture;software platforms;RTOS;real-time operating systems;software engineering;software development","Computer architecture;Random access memory;Internet of Things;Cloud computing;Taxonomy","Internet of Things;service-oriented architecture;software architecture","taxonomy;IoT client architectures;software architecture options;sensing devices;high-end devices;IoT devices;software development capabilities;IoT systems;Internet of Things devices;fully-fledged OS","","7","","8","","4 May 2018","","","IEEE","IEEE Magazines"
"A Cambrian Explosion of DevOps Tools","M. Kersten",Tasktop,"IEEE Software","12 Mar 2018","2018","35","2","14","17","Specialization, and the resulting tool diversity, is a fundamental aspect of the modern DevOps toolchain. How does this affect the value stream architecture?","1937-4194","","10.1109/MS.2018.1661330","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314153","agile software development;DevOps;DevOps tools;value stream architecture;software development;software engineering","Software tools;Software development management;Task analysis","project management;software development management","resulting tool diversity;modern DevOps toolchain;Cambrian Explosion;value stream architecture","","3","","3","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Microservices","X. Larrucea; I. Santamaria; R. Colomo-Palacios; C. Ebert",Tecnalia; Tecnalia; Østfold University College; Vector Consulting Services,"IEEE Software","4 May 2018","2018","35","3","96","100","Microservices are small applications with a single responsibility that can be deployed, scaled, and tested independently. They're gaining momentum across industries to facilitate agile delivery mechanisms for service-oriented architecture and to migrate function-oriented legacy architectures toward highly flexible service orientation. This article presents a brief overview of microservice technologies and how to migrate to them.","1937-4194","","10.1109/MS.2018.2141030","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354423","microservices;Cross-Origin Resource Sharing;CORS;software development;software engineering;Software Technology","Software development;Service computing;Computer architecture;Browsers;Java","service-oriented architecture;Web services","agile delivery mechanisms;function-oriented legacy architectures;microservice technologies;flexible service orientation;service-oriented architecture","","6","","6","","4 May 2018","","","IEEE","IEEE Magazines"
"Curve Balls","G. J. Holzmann",Nimble Research,"IEEE Software","12 Mar 2018","2018","35","2","18","21","When can we stop testing software, and when is it okay to skip tests? The answers might not be obvious.","1937-4194","","10.1109/MS.2018.1661321","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314157","software testing;software defects;S-curve;unit tests;software development;software engineering;Reliable Code","Software testing;Computer bugs;Software systems;Software reliability","program testing;software quality","curve balls;software testing","","","","2","","12 Mar 2018","","","IEEE","IEEE Magazines"
"“It Depends”: Heuristics for Common-Enough Requirements Practice","S. Gregory",Intel Corporation,"IEEE Software","6 Jul 2018","2018","35","4","12","15","How much diversity is permissible in requirements practices in a large corporation? Can different project teams legitimately use different elicitation methods, specification techniques, standards and checklists for reviews, and databases to manage content? Or is allowing any difference at all only inviting trouble? This instalment of the Requirements department shares how requirements specialists at Intel approach these questions through training, with a few examples of what they teach to better enable individuals and teams to continually improve their requirements engineering (RE) practice. It also discusses why practitioner engagement with the broader RE community is critical.","1937-4194","","10.1109/MS.2018.2801551","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405628","software requirements;requirements engineering;heuristics;software development;software engineering;Requirements","Teamwork;Collaboration;Engineering management;Requirements engineering;Problem-solving","formal specification;systems analysis","common-enough requirements practice;specification techniques;requirements specialists;requirements engineering practice;elicitation methods;requirements department","","","","4","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Agility, Risk, and Uncertainty, Part 2: How Risk Impacts Agile Architecture","M. Waterman",Specialised Architecture Services,"IEEE Software","4 May 2018","2018","35","3","18","19","The amount of technical risk (and the underlying uncertainty) in a software development project can affect the amount of architecting that developers perform up-front. Software architects must determine the proper balance between risk and agility for their projects.","1937-4194","","10.1109/MS.2018.2141017","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354431","agile development;agile architecture;software architecture;technical risk;architecturally significant requirements;ASR;software development;software engineering;The Pragmatic Architect","Computer architecture;Complexity theory;Risk management;Software development;Uncertainty;Software architecture;Project management;Agile software development","software architecture;software prototyping","technical risk;software development project;agile architecture","","","","8","","4 May 2018","","","IEEE","IEEE Magazines"
"Different Databases for Different Strokes","G. Vial",HEC Montréal,"IEEE Software","12 Mar 2018","2018","35","2","80","85","This article provides an overview of current database-management-system technologies and suppliers, along with a case study of an Internet application. The Web Extra at https://extras.computer.org/extra/mso2018020080s1.pdf consists of a table describing various database management systems.","1937-4194","","10.1109/MS.2018.1661308","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314165","relational databases;database management systems;relational database management systems;RDBMS;databases;SQL;NoSQL;CAP theorem;PACELC;Spanner;Google;software engineering;software development","Software development management;Data models;Relational databases;Data structures;Search engines","database management systems;Internet","database-management-system technologies;Internet application","","1","","7","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Software Analysis, Evolution, and Reengineering, and ICT Sustainability","J. Carver; B. Penzenstadler; A. Serebrenik",University of Alabama; California State University; Eindhoven University of Technology,"IEEE Software","6 Jul 2018","2018","35","4","78","80","This issue’s article reports on papers from the IEEE 25th International Conference on Software Analysis, Evolution, and Reengineering (SANER 18) and 5th International Conference on Information and Communications Technology for Sustainability (ICT4S 18).","1937-4194","","10.1109/MS.2018.2801553","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405636","IEEE 25th International Conference on Software Analysis, Evolution, and Reengineering;SANER;5th International Conference on Information and Communications Technology for Sustainability;ICT4S;replication studies;automated program repair;sustainability;software engineering;software development","","","","","","","","","6 Jul 2018","","","IEEE","IEEE Magazines"
"How Common Is Common Enough in Requirements-Engineering Practice?","S. Gregory",Intel Corporation,"IEEE Software","4 May 2018","2018","35","3","20","23","When determining requirements-engineering practices in a complex organization in which different groups might have different needs, the trick is to determine which practices are “common enough” without being too restrictive or too loose.","1937-4194","","10.1109/MS.2018.2141038","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354435","requirements engineering;software requirements;Al Davis;software development;software engineering","Software development;Requirements engineering;Training","formal specification;formal verification;systems analysis","requirements-engineering practice","","2","","4","","4 May 2018","","","IEEE","IEEE Magazines"
"Requirements Engineering and Continuous Deployment","N. Niu; S. Brinkkemper; X. Franch; J. Partanen; J. Savolainen",University of Cincinnati; Utrecht University; Polytechnic University of Catalonia; Bittium; Danfoss,"IEEE Software","12 Mar 2018","2018","35","2","86","90","This article summarizes the RE in the Age of Continuous Deployment panel at the 25th IEEE International Requirements Engineering Conference. It highlights two synergistic points (user stories and linguistic tooling) and one challenge (nonfunctional requirements) in fast-paced, agile-like projects, and recommends how to carry on the dialogue.","1937-4194","","10.1109/MS.2018.1661332","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314167","requirements engineering;continuous deployment;RE in the Age of Continuous Deployment;25th IEEE International Requirements Engineering Conference;user stories;linguistic tooling;agile software development;nonfunctional requirements;software requirements;software engineering;software development","Software development management;Software reliability;Stakeholders;Pragmatics;Software testing;Task analysis;Requirements engineering","formal specification;formal verification;systems analysis","nonfunctional requirements;Continuous Deployment panel;IEEE International Requirements Engineering Conference;synergistic points;user stories;linguistic tooling","","7","","13","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Design with Your Team, Not for Your Team","M. Keeling",IBM,"IEEE Software","6 Jul 2018","2018","35","4","86","88","There are two popular creation myths about software architectures: the Solitary Architect and the Emergent Architecture. These myths need to be replaced with new ones: the Architect as Coach and the Architect as Player-Coach.","1937-4194","","10.1109/MS.2018.2801556","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405638","software architecture;software architects;software design;software engineering;software development;Pragmatic Architect","Software architecture;Software development management;Testing","software architecture;software quality;team working","software architectures;Solitary Architect;Emergent Architecture;quality attributes;Architect as Player-Coach;Architect as Coach","","","","5","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Choosing a Chatbot Development Tool","S. Pérez-Soler; S. Juárez-Puerta; E. Guerra; J. de Lara","Ingeniería Informática, Universidad Autonoma de Madrid, Madrid, 28049 Madrid, Spain; Ingeniería Informática, Universidad Autonoma de Madrid, Madrid, Madrid, Spain; Computer Science, Universidad Autonoma de Madrid, Madrid, Madrid, Spain; Ingeniería Informática, Universidad Autonoma de Madrid, Madrid, 28049 Madrid, Spain","IEEE Software","","2021","PP","99","0","0","Chatbots are programs that supply services to users via conversation in natural language, acting as virtual assistants within social networks or web applications. Companies like Google, IBM, Microsoft or Amazon have released chatbot development tools with different functionalities, capabilities, approaches and pricing models. With so many options, companies that want to offer services through chatbots can find choosing the right tool difficult. To help them make an informed choice, we review the most representative chatbot development tools with a focus on technical and managerial aspects.","1937-4194","","10.1109/MS.2020.3030198","Ministerio de Ciencia e Innovación; Comunidad de Madrid; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9364349","Software Engineering;Chatbots;Natural Language Processing","Chatbot;Tools;Libraries;Companies;Social networking (online);Testing;Software","","","","","","","IEEE","26 Feb 2021","","","IEEE","IEEE Early Access Articles"
"Trends in Agile Updated: Perspectives from the Practitioners","R. Prikladnicki; C. Lassenius; J. C. Carver",Pontifical Catholic University of Rio Grande do Sul; Aalto University; University of Alabama,"IEEE Software","25 Dec 2017","2018","35","1","109","111","The Agile Conference is the largest global conference on agile software development, catering particularly to practitioners. This article reports on three keynotes at Agile 2017 and the second year of an IEEE Software conference initiative.","1937-4194","","10.1109/MS.2017.4541042","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239936","agile development;David Marquet;intent-based leadership;Jez Humble;continuous delivery;Denise Jacobs;inner critic;Amy Silberbauer;Mike Griffiths;business analysts;systems engineers;Agile Conference;Agile 2017;software development;software engineering;Practitioners’ Digest","","","","","1","","","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Why and How Your Traceability Should Evolve: Insights from an Automotive Supplier","R. Wohlrab; P. Pelliccione; A. Shahrokni; E. Knauss","Computer Science and Engineering, Chalmers tekniska hogskola Campus Lindholmen, Göteborg, Västra Götaland, Sweden; Department of Computer Science, University of L'Aquila Department of Information Engineering Computer Science and Mathematics, L'Aquila, Abruzzo, Italy; Zerberus, Zenuity AB, Gothenburg, Västra Götaland, Sweden; Computer Science and Engineering, Chalmers tekniska hogskola Campus Lindholmen, Göteborg, Sweden, Sweden","IEEE Software","","2020","PP","99","0","0","Traceability is a key enabler of various activities in automotive software and systems engineering and required by several standards. However, most existing traceability management approaches do not consider that traceability is situated in constantly changing development contexts involving multiple stakeholders. Together with an automotive supplier, we analyzed how technology, business, and organizational factors raise the need for flexible traceability. We present how traceability can be evolved in the development lifecycle, from early elicitation of traceability needs to the implementation of mature traceability strategies. Moreover, we shed light on how traceability can be managed flexibly within an agile team and more formally when crossing team borders and organizational borders. Based on these insights, we present requirements for flexible tool solutions, supporting varying levels of data quality, change propagation, versioning, and organizational traceability.","1937-4194","","10.1109/MS.2020.2996369","Knut och Alice Wallenbergs Stiftelse; Software Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9097278","Tracing;Software Engineering Process;Organizational management and coordination","Automotive engineering;Safety;Stakeholders;Tools;Data integrity;Modeling;Companies","","","","","","","","20 May 2020","","","IEEE","IEEE Early Access Articles"
"The Web as a Software Connector: Integration Resting on Linked Resources","C. Pautasso; O. Zimmermann","University of Lugano; University of Applied Sciences of Eastern Switzerland, Rapperswil","IEEE Software","25 Dec 2017","2018","35","1","93","98","The web, seen as a graph of linked resources shared between microservices, can serve as an integration style. It offers unique characteristics and possibilities regarding dataflow, control flow, and other qualities, compared to file transfer, shared databases, remote procedure calls, and asynchronous messaging. Carrying these insights in your toolbox will make you aware of all the options to consider next time you build loosely coupled integrated systems.","1937-4194","","10.1109/MS.2017.4541049","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239944","architectural decisions;enterprise application integration;integration styles;microservices;software architecture;REST;Representational State Transfer;WWW;software engineering;software development;the web;Insights","Protocols;Software architecture;Software development;Software architecture;Interoperability;Servers;Web services","data flow computing;integrated software;Internet","loosely coupled integrated systems;control flow;dataflow;software integration;linked resources;Web;software connector","","1","","10","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Managing Energy Consumption as an Architectural Quality Attribute","R. Kazman; S. Haziyev; A. Yakuba; D. A. Tamburri",University of Hawai’i; SoftServe; SoftServe; Jheronimus Academy of Data Science and Technical University of Eindhoven,"IEEE Software","27 Sep 2018","2018","35","5","102","107","A look at the software for an automated weather station shows that energy can be treated like any other architectural quality attribute. It's no different, from the perspective of architectural design, than modifiability, performance, or availability. It can be modeled and prototyped, and we can reason about the design tradeoffs required to achieve better energy use.","1937-4194","","10.1109/MS.2018.3571227","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474494","energy consumption;software architecture;Internet of Things;IoT;weather stations;automated weather stations;software engineering;software development;The Pragmatic Architect","Energy consumption;Power demand;Meteorology;Current measurement;Energy measurement;Internet of Things;Automation","energy consumption;software architecture;software quality","automated weather station;architectural quality attribute;energy consumption","","2","","2","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Over-the-Air Updates for Robotic Swarms","V. S. Varadharajan; D. S. Onge; C. Guß; G. Beltrame",École Polytechnique de Montréal; École Polytechnique de Montréal; Hannover University of Applied Sciences and Arts; École Polytechnique de Montréal,"IEEE Software","12 Mar 2018","2018","35","2","44","50","Along with the growing number of robotic devices introduced by automation and the Internet of Things has come the growth of interest in methods and tools for deploying code updates to active sensor arrays and swarms of robots. This article presents a toolset that can perform an over-the-air code update of the robots in a swarm while the swarm is active, without interrupting the swarm's mission. Each update is generated as a patch of the currently deployed code. A consensus mechanism borrowed from swarm intelligence ensures that, at any given time, all robots in the swarm run the same code version. Simulations were conducted with thousands of units to study the scalability and bandwidth consumption of the update process. Real deployment experiments were then performed on a small swarm of commercial quadcopters. This article is part of a theme issue on release engineering.","1937-4194","","10.1109/MS.2018.111095718","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255775","multiagent systems;distributed artificial intelligence;artificial intelligence;AI;distributed applications;distributed systems;information technology;autonomous vehicles;robotics;UAVs;unmanned aerial vehicles;over-the-air;OTA;computers and society;software development;software engineering","Software development management;Robot sensing systems;Software toolds;Software engineeirng;Cryptography","helicopters;mobile robots;particle swarm optimisation;sensor arrays;wireless sensor networks","currently deployed code;swarm intelligence ensures;robots;code version;update process;robotic swarms;robotic devices;Internet of Things;code updates;active sensor arrays;over-the-air code update;over-the-air updates","","2","","14","","12 Jan 2018","","","IEEE","IEEE Magazines"
"Mining the Ground Truth of Enterprise Toolchains","M. Kersten",Tasktop,"IEEE Software","4 May 2018","2018","35","3","12","17","Data on organizations' use of agile and DevOps tools provides the ground truth of enterprise software delivery.","1937-4194","","10.1109/MS.2018.2141029","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354424","DevOps;DevOps tools;toolchains;value stream integration diagrams;software development;software engineering;On DevOps","Organizations;Software tools;Task analysis;Information analysis;Best practices;Enterprise resource planning;Software development","business data processing;cloud computing;data mining","enterprise software delivery;DevOps tools;enterprise toolchains","","3","","4","","4 May 2018","","","IEEE","IEEE Magazines"
"Blockchain-Enabled E-Voting","N. Kshetri; J. Voas",University of North Carolina at Greensboro; Cigital,"IEEE Software","6 Jul 2018","2018","35","4","95","99","Blockchain-enabled e-voting (BEV) could reduce voter fraud and increase voter access. Eligible voters cast a ballot anonymously using a computer or smartphone. BEV uses an encrypted key and tamper-proof personal IDs. This article highlights some BEV implementations and the approach's potential benefits and challenges.","1937-4194","","10.1109/MS.2018.2801546","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405627","blockchain-enabled e-voting;BEV;e-voting;blockchains;elections;voter fraud;voter access;paper ballots;electronic voting;online voting;software development;software engineering;Invited Content","Electronic voting;Urban areas;Cryptography;Blockchain","cryptography;data privacy;fraud;government data processing","eligible voters;ballot anonymously;blockchain-enabled e-voting;tamper-proof personal ID;encrypted key;voter access;voter fraud reduction;BEV","","38","","29","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Continuous Delivery: Building Trust in a Large-Scale, Complex Government Organization","R. Siqueira; D. Camarinha; M. Wen; P. Meirelles; F. Kon",University of São Paulo; University of São Paulo; University of São Paulo; University of Brasilia; University of São Paulo,"IEEE Software","12 Mar 2018","2018","35","2","38","43","For many software development teams, the first aspects that come to mind regarding continuous delivery (CD) are the operational challenges and competitive benefits. In the authors' experience, CD was much more: it was a survival technique. This article presents how and why they applied CD in a large governmental project for the development of a collaborative development environment. They share the challenges they faced and the strategies they used to overcome them. The article concludes with a set of lessons learned that can be valuable for readers in a variety of situations. This article is part of a special issue on release engineering.","1937-4194","","10.1109/MS.2018.111095426","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255783","continuous delivery;software release management;configuration management;software engineering;government applications;agile software development;software development","Software development management;Software product lines;Product life cycle management;Software engineeirng","software development management","software development teams;continuous delivery;CD;survival technique;governmental project;collaborative development environment;large-scale complex government organization;release engineering","","","","6","","12 Jan 2018","","","IEEE","IEEE Magazines"
"WordPress: A Content Management System to Democratize Publishing","J. Cabot",Universitat Oberta de Catalunya,"IEEE Software","4 May 2018","2018","35","3","89","92","WordPress aims to democratize publishing, ensuring that any nontechnical person can create a website, while building a product that can scale all the way up to enterprise clients with complex needs. The richness and importance of the WordPress code base and ecosystem pose many interesting challenges for the research community.","1937-4194","","10.1109/MS.2018.2141016","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354434","WordPress;website development;content management systems;CMS;plug-ins;software development;software engineering","Software packages;Blogs;Electronic publishing;Content management","content management;publishing;social networking (online)","WordPress;content management system;publishing","","2","","8","","4 May 2018","","","IEEE","IEEE Magazines"
"A Comet Revisited: Lessons Learned from Philaes Landing","A. Balázs",Wigner Research Centre for Physics,"IEEE Software","6 Jul 2018","2018","35","4","89","93","The Philae lander, part of the Rosetta program, was the first to land on and explore a comet. This article explores the lessons learned from the Philae team's experiences with problems that occurred in the hardware and software and in mission operations control.","1937-4194","","10.1109/MS.2018.2801542","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405637","comet 67P/Churyumov-Gerasimenko;Rosetta;Philae;software development;software engineering;Impact","Space missions;Fault tolerant systems;Orbits;Space research","comets;space vehicles","Philae lander;Rosetta program;Philae team;Philaes landing;Philae team experiences;mission operations control","","","","5","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Probabilistic Threat Detection for Risk Management in Cyber-physical Medical Systems","A. Rao; N. Carreón; R. Lysecky; J. Rozenblit",University of Arizona; University of Arizona; University of Arizona; University of Arizona,"IEEE Software","25 Dec 2017","2018","35","1","38","43","Medical devices are complex cyber-physical systems incorporating emergent hardware and software components. However, this complexity leads to a wide attack surface posing security risks and vulnerabilities. Mitigation and management of such risks during premarket design and postmarket deployment are required. Dynamically mitigating threat potential in the presence of unknown vulnerabilities requires an adaptive risk-based scheme to assess the system's state, a secure system architecture that can isolate hardware and software components, and design methods that can adaptively adjust the system's topology based on risk changes. The essential complementary aspects during deployment are detecting, characterizing, and quantifying security threats. This article presents a dynamic risk management and mitigation approach based on probabilistic threat estimation. A smart-connected-pacemaker case study illustrates the approach. This article is part of a special issue on Software Safety and Security Risk Mitigation in Cyber-physical Systems.","1937-4194","","10.1109/MS.2017.4541031","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239935","medical-device security;threat estimation;risk assessment and management;software development;software engineering","Computer security;Runtime;Risk management;Pacemakers;Medical devices;Safety;Cyber-physical systems;Cloud computing","computer network security;pacemakers;risk management;security of data","software safety;security risk mitigation;complex cyber-physical medical systems;medical devices;probabilistic threat detection;probabilistic threat estimation;dynamic risk management;quantifying security threats;secure system architecture;postmarket deployment;premarket design;security risks;wide attack surface;software components;emergent hardware","","7","","14","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Automatic Loop Summarization via Path Dependency Analysis","X. Xie; B. Chen; L. Zou; Y. Liu; W. Le; X. Li","Tianjin University, Tianjin, China; Fudan University, Shanghai Shi, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Department of Computer Science, Iowa State University, Ames, IA; Tianjin University, Tianjin, China","IEEE Transactions on Software Engineering","12 Jun 2019","2019","45","6","537","557","Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.","1939-3520","","10.1109/TSE.2017.2788018","National Research Foundation; National Natural Science Foundation of China; National Natural Science Foundation of China; National Natural Science Foundation of China; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8241837","Disjunctive loop summary;path dependency automaton;path interleaving","Debugging;Automata;Benchmark testing;Public domain software","program debugging;program diagnostics;program testing;program verification;public domain software","automatic loop summarization;test case generation;program optimization;program analysis;path dependency automaton;PDA;loop classification;loop analysis framework;disjunctive loop summary;Proteus;loop program verification;loop bound analysis;path-sensitive loop effects","","3","","77","","29 Dec 2017","","","IEEE","IEEE Journals"
"Code Review Knowledge Perception: Fusing Multi-Features for Salient-Class Location","Y. Huang; N. Jia; X. Chen; K. Hong; Z. Zheng","School of Data and Computer Science, Sun Yat-sen University, Guangzhou, GuangDong China (e-mail: huangyjn@gmail.com); School of Management Science and Engineering, Hebei GEO University, Shijiazhuang, 050031, China, Hebei GEO University, 12410 Shijiazhuang, HeBei China (e-mail: huang_yuan@yahoo.com); Guangdong Key Laboratory for Big Data Analysis and Simulation of Public Opinion, School of Communication and Design, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: chenxp8@mail.sysu.edu.cn); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, China, Sun Yat-sen University, guangzhou, Guangdong China (e-mail: hongkai1995@163.com); School of Data and Computer Science, Sun Yat-sen University, Guangzhou, Guangdong China (e-mail: zibinzheng@yeah.net)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Code review is a common software engineering practice of practical importance to reduce software defects. Review today is often with the help of specialized tools, such as Gerrit. However, even in a tool-supported code review involves a significant amount of human effort to understand the code change, because the information required to inspect code changes may distribute across multiple files that reviewers are not familiar with. Code changes are often organized as commits for review. In this paper, we found that most of the commits contain a salient class(es), which is saliently modified and causes the modification of the rest classes in a commit. Our user studies confirmed that identifying the salient class in a commit can facilitate reviewers in understanding code change. Inspired by the effectiveness of machine learning techniques in the classification field, we model the salient class identification as a binary classification problem and extract a number of discriminative features from commit to characterize the salience of a class. The experiment results show that our approach achieves an accuracy of 88%. A user study with industrial developers shows that our approach can really improve the efficiency of reviewers understanding code changes in a reviewing scenario without using comment.","1939-3520","","10.1109/TSE.2020.3021902","National Key RD Program of China; National Natural Science Foundation of China; Key-Area Research and Development Program of Guangdong Province; China Postdoctoral Science Foundation; Guangdong Basic and Applied Basic Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186620","Code Review;Code Comprehension;Code Change;Code Discriminative Features;Code Commit","Feature extraction;Semantics;Tools;Couplings;Open source software;Knowledge engineering","","","","","","","","4 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Contextual Documentation Referencing on Stack Overflow","S. Baltes; C. Treude; M. P. Robillard","School of Computer Science, The University of Adelaide, 1066 Adelaide, South Australia Australia (e-mail: research@sbaltes.com); School of Computer Science, The University of Adelaide, 1066 Adelaide, South Australia Australia (e-mail: christoph.treude@adelaide.edu.au); School of Computer Science, McGill University, Montreal, Quebec Canada H3A 2A7 (e-mail: martin@cs.mcgill.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software engineering is knowledge-intensive and requires software developers to continually search for knowledge, often on community question answering platforms such as Stack Overflow. Such information sharing platforms do not exist in isolation, and part of the evidence that they exist in a broader software documentation ecosystem is the common presence of hyperlinks to other documentation resources found in forum posts. With the goal of helping to improve the information diffusion between Stack Overflow and other documentation resources, we conducted a study to answer the question of how and why documentation is referenced in Stack Overflow threads. We sampled and classified 759 links from two different domains, regular expressions and Android development, to qualitatively and quantitatively analyze the links' context and purpose, including attribution, awareness, and recommendations. We found that links on Stack Overflow serve a wide range of distinct purposes, ranging from citation links attributing content copied into Stack Overflow, over links clarifying concepts using Wikipedia pages, to recommendations of software components and resources for background reading. This purpose spectrum has major corollaries, including our observation that links to documentation resources are a reflection of the information needs typical to a technology domain. We contribute a framework and method to analyze the context and purpose of Stack Overflow links, a public dataset of annotated links, and a description of five major observations about linking practices on Stack Overflow. Those observations include the above-mentioned purpose spectrum, its interplay with documentation resources and applications domains, and the fact that links on Stack Overflow often lack context in form of accompanying quotes or summaries. We further point to potential tool support to enhance the information diffusion between Stack Overflow and other documentation resources.","1939-3520","","10.1109/TSE.2020.2981898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9042358","Community Question Answering;Software Documentation;Information Diffusion;Hyperlinks;Stack Overflow","Documentation;Context;Internet;Software;Encyclopedias;Electronic publishing","","","","","","","","19 Mar 2020","","","IEEE","IEEE Early Access Articles"
"Integrating Provenance Capture and UML with UML2PROV: Principles and Experience","C. Sáenz-Adán; B. Pérez; F. J. García-Izquierdo; L. Moreau","Department of Mathematics and Computer Science, University of La Rioja, La Rioja, Spain (e-mail: carlos.saenz@unirioja.es); Department of Mathematics and Computer Science, University of La Rioja, La Rioja, Spain (e-mail: beatriz.perez@unirioja.es); Department of Mathematics and Computer Science, University of La Rioja, La Rioja, Spain (e-mail: francisco.garcia@unirioja.es); Department of Informatics, King's College London, London, UK (e-mail: luc.moreau@kcl.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","In response to the increasing calls for algorithmic accountability, UML2PROV is a novel approach to address the existing gap between application design, where models are described by UML diagrams, and provenance design, where generated provenance is meant to describe an application's flows of data, processes and responsibility, enabling greater accountability of this application. The originality of UML2PROV is that designers are allowed to follow their preferred software engineering methodology to create the UML Diagrams for their application, while UML2PROV takes the UML diagrams as a starting point to automatically generate: (1) the design of the provenance to be generated (expressed as PROV templates); and (2) the software library for collecting runtime values of interest (encoded as variable-value associations known as bindings), which can be deployed in the application without developer intervention. At runtime, the PROV templates combined with the bindings are used to generate high-quality provenance suitable for subsequent consumption. UML2PROV is rigorously defined by an extensive set of 17 patterns mapping UML diagrams to provenance templates, and is accompanied by a reference implementation based on Model Driven Development techniques. A systematic evaluation of UML2PROV uses quantitative data and qualitative arguments to show the benefits and trade-offs of applying UML2PROV for software engineers seeking to make applications provenance-aware. In particular, as the UML design drives both the design and capture of provenance, we discuss how the levels of detail in UML designs affect aspects such as provenance design generation, application instrumentation, provenance capability maintenance, storage and run-time overhead, and quality of the generated provenance. Some key lessons are learned such as: starting from a non-tailored UML design leads to the capture of more provenance than required to satisfy provenance requirements and therefore, increases the overhead unnecessarily; alternatively, if the UML design is tailored to focus on addressing provenance requirements, only relevant provenance gets to be collected, resulting in lower overheads.","1939-3520","","10.1109/TSE.2020.2977016","Spanish Ministerio de Economia y Competitividad; University of La Rioja; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018139","provenance;PROV;provenance generation;template","Unified modeling language;Software;Proposals;Runtime;Data models;Tools","","","","","","","","28 Feb 2020","","","IEEE","IEEE Early Access Articles"
"Extending Abstract Interpretation to Dependency Analysis of Database Applications","A. Jana; R. Halder; K. V. Abhishekh; S. D. Ganni; A. Cortesi","Indian Institute of Technology Patna, Patna, Bihar, India; Indian Institute of Technology Patna, Patna, Bihar, India; Indian Institute of Technology Patna, Patna, Bihar, India; Indian Institute of Technology Patna, Patna, Bihar, India; Università Ca’ Foscari Venezia, Venezia, VE, Italy","IEEE Transactions on Software Engineering","14 May 2020","2020","46","5","463","494","Dependency information (data- and/or control-dependencies) among program variables and program statements is playing crucial roles in a wide range of software-engineering activities, e.g., program slicing, information flow security analysis, debugging, code-optimization, code-reuse, code-understanding. Most existing dependency analyzers focus on mainstream languages and they do not support database applications embedding queries and data-manipulation commands. The first extension to the languages for relational database management systems, proposed by Willmor et al. in 2004, suffers from the lack of precision in the analysis primarily due to its syntax-based computation and flow insensitivity. Since then no significant contribution is found in this research direction. This paper extends the Abstract Interpretation framework for static dependency analysis of database applications, providing a semantics-based computation tunable with respect to precision. More specifically, we instantiate dependency computation by using various relational and non-relational abstract domains, yielding to a detailed comparative analysis with respect to precision and efficiency. Finally, we present a prototype $\sf{ semDDA}$semDDA, a semantics-based Database Dependency Analyzer integrated with various abstract domains, and we present experimental evaluation results to establish the effectiveness of our approach. We show an improvement of the precision on an average of 6 percent in the interval, 11 percent in the octagon, 21 percent in the polyhedra and 7 percent in the powerset of intervals abstract domains, as compared to their syntax-based counterpart, for the chosen set of Java Server Page (JSP)-based open-source database-driven web applications as part of the GotoCode project.","1939-3520","","10.1109/TSE.2018.2861707","Science and Engineering Research Board; CINI Cybersecurity National Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423692","Dependency graphs;static analysis;relational databases;structured query languages","Databases;Semantics;Static analysis;Security;Syntactics;Open source software;Debugging","","","","","","75","IEEE","31 Jul 2018","","","IEEE","IEEE Journals"
"A Semantics-Based Hybrid Approach on Binary Code Similarity Comparison","Y. Hu; H. Wang; Y. Zhang; B. Li; D. Gu","School of Electronic, Information and Electrical Engineering, Shanghai Jiao Tong University - Minhang Campus, 12474 Shanghai, Shanghai China (e-mail: yixiaoxian@gmail.com); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: tony-wh@sjtu.edu.cn); Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: yyjess@sjtu.edu.cn); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: uchihal@sjtu.edu.cn); Department of Computer Science and Engineering, Shanghai Jiao Tong University, 12474 Shanghai, Shanghai China (e-mail: dwgu@sjtu.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Binary code similarity comparison is a methodology for identifying similar or identical code fragments in binary programs. It is indispensable in fields of software engineering and security, which has many important applications (e.g., plagiarism detection, bug detection). With the widespread of smart and IoT (Internet of Things) devices, an increasing number of programs are ported to multiple architectures (e.g. ARM, MIPS). It becomes necessary to detect similar binary code across architectures as well. The main challenge of this topic lies in the semantics-equivalent code transformation resulting from different compilation settings, code obfuscation, and varied instruction set architectures. Another challenge is the trade-off between comparison accuracy and coverage. Unfortunately, existing methods still heavily rely on semantics-less code features which are susceptible to the code transformation. Additionally, they perform the comparison merely either in a static or in a dynamic manner, which cannot achieve high accuracy and coverage simultaneously. In this paper, we propose a semantics-based hybrid method to compare binary function similarity. We execute the reference function with test cases, then emulate the execution of every target function with the runtime information migrated from the reference function. Semantic signatures are extracted during the execution as well as the emulation. Lastly, similarity scores are calculated from the signatures to measure the likeness of functions. We have implemented the method in a prototype system designated as BINMATCH which performs binary code similarity comparison across architectures of x86, ARM and MIPS on the Linux platform. We evaluate BINMATCH with nine real-word projects compiled with different compilation settings, on variant architectures, and with commonly-used obfuscation methods, totally performing over 100 million pairs of function comparison. The experimental results show that BINMATCH is resilient to the semantics-equivalent code transformation. Besides, it not only covers all target functions for similarity comparison, but also improves the accuracy comparing to the state-of-the-art solutions.","1939-3520","","10.1109/TSE.2019.2918326","Major Project of Ministry of Industry and Information Tech- nology of China; National Key Research and Development Program of China; Key Program of National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721093","Binary code similarity comparison;reverse engineering;program analysis;code clone","Binary codes;Semantics;Computer architecture;Runtime;Computer science;Feature extraction;Internet of Things","","","","1","","","","23 May 2019","","","IEEE","IEEE Early Access Articles"
"Software Configuration Engineering in Practice Interviews, Survey, and Systematic Literature Review","M. SAYAGH; N. Kerzazi; B. Adams; F. Petrillo","Department du Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, QC, Canada; Ecole Nationale Superieure d'Informatique et d'Analyse des Systemes (ENSIAS), Rabat, Morocco; Department du Genie Informatique et Genie Logiciel, Ecole Polytechnique de Montreal, Montreal, QC, Canada; Département d'informatique et de mathématique, Université du Québec Chicoutimi, Chicoutimi, QC, Canada","IEEE Transactions on Software Engineering","15 Jun 2020","2020","46","6","646","673","Modern software applications are adapted to different situations (e.g., memory limits, enabling/disabling features, database credentials) by changing the values of configuration options, without any source code modifications. According to several studies, this flexibility is expensive as configuration failures represent one of the most common types of software failures. They are also hard to debug and resolve as they require a lot of effort to detect which options are misconfigured among a large number of configuration options and values, while comprehension of the code also is hampered by sprinkling conditional checks of the values of configuration options. Although researchers have proposed various approaches to help debug or prevent configuration failures, especially from the end users' perspective, this paper takes a step back to understand the process required by practitioners to engineer the run-time configuration options in their source code, the challenges they experience as well as best practices that they have or could adopt. By interviewing 14 software engineering experts, followed by a large survey on 229 Java software engineers, we identified 9 major activities related to configuration engineering, 22 challenges faced by developers, and 24 expert recommendations to improve software configuration quality. We complemented this study by a systematic literature review to enrich the experts' recommendations, and to identify possible solutions discussed and evaluated by the research community for the developers' problems and challenges. We find that developers face a variety of challenges for all nine configuration engineering activities, starting from the creation of options, which generally is not planned beforehand and increases the complexity of a software system, to the non-trivial comprehension and debugging of configurations, and ending with the risky maintenance of configuration options, since developers avoid touching and changing configuration options in a mature system. We also find that researchers thus far focus primarily on testing and debugging configuration failures, leaving a large range of opportunities for future work.","1939-3520","","10.1109/TSE.2018.2867847","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8451922","Empirical study;configuration;configuration engineering;Systematic literature review;interviews;survey","Software systems;Interviews;Systematics;Facebook;Bibliographies;Software algorithms","configuration management;Java;program debugging;software quality","software configuration quality;configuration engineering activities;debugging;software configuration engineering;software failures;run-time configuration options;Java software engineers","","4","","123","IEEE","30 Aug 2018","","","IEEE","IEEE Journals"
"A Layered Reference Architecture for Metamodels to Tailor Quality Modeling and Analysis","R. Heinrich; M. Strittmatter; R. Reussner","Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany; Karlsruhe Institute of Technology, Karlsruhe, Germany","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","775","800","Nearly all facets of our everyday life strongly depend on software-intensive systems. Besides correctness, highly relevant quality properties of these systems include performance, as directly perceived by the user, and maintainability, as an important decision factor for evolution. These quality properties strongly depend on architectural design decisions. Hence, to ensure high quality, research and practice is interested in approaches to analyze the system architecture for quality properties. Therefore, models of the system architecture are created and used for analysis. Many different languages (often defined by metamodels) exist to model the systems and reason on their quality. Such languages are mostly specific to quality properties, tools or development paradigms. Unfortunately, the creation of a specific model for any quality property of interest and any different tool used is simply infeasible. Current metamodels for quality modeling and analysis are often not designed to be extensible and reusable. Experience from generalizing and extending metamodels result in hard to evolve and overly complex metamodels. A systematic way of creating, extending and reusing metamodels for quality modeling and analysis, or parts of them, does not exist yet. When comparing metamodels for different quality properties, however, substantial parts show quite similar language features. This leads to our approach to define the first reference architecture for metamodels for quality modeling and analysis. A reference architecture in software engineering provides a general architecture for a given application domain. In this paper, we investigate the applicability of modularization concepts from object-oriented design and the idea of a reference architecture to metamodels for quality modeling and analysis to systematically create, extend and reuse metamodel parts. Thus, the reference architecture allows to tailor metamodels. Requirements on the reference architecture are gathered from a historically grown metamodel. We specify modularization concepts as a foundation of the reference architecture. Detailed application guidelines are described. We argue the reference architecture supports instance compatibility and non-intrusive, independent extension of metamodels. In four case studies, we refactor historically grown metamodels and compare them to the original metamodels. The study results show the reference architecture significantly improves evolvability as well as need-specific use and reuse of metamodels.","1939-3520","","10.1109/TSE.2019.2903797","Helmholtz Association of German Research Centers and the MWK (Ministry of Science, Research and the Arts Baden-Württemberg) in the funding line Research Seed Capital (RiSC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8662719","Domain-specific modeling language;reference architecture;metamodel;quality analysis","Computer architecture;Object oriented modeling;Analytical models;Biological system modeling;Tools;Software;Systematics","","","","","","84","IEEE","7 Mar 2019","","","IEEE","IEEE Journals"
"Which Variables Should I Log?","Z. Liu; X. Xia; D. Lo; Z. Xing; A. E. Hassan; S. Li","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: liu_zx@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: zhenchang.xing@anu.edu.au); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: shan@zju.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Developers usually depend on inserting logging statements into the source code to collect system runtime information. Such logged information is valuable for software maintenance. A logging statement usually prints one or more variables to record vital system status. However, due to the lack of rigorous logging guidance and the requirement of domain-specific knowledge, it is not easy for developers to make proper decisions about which variables to log. To address this need, in this work, we propose an approach to recommend logging variables for developers during development by learning from existing logging statements. Different from other prediction tasks in software engineering, this task has two challenges: 1) Dynamic labels -- different logging statements have different sets of accessible variables, which means in this task, the set of possible labels of each sample is not the same. 2) Out-of-vocabulary words -- identifiers' names are not limited to natural language words and the test set usually contains a number of program tokens which are out of the vocabulary built from the training set and cannot be appropriately mapped to word embeddings. To deal with the first challenge, we convert this task into a representation learning problem instead of a multi-label classification problem. Given a code snippet which lacks a logging statement, our approach first leverages a neural network with an RNN (recurrent neural network) layer and a self-attention layer to learn the proper representation of each program token, and then predicts whether each token should be logged through a unified binary classifier based on the learned representation. To handle the second challenge, we propose a novel method to map program tokens into word embeddings by making use of the pre-trained word embeddings of natural language tokens. We evaluate our approach on 9 large and high-quality Java projects. Our evaluation results show that the average MAP of our approach is over 0.84, outperforming random guess and an information-retrieval-based method by large margins.","1939-3520","","10.1109/TSE.2019.2941943","NSFC Program; National Key Research and Development Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8840982","Log;Logging Variable;Word Embedding;Representation Learning","Task analysis;Recurrent neural networks;Tools;Compounds;Vocabulary;Software maintenance","","","","2","","","","17 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Artificial Intelligence-Powered Worker Engagement in Software Crowdsourcing","J. Wang; Y. Yang; Q. Wang","Software, Chinese Academy of Sciences, China; Systems and Enterprises, Stevens Institute of Technology; Software, Chinese Academy of Science, China","IEEE Software","26 Oct 2020","2020","37","6","94","98","Crowdsourced Software Engineering (CSE) evolved from outsourcing and open source development. It has created a fundamental shift; there are now many open-call software minitasks that are advertised and performed through popular CSE platforms. For instance, TopCoder currently has more than 1.5 million registered designers, developers, and quality engineers; uTest has 400,000-plus testing specialists with diverse expertise to validate various aspects of digital quality.","1937-4194","","10.1109/MS.2020.3017035","National Key R and D Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9239287","","Task analysis;Computer bugs;Crowdsourcing;Artificial intelligence;Software;Testing;Context modeling","artificial intelligence;crowdsourcing;personnel;public domain software;software quality","artificial intelligence;crowdsourced software engineering;open source development;TopCoder;digital quality;open call software minitasks;outsourcing development;software crowdsourcing;CSE platforms;worker engagement;quality engineers","","","","4","","26 Oct 2020","","","IEEE","IEEE Magazines"
"The Missing Requirements Perspective in Large-Scale Agile System Development","E. Knauss","Computer Science and Engineering, Chalmers University of Gothenburg, Sweden","IEEE Software","16 Apr 2019","2019","36","3","9","13","Recent developments in agile methods at scale and continuous delivery have successfully removed major bottlenecks that have, so far, limited the speed at which software can be developed, delivered, and evaluated by customers and end users. Now, the ability to manage requirements and related knowledge in continuous software engineering has become a limiting factor.","1937-4194","","10.1109/MS.2019.2896875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693079","","Agile software development;Large-scale systems;Software development management;Systems engineering and theory;Contracts;Engineering management;Knowledge engineering","formal verification;software prototyping","agile methods;continuous delivery;continuous software engineering;missing requirements perspective;large-scale agile system development","","","","9","","16 Apr 2019","","","IEEE","IEEE Magazines"
"Critical Factors for Open Source Advancement in the U.S. Department of Defense","T. P. Scanlon","Software Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania United States","IEEE Software","22 Oct 2019","2019","36","6","29","33","Leveraging open source components in Department of Defense (DoD) software systems remains challenging and is often met with resistance. This article describes several factors that will increase the likelihood of successfully deploying open source in DoD projects.","1937-4194","","10.1109/MS.2019.2933769","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8790750","","US Department of Defense;Open source software;Software systems;Computer security;Licenses","military computing;public domain software","open source advancement;open source components;DoD projects;department of defense software systems;US department of defense","","","","15","","7 Aug 2019","","","IEEE","IEEE Magazines"
"Ten Years of ""Impact"" Columns—The Good, the Bad, and the Ugly","M. van Genuchten; L. Hatton","VitalHealth Software, United States; Forensic Software Engineering, Kingston University, United Kingdom","IEEE Software","22 Oct 2019","2019","36","6","57","60","Ten years ago, we started the ""Impact"" column in IEEE Software. The goal when we started was to ""build better quantitative insight into how software impacts various businesses. How the product uses the software and how the company built it are equally important.""<sup>1</sup> This article is the 45th instance of the column. We have had 69 authors, mostly industry experts writing about the impact of software on their business and, in some cases, on its end users. Many of the authors had neither taken the time nor been given the opportunity to publish about their work before, so it gave them a forum to write about real systems: their size, their development methods, their economic and end-user impacts, and, perhaps most compelling of all, their ubiquity. The columns have been cited more than 400 times and have given our readers insights into some beautiful software solutions, in terms of both technology (e.g., the Mars rover<sup>2</sup>) and in terms of its impact on people (e.g., supporting farmers in Africa<sup>3</sup>). Our colleague, Zeljko Obrenovic, created a complete overview of the ""Impact"" column articles, which is available at https://www.obren359.com/collection.html?id=ieeesw/impact.","1937-4194","","10.1109/MS.2019.2932495","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880054","","Software developnment management;Social implications of technology","","","","2","","15","","22 Oct 2019","","","IEEE","IEEE Magazines"
"How Do Open Source Software Contributors Perceive and Address Usability? Valued Factors, Practices, and Challenges","W. Wang; J. Cheng; J. L. C. Guo","Department of Computer Science, McGill University Faculty of Science, Montreal, Quebec, Canada (email: wenting.wang@mail.mcgill.ca); Department of Computer and Software Engineering, Ecole Polytechnique de Montreal, Montreal, Quebec, Canada (email: jinghuicheng@gmail.com); Department of Computer Science, McGill University Faculty of Science, Montreal, Quebec, Canada (email: jin.guo@cs.mcgill.ca)","IEEE Software","","2020","PP","99","0","0","Usability is an increasing concern in open source software (OSS). Given the recent changes in the OSS landscape, it is imperative to examine the OSS contributors’ current valued factors, practices, and challenges concerning usability. We accumulated this knowledge through a survey with a wide range of contributors to OSS applications. Through analyzing 84 survey responses, we found that many participants recognized the importance of usability. While most relied on issue tracking systems to collect user feedback, a few participants also adopted typical user-centered design methods. However, most participants demonstrated a system-centric rather than a user-centric view. Understanding the diverse needs and consolidating various feedback of end-users posed unique challenges for the OSS contributors when addressing usability in the most recent development context. Our work provided important insights for OSS practitioners and tool designers in exploring ways for promoting a user-centric mindset and improving usability practice in the current OSS communities.","1937-4194","","10.1109/MS.2020.3009514","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9140320","","Usability;Tools;Open source software;Graphical user interfaces;Instruments;Guidelines","","","","","","","","14 Jul 2020","","","IEEE","IEEE Early Access Articles"
"Toward Solving Social and Technical Problems in Open Source Software Ecosystems: Using Cause-and-Effect Analysis to Disentangle the Causes of Complex Problems","J. Marsan; M. Templier; P. Marois; B. Adams; K. Carillo; G. L. Mopenza","Information Systems, Universite Laval, Canada; Information Systems, Universite Laval, Canada; Information Systems, Universite Laval, Canada; Software Engineering, Polytechnique Montreal, Canada; Toulouse Business School, France; Universite Laval, Canada","IEEE Software","15 Jan 2019","2019","36","1","34","41","Many open source software (OSS) products today are market leaders, 1 which suggests that the development of OSS is key to the growth of the software industry. OSS projects increasingly tend to be incorporated in large-scale projects or ""software ecosystems"" to reduce effort and accelerate innovation.","1937-4194","","10.1109/MS.2018.2874323","Fonds de Recherche du Québec - Fonds de la Recherche Scientifique; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8491285","Open source software;software ecosystem;cause-and-effect analysis;code quality;loss of contributors","Ecosystems;Open source software;Agile software development;Linux;Sociotechnical systems","DP industry;project management;public domain software;software development management","social problems;technical problems;open source software ecosystems;software industry;OSS projects;cause-and-effect analysis;open source software products;OSS ecosystem management","","","","15","","14 Oct 2018","","","IEEE","IEEE Magazines"
"Tailoring Product Ownership in Large-Scale Agile Projects: Managing Scale, Distance, and Governance","J. M. Bass; A. Haxby","Software Engineering, University of Salford, Salford, United Kingdom; Competa, The Hague, The Netherlands","IEEE Software","21 Feb 2019","2019","36","2","58","63","In large-scale agile projects, product owners undertake a range of challenging and varied activities beyond those conventionally associated with that role. We describe product-owner activities and behaviors that are valued by experienced product owners and their line managers.","1937-4194","","10.1109/MS.2018.2885524","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648277","","Agile software development;Companies;Standards;Stakeholders;Software development","organisational aspects;project management;risk management;software development management;software prototyping","product ownership;large-scale agile projects;varied activities;product-owner activities;experienced product owners","","","","12","","21 Feb 2019","","","IEEE","IEEE Magazines"
"A Hitchhiker’s Guide to Model-Driven Engineering for Data-Centric Systems","B. Combemale; J. A. Kienzle; G. Mussbacher; H. Ali; D. Amyot; M. Bagherzadeh; E. Batot; N. Bencomo; B. Benni; J. Bruel; J. Cabot; B. H. C. Cheng; P. Collet; G. Engels; R. Heinrich; J. Jezequel; A. Koziolek; S. Mosser; R. Reussner; H. Sahraoui; R. Saini; J. Sallou; S. Stinckwich; E. Syriani; M. Wimmer","IRISA, University of Rennes 1, Rennes, 35042 Bretagne, France; School of Computer Science, McGill University, Montreal, H2A 3A7 Quebec, Canada; School of Computer Science, McGill University, Montreal, Quebec, Canada; School of Computer Science, McGill University, Montreal, Quebec, Canada; EECS, University of Ottawa, Ottawa, Ontario, Canada; School of Computing, Queen's University, Kingston, Ontario, Canada; Departement d'Informatique et de Recherche Operationnelle, Universite de Montreal, Montreal, Quebec, Canada; ARLES team, INRIA, Le Chesnay, 78153 Ile de France, France; I3S, Nice University, Nice, Provence-Alpes-Cote d'Azur, France; IUT de Blagnac, IRIT, Blagnac, 31703 Midi-Pyrenees, France; IN3-UOC, Institucio Catalana de Recerca i Estudis Avancats, Castelldefels, 08860 Barcelona, Spain; Computer Science and Engineering, Michigan State University, East Lansing, Michigan 48824 United States; I3S (CNRS), University of Nice Sophia Antipolis, Nice, Alpes-Maritimes, France; Dept. of Computer Science, University of Paderborn, Paderborn, 33100 NRW, Germany; Institute for Program Structures and Data Organization, Karlsruhe Institute of Technology, Karlsruhe, BaWü, Germany; IRISA, IRISA-University of Rennes, Rennes, France, France; Software Design and -Quality, Karlsruhe Institute of Technology (KIT), Karlsruhe, 76131 Baden-Württemberg, Germany; Informatique, UQAM, Montreal, Quebec, Canada; Software Design and -Quality, Karlsruhe Institute of Technology (KIT), Karlsruhe, Baden-Württemberg, Germany; Departement d'Informatique et de Recherche Operationnelle, Universite de Montreal, Montreal, H3C 3J7 Quebec, Canada; School of Computer Science, McGill University, Montreal, Quebec, Canada; Geosciences, Universite de Rennes 1, Rennes, Bretagne, France; CS, United Nations University Institute in Macau, Macau, SAR, China; DIRO, Universite de Montreal, Montreal, Quebec, Canada; Software Engineering, Johannes Kepler Universitat Linz, Linz, n/a, Austria","IEEE Software","","2020","PP","99","0","0","","1937-4194","","10.1109/MS.2020.2995125","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9094197","","Data models;Unified modeling language;Mathematical model;Predictive models;Numerical models;Sociotechnical systems;Software","","","","","","","","15 May 2020","","","IEEE","IEEE Early Access Articles"
"Principle of Least Expressiveness","G. Fairbanks","Software Engineering, Google","IEEE Software","16 Apr 2019","2019","36","3","116","119","I'm always delighted to discover a connection between two ideas that I'm already fond of on their own, so I'd like to share a connection I found recently. The first idea is writing code that expresses my thinking about the problem domain, and the second is the principle of least expressiveness (PLE). The connection is that I can use the PLE to reveal my thinking about the problem domain, and because all ambiguity stops at the code, the act of programming using the PLE can help me simplify and debug the flawed ideas I have in my head.","1937-4194","","10.1109/MS.2019.2896876","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693078","","Decoding;Pragmatics;Computational modeling;Software development management;Programming;Resource description framework","program debugging","least expressiveness;problem domain;PLE;flawed ideas","","1","","3","","16 Apr 2019","","","IEEE","IEEE Magazines"
"Next-Generation Software Verification: An AI Perspective","S. Nejati","University of Ottawa, and University of Luxembourg","IEEE Software","19 Apr 2021","2021","38","3","126","130","In recent years, automated software verification has progressed significantly. We can now effectively explore complex software structures through automated testing or to prove properties of complex programs, such as compilers using formal methods. But, for the most part, software testing and formal software verification techniques have advanced independently with relatively few insights on how their research thrusts compare or can be combined.","1937-4194","","10.1109/MS.2021.3049322","NSERC Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407305","","Software testing;Program processors;Software engineering;Artificial intelligence;Next generation networking","","","","","","13","IEEE","19 Apr 2021","","","IEEE","IEEE Magazines"
"What Do We Know About Time Pressure in Software Development?","M. Kuutila; M. Mantyla; U. Farooq; M. Claes","ITEE/M3S, Oulun Yliopisto, Oulu, Oulun lääni, Finland; Computer Science, Oulun Yliopisto Teknillinen Tiedekunta, Oulu, 90014 Pohjois-Pohjanmaa, Finland; ITEE/M3S, Oulun Yliopisto, Oulu, Oulun lääni, Finland; ITEE/M3S, Oulun Yliopisto, Oulu, Oulun lääni, Finland","IEEE Software","","2020","PP","99","0","0","Time Pressure means that time experienced by an individual is scarce in relation to the task demands at hand. In this article, we summarize findings and provide practitioner takeaways based on a systematic review of existing literature. We find that most empirical evidence supports reduced quality, increased productivity, and negative effects on individuals under time pressure. Time pressure is caused by company culture, poor effort estimates, and project management. The effects of time pressure can be explained by Challenge and Hindrance time pressure, the Yerkes-Dodson Law and The Job Demands-Resources model. Finally we conclude the article by giving practitioner takeaways related to minimizing the negative effects of time pressure.","1937-4194","","10.1109/MS.2020.3020784","KAUTE-Säätiö; Academy of Finland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9184214","","Software engineering;Software;Task analysis;Companies;Estimation;Project management;Schedules","","","","","","","","1 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Is Requirements-Engineering Research Delivering What It Promised?: A Review of Its Accomplishments and Opportunities After 10 Years","B. Tenbergen; M. Daun","Computer Science, State University of New York at Oswego, United States; University of Duisburg-Essen, Germany","IEEE Software","17 Jun 2019","2019","36","4","6","11","In the 1990s, it was recognized that requirements engineering (RE) laid the foundation for high-quality software. Since then, a substantial research community has formed and set out to enable pract it ioners in the 21st century to systematically adopt proven strategies to solve common development challenges and to enable the engineering of innovative solutions and product features. But is contemporary RE research producing what it set out to deliver? In this article, we provide a brief overview over the accomplishments of the past 10 years and identify open opportunities.","1937-4194","","10.1109/MS.2019.2909127","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738149","","Software systems;Requirements engineering;Software engineering;Engineering education","formal specification;software quality","requirements engineering;high-quality software;RE research","","","","8","","17 Jun 2019","","","IEEE","IEEE Magazines"
"Correction","",,"IEEE Software","15 Apr 2020","2020","37","3","92","92","In the “Guest Editors’ Introduction” column published in the January/February issue of IEEE Software [1], the guest editors mistakenly omitted the name of the third guest editor: Smita Ghaisas should have been included in the byline as follows: Rick Kazman, Liliana Pasquale, and Smita Ghaisas. The omitted bio is included here.","1937-4194","","10.1109/MS.2020.2971895","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068302","","Software engineering;Object recognition;Requirements engineering;Software;Cloud computing;Data mining;Web 2.0","","","","","","1","","15 Apr 2020","","","IEEE","IEEE Magazines"
"Sentiment Classification Using N-Gram Inverse Document Frequency and Automated Machine Learning","R. Maipradit; H. Hata; K. Matsumoto","Information Science, Nara Institute of Science and Technology, Japan; Nara Institute of Science and Technology, Japan; Science and Technology, Nara Institute of Science and Technology, Japan","IEEE Software","15 Aug 2019","2019","36","5","65","70","We propose a sentiment classification method with a general machine-learning framework. In comparison to publicly available data sets, our method achieved the highest F1 values in positive and negative sentences on all data sets.","1937-4194","","10.1109/MS.2019.2919573","Japan Society for the Promotion of Science; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8725481","Automated machine learning;N-gram IDF;Sentiment classification","Classification;Machine learning;Feature extraction;Software engineering;Training data;Sentiment analysis;Machine learning","learning (artificial intelligence);pattern classification;sentiment analysis","sentiment classification method;general machine-learning framework;data sets;n-gram inverse document frequency;automated machine learning;positive sentences;negative sentences","","","","14","","29 May 2019","","","IEEE","IEEE Magazines"
"Conference Highlights: JIT Fault Prevention, Motivated Modeling, Security in Requirements, and Improving Team Performance","J. C. Carver; B. Penzenstadler; L. L. Minku; R. Colomo-Palacios; X. Larrucea","Computer Science, University of Alabama, United States; Chalmers/Gothenburg University, Sweden; Computer Science, University of Birmingham; Computer Sciences, Ostfold University College, Halden, Norway; Basque Research and Technology Alliance, TECNALIA, Spain","IEEE Software","19 Jun 2020","2020","37","4","83","86","This issue's practitioners' Digest reports on papers from the 2018 International Conference on Mining Sof tware Repositories, the 2019 International Conference on Requirements Engineering, and the 2019 European Conference on Software Process Improvement. Feedback or suggestions are welcome. In addition, if you try or adopt any of the practices included in this article, please send me and the author(s) of the paper(s) a note about your experiences.","1937-4194","","10.1109/MS.2020.2986840","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121617","","Security;Software engineering;Requirements engineering;Cloning;Big Data;Computer science;Data mining","","","","","","4","","19 Jun 2020","","","IEEE","IEEE Magazines"
"Release Early, Release Often, and Watch Your Users' Emotions: Lessons From Emotional Patterns","D. Martens; W. Maalej","Applied Software Technology, University of Hamburg, Germany; Applied Software Technology, University of Hamburg, Germany","IEEE Software","15 Aug 2019","2019","36","5","32","37","App stores are highly competitive markets, and unexpected app changes might incite even loyal users to explore alternative apps. In this article, we present five release lessons, from emotional patterns identified using sentiment analysis tools, to assist app vendors maintain positive emotions and gain competitive advantages.","1937-4194","","10.1109/MS.2019.2923603","European Union Horizon 2020 Project OpenReq; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738898","","Emotion recognition;Software tools;Software engineering;Sentiment analysis;Market research;Google;Computer applications","emotion recognition;mobile computing;sentiment analysis","app stores;alternative apps;emotional patterns;sentiment analysis tools;app vendors;users emotions","","4","","15","","18 Jun 2019","","","IEEE","IEEE Magazines"
"Combined Intuition and Rationality Increases Software Feature Novelty for Female Software Designers","C. Pretorius; M. Razavian; K. Eling; F. Langerak","Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands; Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands; Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands; Industrial Engineering, Eindhoven University of Technology, Eindhoven, 5600 MB, The Netherlands","IEEE Software","15 Feb 2021","2021","38","2","64","69","Different cognitive styles can promote novelty when designing software. Through a detailed experiment, we found that female practitioners who had a preference for more than one cognitive style (intuition and rationality) produced the most novel software features of all the participants.","1937-4194","","10.1109/MS.2020.3043663","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9286837","","Software engineering;Task analysis;Software design;Particle measurements;Atmospheric measurements;Informatics","gender issues;software development management","software features;software feature novelty;cognitive style;female practitioners;detailed experiment;female software designers","","","","15","IEEE","8 Dec 2020","","","IEEE","IEEE Magazines"
"Test Fatigue","G. J. Holzmann",Nimble Research,"IEEE Software","19 Jun 2020","2020","37","4","11","16","As the recent coronavirus outbreak has made painfully clear, the quantity and quality of our test efforts determine what defect rates we measure. If you don't test, or test poorly, you will discover few defects and may be tempted to draw the wrong conclusions about the quality of whatever it was that you were testing.","1937-4194","","10.1109/MS.2020.2986107","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121619","","Complexity theory;Measurement;Switches;Software engineering;Standards;Reliability;Software testing","diseases;epidemics;fatigue;medical computing;testing","test fatigue;defect rates;coronavirus outbreak","","","","7","","19 Jun 2020","","","IEEE","IEEE Magazines"
"Coverage Prediction for Accelerating Compiler Testing","J. Chen; G. Wang; D. Hao; Y. Xiong; H. Zhang; L. Zhang; B. Xie","Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China; University of Newcastle, Newcastle, NSW, Australia; Institute of Software, EECS, Peking University, Beijing, China; Institute of Software, EECS, Peking University, Beijing, China","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","261","278","Compilers are one of the most fundamental software systems. Compiler testing is important for assuring the quality of compilers. Due to the crucial role of compilers, they have to be well tested. Therefore, automated compiler testing techniques (those based on randomly generated programs) tend to run a large number of test programs (which are test inputs of compilers). The cost for compilation and execution for these test programs is significant. These techniques can take a long period of testing time to detect a relatively small number of compiler bugs. That may cause many practical problems, e.g., bringing a lot of costs including time costs and financial costs, and delaying the development/release cycle. Recently, some approaches have been proposed to accelerate compiler testing by executing test programs that are more likely to trigger compiler bugs earlier according to some criteria. However, these approaches ignore an important aspect in compiler testing: different test programs may have similar test capabilities (i.e., testing similar functionalities of a compiler, even detecting the same compiler bug), which may largely discount their acceleration effectiveness if the test programs with similar test capabilities are executed all the time. Test coverage is a proper approximation to help distinguish them, but collecting coverage dynamically is infeasible in compiler testing since most test programs are generated on the fly by automatic test-generation tools like Csmith. In this paper, we propose the first method to predict test coverage statically for compilers, and then propose to prioritize test programs by clustering them according to the predicted coverage information. The novel approach to accelerating compiler testing through coverage prediction is called COP (short for COverage Prediction). Our evaluation on GCC and LLVM demonstrates that COP significantly accelerates compiler testing, achieving an average of 51.01 percent speedup in test execution time on an existing dataset including three old release versions of the compilers and achieving an average of 68.74 percent speedup on a new dataset including 12 latest release versions. Moreover, COP outperforms the state-of-the-art acceleration approach significantly by improving $17.16\%\sim 82.51\%$17.16%∼82.51% speedups in different settings on average.","1939-3520","","10.1109/TSE.2018.2889771","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8588375","Compiler testing;test prioritization;machine learning","Testing;Program processors;Computer bugs;Life estimation;Acceleration;Optimization;Electromagnetic interference","","","","3","","86","IEEE","25 Dec 2018","","","IEEE","IEEE Journals"
"Automatic Mining of Opinions Expressed About APIs in Stack Overflow","G. Uddin; F. Khomh","School of Computer Science, McGill University, Montreal, QC, Canada; SWAT Team, Ecole Polytechnique de Montréal, QC, Canada","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","522","559","With the proliferation of online developer forums, developers share their opinions about the APIs they use. The plethora of such information can present challenges to the developers to get quick but informed insights about the APIs. To understand the potential benefits of such API reviews, we conducted a case study of opinions in Stack Overflow using a benchmark dataset of 4,522 sentences. We observed that opinions about diverse API aspects (e.g., usability) are prevalent and offer insights that can shape developers' perception and decisions related to software development. Motivated by the finding, we built a suite of techniques to automatically mine and categorize opinions about APIs from forum posts. First, we detect opinionated sentences in the forum posts. Second, we associate the opinionated sentences to the API mentions. Third, we detect API aspects (e.g., performance, usability) in the reviews. We developed and deployed a tool called Opiner, supporting the above techniques. Opiner is available online as a search engine, where developers can search for APIs by their names to see all the aggregated opinions about the APIs that are automatically mined and summarized from developer forums.","1939-3520","","10.1109/TSE.2019.2900245","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643972","API;opinion;categorization;review;API aspect;API review mining","Benchmark testing;Usability;Search engines;Java;Data mining;Tools","application program interfaces;data handling;data mining;natural language processing;search engines;text analysis","aggregated opinions;opinionated sentences;forum posts;software development;developers;diverse API aspects;API reviews;quick but informed insights;online developer forums;Stack Overflow;opinions expressed","","6","","124","IEEE","19 Feb 2019","","","IEEE","IEEE Journals"
"A Systematic Literature Review on Bad Smells–5 W's: Which, When, What, Who, Where","E. V. d. P. Sobrinho; A. De Lucia; M. d. A. Maia","Department of Electrical Engineering, Federal University of Triângulo Mineiro, Uberaba, Brazil; University of Salerno, Fisciano, (SA), Italy; Faculty of Computing, Federal University of Uberlândia, Uberlândia, Brazil","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","17","66","Bad smells are sub-optimal code structures that may represent problems needing attention. We conduct an extensive literature review on bad smells relying on a large body of knowledge from 1990 to 2017. We show that some smells are much more studied in the literature than others, and also that some of them are intrinsically inter-related (which). We give a perspective on how the research has been driven across time (when). In particular, while the interest in duplicated code emerged before the reference publications by Fowler and Beck and by Brown et al., other types of bad smells only started to be studied after these seminal publications, with an increasing trend in the last decade. We analyzed aims, findings, and respective experimental settings, and observed that the variability of these elements may be responsible for some apparently contradictory findings on bad smells (what). Moreover, we could observe that, in general, papers tend to study different types of smells at once. However, only a small percentage of those papers actually investigate possible relations between the respective smells (co-studies), i.e., each smell tends to be studied in isolation. Despite of a few relations between some types of bad smells have been investigated, there are other possible relations for further investigation. We also report that authors have different levels of interest in the subject, some of them publishing sporadically and others continuously (who). We observed that scientific connections are ruled by a large “small world” connected graph among researchers and several small disconnected graphs. We also found that the communities studying duplicated code and other types of bad smells are largely separated. Finally, we observed that some venues are more likely to disseminate knowledge on Duplicate Code (which often is listed as a conference topic on its own), while others have a more balanced distribution among other smells (where). Finally, we provide a discussion on future directions for bad smell research.","1939-3520","","10.1109/TSE.2018.2880977","Fundação de Amparo à Pesquisa do Estado de Minas Gerais; Conselho Nacional de Desenvolvimento Científico e Tecnológico; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8532309","Software maintenance;reengineering;bad smell","Systematics;Bibliographies;Software;Measurement;Organizations;Tools;Cloning","graph theory;program diagnostics;software maintenance","systematic literature review;bad smells;duplicated code;possible relations;bad smell research;suboptimal code structures;small world connected graph","","2","","417","IEEE","11 Nov 2018","","","IEEE","IEEE Journals"
"Efficient Summary Reuse for Software Regression Verification","F. He; Q. Yu; L. Cai","School of Software, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: hefei@tsinghua.edu.cn); School of Software, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: yuqianshan@foxmail.com); School of Software, Tsinghua University, 12442 Beijing, Beijing, China, (e-mail: limingcai0101@yeah.net)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Software systems evolve throughout their life cycles. Many revisions are produced over time. Verifying each revision of the software is impractical. Regression verification suggests reusing intermediate results from the previous verification runs. This paper studies regression verification via summary reuse. Not only procedure summaries, but also loop summaries are proposed to be reused. This paper proposes a fully automatic regression verification technique in the context of CEGAR. A lazy counterexample analysis technique is developed to improve the efficiency of summary reuse. We performed extensive experiments on two large sets of industrial programs (3,675 revisions of 488 Linux kernel device drivers). Results show that our summary reuse technique saves 84% to 93% analysis time of the regression verification.","1939-3520","","10.1109/TSE.2020.3021477","National Natural Science Foundation of China; National Key RD Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9186032","Regression Verification;Program Verification;Abstraction Refinement;Summary Reuse","Task analysis;Performance evaluation;Linux;Device drivers;Safety;Interpolation","","","","","","","","3 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Adaptive Test Case Allocation, Selection and Generation Using Coverage Spectrum and Operational Profile","A. Bertolino; B. Miranda; R. Pietrantuono; S. Russo","ISTI - CNR, Pisa, PI, Italy; Federal University of Pernambuco, Recife, PE, Brazil; Università degli Studi di Napoli Federico II, Napoli, Italy; Università degli Studi di Napoli Federico II, Napoli, Italy","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","881","898","We present an adaptive software testing strategy for test case allocation, selection and generation, based on the combined use of operational profile and coverage spectrum, aimed at achieving high delivered reliability of the program under test. Operational profile-based testing is a black-box technique considered well suited when reliability is a major concern, as it selects the test cases having the largest impact on failure probability in operation. Coverage spectrum is a characterization of a program’s behavior in terms of the code entities (e.g., branches, statements, functions) that are covered as the program executes. The proposed strategy - named covrel+ - complements operational profile information with white-box coverage measures, so as to adaptively select/generate the most effective test cases for improving reliability as testing proceeds. We assess covrel+ through experiments with subjects commonly used in software testing research, comparing results with traditional operational testing. The results show that exploiting operational and coverage data in an integrated adaptive way allows generally to outperform operational testing at achieving a given reliability target, or at detecting faults under the same testing budget, and that covrel+ has greater ability than operational testing in detecting hard-to-detect faults.","1939-3520","","10.1109/TSE.2019.2906187","PRIN 2015; Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669842","Software testing;reliability;operational testing;random testing;sampling","Software reliability;Resource management;Software testing;Subspace constraints;Test pattern generators","","","","","","51","IEEE","19 Mar 2019","","","IEEE","IEEE Journals"
"Leveraging Historical Associations between Requirements and Source Code to Identify Impacted Classes","D. Falessi; J. Roll; J. L. C. Guo; J. Cleland-Huang","California Polytechnic State University, San Luis Obispo, CA, USA; California Polytechnic State University, San Luis Obispo, CA, USA; School of Computer Science, McGill University, Montreal, QC, Canada; Computer Science and Engineering, University of Notre Dame, South Bend, IN, USA","IEEE Transactions on Software Engineering","16 Apr 2020","2020","46","4","420","441","As new requirements are introduced and implemented in a software system, developers must identify the set of source code classes which need to be changed. Therefore, past effort has focused on predicting the set of classes impacted by a requirement. In this paper, we introduce and evaluate a new type of information based on the intuition that the set of requirements which are associated with historical changes to a specific class are likely to exhibit semantic similarity to new requirements which impact that class. This new Requirements to Requirements Set (R2RS) family of metrics captures the semantic similarity between a new requirement and the set of existing requirements previously associated with a class. The aim of this paper is to present and evaluate the usefulness of R2RS metrics in predicting the set of classes impacted by a requirement. We consider 18 different R2RS metrics by combining six natural language processing techniques to measure the semantic similarity among texts (e.g., VSM) and three distribution scores to compute overall similarity (e.g., average among similarity scores). We evaluate if R2RS is useful for predicting impacted classes in combination and against four other families of metrics that are based upon temporal locality of changes, direct similarity to code, complexity metrics, and code smells. Our evaluation features five classifiers and 78 releases belonging to four large open-source projects, which result in over 700,000 candidate impacted classes. Experimental results show that leveraging R2RS information increases the accuracy of predicting impacted classes practically by an average of more than 60 percent across the various classifiers and projects.","1939-3520","","10.1109/TSE.2018.2861735","Cal Poly SURP; Cal Poly RSCA; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423658","Impact analysis;mining software repositories;traceability","Measurement;Semantics;Natural language processing;Complexity theory;Open source software;Task analysis","public domain software;software maintenance;software metrics;software quality;text analysis","historical associations;impacted classes;source code classes;semantic similarity;existing requirements;R2RS metrics;leveraging R2RS information;requirements to requirements set;VSM;open-source projects","","","","122","IEEE","31 Jul 2018","","","IEEE","IEEE Journals"
"Identifying Failure-Causing Schemas in the Presence of Multiple Faults","X. Niu; C. Nie; J. Y. Lei; H. Leung; X. Wang","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA; Department of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong; Department of Computer Science, University of Texas at San Antonio, San Antonio, TX, USA","IEEE Transactions on Software Engineering","12 Feb 2020","2020","46","2","141","162","Combinatorial testing (CT) has been proven effective in revealing the failures caused by the interaction of factors that affect the behavior of a system. The theory of Minimal Failure-Causing Schema (MFS) has been proposed to isolate the cause of a failure after CT. Most algorithms that aim to identify MFS focus on handling a single fault in the System Under Test (SUT). However, we argue that multiple faults are more common in practice, under which masking effects may be triggered so that some failures cannot be observed. The traditional MFS theory lacks a mechanism to handle such effects; hence, they may incorrectly isolate the MFS. To address this problem, we propose a new MFS model that takes into account multiple faults. We first formally analyze the impact of the multiple faults on existing MFS identifying algorithms, especially in situations where masking effects are triggered by multiple faults. We then develop an approach that can assist traditional algorithms to better handle multiple faults. Empirical studies were conducted using several kinds of open-source software, which showed that multiple faults with masking effects do negatively affect traditional MFS identifying approaches and that our approach can help to alleviate these effects.","1939-3520","","10.1109/TSE.2018.2844259","National Key Research and Development Plan; National Science Foundation; U.S. Department of Homeland Security; National Institute of Standards and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8372636","Software testing;combinatorial testing;failure-causing schemas;masking effects","Testing;Bars;Fault diagnosis;Computer bugs;Software algorithms;Open source software","fault diagnosis;program testing;software fault tolerance","masking effects;MFS theory;minimal failure-causing schema;combinatorial testing;CT;system under test;SUT;open-source software","","4","","51","IEEE","5 Jun 2018","","","IEEE","IEEE Journals"
"How Developers Choose Names","D. Feitelson; A. Mizrahi; N. Noy; A. Ben Shabat; O. Eliyahu; R. Sheffer","Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: feit@cs.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: ayelet.mizrahi@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: nofar.noy@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: aviad.benshabat@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: or.eliyahu@mail.huji.ac.il); Department of Computer Science, Hebrew University of Jerusalem, 26742 Jerusalem, - Israel (e-mail: roysheffer7@gmail.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The names of variables and functions serve as implicit documentation and are instrumental for program comprehension. But choosing good meaningful names is hard. We perform a sequence of experiments in which a total of 334 subjects are required to choose names in given programming scenarios. The first experiment shows that the probability that two developers would select the same name is low: in the 47 instances in our experiments the median probability was only 6.9%. At the same time, given that a specific name is chosen, it is usually understood by the majority of developers. Analysis of the names given in the experiment suggests a model where naming is a (not necessarily cognizant or serial) three-step process: (1) selecting the concepts to include in the name, (2) choosing the words to represent each concept, and (3) constructing a name using these words. A followup experiment, using the same experimental setup, then checked whether using this model explicitly can improve the quality of names. The results were that names selected by subjects using the model were judged by two independent judges to be superior to names chosen in the original experiment by a ratio of two-to-one. Using the model appears to encourage the use of more concepts and longer names.","1939-3520","","10.1109/TSE.2020.2976920","Israel Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9018121","variable naming;code comprehension","Programming profession;Documentation;Natural languages;Unified modeling language","","","","","","","","28 Feb 2020","","","IEEE","IEEE Early Access Articles"
"Service Candidate Identification from Monolithic Systems Based on Execution Traces","W. Jin; T. Liu; Y. Cai; R. Kazman; R. Mo; Q. Zheng","Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xian, Shaanxi, China; Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xian, Shaanxi, China; Department of Computer Science, Drexel University, Philadelphia, PA, USA; Department of Information Technology Management, University of Hawaii, Honolulu, HI, USA; Department of Computer Science, Drexel University, Philadelphia, PA, USA; Ministry of Education Key Laboratory of Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xian, Shaanxi, China","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","987","1007","Monolithic systems increasingly suffer from maintainability and scalability issues as they grow in functionality, size, and complexity. It is widely believed that (micro)service-based architectures can alleviate these problems as each service is supposed to have the following characteristics: clearly defined functionality, sufficient modularity, and the ability to evolve independently. Industrial practices show that service extraction from a legacy monolithic system is labor-intensive and complex. Existing work on service candidate identification aims to group entities of a monolithic system into potential service candidates, but this process has two major challenges: first, it is difficult to extract service candidates with consistent quality; second, it is hard to evaluate the identified service candidates regarding the above three characteristics. To address these challenges, this paper proposes the Functionality-oriented Service Candidate Identification (FoSCI) framework to identify service candidates from a monolithic system. Our approach is to record the monolith's execution traces, and extract services candidates using a search-based functional atom grouping algorithm. We also contribute a comprehensive service candidate evaluation suite that uses interface information, structural/conceptual dependency, and commit history. This evaluation system consists of 8 metrics, measuring functionality, modularity, and evolvability respectively of identified service candidates. We compare FoSCI with three existing methods, using 6 widely-used open-source projects as our evaluation subjects. Our results show that FoSCI outperforms existing methods in most measures.","1939-3520","","10.1109/TSE.2019.2910531","National Key Research and Development Program of China; National Natural Science Foundation of China; Ministry of Education Innovation Research Team; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686152","Microservice;monolith decomposition;service candidate;execution trace;functionality;modularity;evolvability","Software;Atomic measurements;Frequency measurement;Testing;Computer architecture;History","","","","7","","52","IEEE","11 Apr 2019","","","IEEE","IEEE Journals"
"Semantic Learning and Emulation Based Cross-platform Binary Vulnerability Seeker","J. Gao; Y. Jiang; Z. Liu; X. Yang; C. Wang; X. Jiao; Z. Yang; J. Sun","School of Software, Institute of Software System and Engineering, Beijing, Beijing China (e-mail: gaojian094@gmail.com); Dept.CST, Tsinghua university, Beijing, Beijing China 100084 (e-mail: jiangyu198964@126.com); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: zhe.liu@nuaa.edu.cn); School of Software, Institute of Software System and Engineering, Beijing, Beijing China (e-mail: yangx16@mails.tsinghua.edu.cn); School of Software, Institute of Software System and Engineering, Beijing, Beijing China (e-mail: wangcong15@mails.tsinghua.edu.cn); Computer Science and Engineering, ucsd, Sandiego, California United States (e-mail: xujiao@eng.ucsd.edu); Computer Science, Western Michigan University, Kalamazoo, Michigan United States 49008 (e-mail: zijiang.yang@wmich.edu); School of Software, Tsinghua University, Beijing 100084, Beijing China (e-mail: sunjg@tsinghua.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Clone detection is widely exploited for software vulnerability search. The approaches based on source code analysis cannot be applied to binary clone detection because the same source code can produce significantly different binaries due to different operating systems, microprocessor architectures and compilers. In this paper, we present BinSeeker, a cross-platform binary seeker that integrates semantic learning and emulation. With the help of the labeled semantic flow graph, BinSeeker can quickly identify M candidate functions that are most similar to the vulnerability from the target binary. The value of M is relatively large so this semantic learning procedure essentially eliminates those functions that are very unlikely to have the vulnerability. Then, semantic emulation is conducted on these M candidates to obtain their dynamic signature sequences. By comparing signature sequences, BinSeeker produces top-N functions that exhibit most similar behavior to that of the vulnerability. With fast filtering of semantic learning and accurate comparison of semantic emulation, BinSeeker seeks vulnerability precisely with little overhead. The experiments on six widely used programs with fifteen known CVE vulnerabilities demonstrate that BinSeeker outperforms three state-of-the-art tools Genius, Gemini and CACompare.","1939-3520","","10.1109/TSE.2019.2956932","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918305","semantic emulation;semantic learning;cross-platform binary;vulnerability search;neural network","Drilling machines;Process control;Automation;Rocks;Tools","","","","1","","","","2 Dec 2019","","","IEEE","IEEE Early Access Articles"
"Today Was a Good Day: The Daily Life of Software Developers","A. N. Meyer; E. T. Barr; C. Bird; T. Zimmermann","Department of Informatics, University of Zurich, Zürich, Switzerland; University College London, London, United Kingdom; Microsoft Research, Redmond, WA, USA; Microsoft Research, Redmond, WA, USA","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","863","880","What is a good workday for a software developer? What is a typical workday? We seek to answer these two questions to learn how to make good days typical. Concretely, answering these questions will help to optimize development processes and select tools that increase job satisfaction and productivity. Our work adds to a large body of research on how software developers spend their time. We report the results from 5,971 responses of professional developers at Microsoft, who reflected about what made their workdays good and typical, and self-reported about how they spent their time on various activities at work. We developed conceptual frameworks to help define and characterize developer workdays from two new perspectives: good and typical. Our analysis confirms some findings in previous work, including the fact that developers actually spend little time on development and developers’ aversion for meetings and interruptions. It also discovered new findings, such as that only 1.7 percent of survey responses mentioned emails as a reason for a bad workday, and that meetings and interruptions are only unproductive during development phases; during phases of planning, specification and release, they are common and constructive. One key finding is the importance of agency, developers’ control over their workday and whether it goes as planned or is disrupted by external factors. We present actionable recommendations for researchers and managers to prioritize process and tool improvements that make good workdays typical. For instance, in light of our finding on the importance of agency, we recommend that, where possible, managers empower developers to choose their tools and tasks.","1939-3520","","10.1109/TSE.2019.2904957","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8666786","Software developer workdays;productivity;job satisfaction;good workdays;typical workdays;quantified workplace","Software;Productivity;Task analysis;Encoding;Tools;Collaboration;Birds","","","","4","","111","IEEE","13 Mar 2019","","","IEEE","IEEE Journals"
"Automatic Generation of Tests to Exploit XML Injection Vulnerabilities in Web Applications","S. Jan; A. Panichella; A. Arcuri; L. Briand","University of Luxembourg, Esch-sur-Alzette, Luxembourg; University of Luxembourg, Esch-sur-Alzette, Luxembourg; University of Luxembourg, Esch-sur-Alzette, Luxembourg; University of Luxembourg, Esch-sur-Alzette, Luxembourg","IEEE Transactions on Software Engineering","16 Apr 2019","2019","45","4","335","362","Modern enterprise systems can be composed of many web services (e.g., SOAP and RESTful). Users of such systems might not have direct access to those services, and rather interact with them through a single-entry point which provides a GUI (e.g., a web page or a mobile app). Although the interactions with such entry point might be secure, a hacker could trick such systems to send malicious inputs to those internal web services. A typical example is XML injection targeting SOAP communications. Previous work has shown that it is possible to automatically generate such kind of attacks using search-based techniques. In this paper, we improve upon previous results by providing more efficient techniques to generate such attacks. In particular, we investigate four different algorithms and two different fitness functions. A large empirical study, involving also two industrial systems, shows that our technique is effective at automatically generating XML injection attacks.","1939-3520","","10.1109/TSE.2017.2778711","European Research Council (ERC); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8125155","Evolutionary testing;XML injection;security testing","XML;Simple object access protocol;Testing;Service-oriented architecture","business data processing;graphical user interfaces;mobile computing;security of data;Web services;XML","search-based techniques;industrial systems;XML injection attacks;XML injection vulnerabilities;modern enterprise systems;single-entry point;mobile app;hacker;malicious inputs;SOAP communications;fitness functions;GUI;internal Web services;Web page;Web applications","","2","","71","","30 Nov 2017","","","IEEE","IEEE Journals"
"Observation-Enhanced QoS Analysis of Component-Based Systems","C. Paterson; R. Calinescu","Department of Computer Science, University of York, Heslington, York, United Kingdom; Department of Computer Science, University of York, Heslington, York, United Kingdom","IEEE Transactions on Software Engineering","14 May 2020","2020","46","5","526","548","We present a new method for the accurate analysis of the quality-of-service (QoS) properties of component-based systems. Our method takes as input a QoS property of interest and a high-level continuous-time Markov chain (CTMC) model of the analysed system, and refines this CTMC based on observations of the execution times of the system components. The refined CTMC can then be analysed with existing probabilistic model checkers to accurately predict the value of the QoS property. The paper describes the theoretical foundation underlying this model refinement, the tool we developed to automate it, and two case studies that apply our QoS analysis method to a service-based system implemented using public web services and to an IT support system at a large university, respectively. Our experiments show that traditional CTMC-based QoS analysis can produce highly inaccurate results and may lead to invalid engineering and business decisions. In contrast, our new method reduced QoS analysis errors by 84.4-89.6 percent for the service-based system and by 94.7-97 percent for the IT support system, significantly lowering the risk of such invalid decisions.","1939-3520","","10.1109/TSE.2018.2864159","Defence Science and Technology Laboratory; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428471","Quality of service;component-based systems;Markov models;probabilistic model checking","Quality of service;Unified modeling language;Analytical models;Markov processes;Probabilistic logic;Component architectures","formal verification;Markov processes;object-oriented programming;probability;quality of service;Web services","observation-enhanced QoS analysis;component-based systems;quality-of-service properties;high-level continuous-time Markov chain model;probabilistic model checkers;model refinement;service-based system;public Web services;IT support system;CTMC-based QoS analysis","","","","74","IEEE","7 Aug 2018","","","IEEE","IEEE Journals"
"Mining Likely Analogical APIs Across Third-Party Libraries via Large-Scale Unsupervised API Semantics Embedding","C. Chen; Z. Xing; Y. Liu; K. O. L. Xiong","Faculty of Information Technology, Monash University, Clayton, VIC, Australia; College of Engineering & Computer Science, Australian National University, Canberra, ACT, Australia; SCSE, Nanayng Technological University, Singapore; SCSE, Nanayng Technological University, Singapore","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","432","447","Establishing API mappings between third-party libraries is a prerequisite step for library migration tasks. Manually establishing API mappings is tedious due to the large number of APIs to be examined. Having an automatic technique to create a database of likely API mappings can significantly ease the task. Unfortunately, existing techniques either adopt supervised learning mechanism that requires already-ported or functionality similar applications across major programming languages or platforms, which are difficult to come by for an arbitrary pair of third-party libraries, or cannot deal with lexical gap in the API descriptions of different libraries. To overcome these limitations, we present an unsupervised deep learning based approach to embed both API usage semantics and API description (name and document) semantics into vector space for inferring likely analogical API mappings between libraries. Based on deep learning models trained using tens of millions of API call sequences, method names and comments of 2.8 millions of methods from 135,127 GitHub projects, our approach significantly outperforms other deep learning or traditional information retrieval (IR) methods for inferring likely analogical APIs. We implement a proof-of-concept website (https://similarapi.appspot.com) which can recommend analogical APIs for 583,501 APIs of 111 pairs of analogical Java libraries with diverse functionalities. This scale of third-party analogical-API database has never been achieved before.","1939-3520","","10.1109/TSE.2019.2896123","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8630054","Analogical API;word embedding;skip thoughts","Libraries;Semantics;Databases;Task analysis;Recurrent neural networks;Deep learning;Java","application program interfaces;data mining;database management systems;deep learning (artificial intelligence);Java;software libraries;unsupervised learning","unsupervised API semantics embedding;third-party analogical-API database;analogical Java libraries;API call sequences;analogical API mappings;API usage semantics;unsupervised deep learning;API descriptions;library migration tasks;third-party libraries","","8","","84","IEEE","30 Jan 2019","","","IEEE","IEEE Journals"
"SQAPlanner: Generating Data-Informed Software Quality Improvement Plans","D. Rajapaksha; C. Tantithamthavorn; C. Bergmeir; W. Buntine; J. Jiarpakdee; J. Grundy","Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: dilini.rajapakshahewaranasinghage@monash.edu); Information Technology, Monash University, 2541 Clayton, Victoria, Australia, 3800 (e-mail: chakkrit@monash.edu); Information Technology, Monash University, Melbourne, Australia, Melbourne, Victoria, Australia, (e-mail: christoph.bergmeir@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: Wray.Buntine@monash.edu); Information Technology, Monash University, Melbourne, Australia, Melbourne, Victoria, Australia, (e-mail: jirayus.jiarpakdee@monash.edu); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria, Australia, (e-mail: john.grundy@monash.edu)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Software Quality Assurance (SQA) planning aims to define proactive plans, such as defining maximum file size, to prevent the occurrence of software defects in future releases. To aid this, defect prediction models have been proposed to generate insights as the most important factors that are associated with software quality. Such insights that are derived from traditional defect models are far from actionable---i.e., practitioners still do not know what they should do or avoid to decrease the risk of having defects, and what is the risk threshold for each metric. A lack of actionable guidance and risk threshold can lead to inefficient and ineffective SQA planning processes. In this paper, we investigate the practitioners' perceptions of current SQA planning activities, current challenges of such SQA planning activities, and propose four types of guidance to support SQA planning. We then propose and evaluate our AI-Driven SQAPlanner approach, a novel approach for generating four types of guidance and their associated risk thresholds in the form of rule-based explanations for the predictions of defect prediction models. Finally, we develop and evaluate a visualization for our SQAPlanner approach. Through the use of qualitative survey and empirical evaluation, our results lead us to conclude that SQAPlanner is needed, effective, stable, and practically applicable. We also find that 80% of our survey respondents perceived that our visualization is more actionable. Thus, our SQAPlanner paves a way for novel research in actionable software analytics---i.e., generating actionable guidance on what should practitioners do and not do to decrease the risk of having defects to support SQA planning.","1939-3520","","10.1109/TSE.2021.3070559","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9394771","Software Quality Assurance;SQA Planning;Actionable Software Analytics;Explainable AI","Planning;Software;Predictive models;Visualization;Tools;Artificial intelligence;Software quality","","","","","","","IEEE","2 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Two-Phase Assessment Approach to Improve the Efficiency of Refactoring Identification","A. Han; S. Cha","Department of Computer Science and Engineering, Korea University, Sungbuk-gu, Seoul, South Korea; Department of Computer Science and Engineering, Korea University, Sungbuk-gu, Seoul, South Korea","IEEE Transactions on Software Engineering","14 Oct 2018","2018","44","10","1001","1023","To automate the refactoring identification process, a large number of candidates need to be compared. Such an overhead can make the refactoring approach impractical if the software size is large and the computational load of a fitness function is substantial. In this paper, we propose a two-phase assessment approach to improving the efficiency of the process. For each iteration of the refactoring process, refactoring candidates are preliminarily assessed using a lightweight, fast delta assessment method called the Delta Table. Using multiple Delta Tables, candidates to be evaluated with a fitness function are selected. A refactoring can be selected either interactively by the developer or automatically by choosing the best refactoring, and the refactorings are applied one after another in a stepwise fashion. The Delta Table is the key concept enabling a two-phase assessment approach because of its ability to quickly calculate the varying amounts of maintainability provided by each refactoring candidate. Our approach has been evaluated for three large-scale open-source projects. The results convincingly show that the proposed approach is efficient because it saves a considerable time while still achieving the same amount of fitness improvement as the approach examining all possible candidates.","1939-3520","","10.1109/TSE.2017.2731853","Basic Science Research Program; National Research Foundation of Korea (NRF); Ministry of Education; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990580","Refactoring assessment;refactoring identification;maintainability improvement","Measurement;Couplings;Symmetric matrices;Open source software;Computational efficiency;System analysis and design","iterative methods;public domain software;software maintenance","two-phase assessment approach;refactoring identification process;fitness function;computational load;delta assessment method;lightweight method;delta table;large-scale open-source projects","","","","60","","25 Jul 2017","","","IEEE","IEEE Journals"
"Kernel Spectral Embedding Transfer Ensemble for Heterogeneous Defect Prediction","H. Tong; B. Liu; S. Wang","School of Reliability and Systems Engineering, Beihang University, 12633 Beijing, Beijing China 100083 (e-mail: tonghaonan@buaa.edu.cn); School of Reliability and Systems Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: liubin@buaa.edu.cn); School of Reliability and Systems Engineering, Beihang University, 12633 Beijing, Beijing China (e-mail: wangshihai@buaa.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Cross-project defect prediction (CPDP) refers to predicting defects in the target project lacking of defect data by using prediction models trained on the historical defect data of other projects (i.e., source data). However, CPDP requires the source and target projects have common metric set (CPDP-CM). Recently, heterogeneous defect prediction (HDP) has drawn the increasing attention, which predicts defects across projects having heterogeneous metric sets. However, building high-performance HDP methods remains a challenge owing to several serious challenges including class imbalance problem, nonlinear, and the distribution differences between source and target datasets. In this paper, we propose a novel kernel spectral embedding transfer ensemble (KSETE) approach for HDP. KSETE first addresses the class-imbalance problem of the source data and then tries to find the latent common feature space for the source and target datasets by combining kernel spectral embedding, transfer learning, and ensemble learning. Experiments are performed on 22 public projects in both HDP and CPDP-CM scenarios in terms of multiple well-known performance measures such as, AUC, G-Measure, and MCC. The experimental results show that (1) KSETE improves the performance over previous HDP methods by at least 22.7%, 138.9%, and 494.4% in terms of AUC, G-Measure, and MCC, respectively. (2) KSETE improves the performance over previous CPDP-CM methods by at least 4.5%, 30.2%, and 17.9% in AUC, G-Measure, and MCC, respectively. It can be concluded that the proposed KSETE is very effective in both the HDP scenario and the CPDP-CM scenario.","1939-3520","","10.1109/TSE.2019.2939303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823052","heterogeneous defect prediction;cross-project defect prediction;class imbalance learning;spectral embedding;transfer learning;ensemble learning;multiple kernel learning","Kernel;Predictive models;Software metrics;Correlation;Buildings;Data models","","","","1","","","","3 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Evolution of the Unix System Architecture: An Exploratory Case Study","D. Spinellis; P. C. Avgeriou","Department of Management Science and Technology, Athens University of Economics and Business, Athina, Attiki Greece (e-mail: dds@aueb.gr); Department of Mathematics and Computing Science, University of Groningen, Groningen, groningen Netherlands 9747 AG (e-mail: paris@cs.rug.nl)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Unix has evolved for almost five decades, shaping modern operating systems, key software technologies, and development practices. Studying the evolution of this remarkable system from an architectural perspective can provide insights on how to manage the growth of large, complex, and long-lived software systems. Along main Unix releases leading to the FreeBSD lineage we examine core architectural design decisions, the number of features, and code complexity, based on the analysis of source code, reference documentation, and related publications. We report that the growth in size has been uniform, with some notable outliers, while cyclomatic complexity has been religiously safeguarded. A large number of Unix-defining design decisions were implemented right from the very early beginning, with most of them still playing a major role. Unix continues to evolve from an architectural perspective, but the rate of architectural innovation has slowed down over the system's lifetime. Architectural technical debt has accrued in the forms of functionality duplication and unused facilities, but in terms of cyclomatic complexity it is systematically being paid back through what appears to be a self-correcting process. Some unsung architectural forces that shaped Unix are the emphasis on conventions over rigid enforcement, the drive for portability, a sophisticated ecosystem of other operating systems and development organizations, and the emergence of a federated architecture, often through the adoption of third-party subsystems. These findings have led us to form an initial theory on the architecture evolution of large, complex operating system software.","1939-3520","","10.1109/TSE.2019.2892149","Horizon 2020 Framework Programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8704965","Unix;Software Architecture;Software Evolution;Architecture Design Decisions;Operating Systems","Computer architecture;Complexity theory;Evolution (biology);Linux;Kernel","","","","","","","CCBY","2 May 2019","","","IEEE","IEEE Early Access Articles"
"A Look into Programmers’ Heads","N. Peitek; J. Siegmund; S. Apel; C. Kästner; C. Parnin; A. Bethmann; T. Leich; G. Saake; A. Brechmann","Leibniz Institute for Neurobiology Magdeburg, Magdeburg, Germany; University of Passau, Passau, Germany; University of Passau, Passau, Germany; Carnegie Mellon University, Pittsburgh, PA, USA; NC State University, Raleigh, NC, USA; Leibniz Institute for Neurobiology Magdeburg, Magdeburg, Germany; Metop Research Institute, Magdeburg, Germany; University of Magdeburg, Magdeburg, Germany; Leibniz Institute for Neurobiology Magdeburg, Magdeburg, Germany","IEEE Transactions on Software Engineering","20 Apr 2020","2020","46","4","442","462","Program comprehension is an important, but hard to measure cognitive process. This makes it difficult to provide suitable programming languages, tools, or coding conventions to support developers in their everyday work. Here, we explore whether functional magnetic resonance imaging (fMRI) is feasible for soundly measuring program comprehension. To this end, we observed 17 participants inside an fMRI scanner while they were comprehending source code. The results show a clear, distinct activation of five brain regions, which are related to working memory, attention, and language processing, which all fit well to our understanding of program comprehension. Furthermore, we found reduced activity in the default mode network, indicating the cognitive effort necessary for program comprehension. We also observed that familiarity with Java as underlying programming language reduced cognitive effort during program comprehension. To gain confidence in the results and the method, we replicated the study with 11 new participants and largely confirmed our findings. Our results encourage us and, hopefully, others to use fMRI to observe programmers and, in the long run, answer questions, such as: How should we train programmers? Can we train someone to become an excellent programmer? How effective are new languages and tools for program comprehension?","1939-3520","","10.1109/TSE.2018.2863303","DFG; Bavarian State Ministry of Education, Science; DFG; National Science Foundation; AFRL and DARPA; ERC; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8425769","Functional magnetic resonance imaging;program comprehension","Functional magnetic resonance imaging;Task analysis;Cognition;Brain;Programming;Blood","biomedical MRI;brain;cognition;Java;medical computing;neurophysiology","default mode network;Java;programming language reduced cognitive effort;language processing;working memory;brain regions;fMRI scanner;programming language;program comprehension;functional magnetic resonance imaging","","1","","112","IEEE","6 Aug 2018","","","IEEE","IEEE Journals"
"Empirical Assessment of Multimorphic Testing","P. Temple; M. Acher; J. M. Jezequel","Faculty of Computer Science, University of Namur, 54501 Namur, Belgium Belgium (e-mail: paul.temple@unamur.be); Computer Science, University of Rennes 1 / Inria / IRISA, Rennes, Ille et Vilaine France 35200 (e-mail: mathieu.acher@irisa.fr); Computer Science, University of Rennes 1 / Inria / IRISA, Rennes, Ille et Vilaine France (e-mail: Jean-Marc.Jezequel@irisa.fr)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The performance of software systems (such as speed, memory usage, correct identification rate) tends to be an evermore important concern, often nowadays on par with functional correctness for critical systems.Systematically testing these performance concerns is however extremely difficult, in particular because there exists no theory underpinning the evaluation of a performance test suite, i.e., to tell the software developer whether such a test suite is ""good enough"" or even whether a test suite is better than another one. This paper proposes to apply Multimorphic testing and empirically assess the effectiveness of performance test suites of software systems coming from various domains. By analogy with mutation testing, our core idea is to leverage the typical configurability of these systems, and to check whether it makes any difference in the outcome of the tests: i.e., are some tests able to ""kill"" underperforming system configurations? More precisely, we propose a framework for defining and evaluating the coverage of a test suite with respect to a quantitative property of interest. Such properties can be the execution time, the memory usage or the success rate in tasks performed by a software system. This framework can be used to assess whether a new test case is worth adding to a test suite or to select an optimal test suite with respect to a property of interest. We evaluate several aspects of our proposal through 3 empirical studies carried out in different fields: object tracking in videos, object recognition in images, and code generators.","1939-3520","","10.1109/TSE.2019.2926971","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8755468","software product lines;software testing;performance testing;test evaluation","Testing;Software measurement;Software systems;Videos;Task analysis;Generators","","","","","","","","4 Jul 2019","","","IEEE","IEEE Early Access Articles"
"An Integration Test Order Strategy to Consider Control Coupling","S. JIANG; M. Zhang; Y. Zhang; R. Wang; Q. Yu; J. W. Keung","School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China 221116 (e-mail: shjjiang@cumt.edu.cn); Computer Science, City University of Hong Kong, 53025 Kowloon, Hong Kong Hong Kong (e-mail: miazhang9-c@my.cityu.edu.hk); Mine Digitization Engineering Research Center of the Ministry of Education, School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: ymzhang@cumt.edu.cn); School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: rcwang@cumt.edu.cn); school of Computer Science and technology, Jiangsu Normal University, 12675 Xuzhou, Jiangsu China (e-mail: yuqiao@jsnu.edu.cn); Department of Computer Science, City University of Hong Kong, Kowloon, Kowloon Tong Hong Kong KLN (e-mail: Jacky.Keung@cityu.edu.hk)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Integration testing is a very important step in software testing. Existing methods evaluate the stubbing cost for class inte-gration test orders by considering only the interclass direct relationships such as inheritance, aggregation, and associa-tion, but they omit the interclass indirect relationship caused by control coupling, which can also affect the test orders and the stubbing cost. In this paper, we introduce an integration test order strategy to consider control coupling. We ad-vance the concept of transitive relationship to describe this kind of interclass dependency and propose a new measure-ment method to estimate the complexity of control coupling, which is the complexity of stubs created for a transitive rela-tionship. We evaluate our integration test order strategy on 10 programs on various scales. The results show that consid-ering the transitive relationship when generating class integration test orders can significantly reduce the stubbing cost for most programs and that our integration test order strategy obtains satisfactory results more quickly than other methods.","1939-3520","","10.1109/TSE.2019.2921965","National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province under grant; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8734013","control coupling;integration test order;software testing;stubbing cost","Couplings;Complexity theory;Measurement;Marine vehicles;Mathematical model;Software testing","","","","","","","","10 Jun 2019","","","IEEE","IEEE Early Access Articles"
"Recommending Participants for Collaborative Merge Sessions","C. d. S. Costa; J. J. Figueiredo; J. F. Pimentel; A. Sarma; L. G. P. Murta","Technology and Exacts Science Center, Universidade Federal do Acre, 37872 Rio Branco, Rio Branco Brazil (e-mail: catarinasouzacosta@gmail.com); Computing Institute, Universidade Federal do Acre, 37872 Rio Branco, AC Brazil (e-mail: jjcfigueiredo@ufac.br); Computing Institute, Fluminense Federal University, Niterói, Rio de Janeiro Brazil (e-mail: jpimentel@ic.uff.br); School of Electrical Engineering and Computer Science, Oregon State University, 2694 Corvallis, Oregon United States (e-mail: anita.sarma@oregonstate.edu); Computer Science, Universidade Federal Fluminense, Niterói, RJ Brazil 24210-240 (e-mail: leomurta@ic.uff.br)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Development of large projects often involves parallel work performed in multiple branches. Eventually, these branches need to be reintegrated through a merge operation. During merge, conflicts may arise and developers need to communicate to reach consensus about the desired resolution. For this reason, including the right developers to a collaborative merge session is fundamental. However, this task can be difficult especially when many different developers have made significant changes on each branch over a large number of files. In this paper, we present TIPMerge, an approach designed to recommend participants for collaborative merge sessions. TIPMerge analyzes the project history and builds a ranked list of developers who are the most appropriate to integrate a pair of branches (Developer Ranking) by considering developers' changes in the branches, in the previous history, and in the dependencies among files across branches. Simply selecting the top developers in such a ranking is easy, but is not effective for collaborative merge sessions as the top developers may have overlapping knowledge. To support collaborative merge, TIPMerge employs optimization techniques to recommend developers with complementary knowledge (Team Recommendation) aiming to maximize joint knowledge coverage. Our results show a mean normalized improvement of 49.5% (median 50.4%) for the joint knowledge coverage with the optimization techniques for assembling teams of three developers for collaborative merge in comparison to choosing the top-3 developers in the ranked list.","1939-3520","","10.1109/TSE.2019.2917191","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8716294","Version Control;Branch Merging;Collaborative Merge;Developer Recommendation;Optimization","Collaboration;History;Optimization;Data mining;Merging;Task analysis;Software","","","","","","","","16 May 2019","","","IEEE","IEEE Early Access Articles"
"makeSense: Simplifying the Integration of Wireless Sensor Networks into Business Processes","L. Mottola; G. P. Picco; F. J. Oppermann; J. Eriksson; N. Finne; H. Fuchs; A. Gaglione; S. Karnouskos; P. M. Montero; N. Oertel; K. Römer; P. Spieß; S. Tranquillini; T. Voigt","RISE Swedish Institute of Computer Science, Kista, Sweden; University of Trento, Trento, Italy; Graz University of Technology, Ultimo, NSW, Australia; RISE Swedish Institute of Computer Science, Kista, Sweden; RISE Swedish Institute of Computer Science, Kista, Sweden; SAP, Walldorf, Germany; University of Trento, Trento, Italy; SAP, Walldorf, Germany; Acciona Infraestructuras S.A. Alcobendas, Madrid, Spain; SAP, Walldorf, Germany; Graz University of Technology, Ultimo, NSW, Australia; SAP, Walldorf, Germany; University of Trento, Trento, Italy; RISE Swedish Institute of Computer Science, Kista, Sweden","IEEE Transactions on Software Engineering","12 Jun 2019","2019","45","6","576","596","A wide gap exists between the state of the art in developing Wireless Sensor Network (WSN) software and current practices concerning the design, execution, and maintenance of business processes. WSN software is most often developed based on low-level OS abstractions, whereas business process development leverages high-level languages and tools. This state of affairs places WSNs at the fringe of industry. The makeSense system addresses this problem by simplifying the integration of WSNs into business processes. Developers use BPMN models extended with WSN-specific constructs to specify the application behavior across both traditional business process execution environments and the WSN itself, which is to be equipped with application-specific software. We compile these models into a high-level intermediate language-also directly usable by WSN developers-and then into OS-specific deployment-ready binaries. Key to this process is the notion of meta-abstraction, which we define to capture fundamental patterns of interaction with and within the WSN. The concrete realization of meta-abstractions is application-specific; developers tailor the system configuration by selecting concrete abstractions out of the existing codebase or by providing their own. Our evaluation of makeSense shows that i) users perceive our approach as a significant advance over the state of the art, providing evidence of the increased developer productivity when using makeSense; ii) in large-scale simulations, our prototype exhibits an acceptable system overhead and good scaling properties, demonstrating the general applicability of makeSense; and, iii) our prototype-including the complete tool-chain and underlying system support-sustains a real-world deployment where estimates by domain specialists indicate the potential for drastic reductions in the total cost of ownership compared to wired and conventional WSN-based solutions.","1939-3520","","10.1109/TSE.2017.2787585","European Union 7th Framework Programme (FP7-ICT-2009-5); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240710","Business processes;wireless sensor networks;embedded software;internet of things","Wireless sensor networks;Business;Programming;Ventilation;Software;Concrete","business data processing;operating systems (computers);wireless sensor networks","wireless sensor networks;business processes;WSN software;low-level OS abstractions;makeSense system;WSN-specific constructs;application-specific software;OS-specific deployment-ready binaries;meta-abstraction;concrete abstractions;complete tool-chain;wired WSN-based solutions;high-level intermediate language;developer productivity;WSN developers;business process execution environments;business process development;high-level languages","","","","93","","27 Dec 2017","","","IEEE","IEEE Journals"
"Debugging of Behavioural Models using Counterexample Analysis","G. Barbon; V. Leroy; G. Salaun","LIG, Universite Grenoble Alpes, 27015 Saint-Martin-d'Heres, Rhone-Alpes France (e-mail: gianluca.barbon@gmail.com); LIG, Universite Grenoble Alpes, 133618 Saint-Martin-d'Heres, Rhone-Alpes France (e-mail: vincent.leroy@imag.fr); LIG, Universite Grenoble Alpes, 27015 Saint-Martin-d'Heres, Rhone-Alpes France (e-mail: gwen.salaun@inria.fr)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Model checking is an established technique for automatically verifying that a model satisfies a given temporal property. When the model violates the property, the model checker returns a counterexample, which is a sequence of actions leading to a state where the property is not satisfied. Understanding this counterexample for debugging the specification is a complicated task for several reasons: (i) the counterexample can contain a large number of actions, (ii) the debugging task is mostly achieved manually, and (iii) the counterexample does not explicitly highlight the source of the bug that is hidden in the model. This article presents a new approach that improves the usability of model checking by simplifying the comprehension of counterexamples. To do so, we first extract in the model all the counterexamples. Second, we define an analysis algorithm that identifies actions that make the model skip from incorrect to correct behaviours, making these actions relevant from a debugging perspective. Third, we develop a set of abstraction techniques to extract these actions from counterexamples. Our approach is fully automated by a tool we implemented and was applied on real-world case studies from various application areas for evaluation purposes.","1939-3520","","10.1109/TSE.2019.2915303","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708934","","Computer bugs;Debugging;Safety;Model checking;Task analysis;Tools;Analytical models","","","","","","","","7 May 2019","","","IEEE","IEEE Early Access Articles"
"Combinatorial Test Generation for Multiple Input Models with Shared Parameters","C. Rao; N. Li; Y. Lei; J. Guo; Y. Zhang; R. Kacker; D. R. R. Kuhn","School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan, China, 611756 (e-mail: changrao@my.swjtu.edu.cn); Research and Development, Dassault Systems, New York, New York, United States, (e-mail: nli1@gmu.edu); Computer Science and Engineering, The University of Texas at Arlington, Arlington, Texas, United States, 76019 (e-mail: ylei@cse.uta.edu); School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan, China, (e-mail: jguo_scce@home.swjtu.edu.cn); School of Information Science and Technology, Southwest Jiaotong University, 56711 Chengdu, Sichuan, China, (e-mail: ydzhang@home.swjtu.edu.cn); math division, National Institute of Standards & Technology, Gaithersburg, Maryland, United States, (e-mail: raghu.kacker@nist.gov); computer security division, National Institute of Standards & Technology, Gaithersburg, Maryland, United States, 20899 (e-mail: kuhn@nist.gov)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Combinatorial testing typically considers a single input model and creates a single test set that achieves t-way coverage. This paper addresses the problem of combinatorial test generation for multiple input models with shared parameters. We formally define the problem and propose an efficient approach to generating multiple test sets, one for each input model, that together satisfy t-way coverage for all of these input models while minimizing the amount of redundancy between these test sets. We report an experimental evaluation that applies our approach to five real-world applications. The results show that our approach can significantly reduce the amount of redundancy between the test sets generated for multiple input models and perform better than a post-optimization approach.","1939-3520","","10.1109/TSE.2021.3065950","Fundamental Research Funds for the Central Universities; China State Railway Corporation; China Scholarship Council; National Natural Science Foundation of China; National Institute of Standards and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9380551","Combinatorial Testing;T-way Test Generation;Multiple Input Models;Shared Parameters","Testing;Test pattern generators;Redundancy;Tools;Schedules;Presses;Information science","","","","","","","IEEE","17 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Managing Episodic Volunteers in Free/Libre/Open Source Software Communities","A. Barcomb; K. Stol; B. Fitzgerald; D. Riehle","Open Source Research Group, Friedrich-Alexander-Universitat Erlangen-Nurnberg Technische Fakultat, 88768 Erlangen, Bayern Germany (e-mail: ann@barcomb.org); Computer Science, University College Cork, Cork, Cork Ireland (e-mail: klaas-jan.stol@lero.ie); CSIS, Lero Irish Software Research Centre, Limerick, Limerick Ireland (e-mail: brian.fitzgerald@ul.ie); Computer Science, Friedrich-Alexander-Universitat Erlangen-Nurnberg, 9171 Erlangen, Bavaria Germany 91058 (e-mail: dirk@riehle.org)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","We draw on the concept of episodic volunteering (EV) from the general volunteering literature to identify practices for managing EV in free/libre/open source software (FLOSS) communities. Infrequent but ongoing participation is widespread, but the practices that community managers are using to manage EV, and their concerns about EV, have not been previously documented. We conducted a policy Delphi study involving 24 FLOSS community managers from 22 different communities. Our panel identified 16 concerns related to managing EV in FLOSS, which we ranked by prevalence. We also describe 65 practices for managing EV in FLOSS. Almost three-quarters of these practices are used by at least three community managers. We report these practices using a systematic presentation that includes context, relationships between practices, and concerns that they address. These findings provide a coherent framework that can help FLOSS community managers to better manage episodic contributors.","1939-3520","","10.1109/TSE.2020.2985093","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9057411","best practices;community management;episodic volunteering;free software;open source software","Software;Computer bugs;Organizations;Systematics;Lenses;Sustainable development;Object recognition","","","","","","","","6 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Detecting Bugs by Discovering Expectations and Their Violations","P. Bian; B. Liang; Y. Zhang; C. Yang; W. Shi; Y. Cai","Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; Renmin University of China, Beijing, China; State Key Laboratory of Computer Science, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Software Engineering","16 Oct 2019","2019","45","10","984","1001","Code mining has been proven to be a promising approach to inferring implicit programming rules for finding software bugs. However, existing methods may report large numbers of false positives and false negatives. In this paper, we propose a novel approach called EAntMiner to improve the effectiveness of code mining. EAntMiner elaborately reduces noises from statements irrelevant to interesting rules and different implementation forms of the same logic. During preprocessing, we employ program slicing to decompose the original source repository into independent sub-repositories. In each sub-repository, statements irrelevant to critical operations (automatically extracted from source code) are excluded and various semantics-equivalent implementations are normalized into a canonical form as far as possible. Moreover, to tackle the challenge that some bugs are difficult to be detected by mining frequent patterns as rules, we further developed a kNN-based method to identify them. We have implemented EAntMiner and evaluated it on four large-scale C systems. EAntMiner successfully detected 105 previously unknown bugs that have been confirmed by corresponding development communities. A set of comparative evaluations also demonstrate that EAntMiner can effectively improve the precision of code mining.","1939-3520","","10.1109/TSE.2018.2816639","National Natural Science Foundation of China; National 973 program of China; National Science and Technology Major Project of China; Youth Innovation Promotion Association of the Chinese Academy of Sciences; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8318656","Bug detection;code mining;program slicing;instance-based learning","Computer bugs;Data mining;Linux;Programming;Kernel;Semantics","data mining;nearest neighbour methods;program debugging;program slicing;program testing","code mining;implicit programming rules;software bugs;false positives;false negatives;EAntMiner;different implementation forms;frequent pattern mining;unknown bugs;kNN-based method;canonical form;semantics-equivalent implementations;source code;sub-repository;independent sub-repositories;original source repository;program slicing","","3","","66","","16 Mar 2018","","","IEEE","IEEE Journals"
"The ORIS Tool: Quantitative Evaluation of Non-Markovian Systems","M. Paolieri; M. Biagi; L. Carnevali; E. Vicario","Department of Computer Science, University of Southern California, 5116 Los Angeles, California United States (e-mail: paolieri@usc.edu); Department of Information Engineering, University of Florence, Florence, Florence Italy (e-mail: marco.biagi@unifi.it); Department of Information Engineering, University of Florence, Florence, Florence Italy 50139 (e-mail: laura.carnevali@unifi.it); Information Engineering department, University of Florence, Florence, Florence Italy 50139 (e-mail: enrico.vicario@unifi.it)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","We present the next generation of ORIS, a toolbox for quantitative evaluation of concurrent models with non-Markovian timers. The tool shifts the focus from timed models to stochastic ones: it includes a new graphical user interface, new analysis methods and a Java Application Programming Interface (API). Models can be specified as Stochastic Time Petri Nets (STPNs) through the graphical editor, validated using an interactive token game, and analyzed through several techniques to compute instantaneous or cumulative rewards. STPNs can also be exported as Java code to conduct extensive parametric studies through the Java library, now distributed as open-source. A well-engineered software architecture allows the user to implement new features for STPNs, new modeling formalisms, and new analysis methods. The most distinctive features of ORIS include transient and steady-state analysis of STPNs modeling Markov Regenerative Processes (MRPs), and transient analysis of STPNs modeling generalized semi-Markov processes. ORIS also supports state-space analysis of time Petri nets, simulation of STPNs, and standard analysis techniques for continuous-time Markov chains or MRPs with at most one non-exponential timer in each state. We illustrate the general workflow for the application of ORIS to the modeling and evaluation of non-functional requirements of software-intensive systems.","1939-3520","","10.1109/TSE.2019.2917202","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8719961","Quantitative Evaluation;Formal Methods;Stochastic Models;Concurrency;Stochastic Petri Nets;Non-Markovian Processes;Markov Regenerative Processes;Performance;Reliability;Software Tools and Libraries","Analytical models;Stochastic processes;Transient analysis;Java;Petri nets;Numerical models;Graphical user interfaces","","","","","","","","22 May 2019","","","IEEE","IEEE Early Access Articles"
"Entropy Based Software Reliability Analysis of Multi-Version Open Source Software","V. B. Singh; M. Sharma; H. Pham","University of Delhi, Delhi, India; University of Delhi, Delhi, India; Department of Industrial and Systems Engineering, Rutgers, State University of New Jersey, Piscataway, NJ","IEEE Transactions on Software Engineering","9 Dec 2018","2018","44","12","1207","1223","The number of issues fixed in the current release of the software is one of the factors which decides the next release of the software. The source code files get changed during fixing of these issues. The uncertainty arises due to these changes is quantified using entropy based measures. We developed a Non-Homogeneous Poisson Process model for Open Source Software to understand the fixing of issues across releases. Based on this model, optimal release-updating using entropy and maximizing the active user's satisfaction level subject to fixing of issues up to a desired level, is investigated as well. The proposed models have been validated on five products of the Apache open source project. The optimal release time estimated from the proposed model is close to the observed release time at different active user's satisfaction levels. The proposed decision model can assist management to appropriately determine the optimal release-update time. The proposed entropy based model for issues estimation shows improvement in performance for 21 releases out of total 23 releases, when compared with well-known traditional software reliability growth models, namely GO model [1] and S-shaped model [2] . The proposed model is also found statistically significant.","1939-3520","","10.1109/TSE.2017.2766070","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8081836","Entropy;feature improvement;new feature;release time problem;software repositories;cobb-douglas","Entropy;Software reliability;Software product lines;Computer bugs;Open source software","entropy;program diagnostics;public domain software;software maintenance;software reliability;source code (software);stochastic processes","multiversion Open Source Software;source code files;NonHomogeneous Poisson Process model;Apache open source project;GO model;S-shaped model;software reliability analysis;entropy","","4","","55","","24 Oct 2017","","","IEEE","IEEE Journals"
"Coordination Challenges in Large-Scale Software Development: A Case Study of Planning Misalignment in Hybrid Settings","S. Bick; K. Spohrer; R. Hoda; A. Scheerer; A. Heinzl","SAP SE, Walldorf, Germany; University of Mannheim, Mannheim, Germany; University of Auckland, Auckland, New Zealand; SAP SE, Walldorf, Germany; University of Mannheim, Mannheim, Germany","IEEE Transactions on Software Engineering","14 Oct 2018","2018","44","10","932","950","Achieving effective inter-team coordination is one of the most pressing challenges in large-scale software development. Hybrid approaches of traditional and agile development promise combining the overview and predictability of long-term planning on an inter-team level with the flexibility and adaptability of agile development on a team level. It is currently unclear, however, why such hybrids often fail. Our case study within a large software development unit of 13 teams at a global enterprise software company explores how and why a combination of traditional planning on an inter-team level and agile development on a team level can result in ineffective coordination. Based on a variety of data, including interviews with scrum masters, product owners, architects and senior management, and using Grounded Theory data analysis procedures, we identify a lack of dependency awareness across development teams as a key explanation of ineffective coordination. Our findings show how a lack of dependency awareness emerges from misaligned planning activities of specification, prioritization, estimation and allocation between agile team and traditional inter-team levels and ultimately prevents effective coordination. Knowing about these issues, large-scale hybrid projects in similar contexts can try to better align their planning activities across levels to improve dependency awareness and in turn achieve more effective coordination.","1939-3520","","10.1109/TSE.2017.2730870","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990187","Large-scale software development;agile;hybrid;inter-team coordination;dependency awareness;planning alignment;information systems development","Software;Planning;Agile software development;Companies;Task analysis;Interviews","data analysis;project management;software development management;software prototyping;team working","large-scale software development;agile development;long-term planning;inter-team level;software development unit;global enterprise software company;ineffective coordination;agile team;large-scale hybrid projects;coordination challenges;planning misalignment;hybrid settings;effective inter-team coordination;pressing challenges;scrum masters;product owners;architects;senior management;grounded theory data analysis procedures","","5","","97","","24 Jul 2017","","","IEEE","IEEE Journals"
"An Interleaving Approach to Combinatorial Testing and Failure-Inducing Interaction Identification","X. Niu; C. Nie; H. Leung; Y. Lei; X. Wang; J. Xu; Y. Wang","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computing, Hong Kong Polytechnic University, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The University of Texas at Arlington, Arlington, TX, USA; Department of Computer Science, University of Texas at San Antonio, San Antonio, TX, USA; School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, Jiangsu, China; School of Information Engineering, Nanjing Xiaozhuang University, Nanjing, Jiangsu, China","IEEE Transactions on Software Engineering","15 Jun 2020","2020","46","6","584","615","Combinatorial testing (CT) seeks to detect potential faults caused by various interactions of factors that can influence the software systems. When applying CT, it is a common practice to first generate a set of test cases to cover each possible interaction and then to identify the failure-inducing interaction after a failure is detected. Although this conventional procedure is simple and forthright, we conjecture that it is not the ideal choice in practice. This is because 1) testers desire to identify the root cause of failures before all the needed test cases are generated and executed 2) the early identified failure-inducing interactions can guide the remaining test case generation so that many unnecessary and invalid test cases can be avoided. For these reasons, we propose a novel CT framework that allows both generation and identification process to interact with each other. As a result, both generation and identification stages will be done more effectively and efficiently. We conducted a series of empirical studies on several open-source software, the results of which show that our framework can identify the failure-inducing interactions more quickly than traditional approaches while requiring fewer test cases.","1939-3520","","10.1109/TSE.2018.2865772","National Key Research and Development Plan; National Science Foundation; U.S. Department of Homeland Security; National Institute of Standards and Technologies Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438906","Software testing;combinatorial testing;covering array;failure-inducing interactions","Testing;Software systems;Computer science;Fault diagnosis;Open source software;Indexes","program testing;software fault tolerance","interleaving approach;combinatorial testing;failure-inducing interaction identification;test case generation;CT framework;identification process;failure-inducing interaction","","4","","73","OAPA","17 Aug 2018","","","IEEE","IEEE Journals"
"SEQUENCER: Sequence-to-Sequence Learning for End-to-End Program Repair","Z. Chen; S. J. Kommrusch; M. Tufano; L. -N. Pouchet; D. Poshyvanyk; M. Monperrus","Department of Theoretical Computer Science (TCS), Kungliga Tekniska Hogskolan, 7655 Stockholm, Stockholm Sweden (e-mail: zimin@kth.se); Computer Science, Colorado State University, 3447 Fort Collins, Colorado United States 80523-1019 (e-mail: steve.kommrusch@gmail.com); Computer Science, College of William and Mary, 8604 Williamsburg, Virginia United States 23187-8795 (e-mail: mtufano@email.wm.edu); Computer Science, colorado state university, Fort Collins, Colorado United States (e-mail: pouchet@cs.ucla.edu); Computer Science, William and Mary, Williamsburg, Virginia United States 23188 (e-mail: denys@cs.wm.edu); Department of Theoretical Computer Science (TCS), KTH Royal Institute of Technology, 7655 Stockholm, Stockholm Sweden (e-mail: martin.monperrus@csc.kth.se)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","This paper presents a novel end-to-end approach to program repair based on sequence-to-sequence learning. We devise, implement, and evaluate a technique, called SEQUENCER, for fixing bugs based on sequence-to-sequence learning on source code. This approach uses the copy mechanism to overcome the unlimited vocabulary problem that occurs with big code. Our system is data-driven; we train it on 35,578 samples, carefully curated from commits to open-source repositories. We evaluate SEQUENCER on 4,711 independent real bug fixes, as well on the Defects4J benchmark used in program repair research. SEQUENCER is able to perfectly predict the fixed line for 950/4,711 testing samples, and find correct patches for 14 bugs in Defects4J benchmark. SEQUENCER captures a wide range of repair operators without any domain-specific top-down design.","1939-3520","","10.1109/TSE.2019.2940179","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8827954","program repair;machine learning","Maintenance engineering;Computer bugs;Vocabulary;Training;Natural languages;Benchmark testing","","","","14","","","IEEE","10 Sep 2019","","","IEEE","IEEE Early Access Articles"
"VT-Revolution: Interactive Programming Video Tutorial Authoring and Watching System","L. Bao; Z. Xing; X. Xia; D. Lo","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; Research School of Computer Science, Australian National University, Canberra, ACT, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Information Systems, Singapore Management University, Singapore","IEEE Transactions on Software Engineering","26 Aug 2019","2019","45","8","823","838","Procedural knowledge describes actions and manipulations that are carried out to complete programming tasks. An effective way to document procedural knowledge is programming video tutorials. Unlike text-based software artifacts and tutorials that can be effectively searched and linked using information retrieval techniques, the streaming nature of programming videos limits the ways to explore the captured workflows and interact with files, code and program output in the videos. Existing solutions to adding interactive workflow and elements to programming videos have a dilemma between the level of desired interaction and the efforts required for authoring tutorials. In this work, we tackle this dilemma by designing and building a programming video tutorial authoring system that leverages operating system level instrumentation to log workflow history while tutorial authors are creating programming videos, and the corresponding tutorial watching system that enhances the learning experience of video tutorials by providing programming-specific workflow history and timeline-based browsing interactions. Our tutorial authoring system does not incur any additional burden on tutorial authors to make programming videos interactive. Given a programming video accompanied by synchronously-logged workflow history, our tutorial watching system allows tutorial watchers to freely explore the captured workflows and interact with files, code and program output in the tutorial. We conduct a user study of 135 developers to evaluate the design and effectiveness of our system in helping developers learn programming knowledge in video tutorials.","1939-3520","","10.1109/TSE.2018.2802916","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283605","Program comprehension;human-computer interaction;workflow","Tutorials;Programming;Streaming media;Tools;Task analysis;History;Software","authoring systems;computer aided instruction;computer science education;interactive systems;multimedia systems;programming","interactive programming video tutorial authoring;procedural knowledge;video tutorials;text-based software artifacts;authoring tutorials;programming video tutorial authoring system;programming-specific workflow history;programming tasks;tutorial watching system;operating system level instrumentation","","1","","43","","6 Feb 2018","","","IEEE","IEEE Journals"
"A Deep Learning Model for Estimating Story Points","M. Choetkiertikul; H. K. Dam; T. Tran; T. Pham; A. Ghose; T. Menzies","Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; Deakin University, Waurn Ponds, VIC, Australia; Deakin University, Waurn Ponds, VIC, Australia; Faculty of Engineering and Information Sciences, University of Wollongong, Wollongong, NSW, Australia; North Carolina State University, Raleigh, NC","IEEE Transactions on Software Engineering","16 Jul 2019","2019","45","7","637","656","Although there has been substantial research in software analytics for effort estimation in traditional software projects, little work has been done for estimation in agile projects, especially estimating the effort required for completing user stories or issues. Story points are the most common unit of measure used for estimating the effort involved in completing a user story or resolving an issue. In this paper, we propose a prediction model for estimating story points based on a novel combination of two powerful deep learning architectures: long short-term memory and recurrent highway network. Our prediction system is end-to-end trainable from raw input data to prediction outcomes without any manual feature engineering. We offer a comprehensive dataset for story points-based estimation that contains 23,313 issues from 16 open source projects. An empirical evaluation demonstrates that our approach consistently outperforms three common baselines (Random Guessing, Mean, and Median methods) and six alternatives (e.g., using Doc2Vec and Random Forests) in Mean Absolute Error, Median Absolute Error, and the Standardized Accuracy.","1939-3520","","10.1109/TSE.2018.2792473","Mahidol University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8255666","Software analytics;effort estimation;story point estimation;deep learning","Project management;Software architecture;Learning (artificial intelligence);Deep learning","learning (artificial intelligence);project management;public domain software;software architecture;software management","software analytics;effort estimation;agile projects;prediction model;end-to-end trainable;story points-based estimation;software projects;open source projects;deep learning architectures;mean absolute error;median absolute error;standardized accuracy","","13","","111","","12 Jan 2018","","","IEEE","IEEE Journals"
"Smart Contract Development: Challenges and Opportunities","W. Zou; D. Lo; P. S. Kochhar; X. D. Le; X. Xia; Y. Feng; Z. Chen; B. Xu","State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, Jiangsu China (e-mail: wqzou@smail.nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Information Systems, Singapore Management University School of Information Systems, 274434 Singapore, Singapore Singapore (e-mail: kochharps.2012@phdis.smu.edu.sg); School of Computing and Information Systems, The University of Melbourne - Parkville Campus, 2281 Melbourne, Victoria Australia (e-mail: bachldx@cmu.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, Jiangsu China (e-mail: charles.fy0708@gmail.com); State Key Laboratory for Novel Software Technology, Nanjing University, Jiangsu, Jiangsu China 210093 (e-mail: zychen@nju.edu.cn); Computer, Nanjing University, Nanjing, Jiangsu China (e-mail: bwxu@nju.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Smart contract, a term which was originally coined to refer to the automation of legal contracts in general, has recently seen much interest due to the advent of blockchain technology. Recently, the term is popularly used to refer to low-level code scripts running on a blockchain platform. Our study focuses exclusively on this subset of smart contracts. Such smart contracts have increasingly been gaining ground, finding numerous important applications (e.g., crowdfunding) in the real world. Despite the increasing popularity, smart contract development still remains somewhat a mystery to many developers largely due to its special design and applications. Are there any differences between smart contract development and traditional software development? What kind of challenges are faced by developers during smart contract development? Questions like these are important but have not been explored by researchers yet. In this paper, we performed an exploratory study to understand the current state and potential challenges developers are facing in developing smart contracts on blockchains, with a focus on Ethereum (the most popular public blockchain platform for smart contracts). Toward this end, we conducted this study in two phases. In the first phase, we conducted semi-structured interviews with 20 developers from GitHub and industry professionals who are working on smart contracts. In the second phase, we performed a survey on 232 practitioners to validate the findings from the interviews. Our interview and survey results revealed several major challenges developers are facing during smart contract development: (1) there is no effective way to guarantee the security of smart contract code; (2) existing tools for development are still very basic; (3) the programming languages and the virtual machines still have a number of limitations; (4) performance problems are hard to handle under resource constrained running environment; and (5) online resources (including advanced/updated documents and community support) are still limited. Our study suggests several directions that researchers and practitioners can work on to help improve developers? experience on developing high-quality smart contracts.","1939-3520","","10.1109/TSE.2019.2942301","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847638","Smart Contract;Challenges;Empirical Study;Blockchain","Smart contracts;Blockchain;Law;Interviews;Software","","","","8","","","","24 Sep 2019","","","IEEE","IEEE Early Access Articles"
"A Test Case Prioritization Genetic Algorithm Guided by the Hypervolume Indicator","D. Di Nucci; A. Panichella; A. Zaidman; A. De Lucia","Vrije Universiteit Brussel, Brussels, Belgium; Delft University of Technology, Delft, CD, The Netherlands; Delft University of Technology, Delft, CD, The Netherlands; University of Salerno, Fisciano (SA), Italy","IEEE Transactions on Software Engineering","15 Jun 2020","2020","46","6","674","696","Regression testing is performed during maintenance activities to assess whether the unchanged parts of a software behave as intended. To reduce its cost, test case prioritization techniques can be used to schedule the execution of the available test cases to increase their ability to reveal regression faults earlier. Optimal test ordering can be determined using various techniques, such as greedy algorithms and meta-heuristics, and optimizing multiple fitness functions, such as the average percentage of statement and branch coverage. These fitness functions condense the cumulative coverage scores achieved when incrementally running test cases in a given ordering using Area Under Curve (AUC) metrics. In this paper, we notice that AUC metrics represent a bi-dimensional (simplified) version of the hypervolume metric, which is widely used in many-objective optimization. Thus, we propose a Hypervolume-based Genetic Algorithm, namely HGA, to solve the Test Case Prioritization problem when using multiple test coverage criteria. An empirical study conducted with respect to five state-of-the-art techniques shows that (i) HGA is more cost-effective, (ii) HGA improves the efficiency of Test Case Prioritization, (iii) HGA has a stronger selective pressure when dealing with more than three criteria.","1939-3520","","10.1109/TSE.2018.2868082","F.R.S.-FNRS and FWO-Vlaanderen EOS Seco-Assist project; STAMP ICT-16-10; NWO TestRoots project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453036","Test case prioritization;genetic algorithm;hypervolume","Measurement;Greedy algorithms;Genetic algorithms;Testing;Software systems;Fault detection","genetic algorithms;greedy algorithms;program testing;regression analysis;statistical testing","hypervolume metric;many-objective optimization;HGA;multiple test coverage criteria;test case prioritization genetic algorithm;hypervolume indicator;regression testing;maintenance activities;regression faults;optimizing multiple fitness functions;AUC metrics;bi-dimensional version;hypervolume-based genetic algorithm;area under curve metrics;software behave","","5","","83","IEEE","31 Aug 2018","","","IEEE","IEEE Journals"
"The best laid plans or lack thereof: Security decision-making of different stakeholder groups","B. Shreeve; J. Hallett; M. Edwards; K. M. Ramokapane; R. Atkins; A. Rashid","Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: ben.shreeve@bristol.ac.uk); Bristol Cyber Security Group, University of Bristol, Bristol, Clifton United Kingdom of Great Britain and Northern Ireland BS8 1UB (e-mail: joseph.hallett@bristol.ac.uk); Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: matthew.john.edwards@bristol.ac.uk); Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: marvin.ramokapane@bristol.ac.uk); Cyber Griffin, City of London Police, 89794 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: Richard.Atkins@city-of-london.pnn.police.uk); Bristol Cyber Security Group, University of Bristol, 1980 Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: awais.rashid@bristol.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Cyber security requirements are influenced by the priorities and decisions of a range of stakeholders. Board members and CISOs determine strategic priorities. Managers have responsibility for resource allocation and project management. Legal professionals concern themselves with regulatory compliance. Little is understood about how the security decision-making approaches of these different stakeholders contrast, and if particular groups of stakeholders have a better appreciation of security requirements during decision-making. Are risk analysts better decision makers than CISOs Do security experts exhibit more effective strategies than board members' This paper explores the effect that different experience and diversity of expertise has on the quality of a team's cyber security decision-making and whether teams with members from more varied backgrounds perform better than those with more focused, homogeneous skill sets. Using data from 208 sessions and 948 players of a tabletop game run in the wild by a major national organization over 16 months, we explore how choices are affected by player background (e.g., cyber security experts versus risk analysts, board-level decision makers versus technical experts) and different team make-ups (homogeneous teams of security experts versus various mixes). We find that no group of experts makes significantly better, or even different decisions than anyone else. Instead we discover that experts of all kinds often obsess over technology, becoming fixated on singular issues, regularly failing to fully comprehend what it is they are defending or how the defenses available to them really work.","1939-3520","","10.1109/TSE.2020.3023735","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9195777","","Games;Stakeholders;Computer security;Decision making;Organizations;Investment","","","","","","","IEEE","14 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Semantic Slicing of Software Version Histories","Y. Li; C. Zhu; J. Rubin; M. Chechik","Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada","IEEE Transactions on Software Engineering","12 Feb 2018","2018","44","2","182","201","Software developers often need to transfer functionality, e.g., a set of commits implementing a new feature or a bug fix, from one branch of a configuration management system to another. That can be a challenging task as the existing configuration management tools lack support for matching high-level, semantic functionality with low-level version histories. The developer thus has to either manually identify the exact set of semantically-related commits implementing the functionality of interest or sequentially port a segment of the change history, “inheriting” additional, unwanted functionality. In this paper, we tackle this problem by providing automated support for identifying the set of semantically-related commits implementing a particular functionality, which is defined by a set of tests. We formally define the semantic slicing problem, provide an algorithm for identifying a set of commits that constitute a slice, and propose techniques to minimize the produced slice. We then instantiate the overall approach, CSlicer, in a specific implementation for Java projects managed in Git and evaluate its correctness and effectiveness on a set of open-source software repositories. We show that it allows to identify subsets of change histories that maintain the functionality of interest but are substantially smaller than the original ones.","1939-3520","","10.1109/TSE.2017.2664824","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7843626","Software changes;version control;dependency;program analysis","History;Semantics;Software;Minimization;Context;Computer bugs;Java","configuration management;Java;program slicing;public domain software","CSlicer;configuration management system;software developers;software version histories;open-source software repositories;semantic slicing problem;semantically-related commits","","9","","63","","6 Feb 2017","","","IEEE","IEEE Journals"
"ConPredictor: Concurrency Defect Prediction in Real-World Applications","T. Yu; W. Wen; X. Han; J. H. Hayes","Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY; Department of Computer Science, University of Kentucky, Lexington, KY","IEEE Transactions on Software Engineering","12 Jun 2019","2019","45","6","558","575","Concurrent programs are difficult to test due to their inherent non-determinism. To address this problem, testing often requires the exploration of thread schedules of a program; this can be time-consuming when applied to real-world programs. Software defect prediction has been used to help developers find faults and prioritize their testing efforts. Prior studies have used machine learning to build such predicting models based on designed features that encode the characteristics of programs. However, research has focused on sequential programs; to date, no work has considered defect prediction for concurrent programs, with program characteristics distinguished from sequential programs. In this paper, we present ConPredictor, an approach to predict defects specific to concurrent programs by combining both static and dynamic program metrics. Specifically, we propose a set of novel static code metrics based on the unique properties of concurrent programs. We also leverage additional guidance from dynamic metrics constructed based on mutation analysis. Our evaluation on four large open source projects shows that ConPredictor improved both within-project defect prediction and cross-project defect prediction compared to traditional features.","1939-3520","","10.1109/TSE.2018.2791521","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8252721","Concurrency;defect prediction;software quality;software metrics","Concurrent computing;Predictive models;Software;Programming;Testing;Synchronization","concurrency control;program diagnostics;program testing;public domain software;software fault tolerance;software metrics;software quality","real-world programs;software defect prediction;predicting models;sequential programs;concurrent programs;program characteristics;ConPredictor;static program metrics;dynamic program metrics;within-project defect prediction;cross-project defect prediction;concurrency defect prediction;static code metrics;mutation analysis;open source projects","","1","","100","","9 Jan 2018","","","IEEE","IEEE Journals"
"Rebooting Research on Detecting Repackaged Android Apps: Literature Review and Benchmark","L. Li; T. F. Bissyandé; J. Klein","Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette, Luxembourg","IEEE Transactions on Software Engineering","20 Apr 2021","2021","47","4","676","693","Repackaging is a serious threat to the Android ecosystem as it deprives app developers of their benefits, contributes to spreading malware on users’ devices, and increases the workload of market maintainers. In the space of six years, the research around this specific issue has produced 57 approaches which do not readily scale to millions of apps or are only evaluated on private datasets without, in general, tool support available to the community. Through a systematic literature review of the subject, we argue that the research is slowing down, where many state-of-the-art approaches have reported high-performance rates on closed datasets, which are unfortunately difficult to replicate and to compare against. In this work, we propose to reboot the research in repackaged app detection by providing a literature review that summarises the challenges and current solutions for detecting repackaged apps and by providing a large dataset that supports replications of existing solutions and implications of new research directions. We hope that these contributions will re-activate the direction of detecting repackaged apps and spark innovative approaches going beyond the current state-of-the-art.","1939-3520","","10.1109/TSE.2019.2901679","Monash-Warwick Alliance Catalyst Fund (2018/2019); European Union, under the SPARTA project; Fonds National de la Recherche, Luxembourg; University of Luxembourg, under the VulFix project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8653409","Android;repackaging;clone;literature review;benchmark","Bibliographies;Malware;Cloning;Systematics;Tools;Aging;Libraries","","","","7","","110","IEEE","26 Feb 2019","","","IEEE","IEEE Journals"
"Contract-Based Program Repair without The Contracts: An Extended Study","L. Chen; Y. Pei; C. A. Furia","Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: cslschen@comp.polyu.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: maximilian.pei@gmail.com); Computer Science and Engineering, Chalmers tekniska hogskola, 11248 Goteborg, Vastra Gotaland Sweden 412 96 (e-mail: furiac@usi.ch)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Most techniques for automated program repair (APR) use tests to drive the repair process; this makes them prone to generating spurious repairs that overfit the available tests unless additional information about expected program behavior is available. Our previous work on JAID, an APR technique for Java programs, showed that constructing detailed state abstractions-similar to those employed by techniques for programs with contracts-from plain Java code without any special annotations provides valuable additional information, and hence helps mitigate the overfitting problem. This paper extends the work on JAID with a comprehensive experimental evaluation involving 693 bugs in three different benchmark suites. The evaluation shows, among other things, that: 1) JAID is effective: it produced correct fixes for over 15% of all bugs, with a precision of nearly 60%; 2) JAID is reasonably efficient: on average, it took less than 30 minutes to output a correct fix; 3) JAID is competitive with the state of the art, as it fixed more bugs than any other technique, and 11 bugs that no other tool can fix; 4) JAID is robust: its heuristics are complementary and their effectiveness does not depend on the fine-tuning of parameters. The experimental results also indicate the main trade-offs involved in designing an APR technique based on tests, as well as possible directions for further progress in this line of work.","1939-3520","","10.1109/TSE.2020.2970009","Schweizerischer Nationalfonds zur Forderung der Wissenschaftlichen Forschung; The Hong Kong Polytechnic University Internal Fund; Research Grants Council University Grants Committee; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8972483","","Maintenance engineering;Computer bugs;Tools;Java;Monitoring;Contracts;Programming","","","","","","","","28 Jan 2020","","","IEEE","IEEE Early Access Articles"
"Dynamic Update of Discrete Event Controllers","L. Nahabedian; V. Braberman; N. D'Ippolito; S. Honiden; J. Kramer; K. Tei; S. Uchitel","FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina; FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina; FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina; National Institute of Informatics, Tokyo, Japan; Department of Computing, Imperial College, London, United Kingdom; National Institute of Informatics, Tokyo, Japan; FCEyN, ICC, CONICET, Universidad de Buenos Aires, Buenos Aires, Argentina","IEEE Transactions on Software Engineering","13 Nov 2020","2020","46","11","1220","1240","Discrete event controllers are at the heart of many software systems that require continuous operation. Changing these controllers at runtime to cope with changes in its execution environment or system requirements change is a challenging open problem. In this paper we address the problem of dynamic update of controllers in reactive systems. We present a general approach to specifying correctness criteria for dynamic update and a technique for automatically computing a controller that handles the transition from the old to the new specification, assuring that the system will reach a state in which such a transition can correctly occur and in which the underlying system architecture can reconfigure. Our solution uses discrete event controller synthesis to automatically build a controller that guarantees both progress towards update and safe update.","1939-3520","","10.1109/TSE.2018.2876843","ANPCYT; Secretaría de Ciencia y Técnica, Universidad de Buenos Aires; Consejo Nacional de Investigaciones Científicas y Técnicas; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8500345","Controller synthesis;dynamic update;adaptive systems","Tools;Runtime;Paints;Control systems;Business;Safety","control system synthesis;discrete event systems","discrete event controllers;software systems;reactive systems;event controller synthesis","","2","","71","IEEE","19 Oct 2018","","","IEEE","IEEE Journals"
"Network-Clustered Multi-Modal Bug Localization","T. Hoang; R. J. Oentaryo; T. B. Le; D. Lo","Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore; Singapore Management University, Singapore","IEEE Transactions on Software Engineering","16 Oct 2019","2019","45","10","1002","1023","Developers often spend much effort and resources to debug a program. To help the developers debug, numerous information retrieval (IR)-based and spectrum-based bug localization techniques have been devised. IR-based techniques process textual information in bug reports, while spectrum-based techniques process program spectra (i.e., a record of which program elements are executed for each test case). While both techniques ultimately generate a ranked list of program elements that likely contain a bug, they only consider one source of information-either bug reports or program spectra-which is not optimal. In light of this deficiency, this paper presents a new approach dubbed Network-clustered Multi-modal Bug Localization (NetML), which utilizes multi-modal information from both bug reports and program spectra to localize bugs. NetML facilitates an effective bug localization by carrying out a joint optimization of bug localization error and clustering of both bug reports and program elements (i.e., methods). The clustering is achieved through the incorporation of network Lasso regularization, which incentivizes the model parameters of similar bug reports and similar program elements to be close together. To estimate the model parameters of both bug reports and methods, NetML employs an adaptive learning procedure based on Newton method that updates the parameters on a per-feature basis. Extensive experiments on 355 real bugs from seven software systems have been conducted to benchmark NetML against various state-of-the-art localization methods. The results show that NetML surpasses the best-performing baseline by 31.82, 22.35, 19.72, and 19.24 percent, in terms of the number of bugs successfully localized when a developer inspects the top 1, 5, and 10 methods and Mean Average Precision (MAP), respectively.","1939-3520","","10.1109/TSE.2018.2810892","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8306117","Bug localization;information retrieval;program spectra","Computer bugs;Adaptation models;Optimization;Debugging;Task analysis;Computational modeling;Information retrieval","information retrieval;learning (artificial intelligence);Newton method;program debugging","Network-clustered Multimodal Bug Localization;NetML;multimodal information;effective bug localization;bug localization error;bug reports;information retrieval-based bug localization techniques;bug localization techniques;IR-based techniques process textual information;program spectra;spectrum-based techniques process;program elements;mean average precision","","5","","81","","2 Mar 2018","","","IEEE","IEEE Journals"
"Chaff from the Wheat: Characterizing and Determining Valid Bug Reports","Y. Fan; X. Xia; D. Lo; A. E. Hassan","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang Sheng, China; Faculty of Information Technology, Monash University, Melbourne, Australia; School of Information Systems, Singapore Management University, Singapore; School of Computing, Queen's University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","14 May 2020","2020","46","5","495","525","Developers use bug reports to triage and fix bugs. When triaging a bug report, developers must decide whether the bug report is valid (i.e., a real bug). A large amount of bug reports are submitted every day, with many of them end up being invalid reports. Manually determining valid bug report is a difficult and tedious task. Thus, an approach that can automatically analyze the validity of a bug report and determine whether a report is valid can help developers prioritize their triaging tasks and avoid wasting time and effort on invalid bug reports. In this study, motivated by the above needs, we propose an approach which can determine whether a newly submitted bug report is valid. Our approach first extracts 33 features from bug reports. The extracted features are grouped along 5 dimensions, i.e., reporter experience, collaboration network, completeness, readability and text. Based on these features, we use a random forest classifier to identify valid bug reports. To evaluate the effectiveness of our approach, we experiment on large-scale datasets containing a total of 560,697 bug reports from five open source projects (i.e., Eclipse, Netbeans, Mozilla, Firefox and Thunderbird). On average, across the five datasets, our approach achieves an F1-score for valid bug reports and F1-score for invalid ones of 0.74 and 0.67, respectively. Moreover, our approach achieves an average AUC of 0.81. In terms of AUC and F1-scores for valid and invalid bug reports, our approach statistically significantly outperforms two baselines using features that are proposed by Zanetti et al. [104] . We also study the most important features that distinguish valid bug reports from invalid ones. We find that the textual features of a bug report and reporter's experience are the most important factors to distinguish valid bug reports from invalid ones.","1939-3520","","10.1109/TSE.2018.2864217","National Basic Research Program of China (973 Program); National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8428477","Bug report;feature generation;machine learning","Computer bugs;Feature extraction;Collaboration;Forestry;Support vector machines;Task analysis;Software","feature extraction;program debugging","bug reports;feature extraction;AUC","","6","","109","IEEE","7 Aug 2018","","","IEEE","IEEE Journals"
"A Theoretical and Empirical Analysis of Program Spectra Diagnosability","A. Perez; R. Abreu; A. Van Deursen","Faculty of Engineering, University of Porto, Porto, Portugal; INESC-ID and Instituto Superior Ténico, University of Lisbon, Lisbon, Portugal; Delft University of Technology, Delft, The Netherlands","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","412","431","Current metrics for assessing the adequacy of a test-suite plainly focus on the number of components (be it lines, branches, paths) covered by the suite, but do not explicitly check how the tests actually exercise these components and whether they provide enough information so that spectrum-based fault localization techniques can perform accurate fault isolation. We propose a metric, called DDU, aimed at complementing adequacy measurements by quantifying a test-suite's diagnosability, i.e., the effectiveness of applying spectrum-based fault localization to pinpoint faults in the code in the event of test failures. Our aim is to increase the value generated by creating thorough test-suites, so they are not only regarded as error detection mechanisms but also as effective diagnostic aids that help widely-used fault-localization techniques to accurately pinpoint the location of bugs in the system. We have performed a topology-based simulation of thousands of spectra and have found that DDU can effectively establish an upper bound on the effort to diagnose faults. Furthermore, our empirical experiments using the Defects4J dataset show that optimizing a test suite with respect to DDU yields a 34 percent gain in spectrum-based fault localization report accuracy when compared to the standard branch-coverage metric.","1939-3520","","10.1109/TSE.2019.2895640","Fundação para a Ciência e Tecnologia; FaultLocker Project; FCT scholarship; EU Project STAMP; 4TU project; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8627980","Testing;coverage;diagnosability","Software;Measurement uncertainty;Diversity reception;Cognition;Current measurement;Tools","fault diagnosis;program debugging;program diagnostics;program testing;software fault tolerance","DDU;adequacy measurements;fault-localization techniques;test suite;program spectra diagnosability;test-suite;spectrum-based fault localization techniques;fault isolation;branch-coverage metric;bug location","","","","54","IEEE","27 Jan 2019","","","IEEE","IEEE Journals"
"Automated Documentation of Android Apps","E. Aghajani; G. Bavota; M. Linares-Vásquez; M. Lanza","Università della Svizzera italiana (USI), Lugano, Switzerland; Università della Svizzera italiana (USI), Lugano, Switzerland; Universidad de los Andes, Bogotá, Colombia; Università della Svizzera italiana (USI), Lugano, Switzerland","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","204","220","Developers do not always have the knowledge needed to understand source code and must refer to different resources (e.g., teammates, documentation, the web). This non-trivial process, called program comprehension, is very time-consuming. While many approaches support the comprehension of a given code at hand, they are mostly focused on defining extractive summaries from the code (i.e., on selecting from a given piece of code the most important statements/comments to comprehend it). However, if the information needed to comprehend the code is not there, their usefulness is limited. We present ADANA, an approach to automatically inject comments describing a given piece of Android code. ADANA reuses the descriptions of similar and well-documented code snippets retrieved from various online resources. Our evaluation has shown that ADANA is able to aid the program comprehension process.","1939-3520","","10.1109/TSE.2018.2890652","Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8598894","Program comprehension;documentation;Android","Knowledge based systems;Documentation;Java;Cloning;Asia;Task analysis;Data mining","Android (operating system);document handling;Internet;mobile computing;program diagnostics;query processing;reverse engineering;software maintenance","program comprehension process;online resources;well-documented code snippets;Android code;ADANA;given piece;defining extractive summaries;given code;called program comprehension;nontrivial process;teammates;source code;android apps;automated documentation","","1","","71","IEEE","1 Jan 2019","","","IEEE","IEEE Journals"
"Are Fix-Inducing Changes a Moving Target? A Longitudinal Case Study of Just-In-Time Defect Prediction","S. McIntosh; Y. Kamei","Department of Electrical and Computer Engineering, McGill University, Montreal, QC, Canada; Principles of Software Languages Group (POSL), Kyushu University, Fukuoka, Japan","IEEE Transactions on Software Engineering","14 May 2018","2018","44","5","412","428","Just-In-Time (JIT) models identify fix-inducing code changes. JIT models are trained using techniques that assume that past fix-inducing changes are similar to future ones. However, this assumption may not hold, e.g., as system complexity tends to accrue, expertise may become more important as systems age. In this paper, we study JIT models as systems evolve. Through a longitudinal case study of 37,524 changes from the rapidly evolving Qt and OpenStack systems, we find that fluctuations in the properties of fix-inducing changes can impact the performance and interpretation of JIT models. More specifically: (a) the discriminatory power (AUC) and calibration (Brier) scores of JIT models drop considerably one year after being trained; (b) the role that code change properties (e.g., Size, Experience) play within JIT models fluctuates over time; and (c) those fluctuations yield over- and underestimates of the future impact of code change properties on the likelihood of inducing fixes. To avoid erroneous or misleading predictions, JIT models should be retrained using recently recorded data (within three months). Moreover, quality improvement plans should be informed by JIT models that are trained using six months (or more) of historical data, since they are more resilient to period-specific fluctuations in the importance of code change properties.","1939-3520","","10.1109/TSE.2017.2693980","Natural Sciences and Engineering Research Council of Canada (NSERC); JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7898457","Just-In-Time prediction;defect prediction;mining software repositories","Predictive models;Data models;Software;Complexity theory;Market research;Context modeling;Calibration","data mining;just-in-time;learning (artificial intelligence);public domain software;software management;software quality;source code (software)","Just-In-Time models;fix-inducing code changes;code change properties;target moving;just-in-time defect prediction;fix-inducing changes;JIT models;OpenStack systems;Qt systems;mining software repositories","","21","","48","","12 Apr 2017","","","IEEE","IEEE Journals"
"MAHAKIL: Diversity Based Oversampling Approach to Alleviate the Class Imbalance Issue in Software Defect Prediction","K. E. Bennin; J. Keung; P. Phannachitta; A. Monden; S. Mensah","Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong; College of Arts, Media and Technology, Chiang Mai University, Chiang Mai, Thailand; Graduate School of Natural Science and Technology, Okayama University, Okayama, Japan; Department of Computer Science, City University of Hong Kong, Kowloon Tong, Hong Kong","IEEE Transactions on Software Engineering","12 Jun 2018","2018","44","6","534","550","Highly imbalanced data typically make accurate predictions difficult. Unfortunately, software defect datasets tend to have fewer defective modules than non-defective modules. Synthetic oversampling approaches address this concern by creating new minority defective modules to balance the class distribution before a model is trained. Notwithstanding the successes achieved by these approaches, they mostly result in over-generalization (high rates of false alarms) and generate near-duplicated data instances (less diverse data). In this study, we introduce MAHAKIL, a novel and efficient synthetic oversampling approach for software defect datasets that is based on the chromosomal theory of inheritance. Exploiting this theory, MAHAKIL interprets two distinct sub-classes as parents and generates a new instance that inherits different traits from each parent and contributes to the diversity within the data distribution. We extensively compare MAHAKIL with SMOTE, Borderline-SMOTE, ADASYN, Random Oversampling and the No sampling approach using 20 releases of defect datasets from the PROMISE repository and five prediction models. Our experiments indicate that MAHAKIL improves the prediction performance for all the models and achieves better and more significant pf values than the other oversampling approaches, based on Brunner's statistical significance test and Cliff's effect sizes. Therefore, MAHAKIL is strongly recommended as an efficient alternative for defect prediction models built on highly imbalanced datasets.","1939-3520","","10.1109/TSE.2017.2731766","General Research Fund of the Research Grants Council of Hong Kong; City University of Hong Kong; JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7990590","Software defect prediction;class imbalance learning;synthetic sample generation;data sampling methods;classification problems","Biological cells;Software;Predictive models;Animals;Electronic mail;Sampling methods","learning (artificial intelligence);pattern classification;sampling methods;software quality","MAHAKIL;software defect prediction;software defect datasets;nondefective modules;minority defective modules;class distribution;data instances;less diverse data;distinct sub-classes;data distribution;Random Oversampling;No sampling approach;prediction performance;defect prediction models;highly imbalanced datasets;defective modules;class imbalance issue;synthetic oversampling approaches;synthetic oversampling approach","","28","","80","","25 Jul 2017","","","IEEE","IEEE Journals"
"Complete and Interpretable Conformance Checking of Business Processes","L. García-Bañuelos; N. R. T. P. van Beest; M. Dumas; M. L. Rosa; W. Mertens","University of Tartu, Tartu, Estonia; Data61, CSIRO, Brisbane, QLD, Australia; University of Tartu, Tartu, Estonia; Queensland University of Technology, Brisbane, QLD, Australia; Queensland University of Technology, Brisbane, QLD, Australia","IEEE Transactions on Software Engineering","13 Mar 2018","2018","44","3","262","290","This article presents a method for checking the conformance between an event log capturing the actual execution of a business process, and a model capturing its expected or normative execution. Given a process model and an event log, the method returns a set of statements in natural language describing the behavior allowed by the model but not observed in the log and vice versa. The method relies on a unified representation of process models and event logs based on a well-known model of concurrency, namely event structures. Specifically, the problem of conformance checking is approached by converting the event log into an event structure, converting the process model into another event structure, and aligning the two event structures via an error-correcting synchronized product. Each difference detected in the synchronized product is then verbalized as a natural language statement. An empirical evaluation shows that the proposed method can handle real datasets and produces more concise and higher-level difference descriptions than state-of-the-art conformance checking methods. In a survey designed according to the technology acceptance model, practitioners showed a preference towards the proposed method with respect to a state-of-the-art baseline.","1939-3520","","10.1109/TSE.2017.2668418","Australian Research Council Discovery; Estonian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7852436","Process mining;conformance checking;process model;event log;event structure","Business;Synchronization;Computational modeling;Data mining;Natural languages;Software systems;Context modeling","business data processing;data mining;natural languages","event log;process model;event structure;conformance checking;technology acceptance model;business process expected execution;business process normative execution;concurrency model;error-correcting synchronized product;natural language statement","","8","","39","","13 Feb 2017","","","IEEE","IEEE Journals"
"Using Local Clocks to Reproduce Concurrency Bugs","Z. Wang; C. Wu; X. Yuan; Z. Wang; J. Li; P. -C. Yew; J. Huang; X. Feng; Y. Lan; Y. Chen; Y. Lai; Y. Guan","Institute of Computing Technology, University of Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; Huawei Technologies, Huairou, Beijing, P.R. China; Huawei Technologies, Huairou, Beijing, P.R. China; Horizon Robotics, Inc. Huairou, Beijing, P.R. China; Department of Computer Science and Engineering, University of Minnesota at Twin-Cities, Minnesota, MN; Department of Computer Science and Engineering, Texas A&M University, College Station, TX; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; State Key Laboratory of Computer Architecture, Chinese Academy of Sciences, Huairou, Beijing, P.R. China; Capital Normal University, Huairou, Beijing, P.R. China","IEEE Transactions on Software Engineering","12 Nov 2018","2018","44","11","1112","1128","Multi-threaded programs play an increasingly important role in current multi-core environments. Exposing concurrency bugs and debugging such multi-threaded programs are quite challenging due to their inherent non-determinism. In order to mitigate such non-determinism, many approaches such as record-and-replay have been proposed. However, those approaches often suffer significant performance degradation because they require a large amount of recorded information and/or long analysis and replay time. In this paper, we propose an efficient and effective approach, ReCBuLC (reproducing concurrency bugs using local clocks), to take advantage of the hardware clocks available on modern processors. The key idea is to reduce the recording overhead and the time to analyze events’ global order by recording timestamps in each thread. These timestamps are used to determine the global order of shared accesses. To avoid the large overhead in accessing system-wide global clock, we opt to use local per-core clocks that incur much less access overhead. We then propose techniques to resolve skews among local clocks and obtain an accurate global event order. By using per-core clocks, state-of-the-art bug reproducing systems such as PRES and CLAP can reduce their recording overheads by up to 85 percent, and the analysis time up to 84.66% $\sim$ 99.99%, respectively.","1939-3520","","10.1109/TSE.2017.2752158","National High Technology Research and Development Program of China; National Natural Science Foundation of China (NSFC); Innovation Research Group of NSFC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8038023","Concurrency;bug reproducing;local clock","Clocks;Program processors;Computer bugs;Concurrent computing;Hardware;Debugging;Computer architecture","","","","","","44","","14 Sep 2017","","","IEEE","IEEE Journals"
"Checking Smart Contracts with Structural Code Embedding","Z. Gao; L. Jiang; X. Xia; D. Lo; J. Grundy","Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: zhipeng.gao@monash.edu); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 178902 (e-mail: lxjiang@smu.edu.sg); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Smart contracts have been increasingly used together with blockchains to automate financial and business transactions. However, many bugs and vulnerabilities have been identified in many contracts which raises serious concerns about smart contract security, not to mention that the blockchain systems on which the smart contracts are built can be buggy. Thus, there is a significant need to better maintain smart contract code and ensure its high reliability. In this paper, we propose an automated approach to learn characteristics of smart contracts in Solidity, useful for repetitive contract code, bug detection and contract validation. Our new approach is based on word embeddings and vector space comparison. We parse smart contract code into word streams with code structural information, convert code elements (e.g., statements, functions) into numerical vectors that are supposed to encode the code syntax and semantics, and compare the similarities among the vectors encoding code and known bugs, to identify potential issues. We have implemented the approach in a prototype, named SmartEmbed, and evaluated it with more than 22,000 smart contracts collected from the Ethereum blockchain. Results show that our tool can effectively identify many repetitive instances of Solidity code, where the clone ratio is around 90%. Code clones such as type-III or even type-IV semantic clones can also be detected. Our tool can identify more than 500 clone related bugs based on our bug databases efficiently and accurately. Our tool can also help to efficiently validate any given smart contract against the known set of bugs, which can help to improve the users' confidence in the reliability of the contract.","1939-3520","","10.1109/TSE.2020.2971482","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8979435","","Computer bugs;Smart contracts;Cloning;Tools;Blockchain;Security","","","","3","","","","3 Feb 2020","","","IEEE","IEEE Early Access Articles"
"Automated Selection of Optimal Model Transformation Chains via Shortest-Path Algorithms","F. Basciani; M. D'Emidio; D. D. Ruscio; D. Frigioni; L. Iovino; A. Pierantonio","Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy; Gran Sasso Science Institute (GSSI), L'Aquila, Italy; Dipartimento di Ingegneria e Scienze dell'Informazione e Matematica, Università dell'Aquila, Via Vetoio, L'Aquila, Italy","IEEE Transactions on Software Engineering","13 Mar 2020","2020","46","3","251","279","Conventional wisdom on model transformations in Model-Driven Engineering (MDE) suggests that they are crucial components in modeling environments to achieve superior automation, whether it be refactoring, simulation, or code generation. While their relevance is well-accepted, model transformations are challenging to design, implement, and verify because of the inherent complexity that they must encode. Thus, defining transformations by chaining existing ones is key to success for enhancing their reusability. This paper proposes an approach, based on well-established algorithms, to support modellers when multiple transformation chains are available to bridge a source metamodel with a target one. The all-important goal of selecting the optimal chain has been based on the quality criteria of coverage and information loss. The feasibility of the approach has been demonstrated by means of experiments operated on chains obtained from transformations borrowed from a publicly available repository.","1939-3520","","10.1109/TSE.2018.2846223","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8383962","Model-driven engineering;model transformation composition;graph algorithms;shortest paths","Unified modeling language;Adaptation models;Bridges;Analytical models;Model driven engineering;Ecosystems","graph theory;program processors;software maintenance;software quality","model-driven engineering;optimal chain;optimal model transformation chains;automated selection;shortest-path algorithms;quality criteria","","1","","63","IEEE","13 Jun 2018","","","IEEE","IEEE Journals"
"Testing with Fewer Resources: An Adaptive Approach to Performance-Aware Test Case Generation","G. Grano; C. Laaber; A. Panichella; S. Panichella","Department of Informatics, University of Zurich, Zurich, Zurich Switzerland (e-mail: grano@ifi.uzh.ch); Department of Informatics, University Of Zurich, Zurich, Zurich Switzerland (e-mail: laaber@ifi.uzh.ch); EWI, Technische Universiteit Delft Faculteit Elektrotechniek Wiskunde en Informatica, 225112 Delft, Zuid Holland Netherlands (e-mail: A.Panichella@tudelft.nl); School of Engineering, Zurcher Hochschule fur Angewandte Wissenschaften, 30944 Winterthur, Zurich Switzerland (e-mail: panc@zhaw.ch)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Automated test case generation is an effective technique to yield high-coverage test suites. While the majority of research effort has been devoted to satisfying coverage criteria, a recent trend emerged towards optimizing other non-coverage aspects. In this regard, runtime and memory usage are two essential dimensions: less expensive tests reduce the resource demands for the generation process and later regression testing phases. This study shows that performance-aware test case generation requires solving two main challenges: providing a good approximation of resource usage with minimal overhead and avoiding detrimental effects on both final coverage and fault detection effectiveness. To tackle these challenges, we conceived a set of performance proxies -inspired by previous work on performance testing- that provide a reasonable estimation of the test execution costs (i.e., runtime and memory usage). Thus, we propose an adaptive strategy, called aDynaMOSA, which leverages these proxies by extending DynaMOSA, a state-of-the-art evolutionary algorithm in unit testing. Our empirical study -involving 110 non-trivial Java classes- reveals that our adaptive approach generates test suite with statistically significant improvements in runtime (-25%) and heap memory consumption (-15%) compared to DynaMOSA. Additionally, aDynaMOSA has comparable results to DynaMOSA over seven different coverage criteria and similar fault detection effectiveness. Our empirical investigation also highlights that the usage of performance proxies (i.e., without the adaptiveness) is not sufficient to generate more performant test cases without compromising the overall coverage.","1939-3520","","10.1109/TSE.2019.2946773","Schweizerischer Nationalfonds zur Furderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865437","Evolutionary testing;many-objective optimization;performance","Testing;Runtime;Genetic algorithms;Memory management;Fault detection;Sociology;Statistics","","","","","","","","14 Oct 2019","","","IEEE","IEEE Early Access Articles"
"A Survey of Recent Trends in Testing Concurrent Software Systems","F. A. Bianchi; A. Margara; M. Pezzè","Faculty of Informatics, Univeristà della Svizzera italiana, USI Lugano, Lugano, Switzerland; Faculty of Informatics, Univeristà della Svizzera italiana, USI Lugano, Lugano, Switzerland; Faculty of Informatics, Univeristà della Svizzera italiana, USI Lugano, Lugano, Switzerland","IEEE Transactions on Software Engineering","13 Aug 2018","2018","44","8","747","783","Many modern software systems are composed of multiple execution flows that run simultaneously, spanning from applications designed to exploit the power of modern multi-core architectures to distributed systems consisting of multiple components deployed on different physical nodes. We collectively refer to such systems as concurrent systems. Concurrent systems are difficult to test, since the faults that derive from their concurrent nature depend on the interleavings of the actions performed by the individual execution flows. Testing techniques that target these faults must take into account the concurrency aspects of the systems. The increasingly rapid spread of parallel and distributed architectures led to a deluge of concurrent software systems, and the explosion of testing techniques for such systems in the last decade. The current lack of a comprehensive classification, analysis and comparison of the many testing techniques for concurrent systems limits the understanding of the strengths and weaknesses of each approach and hampers the future advancements in the field. This survey provides a framework to capture the key features of the available techniques to test concurrent software systems, identifies a set of classification criteria to review and compare the available techniques, and discusses in details their strengths and weaknesses, leading to a thorough assessment of the field and paving the road for future progresses.","1939-3520","","10.1109/TSE.2017.2707089","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7932530","Survey;classification;testing;concurrent systems;parallel systems;distributed systems","Testing;Software systems;Message passing;History;Concurrent computing;Computer architecture;Synchronization","formal specification;multiprocessing systems;object-oriented programming;parallel architectures;program testing","distributed systems;testing techniques;concurrency aspects;modern software systems;modern multicore architectures;concurrent software system testing;multiple execution flows;parallel architecture;distributed architecture;classification criteria","","7","","216","","23 May 2017","","","IEEE","IEEE Journals"
"Characterizing the Usage, Evolution and Impact of Java Annotations in Practice","Z. Yu; C. Bai; L. Seinturier; M. Monperrus","KTH Royal Institute of Technology, Stockholm, Sweden; Beihang University, Beijing, China; Inria Lille Nord Europe, Villeneuve d’Ascq, France; KTH Royal Institute of Technology, Stockholm, Sweden","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","969","986","Annotations have been formally introduced into Java since Java 5. Since then, annotations have been widely used by the Java community for different purposes, such as compiler guidance and runtime processing. Despite the ever-growing use, there is still limited empirical knowledge about the actual usage of annotations in practice, the changes made to annotations during software evolution, and the potential impact of annotations on code quality. To fill this gap, we perform the first large-scale empirical study about Java annotations on 1,094 notable open-source projects hosted on GitHub. Our study systematically investigates annotation usage, annotation evolution, and annotation impact, and generates 10 novel and important findings. We also present the implications of our findings, which shed light for developers, researchers, tool builders, and language or library designers in order to improve all facets of Java annotation engineering.","1939-3520","","10.1109/TSE.2019.2910516","Wallenberg AI, Autonomous Systems and Software Program; Knut och Alice Wallenbergs Stiftelse; National Natural Science Foundation of China; Equipment Preliminary R&D Project of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8686056","Annotation;software evolution;empirical study;statistical modelling","Annotations;Java;Tools;Libraries;Runtime;Open source software","","","","","","54","IEEE","11 Apr 2019","","","IEEE","IEEE Journals"
"Automatically Categorizing Software Technologies","M. Nassif; C. Treude; M. P. Robillard","School of Computer Science, McGill University, Montréal, QC, Canada; School of Computer Science, University of Adelaide, Adelaide, SA, Australia; School of Computer Science, McGill University, Montréal, QC, Canada","IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","20","32","Informal language and the absence of a standard taxonomy for software technologies make it difficult to reliably analyze technology trends on discussion forums and other on-line venues. We propose an automated approach called Witt for the categorization of software technologies (an expanded version of the hypernym discovery problem). Witt takes as input a phrase describing a software technology or concept and returns a general category that describes it (e.g., integrated development environment), along with attributes that further qualify it (commercial, php, etc.). By extension, the approach enables the dynamic creation of lists of all technologies of a given type (e.g., web application frameworks). Our approach relies on Stack Overflow and Wikipedia, and involves numerous original domain adaptations and a new solution to the problem of normalizing automatically-detected hypernyms. We compared Witt with six independent taxonomy tools and found that, when applied to software terms, Witt demonstrated better coverage than all evaluated alternative solutions, without a corresponding degradation in false positive rate.","1939-3520","","10.1109/TSE.2018.2836450","Natural Sciences and Engineering Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8359344","Taxonomy;information retrieval;natural language processing;Wikipedia;tagging","Software;Encyclopedias;Electronic publishing;Internet;Taxonomy;Tools","encyclopaedias;public domain software;Web sites","Witt;software terms;software technology;hypernym discovery problem;taxonomy tools;stack overflow;Wikipedia;software technologies categorization;online venues;forums","","4","","46","IEEE","15 May 2018","","","IEEE","IEEE Journals"
"Deep Semantic Feature Learning for Software Defect Prediction","S. Wang; T. Liu; J. Nam; L. Tan","Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; School of Computer Science and Electrical Engineering, Handong Global University, Pohang, Korea; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada","IEEE Transactions on Software Engineering","10 Dec 2020","2020","46","12","1267","1293","Software defect prediction, which predicts defective code regions, can assist developers in finding bugs and prioritizing their testing efforts. Traditional defect prediction features often fail to capture the semantic differences between different programs. This degrades the performance of the prediction models built on these traditional features. Thus, the capability to capture the semantics in programs is required to build accurate prediction models. To bridge the gap between semantics and defect prediction features, we propose leveraging a powerful representation-learning algorithm, deep learning, to learn the semantic representations of programs automatically from source code files and code changes. Specifically, we leverage a deep belief network (DBN) to automatically learn semantic features using token vectors extracted from the programs' abstract syntax trees (AST) (for file-level defect prediction models) and source code changes (for change-level defect prediction models). We examine the effectiveness of our approach on two file-level defect prediction tasks (i.e., file-level within-project defect prediction and file-level cross-project defect prediction) and two change-level defect prediction tasks (i.e., change-level within-project defect prediction and change-level cross-project defect prediction). Our experimental results indicate that the DBN-based semantic features can significantly improve the examined defect prediction tasks. Specifically, the improvements of semantic features against existing traditional features (in F1) range from 2.1 to 41.9 percentage points for file-level within-project defect prediction, from 1.5 to 13.4 percentage points for file-level cross-project defect prediction, from 1.0 to 8.6 percentage points for change-level within-project defect prediction, and from 0.6 to 9.9 percentage points for change-level cross-project defect prediction.","1939-3520","","10.1109/TSE.2018.2877612","Natural Sciences and Engineering Research Council of Canada; National Research Foundation of Korea; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502853","Defect prediction;quality assurance;deep learning;semantic features","Semantics;Predictive models;Feature extraction;Quality assurance;Computer bugs;Data models;Prediction models","abstract data types;belief networks;feature extraction;learning (artificial intelligence);program debugging;program testing;programming language semantics;software quality;tree data structures","deep semantic feature learning;software defect prediction;defective code regions;semantic differences;semantic representations;source code files;file-level defect prediction models;source code changes;change-level defect prediction models;file-level within-project defect prediction;change-level within-project defect prediction;DBN-based semantic features;file-level cross-project defect prediction;change-level cross-project defect prediction;representation-learning algorithm;defect prediction features;deep belief network;token vectors;abstract syntax trees","","15","","111","IEEE","23 Oct 2018","","","IEEE","IEEE Journals"
"Towards Security Threats of Deep Learning Systems: A Survey","Y. He; G. Meng; K. Chen; X. Hu; J. He","Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: heyingzhe@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: mengguozhu@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: chenkai@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: huxingbo@iie.ac.cn); Institute of Information Engineering, Chinese Academy of Sciences, 12381 Beijing, Beijing, China, (e-mail: hejinwen@iie.ac.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Deep learning has gained tremendous success and great popularity in the past few years. However, deep learning systems are suffering several inherent weaknesses, which can threaten the security of learning models. Deep learning's wide use further magnifies the impact and consequences. To this end, lots of research has been conducted with the purpose of exhaustively identifying intrinsic weaknesses and subsequently proposing feasible mitigation. Yet few are clear about how these weaknesses are incurred and how effective these attack approaches are in assaulting deep learning. In order to unveil the security weaknesses and aid in the development of a robust deep learning system, we undertake an investigation on attacks towards deep learning, and analyze these attacks to conclude some findings in multiple views. In particular, we focus on four types of attacks associated with security threats of deep learning: model extraction attack, model inversion attack, poisoning attack and adversarial attack. For each type of attack, we construct its essential workflow as well as adversary capabilities and attack goals. Pivot metrics are devised for comparing the attack approaches, by which we perform quantitative and qualitative analyses. From the analysis, we have identified significant and indispensable factors in an attack vector, <i>e.g.</i>, how to reduce queries to target models, what distance should be used for measuring perturbation. We shed light on 18 findings covering these approaches' merits and demerits, success probability, deployment complexity and prospects. Moreover, we discuss other potential security weaknesses and possible mitigation which can inspire relevant research in this area.","1939-3520","","10.1109/TSE.2020.3034721","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9252914","deep learning;poisoning attack;adversarial attack;model extraction attack;model inversion attack","Deep learning;Security;Data models;Privacy;Predictive models;Training data","","","","1","","","IEEE","9 Nov 2020","","","IEEE","IEEE Early Access Articles"
"FutureWare: Designing a Middleware for Anticipatory Mobile Computing","A. Mehrotra; V. Pejovic; M. Musolesi","Department of Geography, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: abhinav.iims@gmail.com); Faculty of Computer and Information Science, University of Ljubljana, Ljubljana, Ljubljana Slovenia (e-mail: veljko.pejovic@fri.uni-lj.si); Department of Geography, University College London, London, London United Kingdom of Great Britain and Northern Ireland (e-mail: m.musolesi@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Ubiquitous computing is moving from context-awareness to context-prediction. In order to build truly anticipatory systems developers have to deal with many challenges, from multimodal sensing to modeling context from sensed data, and, when necessary, coordinating multiple predictive models across devices. Novel expressive programming interfaces and paradigms are needed for this new class of mobile and ubiquitous applications. In this paper we present FutureWare, a middleware for seamless development of mobile applications that rely on context prediction. FutureWare exposes an expressive API to lift the burden of mobile sensing, individual and group behavior modeling, and future context querying, from an application developer. We implement FutureWare as an Android library, and through a scenario-based testing and a demo app we show that it represents an efficient way of supporting anticipatory applications, reducing the necessary coding effort by two orders of magnitude.","1939-3520","","10.1109/TSE.2019.2943554","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8847471","Anticipatory computing;mobile middleware;mobile sensing;prediction","Middleware;Sensors;Predictive models;Context modeling;Machine learning;Servers;Mobile applications","","","","","","","","24 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Too Many User-Reviews! What Should App Developers Look at First?","E. Noei; F. Zhang; Y. Zou","Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada; School of Computing, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, Queen's University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","367","378","Due to the rapid growth in the number of mobile applications (apps) in the past few years, succeeding in mobile app markets has become ruthless. Online app markets, such as Google Play Store, let users rate apps on a five-star scale and leave feedback. Given the importance of high star-ratings to the success of an app, it is crucial to help developers find the key topics of user-reviews that are significantly related to star-ratings of a given category. Having considered the key topics of user-reviews, app developers can narrow down their effort to the user-reviews that matter to be addressed for receiving higher star-ratings. We study 4,193,549 user-reviews of 623 Android apps that were collected from Google Play Store in ten different categories. The results show that few key topics commonly exist across categories, and each category has a specific set of key topics. We also evaluated the identified key topics with respect to the changes that are made to each version of the apps for 19 months. We observed, for 77 percent of the apps, considering the key topics in the next versions shares a significant relationship with increases in star-ratings.","1939-3520","","10.1109/TSE.2019.2893171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613795","Mobile application;empirical study;software release;user-review","Google;Measurement;Crawlers;Natural language processing;Computer bugs;Tools;Filtering","Android (operating system);mobile computing","app developers;mobile app markets;online app markets;Google Play Store;high star-ratings;user-reviews;Android apps","","4","","77","IEEE","16 Jan 2019","","","IEEE","IEEE Journals"
"Studying Ad Library Integration Strategies of Top Free-to-Download Apps","M. Ahasanuzzaman; S. Hassan; A. E. Hassan","School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: md.ahasanuzzaman@queensu.ca); School of Computing, Queen's University School of Computing, 374016 Ontario, Ontario Canada (e-mail: shassan@cs.queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","In-app advertisements have become a major revenue source for app developers in the mobile app ecosystem. Ad libraries play an integral part in this ecosystem as app developers integrate these libraries into their apps to display ads. In this paper, we study ad library integration practices by analyzing 35,459 updates of 1,837 top free-to-download apps of the Google Play Store. We observe that ad libraries (e.g., Google AdMob) are not always used for serving ads -- 22.5% of the apps that integrate Google AdMob do not display ads. They instead depend on Google AdMob for analytical purposes. Among the apps that display ads, we observe that 57.9% of them integrate multiple ad libraries. We observe that such integration of multiple ad libraries occurs commonly in apps with a large number of downloads and ones in app categories with a high proportion of ad-displaying apps. We manually analyze a sample of apps and derive a set of rules to automatically identify four common strategies for integrating multiple ad libraries. Our analysis of the apps across the identified strategies shows that app developers prefer to manage their own integrations instead of using off-the-shelf features of ad libraries for integrating multiple ad libraries. Our findings are valuable for ad library developers who wish to learn first hand about the challenges of integrating ad libraries.","1939-3520","","10.1109/TSE.2020.2983399","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9052472","Ad libraries;Integration strategies;Mining Android mobile apps;Google Play Store","Libraries;Google;Advertising;Mobile applications;Tools;Ecosystems;Companies","","","","","","","","1 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Lightweight Assessment of Test-Case Effectiveness Using Source-Code-Quality Indicators","G. Grano; F. Palomba; H. C. Gall","University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland; University of Zurich, Zurich, Switzerland","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","758","774","Test cases are crucial to help developers preventing the introduction of software faults. Unfortunately, not all the tests are properly designed or can effectively capture faults in production code. Some measures have been defined to assess test-case effectiveness: the most relevant one is the mutation score, which highlights the quality of a test by generating the so-called mutants, i.e., variations of the production code that make it faulty and that the test is supposed to identify. However, previous studies revealed that mutation analysis is extremely costly and hard to use in practice. The approaches proposed by researchers so far have not been able to provide practical gains in terms of mutation testing efficiency. This leaves the problem of efficiently assessing test-case effectiveness as still open. In this paper, we investigate a novel, orthogonal, and lightweight methodology to assess test-case effectiveness: in particular, we study the feasibility to exploit production and test-code-quality indicators to estimate the mutation score of a test case. We first select a set of 67 factors and study their relation with test-case effectiveness. Then, we devise a mutation score estimation model exploiting such factors and investigate its performance as well as its most relevant features. The key results of the study reveal that our estimation model only based on static features has 86 percent of both F-Measure and AUC-ROC. This means that we can estimate the test-case effectiveness, using source-code-quality indicators, with high accuracy and without executing the tests. As a consequence, we can provide a practical approach that is beyond the typical limitations of current mutation testing techniques.","1939-3520","","10.1109/TSE.2019.2903057","Swiss National Science Foundation (SNSF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658120","Automated software testing;mutation testing;software quality","Testing;Production;Estimation;Measurement;Predictive models;Machine learning;Computational modeling","","","","4","","108","IEEE","4 Mar 2019","","","IEEE","IEEE Journals"
"Tracking Load-Time Configuration Options","M. Lillack; C. Kästner; E. Bodden","University of Leipzig, Leipzig, Germany; Carnegie Mellon University, Pittsburgh, PA; Paderborn University & Fraunhofer IEM, Paderborn, Germany","IEEE Transactions on Software Engineering","9 Dec 2018","2018","44","12","1269","1291","Many software systems are highly configurable, despite the fact that configuration options and their interactions make those systems significantly harder to understand and maintain. In this work, we consider load-time configuration options, such as parameters from the command-line or from configuration files. They are particularly hard to reason about: tracking configuration options from the point at which they are loaded to the point at which they influence control-flow decisions is tedious and error-prone, if done manually. We design and implement Lotrack, an extended static taint analysis to track configuration options automatically. Lotrack derives a configuration map that explains for each code fragment under which configurations it may be executed. An evaluation on Android apps and Java applications from different domains shows that Lotrack yields high accuracy with reasonable performance. We use Lotrack to empirically characterize how much of the implementation of Android apps depends on the platform's configuration options or interactions of these options.","1939-3520","","10.1109/TSE.2017.2756048","German Federal Ministry of Education and Research; US National Science Foundation; Science of Security Lablet; AFRL and DARPA; German Research Foundation (DFG); Heinz Nixdorf Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049300","Variability mining;configuration options;static analysis","Androids;Humanoid robots;Java;Static analysis;Bluetooth;Data mining","Java;mobile computing","configuration map;Lotrack;tracking load-time configuration options;configuration files;tracking configuration options","","7","","58","","25 Sep 2017","","","IEEE","IEEE Journals"
"Enriching API Documentation with Code Samples and Usage Scenarios from Crowd Knowledge","J. Zhang; H. Jiang; Z. Ren; T. Zhang; Z. Huang","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, 47854 Nanjing, Jiangsu China (e-mail: jxzhang@nuaa.edu.cn); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: jianghe@dlut.edu.cn); School of Software, Dalian university of technology, Dalian, Liaoning China (e-mail: zren@dlut.edu.cn); College of Computer Science and Technology, Harbin Engineering University, 12428 Harbin, Heilongjiang China (e-mail: cstzhang@hrbeu.edu.cn); College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, Jiangsu China (e-mail: zqhuang@nuaa.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","As one key resource to learn Application Programming Interfaces (APIs), a lot of API reference documentation lacks code samples with usage scenarios, thus heavily hindering developers from programming with APIs. Although researchers have investigated how to enrich API documentation with code samples from general code search engines, two main challenges remain to be resolved, including the quality challenge of acquiring high-quality code samples and the mapping challenge of matching code samples to usage scenarios. In this study, we propose a novel approach named ADECK towards enriching API documentation with code samples and corresponding usage scenarios by leveraging crowd knowledge from Stack Overflow, a popular technical Question and Answer (Q&A) website attracting millions of developers. Given an API related Q&A pair, a code sample in the answer is extensively evaluated by developers and targeted towards resolving the question under the specified usage scenario. Hence, ADECK can obtain high-quality code samples and map them to corresponding usage scenarios to address the above challenges. Extensive experiments on the Java SE and Android API documentation show that the number of code-sample-illustrated API types in the ADECK-enriched API documentation is 3.35 and 5.76 times as many as that in the raw API documentation. Meanwhile, the quality of code samples obtained by ADECK is better than that of code samples by the baseline approach eXoaDocs in terms of correctness, conciseness, and usability, e.g., the average correctness values of representative code samples obtained by ADECK and eXoaDocs are 4.26 and 3.28 on a 5-point scale in the enriched Java SE API documentation. In addition, an empirical study investigating the impacts of different types of API documentation on the productivity of developers shows that, compared against the raw and the eXoaDocs-enriched API documentation, the ADECK-enriched API documentation can help developers complete 23.81% and 14.29% more programming tasks and reduce the average completion time by 9.43% and 11.03%.","1939-3520","","10.1109/TSE.2019.2919304","National Key Research and Development Plan of China; China Postdoctoral Science Foundation; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8723145","API Documentation;Code Sample;Usage Scenario;Stack Overflow;Crowd knowledge","Documentation;Programming;Java;Knowledge engineering;Search engines;Productivity;Task analysis","","","","3","","","","27 May 2019","","","IEEE","IEEE Early Access Articles"
"Heterogeneous Defect Prediction","J. Nam; W. Fu; S. Kim; T. Menzies; L. Tan","Handong Global University, Pohang, Korea; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Computer Science and Engineering, Hong Kong University of Science and Technology, Hong Kong, China; Department of Computer Science, North Carolina State University, Raleigh, NC; Department of Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada","IEEE Transactions on Software Engineering","16 Sep 2018","2018","44","9","874","896","Many recent studies have documented the success of cross-project defect prediction (CPDP) to predict defects for new projects lacking in defect data by using prediction models built by other projects. However, most studies share the same limitations: it requires homogeneous data; i.e., different projects must describe themselves using the same metrics. This paper presents methods for heterogeneous defect prediction (HDP) that matches up different metrics in different projects. Metric matching for HDP requires a “large enough” sample of distributions in the source and target projects-which raises the question on how large is “large enough” for effective heterogeneous defect prediction. This paper shows that empirically and theoretically, “large enough” may be very small indeed. For example, using a mathematical model of defect prediction, we identify categories of data sets were as few as 50 instances are enough to build a defect prediction model. Our conclusion for this work is that, even when projects use different metric sets, it is possible to quickly transfer lessons learned about defect prediction.","1939-3520","","10.1109/TSE.2017.2720603","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7959597","Defect prediction;quality assurance;heterogeneous metrics;transfer learning","Predictive models;Software metrics;Quality assurance;Training","data handling;pattern matching","metric matching;cross-project defect prediction;defect data;homogeneous data;heterogeneous defect prediction;metric sets","","30","","103","","27 Jun 2017","","","IEEE","IEEE Journals"
"Analyzing the Effects of Bugs on Software Interfaces","R. Natella; S. Winter; D. Cotroneo; N. Suri","DIETI Department, Federico II University of Naples, Napoli, NA, Italy; DEEDS Group, TU Darmstadt, Darmstadt, Germany; DIETI Department, Federico II University of Naples, Napoli, NA, Italy; DEEDS Group, TU Darmstadt, Darmstadt, Germany","IEEE Transactions on Software Engineering","13 Mar 2020","2020","46","3","280","301","Critical systems that integrate software components (e.g., from third-parties) need to address the risk of residual software defects in these components. Software fault injection is an experimental solution to gauge such risk. Many error models have been proposed for emulating faulty components, such as by injecting error codes and exceptions, or by corrupting data with bit-flips, boundary values, and random values. Even if these error models have been able to find breaches in fragile systems, it is unclear whether these errors are in fact representative of software faults. To pursue this open question, we propose a methodology to analyze how software faults in C/C++ software components turn into errors at components' interfaces (interface error propagation), and present an experimental analysis on what, where, and when to inject interface errors. The results point out that the traditional error models, as used so far, do not accurately emulate software faults, but that richer interface errors need to be injected, by: injecting both fail-stop behaviors and data corruptions; targeting larger amounts of corrupted data structures; emulating silent data corruptions not signaled by the component; combining bit-flips, boundary values, and data perturbations.","1939-3520","","10.1109/TSE.2018.2850755","Universit?? degli Studi di Napoli Federico II; Compagnia di San Paolo; BMBF TUD-CRISP; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8396273","Dependability;fault injection;software components;error propagation;error modeling;error handling","Software;Unified modeling language;Computer bugs;Perturbation methods;Testing;Fault tolerance","C++ language;data structures;program debugging;software fault tolerance;source code (software);user interfaces","software faults;boundary values;software interfaces;critical systems;residual software defects;software fault injection;error codes;bug effects;C/C++ software components;interface error propagation;data structure;bit-flips;data perturbations","","1","","95","IEEE","26 Jun 2018","","","IEEE","IEEE Journals"
"An Empirical Study of Dependency Downgrades in the npm Ecosystem","F. R. Cogo; G. A. Oliva; A. E. Hassan","School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: filipe.cogo@gmail.com); School of Computing, Queen's University, Kingston, Ontario Canada K7L 2N8 (e-mail: golivax@gmail.com); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","In a software ecosystem, a dependency relationship enables a client package to reuse a certain version of a provider package. Packages in a software ecosystem often release versions containing bug fixes, new functionalities, and security enhancements. Hence, updating the provider version is an important maintenance task for client packages. Despite the number of investigations about dependency updates, there is a lack of studies about dependency downgrades in software ecosystems. A downgrade indicates that the adopted version of a provider package is not suitable to the client package at a certain moment. In this paper, we investigate downgrades in the npm ecosystem. We address three research questions. In our first RQ, we provide a list of the reasons behind the occurrence of downgrades. Two categories of downgrades according to their rationale: reactive and preventive. The reasons behind reactive downgrades are defects in a specific version of a provider, unexpected feature changes in a provider, and incompatibilities. In turn, preventive downgrades are an attempt to avoid issues in future releases. In our second RQ, we investigate how the versioning of dependencies is modified when a downgrade occurs. We observed that 49% of the downgrades are performed by replacing a range of acceptable versions of a provider by a specific old version. Also, 48% of the downgrades reduce the provider version by a minor level (e.g., from 2.1.0 to 2.0.0). In our third RQ we observed that 50% of the downgrades are performed at a rate that is four times as slow as the median time-between-releases of their associated client packages. We also observed that downgrades that follow an explicit update of a provider package occur 9 times faster than downgrades that follow an implicit update. Explicit updates occur when the provider is updated by means of an explicit change to the versioning specification (i.e., the string used by client packages to define the provider version that they are willing to adopt). We conjecture that, due to the controlled nature of explicit updates, it is easier for client packages to identify the provider that is associated with the problem that motivated the downgrade.","1939-3520","","10.1109/TSE.2019.2952130","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8894401","downgrades;dependency management;npm;software ecosystems","Ecosystems;Software;Computer bugs;Tools;Security;Task analysis","","","","2","","","","8 Nov 2019","","","IEEE","IEEE Early Access Articles"
"Review Dynamics and Their Impact on Software Quality","P. Thongtanunam; A. E. Hassan","School of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria Australia (e-mail: patanamon.t@unimelb.edu.au); School of Computing, Queen's University, Kingston, Ontario Canada (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Code review is a crucial activity for ensuring the quality of software products. Unlike the traditional code review process of the past where reviewers independently examine software artifacts, contemporary code review processes allow teams to collaboratively examine and discuss proposed patches. While the visibility of reviewing activities including review discussions in a contemporary code review tends to increase developer collaboration and openness, little is known whether such visible information influences the evaluation decision of a reviewer or not (i.e., knowing others' feedback about the patch before providing ones own feedback). Therefore, in this work, we set out to investigate the review dynamics, i.e., a practice of providing a vote to accept a proposed patch, in a code review process. To do so, we first characterize the review dynamics by examining the relationship between the evaluation decision of a reviewer and the visible information about a patch under review (e.g., comments and votes that are provided by prior co-reviewers). We then investigate the association between the characterized review dynamics and the defect-proneness of a patch. Through a case study of 83,750 patches of the OpenStack and Qt projects, we observe that the amount of feedback (either votes and comments of prior reviewers) and the co-working frequency of a reviewer with the patch author are highly associated with the likelihood that the reviewer will provide a positive vote to accept a proposed patch. Furthermore, we find that the proportion of reviewers who provided a vote consistent with prior reviewers is significantly associated with the defect-proneness of a patch. However, the associations of these review dynamics are not as strong as the confounding factors (i.e., patch characteristics and overall reviewing activities). Our observations shed light on the implicit influence of the visible information about a patch under review on the evaluation decision of a reviewer. Our findings suggest that the code reviewing policies that are mindful of these practices may help teams improve code review effectiveness. Nonetheless, such review dynamics should not be too concerning in terms of software quality.","1939-3520","","10.1109/TSE.2020.2964660","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8951283","Code review;Collaboration;Human Aspects;Software Quality;Peer Review;Biases","Software quality;Tools;Collaboration;Measurement;Manuals;Proposals","","","","4","","","","7 Jan 2020","","","IEEE","IEEE Early Access Articles"
"Moving from Closed to Open Source: Observations from Six Transitioned Projects to GitHub","P. S. Kochhar; E. Kalliamvakou; N. Nagappan; T. Zimmermann; C. Bird","Information Systems, Singapore Management University School of Information Systems, 274434 Singapore, Singapore Singapore (e-mail: kochharps.2012@phdis.smu.edu.sg); Computer Science, University of Victoria, Victoria, British Columbia Canada V8W 2Y2 (e-mail: ikaliam@uvic.ca); Testing, Verification and Measurement Research, Microsoft Research, Redmond, Washington United States 98052 (e-mail: nachin@microsoft.com); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Microsoft Research, Microsoft Corportation, Redmond, Washington United States 98052 (e-mail: cbird@microsoft.com)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Open source software systems have gained a lot of attention in the past few years. With the emergence of open source platforms like GitHub, developers can contribute, store, and manage their projects with ease. Large organizations like Microsoft, Google, and Facebook are open sourcing their in-house technologies in an effort to more broadly involve the community in the development of software systems. Although closed source and open source systems have been studied extensively, there has been little research on the transition from closed source to open source systems. Through the study we report in this paper we aim to: a) provide guidance and insight for other teams planning to open source their projects and b) to help them avoid pitfalls during the transition process. We studied six Microsoft systems, which were recently open-sourced i.e., CoreFX, CoreCLR, Roslyn, Entity Framework, MVC, and Orleans. This paper presents the transition from the viewpoints of both Microsoft and the open source community based on interviews with eleven Microsoft developer, five Microsoft senior managers involved in the decision to open source, and eleven open-source developers. From Microsoft's perspective we discuss the reasons for the transition, experiences of developers involved, and the transition's outcomes and challenges. Our results show that building a vibrant community, prompt answers, developing an open source culture, security regulations and business opportunities are the factors which persuade companies to open source their products. We also discuss the transition outcomes on processes such as code reviews, version control systems, continuous integration as well as developers' perception of these changes. From the open source community's perspective, we illustrate the response to the open-sourcing initiative through contributions and interactions with the internal developers and provide guidelines for other projects planning to go open source.","1939-3520","","10.1109/TSE.2019.2937025","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8812899","Empirical Study;GitHub;Open-source;Microsoft","Interviews;Encoding;Planning;Software systems;Open source software;Companies","","","","1","","","","26 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Test Generation and Test Prioritization for Simulink Models with Dynamic Behavior","R. Matinnejad; S. Nejati; L. C. Briand; T. Bruckmann","SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; SnT Centre for Security, Reliability, and Trust, University of Luxembourg, Luxembourg; Delphi Automotive Systems, Luxembourg","IEEE Transactions on Software Engineering","17 Sep 2019","2019","45","9","919","944","All engineering disciplines are founded and rely on models, although they may differ on purposes and usages of modeling. Among the different disciplines, the engineering of Cyber Physical Systems (CPSs) particularly relies on models with dynamic behaviors (i.e., models that exhibit time-varying changes). The Simulink modeling platform greatly appeals to CPS engineers since it captures dynamic behavior models. It further provides seamless support for two indispensable engineering activities: (1) automated verification of abstract system models via model simulation, and (2) automated generation of system implementation via code generation. We identify three main challenges in the verification and testing of Simulink models with dynamic behavior, namely incompatibility, oracle and scalability challenges. We propose a Simulink testing approach that attempts to address these challenges. Specifically, we propose a black-box test generation approach, implemented based on meta-heuristic search, that aims to maximize diversity in test output signals generated by Simulink models. We argue that in the CPS domain test oracles are likely to be manual and therefore the main cost driver of testing. In order to lower the cost of manual test oracles, we propose a test prioritization algorithm to automatically rank test cases generated by our test generation algorithm according to their likelihood to reveal a fault. Engineers can then select, according to their test budget, a subset of the most highly ranked test cases. To demonstrate scalability, we evaluate our testing approach using industrial Simulink models. Our evaluation shows that our test generation and test prioritization approaches outperform baseline techniques that rely on random testing and structural coverage.","1939-3520","","10.1109/TSE.2018.2811489","H2020 European Research Council; Delphi Automotive Systems, Luxembourg; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8305644","Simulink models;search-based software testing;test generation;test prioritization;test oracle;output diversity;signal features;structural coverage","Software packages;Testing;Tools;Computational modeling;Vehicle dynamics;Scalability","computer simulation;cyber-physical systems;program compilers;program testing;program verification;search problems","industrial Simulink models;random testing;Simulink modeling platform;dynamic behavior models;abstract system models;code generation;Simulink testing approach;black-box test generation approach;test output signals;CPS domain test oracles;test budget;cyber physical systems;automated verification;automated generation;meta-heuristic search;cost driver;test prioritization approach;structural coverage","","9","","124","","1 Mar 2018","","","IEEE","IEEE Journals"
"Empirical Evaluation of the Impact of Object-Oriented Code Refactoring on Quality Attributes: A Systematic Literature Review","J. Al Dallal; A. Abdin","Department of Information Science, Kuwait University, Safat, Kuwait; Department of Information Science, Kuwait University, Safat, Kuwait","IEEE Transactions on Software Engineering","8 Jan 2018","2018","44","1","44","69","Software refactoring is a maintenance task that addresses code restructuring to improve its quality. Many studies have addressed the impact of different refactoring scenarios on software quality. This study presents a systematic literature review that aggregates, summarizes, and discusses the results of 76 relevant primary studies (PSs) concerning the impact of refactoring on several internal and external quality attributes. The included PSs were selected using inclusion and exclusion criteria applied to relevant articles published before the end of 2015. We analyzed the PSs based on a set of classification criteria, including software quality attributes and measures, refactoring scenarios, evaluation approaches, datasets, and impact results. We followed the vote-counting approach to determine the level of consistency among the PS reported results concerning the relationship between refactoring and software quality. The results indicated that different refactoring scenarios sometimes have opposite impacts on different quality attributes. Therefore, it is false that refactoring always improves all software quality aspects. The vote-counting study provided a clear view of the impacts of some individual refactoring scenarios on some internal quality attributes such as cohesion, coupling, complexity, inheritance, and size, but failed to identify their impacts on external and other internal quality attributes due to insufficient findings.","1939-3520","","10.1109/TSE.2017.2658573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7833023","quality attribute;quality measure;refactoring scenario;systematic literature review","Software quality;Systematics;Unified modeling language;Bibliographies;Libraries;Object oriented modeling","software maintenance;software metrics;software quality","76 relevant primary studies;PSs;internal quality;external quality;classification criteria;software quality attributes;evaluation approaches;vote-counting approach;different refactoring scenarios;opposite impacts;different quality attributes;software quality aspects;vote-counting study;individual refactoring scenarios;systematic literature review;software refactoring;maintenance task;code restructuring","","6","","99","","25 Jan 2017","","","IEEE","IEEE Journals"
"Enhancing the Description-to-Behavior Fidelity in Android Apps with Privacy Policy","L. Yu; X. Luo; C. Qian; S. Wang; H. K. N. Leung","Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hung Hom, Hong Kong","IEEE Transactions on Software Engineering","16 Sep 2018","2018","44","9","834","854","Since more than 96 percent of mobile malware targets the Android platform, various techniques based on static code analysis or dynamic behavior analysis have been proposed to detect malicious apps. As malware is becoming more complicated and stealthy, recent research proposed a promising detection approach that looks for the inconsistency between an app's permissions and its description. In this paper, we first revisit this approach and reveal that using description and permission will lead to many false positives because descriptions often fail to declare all sensitive operations. Then, we propose exploiting an app's privacy policy and its bytecode to enhance the malware detection based on description and permissions. It is non-trivial to automatically analyze privacy policy and perform the cross-verification among these four kinds of software artifacts including, privacy policy, bytecode, description, and permissions. To address these challenging issues, we first propose a novel data flow model for analyzing privacy policy, and then develop a new system, named TAPVerifier, for carrying out investigation of individual software artifacts and conducting the cross-verification. The experimental results show that TAPVerifier can analyze privacy policy with a high accuracy and recall rate. More importantly, integrating privacy policy and bytecode level information can remove up to 59.4 percent false alerts of the state-of-the-art systems, such as AutoCog, CHABADA, etc.","1939-3520","","10.1109/TSE.2017.2730198","Hong Kong GRF; Shenzhen City Science and Technology R&D Fund; Hong Kong RGC Project; HKPolyU Research; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7987793","Mobile applications;privacy policy","Privacy;Data privacy;Semantics;Malware;Permission;Google;Androids","Android (operating system);data privacy;invasive software;mobile computing;program diagnostics","privacy policy;permission;description-to-behavior fidelity;Android apps;static code analysis;dynamic behavior analysis;malicious apps;promising detection approach;malware detection;mobile malware;TAPVerifier","","10","","91","","21 Jul 2017","","","IEEE","IEEE Journals"
"Defining Smart Contract Defects on Ethereum","J. Chen; X. Xia; D. Lo; J. Grundy; X. Luo; T. Chen","Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: Jiachi.Chen@monash.edu); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxia@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxluo@comp.polyu.edu.hk); Institute of Big Data Security, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, Sichuan China (e-mail: brokendragon@uestc.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Smart contracts are programs running on a blockchain. They are immutable to change, and hence can not be patched for bugs once deployed. Thus it is critical to ensure they are bug-free and well-designed before deployment. Code smells are symptoms in source code that possibly indicate e.g. security, architecture and/or usability problems. The detection of code smells is a method to avoid potential bugs and improve the design of existing code. However, traditional code smell patterns are designed for centralized OO programs, e.g., Java or C++. Smart contracts are however decentralized and contain numerous distinctive features, such as the gas system. To fill this gap, we collected smart-contract-related posts from Ethereum Stack Exchange, as well as real-world smart contracts. We manually analyzed these posts and used them to define 20 kinds of code smells for smart contracts. We categorized these into indicating potential security, architecture, and usability problems. To validate if practitioners consider these contract smells as harmful, we created an online survey and received 96 responses from 24 different countries. Feedback showed these code smells are harmful and removing them would improve the quality and robustness of smart contracts. We manually identified our defined code smells in 587 contract accounts and publicly released our dataset. Finally, we summarized 5 impacts caused by contract code smells. These help developers better understand the symptoms of the smells and removal priority.","1939-3520","","10.1109/TSE.2020.2989002","National Key RD Program of China; ARC Laureate Fellowship; ARC Discovery Project; Hong Kong RGC Project; National Natural Science Foundation of China; Australian Research Councils Discovery Early Career Researcher Award DECRA; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072659","Empirical Study;Smart Contracts;Ethereum;Contract Defect","Contracts;Computer bugs;Robustness;Protocols;Bitcoin","","","","2","","","","20 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Smart Bound Selection for the Verification of UML/OCL Class Diagrams","R. Clarisó; C. A. González; J. Cabot","IT, Multimedia and Telecommunication Department, Universitat Oberta de Catalunya, Barcelona, Spain; University of Luxembourg, Esch-sur-Alzette, Luxembourg; ICREA, Pg. Lluís Companys 23, Barcelona, Spain","IEEE Transactions on Software Engineering","16 Apr 2019","2019","45","4","412","426","Correctness of UML class diagrams annotated with OCL constraints can be checked using bounded verification techniques, e.g., SAT or constraint programming (CP) solvers. Bounded verification detects faults efficiently but, on the other hand, the absence of faults does not guarantee a correct behavior outside the bounded domain. Hence, choosing suitable bounds is a non-trivial process as there is a trade-off between the verification time (faster for smaller domains) and the confidence in the result (better for larger domains). Unfortunately, bounded verification tools provide little support in the bound selection process. In this paper, we present a technique that can be used to (i) automatically infer verification bounds whenever possible, (ii) tighten a set of bounds proposed by the user and (iii) guide the user in the bound selection process. This approach may increase the usability of UML/OCL bounded verification tools and improve the efficiency of the verification process.","1939-3520","","10.1109/TSE.2017.2777830","H2020 ECSEL; Spanish Ministry of Economy and Competitivity; Internet Interdisciplinary Institute (IN3); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119996","Formal verification;UML;class diagram;OCL;constraint propagation;SAT","Unified modeling language;Tools;Sociology;Statistics;Analytical models;Computational modeling;Software","constraint handling;formal verification;Unified Modeling Language","UML class diagrams;OCL constraints;constraint programming solvers;bounded verification detects faults;correct behavior;bounded domain;suitable bounds;nontrivial process;verification time;bounded verification tools;bound selection process;automatically infer verification;verification process;smart bound selection;UML-OCL class diagrams","","1","","51","","27 Nov 2017","","","IEEE","IEEE Journals"
"Studying Task Processes for Improving Programmer Productivity","P. Jalote; D. Kamma","IIIT-Delhi, New Delhi, Delhi, India; Robert Bosch Engineering and Business Solutions Limited, Bengaluru, Karnataka, India","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","801","817","Productivity of a software development organization can be enhanced by improving the software process, using better tools/technology, and enhancing the productivity of programmers. This work focuses on improving programmer productivity by studying the process used by a programmer for executing an assigned task, which we call the task process. We propose a general framework for studying the impact of task processes on programmer productivity and also the impact of transferring task processes of high-productivity programmers to average-productivity peers. We applied the framework to a few live projects in Robert Bosch Engineering and Business Solutions Limited, a CMMI Level 5 company. In each project, we identified two groups of programmers: high-productivity and average-productivity programmers. We requested each programmer to video capture their computer screen while executing his/her assigned tasks. We then analyzed these task videos to extract the task processes and then used them to identify the differences between the task processes used by the two groups. Some key differences were found between the task processes, which could account for the difference in productivities of the two groups. Similarities between the task processes were also analyzed quantitatively by modeling each task process as a Markov chain. We found that programmers from the same group used similar task processes, but the task processes of the two groups differed considerably. The task processes of high-productivity programmers were transferred to the average-productivity programmers by training them on the key steps missing in their process but commonly present in the work of their high-productivity peers. A substantial productivity gain was found in the average-productivity programmers as a result of this transfer. The study shows that task processes of programmers impact their productivity, and it is possible to improve the productivity of average-productivity programmers by transferring task processes from high-productivity programmers to them.","1939-3520","","10.1109/TSE.2019.2904230","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8664196","Programmer;productivity;task processes;task execution;industrial study;software;efficiency;improvement;experiments","Task analysis;Productivity;Software;Companies;Markov processes","","","","","","67","IEEE","10 Mar 2019","","","IEEE","IEEE Journals"
"Design Rule Spaces: A New Model for Representing and Analyzing Software Architecture","Y. Cai; L. Xiao; R. Kazman; R. Mo; Q. Feng","Department of Computer Science, Drexel University, Philadelphia, PA; Stevens Institute of Technology, Hoboken, NJ; Department of Information Technology Management, University of Hawaii, Honolulu, HI; Department of Computer Science, Drexel University, Philadelphia, PA; Department of Computer Science, Drexel University, Philadelphia, PA","IEEE Transactions on Software Engineering","16 Jul 2019","2019","45","7","657","682","In this paper, we propose an architecture model called Design Rule Space (DRSpace). We model the architecture of a software system as multiple overlapping DRSpaces, reflecting the fact that any complex software system must contain multiple aspects, features, patterns, etc. We show that this model provides new ways to analyze software quality. In particular, we introduce an Architecture Root detection algorithm that captures DRSpaces containing large numbers of a project's bug-prone files, which are called Architecture Roots (ArchRoots). After investigating ArchRoots calculated from 15 open source projects, the following observations become clear: from 35 to 91 percent of a project's most bug-prone files can be captured by just 5 ArchRoots, meaning that bug-prone files are likely to be architecturally connected. Furthermore, these ArchRoots tend to live in the system for significant periods of time, serving as the major source of bug-proneness and high maintainability costs. Moreover, each ArchRoot reveals multiple architectural flaws that propagate bugs among files and this will incur high maintenance costs over time. The implication of our study is that the quality, in terms of bug-proneness, of a large, complex software project cannot be fundamentally improved without first fixing its architectural flaws.","1939-3520","","10.1109/TSE.2018.2797899","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8268667","Software architecture;reverse-engineering;defect prediction;technical debt;code smells;bug localization","Computer bugs;Computer architecture;Software architecture;Production facilities;Analytical models;Software systems","computer debugging;software architecture;software maintenance;software quality","architecture model;DRSpace;complex software system;multiple aspects;software quality;ArchRoot;bug-prone files;complex software project;software architecture;design rule spaces;architecture root detection algorithm","","8","","118","","24 Jan 2018","","","IEEE","IEEE Journals"
"Enhancing Trustability of Android Applications via User-Centric Flexible Permissions","G. L. Scoccia; I. Malavolta; M. Autili; A. Di Salle; P. Inverardi","Department of Information Engineering Computer Science and Mathematics, University of L'Aquila Department of Information Engineering Computer Science and Mathematics, 220003 L'Aquila, Abruzzo Italy (e-mail: gianluca.scoccia@univaq.it); Computer Science, Vrije Universiteit Amsterdam, 1190 Amsterdam, Noord-Holland Netherlands (e-mail: i.malavolta@vu.nl); Department of Information Engineering Computer Science and Mathematics, University of L'Aquila, L'Aquila, Italy Italy 67100 (e-mail: marco.autili@univaq.it); Department of Information Engineering Computer Science and Mathematics, University of L'Aquila, L'Aquila, AQ Italy (e-mail: amleto.disalle@univaq.it); Informatica, Universita dell'Aquila, L'Aquila, Italy Italy I-67010 (e-mail: paola.inverardi@univaq.it)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The Android OS market is experiencing a growing share globally. It is becoming the mobile platform of choice for an increasing number of users. People rely on Android mobile devices for surfing the web, purchasing products, or to be part of a social network. The large amount of personal information that is exchanged makes privacy an important concern. As a result, the trustability of mobile apps is a fundamental aspect to be considered, particularly with regard to meeting the expectations of end users. The rigidities of the Android permission model confine end users into a secondary role, offering the only option of choosing between either privacy or functionalities. In this paper, we aim at improving the trustability of Android apps by proposing a user-centric approach to the flexible management of Android permissions.The proposed approach empowers end users to selectively grant permission by specifying (i) the desired level of permissions granularity and (ii) the specific features of the app in which the chosen permission levels are granted. Four experiments have been designed, conducted, and reported for evaluating it. The experiments consider performance, usability, and acceptance from both the end users and developers perspective. Results confirm confidence on the approach.","1939-3520","","10.1109/TSE.2019.2941936","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8844813","Android Permissions;Static Analysis;Trustability","Privacy;Runtime;Usability;Social networking (online);Libraries;Fatigue;Smart phones","","","","2","","","","19 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Accelerating Continuous Integration by Caching Environments and Inferring Dependencies","K. Gallaba; Y. Junqueira; J. Ewart; S. Mcintosh","Department of Electrical & Computer Engineering, McGill University, Montreal, Quebec, Canada, H3A 0E9 (e-mail: keheliya.gallaba@mail.mcgill.ca); Engineering, YourBase Inc., Redmond, Washington, United States, (e-mail: yves@yourbase.io); Engineering, YourBase Inc., Redmond, Washington, United States, (e-mail: john@yourbase.io); Cheriton School of Computer Science, University of Waterloo, 8430 Waterloo, Ontario, Canada, (e-mail: shane.mcintosh@uwaterloo.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","To facilitate the rapid release cadence of modern software (on the order of weeks, days, or even hours), software development organizations invest in practices like Continuous Integration (CI), where each change submitted by developers is built (e.g., compiled, tested, linted) to detect problematic changes early. A fast and efficient build process is crucial to provide timely CI feedback to developers. If CI feedback is too slow, developers may switch contexts to other tasks, which is known to be a costly operation for knowledge workers. Thus, minimizing the build execution time for CI services is an important task. While recent work has made several important advances in the acceleration of CI builds, optimizations often depend upon explicitly defined build dependency graphs (e.g., make, Gradle, CloudBuild, Bazel). These hand-maintained graphs may be (a) underspecified, leading to incorrect build behaviour; or (b) overspecified, leading to missed acceleration opportunities. In this paper, we propose Kotinos'a language-agnostic approach to infer data from which build acceleration decisions can be made without relying upon build specifications. After inferring this data, our approach accelerates CI builds by caching the build environment and skipping unaffected build steps. Kotinos is at the core of a commercial CI service with a growing customer base. To evaluate Kotinos, we mine 14,364 historical CI build records spanning three proprietary and seven open-source software projects. We find that: (1) at least 87.9% of the builds activate at least one Kotinos acceleration; and (2) 74% of accelerated builds achieve a speed-up of two-fold with respect to their non-accelerated counterparts. Moreover, (3) the benefits of Kotinos can also be replicated in open source software systems; and (4) Kotinos imposes minimal resource overhead (i.e., < 1% median CPU usage, 2 MB - 2.2 GB median memory usage, and 0.4 GB - 5.2 GB median storage overhead) and does not compromise build outcomes. Our results suggest that migration to Kotinos yields substantial benefits with minimal investment of effort (e.g., no migration of build systems is necessary).","1939-3520","","10.1109/TSE.2020.3048335","Mitacs; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311876","Automated Builds;Build Systems;Continuous Integration","Acceleration;Software;Tools;Statistics;Sociology;Organizations;Testing","","","","","","","IEEE","31 Dec 2020","","","IEEE","IEEE Early Access Articles"
"Studying Bad Updates of Top Free-to-Download Apps in the Google Play Store","S. Hassan; C. Bezemer; A. E. Hassan","Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada; Department of Electrical and Computer Engineering, University of Alberta, Edmonton, AB, Canada; Software Analysis and Intelligence Lab (SAIL), School of Computing, Queen's University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","15 Jul 2020","2020","46","7","773","793","Developers always focus on delivering high-quality updates to improve, or maintain the rating of their apps. Prior work has studied user reviews by analyzing all reviews of an app. However, this app-level analysis misses the point that users post reviews to provide their feedback on a certain update. For example, two bad updates of an app with a history of good updates would not be spotted using app-level analysis. In this paper, we examine reviews at the update-level to better understand how users perceive bad updates. We focus our study on the top 250 bad updates (i.e., updates with the highest increase in the percentage of negative reviews relative to the prior updates of the app) from 26,726 updates of 2,526 top free-to-download apps in the Google Play Store. We find that feature removal and UI issues have the highest increase in the percentage of negative reviews. Bad updates with crashes and functional issues are the most likely to be fixed by a later update. However, developers often do not mention these fixes in the release notes. Our work demonstrates the necessity of an update-level analysis of reviews to capture the feelings of an app's user-base about a particular update.","1939-3520","","10.1109/TSE.2018.2869395","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457304","Mobile app reviews;Google Play Store;bad updates;Android mobile apps","Google;Computer bugs;Feature extraction;Global Positioning System;User interfaces;History","Android (operating system);mobile computing;user interfaces","free-to-download apps;Google Play Store;user reviews;update-level analysis;UI issues;Android mobile apps","","2","","49","IEEE","11 Sep 2018","","","IEEE","IEEE Journals"
"Perceptions, Expectations, and Challenges in Defect Prediction","Z. Wan; X. Xia; A. E. Hassan; D. Lo; J. Yin; X. Yang","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; Faculty of Information Technology, Monash University, Melbourne, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada; School of Information Systems, Singapore Management University, Singapore; College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China; College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang, China","IEEE Transactions on Software Engineering","11 Nov 2020","2020","46","11","1241","1266","Defect prediction has been an active research area for over four decades. Despite numerous studies on defect prediction, the potential value of defect prediction in practice remains unclear. To address this issue, we performed a mixed qualitative and quantitative study to investigate what practitioners think, behave and expect in contrast to research findings when it comes to defect prediction. We collected hypotheses from open-ended interviews and a literature review of defect prediction papers that were published at ICSE, ESEC/FSE, ASE, TSE and TOSEM in the last 6 years (2012-2017). We then conducted a validation survey where the hypotheses became statements or options of our survey questions. We received 395 responses from practitioners from over 33 countries across five continents. Some of our key findings include: 1) Over 90 percent of respondents are willing to adopt defect prediction techniques. 2) There exists a disconnect between practitioners' perceptions and well supported research evidence regarding defect density distribution and the relationship between file size and defectiveness. 3) 7.2 percent of the respondents reveal an inconsistency between their behavior and perception regarding defect prediction. 4) Defect prediction at the feature level is the most preferred level of granularity by practitioners. 5) During bug fixing, more than 40 percent of the respondents acknowledged that they would make a “work-around” fix rather than correct the actual error-causing code. Through a qualitative analysis of free-form text responses, we identified reasons why practitioners are reluctant to adopt defect prediction tools. We also noted features that practitioners expect defect prediction tools to deliver. Based on our findings, we highlight future research directions and provide recommendations for practitioners.","1939-3520","","10.1109/TSE.2018.2877678","National Key Research and Development Program of China; NSFC Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8502824","Defect prediction;empirical study;practitioner;survey","Interviews;Tools;Software;Bibliographies;Computer bugs;Companies;Continents","program debugging;software development management;software maintenance;software metrics;software quality;software reliability","defect prediction papers;defect prediction techniques;defect prediction tools;bug fixing;efficiency 90.0 percent;efficiency 7.2 percent;efficiency 40.0 percent","","9","","103","IEEE","23 Oct 2018","","","IEEE","IEEE Journals"
"CHiP: A Configurable Hybrid Parallel Covering Array Constructor","H. Mercan; C. Yilmaz; K. Kaya","Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey; Faculty of Engineering and Natural Sciences, Sabanci University, Istanbul, Turkey","IEEE Transactions on Software Engineering","10 Dec 2019","2019","45","12","1270","1291","We present a configurable, hybrid, and parallel covering array constructor, called CHiP. CHiP is parallel in that it utilizes vast amount of parallelism provided by graphics processing units (GPUs). CHiP is hybrid in that it bundles the bests of two construction approaches for computing covering arrays; a metaheuristic search-based approach for efficiently covering a large portion of the required combinations and a constraint satisfaction-based approach for effectively covering the remaining hard-to-cover-by-chance combinations. CHiP is configurable in that a trade-off between covering array sizes and construction times can be made. We have conducted a series of experiments, in which we compared the efficiency and effectiveness of CHiP to those of a number of existing constructors by using both full factorial designs and well-known benchmarks. In these experiments, we report new upper bounds on covering array sizes, demonstrating the effectiveness of CHiP, and the first results for a higher coverage strength, demonstrating the scalability of CHiP.","1939-3520","","10.1109/TSE.2018.2837759","Türkiye Bilimsel ve Teknolojik Araştirma Kurumu; Nvidia; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360512","Covering arrays;parallel computing;graphics processing units;CUDA;metaheuristic search;constraint satisfaction problem","Simulated annealing;Graphics processing units;Parallel processing;Benchmark testing;Upper bound;Scalability","constraint satisfaction problems;graphics processing units;parallel architectures;search problems","full factorial designs;covering array sizes;hard-to-cover-by-chance combinations;GPU;graphics processing units;CHiP;constraint satisfaction-based approach;metaheuristic search-based approach;construction approaches;configurable hybrid parallel covering array constructor","","2","","59","IEEE","17 May 2018","","","IEEE","IEEE Journals"
"Metamorphic Testing of RESTful Web APIs","S. Segura; J. A. Parejo; J. Troya; A. Ruiz-Cortés","Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain; Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain; Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain; Department of Computer Languages and Systems, Universidad de Sevilla, Sevilla, Spain","IEEE Transactions on Software Engineering","11 Nov 2018","2018","44","11","1083","1099","Web Application Programming Interfaces (APIs) allow systems to interact with each other over the network. Modern Web APIs often adhere to the REST architectural style, being referred to as RESTful Web APIs. RESTful Web APIs are decomposed into multiple resources (e.g., a video in the YouTube API) that clients can manipulate through HTTP interactions. Testing Web APIs is critical but challenging due to the difficulty to assess the correctness of API responses, i.e., the oracle problem. Metamorphic testing alleviates the oracle problem by exploiting relations (so-called metamorphic relations) among multiple executions of the program under test. In this paper, we present a metamorphic testing approach for the detection of faults in RESTful Web APIs. We first propose six abstract relations that capture the shape of many of the metamorphic relations found in RESTful Web APIs, we call these Metamorphic Relation Output Patterns (MROPs). Each MROP can then be instantiated into one or more concrete metamorphic relations. The approach was evaluated using both automatically seeded and real faults in six subject Web APIs. Among other results, we identified 60 metamorphic relations (instances of the proposed MROPs) in the Web APIs of Spotify and YouTube. Each metamorphic relation was implemented using both random and manual test data, running over 4.7K automated tests. As a result, 11 issues were detected (3 in Spotify and 8 in YouTube), 10 of them confirmed by the API developers or reproduced by other users, supporting the effectiveness of the approach.","1939-3520","","10.1109/TSE.2017.2764464","European Commission (FEDER) and Spanish Government; Andalusian Government project COPAS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8074764","Metamorphic testing;REST;RESTful Web services;web API","Testing;YouTube;Web services;Companies;Standards;Manuals;Indexes","application program interfaces;hypermedia;program testing;social networking (online);transport protocols;Web services","metamorphic relation output pattern;web application programming interfaces;RESTful web API;REST architectural style;HTTP interaction;oracle problem;abstract relation;MROP;YouTube;Spotify","","14","","63","","19 Oct 2017","","","IEEE","IEEE Journals"
"Machine Learning-Based Prototyping of Graphical User Interfaces for Mobile Apps","K. Moran; C. Bernal-Cárdenas; M. Curcio; R. Bonett; D. Poshyvanyk","Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA; Department of Computer Science, College of William & Mary, Williamsburg, VA, USA","IEEE Transactions on Software Engineering","12 Feb 2020","2020","46","2","196","221","It is common practice for developers of user-facing software to transform a mock-up of a graphical user interface (GUI) into code. This process takes place both at an application's inception and in an evolutionary context as GUI changes keep pace with evolving features. Unfortunately, this practice is challenging and time-consuming. In this paper, we present an approach that automates this process by enabling accurate prototyping of GUIs via three tasks: detection, classification, and assembly. First, logical components of a GUI are detected from a mock-up artifact using either computer vision techniques or mock-up metadata. Then, software repository mining, automated dynamic analysis, and deep convolutional neural networks are utilized to accurately classify GUI-components into domain-specific types (e.g., toggle-button). Finally, a data-driven, K-nearest-neighbors algorithm generates a suitable hierarchical GUI structure from which a prototype application can be automatically assembled. We implemented this approach for Android in a system called ReDraw. Our evaluation illustrates that ReDraw achieves an average GUI-component classification accuracy of 91 percent and assembles prototype applications that closely mirror target mock-ups in terms of visual affinity while exhibiting reasonable code structure. Interviews with industrial practitioners illustrate ReDraw's potential to improve real development workflows.","1939-3520","","10.1109/TSE.2018.2844788","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8374985","GUI;CNN;mobile;prototyping;machine-learning;mining software repositories","Graphical user interfaces;Software;Task analysis;Prototypes;Metadata;Androids;Humanoid robots","computer vision;data mining;graphical user interfaces;image classification;learning (artificial intelligence);mobile computing;neural nets;program testing","prototype application;GUI-component classification accuracy;assembles prototype applications;target mock-ups;reasonable code structure;machine learning-based prototyping;graphical user interface;mobile applications;user-facing software;evolutionary context;GUI changes;logical components;computer vision techniques;software repository mining;automated dynamic analysis;deep convolutional neural networks;hierarchical GUI structure","","6","","109","IEEE","7 Jun 2018","","","IEEE","IEEE Journals"
"Comparing Methods for Large-Scale Agile Software Development: A Systematic Literature Review","H. Edison; X. Wang; K. Conboy","The Maersk Mc Kinney Moller Institute, Syddansk Universitet, DK-5230 Odense, Syddanmark, Denmark, (e-mail: hedis@mmmi.sdu.dk); Computer Science, Free University of Bozen-Bolzano, 18956 Bolzano, Trentino-Alto Adige, Italy, (e-mail: xiaofeng.wang@unibz.it); Business Information Systems, National University of Ireland Galway, H91 TK33 Galway, Galway, Ireland, (e-mail: Kieran.Conboy@nuigalway.ie)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Following the highly pervasive and effective use of agile methods at the team level, many software organisations now wish to replicate this success at the organisational level, adopting large-scale agile methods such as SAFe, Scrum-at-Scale, and others. However, this has proven significantly challenging. An analysis of the extant literature reveals a disparate set of studies across each individual method, with no cross-method comparison based on empirical evidence. This systematic literature review compares the main large-scale agile methods, namely SAFe, LeSS, Scrum-at-Scale, DAD, and the Spotify model. It is the first study to analyse and compare each of the method's principles, practices, tools, and metrics in a standardised manner. For each method, it presents not just the original method specifications but also all extensions and modifications to each method proposed by subsequent empirical research. It includes in this comparison not just commercial large-scale methods but also those that have been custom-built in organisations such as Nokia, Ericsson, and others. Based on the findings reported in this study, practitioners can make a more informed decision as to which commercial method or method component or, indeed, custom-built method is better suited to their needs. Our study reveals a number of theoretical and practical issues in the current literature, such as an emphasis on the practices of commercial frameworks at the expense of their underlying principles, or indeed any of the custom method. A set of challenges and success factors associated with the use of large-scale agile methods are identified. The study also identifies a number of research gaps to be addressed across methods.","1939-3520","","10.1109/TSE.2021.3069039","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9387593","large-scale agile;critical assessment;challenges and success factors;systematic literature review","Bibliographies;Systematics;Software;Tools;Measurement;Information systems;Libraries","","","","","","","CCBY","26 Mar 2021","","","IEEE","IEEE Early Access Articles"
"A Rigorous Framework for Specification, Analysis and Enforcement of Access Control Policies","A. Margheri; M. Masi; R. Pugliese; F. Tiezzi","University of Southampton, Southampton, United Kingdom; Tiani “Spirit” GmbH, Wien, Austria; Dipartimento di Statistica, Università degli Studi di Firenze, Firenze, Italy; Università di Camerino, Camerino, Italy","IEEE Transactions on Software Engineering","8 Jan 2019","2019","45","1","2","33","Access control systems are widely used means for the protection of computing systems. They are defined in terms of access control policies regulating the access to system resources. In this paper, we introduce a formally-defined, fully-implemented framework for specification, analysis and enforcement of attribute-based access control policies. The framework rests on FACPL, a language with a compact, yet expressive, syntax for specification of real-world access control policies and with a rigorously defined denotational semantics. The framework enables the automated verification of properties regarding both the authorisations enforced by single policies and the relationships among multiple policies. Effectiveness and performance of the analysis rely on a semantic-preserving representation of FACPL policies in terms of SMT formulae and on the use of efficient SMT solvers. Our analysis approach explicitly addresses some crucial aspects of policy evaluation, such as missing attributes, erroneous values and obligations, which are instead overlooked in other proposals. The framework is supported by Java-based tools, among which an Eclipse-based IDE offering a tailored development and analysis environment for FACPL policies and a Java library for policy enforcement. We illustrate the framework and its formal ingredients by means of an e-Health case study, while its effectiveness is assessed by means of performance stress tests and experiments on a well-established benchmark.","1939-3520","","10.1109/TSE.2017.2765640","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8081817","Attribute-based access control;policy languages;policy analysis;SMT","Semantics;Authorization;Tools;Syntactics;Proposals;Java","authorisation;Java;programming language semantics","access control systems;attribute-based access control policies;real-world access control policies;rigorously defined denotational semantics;FACPL policies;authorisations;semantic-preserving representation;SMT formulae;SMT solvers;Java-based tools;Eclipse-based IDE","","5","","68","","24 Oct 2017","","","IEEE","IEEE Journals"
"Where2Change: Change Request Localization for App Reviews","T. Zhang; J. Chen; X. Zhan; X. Luo; D. Lo; H. Jiang","Faculty of Information Technology, Macau University of Science and Technology, Macao, China (e-mail: tazhang@must.edu.mo); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csjcchen@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxzhan@comp.polyu.edu.hk); Department of Computing, The Hong Kong Polytechnic University, Hong Kong, Hong Kong Hong Kong (e-mail: csxluo@comp.polyu.edu.hk); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Software, Dalian University of Technology, Dalian, Liaoning China 116621 (e-mail: jianghe@dlut.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Million of mobile apps have been released to the market. App developers usually extract useful information from user reviews to maintain and evolve mobile apps. One of the important activities that developers need to do while reading user reviews is to locate the source code related to requested changes. Unfortunately, this manual work is costly and time consuming since: (1) an app can receive thousands of reviews, and (2) a mobile app can consist of hundreds of source code files. To address this challenge, Palomba et al. recently proposed CHANGEADVISOR that utilizes user reviews to locate source code to be changed. However, we find that it cannot identify real source code to be changed for part of reviews. In this paper, we propose a novel approach that can achieve higher accuracy in change localization. Our approach first extracts the informative sentences (i.e., user feedback) from user reviews and identifies user feedback related to various problems and feature requests, and then cluster the corresponding user feedback into groups. Each group reports the similar users' needs. Next, these groups are mapped to issue reports by using W ord2V ec. The resultant enriched text consisting of user feedback and their corresponding issue reports is used to identify source code classes that should be changed by using our novel weight selection-based cosine similarity metric. We have evaluated the new proposed change request localization approach (Where2Change) on 31,597 user reviews and 3,272 issue reports of 10 open source mobile apps. The experiments demonstrate that Where2Change can successfully locate more source code classes related to the change requests for more user feedback clusters than CHANGEADVISOR as demonstrated by higher Top-N and Recall values. In addition, we also compare the performance of Where2Change and two previous Information Retrieval (IR)-based fault localization technologies:BLUiR and BLIA. The results showed that our approach performs better than them. We also conduct an empirical study to investigate the value of using both user reviews and historical issue reports for change request localization; the results shown that historical issue reports can help to improve the performance of change localization.","1939-3520","","10.1109/TSE.2019.2956941","Natural Science Foundation of Heilongjiang Province; National Natural Science Foundation of China; Hong Kong RGC Project; National Key Research and Development Plan of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8924692","User review;Issue report;Mobile app;Change Request localization;Software maintenance","Information retrieval;Measurement;Task analysis;Tools;Feature extraction;Software maintenance","","","","2","","","CCBY","5 Dec 2019","","","IEEE","IEEE Early Access Articles"
"Uncovering the Periphery: A Qualitative Survey of Episodic Volunteering in Free/Libre and Open Source Software Communities","A. Barcomb; A. Kaufmann; D. Riehle; K. -J. Stol; B. Fitzgerald","Open Source Research Group, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Open Source Research Group, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Open Source Research Group, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Lero, Irish Software Research Centre, University College Cork, Cork, Ireland; Lero, Irish Software Research Centre, University of Limerick, Limerick, Ireland","IEEE Transactions on Software Engineering","16 Sep 2020","2020","46","9","962","980","Free/Libre and Open Source Software (FLOSS) communities are composed, in part, of volunteers, many of whom contribute infrequently. However, these infrequent volunteers contribute to the sustainability of FLOSS projects, and should ideally be encouraged to continue participating, even if they cannot be persuaded to contribute regularly. Infrequent contributions are part of a trend which has been widely observed in other sectors of volunteering, where it has been termed “episodic volunteering” (EV). Previous FLOSS research has focused on the Onion model, differentiating core and peripheral developers, with the latter considered as a homogeneous group. We argue this is too simplistic, given the size of the periphery group and the myriad of valuable activities they perform beyond coding. Our exploratory qualitative survey of 13 FLOSS communities investigated what episodic volunteering looks like in a FLOSS context. EV is widespread in FLOSS communities, although not specifically managed. We suggest several recommendations for managing EV based on a framework drawn from the volunteering literature. Also, episodic volunteers make a wide range of value-added contributions other than code, and they should neither be expected nor coerced into becoming habitual volunteers.","1939-3520","","10.1109/TSE.2018.2872713","Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8477174","Community management;episodic volunteering;free software;open source software;peripheral developer","Companies;Lenses;Open source software;Sustainable development;Task analysis","public domain software","episodic volunteering;open source software communities;infrequent volunteers;FLOSS projects;episodic volunteers;value-added contributions;habitual volunteers;Free/Libre","","1","","142","CCBY","30 Sep 2018","","","IEEE","IEEE Journals"
"Topology-Specific Synthesis of Self-Stabilizing Parameterized Systems with Constant-Space Processes","A. Ebnenasir; A. P. Klinkhamer","Department of Computer Science, Michigan Technological University, Houghton, MI, USA; Google, Mountain View, CA, USA","IEEE Transactions on Software Engineering","16 Mar 2021","2021","47","3","614","629","This paper investigates the synthesis of parameterized systems that are self-stabilizing by construction. To this end, we present several significant results. First, we show a counterintuitive result that despite the undecidability of verifying self-stabilization for parameterized unidirectional rings, synthesizing self-stabilizing unidirectional rings is decidable! This is surprising because it is known that, in general, the synthesis of distributed systems is harder than their verification. Second, we present a topology-specific synthesis method (derived from our proof of decidability) that generates the state transition system of template processes of parameterized self-stabilizing systems with elementary unidirectional topologies (e.g., rings, chains, trees). We also provide a software tool that implements our synthesis algorithms and generates interesting self-stabilizing parameterized unidirectional rings in less than 50 microseconds on a regular laptop. We validate the proposed synthesis algorithms for decidable cases in the context of several interesting distributed protocols. Third, we show that synthesis of self-stabilizing bidirectional rings remains undecidable.","1939-3520","","10.1109/TSE.2019.2901485","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651426","Self-stabilization;distributed programming;formal methods;program synthesis","Topology;Protocols;Convergence;Software algorithms;Portable computers;Automata;Transforms","decidability;distributed algorithms;formal specification;formal verification;stability;topology","distributed protocols;decidability proof;undecidability;constant-space process;topology-specific synthesis;self-stabilizing parameterized unidirectional rings;bidirectional rings;synthesis algorithms;elementary unidirectional topologies;parameterized self-stabilizing systems;template process;state transition system;distributed systems;self-stabilization;self-stabilizing parameterized systems","","","","43","IEEE","24 Feb 2019","","","IEEE","IEEE Journals"
"Detecting Trivial Mutant Equivalences via Compiler Optimisations","M. Kintis; M. Papadakis; Y. Jia; N. Malevris; Y. Le Traon; M. Harman","Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette 4365, Luxembourg; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette 4365, Luxembourg; CREST Centre, University College London, London, United Kingdom; Athens University of Economics and Business, Athens, Greece; Interdisciplinary Centre for Security, Reliability and Trust, University of Luxembourg, Esch-sur-Alzette 4365, Luxembourg; CREST Centre, University College London, London, United Kingdom","IEEE Transactions on Software Engineering","16 Apr 2018","2018","44","4","308","333","Mutation testing realises the idea of fault-based testing, i.e., using artificial defects to guide the testing process. It is used to evaluate the adequacy of test suites and to guide test case generation. It is a potentially powerful form of testing, but it is well-known that its effectiveness is inhibited by the presence of equivalent mutants. We recently studied Trivial Compiler Equivalence (TCE) as a simple, fast and readily applicable technique for identifying equivalent mutants for C programs. In the present work, we augment our findings with further results for the Java programming language. TCE can remove a large portion of all mutants because they are determined to be either equivalent or duplicates of other mutants. In particular, TCE equivalent mutants account for 7.4 and 5.7 percent of all C and Java mutants, while duplicated mutants account for a further 21 percent of all C mutants and 5.4 percent Java mutants, on average. With respect to a benchmark ground truth suite (of known equivalent mutants), approximately 30 percent (for C) and 54 percent (for Java) are TCE equivalent. It is unsurprising that results differ between languages, since mutation characteristics are language-dependent. In the case of Java, our new results suggest that TCE may be particularly effective, finding almost half of all equivalent mutants.","1939-3520","","10.1109/TSE.2017.2684805","Research Centre of Athens University of Economics and Business (RC/AUEB); National Research Fund, Luxembourg; Microsoft Azure; UK EPSRC projects; Centre for Research on Evolution Search and Testing (CREST); UCL; EPSRC project; Microsoft Azure; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7882714","Mutation testing;equivalent mutants;duplicated mutants;compiler optimisation","Java;Testing;Optimization;Syntactics;Program processors;Electronic mail","Java;program compilers;program testing","mutation testing;test case generation;Java programming language;TCE equivalent mutants;trivial mutant equivalences detection;fault-based testing;TCE duplicated mutants;Java mutants;compiler equivalence","","10","","75","CCBY","20 Mar 2017","","","IEEE","IEEE Journals"
"Tracking Buggy Files: New Efficient Adaptive Bug Localization Algorithm","M. M. Fejzer; J. Narebski; P. M. Przymus; K. Stencel","The Faculty of Mathematics and Computer Science, Nicolaus Copernicus University in Torun, 49577 Torun, Kuyavian-Pomeranian Voivodeship, Poland, (e-mail: mfejzer@mat.umk.pl); Faculty of Mathematics and Computer Science, Nicolaus Copernicus University in Torun, 49577 Torun, Kuyavian-Pomeranian Voivodeship, Poland, (e-mail: jnareb@mat.umk.pl); The Faculty of Mathematics and Computer Science, Nicolaus Copernicus University in Torun, 49577 Torun, Kuyavian-Pomeranian Voivodeship, Poland, (e-mail: piotr.przymus@mat.umk.pl); Institute of Informatics, University of Warsaw Faculty of Mathematics Informatics and Mechanics, 121883 Warszawa, Masovian Voivodeship, Poland, (e-mail: stencel@mimuw.edu.pl)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Upon receiving a new bug report, developers need to find its cause in the source code. Bug localization can be helped by a tool that ranks all source files according to how likely they include the bug. This problem was thoroughly examined by numerous scientists. We introduce a novel adaptive bug localization algorithm. The concept behind it is based on new feature weighting approaches and an adaptive selection algorithm utilizing pointwise learntorank method. The algorithm is evaluated on publicly available datasets, and is competitive in terms of accuracy and required computational resources compared to stateoftheart. Additionally, to improve reproducibility we provide extended datasets that include computed features and partial steps, and we also provide the source code.","1939-3520","","10.1109/TSE.2021.3064447","Narodowa Agencja Wymiany Akademickiej; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9372820","Bug reports;software maintenance;learning to rank","Computer bugs;Location awareness;Software;History;Software algorithms;Machine learning algorithms;Training","","","","","","","CCBY","8 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Toward a Smell-Aware Bug Prediction Model","F. Palomba; M. Zanoni; F. A. Fontana; A. De Lucia; R. Oliveto","Delft University of Technology, Delft, The Netherlands; University of Milano-Bicocca, Milano, MI, Italy; University of Milano-Bicocca, Milano, MI, Italy; University of Salerno, Fisciano, SA, Italy; University of Molise, Campobasso, Italy","IEEE Transactions on Software Engineering","12 Feb 2019","2019","45","2","194","218","Code smells are symptoms of poor design and implementation choices. Previous studies empirically assessed the impact of smells on code quality and clearly indicate their negative impact on maintainability, including a higher bug-proneness of components affected by code smells. In this paper, we capture previous findings on bug-proneness to build a specialized bug prediction model for smelly classes. Specifically, we evaluate the contribution of a measure of the severity of code smells (i.e., code smell intensity) by adding it to existing bug prediction models based on both product and process metrics, and comparing the results of the new model against the baseline models. Results indicate that the accuracy of a bug prediction model increases by adding the code smell intensity as predictor. We also compare the results achieved by the proposed model with the ones of an alternative technique which considers metrics about the history of code smells in files, finding that our model works generally better. However, we observed interesting complementarities between the set of buggy and smelly classes correctly classified by the two models. By evaluating the actual information gain provided by the intensity index with respect to the other metrics in the model, we found that the intensity index is a relevant feature for both product and process metrics-based models. At the same time, the metric counting the average number of code smells in previous versions of a class considered by the alternative model is also able to reduce the entropy of the model. On the basis of this result, we devise and evaluate a smell-aware combined bug prediction model that included product, process, and smell-related features. We demonstrate how such model classifies bug-prone code components with an F-Measure at least 13 percent higher than the existing state-of-the-art models.","1939-3520","","10.1109/TSE.2017.2770122","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097044","Code smells;bug prediction;empirical study;mining software repositories","Computer bugs;Measurement;Predictive models;Indexes;Software;Complexity theory;Entropy","program debugging;software maintenance;software quality","bug-prone code components;process metrics-based models;code smell intensity;smell-aware combined bug prediction model","","4","","132","","7 Nov 2017","","","IEEE","IEEE Journals"
"Toxic Code Snippets on Stack Overflow","C. Ragkhitwetsagul; J. Krinke; M. Paixao; G. Bianco; R. Oliveto","Computer Science, Faculty of Information and Communication Technology, Mahidol University, Salaya, Thailand; Computer Science, University College London, London, United Kingdom; Computer Science, Universidade Estadual do Ceara, Fortaleza, Brazil; Computer Science, Universita degli Studi del Molise, Campobasso, Italy; Department of Bioscience and Territory, University of Molise, Pesche, Italy","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","560","581","Online code clones are code fragments that are copied from software projects or online sources to Stack Overflow as examples. Due to an absence of a checking mechanism after the code has been copied to Stack Overflow, they can become toxic code snippets, e.g., they suffer from being outdated or violating the original software license. We present a study of online code clones on Stack Overflow and their toxicity by incorporating two developer surveys and a large-scale code clone detection. A survey of 201 high-reputation Stack Overflow answerers (33 percent response rate) showed that 131 participants (65 percent) have ever been notified of outdated code and 26 of them (20 percent) rarely or never fix the code. 138 answerers (69 percent) never check for licensing conflicts between their copied code snippets and Stack Overflow's CC BY-SA 3.0. A survey of 87 Stack Overflow visitors shows that they experienced several issues from Stack Overflow answers: mismatched solutions, outdated solutions, incorrect solutions, and buggy code. 85 percent of them are not aware of CC BY-SA 3.0 license enforced by Stack Overflow, and 66 percent never check for license conflicts when reusing code snippets. Our clone detection found online clone pairs between 72,365 Java code snippets on Stack Overflow and 111 open source projects in the curated Qualitas corpus. We analysed 2,289 non-trivial online clone candidates. Our investigation revealed strong evidence that 153 clones have been copied from a Qualitas project to Stack Overflow. We found 100 of them (66 percent) to be outdated, of which 10 were buggy and harmful for reuse. Furthermore, we found 214 code snippets that could potentially violate the license of their original software and appear 7,112 times in 2,427 GitHub projects.","1939-3520","","10.1109/TSE.2019.2900307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8643998","Code clone detection;stack overflow;outdated code;software licensing","Cloning;Licenses;Software;Programming;Computer bugs;Security;Tutorials","Java;public domain software;software reusability","toxic code snippets;online code clones;code fragments;large-scale code clone detection;high-reputation Stack Overflow answerers;outdated code;Stack Overflow answers;buggy code;Java code snippets;code snippet reusing;Stack Overflow's CC BY-SA 3.0 license;software project;curated Qualitas corpus;efficiency 20.0 percent;efficiency 69.0 percent;efficiency 85.0 percent;efficiency 66.0 percent;efficiency 33.0 percent;efficiency 65.0 percent","","5","","82","IEEE","19 Feb 2019","","","IEEE","IEEE Journals"
"Orderly Generation of Test Data via Sorting Mutant Branches Based on Their Dominance Degrees for Weak Mutation Testing","X. Yao; G. Zhang; F. Pan; D. Gong; C. Wei","School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: yaoxj@cumt.edu.cn); School of Computer Science and Technology, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: zhanggongjie@126.com); School of Information and Control Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: fengpan0315@126.com); School of Information and Electrical Engineering, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: dwgong@vip.163.com); School of Mathematics, China University of Mining and Technology, 12392 Xuzhou, Jiangsu China (e-mail: 1536113693@qq.com)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Compared with traditional structural test criteria, test data generated based on mutation testing are proved more effective at detecting faults. However, not all test data have the same potence in detecting software faults. If test data are prioritized while generating for mutation testing, the defect detectability of the test suite can be further strengthened. In view of this, we propose a method of test data generation for weak mutation testing via sorting mutant branches based on their dominance degrees. First, the problem of weak mutation testing is transformed into that of covering mutant branches for a transformed program. Then, the dominance relation of mutant branches in the transformed program is analyzed to obtain the non-dominated mutant branches and their dominance degrees. Following that, we prioritize all non-dominated mutant branches in descending order by virtue of their dominance degrees. Finally, the test data are generated in an orderly manner by selecting the mutant branches sequentially. The experimental results on 15 programs show that compared with other methods, the proposed test data generation method can not only improve the error detectability of the test suite, but also has higher efficiency.","1939-3520","","10.1109/TSE.2020.3014960","Fundamental Research Funds for the Central Universities; National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9162547","Software testing;Mutation testing;Test data generation;Mutant branch;Dominance degree","Software;Software testing;Fault detection;Control engineering;Data mining;Sorting","","","","","","","","7 Aug 2020","","","IEEE","IEEE Early Access Articles"
"The Impact of Correlated Metrics on the Interpretation of Defect Models","J. Jiarpakdee; C. Tantithamthavorn; A. E. Hassan","Faculty of Information Technology, Monash University, Clayton, VIC, Australia; Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","320","331","Defect models are analytical models for building empirical theories related to software quality. Prior studies often derive knowledge from such models using interpretation techniques, e.g., ANOVA Type-I. Recent work raises concerns that correlated metrics may impact the interpretation of defect models. Yet, the impact of correlated metrics in such models has not been investigated. In this paper, we investigate the impact of correlated metrics on the interpretation of defect models and the improvement of the interpretation of defect models when removing correlated metrics. Through a case study of 14 publicly- available defect datasets, we find that (1) correlated metrics have the largest impact on the consistency, the level of discrepancy, and the direction of the ranking of metrics, especially for ANOVA techniques. On the other hand, we find that removing all correlated metrics (2) improves the consistency of the produced rankings regardless of the ordering of metrics (except for ANOVA Type-I); (3) improves the consistency of ranking of metrics among the studied interpretation techniques; (4) impacts the model performance by less than 5 percentage points. Thus, when one wishes to derive sound interpretation from defect models, one must (1) mitigate correlated metrics especially for ANOVA analyses; and (2) avoid using ANOVA Type-I even if all correlated metrics are removed.","1939-3520","","10.1109/TSE.2019.2891758","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8608002","Software quality assurance;defect models;hypothesis testing;correlated metrics;model specification","Measurement;Analytical models;Analysis of variance;Complexity theory;Software quality;Computer bugs;Correlation","software quality;statistical analysis","defect models;software quality;interpretation techniques;ANOVA Type-I","","5","","88","IEEE","10 Jan 2019","","","IEEE","IEEE Journals"
"A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches","S. Herbold; A. Trautsch; J. Grabowski","University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany","IEEE Transactions on Software Engineering","16 Sep 2018","2018","44","9","811","833","Cross-Project Defect Prediction (CPDP) as a means to focus quality assurance of software projects was under heavy investigation in recent years. However, within the current state-of-the-art it is unclear which of the many proposals performs best due to a lack of replication of results and diverse experiment setups that utilize different performance metrics and are based on different underlying data. Within this article, we provide a benchmark for CPDP. We replicate 24 approaches proposed by researchers between 2008 and 2015 and evaluate their performance on software products from five different data sets. Based on our benchmark, we determined that an approach proposed by Camargo Cruz and Ochimizu (2009) based on data standardization performs best and is always ranked among the statistically significant best results for all metrics and data sets. Approaches proposed by Turhan et al. (2009), Menzies et al. (2011), and Watanabe et al. (2008) are also nearly always among the best results. Moreover, we determined that predictions only seldom achieve a high performance of 0.75 recall, precision, and accuracy. Thus, CPDP still has not reached a point where the performance of the results is sufficient for the application in practice.","1939-3520","","10.1109/TSE.2017.2724538","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7972992","Cross-project defect prediction;benchmark;comparison;replication","Benchmark testing;Prediction methods;Software;Quality assurance;Measurement;Correlation","project management;quality assurance;software metrics;software quality","benchmark cross-Project Defect Prediction approaches;CPDP;quality assurance;software projects;software products;data standardization;performance metrics;data sets","","25","","90","","11 Jul 2017","","","IEEE","IEEE Journals"
"A Framework for Temporal Verification Support in Domain-Specific Modelling","B. Meyers; H. Vangheluwe; J. Denil; R. Salay","Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Mathematics and Computer Science, University of Antwerp, Antwerp, Belgium; Department of Computer Science, University of Toronto, Toronto, ON, Canada","IEEE Transactions on Software Engineering","16 Apr 2020","2020","46","4","362","404","In Domain-Specific Modelling (DSM) the general goal is to provide Domain-Specific Modelling Languages (DSMLs) for domain users to model systems using concepts and notations they are familiar with, in their problem domain. Verifying whether a model satisfies a set of requirements is considered to be an important challenge in DSM, but is nevertheless mostly neglected. We present a solution in the form of ProMoBox, a framework that integrates the definition and verification of temporal properties in discrete-time behavioural DSMLs, whose semantics can be described as a schedule of graph rewrite rules. Thanks to the expressiveness of graph rewriting, this covers a very large class of problems. With ProMoBox, the domain user models not only the system with a DSML, but also its properties, input model, run-time state and output trace. A DSML is thus comprised of five sublanguages, which share domain-specific syntax, and are generated from a single metamodel. Generic transformations to and from a verification backbone ensure that both the language engineer and the domain user are shielded from underlying notations and techniques. We explicitly model the ProMoBox framework's process in the paper. Furthermore, we evaluate ProMoBox to assert that it supports the specification and verification of properties in a highly flexible and automated way.","1939-3520","","10.1109/TSE.2018.2859946","Flanders Make vzw; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8419296","Domain-specific modelling;model-driven engineering;language engineering","Syntactics;Semantics;Formal specifications;Formal verification;Model driven engineering;Model checking","formal specification;formal verification;graph theory;rewriting systems;temporal logic","domain-specific modelling languages;domain user models;input model;share domain-specific syntax;ProMoBox framework;temporal verification support;discrete-time behavioural DSML;generic transformations;verification backbone","","4","","88","IEEE","25 Jul 2018","","","IEEE","IEEE Journals"
"On the Nature of Merge Conflicts: A Study of 2,731 Open Source Java Projects Hosted by GitHub","G. Ghiotto; L. Murta; M. Barros; A. van der Hoek","Computing Institute, Fluminense Federal University, Niterói, RJ, Brazil; Computing Institute, Fluminense Federal University, Niterói, RJ, Brazil; Information Systems Program, UNIRIO, Rio de Janeiro, RJ, Brazil; Department of Informatics, University of California Irvine, Irvine, CA, USA","IEEE Transactions on Software Engineering","13 Aug 2020","2020","46","8","892","915","When multiple developers change a software system in parallel, these concurrent changes need to be merged to all appear in the software being developed. Numerous merge techniques have been proposed to support this task, but none of them can fully automate the merge process. Indeed, it has been reported that as much as 10 to 20 percent of all merge attempts result in a merge conflict, meaning that a developer has to manually complete the merge. To date, we have little insight into the nature of these merge conflicts. What do they look like, in detail? How do developers resolve them? Do any patterns exist that might suggest new merge techniques that could reduce the manual effort? This paper contributes an in-depth study of the merge conflicts found in the histories of 2,731 open source Java projects. Seeded by the manual analysis of the histories of five projects, our automated analysis of all 2,731 projects: (1) characterizes the merge conflicts in terms of number of chunks, size, and programming language constructs involved, (2) classifies the manual resolution strategies that developers use to address these merge conflicts, and (3) analyzes the relationships between various characteristics of the merge conflicts and the chosen resolution strategies. Our results give rise to three primary recommendations for future merge techniques, that - when implemented - could on one hand help in automatically resolving certain types of conflicts and on the other hand provide the developer with tool-based assistance to more easily resolve other types of conflicts that cannot be automatically resolved.","1939-3520","","10.1109/TSE.2018.2871083","Coordenação de Aperfeiçoamento de Pessoal de Nível Superior; Conselho Nacional de Desenvolvimento Científico e Tecnológico; Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8468085","Software merge;merge conflict;merge resolution","Tools;History;Electronic mail;Java;Software;Task analysis","Java;merging;parallel processing;public domain software","merge conflicts;open source Java projects;GitHub;software system;parallel software;programming language","","8","","45","IEEE","19 Sep 2018","","","IEEE","IEEE Journals"
"Automatically Assessing Code Understandability","S. Scalabrino; G. Bavota; C. Vendome; M. Linares-Vásquez; D. Poshyvanyk; R. Oliveto","University of Molise, Campobasso, CB, Italy; Università della Svizzera italiana(USI), Lugano, Switzerland; Miami University, Oxford, OH, USA; Universidad de los Andes, Bogota, Colombia; College of William & Mary, Williamsburg, VA, USA; University of Molise, Campobasso, CB, Italy","IEEE Transactions on Software Engineering","16 Mar 2021","2021","47","3","595","613","Understanding software is an inherent requirement for many maintenance and evolution tasks. Without a thorough understanding of the code, developers would not be able to fix bugs or add new features timely. Measuring code understandability might be useful to guide developers in writing better code, and could also help in estimating the effort required to modify code components. Unfortunately, there are no metrics designed to assess the understandability of code snippets. In this work, we perform an extensive evaluation of 121 existing as well as new code-related, documentation-related, and developer-related metrics. We try to (i) correlate each metric with understandability and (ii) build models combining metrics to assess understandability. To do this, we use 444 human evaluations from 63 developers and we obtained a bold negative result: none of the 121 experimented metrics is able to capture code understandability, not even the ones assumed to assess quality attributes apparently related, such as code readability and complexity. While we observed some improvements while combining metrics in models, their effectiveness is still far from making them suitable for practical applications. Finally, we conducted interviews with five professional developers to understand the factors that influence their ability to understand code snippets, aiming at identifying possible new metrics.","1939-3520","","10.1109/TSE.2019.2901468","SNF project JITRA; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8651396","Software metrics;code understandability;empirical study;negative result","Complexity theory;Software;Computer bugs;Readability metrics;Software measurement;Indexes","program debugging;software maintenance;software metrics;software quality","code-related;code components;measuring code understandability;evolution tasks;maintenance;inherent requirement;understanding software;assessing code understandability;code snippets;professional developers;code readability;121 experimented metrics;444 human evaluations;developer-related metrics;documentation-related","","8","","55","IEEE","24 Feb 2019","","","IEEE","IEEE Journals"
"Locating Latent Design Information in Developer Discussions: A Study on Pull Requests","G. Viviani; M. Famelis; X. Xia; C. Janik-Jones; G. C. Murphy","Department of Computer Science, University of British Columbia, Vancouver, British Columbia Canada (e-mail: vivianig@cs.ubc.ca); Department of Computer Science and Operations Research, Université de Montréal, Montréal, Quebec Canada (e-mail: famelis@iro.umontreal.ca); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia (e-mail: xxkidd@zju.edu.cn); Department of Speech-Language Pathology, University Of Toronto, Toronto, Ontario Canada (e-mail: cal.janik.jones@mail.utoronto.ca); Department of Computer Science, University of British Columbia, Vancouver, British Columbia Canada (e-mail: murphy@cs.ubc.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","A software system's design determines many of its properties, such as maintainability and performance. An understanding of design is needed to maintain system properties as changes to the system occur. Unfortunately, many systems do not have up-to-date design documentation and approaches that have been developed to recover design often focus on how a system works by extracting structural and behaviour information rather than information about the desired design properties, such as robustness or performance. In this paper, we explore whether it is possible to automatically locate where design is discussed in on-line developer discussions. We investigate and introduce a classifier that can locate paragraphs in pull request discussions that pertain to design with an average AUC score of 0.87. We show that this classifier agrees with human developers in 81% of cases considered. To show how the location of latent design information in developer discussions is useful, we present a proof-of-concept tool that can identify design concerns automatically from the identified design discussions and describe how this extracted design information might be provided to developers.","1939-3520","","10.1109/TSE.2019.2924006","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8742578","Design Discussions;Latent Design;Conversations;Prediction Model;Design Recovery","System analysis and design;Tools;Documentation;Robustness;Predictive models;Software systems","","","","3","","","","20 Jun 2019","","","IEEE","IEEE Early Access Articles"
"How Does Refactoring Impact Security When Improving Quality? A Security-Aware Refactoring Approach","C. Abid; M. Kessentini; V. Alizadeh; M. Dhouadi; R. Kazman","CIS, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: cabid@umich.edu); CIS, University of Michigan, 1259 Ann Arbor, Michigan United States (e-mail: marouane@umich.edu); CIS Department, University of Michigan, Dearborn, Michigan United States (e-mail: alizadeh@umich.edu); CIS Department, University of Michigan, Dearborn, Michigan United States (e-mail: mounad@umich.edu); Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii United States 96822 (e-mail: kazman@hawaii.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","While state of the art of software refactoring research uses various quality attributes to identify refactoring opportunities and evaluate refactoring recommendations, the impact of refactoring on the security of software systems when improving other quality objectives is under-explored. It is critical to understand how a system is resistant to security risks after refactoring to improve quality metrics. For instance, refactoring is widely used to improve the reusability of code, however such an improvement may increase the attack surface due to the created abstractions. Increasing the spread of security-critical classes in the design to improve modularity may result in reducing the resilience of software systems to attacks. In this paper, we investigated the possible impact of improving different quality attributes (e.g. reusability, extendibility, etc.), from the QMOOD model, effectiveness on a set of 8 security metrics defined in the literature related to the data access. We also studied the impact of different refactorings on these static security metrics. Then, we proposed a multi-objective refactoring recommendation approach to find a balance between quality attributes and security based on the correlation results to guide the search. We evaluated our tool on 30 open source projects. We also collected the practitioner perceptions on the refactorings recommended by our tool in terms of the possible impact on both security and other quality attributes. Our results confirm that developers need to make trade-offs between security and other qualities when refactoring software systems due to the negative correlations between them.","1939-3520","","10.1109/TSE.2020.3005995","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9130035","Quality;critical code;security metrics;attack surface;refactoring;multi-objective search","Security;Measurement;Tools;Correlation;Software systems;Computer bugs","","","","","","","","30 Jun 2020","","","IEEE","IEEE Early Access Articles"
"Discipline Matters: Refactoring of Preprocessor Directives in the #ifdef  Hell","F. Medeiros; M. Ribeiro; R. Gheyi; S. Apel; C. Kästner; B. Ferreira; L. Carvalho; B. Fonseca","Federal Institute of Alagoas, AL, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Department of Computing and Systems, Federal University of Campina Grande, PB, Brazil; Department of Informatics and Mathematics, University of Passau, Passau, Germany; Institute for Software Research, School of Computer Science, Carnegie Mellon University, Pittsburgh, PA; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil; Computing Institute, Federal University of Alagoas, Maceió, AL, Brazil","IEEE Transactions on Software Engineering","14 May 2018","2018","44","5","453","469","The C preprocessor is used in many C projects to support variability and portability. However, researchers and practitioners criticize the C preprocessor because of its negative effect on code understanding and maintainability and its error proneness. More importantly, the use of the preprocessor hinders the development of tool support that is standard in other languages, such as automated refactoring. Developers aggravate these problems when using the preprocessor in undisciplined ways (e.g., conditional blocks that do not align with the syntactic structure of the code). In this article, we proposed a catalogue of refactorings and we evaluated the number of application possibilities of the refactorings in practice, the opinion of developers about the usefulness of the refactorings, and whether the refactorings preserve behavior. Overall, we found 5,670 application possibilities for the refactorings in 63 real-world C projects. In addition, we performed an online survey among 246 developers, and we submitted 28 patches to convert undisciplined directives into disciplined ones. According to our results, 63 percent of developers prefer to use the refactored (i.e., disciplined) version of the code instead of the original code with undisciplined preprocessor usage. To verify that the refactorings are indeed behavior preserving, we applied them to more than 36 thousand programs generated automatically using a model of a subset of the C language, running the same test cases in the original and refactored programs. Furthermore, we applied the refactorings to three real-world projects: BusyBox, OpenSSL, and SQLite. This way, we detected and fixed a few behavioral changes, 62 percent caused by unspecified behavior in the C programming language.","1939-3520","","10.1109/TSE.2017.2688333","Conselho Nacional de Desenvolvimento Científico e Tecnológico; FAPEAL PPGs; CAPES; DEVASSES; European Union's Seventh Framework Programme for research, technological development and demonstration; NSF; Science of Security Lablet; AFRL; DARPA; German Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888579","Configurable systems;preprocessors;and refactoring","Syntactics;C languages;Guidelines;Linux;Kernel;Standards","C language;program compilers;program diagnostics;program processors;public domain software;software maintenance","refactored programs;preprocessor directives;C preprocessor;automated refactoring;preprocessor usage;BusyBox;OpenSSL;SQLite;C programming language","","5","","50","","28 Mar 2017","","","IEEE","IEEE Journals"
"Gray Computing: A Framework for Computing with Background JavaScript Tasks","Y. Pan; J. White; Y. Sun; J. Gray","Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN; Department of Electrical Engineering and Computer Science, Vanderbilt University, Nashville, TN; Department of Computer Science, California State Polytechnic University, Pomona, CA; Department of Computer Science, University of Alabama, Tuscaloosa, AL","IEEE Transactions on Software Engineering","12 Feb 2019","2019","45","2","171","193","Website visitors are performing increasingly complex computational work on the websites' behalf, such as validating forms, rendering animations, and producing data visualizations. In this article, we explore the possibility of increasing the work offloaded to web visitors' browsers. The idle computing cycles of web visitors can be turned into a large-scale distributed data processing engine, which we term gray computing. Past research has looked primarily at either volunteer computing with specialized clients or browser-based volunteer computing where the visitors keep their browsers open to a single web page for a long period of time. This article provides a comprehensive analysis of the architecture, performance, security, cost effectiveness, user experience, and other issues of gray computing distributed data processing engines with heterogeneous computing power, non-uniform page view times, and high computing pool volatility. Several real-world applications are examined and gray computing is shown to be cost effective for a number of complex tasks ranging from computer vision to bioinformatics to cryptology.","1939-3520","","10.1109/TSE.2017.2772812","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8105894","Software economics;JavaScript;web browser;cloud computing","Distributed processing;Browsers;Data processing;Web pages;Cloud computing","data visualisation;grey systems;Java;volunteer computing;Web sites","computer vision;gray computing;website visitors;increasingly complex computational work;idle computing cycles;large-scale distributed data processing engine;browser-based volunteer computing;heterogeneous computing power;JavaScript tasks;computing pool volatility;bioinformatics;cryptology;data visualizations","","","","96","","13 Nov 2017","","","IEEE","IEEE Journals"
"Metric-based Fault Prediction for Spreadsheets","P. Koch; K. Schekotihin; D. Jannach; B. Hofer; F. Wotawa","Applied Informatics, Alpen-Adria Universitat Klagenfurt Fakultat fur Technische Wissenschaften, 392327 Klagenfurt, Carinthia Austria (e-mail: patrick.koch@aau.at); Applied Informatics, Alpen-Adria Universitat Klagenfurt Fakultat fur Technische Wissenschaften, 392327 Klagenfurt, Carinthia Austria (e-mail: konstantin.schekotihin@aau.at); Applied Informatics, Alpen-Adria Universitat Klagenfurt Fakultat fur Technische Wissenschaften, 392327 Klagenfurt, Carinthia Austria (e-mail: Dietmar.Jannach@aau.at); Institute for Software Technology, Technische Universitat Graz, 27253 Graz, Steiermark Austria (e-mail: bhofer@ist.tugraz.at); Institute for Software Technology, TU Graz, Graz, Styria Austria 8010 (e-mail: wotawa@ist.tugraz.at)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Electronic spreadsheets are widely used in organizations for various data analytics and decision-making tasks. Even though faults within such spreadsheets are common and can have significant negative consequences, today's tools for creating and handling spreadsheets provide limited support for fault detection, localization, and repair. Being able to predict whether a certain part of a spreadsheet is faulty or not is often central for the implementation of such supporting functionality. In this work, we propose a novel approach to fault prediction in spreadsheet formulas, which combines an extensive catalog of spreadsheet metrics with modern machine learning algorithms. An analysis of the individual metrics from our catalog reveals that they are generally suited to discover a wide range of faults. Their predictive power is, however, limited when considered in isolation. Therefore, in our approach we apply supervised learning algorithms to obtain fault predictors that utilize all data provided by multiple spreadsheet metrics from our catalog. Experiments on different datasets containing faulty spreadsheets show that particularly Random Forests classifiers are often effective. As a result, the proposed method is in many cases able to make highly accurate predictions whether a given formula of a spreadsheet is faulty.","1939-3520","","10.1109/TSE.2019.2944604","Austrian Science Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8859280","Spreadsheets;Fault Prediction;Machine Learning","Measurement;Software;Prediction algorithms;Predictive models;Tools;Radio frequency;Task analysis","","","","","","","CCBY","4 Oct 2019","","","IEEE","IEEE Early Access Articles"
"An Empirical Comparison of Combinatorial Testing, Random Testing and Adaptive Random Testing","H. Wu; C. Nie; J. Petke; Y. Jia; M. Harman","Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; CREST, Computer Science, University College London, London, United Kingdom; Facebook Inc., London, United Kingdom; Facebook Inc., London, United Kingdom","IEEE Transactions on Software Engineering","13 Mar 2020","2020","46","3","302","320","We present an empirical comparison of three test generation techniques, namely, Combinatorial Testing (CT), Random Testing (RT) and Adaptive Random Testing (ART), under different test scenarios. This is the first study in the literature to account for the (more realistic) testing setting in which the tester may not have complete information about the parameters and constraints that pertain to the system, and to account for the challenge posed by faults (in terms of failure rate). Our study was conducted on nine real-world programs under a total of 1683 test scenarios (combinations of available parameter and constraint information and failure rate). The results show significant differences in the techniques' fault detection ability when faults are hard to detect (failure rates are relatively low). CT performs best overall; no worse than any other in 98 percent of scenarios studied. ART enhances RT, and is comparable to CT in 96 percent of scenarios, but its computational cost can be up to 3.5 times higher than CT when the program is highly constrained. Additionally, when constraint information is unavailable for a highly-constrained program, a large random test suite is as effective as CT or ART, yet its computational cost of test generation is significantly lower than that of other techniques.","1939-3520","","10.1109/TSE.2018.2852744","National Key Research and Development Plan; Nanjing University; DAASE EPSRC; EPSRC Fellowship; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405609","Combinatorial testing;random testing;adaptive random testing","Testing;Subspace constraints;Computational efficiency;Fault detection;Analytical models;Software systems","program testing","constraint information;failure rate;CT;random test suite;empirical comparison;combinatorial testing;adaptive random testing;test generation techniques;different test scenarios;testing setting;test scenarios;efficiency 98.0 percent;efficiency 96.0 percent","","5","","57","OAPA","6 Jul 2018","","","IEEE","IEEE Journals"
"PPChecker: Towards Accessing the Trustworthiness of Android Apps’ Privacy Policies","L. Yu; X. Luo; J. Chen; H. Zhou; T. Zhang; H. Chang; H. K. N. Leung","Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong; Department of Law, University of Hong Kong, Hong Kong; Department of Computing, Hong Kong Polytechnic University, Hong Kong","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","221","242","Recent years have witnessed a sharp increase of malicious apps that steal users' personal information. To address users' concerns about privacy risks and to comply with data protection laws, more and more apps are supplied with privacy policies written in natural language to help users understand an app's privacy practices. However, little is known whether these privacy policies are trustworthy or not. Questionable privacy policies may be prepared by careless app developers or someone with malicious intention. In this paper, we carry out a systematic study on privacy policy by proposing a novel approach to automatically identify five kinds of problems in privacy policy. After tackling several challenging issues, we implement the approach in a system, named PPChecker, and evaluate it with real apps and their privacy policies. The experimental results show that PPChecker can effectively identify questionable privacy policies with high precision. Applying PPChecker to 2,500 popular apps, we find that 1,850 apps (i.e., 74.0 percent) have at least one kind of problems. This study sheds light on the research of improving and regulating apps' privacy policies.","1939-3520","","10.1109/TSE.2018.2886875","Hong Kong RGC Projects; HKPolyU Research; National Natural Science Foundation of China; China Postdoctoral Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8576579","Android apps;privacy policy","Privacy;Google;Natural languages;Mobile handsets;Data protection;Force","Android (operating system);data privacy;mobile computing;trusted computing","PPChecker;malicious apps;privacy policy;app developers;Android app privacy policies","","","","92","OAPA","14 Dec 2018","","","IEEE","IEEE Journals"
"Integrative Double Kaizen Loop (IDKL): Towards a Culture of Continuous Learning and Sustainable Improvements for Software Organizations","O. Al-Baik; J. Miller","Department of Electronics & Computer Engineering, University of Alberta Edmonton, Edmonton, AB, Canada; Department of Electronics & Computer Engineering, University of Alberta Edmonton, Edmonton, AB, Canada","IEEE Transactions on Software Engineering","10 Dec 2019","2019","45","12","1189","1210","In the past decades, software organizations have been relying on implementing process improvement methods to advance quality, productivity, and predictability of their development and maintenance efforts. However, these methods have proven to be challenging to implement in many situations, and when implemented, their benefits are often not sustained. Commonly, the workforce requires guidance during the initial deployment, but what happens after the guidance stops? Why do not traditional improvement methods deliver the desired results? And, how do we maintain the improvements when they are realized? In response to these questions, we have combined social and organizational learning methods with Lean's continuous improvement philosophy, Kaizen, which has resulted in an IDKL model that has successfully promoted continuous learning and improvement. The IDKL has evolved through a real-life project with an industrial partner; the study employed ethnographic action research with 231 participants and had lasted for almost 3 years. The IDKL requires employees to continuously apply small improvements to the daily routines of the work-procedures. The small improvements by themselves are unobtrusive. However, the IDKL has helped the industrial partner to implant continuous improvement as a daily habit. This has led to realizing sustainable and noticeable improvements. The findings show that on average, Lead Time has dropped by 46 percent, Process Cycle Efficiency has increased by 137 percent, First-Pass Process Yield has increased by 27 percent, and Customer Satisfaction has increased by 25 percent.","1939-3520","","10.1109/TSE.2018.2829722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8345680","Kaizen;lean;organization learning;double loop learning;case study;empirical research","Continuous improvement;Research and development;Standards organizations;Learning systems","continuous improvement;customer satisfaction;organisational aspects;personnel;project management;software development management","process improvement methods;continuous improvement philosophy;first-pass process yield;process cycle efficiency;industrial partner;IDKL model;organizational learning methods;social learning methods;software organizations;sustainable improvements;continuous learning;integrative double Kaizen loop;efficiency 46.0 percent;efficiency 137.0 percent;efficiency 27.0 percent;efficiency 25.0 percent;time 3.0 year","","","","66","IEEE","24 Apr 2018","","","IEEE","IEEE Journals"
"ProXray: Protocol Model Learning and Guided Firmware Analysis","F. Fowze; D. J. Tian; G. Hernandez; K. Butler; T. Yavuz","Electrical and Computer Engineering, University of florida, Gainesville, Florida United States 32611 (e-mail: farhaan104@ufl.edu); CISE Department, University of Florida Herbert Wertheim College of Engineering, 130358 Gainesville, Florida United States (e-mail: root@davetingjian.org); CISE Department, University of Florida Herbert Wertheim College of Engineering, 130358 Gainesville, Florida United States (e-mail: grant.hernandez@ufl.edu); Computer and Information Science and Engineering, University of Florida, Gainesville, Florida United States 32611-1906 (e-mail: butler@ufl.edu); Electrical and Computer Engineering, University of Florida, Gainesville, Florida United States 32611 (e-mail: tuba@ece.ufl.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The number of Internet of Things (IoT) has reached 7 billion globally in early 2018 and are nearly ubiquitous in daily life. Knowing whether or not these devices are safe and secure to use is becoming critical. IoT devices usually implement communication protocols such as USB and Bluetooth within firmware to allow a wide range of functionality. Thus analyzing firmware using domain knowledge from these protocols is vital to understand device behavior, detect implementation bugs, and identify malicious components. Unfortunately, due to the complexity of these protocols, there is usually no formal specification available that can help automate the firmware analysis; as a result significant manual effort is currently required to study these protocols and to reverse engineer the device firmware. In this paper, we propose a new firmware analysis methodology using symbolic execution called ProXray, which can learn a protocol model from known firmware, and apply the model to recognize the protocol relevant fields and detect functionality within unknown firmware automatically. After the training phase, ProXray can fully automate the firmware analysis process while supporting user's queries in the form of protocol relevant constraints. We have applied ProXray to the USB and the Bluetooth protocols by learning protocol constraint models from firmware that implement these protocols. We are then able to map protocol fields and identify USB functionality automatically within all 6 unknown USB firmware while achieving more than an order of magnitude speedup in achieving protocol relevant targets in unknown Bluetooth firmware. Our model achieved high coverage of the USB and Bluetooth specifications for several important protocol fields. ProXray provides a new method to apply domain knowledge to firmware analysis automatically.","1939-3520","","10.1109/TSE.2019.2939526","Division of Computer and Network Systems; Semiconductor Research Corporation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823941","Protocol Learning;Model Extraction;Firmware;Symbolic Execution","Protocols;Universal Serial Bus;Bluetooth;Hidden Markov models;Analytical models;Microprogramming;Feature extraction","","","","","","","","4 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Correction of “A Comparative Study to Benchmark Cross-Project Defect Prediction Approaches”","S. Herbold; A. Trautsch; J. Grabowski","University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany; University of Goettingen, Göttingen, Germany","IEEE Transactions on Software Engineering","12 Jun 2019","2019","45","6","632","636","Unfortunately, the article “A Comparative Study to Benchmark Cross-project Defect Prediction Approaches” has a problem in the statistical analysis which was pointed out almost immediately after the pre-print of the article appeared online. While the problem does not negate the contribution of the the article and all key findings remain the same, it does alter some rankings of approaches used in the study. Within this correction, we will explain the problem, how we resolved it, and present the updated results.","1939-3520","","10.1109/TSE.2018.2790413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8248781","Cross-project defect prediction;benchmark;comparison;replication;correction","Sociology;Measurement;Benchmark testing;Statistical analysis;Ranking (statistics);Terminology","","","","","","13","","8 Jan 2018","","","IEEE","IEEE Journals"
"Safety Practices in Requirements Engineering: The Uni-REPM Safety Module","J. Vilela; J. Castro; L. E. G. Martins; T. Gorschek","Universidade Federal do Ceará (UFC), Quixadá, Cear??, Brazil; Universidade Federal de Pernambuco (UFPE), Recife-PE, Brazil; Departamento de Ciência e Tecnologia, Universidade Federal de São Paulo (UNIFESP), José dos, S??o Paulo, Brazil; Blekinge Institute of Technology (BTH), Karlskrona, Sweden","IEEE Transactions on Software Engineering","13 Mar 2020","2020","46","3","222","250","Context: Software is an important part in safety-critical system (SCS) development since it is becoming a major source of hazards. Requirements-related hazards have been associated with many accidents and safety incidents. Requirements issues tend to be mitigated in companies with high processes maturity levels since they do their business in a systematic, consistent and proactive approach. However, requirements engineers need systematic guidance to consider safety concerns early in the development process. Goal: the paper investigates which safety practices are suitable to be used in the Requirements Engineering (RE) process for SCS and how to design a safety maturity model for this area. Method: we followed the design science methodology to propose Uni-REPM SCS, a safety module for Unified Requirements Engineering Process Maturity Model (Uni-REPM). We also conducted a static validation with two practitioners and nine academic experts to evaluate its coverage, correctness, usefulness, and applicability. Results: The module has seven main processes, fourteen sub-processes and 148 practices that form the basis of safety processes maturity. Moreover, we describe its usage through a tool. Conclusions: The validation indicates a good coverage of practices and well receptivity by the experts. Finally, the module can help companies in evaluating their current practices.","1939-3520","","10.1109/TSE.2018.2846576","Funda????o de Amparo ?? Ci??ncia e Tecnologia do Estado de Pernambuco; Conselho Nacional de Desenvolvimento Cient??fico e Tecnol??gico; The Knowledge Foundation Sweden; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8382315","Safety-critical systems;requirements engineering;maturity models;Uni-REPM;safety engineering","Safety;Companies;Software;Capability maturity model;Requirements engineering;Systematics;Standards","DP industry;safety-critical software;systems analysis","design science methodology;Uni-REPM SCS;Unified Requirements Engineering Process Maturity Model;safety processes maturity;safety practices;Uni-REPM safety module;safety-critical system development;Requirements-related hazards;high processes maturity levels;safety maturity model","","","","98","IEEE","12 Jun 2018","","","IEEE","IEEE Journals"
"Companies' Participation in OSS Development - An Empirical Study of OpenStack","Y. Zhang; M. Zhou; A. Mockus; Z. Jin","School of Electronics Engineering and Computer Science, Peking University, 12465 Beijing, Beijing China (e-mail: yuxiaz@pku.edu.cn); School of Electronics Engineering and Computer Science, Peking University, Software Institute, Beijing, Beijing China 100871 (e-mail: zhmh@pku.edu.cn); Avaya Labs Research, Avaya Labs, Basking Ridge, New Jersey United States 07920 (e-mail: audris@utk.edu); School of EECS, Peking University, Beijing, Beijing China 100871 (e-mail: zhijin@pku.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Commercial participation continues to grow in open source software (OSS) projects and novel arrangements appear to emerge in company-dominated projects and ecosystems. What is the nature of these novel arrangements' Does volunteers' participation remain critical for these ecosystems' Despite extensive research on commercial participation in OSS, the exact nature and extent of company contributions to OSS development, and the impact of this engagement may have on the volunteer community have not been clarified. To bridge the gap, we perform an exploratory study of OpenStack: a large OSS ecosystem with intense commercial participation. We quantify companies' contributions via the developers that they provide and the commits made by those developers. We find that companies made far more contributions than volunteers and the distribution of the contributions made by different companies is also highly unbalanced. We observe eight unique contribution models based on companies' commercial objectives and characterize each model according to three dimensions: contribution intensity, extent, and focus. Companies providing full cloud solutions tend to make both intensive (more than other companies) and extensive (involving a wider variety of projects) contributions. Usage-oriented companies make extensive but less intense contributions. Companies driven by particular business needs focus their contributions on the specific projects addressing these needs. Minor contributors include community players (e.g., the Linux Foundation) and research groups. A model relating the number of volunteers to the diversity of contribution, shows a strong positive association between them.","1939-3520","","10.1109/TSE.2019.2946156","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862903","Open source ecosystem;software development;commercial participation;contribution extent;contribution intensity;contribution focus","Companies;Ecosystems;Biological system modeling;Software;Cloud computing;Linux","","","","3","","","CCBY","8 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Text Filtering and Ranking for Security Bug Report Prediction","F. Peters; T. T. Tun; Y. Yu; B. Nuseibeh","University of Limerick, Limerick, Ireland; Department of Computing and Communications, The Open University, Milton Keynes, United Kingdom; Department of Computing and Communications, The Open University, Milton Keynes, United Kingdom; University of Limerick, Limerick, Ireland","IEEE Transactions on Software Engineering","12 Jun 2019","2019","45","6","615","631","Security bug reports can describe security critical vulnerabilities in software products. Bug tracking systems may contain thousands of bug reports, where relatively few of them are security related. Therefore finding unlabelled security bugs among them can be challenging. To help security engineers identify these reports quickly and accurately, text-based prediction models have been proposed. These can often mislabel security bug reports due to a number of reasons such as class imbalance, where the ratio of non-security to security bug reports is very high. More critically, we have observed that the presence of security related keywords in both security and non-security bug reports can lead to the mislabelling of security bug reports. This paper proposes FARSEC, a framework for filtering and ranking bug reports for reducing the presence of security related keywords. Before building prediction models, our framework identifies and removes non-security bug reports with security related keywords. We demonstrate that FARSEC improves the performance of text-based prediction models for security bug reports in 90 percent of cases. Specifically, we evaluate it with 45,940 bug reports from Chromium and four Apache projects. With our framework, we mitigate the class imbalance issue and reduce the number of mislabelled security bug reports by 38 percent.","1939-3520","","10.1109/TSE.2017.2787653","Science Foundation Ireland; H2020 European Research Council; EPSRC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240740","Security cross words;security related keywords;security bug reports;text filtering;ranking;prediction models;transfer learning","Security;Computer bugs;Predictive models;Software;Data models;Measurement;Buildings","information filtering;program debugging;public domain software;security of data;text analysis","security bug report prediction;security critical vulnerabilities;text-based prediction models;text filtering;software products;FARSEC","","3","","50","","27 Dec 2017","","","IEEE","IEEE Journals"
"Empirical Evaluation of Fault Localisation Using Code and Change Metrics","J. Sohn; S. Yoo","School of Computing, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: kasio555@kaist.ac.kr); School of Computing, Korea Advanced Institute of Science and Technology, 34968 Daejeon, Daejeon Korea (the Republic of) (e-mail: shin.yoo@kaist.ac.kr)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Fault localisation aims to reduce the debugging efforts of human developers by highlighting the program elements that are suspected to be the root cause of the observed failure. Spectrum Based Fault Localisation (SBFL), a coverage based approach, has been widely studied in many researches as a promising localisation technique. Recently, however, it has been proven that SBFL techniques have reached the limit of further improvement. To overcome the limitation, we extend SBFL with code and change metrics that have been mainly studied in defect prediction, such as size, age, and churn. FLUCCS, our fault learn-to-rank localisation technique, employs both existing SBFL formulas and these metrics as input. We investigate the effect of employing code and change metrics for fault localisation using four different learn-to-rank techniques: Genetic Programming, Gaussian Process Modelling, Support Vector Machine, and Random Forest. We evaluate the performance of FLUCCS with 386 real world faults collected from Defects4J repository. The results show that FLUCCS with code and change metrics places 144 faults at the top and 304 faults within the top ten. This is a significant improvement over the state-of-art SBFL formulas, which can locate 65 and 212 faults at the top and within the top ten, respectively. We also investigate the feasibility of cross-project transfer learning of fault localisation. The results show that, while there exist project-specific properties that can be exploited for better localisation per project, ranking models learnt from one project can be applied to others without significant loss of effectiveness.","1939-3520","","10.1109/TSE.2019.2930977","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8772166","Fault Localisation;SBSE;Genetic Programming","Measurement;Debugging;Genetic programming;Feature extraction;Support vector machines;Training","","","","3","","","","25 Jul 2019","","","IEEE","IEEE Early Access Articles"
"MSeer—An Advanced Technique for Locating Multiple Bugs in Parallel","R. Gao; W. E. Wong","University of Texas at Dallas, Richardson, TX; University of Texas at Dallas, Richardson, TX","IEEE Transactions on Software Engineering","13 Mar 2019","2019","45","3","301","318","In practice, a program may contain multiple bugs. The simultaneous presence of these bugs may deteriorate the effectiveness of existing fault-localization techniques to locate program bugs. While it is acceptable to use all failed and successful tests to identify suspicious code for programs with exactly one bug, it is not appropriate to use the same approach for programs with multiple bugs because the due-to relationship between failed tests and underlying bugs cannot be easily identified. One solution is to generate fault-focused clusters by grouping failed tests caused by the same bug into the same clusters. We propose MSeer-an advanced fault localization technique for locating multiple bugs in parallel. Our major contributions include the use of (1) a revised Kendall tau distance to measure the distance between two failed tests, (2) an innovative approach to simultaneously estimate the number of clusters and assign initial medoids to these clusters, and (3) an improved K-medoids clustering algorithm to better identify the due-to relationship between failed tests and their corresponding bugs. Case studies on 840 multiple-bug versions of seven programs suggest that MSeer performs better in terms of effectiveness and efficiency than two other techniques for locating multiple bugs in parallel.","1939-3520","","10.1109/TSE.2017.2776912","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8119545","Software fault localization;parallel debugging;multiple bugs;clustering;distance metrics","Computer bugs;Clustering algorithms;Measurement;Software;Indexes;Debugging;Runtime","fault diagnosis;pattern clustering;program debugging;program testing;software fault tolerance","failed tests;corresponding bugs;multiple-bug versions;locating multiple bugs;program bugs;successful tests;underlying bugs;fault-focused clusters;MSeer;advanced fault localization technique;K-medoids clustering algorithm","","3","","76","","23 Nov 2017","","","IEEE","IEEE Journals"
"Verification Templates for the Analysis of User Interface Software Design","M. D. Harrison; P. Masci; J. C. Campos","School of Computing, Newcastle University, Newcastle upon Tyne, United Kingdom; HASLab/INESC TEC and Universidade do Minho, Braga, Portugal; HASLab/INESC TEC and Universidade do Minho, Braga, Portugal","IEEE Transactions on Software Engineering","26 Aug 2019","2019","45","8","802","822","The paper describes templates for model-based analysis of usability and safety aspects of user interface software design. The templates crystallize general usability principles commonly addressed in user-centred safety requirements, such as the ability to undo user actions, the visibility of operational modes, and the predictability of user interface behavior. These requirements have standard forms across different application domains, and can be instantiated as properties of specific devices. The modeling and analysis process is carried out using the Prototype Verification System (PVS), and is further facilitated by structuring the specification of the device using a format that is designed to be generic across interactive systems. A concrete case study based on a commercial infusion pump is used to illustrate the approach. A detailed presentation of the automated verification process using PVS shows how failed proof attempts provide precise information about problematic user interface software features.","1939-3520","","10.1109/TSE.2018.2804939","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8289349","Human-computer interaction;model-based development;formal specifications;formal verification;prototype verification system (PVS)","User interfaces;Safety;ISO Standards;Usability","program verification;security of data;user interfaces","user interface software design;model-based analysis;safety aspects;general usability principles;user-centred safety requirements;automated verification process;prototype verification system;verification templates","","","","62","","12 Feb 2018","","","IEEE","IEEE Journals"
"LEILA: Formal Tool for Identifying Mobile Malicious Behaviour","G. Canfora; F. Martinelli; F. Mercaldo; V. Nardone; A. Santone; C. A. Visaggio","Department of Engineering, University of Sannio, Benevento, BN, Italy; National Research Council of Italy (CNR), Pisa, Italy; National Research Council of Italy (CNR), Pisa, Italy; Department of Engineering, University of Sannio, Benevento, BN, Italy; Department of Bioscience and Territory, University of Molise, Pesche (IS), CB, Italy; Department of Engineering, University of Sannio, Benevento, BN, Italy","IEEE Transactions on Software Engineering","10 Dec 2019","2019","45","12","1230","1252","With the increasing diffusion of mobile technologies, nowadays mobile devices represent an irreplaceable tool to perform several operations, from posting a status on a social network to transfer money between bank accounts. As a consequence, mobile devices store a huge amount of private and sensitive information and this is the reason why attackers are developing very sophisticated techniques to extort data and money from our devices. This paper presents the design and the implementation of LEILA (formaL tool for idEntifying mobIle maLicious behAviour), a tool targeted at Android malware families detection. LEILA is based on a novel approach that exploits model checking to analyse and verify the Java Bytecode that is produced when the source code is compiled. After a thorough description of the method used for Android malware families detection, we report the experiments we have conducted using LEILA. The experiments demonstrated that the tool is effective in detecting malicious behaviour and, especially, in localizing the payload within the code: we evaluated real-world malware belonging to several widespread families obtaining an accuracy ranging between 0.97 and 1.","1939-3520","","10.1109/TSE.2018.2834344","H2020 EU; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356128","Security;malware;model checking;testing;Android","Malware;Androids;Humanoid robots;Payloads;Computer security;Model checking;Automata","Android (operating system);formal verification;invasive software;Java;mobile computing","LEILA;Android malware families detection;real-world malware;formal tool;mobile technologies;nowadays mobile devices;irreplaceable tool;social network;bank accounts;private information;sensitive information;sophisticated techniques;mobile malicious behaviour;identifying mobile malicious behaviour","","8","","55","IEEE","8 May 2018","","","IEEE","IEEE Journals"
"The Mutation and Injection Framework: Evaluating Clone Detection Tools with Mutation Analysis","J. Svajlenko; C. K. Roy","Department of Computer Science, University of Saskatchewan, Saskatoon, SK, Canada; Department of Computer Science, University of Saskatchewan, Saskatoon, SK, Canada","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","1060","1087","An abundant number of clone detection tools have been proposed in the literature due to the many applications and benefits of clone detection. However, there has been difficulty in the performance evaluation and comparison of these clone detectors. This is due to a lack of reliable benchmarks, and the manual efforts required to validate a large number of candidate clones. In particular, there has been a lack of a synthetic benchmark that can precisely and comprehensively measure clone-detection recall. In this paper, we present a mutation-analysis based benchmarking framework that can be used not only to evaluate the recall of clone detection tools for different types of clones but also for specific kinds of clone edits and without any manual efforts. The framework uses an editing taxonomy of clone synthesis for generating thousands of artificial clones, injects into code bases and automatically evaluates the subject clone detection tools following the mutation analysis approach. Additionally, the framework has features where custom clone pairs could also be used in the framework for evaluating the subject tools. This gives the opportunity of evaluating specialized tools for specialized contexts such as evaluating a tool’s capability for the detection of complex Type-4 clones or real world clones without writing complex mutation operators for them. We demonstrate this framework by evaluating the performance of ten modern clone detection tools across two clone granularities (function and block) and three programming languages (Java, C and C#). Furthermore, we provide a variant of the framework that can be used to evaluate specialized tools such as for large gaped clone detection. Our experiments demonstrate confidence in the accuracy of our Mutation and Injection Framework when comparing against the expected results of the corresponding tools, and widely used real-world benchmarks such as Bellon’s benchmark and BigCloneBench. We provide features so that most clone detection tools that report clones in the form of clone pairs (either in filename/line numbers or filename/tokens) could be evaluated using the framework.","1939-3520","","10.1109/TSE.2019.2912962","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8695849","Clone;clone detection;benchmark;mutation analysis;mutation operators;recall","Cloning;Tools;Benchmark testing;Software systems;Detectors;Atmospheric measurements;Particle measurements","","","","1","","53","IEEE","23 Apr 2019","","","IEEE","IEEE Journals"
"Modeling and Recommending Open Source Licenses with findOSSLicense","G. M. Kapitsaki; G. Charalambous","University of Cyprus, Nicosia, Cyprus; University of Cyprus, Nicosia, Cyprus","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","919","935","Open source software is widely used in the software industry and the academia. Licenses applied to open source software provide the terms for its further use and distribution. Decisions regarding licensing for new software systems are essential for the system's future use. In this paper, we introduce findOSSLicense, a license recommender that guides users into choosing the appropriate open source license for their software under creation. We also introduce our license modeling concept that is used in the recommendation process. The license modeling captures the properties usually found in existing open source licenses following an analysis performed on license texts. The recommendation process of findOSSLicense is based on a hybrid recommender that uses constraint-based, content-based and collaborative filtering giving also space for flexibility in the use of the system by its end-users who can adapt some system properties. User input, but also external sources of information including existing open source projects, are considered for the creation of the recommendations, whereas licenses used in third party software employed in the software are examined on a limited basis. findOSSLicense has been evaluated with the participation of users of various expertise.","1939-3520","","10.1109/TSE.2019.2909021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680684","Open source software;recommender systems;software reusability;software tools","Licenses;Task analysis;Encoding;Analytical models;Open source software;Law","","","","","","54","IEEE","2 Apr 2019","","","IEEE","IEEE Journals"
"A Chaos Engineering System for Live Analysis and Falsification of Exception-handling in the JVM","L. Zhang; B. Morin; P. Haller; B. Baudry; M. Monperrus","EECS - TCS, KTH Royal Institute of Technology, Stockholm, Stockholm Sweden 10044 (e-mail: longz@kth.se); ICT, SINTEF, Oslo, Norway Norway 0314 (e-mail: brice.morin@sintef.no); EECS - TCS, KTH Royal Institute of Technology, Stockholm, Stockholm Sweden (e-mail: phaller@kth.se); EECS - SCS, KTH Royal Institute of Technology, Stockholm, Stockholm Sweden (e-mail: baudry@kth.se); Department of Computer Science, KTH Royal Institute of Technology School of Electrical Engineering and Computer Science, Stockholm, Stockholm Sweden (e-mail: martin.monperrus@csc.kth.se)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Software systems contain resilience code to handle those failures and unexpected events happening in production. It is essential for developers to understand and assess the resilience of their systems. Chaos engineering is a technology that aims at assessing resilience and uncovering weaknesses by actively injecting perturbations in production. In this paper, we propose a novel design and implementation of a chaos engineering system in Java called ChaosMachine. It provides a unique and actionable analysis on exception-handling capabilities in production, at the level of try-catch blocks. To evaluate our approach, we have deployed ChaosMachine on top of 3 large-scale and well-known Java applications totaling 630k lines of code. Our results show that ChaosMachine reveals both strengths and weaknesses of the resilience code of a software system at the level of exception handling.","1939-3520","","10.1109/TSE.2019.2954871","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8908767","dynamic analysis;exception-handling;production systems;chaos engineering","Chaos;Production;Perturbation methods;Resilience;Measurement;Monitoring;Java","","","","2","","","","21 Nov 2019","","","IEEE","IEEE Early Access Articles"
"Towards Prioritizing Documentation Effort","P. W. McBurney; S. Jiang; M. Kessentini; N. A. Kraft; A. Armaly; M. W. Mkaouer; C. McMillan","Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer and Information Science, University of Michigan-Dearborn, Dearborn, MI; ABB Corporate Research, Raleigh, NC; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN; Department of Computer and Information Science, University of Michigan-Dearborn, Dearborn, MI; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN","IEEE Transactions on Software Engineering","17 Sep 2018","2018","44","9","897","913","Programmers need documentation to comprehend software, but they often lack the time to write it. Thus, programmers must prioritize their documentation effort to ensure that sections of code important to program comprehension are thoroughly explained. In this paper, we explore the possibility of automatically prioritizing documentation effort. We performed two user studies to evaluate the effectiveness of static source code attributes and textual analysis of source code towards prioritizing documentation effort. The first study used open-source API Libraries while the second study was conducted using closed-source industrial software from ABB. Our findings suggest that static source code attributes are poor predictors of documentation effort priority, whereas textual analysis of source code consistently performed well as a predictor of documentation effort priority.","1939-3520","","10.1109/TSE.2017.2716950","National Science Foundation Graduate Research Fellowship Program; National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953505","Code documentation;program comprehension;software maintenance","Documentation;Libraries;Java;Gold;Programming;Software;Neural networks","application program interfaces;program diagnostics;public domain software;software maintenance","prioritizing documentation effort;static source code attributes;open-source API Libraries;closed-source industrial software;documentation effort priority","","1","","78","","19 Jun 2017","","","IEEE","IEEE Journals"
"Better Data Labelling with EMBLEM (and how that Impacts Defect Prediction)","H. Tu; Z. Yu; T. Menzies","Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States (e-mail: hqtu@ncsu.edu); Computer Science, North Carolina State University, 6798 Raleigh, North Carolina United States 27606 (e-mail: zyu9@ncsu.edu); Computer Science, North Carolina State University College of Engineering, 242510 Raleigh, North Carolina United States 27695-7901 (e-mail: timm@ieee.org)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Standard automatic methods for recognizing problematic development commits can be greatly improved via the incremental application of human+artificial expertise. In this approach, called EMBLEM, an AI tool first explore the software development process to label commits that are most problematic. Humans then apply their expertise to check those labels (perhaps resulting in the AI updating the support vectors within their SVM learner). We recommend this human+AI partnership, for several reasons. When a new domain is encountered, EMBLEM can learn better ways to label which comments refer to real problems. Also, in studies with 9 open source software projects, labelling via EMBLEM's incremental application of human+AI is at least an order of magnitude cheaper than existing methods (approximately, eight times). Further, EMBLEM is very effective. For the data sets explored here, EMBLEM better labelling methods significantly improved Popt(20) and G-scores performance in nearly all the projects studied here.","1939-3520","","10.1109/TSE.2020.2986415","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9064604","Human-in-the-loop AI;Data Labelling;Defect Prediction;Software Analytics","Labeling;Computer bugs;Data models;Software;Support vector machines;Standards;Task analysis","","","","2","","","","13 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Historical Spectrum based Fault Localization","M. Wen; J. Chen; Y. Tian; R. Wu; D. Hao; S. Han; S. C. Cheung","Cyber Science and Engineering, Huazhong University of Science and Technology, 12443 Wuhan, Hubei China (e-mail: mwenaa@cse.ust.hk); College of Intelligence and Computing, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: junjiechen@tju.edu.cn); Computer Science and Engineering, the Hong Kong University of Science and Technology, Hong Kong, Hong Kong Hong Kong (e-mail: ytianas@cse.ust.hk); the Department of Cyber Space Security, Xiamen University, 12466 Xiamen, Fujian China (e-mail: wurongxin@xmu.edu.cn); EECS,Peking University, Institute of Software, Beijing, Beijing China 100871 (e-mail: haodan@pku.edu.cn); Software Analytics, Microsoft Research Asia, Beijing, Beijing China 100080 (e-mail: shihan@microsoft.com); Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon Hong Kong (e-mail: scc@cse.ust.hk)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Spectrum-based fault localization (SBFL) techniques are widely studied and have been evaluated to be effective in locating faults. Recent studies also showed that developers from industry value automated SBFL techniques. However, their effectiveness is still limited by two main reasons. First, the test coverage information leveraged to construct the spectrum does not reflect the root cause directly. Second, SBFL suffers from the tie issue so that the buggy code entities can not be well differentiated from non-buggy ones. To address these challenges, we propose to leverage the information of version histories in fault localization based on the following two intuitions. First, version histories record how bugs are introduced to software projects and this information reflects the root cause of bugs directly. Second, the evolution histories of code can help differentiate those suspicious code entities ranked in tie by SBFL. Our intuitions are also inspired by the observations on debugging practices from large open source projects and industry. Based on the intuitions, we propose a novel technique HSFL (historical spectrum based fault localization). Specifically, HSFL identifies bug-inducing commits from the version history in the first step. It then constructs historical spectrum (denoted as Histrum) based on bug-inducing commits, which is another dimension of spectrum orthogonal to the coverage based spectrum used in SBFL. HSFL finally ranks the suspicious code elements based on our proposed Histrum and the conventional spectrum. HSFL outperforms the state-of-the-art SBFL techniques significantly on the Defects4J benchmark. Specifically, it locates and ranks the buggy statement at Top-1 for 77.8% more bugs as compared with SBFL, and 33.9% more bugs at Top-5. Besides, for the metrics MAP and MRR, HSFL achieves an average improvement of 28.3% and 40.8% over all bugs, respectively. Moreover, HSFL can also outperform other six families of fault localization techniques, and our proposed Histrum model can be integrated with different families of techniques and boost their performance.","1939-3520","","10.1109/TSE.2019.2948158","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8873606","Fault Localization;Version Histories;Bug-Inducing Commits","Computer bugs;History;Debugging;Industries;Software;Benchmark testing;Maintenance engineering","","","","1","","","","17 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Coverage-Based Greybox Fuzzing as Markov Chain","M. Böhme; V. Pham; A. Roychoudhury","Department of Computer Science, National University of Singpore, Singapore; Department of Computer Science, National University of Singpore, Singapore; Department of Computer Science, National University of Singpore, Singapore","IEEE Transactions on Software Engineering","15 May 2019","2019","45","5","489","506","Coverage-based Greybox Fuzzing (CGF) is a random testing approach that requires no program analysis. A new test is generated by slightly mutating a seed input. If the test exercises a new and interesting path, it is added to the set of seeds; otherwise, it is discarded. We observe that most tests exercise the same few “high-frequency” paths and develop strategies to explore significantly more paths with the same number of tests by gravitating towards low-frequency paths. We explain the challenges and opportunities of CGF using a Markov chain model which specifies the probability that fuzzing the seed that exercises path i generates an input that exercises path j. Each state (i.e., seed) has an energy that specifies the number of inputs to be generated from that seed. We show that CGF is considerably more efficient if energy is inversely proportional to the density of the stationary distribution and increases monotonically every time that seed is chosen. Energy is controlled with a power schedule. We implemented several schedules by extending AFL. In 24 hours, AFLFast exposes 3 previously unreported CVEs that are not exposed by AFL and exposes 6 previously unreported CVEs 7x faster than AFL. AFLFast produces at least an order of magnitude more unique crashes than AFL. We compared AFLFast to the symbolic executor Klee. In terms of vulnerability detection, AFLFast is significantly more effective than Klee on the same subject programs that were discussed in the original Klee paper. In terms of code coverage, AFLFast only slightly outperforms Klee while a combination of both tools achieves best results by mitigating the individual weaknesses.","1939-3520","","10.1109/TSE.2017.2785841","National Research Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8233151","Vulnerability detection;fuzzing;path exploration;symbolic execution;automated testing","Schedules;Markov processes;Computer crashes;Search problems;Tools;Systematics","Markov processes;probability;program diagnostics;program testing","CGF;random testing approach;program analysis;seed input;high-frequency paths;low-frequency paths;Markov chain model;code coverage;coverage-based greybox fuzzing;AFLFast","","22","","37","","21 Dec 2017","","","IEEE","IEEE Journals"
"Developer Testing in the IDE: Patterns, Beliefs, and Behavior","M. Beller; G. Gousios; A. Panichella; S. Proksch; S. Amann; A. Zaidman","Delft University of Technology, Delft, CD, The Netherlands; Delft University of Technology, Delft, CD, The Netherlands; University of Luxembourg, Esch-sur-Alzette, Luxembourg; Technische Universität Darmstadt, Darmstadt, Germany; Technische Universität Darmstadt, Darmstadt, Germany; Delft University of Technology, Delft, CD, The Netherlands","IEEE Transactions on Software Engineering","13 Mar 2019","2019","45","3","261","284","Software testing is one of the key activities to achieve software quality in practice. Despite its importance, however, we have a remarkable lack of knowledge on how developers test in real-world projects. In this paper, we report on a large-scale field study with 2,443 software engineers whose development activities we closely monitored over 2.5 years in four integrated development environments (IDEs). Our findings, which largely generalized across the studied IDEs and programming languages Java and C#, question several commonly shared assumptions and beliefs about developer testing: half of the developers in our study do not test; developers rarely run their tests in the IDE; most programming sessions end without any test execution; only once they start testing, do they do it extensively; a quarter of test cases is responsible for three quarters of all test failures; 12 percent of tests show flaky behavior; Test-Driven Development (TDD) is not widely practiced; and software developers only spend a quarter of their time engineering tests, whereas they think they test half of their time. We summarize these practices of loosely guiding one's development efforts with the help of testing in an initial summary on Test-Guided Development (TGD), a behavior we argue to be closer to the development reality of most developers than TDD.","1939-3520","","10.1109/TSE.2017.2776152","Dutch Science Foundation; German Federal Ministry of Education and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8116886","Developer testing;unit tests;testing effort;field study;test-driven development (TDD);JUnit;TestRoots WatchDog;KaVE FeedBag++","Testing;Software;Visualization;Servers;Java;Androids;Humanoid robots","C# language;Java;program testing;software quality","developer testing;IDE;software testing;integrated development environments;test execution;test cases;test failures;software developers;time engineering tests;development reality;test-driven development;software engineers;test-guided development;software quality;programming languages;Java;C#;programming sessions","","11","","107","","22 Nov 2017","","","IEEE","IEEE Journals"
"Diversified Third-party Library Prediction for Mobile App Development","Q. He; B. Li; F. Chen; J. Grundy; X. Xia; Y. Yang","School of Software and Electrical Engineering, Swinburne University of Technology, 3783 Hawthorn, Victoria Australia (e-mail: qhe@swin.edu.au); School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Victoria Australia (e-mail: boli@swin.edu.au); School of Information Technology, Deakin University, Burwood, Victoria Australia (e-mail: feifei.chen@deakin.edu.au); Faculty of IT, Monash University, Clayton, Victoria Australia 3800 (e-mail: john.grundy@monash.edu); Faculty of Information Technology, Monash University, 2541 MELBOURNE, Victoria Australia 3800 (e-mail: xin.xia@monash.edu); School of Software and Electrical Engineering, Swinburne University of Technology, Melbourne, Victoria Australia 3122 (e-mail: yyang@swin.edu.au)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","The rapid growth of mobile apps has significantly promoted the use of third-party libraries in mobile app development. However, mobile app developers are now facing the challenge of finding useful third-party libraries for improving their apps, e.g., to enhance user interfaces, to add social features, etc. An effective approach is to leverage collaborative filtering (CF) to predict useful third-party libraries for developers. We employed Matrix Factorization (MF) approaches - the classic CF-based prediction approaches - to make the predictions based on a total of 31,432 Android apps from Google Play. However, our investigation shows that there is a significant lack of diversity in the prediction results - a small fraction of popular third-party libraries dominate the prediction results while most other libraries are ill-served. The low diversity in the prediction results limits the usefulness of the prediction because it lacks novelty and serendipity which are much appreciated by mobile app developers. In order to increase the diversity in the prediction results, we designed an innovative MF-based approach, namely LibSeek, specifically for predicting useful third-party libraries for mobile apps. It employs an adaptive weighting mechanism to neutralize the bias caused by the popularity of third-party libraries. In addition, it introduces neighborhood information, i.e., information about similar apps and similar third-party libraries, to personalize the predictions for individual apps. The experimental results show that LibSeek can significantly diversify the prediction results, and in the meantime, increase the prediction accuracy.","1939-3520","","10.1109/TSE.2020.2982154","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9043686","Third-party library;prediction;mobile app development;matrix factorization;diversity;accuracy bias","Libraries;Mobile applications;Predictive models;Google;Gold;User interfaces;Collaboration","","","","2","","","","20 Mar 2020","","","IEEE","IEEE Early Access Articles"
"Fine-grained Dynamic Resource Allocation for Big-Data Applications","L. Baresi; A. Leva; G. Quattrocchi","Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Milano, MI Italy (e-mail: baresi@elet.polimi.it); Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, Mlano, MI Italy (e-mail: alberto.leva@polimi.it); Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, 18981 Milano, MI Italy (e-mail: giovanni.quattrocchi@polimi.it)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Big-data applications are batch applications that exploit dedicated frameworks to perform massively parallel computations across clusters of machines. The time needed to process the entirety of the inputs represents the application's response time, which can be subject to deadlines. Spark, probably the most famous incarnation of these frameworks today, allocates resources to applications statically at the beginning of the execution and deviations are not managed: to meet the applications' deadlines, resources must be allocated carefully. This paper proposes an extension to Spark, called xSpark, that is able to allocate and redistribute resources to applications dynamically to meet deadlines and cope with the execution of unanticipated applications. This work is based on two key enablers: containers, to isolate Spark's parallel executors and allow for the dynamic and fast allocation of resources, and control-theory to govern resource allocation at runtime and obtain the precision and speed that are needed. Our evaluation shows that xSpark can (i) allocate resources efficiently to execute single applications with respect to set deadlines and (ii) reduce deadline violations (w.r.t. Spark) when executing multiple concurrent applications.","1939-3520","","10.1109/TSE.2019.2931537","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8778680","Distributed architectures;Control theory;Quality assurance;Batch processing systems","Sparks;Resource management;Dynamic scheduling;Containers;Task analysis;Runtime;Control theory","","","","4","","","","29 Jul 2019","","","IEEE","IEEE Early Access Articles"
"A Developer Centered Bug Prediction Model","D. Di Nucci; F. Palomba; G. De Rosa; G. Bavota; R. Oliveto; A. De Lucia","University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; University of Salerno, Fisciano, SA, Italy; Università della Svizzera Italiana (USI), Lugano, Switzerland; University of Molise, Pesche (IS), Campobasso, Italy; University of Salerno, Fisciano, SA, Italy","IEEE Transactions on Software Engineering","8 Jan 2018","2018","44","1","5","24","Several techniques have been proposed to accurately predict software defects. These techniques generally exploit characteristics of the code artefacts (e.g., size, complexity, etc.) and/or of the process adopted during their development and maintenance (e.g., the number of developers working on a component) to spot out components likely containing bugs. While these bug prediction models achieve good levels of accuracy, they mostly ignore the major role played by human-related factors in the introduction of bugs. Previous studies have demonstrated that focused developers are less prone to introduce defects than non-focused developers. According to this observation, software components changed by focused developers should also be less error prone than components changed by less focused developers. We capture this observation by measuring the scattering of changes performed by developers working on a component and use this information to build a bug prediction model. Such a model has been evaluated on 26 systems and compared with four competitive techniques. The achieved results show the superiority of our model, and its high complementarity with respect to predictors commonly used in the literature. Based on this result, we also show the results of a “hybrid” prediction model combining our predictors with the existing ones.","1939-3520","","10.1109/TSE.2017.2659747","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835258","Scattering metrics;bug prediction;empirical study;mining software repositories","Measurement;Computer bugs;Predictive models;Complexity theory;Scattering;Entropy;Software","object-oriented programming;program debugging;software maintenance;software reliability","software components;hybrid prediction model;code artefacts;software defects prediction;developer centered bug prediction model","","18","","54","","26 Jan 2017","","","IEEE","IEEE Journals"
"A Model-Integrated Approach to Designing Self-Protecting Systems","S. Iannucci; S. Abdelwahed; A. Montemaggio; M. Hannis; L. Leonard; J. S. King; J. A. Hamilton","Department of Computer Science and Engineering, Mississippi State University, Starkville, MS, USA; Department of Electrical and Computer Engineering, Virginia Commonwealth University, Richmond, VA, USA; Center for Cyber Innovation (CCI), Mississippi State University, Starkville, MS, USA; Center for Cyber Innovation (CCI), Mississippi State University, Starkville, MS, USA; U.S. Army Engineer Research and Development Center (ERDC), Vicksburg, MS, USA; U.S. Army Engineer Research and Development Center (ERDC), Vicksburg, MS, USA; Center for Cyber Innovation (CCI), Mississippi State University, Starkville, MS, USA","IEEE Transactions on Software Engineering","10 Dec 2020","2020","46","12","1380","1392","One of the major trends in research on Self-Protecting Systems is to use a model of the system to be protected to predict its evolution. However, very often, devising the model requires special knowledge of mathematical frameworks, that prevents the adoption of this technique outside of the academic environment. Furthermore, some of the proposed approaches suffer from the curse of dimensionality, as their complexity is exponential in the size of the protected system. In this paper, we introduce a model-integrated approach for the design of Self-Protecting Systems, which automatically generates and solves Markov Decision Processes (MDPs) to obtain optimal defense strategies for systems under attack. MDPs are created in such a way that the size of the state space does not depend on the size of the system, but on the scope of the attack, which allows us to apply it to systems of arbitrary size.","1939-3520","","10.1109/TSE.2018.2880218","Engineer Research and Development Center; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8528892","Intrusion response system;autonomic security management","Computational modeling;Servers;Microwave integrated circuits;Predictive models;Security;Mathematical model","Markov processes;security of data","model-integrated approach;protected system;Self-Protecting Systems;MarkoV decision processes;optimal defense strategies;curse of dimensionality","","1","","62","IEEE","9 Nov 2018","","","IEEE","IEEE Journals"
"The Impact of Class Rebalancing Techniques on the Performance and Interpretation of Defect Prediction Models","C. Tantithamthavorn; A. E. Hassan; K. Matsumoto","Faculty of Information Technology, Monash University, Clayton, VIC, Australia; School of Computing, Queen's University, Kingston, ON, Canada; Graduate School of Information Science, Nara Institute of Science and Technology, Ikoma, Japan","IEEE Transactions on Software Engineering","11 Nov 2020","2020","46","11","1200","1219","Defect models that are trained on class imbalanced datasets (i.e., the proportion of defective and clean modules is not equally represented) are highly susceptible to produce inaccurate prediction models. Prior research compares the impact of class rebalancing techniques on the performance of defect models but arrives at contradictory conclusions due to the use of different choice of datasets, classification techniques, and performance measures. Such contradictory conclusions make it hard to derive practical guidelines for whether class rebalancing techniques should be applied in the context of defect models. In this paper, we investigate the impact of class rebalancing techniques on the performance measures and interpretation of defect models. We also investigate the experimental settings in which class rebalancing techniques are beneficial for defect models. Through a case study of 101 datasets that span across proprietary and open-source systems, we conclude that the impact of class rebalancing techniques on the performance of defect prediction models depends on the used performance measure and the used classification techniques. We observe that the optimized SMOTE technique and the under-sampling technique are beneficial when quality assurance teams wish to increase AUC and Recall, respectively, but they should be avoided when deriving knowledge and understandings from defect models.","1939-3520","","10.1109/TSE.2018.2876537","Grant-in-Aid for JSPS Fellows; Natural Sciences and Engineering Research Council of Canada; Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8494821","Software quality assurance;software defect prediction;class rebalancing techniques;experimental design;empirical investigation","Predictive models;Training;Analytical models;Guidelines;Context modeling;Open source software","learning (artificial intelligence);pattern classification;sampling methods;software metrics;software quality;software reliability","classification techniques;class rebalancing techniques;defect prediction models;SMOTE technique;class imbalanced datasets;performance measure","","17","","99","IEEE","17 Oct 2018","","","IEEE","IEEE Journals"
"Implementing and Evaluating Candidate-Based Invariant Generation","A. Betts; N. Chong; P. Deligiannis; A. F. Donaldson; J. Ketema","Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom","IEEE Transactions on Software Engineering","16 Jul 2018","2018","44","7","631","650","The discovery of inductive invariants lies at the heart of static program verification. Presently, many automatic solutions to inductive invariant generation are inflexible, only applicable to certain classes of programs, or unpredictable. An automatic technique that circumvents these deficiencies to some extent is candidate-based invariant generation, whereby a large number of candidate invariants are guessed and then proven to be inductive or rejected using a sound program analyzer. This paper describes our efforts to apply candidate-based invariant generation in GPUVerify, a static checker for programs that run on GPUs. We study a set of 383 GPU programs that contain loops, drawn from a number of open source suites and vendor SDKs. Among this set, 253 benchmarks require provision of loop invariants for verification to succeed. We describe the methodology we used to incrementally improve the invariant generation capabilities of GPUVerify to handle these benchmarks, through candidate-based invariant generation, using cheap static analysis to speculate potential program invariants. We also describe a set of experiments that we used to examine the effectiveness of our rules for candidate generation, assessing rules based on their generality (the extent to which they generate candidate invariants), hit rate (the extent to which the generated candidates hold), worth (the extent to which provable candidates actually help in allowing verification to succeed), and influence (the extent to which the success of one generation rule depends on candidates generated by another rule). We believe that our methodology may serve as a useful framework for other researchers interested in candidate-based invariant generation. The candidates produced by GPUVerify help to verify 231 of the 253 programs. This increase in precision, however, makes GPUVerify sluggish: the more candidates that are generated, the more time is spent determining which are inductive invariants. To speed up this process, we have investigated four under-approximating program analyses that aim to reject false candidates quickly and a framework whereby these analyses can run in sequence or in parallel. Across two platforms, running Windows and Linux, our results show that the best combination of these techniques running sequentially-speeds up invariant generation across our benchmarks by 1.17× (Windows) and 1.01× (Linux), with per-benchmark best speedups of 93.58× (Windows) and 48.34× (Linux), and worst slowdowns of 10.24× (Windows) and 43.31× (Linux). We find that parallelizing the strategies marginally improves overall invariant generation speedups to 1.27× (Windows) and 1.11× (Linux), maintains good best-case speedups of 91.18× (Windows) and 44.60× (Linux), and, importantly, dramatically reduces worst-case slowdowns to 3.15× (Windows) and 3.17× (Linux).","1939-3520","","10.1109/TSE.2017.2718516","EU FP7 STREP project CARP; EPSRC PSL; Imperial College London’s EPSRC Impact Acceleration Account; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7955079","Formal verification;GPUs;invariant generation","Linux;Graphics processing units;Benchmark testing;Tools;Cognition;Acceleration","formal verification;graphics processing units;Linux;Microsoft Windows (operating systems);program verification","invariant generation speedups;inductive invariant generation;candidate invariants;invariant generation capabilities;potential program invariants;GPUVerify;SDK;candidate-based invariant generation evaluation;GPU programs;Windows;Linux;static program verification","","","","62","","22 Jun 2017","","","IEEE","IEEE Journals"
"Interlocking Safety Cases for Unmanned Autonomous Systems in Shared Airspaces","M. Vierhauser; S. Bayley; J. Wyngaard; W. Xiong; J. Cheng; J. Huseman; R. Lutz; J. Cleland-Huang","Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Engineering, Polythechnique Montréal, Montreal, QC, Canada; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA; Department Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science and Engineering, University of Notre Dame, Notre Dame, IN, USA","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","899","918","The growing adoption of unmanned aerial vehicles (UAVs) for tasks such as eCommerce, aerial surveillance, and environmental monitoring introduces the need for new safety mechanisms in an increasingly cluttered airspace. In our work we thus emphasize safety issues that emerge at the intersection of infrastructures responsible for controlling the airspace, and the diverse UAVs operating in their space. We build on safety assurance cases (SAC) – a state-of-the-art solution for reasoning about safety – and propose a novel approach based on interlocking SACs. The infrastructure safety case (ISAC) specifies assumptions upon UAV behavior, while each UAV demonstrates compliance to the ISAC by presenting its own (pluggable) safety case (pSAC) which connects to the ISAC through a set of interlock points. To collect information on each UAV we enforce a “trust but monitor” policy, supported by runtime monitoring and an underlying reputation model. We evaluate our approach in three ways: first by developing ISACs for two UAV infrastructures, second by running simulations to evaluate end-to-end effectiveness, and finally via an outdoor field-study with physical UAVs. The results show that interlocking SACs can be effective for identifying, specifying, and monitoring safety-related constraints upon UAVs flying in a controlled airspace.","1939-3520","","10.1109/TSE.2019.2907595","National Science Foundation; Austrian Science Fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8674543","UAV;unmanned autonomous systems;safety assurance cases;monitoring","Safety;Unmanned aerial vehicles;Monitoring;Runtime;Software;Atmospheric modeling;NASA","","","","1","","121","IEEE","26 Mar 2019","","","IEEE","IEEE Journals"
"CBGA-ES+: A Cluster-Based Genetic Algorithm with Non-Dominated Elitist Selection for Supporting Multi-Objective Test Optimization","D. Pradhan; S. Wang; S. Ali; T. Yue; M. Liaaen","Simula Research Laboratory, Lysaker, Norway; Testify As, Lysaker, Norway; Simula Research Laboratory, Lysaker, Norway; Simula Research Laboratory, Lysaker, Norway; Cisco Systems, Oslo, Norway","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","86","107","Many real-world test optimization problems (e.g., test case prioritization) are multi-objective intrinsically and can be tackled using various multi-objective search algorithms (e.g., Non-dominated Sorting Genetic Algorithm (NSGA-II)). However, existing multi-objective search algorithms have certain randomness when selecting parent solutions for producing offspring solutions. In a worse case, suboptimal parent solutions may result in offspring solutions with bad quality, and thus affect the overall quality of the solutions in the next generation. To address such a challenge, we propose CBGA-ES+, a novel cluster-based genetic algorithm with non-dominated elitist selection to reduce the randomness when selecting the parent solutions to support multi-objective test optimization. We empirically compared CBGA-ES+ with random search and greedy (as baselines), four commonly used multi-objective search algorithms (i.e., Multi-objective Cellular genetic algorithm (MOCell), NSGA-II, Pareto Archived Evolution Strategy (PAES), and Strength Pareto Evolutionary Algorithm (SPEA2)), and the predecessor of CBGA-ES+ (named CBGA-ES) using five multi-objective test optimization problems with eight subjects (two industrial, one real world, and five open source). The results showed that CBGA-ES+ managed to significantly outperform the selected search algorithms for a majority of the experiments. Moreover, for the solutions in the same search space, CBGA-ES+ managed to perform better than CBGA-ES, MOCell, NSGA-II, PAES, and SPEA2 for 2.2, 13.6, 14.5, 17.4, and 9.9 percent, respectively. Regarding the running time of the algorithm, CBGA-ES+ was faster than CBGA-ES for all the experiments.","1939-3520","","10.1109/TSE.2018.2882176","Norges Forskningsråd; RCN funded Zen-Configurator; RCN funded MBT4CPS; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8540431","Elitist selection;multi-objective genetic algorithm;multi-objective test optimization;search","Optimization;Genetic algorithms;Sociology;Statistics;Search problems;Clustering algorithms;Software algorithms","evolutionary computation;genetic algorithms;Pareto optimisation;search problems","nondominated elitist selection;real-world test optimization problems;test case prioritization;nondominated sorting genetic algorithm;NSGA-II;multiobjective search algorithms;offspring solutions;suboptimal parent solutions;cluster-based genetic algorithm;multiobjective cellular genetic algorithm;strength Pareto evolutionary algorithm;search algorithms;CBGA-ES+;multiobjective test optimization;Pareto archived evolution strategy","","1","","98","IEEE","18 Nov 2018","","","IEEE","IEEE Journals"
"Instance Migration Validity for Dynamic Evolution of Data-Aware Processes","W. Song; X. Ma; H. Jacobsen","School of Computer Science and Engineering, Nanjing University of Science and Technology, Nanjing, China; State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China; Middleware Systems Research Group, Technische Universität München, Garching, Germany","IEEE Transactions on Software Engineering","26 Aug 2019","2019","45","8","782","801","Likely more than many other software artifacts, business processes constantly evolve to adapt to ever changing application requirements. To enable dynamic process evolution, where changes are applied to in-flight processes, running process instances have to be migrated. On the one hand, as many instances as possible should be migrated to the changed process. On the other hand, the validity to migrate an instance should be guaranteed to avoid introducing dynamic change bugs after migration. As our theoretical results show, when the state of variables is taken into account, migration validity of data-aware process instances is undecidable. Based on the trace of an instance, existing approaches leverage trace replaying to check migration validity. However, they err on the side of caution, not identifying many instances as potentially safe to migrate. We present a more relaxed migration validity checking approach based on the dependence graph of a trace. We evaluate effectiveness and efficiency of our approach experimentally showing that it allows for more instances to safely migrate than for existing approaches and that it scales in the number of instances checked.","1939-3520","","10.1109/TSE.2018.2802925","National Key R&D Program of China; National Natural Science Foundation of China; Natural Science Foundation of Jiangsu Province; Fundamental Research Funds for the Central Universities; Deutsche Forschungsgemeinschaft; American Friends of the Alexander von Humboldt Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283529","Data-aware process;dynamic evolution;instance migration;migration validity;trace slicing","Process control;Business data processing;Debugging;Software architecture","business data processing;graph theory;program debugging;program diagnostics;software architecture","instance migration validity;dynamic evolution;business processes;dynamic process evolution;in-flight processes;data-aware process instances;trace replaying;dependence graph","","2","","62","","6 Feb 2018","","","IEEE","IEEE Journals"
"Evaluating Model-Driven Development Claims with Respect to Quality: A Family of Experiments","J. I. Panach; Ó. Dieste; B. Marín; S. España; S. Vegas; Ó. Pastor; N. Juristo","Departament d'Informàtica, Escola Tècnica Superior d'Enginyeria, Universitat de València, Avinguda de la Universitat, València, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain; Escuela de Informática y Telecomunicaciones, Facultad de Ingeniería, Universidad Diego Portales, Santiago, Chile; Utrecht University, Utrecht, The Netherlands; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain; Centro de Investigación en Métodos de Producción de Software, Universitat Politècnica de València, Valencia, Spain; Escuela Técnica Superior de Ingenieros Informáticos, Universidad Politécnica de Madrid, Boadilla del Monte, Spain","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","130","145","Context: There is a lack of empirical evidence on the differences between model-driven development (MDD), where code is automatically derived from conceptual models, and traditional software development method, where code is manually written. In our previous work, we compared both methods in a baseline experiment concluding that quality of the software developed following MDD was significantly better only for more complex problems (with more function points). Quality was measured through test cases run on a functional system. Objective: This paper reports six replications of the baseline to study the impact of problem complexity on software quality in the context of MDD. Method: We conducted replications of two types: strict replications and object replications. Strict replications were similar to the baseline, whereas we used more complex experimental objects (problems) in the object replications. Results: MDD yields better quality independently of problem complexity with a moderate effect size. This effect is bigger for problems that are more complex. Conclusions: Thanks to the bigger size of the sample after aggregating replications, we discovered an effect that the baseline had not revealed due to the small sample size. The baseline results hold, which suggests that MDD yields better quality for more complex problems.","1939-3520","","10.1109/TSE.2018.2884706","Ministerio de Ciencia e Innovación; European Regional Development Fund; Generalitat Valenciana; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565892","Automatic programming;methodologies;validation","Unified modeling language;Productivity;Complexity theory;Inspection;Model-driven development;Software quality","program testing;software quality","object replications;strict replications;complex experimental objects;MDD;problem complexity;model-driven development;software development;function points;functional system;software quality;test cases","","1","","50","IEEE","6 Dec 2018","","","IEEE","IEEE Journals"
"Eliminating Path Redundancy via Postconditioned Symbolic Execution","Q. Yi; Z. Yang; S. Guo; C. Wang; J. Liu; C. Zhao","National Engineering Research Center for Fundamental Software, Institute of Software Chinese Academy of Sciences, University of Chinese Academy of Sciences, Beijing, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI; Department of Electrical and Computer Engineering, Virginia Tech, Blacksburg, VA; Department of Computer Science, University of Southern California, Los Angeles, CA; Key Laboratory of Network Assessment Technology and Beijing Key Laboratory of Network Security Technology, Institute of Information Engineering and University of Chinese Academy of Sciences, Chinese Academy of Sciences, Beijing, China; National Engineering Research Center for Fundamental Software and State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Software Engineering","8 Jan 2018","2018","44","1","25","43","Symbolic execution is emerging as a powerful technique for generating test inputs systematically to achieve exhaustive path coverage of a bounded depth. However, its practical use is often limited by path explosion because the number of paths of a program can be exponential in the number of branch conditions encountered during the execution. To mitigate the path explosion problem, we propose a new redundancy removal method called postconditioned symbolic execution. At each branching location, in addition to determine whether a particular branch is feasible as in traditional symbolic execution, our approach checks whether the branch is subsumed by previous explorations. This is enabled by summarizing previously explored paths by weakest precondition computations. Postconditioned symbolic execution can identify path suffixes shared by multiple runs and eliminate them during test generation when they are redundant. Pruning away such redundant paths can lead to a potentially exponential reduction in the number of explored paths. Since the new approach is computationally expensive, we also propose several heuristics to reduce its cost. We have implemented our method in the symbolic execution engine KLEE [1] and conducted experiments on a large set of programs from the GNU Coreutils suite. Our results confirm that redundancy due to common path suffix is both abundant and widespread in real-world applications.","1939-3520","","10.1109/TSE.2017.2659751","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7835264","Symbolic execution;testing and debugging;testing tools","Concrete;Explosions;Input variables;Redundancy;Software;Syntactics;Testing","program diagnostics;program testing","common path suffix;postconditioned symbolic execution;exhaustive path coverage;branch conditions;path explosion problem;redundancy removal method;branching location;traditional symbolic execution;path suffixes;path redundancy elimination","","4","","67","","26 Jan 2017","","","IEEE","IEEE Journals"
"Global-Aware Recommendations for Repairing Violations in Exception Handling","E. A. Barbosa; A. Garcia","Federal University of Rio Grande do Norte, Caicó - RN, Brazil; Informatics Department, Pontifical Catholic University of Rio de Janeiro, Rio de Janeiro - RJ, Brazil","IEEE Transactions on Software Engineering","16 Sep 2018","2018","44","9","855","873","Empirical evidence suggests exception handling is not reliably implemented. Most faults in exception handling are related to global exceptions violating the intended exception handling design. However, repairing these violations is a cumbersome and error-prone task. It requires knowing the intended design and understanding how the source code violates it. It also requires changing the source code to make it compliant with the intended design. But changing the exception handling code is a difficult task, since changes in exception handling requires changing different parts of a program. Currently, there is still no solution to assist the repair of this type of violations. To bridge this gap, we present RAVEN, a heuristic strategy aware of the global context of exceptions that produces recommendations of how violations in exception handling may be repaired. This strategy takes advantage of explicit specifications of the intended design, although their availability is not mandatory. Our results revealed RAVEN provides recommendations able to repair violations in 69 percent of the cases when policy specifications are not available and in 97 percent of the cases when specifications are available. Thus, development teams may benefit from RAVEN, even when exception handling design decisions are not documented in their projects.","1939-3520","","10.1109/TSE.2017.2716925","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7953550","Exception handling;recommender heuristic;software repair","Source coding;Robustness;Runtime;Software development management;Software reliability","exception handling;recommender systems;software fault tolerance;software quality","intended exception handling design;source code;repair violations;exception handling design decisions;global-aware recommendations;RAVEN strategy","","2","","51","","19 Jun 2017","","","IEEE","IEEE Journals"
"A Screening Test for Disclosed Vulnerabilities in FOSS Components","S. Dashevskyi; A. D. Brucker; F. Massacci","University of Trento, TN, Italy; University of Sheffield, Sheffield, United Kingdom; University of Trento, Trento, TN, Italy","IEEE Transactions on Software Engineering","16 Oct 2019","2019","45","10","945","966","Free and Open Source Software (FOSS) components are ubiquitous in both proprietary and open source applications. Each time a vulnerability is disclosed in a FOSS component, a software vendor using this component in an application must decide whether to update the FOSS component, patch the application itself, or just do nothing as the vulnerability is not applicable to the older version of the FOSS component used. This is particularly challenging for enterprise software vendors that consume thousands of FOSS components and offer more than a decade of support and security fixes for their applications. Moreover, customers expect vendors to react quickly on disclosed vulnerabilities-in case of widely discussed vulnerabilities such as Heartbleed, within hours. To address this challenge, we propose a screening test: a novel, automatic method based on thin slicing, for estimating quickly whether a given vulnerability is present in a consumed FOSS component by looking across its entire repository. We show that our screening test scales to large open source projects (e.g., Apache Tomcat, Spring Framework, Jenkins) that are routinely used by large software vendors, scanning thousands of commits and hundred thousands lines of code in a matter of minutes. Further, we provide insights on the empirical probability that, on the above mentioned projects, a potentially vulnerable component might not actually be vulnerable after all.","1939-3520","","10.1109/TSE.2018.2816033","European Commission; CISCO Country Digitalization; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8316943","Security maintenance;security vulnerabilities;patch management;free and open source software","Security;Maintenance engineering;Tools;Jacobian matrices;Patents;Open source software","DP industry;program slicing;program testing;public domain software;security of data","proprietary source applications;open source applications;screening test;disclosed vulnerabilities;FOSS component;free and open source software component;thin slicing;enterprise software vendors","","2","","51","","15 Mar 2018","","","IEEE","IEEE Journals"
"How Well Do Change Sequences Predict Defects? Sequence Learning from Software Changes","M. Wen; R. Wu; S. -C. Cheung","Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Kowloon, Hong Kong, China","IEEE Transactions on Software Engineering","11 Nov 2020","2020","46","11","1155","1175","Software defect prediction, which aims to identify defective modules, can assist developers in finding bugs and prioritizing limited quality assurance resources. Various features to build defect prediction models have been proposed and evaluated. Among them, process metrics are one important category. Yet, existing process metrics are mainly encoded manually from change histories and ignore the sequential information arising from the changes during software evolution. Are the change sequences derived from such information useful to characterize buggy program modules? How can we leverage such sequences to build good defect prediction models? Unlike traditional process metrics used for existing defect prediction models, change sequences are mostly vectors of variable length. This makes it difficult to apply such sequences directly in prediction models that are driven by conventional classifiers. To resolve this challenge, we utilize Recurrent Neural Network (RNN), which is a deep learning technique, to encode features from sequence data automatically. In this paper, we propose a novel approach called Fences, which extracts six types of change sequences covering different aspects of software changes via fine-grained change analysis. It approaches defects prediction by mapping it to a sequence labeling problem solvable by RNN. Our evaluations on 10 open source projects show that Fences can predict defects with high performance. In particular, our approach achieves an average F-measure of 0.657, which improves the prediction models built on traditional metrics significantly. The improvements vary from 31.6 to 46.8 percent on average. In terms of AUC, Fences achieves an average value of 0.892, and the improvements over baselines vary from 4.2 to 16.1 percent. Fences also outperforms the state-of-the-art technique which learns semantic features automatically from static code via deep learning.","1939-3520","","10.1109/TSE.2018.2876256","Hong Kong RGC/GRF; 2018 MSRA collaborative research fund; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493303","Defect prediction;process metrics;sequence learning","Measurement;Software;Predictive models;Semantics;History;Machine learning;Feature extraction","learning (artificial intelligence);program debugging;program diagnostics;public domain software;recurrent neural nets;software maintenance;software metrics;software quality","software changes;software defect prediction;software evolution;defect prediction models;fine-grained change analysis;sequence labeling problem;sequence learning;Fences approach;RNN;recurrent neural network;efficiency 16.1 percent;efficiency 46.8 percent","","","","74","IEEE","16 Oct 2018","","","IEEE","IEEE Journals"
"Deep Learning Based Code Smell Detection","H. Liu; J. Jin; Z. Xu; Y. Bu; Y. Zou; L. Zhang","Computer Science and Technology, Software Lab, Beijing, Beijing China 100081 (e-mail: liuhui2005@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: jinjiahao1993@gmail.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: 848602422@qq.com); School of Computer Science and Technology, Beijing Institute of Technology, 47833 Beijing, Beijing China (e-mail: yifan_bu@qq.com); Key Laboratory of High Confidence Software Technologies, Ministry of Education, Peking University, 12465 Beijing, Beijing China (e-mail: zouyz@pku.edu.cn); Electronics Engineering and Computer Science, Peking University, Beijing, Beijing China 100871 (e-mail: zhanglu@sei.pku.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Code smells are structures in the source code that suggest the possibility of refactorings. Consequently, developers may identify refactoring opportunities by detecting code smells. However, manual identification of code smells is challenging and tedious. To this end, a number of approaches have been proposed to identify code smells automatically or semi-automatically. Most of such approaches rely on manually designed heuristics to map manually selected source code metrics into predictions. However, it is challenging to manually select the best features. It is also difficult to manually construct the optimal heuristics. To this end, in this paper we propose a deep learning based novel approach to detecting code smells. The key insight is that deep neural networks and advanced deep learning techniques could automatically select features of source code for code smell detection, and could automatically build the complex mapping between such features and predictions. A big challenge for deep learning based smell detection is that deep learning often requires a large number of labeled training data (to tune a large number of parameters within the employed deep neural network) whereas existing datasets for code smell detection are rather small. To this end, we propose an automatic approach to generating labeled training data for the neural network based classifier, which does not require any human intervention. As an initial try, we apply the proposed approach to four common and well-known code smells, i.e., feature envy, long method, large class, and misplaced class. Evaluation results on open-source applications suggest that the proposed approach significantly improves the state-of-the-art.","1939-3520","","10.1109/TSE.2019.2936376","National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8807230","Software Refactoring;Code Smells;Identification;Deep Learning;Quality","Software;Deep learning;Feature extraction;Training data;Neural networks;Measurement","","","","4","","","","20 Aug 2019","","","IEEE","IEEE Early Access Articles"
"An Empirical Study of Boosting Spectrum-based Fault Localization via PageRank","M. Zhang; Y. Li; X. Li; L. Chen; Y. Zhang; L. Zhang; S. Khurshid","Electrical and Computer Engineering, University of Texas at Austin, 12330 Austin, Texas United States (e-mail: mengshi.zhang@utexas.edu); Computer Science and Engineering, South University of Science and Technology, 255310 Shenzhen, Guangdong China (e-mail: liyx@mail.sustc.edu.cn); Computer Science, University of Texas at Dallas, Dallas, Texas United States (e-mail: xxl124730@utdallas.edu); Computer Science, University of Texas at Dallas, Dallas, Texas United States (e-mail: lxc170330@utdallas.edu); Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong China (e-mail: zhangyq@sustc.edu.cn); Computer Science, University of Texas at Dallas, Richardson, Texas United States (e-mail: lingming.zhang@utdallas.edu); Electrical and Computer Engineering, University of Texas at Austin, Austin, Texas United States (e-mail: khurshid@ece.utexas.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Manual debugging is notoriously tedious and time-consuming. Therefore, various automated fault localization techniques have been proposed to help with manual debugging. Among the existing fault localization techniques, spectrum-based fault localization (SBFL) is one of the most widely studied techniques due to being lightweight. The focus of the existing SBFL techniques is to consider how to differentiate program entities (i.e., one dimension in program spectra); indeed, this focus is aligned with the ultimate goal of finding the faulty lines of code. Our key insight is to enhance the existing SBFL techniques by additionally considering how to differentiate tests (i.e., the other dimension in program spectra), which, to the best of our knowledge, has not been studied in prior work. We present our basic approach, PRFL, a lightweight technique that boosts SBFL by differentiating tests using PageRank algorithm. Specifically, given the original program spectrum information, PRFL uses PageRank to recompute the spectrum by considering the contributions of different tests. Next, traditional SBFL techniques are applied to the recomputed spectrum to achieve more effective fault localization. On top of PRFL, we explore PRFL+ and PRFLMA, two variants which extend PRFL by optimizing its components and integrating Method-level Aggregation technique, respectively. Though being simple and lightweight, PRFL has been demonstrated to outperform state-of-the-art SBFL techniques significantly (e.g., ranking 39.2% / 82.3% more real/artificial faults within Top-1 compared with the most effective traditional SBFL technique) with low overhead on 395 real faults from 6 Defects4J projects and 96925 artificial faults from 240 GitHub projects. To further validate PRFL's effectiveness, we compare PRFL with multiple recent proposed fault localization techniques (e.g., Multric, Metallaxis and MBFL-hybrid-avg), and the experimental results show that PRFL outperforms them as well. Furthermore, we study the performance of PRFLMA, and the experimental results present it can locate 137 real faults (73.4% / 24.5% more compared with the most effective SBFL/PRFL technique) and 35058 artificial faults (159.6% / 28.1% more than SBFL/PRFL technique) at Top-1. At last, we study the generalizability of PRFL on another benchmark Bugs.jar, and the result shows PRFL can help locate around 30% more faults at Top 1.","1939-3520","","10.1109/TSE.2019.2911283","UT Dallas start-up fund; Google Faculty Research Award; Shenzhen Peacock Plan; Science and Technology Innovation Committee Foundation of Shenzhen; National Science Foundation; Ministry of Science and Technology of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8698881","Software testing;Automated debugging;Spectrum-based fault localization;SBFL;PageRank analysis","Debugging;Benchmark testing;Spectral analysis;Java;Boosting;Manuals","","","","5","","","","25 Apr 2019","","","IEEE","IEEE Early Access Articles"
"Automatic Software Repair: A Survey","L. Gazzola; D. Micucci; L. Mariani","Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy; Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy; Department of Informatics, Systems and Communication (DISCo), University of Milano Bicocca, Milano, Italy","IEEE Transactions on Software Engineering","8 Jan 2019","2019","45","1","34","67","Despite their growing complexity and increasing size, modern software applications must satisfy strict release requirements that impose short bug fixing and maintenance cycles, putting significant pressure on developers who are responsible for timely producing high-quality software. To reduce developers workload, repairing and healing techniques have been extensively investigated as solutions for efficiently repairing and maintaining software in the last few years. In particular, repairing solutions have been able to automatically produce useful fixes for several classes of bugs that might be present in software programs. A range of algorithms, techniques, and heuristics have been integrated, experimented, and studied, producing a heterogeneous and articulated research framework where automatic repair techniques are proliferating. This paper organizes the knowledge in the area by surveying a body of 108 papers about automatic software repair techniques, illustrating the algorithms and the approaches, comparing them on representative examples, and discussing the open challenges and the empirical evidence reported so far.","1939-3520","","10.1109/TSE.2017.2755013","EU H2020; ERC Consolidator; MIUR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8089448","Automatic program repair;generate and validate;search-based;semantics-driven repair;correct by construction;program synthesis;self-repairing","Software;Maintenance engineering;Debugging;Computer bugs;Software algorithms;Fault diagnosis;Conferences","program debugging;software maintenance;software quality","modern software applications;maintenance cycles;software programs;heterogeneous research framework;articulated research framework;automatic software repair techniques;high-quality software","","27","","176","","30 Oct 2017","","","IEEE","IEEE Journals"
"The Scent of a Smell: An Extensive Comparison Between Textual and Structural Smells","F. Palomba; A. Panichella; A. Zaidman; R. Oliveto; A. De Lucia","TU Delft, Delft, The Netherlands; SnT Centre—University of Luxembourg, Esch-sur-Alzette, Luxembourg; TU Delft, Delft, The Netherlands; University of Molise, Campobasso, Italy; University of Salerno, Fisciano, Italy","IEEE Transactions on Software Engineering","15 Oct 2018","2018","44","10","977","1000","Code smells are symptoms of poor design or implementation choices that have a negative effect on several aspects of software maintenance and evolution, such as program comprehension or change- and fault-proneness. This is why researchers have spent a lot of effort on devising methods that help developers to automatically detect them in source code. Almost all the techniques presented in literature are based on the analysis of structural properties extracted from source code, although alternative sources of information (e.g., textual analysis) for code smell detection have also been recently investigated. Nevertheless, some studies have indicated that code smells detected by existing tools based on the analysis of structural properties are generally ignored (and thus not refactored) by the developers. In this paper, we aim at understanding whether code smells detected using textual analysis are perceived and refactored by developers in the same or different way than code smells detected through structural analysis. To this aim, we set up two different experiments. We have first carried out a software repository mining study to analyze how developers act on textually or structurally detected code smells. Subsequently, we have conducted a user study with industrial developers and quality experts in order to qualitatively analyze how they perceive code smells identified using the two different sources of information. Results indicate that textually detected code smells are easier to identify and for this reason they are considered easier to refactor with respect to code smells detected using structural properties. On the other hand, the latter are often perceived as more severe, but more difficult to exactly identify and remove.","1939-3520","","10.1109/TSE.2017.2752171","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8038053","Code smells;empirical study;mining software repositories","Tools;Data mining;Software systems;Detectors;Maintenance engineering;Large scale integration","data mining;software maintenance;software quality;source code (software)","source code;textually detected code smells;structurally detected code smells;software maintenance;software repository mining;qualitatively analyze","","9","","111","","14 Sep 2017","","","IEEE","IEEE Journals"
"ConfigMiner: Identifying the Appropriate Configuration Options for Config-related User Questions by Mining Online Forums","M. Sayagh; A. E. Hassan","Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: sayaghmohammed@gmail.com); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","While the behavior of a software system can be easily changed by modifying the values of a couple of configuration options, finding one out of hundreds or thousands of available options is, unfortunately, a challenging task. Therefore, users often spend a considerable amount of time asking and searching around for the appropriate configuration options in online forums such as StackOverflow. In this paper, we propose ConfigMiner, an approach to automatically identify the appropriate option(s) to config-related user questions by mining already-answered config-related questions in online forums. Our evaluation on 2,061 config-related user questions for seven software systems shows that ConfigMiner can identify the appropriate option(s) for a median of 83% (up to 91%) of user questions within the top-20 recommended options, improving over state-of-the-art approaches by a median of 130%. Besides, ConfigMiner reports the relevant options at a median rank of 4, compared to a median of 16-20.5 as reported by the state-of-the-art approaches.","1939-3520","","10.1109/TSE.2020.2973997","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8999583","Configuration;user questions;online forums;stackOverflow","Software systems;Computer bugs;Debugging;Statistical analysis;Task analysis;Prediction algorithms;Data mining","","","","1","","","","14 Feb 2020","","","IEEE","IEEE Early Access Articles"
"A PVS-Simulink Integrated Environment for Model-Based Analysis of Cyber-Physical Systems","C. Bernardeschi; A. Domenici; P. Masci","Department of Information Engineering, University of Pisa, PI, Italy; Department of Information Engineering, University of Pisa, PI, Italy; HASLab/INESC TEC and Universidade do Minho, Braga, Portugal","IEEE Transactions on Software Engineering","12 Jun 2018","2018","44","6","512","533","This paper presents a methodology, with supporting tool, for formal modeling and analysis of software components in cyber-physical systems. Using our approach, developers can integrate a simulation of logic-based specifications of software components and Simulink models of continuous processes. The integrated simulation is useful to validate the characteristics of discrete system components early in the development process. The same logic-based specifications can also be formally verified using the Prototype Verification System (PVS), to gain additional confidence that the software design complies with specific safety requirements. Modeling patterns are defined for generating the logic-based specifications from the more familiar automata-based formalism. The ultimate aim of this work is to facilitate the introduction of formal verification technologies in the software development process of cyber-physical systems, which typically requires the integrated use of different formalisms and tools. A case study from the medical domain is used to illustrate the approach. A PVS model of a pacemaker is interfaced with a Simulink model of the human heart. The overall cyber-physical system is co-simulated to validate design requirements through exploration of relevant test scenarios. Formal verification with the PVS theorem prover is demonstrated for the pacemaker model for specific safety aspects of the pacemaker design.","1939-3520","","10.1109/TSE.2017.2694423","North Portugal Regional Operational Programme; PORTUGAL 2020 Partnership Agreement, and through the European Regional Development Fund (ERDF); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7900400","Real-time and embedded systems;modeling techniques;specification;formal methods","Software packages;Automata;Analytical models;Cyber-physical systems;Mathematical model;Data models","cyber-physical systems;formal specification;program testing;program verification;software development management;software tools;theorem proving","formal modeling;software components;cyber-physical system;Simulink model;discrete system components;logic-based specifications;Prototype Verification System;formal verification technologies;software development process;PVS model;pacemaker model;PVS-Simulink integrated environment;software design;formal verification","","5","","76","","14 Apr 2017","","","IEEE","IEEE Journals"
"Easy-to-Deploy API Extraction by Multi-Level Feature Embedding and Transfer Learning","S. Ma; Z. Xing; C. Chen; C. Chen; L. Qu; G. Li","Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: u6095071@anu.edu.au); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: zhenchang.xing@anu.edu.au); Faculty of Information Technology, Monash University, 2541 Clayton, Victoria Australia (e-mail: chunyang.chen@monash.edu); Research School of Computer Science, Australian National University, Canberra, Australian Capital Territory Australia (e-mail: u5969643@anu.edu.au); Faculty of Information Technology, Monash University, 2541 Caulfield, Victoria Australia (e-mail: lizhen.qu@data61.csiro.au); School of Software, Shanghai Jiao Tong University, Shanghai, ShangHai China 200240 (e-mail: li.g@sjtu.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Application Programming Interfaces (APIs) have been widely discussed on social-technical platforms (e.g., Stack Overflow). Extracting API mentions from such informal software texts is the prerequisite for API-centric search and summarization of programming knowledge. Machine learning based API extraction has demonstrated superior performance than rule-based methods in informal software texts that lack consistent writing forms and annotations. However, machine learning based methods have a significant overhead in preparing training data and effective features. In this paper, we propose a multi-layer neural network based architecture for API extraction. Our architecture automatically learns character-, word- and sentence-level features from the input texts, thus removing the need for manual feature engineering and the dependence on advanced features (e.g., API gazzetter) beyond the input texts. We also propose to adopt transfer learning to adapt a source-library-trained model to a target-library, thus reducing the overhead of manual training-data labeling when the software text of multiple programming languages and libraries need to be processed. We conduct extensive experiments with six libraries of four programming languages which support diverse functionalities and have different API-naming and API-mention characteristics. Our experiments investigate the performance of our neural architecture for API extraction in informal software texts, the importance of different features, the effectiveness of transfer learning. Our results confirm not only the superior performance of our neural architecture than existing machine learning based methods for API extraction in informal software texts, but also the easy-to-deploy characteristic of our neural architecture.","1939-3520","","10.1109/TSE.2019.2946830","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8865646","API extraction;CNN;Word embedding;LSTM;Transfer learning","Libraries;Feature extraction;Machine learning;Software;Computer architecture;Training data;Manuals","","","","3","","","","14 Oct 2019","","","IEEE","IEEE Early Access Articles"
"ARJA: Automated Repair of Java Programs via Multi-Objective Genetic Programming","Y. Yuan; W. Banzhaf","Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA; Department of Computer Science and Engineering, Michigan State University, East Lansing, MI, USA","IEEE Transactions on Software Engineering","14 Oct 2020","2020","46","10","1040","1067","Automated program repair is the problem of automatically fixing bugs in programs in order to significantly reduce the debugging costs and improve the software quality. To address this problem, test-suite based repair techniques regard a given test suite as an oracle and modify the input buggy program to make the entire test suite pass. GenProg is well recognized as a prominent repair approach of this kind, which uses genetic programming (GP) to rearrange the statements already extant in the buggy program. However, recent empirical studies show that the performance of GenProg is not fully satisfactory, particularly for Java. In this paper, we propose ARJA, a new GP based repair approach for automated repair of Java programs. To be specific, we present a novel lower-granularity patch representation that properly decouples the search subspaces of likely-buggy locations, operation types and potential fix ingredients, enabling GP to explore the search space more effectively. Based on this new representation, we formulate automated program repair as a multi-objective search problem and use NSGA-II to look for simpler repairs. To reduce the computational effort and search space, we introduce a test filtering procedure that can speed up the fitness evaluation of GP and three types of rules that can be applied to avoid unnecessary manipulations of the code. Moreover, we also propose a type matching strategy that can create new potential fix ingredients by exploiting the syntactic patterns of existing statements. We conduct a large-scale empirical evaluation of ARJA along with its variants on both seeded bugs and real-world bugs in comparison with several state-of-the-art repair approaches. Our results verify the effectiveness and efficiency of the search mechanisms employed in ARJA and also show its superiority over the other approaches. In particular, compared to jGenProg (an implementation of GenProg for Java), an ARJA version fully following the redundancy assumption can generate a test-suite adequate patch for more than twice the number of bugs (from 27 to 59), and a correct patch for nearly four times of the number (from 5 to 18), on 224 real-world bugs considered in Defects4J. Furthermore, ARJA is able to correctly fix several real multi-location bugs that are hard to be repaired by most of the existing repair approaches.","1939-3520","","10.1109/TSE.2018.2874648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8485732","Program repair;patch generation;genetic programming;multi-objective optimization;genetic improvement","Maintenance engineering;Computer bugs;Java;Genetic programming;Search problems;Sociology;Statistics","genetic algorithms;Java;program debugging;program testing;search problems;software maintenance;software quality;sorting","ARJA;multiobjective genetic programming;automated program repair;test-suite based repair techniques;buggy program;GenProg;GP based repair approach;search space;multiobjective search problem;real-world bugs;multilocation bugs;test filtering;automated repair of Java programs;program bugs;debugging costs;software quality;NSGA-II","","8","","87","IEEE","7 Oct 2018","","","IEEE","IEEE Journals"
"Debugging Static Analysis","L. N. Q. Do; S. Krüger; P. Hill; K. Ali; E. Bodden","Paderborn University, Paderborn, Germany; Paderborn University, Paderborn, Germany; Paderborn University, Paderborn, Germany; University of Alberta, Edmonton, AB, Canada; Paderborn University & Fraunhofer IEM, Paderborn, Germany","IEEE Transactions on Software Engineering","15 Jul 2020","2020","46","7","697","709","Static analysis is increasingly used by companies and individual code developers to detect and fix bugs and security vulnerabilities. As programs grow more complex, the analyses have to support new code concepts, frameworks and libraries. However, static-analysis code itself is also prone to bugs. While more complex analyses are written and used in production systems every day, the cost of debugging and fixing them also increases tremendously. To understand the difficulties of debugging static analysis, we surveyed 115 static-analysis writers. From their responses, we determined the core requirements to build a debugger for static analyses, which revolve around two main issues: abstracting from both the analysis code and the code it analyses at the same time, and tracking the analysis internal state throughout both code bases. Most tools used by our survey participants lack the capabilities to address both issues. Focusing on those requirements, we introduce Visuflow, a debugging environment for static data-flow analysis. Visuflow features graph visualizations and custom breakpoints that enable users to view the state of an analysis at any time. In a user study on 20 static-analysis writers, Visuflow helped identify 25 and fix 50 percent more errors in the analysis code compared to the standard Eclipse debugging environment.","1939-3520","","10.1109/TSE.2018.2868349","Heinz Nixdorf Foundation; DFG; Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8453858","Testing and debugging;program analysis;development tools;integrated environments;graphical environments;usability testing","Debugging;Static analysis;Tools;Computer bugs;Standards;Writing;Encoding","data flow analysis;data visualisation;program debugging;program diagnostics","code bases;static data-flow analysis;code developers;libraries;static-analysis code;security vulnerabilities;graph visualizations;Visuflow;Eclipse debugging environment","","","","36","IEEE","2 Sep 2018","","","IEEE","IEEE Journals"
"Symbolic Refinement of Extended State Machines with Applications to the Automatic Derivation of Sub-Components and Controllers","K. El-Fakih; G. V. Bochmann","College of Engineering, American University of Sharjah, Sharjah, UAE; School of Electrical Engineering and Computer Science, University of Ottawa, Ottawa, Canada","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","1","16","Nowadays, extended state machines are prominent requirements specification techniques due to their capabilities of modeling complex systems in a compact way. These machines extend the standard state machines with variables and have transitions guarded by enabling predicates and may include variable update statements. Given a system modeled as an extended state machine, with possibly infinite state space and some non-controllable (parameterized) interactions, a pruning procedure is proposed to symbolically derive a maximal sub-machine of the original system that satisfies certain conditions; namely, some safeness and absence of undesirable deadlocks which could be produced during pruning. In addition, the user may specify, as predicates associated with states, some general goal assertions that should be preserved in the obtained sub-machine. Further, one may also specify some specific requirements such as the elimination of certain undesirable deadlocks at states, or fail states that should never be reached. Application examples are given considering deadlock avoidance and loops including infinite loops over non-controllable interactions showing that the procedure may not terminate. In addition, the procedure is applied for finding a controller of a system to be controlled. The approach generalizes existing work in respect to the considered extended machine model and the possibility of user defined control objectives written as assertions at states.","1939-3520","","10.1109/TSE.2018.2878728","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8515084","Requirements/specifications;component design and refinement;discrete event control systems;extended state machines;submodule construction and automatic derivation of a component behavior","System recovery;Control systems;Calculators;Facsimile;Electronic mail;Unified modeling language;Computer architecture","control engineering computing;finite state machines;formal specification;formal verification;large-scale systems","prominent requirements specification techniques;standard state machines;extended state machine;possibly infinite state space;noncontrollable interactions;maximal sub-machine;considered extended machine model","","","","31","IEEE","30 Oct 2018","","","IEEE","IEEE Journals"
"Accurate and Scalable Cross-Architecture Cross-OS Binary Code Search with Emulation","Y. Xue; Z. Xu; M. Chandramohan; Y. Liu","University of Science of Technology of China, Hefei, Anhui, China; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore; Nanyang Technological University, Singapore","IEEE Transactions on Software Engineering","12 Nov 2019","2019","45","11","1125","1149","Different from source code clone detection, clone detection (similar code search) in binary executables faces big challenges due to the gigantic differences in the syntax and the structure of binary code that result from different configurations of compilers, architectures and OSs. Existing studies have proposed different categories of features for detecting binary code clones, including CFG structures, n-gram in CFG, input/output values, etc. In our previous study and the tool BinGo, to mitigate the huge gaps in CFG structures due to different compilation scenarios, we propose a selective inlining technique to capture the complete function semantics by inlining relevant library and user-defined functions. However, only features of input/output values are considered in BinGo. In this study, we propose to incorporate features from different categories (e.g., structural features and high-level semantic features) for accuracy improvement and emulation for efficiency improvement. We empirically compare our tool, BinGo-E, with the pervious tool BinGo and the available state-of-the-art tools of binary code search in terms of search accuracy and performance. Results show that BinGo-E achieves significantly better accuracies than BinGo for cross-architecture matching, cross-OS matching, cross-compiler matching and intra-compiler matching. Additionally, in the new task of matching binaries of forked projects, BinGo-E also exhibits a better accuracy than the existing benchmark tool. Meanwhile, BinGo-E takes less time than BinGo during the process of matching.","1939-3520","","10.1109/TSE.2018.2827379","National Research Foundation; CAS Pioneer Hundred Talents Program of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338420","Binary code search;binary clone detection;vulnerability matching;emulation;3D-CFG","Binary codes;Semantics;Tools;Feature extraction;Cloning;Syntactics;Emulation","binary codes;Java;program compilers;program diagnostics;public domain software","source code clone detection;similar code search;binary executables;binary code clones;CFG structures;selective inlining technique;structural features;high-level semantic features;BinGo-E;cross-architecture matching;cross-OS matching;cross-compiler matching;intra-compiler matching;BinGo tool;compilation scenario;cross-architecture cross-OS binary code search","","1","","59","","16 Apr 2018","","","IEEE","IEEE Journals"
"Automatic Detection and Removal of Ineffective Mutants for the Mutation Analysis of Relational Database Schemas","P. McMinn; C. J. Wright; C. J. McCurdy; G. M. Kapfhammer","Department of Computer Science, University of Sheffield, Sheffield, South Yorkshire, United Kingdom; Department of Computer Science, University of Sheffield, Sheffield, South Yorkshire, United Kingdom; Department of Computer Science, Allegheny College, Meadville, PA; Department of Computer Science, Allegheny College, Meadville, PA","IEEE Transactions on Software Engineering","14 May 2019","2019","45","5","427","463","Data is one of an organization's most valuable and strategic assets. Testing the relational database schema, which protects the integrity of this data, is of paramount importance. Mutation analysis is a means of estimating the fault-finding “strength” of a test suite. As with program mutation, however, relational database schema mutation results in many “ineffective” mutants that both degrade test suite quality estimates and make mutation analysis more time consuming. This paper presents a taxonomy of ineffective mutants for relational database schemas, summarizing the root causes of ineffectiveness with a series of key patterns evident in database schemas. On the basis of these, we introduce algorithms that automatically detect and remove ineffective mutants. In an experimental study involving the mutation analysis of 34 schemas used with three popular relational database management systems-HyperSQL, PostgreSQL, and SQLite-the results show that our algorithms can identify and discard large numbers of ineffective mutants that can account for up to 24 percent of mutants, leading to a change in mutation score for 33 out of 34 schemas. The tests for seven schemas were found to achieve 100 percent scores, indicating that they were capable of detecting and killing all non-equivalent mutants. The results also reveal that the execution cost of mutation analysis may be significantly reduced, especially with “heavyweight” DBMSs like PostgreSQL.","1939-3520","","10.1109/TSE.2017.2786286","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8240964","software testing;software quality;software tools;relational databases","Relational databases;Algorithm design and analysis;Testing;Taxonomy;Google;Software","program diagnostics;program testing;relational databases;SQL","mutation analysis;program mutation;test suite quality estimates;SQLite;PostgreSQL;HyperSQL;relational database management systems;relational database schemas","","2","","84","","27 Dec 2017","","","IEEE","IEEE Journals"
"Fully Reflective Execution Environments: Virtual Machines for More Flexible Software","G. Chari; D. Garbervetsky; S. Marr; S. Ducasse","Departamento de Computación, FCEyN, UBA, ICC CONICET, Buenos Aires, Argentina; Departamento de Computación, FCEyN, UBA, ICC CONICET, Buenos Aires, Argentina; University of Kent, Canterbury, United Kingdom; RMoD project team, Inria Lille - Nord Europe, Villeneuve d'Ascq, France","IEEE Transactions on Software Engineering","17 Sep 2019","2019","45","9","858","876","VMs are complex pieces of software that implement programming language semantics in an efficient, portable, and secure way. Unfortunately, mainstream VMs provide applications with few mechanisms to alter execution semantics or memory management at run time. We argue that this limits the evolvability and maintainability of running systems for both, the application domain, e.g., to support unforeseen requirements, and the VM domain, e.g., to modify the organization of objects in memory. This work explores the idea of incorporating reflective capabilities into the VM domain and analyzes its impact in the context of software adaptation tasks. We characterize the notion of a fully reflective VM, a kind of VM that provides means for its own observability and modifiability at run time. This enables programming languages to adapt the underlying VM to changing requirements. We propose a reference architecture for such VMs and present TruffleMATE as a prototype for this architecture. We evaluate the mechanisms TruffleMATE provides to deal with unanticipated dynamic adaptation scenarios for security, optimization, and profiling aspects. In contrast to existing alternatives, we observe that TruffleMATE is able to handle all scenarios, using less than 50 lines of code for each, and without interfering with the application's logic.","1939-3520","","10.1109/TSE.2018.2812715","ANPCYT; UBA-CYT 384; CONICET; Austrian Science Fund; Johannes Kepler University Linz, Austria; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8307099","Reflection;virtual machines;metaobject protocols;dynamic adaptation","Software;Memory management;Task analysis;Virtual machining;Semantics;Shape","programming language semantics;security of data;software maintenance;virtual machines","reflective execution environments;virtual machines;flexible software;mainstream VMs;execution semantics;memory management;evolvability;maintainability;software adaptation tasks;fully reflective VM;programming languages;reference architecture;programming language semantics;dynamic adaptation scenarios;TruffleMATE mechanism","","","","74","","6 Mar 2018","","","IEEE","IEEE Journals"
"Decomposition-Based Approach for Model-Based Test Generation","P. Arcaini; A. Gargantini; E. Riccobene","Department of Distributed and Dependable Systems, Charles University, Praha, Czech Republic; Dipartimento di Ingegneria, University of Bergamo, Dalmine, Bergamo, Italy; Computer Science, Universita degli Studi di Milano, Crema, CR, Italy","IEEE Transactions on Software Engineering","14 May 2019","2019","45","5","507","520","Model-based test generation by model checking is a well-known testing technique that, however, suffers from the state explosion problem of model checking and it is, therefore, not always applicable. In this paper, we address this issue by decomposing a system model into suitable subsystem models separately analyzable. Our technique consists in decomposing that portion of a system model that is of interest for a given testing requirement, into a tree of subsystems by exploiting information on model variable dependency. The technique generates tests for the whole system model by merging tests built from those subsystems. We measure and report effectiveness and efficiency of the proposed decomposition-based test generation approach, both in terms of coverage and time.","1939-3520","","10.1109/TSE.2017.2781231","Grantová Agentura České Republiky; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8170269","Model-based testing;test case generation;model checking;state explosion problem;decomposition","Model checking;Unified modeling language;Valves;Silicon;Explosions;Presses","formal verification;program testing","decomposition-based approach;model-based test generation;model checking;testing technique;model variable dependency;decomposition-based test generation approach;testing requirement","","1","","41","","8 Dec 2017","","","IEEE","IEEE Journals"
"Detecting Developers' Task Switches and Types","A. N. Meyer; C. Satterfield; M. Züger; K. Kevic; G. C. Murphy; T. Zimmermann; T. Fritz","Department of Informatics, University of Zurich, Zurich, ZH Switzerland 8050 (e-mail: ameyer@ifi.uzh.ch); Department of Informatics, University of British Columbia, Vancouver, British Columbia Canada (e-mail: cds00@cs.ub.ca); Department of Informatics, University of Zurich, Zurich, ZH Switzerland (e-mail: zuger@ifi.uzh.ch); Microsoft Research, Microsoft Research, 214606 Cambridge, Cambridge United Kingdom of Great Britain and Northern Ireland (e-mail: kakevic@microsoft.com); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: fritz@ifi.uzh.ch)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Developers work on a broad variety of tasks during their workdays and constantly switch between them. While these task switches can be beneficial, they can also incur a high cognitive burden on developers, since they have to continuously remember and rebuild task context - the artifacts and applications relevant to the task. Researchers have therefore proposed to capture task context more explicitly and use it to provide better task support, such as task switch reduction or task resumption support. Yet, these approaches generally require the developer to manually identify task switches. Automatic approaches for predicting task switches have so far been limited in their accuracy, scope, evaluation, and the time discrepancy between predicted and actual task switches. In our work, we examine the use of automatically collected computer interaction data for detecting developers' task switches as well as task types. In two field studies - a 4h observational study and a multi-day study with experience sampling - we collected data from a total of 25 professional developers. Our study results show that we are able to use temporal and semantic features from developers' computer interaction data to detect task switches and types in the field with high accuracy of 84% and 61% respectively, and within a short time window of less than 1.6 minutes on average from the actual task switch. We discuss our findings and their practical value for a wide range of applications in real work settings.","1939-3520","","10.1109/TSE.2020.2984086","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9069309","Task Detection;Task Switching;Multi-Tasking;Work Fragmentation;Activity Recognition;Machine Learning","Task analysis;Feature extraction;Semantics;Microsoft Windows;Switches;Machine learning","","","","1","","","CCBY","16 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention","W. Wang; Y. Zhang; Y. Sui; Y. Wan; Z. Zhao; J. Wu; P. Yu; G. Xu","Computer Science and Engineering, Southern University of Science and Technology, 255310 Shenzhen, Guangdong China (e-mail: cs_wwhua@163.com); Computer science and Engineering, Southern University of Science and Technology, Shenzhen, Guangdong China (e-mail: zhangyq@sustc.edu.cn); Faculty of Engineering and Information Technology, UTS, Sydney, New South Wales Australia (e-mail: yulei.sui@uts.edu.au); College of Computer Science and Technology, Zhejiang University, 12377 Hangzhou, Zhejiang China (e-mail: wanyao1992@gmail.com); Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: zhaozhou@zju.edu.cn); Computer Science, Zhejiang University, Hangzhou, Zhejiang China 310027 (e-mail: wujian2000@zju.edu.cn); Computer Science, UIC, Chicago, Illinois United States (e-mail: psyu@uic.edu); Faculty of Engineering and IT, University of Technology Sidney, Chippendale, New South Wales Australia 2008 (e-mail: guandong.xu@uts.edu.au)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Code summarization (aka comment generation) provides a high-level natural language description of the function performed by code, which can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, the state-of-the-art approaches follow an encoder-decoder framework which encodes source code into a hidden space and later decodes it into a natural language space. Such approaches suffer from the following drawbacks: (a) they are mainly input by representing code as a sequence of tokens while ignoring code hierarchy; (b) most of the encoders only input simple features (e.g., tokens) while ignoring the features that can help capture the correlations between comments and code; (c) the decoders are typically trained to predict subsequent words by maximizing the likelihood of subsequent ground truth words, while in real world, they are excepted to generate the entire word sequence from scratch. As a result, such drawbacks lead to inferior and inconsistent comment generation accuracy. To address the above limitations, this paper presents a new code summarization approach using hierarchical attention network by incorporating multiple code features, including type-augmented abstract syntax trees and program control flows. Such features, along with plain code sequences, are injected into a deep reinforcement learning (DRL) framework (e.g., actor-critic network) for comment generation. Our approach assigns weights (pays “attention”) to tokens and statements when constructing the code representation to reflect the hierarchical code structure under different contexts regarding code features (e.g., control flows and abstract syntax trees). Our reinforcement learning mechanism further strengthens the prediction results through the actor network and the critic network, where the actor network provides the confidence of predicting subsequent words based on the current state, and the critic network computes the reward values of all the possible extensions of the current state to provide global guidance for explorations. Eventually, we employ an advantage reward to train both networks and conduct a set of experiments on a real-world dataset. The experimental results demonstrate that our approach outperforms the baselines by around 22% to 45% in BLEU-1 and outperforms the state-of-the-art approaches by around 5% to 60% in terms of S-BLEU and C-BLEU.","1939-3520","","10.1109/TSE.2020.2979701","Australian Research Council; Science and Technology Innovation Committee Foundation of Shenzhen; National Natural Science Foundation of China; Shenzhen Peacock Plan; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9031440","Code summarization;hierarchical attention;reinforcement learning","Software;Recurrent neural networks;Training;Machine learning;Decoding;Syntactics;Maintenance engineering","","","","3","","","","10 Mar 2020","","","IEEE","IEEE Early Access Articles"
"Finding Substitutable Binary Code By Synthesizing Adapters","V. Sharma; K. Hietala; S. McCamant","Department of Computer Science and Engineering, University of Minnesota, Minneapolis, Minnesota United States (e-mail: vaibhav@umn.edu); Department of Computer Science, University of Maryland, College Park, Maryland United States (e-mail: kesha@cs.umd.edu); Computer Science & Engineering, University of Minnesota, Minneapolis, Minnesota United States 55455 (e-mail: mccamant@cs.umn.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Independently developed codebases typically contain many segments of code that perform same or closely related operations (semantic clones). Finding functionally equivalent segments enables applications like replacing a segment by a more efficient or more secure alternative. Such related segments often have different interfaces, so some glue code (an adapter) is needed to replace one with the other. We present an algorithm that searches for replaceable code segments by attempting to synthesize an adapter between them from some finite family of adapters; it terminates if it finds no possible adapter. We implement our technique using concrete adapter enumeration based on Intel's Pin framework and binary symbolic execution, and explore the relation between size of adapter search space and total search time. We present examples of applying adapter synthesis for improving security of binary functions and switching between binary implementations of RC4. We present two large-scale evaluations: (1) we run adapter synthesis on more than 13,000 function pairs from the Linux C library, and (2) we reverse engineer fragments of ARM binary code by running more than a million adapter synthesis tasks. Our results confirm that several instances of adaptably equivalent binary functions exist in real-world code, and suggest that adapter synthesis can be applied for automatically replacing binary code with its adaptably equivalent variants.","1939-3520","","10.1109/TSE.2019.2931000","Division of Computing and Communication Foundations; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8776650","","Tools;Binary codes;Libraries;Security;Task analysis;Reverse engineering;Computer science","","","","1","","","","25 Jul 2019","","","IEEE","IEEE Early Access Articles"
"A Multi-Armed Bandit Approach for Test Case Prioritization in Continuous Integration Environments","J. A. d. Prado Lima; S. R. Vergilio","Computer Science, Federal University of Parana, 28122 Curitiba, Paran Brazil (e-mail: jacksonpradolima@gmail.com); Computer Science Department, Federal University of Paran - UFPR, Curitiba, Parana Brazil 81531-970 (e-mail: silvia@inf.ufpr.br)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Continuous Integration (CI) environments have been increasingly adopted in the industry to allow frequent integration of software changes, making software evolution faster and cost-effective. In such environments, Test Case Prioritization (TCP) techniques play an important role to reduce regression testing costs, establishing a test case execution order that usually maximizes early fault detection. Existing works on TCP in CI environments (TCPCI) present some limitations. Few pieces of work consider CI particularities, such as the test case volatility, that is, they do not consider the dynamic environment of the software life-cycle in which new test cases can be added or removed (discontinued), characteristic related to the Exploration versus Exploitation (EvE) dilemma. To solve such a dilemma an approach needs to balance: i) the diversity of test suite; and ii) the quantity of new test cases and test cases that are error-prone or that comprise high fault-detection capabilities. To deal with this, most approaches use, besides the failure-history, other measures that rely on code instrumentation or require additional information, such as testing coverage. However, to maintain the information updated can be difficult and time-consuming, not scalable due to the test budget of CI environments. In this context, and to properly deal with the TCPCI problem, this work presents an approach based on Multi-Armed Bandit (MAB) called COLEMAN (Combinatorial VOlatiLE Multi-Armed BANdit). The TCPCI problem falls into the category of volatile and combinatorial MAB, because multiple arms (test cases) need to be selected, and they are added or removed over the cycles. We conducted an evaluation considering three time budgets and eleven systems. The results show the applicability of our approach and that COLEMAN outperforms the most similar approach from literature in terms of early fault detection and performance.","1939-3520","","10.1109/TSE.2020.2992428","Conselho Nacional de Desenvolvimento Cientfico e Tecnolgico; Coordenao de Aperfeioamento de Pessoal de Nvel Superior; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9086053","Test Case Prioritization;Continuous Integration;Multi-Armed Bandit","Testing;Fault detection;Software;Instruments;Google;Industries;Companies","","","","","","","","4 May 2020","","","IEEE","IEEE Early Access Articles"
"Large-Scale Third-Party Library Detection in Android Markets","M. Li; P. Wang; W. Wang; S. Wang; D. Wu; J. Liu; R. Xue; W. Huo; W. Zou","Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA, USA; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA, USA; College of Information Sciences and Technology, The Pennsylvania State University, University Park, PA, USA; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; State Key Laboratory of Information Security, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China; Key Laboratory of Network Assessment Technology, Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China","IEEE Transactions on Software Engineering","17 Sep 2020","2020","46","9","981","1003","With the thriving of mobile app markets, third-party libraries are pervasively used in Android applications. The libraries provide functionalities such as advertising, location, and social networking services, making app development much more productive. However, the spread of vulnerable and harmful third-party libraries can also hurt the mobile ecosystem, leading to various security problems. Therefore, third-party library identification has emerged as an important problem, being the basis of many security applications such as repackaging detection, vulnerability identification, and malware analysis. Previously, we proposed a novel approach to identifying third-party Android libraries at a massive scale. Our method uses the internal code dependencies of an app to recognize library candidates and further classify them. With a fine-grained feature hashing strategy, we can better handle code whose package and method names are obfuscated than historical work. We have developed a prototypical tool called LibD and evaluated it with an up-to-date dataset containing 1,427,395 Android apps. Our experiment results show that LibD outperforms existing tools in detecting multi-package third-party libraries with the presence of name-based obfuscation, leading to significantly improved precision without the loss of scalability. In this paper, we extend our early work by investigating the possibility of employing effective and scalable library detection to boost the performance of large-scale app analyses in the real world. We show that the technique of LibD can be used to accelerate whole-app Android vulnerability detection and quickly identify variants of vulnerable third-party libraries. This extension paper sheds light on the practical value of our previous research.","1939-3520","","10.1109/TSE.2018.2872958","National Natural Science Foundation of China; Beijing Municipal Science and Technology Commission; National Science Foundation; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478000","Android;third-party library;software mining;code similarity detection","Libraries;Androids;Humanoid robots;Tools;Security;Java;Feature extraction","Android (operating system);invasive software;mobile computing;security of data;smart phones;software libraries","Android apps;third-party Android libraries;third-party library identification;app development;Android applications;mobile app markets;Android markets;third-party library detection;whole-app Android vulnerability detection;large-scale app analyses;scalable library detection","","","","79","IEEE","30 Sep 2018","","","IEEE","IEEE Journals"
"Automated Generation of Consistent Graph Models with Multiplicity Reasoning","K. Marussy; O. Semerath; D. Varro","Department of Measurement and Information Systems, Budapest University of Technology and Economics Faculty of Electrical Engineering and Informatics, 309392 Budapest, Budapest, Hungary, 1117 (e-mail: marussy@mit.bme.hu); Department of Measurement and Information System, Budapest University of Technology and Economics, 61810 Budapest, Budapest, Hungary, (e-mail: semerath@mit.bme.hu); Department of Electrical & Computer Engineering, McGill University, 5620 Montreal, Quebec, Canada, (e-mail: daniel.varro@mcgill.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Advanced tools used in model-based systems engineering (MBSE) frequently represent their models as graphs. In order to test those tools, the automated generation of well-formed (or intentionally malformed) graph models is necessitated which is often carried out by solver-based model generation techniques. In many model generation scenarios, one needs more refined control over the generated unit tests to focus on the more relevant models. Type scopes allow to precisely define the required number of newly generated elements, thus one can avoid the generation of unrealistic and highly symmetric models having only a single type of elements. In this paper, we propose a 3-valued scoped partial modeling formalism, which innovatively extends partial graph models with predicate abstraction and counter abstraction. As a result, well-formedness constraints and multiplicity requirements can be evaluated in an approximated way on incomplete (unfinished) models by using advanced graph query engines with numerical solvers (e.g. IP or LP solvers). Based on the refinement of 3-valued scoped partial models, we propose an efficient model generation algorithm that generates models that are both well-formed and satisfy the scope requirements. We show that the proposed approach scales significantly better than existing SAT-solver techniques or the original graph solver without multiplicity reasoning. We illustrate our approach in a complex design-space exploration case study of collaborating satellites introduced by researchers at NASA Jet Propulsion Lab.","1939-3520","","10.1109/TSE.2020.3025732","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9201551","D.2.11.b Domain-specific architectures;E.1.d Graphs and networks;F.4.1.d Logic and constraint programming;I.6.4 Model Validation and Analysis","Numerical models;Tools;Object oriented modeling;Generators;Unified modeling language;Biological system modeling","","","","","","","CCBY","21 Sep 2020","","","IEEE","IEEE Early Access Articles"
"Code Reviews with Divergent Review Scores: An Empirical Study of the OpenStack and Qt Communities","T. Hirao; S. McIntosh; A. Ihara; K. Matsumoto","Graduate School of Information Science, Nara Institute of Science and Technology, Japan (e-mail: hirao.toshiki.ho7@is.naist.jp); Department of Electrical and Computer Engineering, McGill University, Canada (e-mail: shane.mcintosh@mcgill.ca); Fuculty of System Engineering, Wakayama University, Japan (e-mail: ihara@sys.wakayama-u.ac.jp); Graduate School of Information Science, Nara Institute of Science and Technology, Japan (e-mail: matumoto@is.naist.jp)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Code review is a broadly adopted software quality practice where developers critique each others' patches. In addition to providing constructive feedback, reviewers may provide a score to indicate whether the patch should be integrated. Since reviewer opinions may differ, patches can receive both positive and negative scores. If reviews with divergent scores are not carefully resolved, they may contribute to a tense reviewing culture and may slow down integration. In this paper, we study patches with divergent review scores in the OPENSTACK and QT communities. Quantitative analysis indicates that patches with divergent review scores: (1) account for 15%-37% of patches that receive multiple review scores; (2) are integrated more often than they are abandoned; and (3) receive negative scores after positive ones in 70% of cases. Furthermore, a qualitative analysis indicates that patches with strongly divergent scores that: (4) are abandoned more often suffer from external issues (e.g., integration planning, content duplication) than patches with weakly divergent scores and patches without divergent scores; and (5) are integrated often address reviewer concerns indirectly (i.e., without changing patches). Our results suggest that review tooling should integrate with release schedules and detect concurrent development of similar patches to optimize review discussions with divergent scores. Moreover, patch authors should note that even the most divisive patches are often integrated through discussion, integration timing, and careful revision.","1939-3520","","10.1109/TSE.2020.2977907","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9023005","Modern Code Review;Divergent discussion;Empirical Study","Testing;Timing;Software quality;Statistical analysis;Planning;Organizations","","","","1","","","","3 Mar 2020","","","IEEE","IEEE Early Access Articles"
"Reviving Sequential Program Birthmarking for Multithreaded Software Plagiarism Detection","Z. Tian; T. Liu; Q. Zheng; E. Zhuang; M. Fan; Z. Yang","Department of Computer Science and Technology, Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), School of Electronic and Information Engineering, Xi'an Jiaotong University, Xi'an, China; Department of Computer Science and Technology, Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xi'an, China; Department of Computer Science and Technology, Ministry of Education Key Lab For Intelligent Networks and Network Security (MOEKLINNS), Xi'an Jiaotong University, Xi'an, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI","IEEE Transactions on Software Engineering","9 May 2018","2018","44","5","491","511","As multithreaded programs become increasingly popular, plagiarism of multithreaded programs starts to plague the software industry. Although there has been tremendous progress on software plagiarism detection technology, existing dynamic birthmark approaches are applicable only to sequential programs, due to the fact that thread scheduling nondeterminism severely perturbs birthmark generation and comparison. We propose a framework called TOB (Thread-oblivious dynamic Birthmark) that revives existing techniques so they can be applied to detect plagiarism of multithreaded programs. This is achieved by thread-oblivious algorithms that shield the influence of thread schedules on executions. We have implemented a set of tools collectively called TOB-PD (TOB based Plagiarism Detection tool) by applying TOB to three existing representative dynamic birthmarks, including SCSSB (System Call Short Sequence Birthmark), DYKIS (DYnamic Key Instruction Sequence birthmark) and JB (an API based birthmark for Java). Our experiments conducted on large number of binary programs show that our approach exhibits strong resilience against state-of-the-art semantics-preserving code obfuscation techniques. Comparisons against the three existing tools SCSSB, DYKIS and JB show that the new framework is effective for plagiarism detection of multithreaded programs. The tools, the benchmarks and the experimental results are all publicly available.","1939-3520","","10.1109/TSE.2017.2688383","National Key Research and Development Program of China; National Science Foundation of China; Fok Ying-Tong Education Foundation; Ministry of Education Innovation Research Team; Science and Technology Project in Shaanxi Province of China; Fundamental Research Funds for the Central Universities; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7888597","Software plagiarism detection;multithreaded program;software birthmark;thread-oblivious birthmark","Plagiarism;Instruction sets;Computer science;Dynamic scheduling;Indexes;Electronic mail","computer crime;fraud;multi-threading;scheduling","sequential program birthmarking;multithreaded programs;software industry;software plagiarism detection technology;dynamic birthmark approaches;thread scheduling nondeterminism;birthmark generation;Thread-oblivious dynamic Birthmark;thread-oblivious algorithms;thread schedules;Plagiarism Detection tool;System Call Short Sequence Birthmark;DYnamic Key Instruction Sequence birthmark;API based birthmark;binary programs;multithreaded software","","7","","65","","28 Mar 2017","","","IEEE","IEEE Journals"
"A Systematic Literature Review of Applications of the Physics of Notations","D. van der Linden; I. Hadar","Department of Computer Science, University of Bristol, Bristol, United Kingdom; Department of Information Systems, University of Haifa, Haifa, Israel","IEEE Transactions on Software Engineering","26 Aug 2019","2019","45","8","736","759","INTRODUCTION: The Physics of Notations (PoN) is a theory for the design of cognitively effective visual notations, emphasizing the need for design grounded in objective and verifiable rationale. Although increasingly applied, no systematic analysis of PoN applications has yet been performed to assess the theory's efficacy in practice. OBJECTIVES: Our primary objective was to assess the scope and verifiability of PoN applications. METHOD: We performed a systematic literature review (SLR) of peer-reviewed PoN applications. We analyzed what visual notations have been evaluated and designed using the PoN, for what reasons, to what degree applications consider requirements of their notation's users, and how verifiable these applications are. RESULTS: Seventy PoN applications were analyzed. We found major differences between applications evaluating existing notations and applications designing new notations. Particularly, in the case of new notations, we found that most applications adopted the PoN with little critical thought towards it, rarely considered its suitability for a particular context, and typically treated and discussed the PoN with few, if any, verifiable details and data. CONCLUSION: The results warrant consideration for those applying the PoN to do so carefully, and show the need for additional means to guide designers in systematically applying the PoN.","1939-3520","","10.1109/TSE.2018.2802910","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8283537","Systematic literature review;physics of notations;visual notations;cognitive effectiveness;design rationale","Visualization;Unified modeling language;Semantics;Complexity theory;Physics","data visualisation;formal specification;visual languages","systematic literature review;cognitively effective visual notations;verifiable rationale;systematic analysis;peer-reviewed PoN applications;physics of notations;SLR;objective rationale","","","","113","","6 Feb 2018","","","IEEE","IEEE Journals"
"Requirements Framing Affects Design Creativity","R. Mohanani; B. Turhan; P. Ralph","Dept. of CSE & HCD, IIIT Delhi, New Delhi, Delhi, India; M3S Group, University of Oulu, FI, Finland; Dept. of Comp. Sci., Univ. of Auckland, Auckland, New Zealand","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","936","947","Design creativity, the originality and practicality of a solution concept, is critical for the success of many software projects. However, little research has investigated the relationship between the way desiderata are presented and design creativity. This study therefore investigates the impact of presenting desiderata as ideas, requirements or prioritized requirements on design creativity. Two between-subjects randomized controlled experiments were conducted with 42 and 34 participants. Participants were asked to create design concepts from a list of desiderata. Participants who received desiderata framed as requirements or prioritized requirements created designs that are, on average, less original but more practical than the designs created by participants who received desiderata framed as ideas. This suggests that more formal, structured presentations of desiderata are less appropriate where more innovative solutions are desired. The results also show that design performance is highly susceptible to minor changes in the vernacular used to communicate desiderata.","1939-3520","","10.1109/TSE.2019.2909033","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8680661","Cognitive bias;creativity;design;experiment;originality;practicality;requirements;prioritization","Creativity;Software;Task analysis;Requirements engineering;Random access memory;Ferroelectric films;Nonvolatile memory","","","","2","","93","IEEE","2 Apr 2019","","","IEEE","IEEE Journals"
"RefDiff 2.0: A Multi-language Refactoring Detection Tool","D. Silva; J. Silva; G. J. De Souza Santos; R. Terra; M. T. O. Valente","Department of Computer Science, Universidade Federal de Minas Gerais, 28114 Belo Horizonte, MG Brazil (e-mail: danilofes@gmail.com); n/a, Quimbik, Inc., San Rafael, California United States (e-mail: joao@jpribeiro.com.br); COENS, Universidade Tecnológica Federal do Paraná, 74354 Dois Vizinhos, Paranó Brazil (e-mail: gustavosantos@utfpr.edu.br); DCC, Universidade Federal de Lavras, Lavras, MG Brazil (e-mail: rterrabh@gmail.com); Department of Computer Science, Universidade Federal de Minas Gerais, 28114 Belo Horizonte, MG Brazil (e-mail: mtov@dcc.ufmg.br)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Identifying refactoring operations in source code changes is valuable to understand software evolution. Therefore, several tools have been proposed to automatically detect refactorings applied in a system by comparing source code between revisions. The availability of such infrastructure has enabled researchers to study refactoring practice in large scale, leading to important advances on refactoring knowledge. However, although a plethora of programming languages are used in practice, the vast majority of existing studies are restricted to the Java language due to limitations of the underlying tools. This fact poses an important threat to external validity. Thus, to overcome such limitation, in this paper we propose RefDiff 2.0, a multi-language refactoring detection tool. Our approach leverages techniques proposed in our previous work and introduces a novel refactoring detection algorithm that relies on the Code Structure Tree (CST), a simple yet powerful representation of the source code that abstracts away the specificities of particular programming languages. Despite its language-agnostic design, our evaluation shows that RefDiff's precision (96%) and recall (80%) are on par with state-of-the-art refactoring detection approaches specialized in the Java language. Our modular architecture also enables one to seamless extend RefDiff to support other languages via a plugin system. As a proof of this, we implemented plugins to support two other popular programming languages: JavaScript and C. Our evaluation in these languages reveals that precision and recall ranges from 88% to 91%. With these results, we envision RefDiff as a viable alternative for breaking the single-language barrier in refactoring research and in practical applications of refactoring detection.","1939-3520","","10.1109/TSE.2020.2968072","Fundacao de Amparo a Pesquisa do Estado de Minas Gerais; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8966516","","Tools;Java;Software;History;Crawlers;Measurement","","","","","","","","22 Jan 2020","","","IEEE","IEEE Early Access Articles"
"On the Energy Footprint of Mobile Testing Frameworks","L. Cruz; R. Abreu","SERG, Delft University of Technology, 2860 Delft, Zuid-Holland Netherlands (e-mail: luiscruz@fe.up.pt); Computer Science and Engineering, Instituto Superior Técnico, University of Lisbon, Lisbon, Lisbon Portugal 1049-001 (e-mail: rui@computer.org)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","High energy consumption is a challenging issue that an ever increasing number of mobile applications face today. However, energy consumption is being tested in an ad hoc way, despite being an important non-functional requirement of an application. Such limitation becomes particularly disconcerting during software testing: on the one hand, developers do not really know how to measure energy; on the other hand, there is no knowledge as to what is the energy overhead imposed by the testing framework. In this paper, as we evaluate eight popular mobile UI automation frameworks, we have discovered that there are automation frameworks that increase energy consumption up to roughly 2200%. While limited in the interactions one can do, Espresso is the most energy efficient framework. However, depending on the needs of the tester, Appium, Monkeyrunner, or UIAutomator are good alternatives. In practice, results show that deciding which is the most suitable framework is vital. We provide a decision tree to help developers make an educated decision on which framework suits best their testing needs.","1939-3520","","10.1109/TSE.2019.2946163","Faculdade de Ciências e Tecnologia, Universidade Nova de Lisboa; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862921","Mobile Testing;Testing Frameworks;Energy Consumption","Automation;Energy consumption;Testing;Tools;Energy measurement;Monitoring;Robots","","","","","","","","8 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Incidents Are Meant for Learning, Not Repeating: Sharing Knowledge About Security Incidents in Cyber-Physical Systems","F. Alrimawi; L. Pasquale; D. Mehta; N. Yoshioka; B. Nuseibeh","Lero-The Irish Software Research Centre, University of Limerick, 8808 Limerick, Munster Ireland (e-mail: faeq.rimawi@gmail.com); Computer Science, University College Dublin, 8797 Dublin, Belfield Ireland (e-mail: liliana.pasquale@ucd.ie); UTRC, United Technologies Research Center, 129535 Cork, Munster Ireland (e-mail: MehtaD@utrc.utc.com); NII, National Institute of Informatics, 13513 Chiyoda-ku, Tokyo Japan (e-mail: nobukazu@nii.ac.jp); Lero-The Irish Software Research Centre, University of Limerick, 8808 Limerick, Munster Ireland (e-mail: bashar.nuseibeh@lero.ie)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Cyber-physical systems (CPSs) are part of many critical infrastructures such as industrial automation and transportation systems. Thus, security incidents targeting CPSs can have disruptive consequences to assets and people. As incidents tend to re-occur, sharing knowledge about these incidents can help organizations be more prepared to prevent, mitigate or investigate future incidents. This paper proposes a novel approach to enable representation and sharing of knowledge about CPS incidents across different organizations. To support sharing, we represent incident knowledge (incident patterns) capturing incident characteristics that can manifest again, such as incident activities or vulnerabilities exploited by offenders. Incident patterns are a more abstract representation of specific incident instances and, thus, are general enough to be applicable to various systems - different than the one in which the incident occurred. They can also avoid disclosing potentially sensitive information about an organization's assets and resources. We provide an automated technique to extract an incident pattern from a specific incident instance. To understand how an incident pattern can manifest again in other cyber-physical systems, we also provide an automated technique to instantiate incident patterns to specific systems. We demonstrate the feasibility of our approach in the application domain of smart buildings. We evaluate correctness, scalability, and performance using two substantive scenarios inspired by real-world systems and incidents.","1939-3520","","10.1109/TSE.2020.2981310","ERC Advanced Grant; Science Foundation Ireland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9039700","Cyber-physical systems;Security incidents;Smart building;Knowledge Sharing","Security;Smart buildings;Cyber-physical systems;Organizations;HVAC;Servers","","","","1","","","","17 Mar 2020","","","IEEE","IEEE Early Access Articles"
"Value-Flow-Based Demand-Driven Pointer Analysis for C and C++","Y. Sui; J. Xue","Artificial Intelligence (CAI), University of Technology Sydney (UTS), Ultimo, NSW, Australia; University of New South Wales (UNSW), Sydney, NSW, Australia","IEEE Transactions on Software Engineering","13 Aug 2020","2020","46","8","812","835","We present Supa, a value-flow-based demand-driven flow- and context-sensitive pointer analysis with strong updates for C and C++ programs. Supa enables computing points-to information via value-flow refinement, in environments with small time and memory budgets. We formulate Supa by solving a graph-reachability problem on an inter-procedural value-flow graph representing a program's def-use chains, which are pre-computed efficiently but over-approximately. To answer a client query (a request for a variable's points-to set), Supa reasons about the flow of values along the pre-computed def-use chains sparsely (rather than across all program points), by performing only the work necessary for the query (rather than analyzing the whole program). In particular, strong updates are performed to filter out spurious def-use chains through value-flow refinement as long as the total budget is not exhausted. We have implemented Supa on top of LLVM (4.0.0) together with a comprehensive micro-benchmark suite after a years-long effort (consisting of around 400 test cases, including hand-written ones and the ones extracted from real programs). We have evaluated Supa by choosing uninitialized pointer detection and C++ virtual table resolution as two major clients, using 24 real-world programs including 18 open-source C programs and 6 large CPU2000/2006 C++ benchmarks. For uninitialized pointer client, Supa achieves improved precision as the analysis budget increases, with its flow-sensitive (context-insensitive) analysis reaching 97.4 percent of that achieved by whole-program Sparse Flow-Sensitive analysis (SFS) by consuming about 0.18 seconds and 65 KB of memory per query, on average (with a budget of at most 10,000 value-flow edges per query). With context-sensitivity also considered, Supa becomes more precise for some programs but also incurs more analysis times. To further demonstrate the effectiveness of Supa, we have also evaluated Supa in resolving C++ virtual tables by querying the function pointers at every virtual callsite. Compared to analysis without strong updates for heap objects, Supa's demand-driven context-sensitive strong update analysis reduces 7.35 percent spurious virtual table targets with only 0.4 secs per query, on average.","1939-3520","","10.1109/TSE.2018.2869336","Australian Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8457263","Strong updates;value flow;pointer analysis;flow sensitivity","C++ languages;Resource management;Open source software;Sensitivity;Reachability analysis;Instruction sets;Registers","data flow analysis;data structures;flow graphs;object-oriented programming;optimising compilers;program diagnostics;reachability analysis;sensitivity analysis","value-flow-based demand-driven flow;context-sensitive pointer analysis;value-flow refinement;inter-procedural value-flow graph;pre-computed def-use chains;pointer client;sparse flow-sensitive analysis;value-flow-based demand-driven pointer analysis;Supa demand-driven context-sensitive strong update analysis;C++ program;C program;time 0.4 s;memory size 65.0 KByte;temperature 2006.0 C;efficiency 97.4 percent;efficiency 7.35 percent","","2","","58","IEEE","11 Sep 2018","","","IEEE","IEEE Journals"
"Tell You a Definite Answer: Whether Your Data is Tainted During Thread Scheduling","X. Zhang; Z. Yang; Q. Zheng; Y. Hao; P. Liu; T. Liu","Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Department of Computer Science, Western Michigan University, Kalamazoo, MI, USA; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China; Ministry of Education Key Lab for Intelligent Networks and Network Security, Xi'an Jiaotong University, Xi'an, Shaanxi, China","IEEE Transactions on Software Engineering","17 Sep 2020","2020","46","9","916","931","With the advent of multicore processors, there is a great need to write parallel programs to take advantage of parallel computing resources. However, due to the nondeterminism of parallel execution, the malware behaviors sensitive to thread scheduling are extremely difficult to detect. Dynamic taint analysis is widely used in security problems. By serializing a multithreaded execution and then propagating taint tags along the serialized schedule, existing dynamic taint analysis techniques lead to under-tainting with respect to other possible interleavings under the same input. In this paper, we propose an approach called DSTAM that integrates symbolic analysis and guided execution to systematically detect tainted instances on all possible executions under a given input. Symbolic analysis infers alternative interleavings of an executed trace that cover new tainted instances, and computes thread schedules that guide future executions. Guided execution explores new execution traces that drive future symbolic analysis. We have implemented a prototype as part of an educational tool that teaches secure C programming, where accuracy is more critical than efficiency. To the best of our knowledge, DSTAM is the first algorithm that addresses the challenge of taint analysis for multithreaded program under fixed inputs.","1939-3520","","10.1109/TSE.2018.2871666","National Key R&D Program of China; National Natural Science Foundation of China; Fok Ying Tung Education Foundation; Ministry of Education Innovation Research Team; Project of China Knowledge Centre for Engineering Science and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8472790","Taint analysis;multithreaded programs;symbolic analysis;encoding;guided execution","Instruction sets;Security;Tools;Monitoring;Schedules;Prototypes","invasive software;microprocessor chips;multiprocessing systems;multi-threading;parallel programming;program diagnostics;scheduling","tainted instances;thread schedules;guide future executions;drive future symbolic analysis;secure C programming;DSTAM;multithreaded program;definite answer;thread scheduling;multicore processors;parallel programs;parallel computing resources;parallel execution;security problems;multithreaded execution;taint tags;serialized schedule;dynamic taint analysis techniques;alternative interleavings;executed trace","","","","62","IEEE","26 Sep 2018","","","IEEE","IEEE Journals"
"A Study of Feature Scattering in the Linux Kernel","L. Passos; R. Queiroz; M. Mukelabai; T. Berger; S. Apel; K. Czarnecki; J. A. Padilla","Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; Computer Science and Engineering, Chalmers University of Technology, Gothenburg, SE, Sweden; Computer Science and Engineering, Chalmers University of Technology, Gothenburg, SE, Sweden; Informatics and Mathematics, University of Passau, Bavaria, DE, Germany; Electrical and Computer Engineering, University of Waterloo, Waterloo, ON, Canada; SAP, SAP Waterloo, Waterloo, ON, Canada","IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","146","164","Feature code is often scattered across a software system. Scattering is not necessarily bad if used with care, as witnessed by systems with highly scattered features that evolved successfully. Feature scattering, often realized with a pre-processor, circumvents limitations of programming languages and software architectures. Unfortunately, little is known about the principles governing scattering in large and long-living software systems. We present a longitudinal study of feature scattering in the Linux kernel, complemented by a survey with 74, and interviews with nine Linux kernel developers. We analyzed almost eight years of the kernel's history, focusing on its largest subsystem: device drivers. We learned that the ratio of scattered features remained nearly constant and that most features were introduced without scattering. Yet, scattering easily crosses subsystem boundaries, and highly scattered outliers exist. Scattering often addresses a performance-maintenance tradeoff (alleviating complicated APIs), hardware design limitations, and avoids code duplication. While developers do not consciously enforce scattering limits, they actually improve the system design and refactor code, thereby mitigating pre-processor idiosyncrasies or reducing its use.","1939-3520","","10.1109/TSE.2018.2884911","Vinnova Sweden; Vetenskapsrådet; Deutsche Forschungsgemeinschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8565973","Pre-processor, linux kernel, feature, scattering","Scattering;Kernel;Linux;Interviews;Software systems;Maintenance engineering","device drivers;Linux;operating system kernels;software maintenance;source code (software)","refactor code;feature scattering;feature code;software system;Linux kernel developers;system design;device drivers","","3","","63","IEEE","6 Dec 2018","","","IEEE","IEEE Journals"
"A Framework for Quantitative Modeling and Analysis of Highly (Re)configurable Systems","M. H. Ter Beek; A. Legay; A. L. Lafuente; A. Vandin","Istituto di Scienza e Tecnologie dell'Informazione, Consiglio Nazionale delle Ricerche, Pisa, Italy; Inria Rennes, Rennes, France; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kgs. Lyngby, Denmark; Department of Applied Mathematics and Computer Science, Technical University of Denmark, Kgs. Lyngby, Denmark","IEEE Transactions on Software Engineering","13 Mar 2020","2020","46","3","321","345","This paper presents our approach to the quantitative modeling and analysis of highly (re)configurable systems, such as software product lines. Different combinations of the optional features of such a system give rise to combinatorially many individual system variants. We use a formal modeling language that allows us to model systems with probabilistic behavior, possibly subject to quantitative feature constraints, and able to dynamically install, remove or replace features. More precisely, our models are defined in the probabilistic feature-oriented language QFLan, a rich domain specific language (DSL) for systems with variability defined in terms of features. QFLan specifications are automatically encoded in terms of a process algebra whose operational behavior interacts with a store of constraints, and hence allows to separate system configuration from system behavior. The resulting probabilistic configurations and behavior converge seamlessly in a semantics based on discrete-time Markov chains, thus enabling quantitative analysis. Our analysis is based on statistical model checking techniques, which allow us to scale to larger models with respect to precise probabilistic analysis techniques. The analyses we can conduct range from the likelihood of specific behavior to the expected average cost, in terms of feature attributes, of specific system variants. Our approach is supported by a novel Eclipse-based tool which includes state-of-the-art DSL utilities for QFLan based on the Xtext framework as well as analysis plug-ins to seamlessly run statistical model checking analyses. We provide a number of case studies that have driven and validated the development of our framework.","1939-3520","","10.1109/TSE.2018.2853726","EU project QUANTICOL; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405597","Software product lines;probabilistic modeling;quantitative constraints;statistical model checking;formal methods","Probabilistic logic;Model checking;Tools;Analytical models;Runtime;Computational modeling;DSL","formal specification;formal verification;Markov processes;probability;process algebra;specification languages;statistical analysis","system configuration;system behavior;resulting probabilistic configurations;quantitative analysis;statistical model checking techniques;larger models;precise probabilistic analysis techniques;specific behavior;feature attributes;specific system variants;analysis plug-ins;statistical model checking analyses;highlyconfigurable systems;quantitative modeling;software product lines;optional features;combinatorially many individual system variants;formal modeling language;probabilistic behavior;quantitative feature constraints;probabilistic feature-oriented language QFLan;rich domain specific language;QFLan specifications;process algebra","","1","","95","IEEE","6 Jul 2018","","","IEEE","IEEE Journals"
"A Cost-efficient Auto-scaling Algorithm for Large-scale Graph Processing in Cloud Environments with Heterogeneous Resources","S. Heidari; R. Buyya","The School of Computing and Information Systems, The University of Melbourne, Melbourne, Victoria Australia (e-mail: sheidari@student.unimelb.edu.au); CSSE, TThe University of Melbourne, Melbourne, Victoria Australia 3010 (e-mail: rbuyya@unimelb.edu.au)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Graph processing model is being adopted extensively in various domains such as online gaming, social media, scientific computing and Internet of Things (IoT). Many frameworks have been developed in recent years to facilitate analytics and computing of large-scale graphs. Dynamic scalability is always a major concern and It becomes even more important when there is a correlation between scalability and monetary cost. The pay-as-you-go model that is used by public cloud providers enables users to pay only for the number of resources they utilize. Nevertheless, processing large-scale graphs in such environments has been less studied. In this paper, we have developed algorithms to take advantage of resource heterogeneity in cloud environments. Using these algorithms, the system can automatically adjust the number and types of virtual machines according to the computation requirements for convergent graph applications to improve the performance and reduce the dollar cost of the entire operation. Also, a smart profiling mechanism along with a novel dynamic repartitioning approach helps to distribute graph partitions expeditiously. It is shown that this method outperforms popular frameworks such as Giraph and decreases more than 50% of the dollar cost compared to Giraph.","1939-3520","","10.1109/TSE.2019.2934849","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8798698","Cloud Computing;Large-scale Graph Processing;Auto-scaling;Cost Saving;Heterogeneous Resources","Cloud computing;Scalability;Computational modeling;Internet of Things;Heuristic algorithms;Software algorithms;Clustering algorithms","","","","","","","","14 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Falsification of Cyber-Physical Systems Using Deep Reinforcement Learning","Y. Yamagata; S. Liu; T. Akazaki; Y. Duan; J. Hao","Cyber Physical Security Research Center, National Institute of Advanced Industrial Science and Technology Kansai Center, 73773 Ikeda, Osaka Japan (e-mail: yoriyuki.yamagata@aist.go.jp); College of Intelligence and Computing, Tianjin University, China. (e-mail: shuang.liu@tju.edu.cn); Software Laboratory, Fujitsu Laboratories Ltd, 133674 Kawasaki, Kanagawa Japan (e-mail: akazaki.takumi@jp.fujitsu.com); College of Intellegence and Computing, Tianjin University, 12605 Tianjin, Tianjin China (e-mail: duanyihai@tju.edu.cn); College of Intelligence and Computing, Tianjin University, China and Noah’s Ark Lab, Huawei. (e-mail: jianye.hao@tju.edu.cn)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","A Cyber-Physical System (CPS) is a system which consists of software components and physical components. Traditional system verification techniques such as model checking or theorem proving are difficult to apply to CPS because the physical components have infinite number of states. To solve this problem, robustness guided falsification of CPS is introduced. Robustness measures how robustly the given specification is satisfied. Robustness guided falsification tries to minimize the robustness by changing inputs and parameters of the system. The input with a minimal robustness (counterexample) is a good candidate to violate the specification. Existing methods use several optimization techniques to minimize robustness. However, those methods do not use temporal structures in a system input and often require a large number of simulation runs to the minimize robustness. In this paper, we explore state-of-the-art Deep Reinforcement Learning (DRL) techniques, i.e., Asynchronous Advantage Actor-Critic (A3C) and Double Deep Q Network (DDQN), to reduce the number of simulation runs required to find such counterexamples. We theoretically show how robustness guided falsification of a safety property is formatted as a reinforcement learning problem. Then, we experimentally compare the effectiveness of our methods with three baseline methods, i.e., random sampling, cross entropy and simulated annealing, on three well known CPS systems. We thoroughly analyse the experiment results and identify two factors of CPS which make DRL based methods better than existing methods. The most important factor is the availability of the system internal dynamics to the reinforcement learning algorithm. The other factor is the existence of learnable structure in the counterexample.","1939-3520","","10.1109/TSE.2020.2969178","Special Program of Artificial Intelligence of Tianjin Municipal Science and Technology Commission; The New Energy and Industrial Technology Development Organization Japan; Special Program of Artificial Intelligence Tianjin Research Program of Application Foundation and Advanced Technology; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8967146","Robustness guided falsification;CPS;Reinforcement Learning","Robustness;Reinforcement learning;Model checking;Measurement;Software;Optimization","","","","1","","","","23 Jan 2020","","","IEEE","IEEE Early Access Articles"
"On the Multiple Sources and Privacy Preservation Issues for Heterogeneous Defect Prediction","Z. Li; X. Jing; X. Zhu; H. Zhang; B. Xu; S. Ying","Wuhan University, Wuhan, China; Wuhan University, Wuhan, China; Henan University, Kaifeng, China; University of Newcastle, Callaghan, NSW, Australia; Wuhan University, Wuhan, China; Wuhan University, Wuhan, China","IEEE Transactions on Software Engineering","16 Apr 2019","2019","45","4","391","411","Heterogeneous defect prediction (HDP) refers to predicting defect-proneness of software modules in a target project using heterogeneous metric data from other projects. Existing HDP methods mainly focus on predicting target instances with single source. In practice, there exist plenty of external projects. Multiple sources can generally provide more information than a single project. Therefore, it is meaningful to investigate whether the HDP performance can be improved by employing multiple sources. However, a precondition of conducting HDP is that the external sources are available. Due to privacy concerns, most companies are not willing to share their data. To facilitate data sharing, it is essential to study how to protect the privacy of data owners before they release their data. In this paper, we study the above two issues in HDP. Specifically, to utilize multiple sources effectively, we propose a multi-source selection based manifold discriminant alignment (MSMDA) approach. To protect the privacy of data owners, a sparse representation based double obfuscation algorithm is designed and applied to HDP. Through a case study of 28 projects, our results show that MSMDA can achieve better performance than a range of baseline methods. The improvement is 3.4-15.3 percent in g-measure and 3.0-19.1 percent in AUG.","1939-3520","","10.1109/TSE.2017.2780222","General Technology Fundamental Research United Fund; National Key Research and Development Program of China; National Natural Science Foundation of China; Science and Technology Program in Henan province; Science and Technique Development Program of Henan; Province-School-Region Project of Henan University; Research Foundation of Henan University; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8168387","Heterogeneous defect prediction;multiple sources;privacy preservation;utility;source selection;manifold discriminant alignment","Measurement;Software;Data privacy;Privacy;Predictive models;Training data;Companies","data privacy;learning (artificial intelligence);software metrics","defect-proneness;target project;heterogeneous metric data;HDP methods;HDP performance;external sources;data owners;multisource selection;privacy preservation issues;heterogeneous defect prediction;efficiency 3.4 percent to 15.3 percent;efficiency 3.0 percent to 19.1 percent","","16","","101","","6 Dec 2017","","","IEEE","IEEE Journals"
"What is Discussed about Blockchain? A Case Study on the Use of Balanced LDA and the Reference Architecture of a Domain to Capture Online Discussions about Blockchain platforms across the Stack Exchange Communities","Z. Wan; X. Xia; A. E. Hassan","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: wanzhiyuan@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxkidd@zju.edu.cn); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Blockchain-related discussions have become increasingly prevalent in programming Q\&A websites, such as Stack Overflow and other Stack Exchange communities. Analyzing and understanding those discussions could provide insights about the topics of interest to practitioners, and help the software development and research communities better understand the needs and challenges facing developers as they work in this new domain. Prior studies propose the use of LDA to study the Stack Exchange discussions. However, a simplistic use of LDA would capture the topics in discussions blindly without keeping in mind the variety of the dataset and domain-specific concepts. Specifically, LDA is biased towards larger sized corpora; LDA-derived topics are not linked to higher level domain-specific concepts. We propose an approach that combines balanced LDA (which ensures that the topics are balanced across the domain) with the reference architecture of a domain to capture and compare topics of discussions across the Stack Exchange communities. We make a number of interesting observations, including: (1) Bitcoin, Ethereum, Hyperledger Fabric and Corda are the four most commonly-discussed blockchain platforms on the Stack Exchange communities; (2) A broad range of topics are discussed at distinct layers in our derived reference architecture. The consensus layer topics are most commonly discussed; (3) We observe an overall growth in the absolute impact for all architectural layer topics. The application layer topics have the greatest absolute impact over time in comparison to other layer topics; (4) Application layer, API layer, consensus layer and network layer topics are commonly discussed across the studied blockchain platforms. Based on our findings, we highlight future directions and provide recommendations for practitioners and researchers.","1939-3520","","10.1109/TSE.2019.2921343","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8732384","Empirical Study;Reference Architecture;Blockchain;Stack Overflow;Stack Exchange","Blockchain;Peer-to-peer computing;Computer architecture;Smart contracts;Programming;Bitcoin","","","","4","","","","6 Jun 2019","","","IEEE","IEEE Early Access Articles"
"Deep Transfer Bug Localization","X. Huo; F. Thung; M. Li; D. Lo; S. Shi","Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: huox@lamda.nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore (e-mail: ferdiant.2013@phdis.smu.edu.sg); Nanjing University, Nantional key Lab for Novel Software Technology, Nanjing, Jiangsu China 210093 (e-mail: lim@nju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Computer Science, Nanjing University, Nanjing, Jiangsu China (e-mail: shist@lamda.nju.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Many projects often receive more bug reports than what they can handle. To help debug and close bug reports, a number of bug localization techniques have been proposed. These techniques analyze a bug report and return a ranked list of potentially buggy source code files. Recent development on bug localization has resulted in the construction of effective supervised approaches that use historical data of manually localized bugs to boost performance. Unfortunately, as highlighted by Zimmermann et al., sufficient bug data is often unavailable for many projects and companies. This raises the need for cross-project bug localization -- the use of data from a project to help locate bugs in another project. To fill this need, we propose a deep transfer learning approach for cross-project bug localization. Our proposed approach named TRANP-CNN extracts transferable semantic features from source project and fully exploits labeled data from target project for effective cross-project bug localization. We have evaluated TRANP-CNN on curated high-quality bug datasets and our experimental results show that TRANP-CNN can locate buggy files correctly at top 1, top 5, and top 10 positions for 29.9%, 51.7%, 61.3% of the bugs respectively, which significantly outperform state-of-the-art bug localization solution based on deep learning and several other advanced alternative solutions considering various standard evaluation metrics.","1939-3520","","10.1109/TSE.2019.2920771","National Key Research and Development Program; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736995","Cross-project bug localization;transfer learning;deep learning","Computer bugs;Feature extraction;Task analysis;Encoding;Computer languages;Semantics;Data models","","","","1","","","","14 Jun 2019","","","IEEE","IEEE Early Access Articles"
"The Good, the Bad and the Ugly: A Study of Security Decisions in a Cyber-Physical Systems Game","S. Frey; A. Rashid; P. Anthonysamy; M. Pinto-Albuquerque; S. A. Naqvi","University of Southampton, Southampton, United Kingdom; University of Bristol, Bristol, United Kingdom; Google, Zurich, CH, Switzerland; Instituto Universita rio de Lisboa (ISCTE-IUL), Lisboa, Portugal; Lancaster University, Lancaster, United Kingdom","IEEE Transactions on Software Engineering","14 May 2019","2019","45","5","521","536","Stakeholders' security decisions play a fundamental role in determining security requirements, yet, little is currently understood about how different stakeholder groups within an organisation approach security and the drivers and tacit biases underpinning their decisions. We studied and contrasted the security decisions of three demographics-security experts, computer scientists and managers-when playing a tabletop game that we designed and developed. The game tasks players with managing the security of a cyber-physical environment while facing various threats. Analysis of 12 groups of players (4 groups in each of our demographics) reveals strategies that repeat in particular demographics, e.g., managers and security experts generally favoring technological solutions over personnel training, which computer scientists preferred. Surprisingly, security experts were not ipso facto better players-in some cases, they made very questionable decisions-yet they showed a higher level of confidence in themselves. We classified players' decision-making processes, i.e., procedure-, experience-, scenario- or intuition-driven. We identified decision patterns, both good practices and typical errors and pitfalls. Our game provides a requirements sandbox in which players can experiment with security risks, learn about decision-making and its consequences, and reflect on their own perception of security.","1939-3520","","10.1109/TSE.2017.2782813","UK Engineering and Physical Science Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8194898","Security decisions;security requirements;game;decision patterns","Games;Data security;Cyber-physical systems;Decision making","computer games;cyber-physical systems;decision making;security of data","cyber-physical systems game;tabletop game;cyber-physical environment;decision patterns;security risks;decision-making","","1","","29","CCBY","13 Dec 2017","","","IEEE","IEEE Journals"
"Automatic Detection and Repair Recommendation of Directive Defects in Java API Documentation","Y. Zhou; C. Wang; X. Yan; T. Chen; S. Panichella; H. Gall","College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; College of Computer Science and Technology, Nanjing University of Aeronautics and Astronautics, Nanjing, China; Department of Computer Science and Information Systems, Birkbeck, University of London, Bloomsbury, London, United Kingdom; Department of Informatics, Zurich University of Applied Science, Winterthur, Switzerland; Department of Informatics, University of Zurich, Zurich, Switzerland","IEEE Transactions on Software Engineering","17 Sep 2020","2020","46","9","1004","1023","Application Programming Interfaces (APIs) represent key tools for software developers to build complex software systems. However, several studies have revealed that even major API providers tend to have incomplete or inconsistent API documentation. This can severely hamper the API comprehension and, as a consequence, the quality of the software built on them. In this paper, we propose DRONE (Detect and Repair of dOcumentatioN dEfects), a framework to automatically detect and repair defects from API documents by leveraging techniques from program analysis, natural language processing, and constraint solving. Specifically, we target at the directives of API documents, which are related to parameter constraints and exception handling declarations. Furthermore, in presence of defects, we also provide a prototypical repair recommendation system. We evaluate our approach on parts of the well-documented APIs of JDK 1.8 APIs (including javaFX) and Android 7.0 (level 24). Across the two empirical studies, our approach can detect API defects with an average F-measure of 79.9, 71.7, and 81.4 percent, respectively. The API repairing capability has also been evaluated on the generated recommendations in a further experiment. User judgments indicate that the constraint information is addressed correctly and concisely in the rendered directives.","1939-3520","","10.1109/TSE.2018.2872971","National Key R&D Program of China; Collaborative Innovation Center of Novel Software Technology in China; UK EPSRC; ARC Discovery Project; National Natural Science Foundation of China; Schweizerischer Nationalfonds zur Förderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8478004","API documentation;directive defects;natural language processing;repair recommendation","Documentation;Maintenance engineering;Software;Drones;Androids;Humanoid robots;Facebook","Android (operating system);application program interfaces;Java;natural language processing;software libraries;system documentation","application programming interfaces;software developers;complex software systems;API providers;incomplete API documentation;inconsistent API documentation;API comprehension;repair defects;API documents;program analysis;prototypical repair recommendation system;API repairing capability;automatic detection;directive defects;java API documentation;API defects;documentation defects;JDK 1.8 API;javaFX;Android 7.0","","","","72","IEEE","30 Sep 2018","","","IEEE","IEEE Journals"
"Understanding and Detecting Fragmentation-Induced Compatibility Issues for Android Apps","L. Wei; Y. Liu; S. -C. Cheung; H. Huang; X. Lu; X. Liu","Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Shenzhen Key Laboratory of Computational Intelligence, Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, China; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Department of Computer Science and Engineering, The Hong Kong University of Science and Technology, Clear Water Bay, Kowloon, Hong Kong; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China; Key Laboratory of High Confidence Software Technologies, Peking University, Ministry of Education, Beijing, China","IEEE Transactions on Software Engineering","11 Nov 2020","2020","46","11","1176","1199","Android ecosystem is heavily fragmented. The numerous combinations of different device models and operating system versions make it impossible for Android app developers to exhaustively test their apps, and thus various compatibility issues arise. Unfortunately, little is known on the characteristics of such fragmentation-induced compatibility issues. No mature tools exist to help developers quickly diagnose and fix these issues. To bridge the gap, we conducted an empirical study on 220 real-world compatibility issues collected from five popular open-source Android apps. We further interviewed Android practitioners and conducted an online survey to gain insights from real practices. Via the studies, we characterized compatibility issues, investigated common practices to handle compatibility issues, and disclosed that these issues exhibit common patterns. With these findings, we propose a technique, FicFinder, to automatically detect compatibility issues in Android apps. FicFinder performs static code analysis based on a model that captures Android APIs as well as their associated context by which compatibility issues can be triggered. FicFinder reports actionable debugging information to developers when it detects potential issues. We evaluated FicFinder with 53 large-scale open-source Android apps. The results show that FicFinder can precisely detect compatibility issues in these apps and uncover previously-unknown issues.","1939-3520","","10.1109/TSE.2018.2876439","Hong Kong RGC/GRF; National Natural Science Foundation of China; Science and Technology Innovation Committee Foundation of Shenzhen; MSRA collaborative research fund; Hong Kong PhD Fellowship Scheme; Nvidia; Google; MSRA; National Key R&D Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493348","Mobile applications;android applications;android fragmentation;compatibility issues;empirical study;program analysis","Androids;Humanoid robots;Biological system modeling;Smart phones;Hardware;Testing;Ecosystems","Android (operating system);application program interfaces;mobile computing;program debugging;program diagnostics;smart phones","large-scale open-source Android apps;Android app developers;fragmentation-induced compatibility issues;FicFinder technique","","7","","106","IEEE","16 Oct 2018","","","IEEE","IEEE Journals"
"A Systematic Evaluation of Static API-Misuse Detectors","S. Amann; H. A. Nguyen; S. Nadi; T. N. Nguyen; M. Mezini","Technische Universität Darmstadt, Darmstadt, Germany; Iowa State University, Ames, IA, USA; University of Alberta, Edmonton, AB, Canada; University of Texas-Dallas, Richardson, TX, USA; Technische Universität Darmstadt, Darmstadt, Germany","IEEE Transactions on Software Engineering","10 Dec 2019","2019","45","12","1170","1188","Application Programming Interfaces (APIs) often have usage constraints, such as restrictions on call order or call conditions. API misuses, i.e., violations of these constraints, may lead to software crashes, bugs, and vulnerabilities. Though researchers developed many API-misuse detectors over the last two decades, recent studies show that API misuses are still prevalent. Therefore, we need to understand the capabilities and limitations of existing detectors in order to advance the state of the art. In this paper, we present the first-ever qualitative and quantitative evaluation that compares static API-misuse detectors along the same dimensions, and with original author validation. To accomplish this, we develop MUC, a classification of API misuses, and MUBENCHPIPE, an automated benchmark for detector comparison, on top of our misuse dataset, MUBENCH. Our results show that the capabilities of existing detectors vary greatly and that existing detectors, though capable of detecting misuses, suffer from extremely low precision and recall. A systematic root-cause analysis reveals that, most importantly, detectors need to go beyond the naive assumption that a deviation from the most-frequent usage corresponds to a misuse and need to obtain additional usage examples to train their models. We present possible directions towards more-powerful API-misuse detectors.","1939-3520","","10.1109/TSE.2018.2827384","German Federal Ministry of Education and Research; Hessen State Ministry for Higher Education, Research and the Arts; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8338426","API-misuse detection;survey;misuse classification;benchmark;MUBench","Detectors;Benchmark testing;Classification;Systematics;Computer bugs","application program interfaces;failure analysis;program diagnostics;security of data","static API-misuse detectors;misuse dataset;MUBENCHPIPE benchmark;systematic root-cause analysis;MUBENCH dataset","","12","","53","IEEE","16 Apr 2018","","","IEEE","IEEE Journals"
"Exploiting Natural Language Structures in Software Informal Documentation","A. Di Sorbo; S. Panichella; C. A. Visaggio; M. Di Penta; G. Canfora; H. C. Gall","Department of Engineering, Universita degli Studi del Sannio, 18952 Benevento, Benevento Italy (e-mail: disorbo@unisannio.it); Department of Engineering, Zurcher Hochschule fur Angewandte Wissenschaften, 30944 Winterthur, Obere Kirchgasse 2 Switzerland (e-mail: spanichella@gmail.com); Research Centre on Software Technology, Univeristy of Sannio, Benevento, Italy Italy 82100 (e-mail: visaggio@unisannio.it); Dept. of Engineering, University of Sannio, Benevento, _ Italy 82100 (e-mail: dipenta@unisannio.it); Dept. of Engineering, University of Sannio, Benevento, BN Italy (e-mail: canfora@unisannio.it); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: gall@ifi.uzh.ch)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Communication means, such as issue trackers, mailing lists, Q&A forums, and app reviews, are premier means of collaboration among developers, and between developers and end-users. Analyzing such sources of information is crucial to build recommenders for developers, for example suggesting experts, re-documenting source code, or transforming user feedback in maintenance and evolution strategies for developers. To ease this analysis, in previous work we proposed DECA (Development Emails Content Analyzer), a tool based on Natural Language Parsing that classifies with high precision development emails' fragments according to their purpose. However, DECA has to be trained through a manual tagging of relevant patterns, which is often effort-intensive, error-prone and requires specific expertise in natural language parsing. In this paper, we first show, with a study involving Master's and Ph.D. students, the extent to which producing rules for identifying such patterns requires effort, depending on the nature and complexity of patterns. Then, we propose an approach, named NEON (Nlp-based softwarE dOcumentation aNalyzer), that automatically mines such rules, minimizing the manual effort. We assess the performances of NEON in the analysis and classification of mobile app reviews, developers discussions, and issues. NEON simplifies the patterns' identification and rules' definition processes, allowing a savings of more than 70% of the time otherwise spent on performing such activities manually. Results also show that NEON-generated rules are close to the manually identified ones, achieving comparable recall.","1939-3520","","10.1109/TSE.2019.2930519","Schweizerischer Nationalfonds zur Furderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8769918","Mining Unstructured Data;Natural Language Processing;Empirical Study","Neon;Software;Linguistics;Pattern recognition;Documentation;Manuals","","","","","","","","23 Jul 2019","","","IEEE","IEEE Early Access Articles"
"Automatic Repair of Timestamp Comparisons","G. Liva; M. T. Khan; M. Pinzger; F. Spegni; L. Spalazzi","Institute of Informatics Systems, Alpen-Adria-Universitat Klagenfurt, 27256 Klagenfurt, Carinthia Austria (e-mail: giovanni.liva@aau.at); Computing and Information Systems, University of Greenwich, 4918 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: m.t.khan@surrey.ac.uk); Institute of Informatics Systems, Alpen-Adria-Universitat Klagenfurt, 27256 Klagenfurt, Carinthia Austria (e-mail: martin.pinzger@aau.at); Ingegneria dell'Informazione, Universita Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: f.spegni@univpm.it); Ingegneria dell'Informazione, Universita Politecnica delle Marche, 9294 Ancona, Marche Italy (e-mail: l.spalazzi@univpm.it)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Automated program repair has the potential to reduce the developers' effort to fix errors in their code. In particular, modern programming languages, such as Java, C, and C\#, represent time as integer variables that suffer from integer overflow, introducing subtle errors that are hard to discover and repair. Recent researches on automated program repair rely on test cases to discover failures to correct, making them suitable only for regression errors. We propose a new strategy to automatically repair programs that suffer from timestamp overflows that are manifested in comparison expressions. It unifies the benefits of static analysis and automatic program repair avoiding dependency on testing to identify and correct defected code. Our approach performs an abstract analysis over the time domain of a program using a Time Type System to identify the problematic comparison expressions. The repairing strategy rewrites the timestamp comparisons exploiting the binary representation of machine numbers to correct the code. We have validated the applicability of our approach with 20 open source Java projects. The results show that it is able to correctly repair all 246 identified errors. To further validate the reliability of our approach, we have proved the soundness of both, type system and repairing strategy. Furthermore, several patches for three open source projects have been acknowledged and accepted by their developers.","1939-3520","","10.1109/TSE.2019.2948351","Osterreichische Forschungsforderungsgesellschaft; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8877769","Software/Program Verification;Formal methods;Error handling and recovery","Maintenance engineering;Java;Semantics;Static analysis;Software;Testing","","","","","","","","21 Oct 2019","","","IEEE","IEEE Early Access Articles"
"A Longitudinal Study of Application Structure and Behaviors in Android","H. Cai; B. G. Ryder","School of Electrical Engineering and Computer Science, Washington State University, 6760 Pullman, Washington United States (e-mail: chapering@gmail.com); Computer Science, Virginia Polytechnic Institute and State University, 1757 Blacksburg, Virginia United States (e-mail: ryder@cs.vt.edu)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","With the rise of the mobile computing market, Android has received tremendous attention from both academia and industry. Application programming in Android is known to have unique characteristics, and Android apps be particularly vulnerable to various security attacks. In response, numerous solutions for particular security issues have been proposed. However, there is little broad understanding about Android app code structure and behaviors along with their implications for app analysis and security defense, especially in an evolutionary perspective. To mitigate this gap, we present a longitudinal characterization study of Android apps to systematically investigate how they are built and execute over time. Through lightweight static analysis and method-level tracing, we examined the code and execution of 17,664 apps sampled from the apps developed in each of eight past years, with respect to metrics in three complementary dimensions. Our study revealed that (1) apps functionalities heavily rely on the Android framework/SDK, and the reliance continues to grow, (2) Activity components constantly dominated over other types of components and were responsible for the invocation of most lifecycle callbacks, (3) event-handling callbacks consistently focused more on user-interface events than system events, (4) the overall use of callbacks has been slowly diminishing over time, (5) the majority of exercised inter-component communications (ICCs) did not carry any data payloads, and (6) sensitive data sources and sinks targeted only one/two dominant categories of information or operations, and the ranking of source/sink categories remained quite stable throughout the eight years. We discuss the implications of our empirical findings for cost-effective app analysis and security defense for Android, and make cost-effectiveness improvement recommendations accordingly.","1939-3520","","10.1109/TSE.2020.2975176","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003217","Android;code structure;app behavior;longitudinal study;evolution;app analysis;security;ICC","Androids;Humanoid robots;Security;Runtime;Measurement;Libraries;Lenses","","","","2","","","","19 Feb 2020","","","IEEE","IEEE Early Access Articles"
"Enabling Good Work Habits in Software Developers through Reflective Goal-Setting","A. N. Meyer; G. C. Murphy; T. Zimmermann; T. Fritz","Department of Informatics, University of Zurich, Zurich, ZH Switzerland 8050 (e-mail: ameyer@ifi.uzh.ch); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca); Research, Microsoft Corporation, Redmond, Washington United States 98052 (e-mail: tzimmer@microsoft.com); Department of Informatics, University of Zurich, Zurich, Zurich Switzerland 8050 (e-mail: fritz@ifi.uzh.ch)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Software developers are generally interested in developing better habits to increase their workplace productivity and well-being, but have difficulties identifying concrete goals and actionable strategies to do so. In several areas of life, such as the physical activity and health domain, self-reflection has been shown to be successful at increasing people's awareness about a problematic behavior, motivating them to define a self-improvement goal, and fostering goal-achievement. We therefore designed a reflective goal-setting study to learn more about developers' goals and strategies to improve or maintain good habits at work. In our study, 52 professional software developers self-reflected about their work on a daily basis during two to three weeks, which resulted in a rich set of work habit goals and actionable strategies that developers pursue at work. We also found that purposeful, continuous self-reflection not only increases developers' awareness about productive and unproductive work habits (84.5%), but also leads to positive self-improvements that increase developer productivity and well-being (79.6%). We discuss how tools could support developers with a better trade-off between the cost and value of workplace self-reflection and increase long-term engagement.","1939-3520","","10.1109/TSE.2019.2938525","Schweizerischer Nationalfonds zur Furderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8823032","Productivity;Work Habits;Goals;Self-Reflection;Reflective Goal-Setting;Personal Analytics;Workplace Awareness","Productivity;Software;Employment;Task analysis;Tools;Informatics;Monitoring","","","","2","","","","3 Sep 2019","","","IEEE","IEEE Early Access Articles"
"Restore: Retrospective Fault Localization Enhancing Automated Program Repair","T. Xu; L. Chen; Y. Pei; T. Zhang; M. Pan; C. A. Furia","State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: dz1633014@smail.nju.edu.cn); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: cslschen@comp.polyu.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong Hong Kong (e-mail: maximilian.pei@gmail.com); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: ztluck@nju.edu.cn); State Key Laboratory for Novel Software Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: mxp@nju.edu.cn); Computer Science and Engineering, Chalmers tekniska hogskola, 11248 Goteborg, Vastra Gotaland Sweden 412 96 (e-mail: furiac@usi.ch)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Fault localization is a crucial step of automated program repair, because accurately identifying program locations that are most closely implicated with a fault greatly affects the effectiveness of the patching process. An ideal fault localization technique would provide precise information while requiring moderate computational resources—to best support an efficient search for correct fixes. In contrast, most automated program repair tools use standard fault localization techniques—which are not tightly integrated with the overall program repair process, and hence deliver only subpar efficiency. In this paper, we present retrospective fault localization: a novel fault localization technique geared to the requirements of automated program repair. A key idea of retrospective fault localization is to reuse the outcome of failed patch validation to support mutation-based dynamic analysis—providing accurate fault localization information without incurring onerous computational costs. We implemented retrospective fault localization in a tool called RESTORE—based on the JAID Java program repair system. Experiments involving faults from the DEFECTS4J standard benchmark indicate that retrospective fault localization can boost automated program repair: RESTORE efficiently explores a large fix space, delivering state-of-the-art effectiveness (41 DEFECTS4J bugs correctly fixed, 8 of which no other automated repair tool for Java can fix) while simultaneously boosting performance (speedup over 3 compared to JAID). Retrospective fault localization is applicable to any automated program repair techniques that rely on fault localization and dynamic validation of patches.","1939-3520","","10.1109/TSE.2020.2987862","the Hong Kong Polytechnic University Internal Fund; Research Grants Council University Grants Committee; National Natural Science Foundation of China; Fundamental Research Research Funds for The Central Universities; Schweizerischer Nationalfonds zur Frderung der Wissenschaftlichen Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068412","","Maintenance engineering;Tools;Java;Computer bugs;Software;Standards;Electronic mail","","","","","","","","15 Apr 2020","","","IEEE","IEEE Early Access Articles"
"The impact of surface features on choice of (in)secure answers by Stackoverflow readers","D. van der Linden; E. Williams; J. Hallett; A. Rashid","Department of Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: djt.vanderlinden@gmail.com); School of Psychological Sciences, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: emma.williams@bristol.ac.uk); Department of Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: joseph.hallett@bristol.ac.uk); Department of Computer Science, University of Bristol, Bristol, Bristol United Kingdom of Great Britain and Northern Ireland (e-mail: awais.rashid@bristol.ac.uk)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Existing research has shown that developers will use StackOverflow to answer programming questions: but what draws them to one particular answer over any other? The choice of answer they select can mean the difference between a secure application and insecure one, as the quality of supposedly secure answers can vary. Prior work has studied people posting on Stack Overflow—a two-way communication between the original poster and the Stack Overflow community. Instead, we study the situation of one-way communication, where people only read a Stack Overflow thread without being actively involved in it, sometimes long after a thread has closed. We report on a mixed-method study including a controlled between-groups experiment and qualitative analysis of participants' rationale (N=1188), investigating whether explanation detail, answer scoring, accepted answer marks, as well as the security of the code snippet itself affect the answers participants accept. Our findings indicate that explanation detail affects what answers participants reading a thread select (p<0.01), while answer score and acceptance do not (p>0.05)—the inverse of what research has shown for those asking and answering questions. The qualitative analysis of participants' rationale further explains how several cognitive biases underpin these findings. Correspondence bias, in particular, plays an important role in instilling readers with a false sense of confidence in an answer through the way it looks, regardless of whether it works, is secure, or if the community agrees with it. As a result, we argue that StackOverflow's use as a knowledge base by people not actively involved in threads'when there is only one-way-communication—may inadvertently contribute to the spread of insecure code, as the community's voting mechanisms hold little power to deter them from answers.","1939-3520","","10.1109/TSE.2020.2981317","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9072521","Software Security;Stack Overflow;Human Factors;Rationale","Security;Semantics;Software;Documentation;Knowledge based systems;Message systems;Licenses","","","","","","","CCBY","20 Apr 2020","","","IEEE","IEEE Early Access Articles"
"Test Case Generation for Boolean Expressions by Cell Covering","L. Yu; W. Tsai","School of Software and Microelectronics in Peking University, Beijing, China; Beihang University, Beijing, China","IEEE Transactions on Software Engineering","10 Jan 2018","2018","44","1","70","99","This paper characterizes Boolean expression faults as changes of the topological structures in terms of shrinking and/or expanding regions in K-map. A cell-covering is a set of cells (test cases) in K-map to cover the fault regions such that faults guarantee to be detected. Minimizing cell covering can be formulated as an Integer Linear Programming (ILP) problem. By analyzing the structures of the constraint coefficient matrix, the original problem can be decomposed into sub-programs that can be solved instead of the original problem, and this significantly reduces the time needed for ILP execution. An efficient approximate algorithm with a tight theoretical bound is used to address those complex Boolean expressions by corresponding the cell-covering problem to the set-covering problem. The optimal approach and the approximate approach are combined into a hybrid process to identify test cases based on the fraction analysis on the ILP relaxation. The proposed approach is evaluated by three sets of Boolean expressions and the results are compared with three leading approaches with respect to test sizes, time consumption and fault detection capabilities. For most Boolean expressions encountered, the proposed approach obtains optimal solutions quickly, and produces near-optimal solutions rapidly for those rare and complex expressions.","1939-3520","","10.1109/TSE.2017.2669184","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7855791","Boolean expression testing;fault characterization;cell-covering problem;approximate algorithms","Fault detection;Approximation algorithms;Optimization;Periodic structures;Algorithm design and analysis;Testing;Software","approximation theory;Boolean functions;computational complexity;fault diagnosis;integer programming;linear programming;set theory","test case generation;Boolean expression faults;topological structures;cell-covering;complex Boolean expressions;set-covering problem;fault detection capabilities;complex expressions;integer linear programming problem;cell covering minimization","","1","","51","","14 Feb 2017","","","IEEE","IEEE Journals"
"The Impact of Changes Mislabeled by SZZ on Just-in-Time Defect Prediction","Y. Fan; X. Xia; D. Alencar da Costa; D. Lo; A. E. Hassan; S. Li","College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: yrfan@zju.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxkidd@zju.edu.cn); Information Science Department, University of Otago, 2495 Dunedin, Dunedin New Zealand (e-mail: daniel.calencar@gmail.com); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca); College of Computer Science and Technology, Zhejiang University, Hangzhou, Zhejiang China (e-mail: shan@zju.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Just-in-Time (JIT) defect prediction---a technique which aims to predict bugs at change level---has been paid more attention. JIT defect prediction leverages the SZZ approach to identify bug-introducing changes. Recently, researchers found that the performance of SZZ (including its variants) is impacted by many noises. SZZ may considerably mislabel changes that are used to train a JIT defect prediction model, and thus impact the prediction accuracy.","1939-3520","","10.1109/TSE.2019.2929761","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8765743","Just-in-Time Defect Prediction;SZZ;Noisy Data;Mining Software Repositories","Predictive models;Data models;Computer bugs;Measurement;Inspection;Analytical models;Testing","","","","3","","","","18 Jul 2019","","","IEEE","IEEE Early Access Articles"
"Inductive Validity Cores","E. Ghassabani; M. Whalen; A. Gacek; M. Heimdahl","Department of Computer Science & Engineering, University of Minnesota, MN, USA; Department of Computer Science & Engineering, University of Minnesota, MN, USA; Rockwell Collins, Advanced Technology Center, Cedar Rapids, IA, USA; Department of Computer Science & Engineering, University of Minnesota, MN, USA","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","279","299","Symbolic model checkers can construct proofs of properties over highly complex models. However, the results reported by the tool when a proof succeeds do not generally provide much insight to the user. It is often useful for users to have traceability information related to the proof: which portions of the model were necessary to construct it. This traceability information can be used to diagnose a variety of modeling problems such as overconstrained axioms and underconstrained properties, measure completeness of a set of requirements over a model, and assist with design optimization given a set of requirements for an existing or synthesized implementation. In this paper, we present a comprehensive treatment of a suite of algorithms to compute inductive validity cores (IVCs), minimal sets of model elements necessary to construct inductive proofs of safety properties for sequential systems. The algorithms are based on the UNSAT core support built into current SMT solvers and novel encodings of the inductive problem to generate approximate and guaranteed minimal inductive validity cores as well as all inductive validity cores. We demonstrate that our algorithms are correct, describe their implementation in the JKind model checker for Lustre models, and present several use cases for the algorithms. We then present a substantial experiment in which we benchmark the efficiency and efficacy of the algorithms.","1939-3520","","10.1109/TSE.2019.2891709","DARPA Systems of Systems Integration Technology and Experimentation; NASA Compositional Verification of Flight-Critical Systems; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8606278","Inductive validity cores;SMT-based model checking;requirements analysis;proof explanation","Computational modeling;Analytical models;Tools;Safety;Mathematical model;Approximation algorithms;Model checking","approximation theory;computability;encoding;formal verification;optimisation;program verification","modeling problems;underconstrained properties;minimal sets;model elements;inductive proofs;safety properties;UNSAT core support;inductive problem;minimal inductive validity cores;JKind model checker;Lustre models;symbolic model checkers;highly complex models;traceability information","","","","95","IEEE","9 Jan 2019","","","IEEE","IEEE Journals"
"Explaining Regressions via Alignment Slicing and Mending","H. Wang; Y. Lin; Z. Yang; J. Sun; Y. Liu; J. S. Dong; Q. Zheng; T. Liu","Ant Financial Services Group, Singapore, Singapore (e-mail: haijun.wang@ntu.edu.sg); School of Computing, National University of Singapore, Singapore, Singapore Singapore 520164 (e-mail: llmhyy@gmail.com); Computer Science, Western Michigan University, Kalamazoo, Michigan United States 49008 (e-mail: zijiang.yang@wmich.edu); School of Information System, Singapore Management University, 54756 Singapore, Singapore Singapore (e-mail: sunjun@sutd.edu.sg); School of Computer Engineering, Nanyang Technological University, Singapore, Singapore Singapore 639798 (e-mail: yangliu@ntu.edu.sg); CS, National University of Singapore, Singapore, S Singapore 117543 (e-mail: dongjs@comp.nus.edu.sg); computer science and technology, Xi'an Jiaotong University, Xi'an, Shaanxi China 710049 (e-mail: qhzheng@mail.xjtu.edu.cn); Control, System Engineering Institute, Xi'an, Shaanxi China 710049 (e-mail: tingliu@mail.xjtu.edu.cn)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Regression faults, which make working code stop functioning, are often introduced when developers make changes to the software. Many regression fault localization techniques have been proposed. However, issues like inaccuracy and lack of explanation are still obstacles for their practical application. In this work, we propose a trace-based approach to identifying not only where the root cause of a regression bug lies, but also how the defect is propagated to its manifestation as the explanation. In our approach, we keep the trace of original correct version as reference and infer the faulty steps on the trace of regression version so that we can build a causality graph of how the defect is propagated. To this end, we overcomes two technical challenges. First, we align two traces derived from two versions of programs by extending state-of-the-art trace alignment technique for regression fault with novel relaxation technique. Second, we construct causality graph (i.e., explanation) by adopting a technique called alignment slicing and mending to isolate the failure-inducing changes and explain the failure. Our comparative experiment with the state-of-the-art techniques including dynamic slicing, delta-debugging, and symbolic execution on 24 real-world regressions shows that (1) our approach is more accurate on isolating the failure-inducing changes, (2) the generated explanation requires acceptable manual effort to inspect, and (3) our approach requires lower runtime overhead. In addition, we also conduct an applicability experiment based on Defects4J bug repository, showing the potential limitations of our trace-based approach and providing guidance for its practical use.","1939-3520","","10.1109/TSE.2019.2949568","National Natural Science Foundation of China; the National Cybersecurity R D Directorate; the Singapore Ministry of Education Academic Research Fund Tier 2 Grant; National Key R D Program of China; Singapore Telecommunications Limited; the National Research Foundation Prime Ministers Office Singapore under its Corporate Laboratory University Scheme National University of Singapore and under its National Cybersecurity RD Program; the National Satellite of Excellence in Trustworthy Software Systems funded by NRF Singapore under National Cyber-security R D programme; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8883062","Regression bug;trace alignment;alignment slicing and mending;fault localization","Computer bugs;Semantics;Debugging;Java;Software;Runtime;Task analysis","","","","2","","","","25 Oct 2019","","","IEEE","IEEE Early Access Articles"
"An Empirical Study of Fault Localization Families and Their Combinations","D. Zou; J. Liang; Y. Xiong; M. D. Ernst; L. Zhang","School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China; Department of Computer Science & Engineering, University of Washington, Seattle, WA, USA; School of Electronics Engineering and Computer Science, Institute of Software, Peking University, Beijing, PR China","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","332","347","The performance of fault localization techniques is critical to their adoption in practice. This paper reports on an empirical study of a wide range of fault localization techniques on real-world faults. Different from previous studies, this paper (1) considers a wide range of techniques from different families, (2) combines different techniques, and (3) considers the execution time of different techniques. Our results reveal that a combined technique significantly outperforms any individual technique (200 percent increase in faults localized in Top 1), suggesting that combination may be a desirable way to apply fault localization techniques and that future techniques should also be evaluated in the combined setting. Our implementation is publicly available for evaluating and combining fault localization techniques.","1939-3520","","10.1109/TSE.2019.2892102","National Key Research and Development Program of China; National Natural Science Foundation of China; Air Force Research Laboratory; DARPA of the U.S.A.; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8607117","Fault localization;learning to rank;program debugging;software testing;empirical study","Switches;Debugging;Software;Fault diagnosis;Task analysis;Computer bugs;History","fault diagnosis;program debugging;program testing;software fault tolerance","software testing;program debugging;fault localization families","","26","","79","IEEE","10 Jan 2019","","","IEEE","IEEE Journals"
"Evolving JavaScript code to reduce load time","F. Farzat; M. O. Barros; G. H. Travassos","Computer Science, COPPE/UFRJ, Rio de Janeiro, RJ Brazil (e-mail: ffarzat@cos.ufrj.br); DIA, UNIRIO, Rio de Janeiro, Rio de Janeiro Brazil 22290-240 (e-mail: marcio.barros@uniriotec.br); Computer Science, COPPE/UFRJ, Rio de Janeiro, Rio de Janeiro Brazil 21942-970 (e-mail: ght@cos.ufrj.br)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","JavaScript is one of the most used programming languages for front-end development of Web applications. The increase in complexity of front-end features brings concerns about performance, especially the load and execution time of JavaScript code. In this paper, we propose an evolutionary program improvement technique to reduce the size of JavaScript programs and, therefore, the time required to load and execute them in Web applications. To guide the development of such technique, we performed an experimental study to characterize the patches applied to JavaScript programs to reduce their size while keeping the functionality required to pass all test cases in their test suites. We applied this technique to 19 JavaScript programs varying from 92 to 15,602 LOC and observed reductions from 0.2% to 73.8% of the original code, as well as a relationship between the quality of a program's test suite and the ability to reduce the size of its source code.","1939-3520","","10.1109/TSE.2019.2928293","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8762190","JavaScript;source code improvement;genetic programming;local search","Software;Syntactics;Genetic programming;Software algorithms;Heuristic algorithms;Libraries;Runtime","","","","1","","","","15 Jul 2019","","","IEEE","IEEE Early Access Articles"
"Ensuring the Observability of Structural Test Obligations","Y. Meng; G. Gay; M. Whalen","Department of Computer Science & Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science & Engineering, University of South Carolina, Columbia, SC, USA; Department of Computer Science and Engineering, University of Minnesota, Minneapolis, MN, USA","IEEE Transactions on Software Engineering","15 Jul 2020","2020","46","7","748","772","Test adequacy criteria are widely used to guide test creation. However, many of these criteria are sensitive to statement structure or the choice of test oracle. This is because such criteria ensure that execution reaches the element of interest, but impose no constraints on the execution path after this point. We are not guaranteed to observe a failure just because a fault is triggered. To address this issue, we have proposed the concept of observability-an extension to coverage criteria based on Boolean expressions that combines the obligations of a host criterion with an additional path condition that increases the likelihood that a fault encountered will propagate to a monitored variable. Our study, conducted over five industrial systems and an additional forty open-source systems, has revealed that adding observability tends to improve efficacy over satisfaction of the traditional criteria, with average improvements of 125.98 percent in mutation detection with the common output-only test oracle and per-model improvements of up to 1760.52 percent. Ultimately, there is merit to our hypothesis-observability reduces sensitivity to the choice of oracle and to the program structure.","1939-3520","","10.1109/TSE.2018.2869146","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8456606","Software testing;automated test generation;test adequacy criteria;model-based test generation","Observability;Test pattern generators;Monitoring;Sensitivity;Software;Complexity theory","program testing;public domain software","structural test obligations;test adequacy criteria;test creation;statement structure;execution path;observability;coverage criteria;Boolean expressions;host criterion;path condition;industrial systems;program structure;open-source systems;mutation detection;onput-only test oracle","","","","77","IEEE","6 Sep 2018","","","IEEE","IEEE Journals"
"IntRepair: Informed Repairing of Integer Overflows","P. Muntean; M. Monperrus; H. Sun; J. Grossklags; C. Eckert","Department of Informatics, Technical University of Munich, 85748 Garching near Munich, Bavaria, Germany (e-mail: paul.muntean@sec.in.tum.de); Department of Computer Science, KTH Royal Institute of Technology, Sweden, 10044 Stockholm, Sweden (e-mail: martin.monperrus@csc.kth.se); Department of Computer Science and Technology, Nanjing University, Xianlin Campus Mailbox 603, Nanjing 210023, China (email: shqking@gmail.com); Department of Informatics, Technical University of Munich, 85748 Garching near Munich, Bavaria, Germany (e-mail: jens.grossklags@in.tum.de); Department of Informatics, Technical University of Munich, 85748 Garching near Munich, Bavaria, Germany (e-mail: claudia.eckert@sec.in.tum.de)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Integer overflows have threatened software applications for decades. Thus, in this paper, we propose a novel technique to provide automatic repairs of integer overflows in C source code. Our technique, based on static symbolic execution, fuses detection, repair generation and validation. This technique is implemented in a prototype named IntRepair. We applied IntRepair to 2,052 C programs (approx. 1 million lines of code) contained in SAMATE's Juliet test suite and 50 synthesized programs that range up to 20 KLOC. Our experimental results show that IntRepair is able to effectively detect integer overflows and successfully repair them, while only increasing the source code (LOC) and binary (Kb) size by around 1%, respectively. Furthermore, we present the results of a user study with 30 participants showing that IntRepair repairs are more efficient than manual repairs.","1939-3520","","10.1109/TSE.2019.2946148","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862860","Program repair;source code refactoring;integer overflow;software bug;symbolic execution;static program analysis","Maintenance engineering;Software;Tools;Fault detection;Runtime;Engines;Fuses","","","","1","","","","8 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Generic Adaptive Scheduling for Efficient Context Inconsistency Detection","H. Wang; C. Xu; B. Guo; X. Ma; J. Lu","State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China; State Key Laboratory for Novel Software Technology and the Department of Computer Science and Technology, Nanjing University, Nanjing, Jiangsu, China","IEEE Transactions on Software Engineering","15 Mar 2021","2021","47","3","464","497","Many applications use contexts to understand their environments and make adaptation. However, contexts are often inaccurate or even conflicting with each other (a.k.a. context inconsistency). To prevent applications from behaving abnormally or even failing, one promising approach is to deploy constraint checking to detect context inconsistencies. A variety of constraint checking techniques have been proposed, based on different incremental or parallel mechanisms for the efficiency. They are commonly deployed with the strategy that schedules constraint checking immediately upon context changes. This assures no missed inconsistency, but also limits the detection efficiency. One may break the limit by grouping context changes for checking together, but this can cause severe inconsistency missing problem (up to 79.2 percent). In this article, we propose a novel strategy GEAS to isolate latent interferences among context changes and schedule constraint checking with adaptive group sizes. This makes GEAS not only improve the detection efficiency, but also assure no missed inconsistency with theoretical guarantee. We experimentally evaluated GEAS with large-volume real-world context data. The results show that GEAS achieved significant efficiency gains for context inconsistency detection by 38.8-566.7 percent (or 1.4x-6.7x). When enhanced with an extended change-cancellation optimization, the gains were up to 2,755.9 percent (or 28.6x).","1939-3520","","10.1109/TSE.2019.2898976","National Key Research and Development Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8640044","Context inconsistency detection;consistency constraint;scheduling strategy;susceptibility/cancellation condition","Unified modeling language;Software;Public transportation;Schedules;Adaptive scheduling;XML","optimisation;scheduling;ubiquitous computing","inconsistency missing problem;context inconsistency detection;adaptive group;schedule constraint checking;parallel mechanisms;different incremental mechanisms;constraint checking techniques;generic adaptive scheduling;real-world context data;GEAS","","1","","75","IEEE","12 Feb 2019","","","IEEE","IEEE Journals"
"Understanding How and Why Developers Seek and Analyze API-Related Opinions","G. Uddin; O. Baysal; L. Guerrouj; F. Khomh","Bank of Canada, Ottawa, ON, Canada; School of Computer Science, Carleton University, Ottawa, ON, Canada; Département LOG et TI, École de Technologie Supérieure, Montreal, QC, Canada; SWAT Lab, Polytechnique Montreal, Montreal, QC, Canada","IEEE Transactions on Software Engineering","16 Apr 2021","2021","47","4","694","735","With the advent and proliferation of online developer forums as informal documentation, developers often share their opinions about the APIs they use. Thus, opinions of others often shape the developer’s perception and decisions related to software development. For example, the choice of an API or how to reuse the functionality the API offers are, to a considerable degree, conditioned upon what other developers think about the API. While many developers refer to and rely on such opinion-rich information about APIs, we found little research that investigates the use and benefits of public opinions. To understand how developers seek and evaluate API opinions, we conducted two surveys involving a total of 178 software developers. We analyzed the data in two dimensions, each corresponding to specific needs related to API reviews: (1) Needs for seeking API reviews, and (2) Needs for automated tool support to assess the reviews. We observed that developers seek API reviews and often have to summarize those for diverse development needs (e.g., API suitability). Developers also make conscious efforts to judge the trustworthiness of the provided opinions and believe that automated tool support for API reviews analysis can assist in diverse development scenarios, including, for example, saving time in API selection as well as making informed decisions on a particular API features.","1939-3520","","10.1109/TSE.2019.2903039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8658125","Opinion mining;API informal documentation;opinion summaries;survey;opinion quality;developer’s perception","Tools;Documentation;Task analysis;Java;Data mining;Open source software","","","","1","","113","IEEE","4 Mar 2019","","","IEEE","IEEE Journals"
"Architecture Anti-Patterns: Automatically Detectable Violations of Design Principles","R. Mo; Y. Cai; R. Kazman; L. Xiao; Q. Feng","Computer Science, Central China Normal University, Wuhan, Hubei, China; Computer Science, Drexel University, Philadelphia, PA, USA; Department of Information Technology Management, University of Hawaii, Honolulu, Hawaii, USA; School of Systems and Enterprises, Stevens Institute of Technology, Hoboken, NJ, USA; Computer Science, Drexel University, Philadelphia, PA, USA","IEEE Transactions on Software Engineering","13 May 2021","2021","47","5","1008","1028","In large-scale software systems, error-prone or change-prone files rarely stand alone. They are typically architecturally connected and their connections usually exhibit architecture problems causing the propagation of error-proneness or change-proneness. In this paper, we propose and empirically validate a suite of architecture anti-patterns that occur in all large-scale software systems and are involved in high maintenance costs. We define these architecture anti-patterns based on fundamental design principles and Baldwin and Clark’s design rule theory. We can automatically detect these anti-patterns by analyzing a project’s structural relationships and revision history. Through our analyses of 19 large-scale software projects, we demonstrate that these architecture anti-patterns have significant impact on files’ bug-proneness and change-proneness. In particular, we show that 1) files involved in these architecture anti-patterns are more error-prone and change-prone; 2) the more anti-patterns a file is involved in, the more error-prone and change-prone it is; and 3) while all of our defined architecture anti-patterns contribute to file’s error-proneness and change-proneness, Unstable Interface and Crossing contribute the most by far.","1939-3520","","10.1109/TSE.2019.2910856","National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8691586","Software architecture;software maintenance;software quality","Computer architecture;Maintenance engineering;History;Software systems;Tools;Observers;Java","","","","5","","81","IEEE","14 Apr 2019","","","IEEE","IEEE Journals"
"ElementRank: Ranking Java Software Classes and Packages using a Multilayer Complex Network-Based Approach","W. Pan; H. Ming; C. Chang; Z. Yang; D. Kim","Computer Science and Information Engineering, Zhejiang Gongshang University, 12625 Hangzhou, Zhejiang China (e-mail: wfpan@zjgsu.edu.cn); Computer Science and Engineering, Oakland University, 6918 Rochester, Michigan United States 48309-4479 (e-mail: ming@oakland.edu); Computer Science, IOWA STATE UNIVERSITY, Ames, Iowa United States 50011 (e-mail: chang@iastate.edu); Computer Science, Western Michigan University, Kalamazoo, Michigan United States 49008 (e-mail: zijiang.yang@wmich.edu); Computer Science and Engineering, Oakland University, Rochester, Michigan United States 48309 (e-mail: kim2@oakland.edu)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Software comprehension is an important part of software maintenance. To understand a piece of large and complex software, the first problem to be solved is where to start the understanding process. Choosing to start the comprehension process from the important software elements has proven to be a practical way. Research on complex networks opens new opportunities for identifying important elements, and many approaches have been proposed. However, the software networks that existing approaches use neglect the multilayer nature of software systems. That is, nodes in the network can have different types of relationships at the same time, and each type of relationship forms a specific layer. Worse still, they mainly focus on identifying important classes, and little work has been done on quantifying package importance. In this paper, we propose an ElementRank approach to provide a ranked list of classes (or packages) for maintainers to start the comprehension process. The top-ranked classes (or packages) can be seen as the starting points for the software comprehension process at the class (or package) level. First, we introduce two kinds of multilayer software networks to describe the topological structure of software at the class level and package level, respectively. Second, we propose a weighted PageRank algorithm to calculate the weighted PageRank value of classes (or packages) in each layer of the corresponding multilayer software network. Then, we use AHP (Analytic Hierarchy Process) to weigh each layer in the corresponding multilayer software network, and further aggregate the weighted PageRank value to obtain the global weighted PageRank value for each class (or package). Finally, all the classes (or packages) are ranked according to their global weighted PageRank values in a descending order, and the top-ranked classes (or packages) can serve as the starting points for the software comprehension process at the class (or package) level. ElementRank is validated theoretically using the widely accepted Weyuker's criteria. Theoretical results show that the global weighted PageRank value for classes (or packages) satisfies most of Weyuker's properties. Furthermore, ElementRank is evaluated empirically using a set of twelve open source software systems. Through a set of experiments, we show the rank correlation between the results of ElementRank and that of the approaches in the related work, and the benefits of ElementRank are also illustrated in comparison with other approaches in the related work. Empirical results also show that ElementRank can be applied to large software systems.","1939-3520","","10.1109/TSE.2019.2946357","the Commonweal Project of Science and Technology Department of Zhejiang Province; National Key RD Program of China; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8862895","Important software elements;weighted PageRank algorithm;complex network;software comprehension;static analysis","Software systems;Nonhomogeneous media;Complex networks;Maintenance engineering;Measurement;Computer science","","","","5","","","","8 Oct 2019","","","IEEE","IEEE Early Access Articles"
"Use and Misuse of Continuous Integration Features: An Empirical Study of Projects That (Mis)Use Travis CI","K. Gallaba; S. McIntosh","Department of Electrical and Computer Engineering, McGill University, Montreal, Quebec, Canada; Department of Electrical and Computer Engineering, McGill University, Montreal, Quebec, Canada","IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","33","50","Continuous Integration (CI) is a popular practice where software systems are automatically compiled and tested as changes appear in the version control system of a project. Like other software artifacts, CI specifications require maintenance effort. Although there are several service providers like TRAVIS CI offering various CI features, it is unclear which features are being (mis)used. In this paper, we present a study of feature use and misuse in 9,312 open source systems that use TRAVIS CI. Analysis of the features that are adopted by projects reveals that explicit deployment code is rare-48.16 percent of the studied TRAVIS CI specification code is instead associated with configuring job processing nodes. To analyze feature misuse, we propose HANSEL-an anti-pattern detection tool for TRAVIS CI specifications. We define four anti-patterns and HANSEL detects anti-patterns in the TRAVIS CI specifications of 894 projects in the corpus (9.60 percent), and achieves a recall of 82.76 percent in a sample of 100 projects. Furthermore, we propose GRETEL-an anti-pattern removal tool for TRAVIS CI specifications, which can remove 69.60 percent of the most frequently occurring antipattern automatically. Using GRETEL, we have produced 36 accepted pull requests that remove TRAVIS CI anti-patterns automatically.","1939-3520","","10.1109/TSE.2018.2838131","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8360943","Continuous integration;anti-patterns;mining software repositories","Object oriented programming;Software development management;Software maintenance;Software quality;Software performance","object-oriented programming;program testing;software development management;software maintenance;software metrics;software performance evaluation;software quality","continuous Integration features;software systems;version control system;CI features;studied TRAVIS CI specification code;anti-pattern detection tool;CI anti-patterns;open source systems;efficiency 48.16 percent;efficiency 9.6 percent;efficiency 69.6 percent","","8","","32","IEEE","18 May 2018","","","IEEE","IEEE Journals"
"Automatic Software Refactoring via Weighted Clustering in Method-Level Networks","Y. Wang; H. Yu; Z. Zhu; W. Zhang; Y. Zhao","Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China; Software College, Northeastern University, Shenyang, China","IEEE Transactions on Software Engineering","13 Mar 2018","2018","44","3","202","236","In this study, we describe a system-level multiple refactoring algorithm, which can identify the move method, move field, and extract class refactoring opportunities automatically according to the principle of “high cohesion and low coupling.” The algorithm works by merging and splitting related classes to obtain the optimal functionality distribution from the system-level. Furthermore, we present a weighted clustering algorithm for regrouping the entities in a system based on merged method-level networks. Using a series of preprocessing steps and preconditions, the “bad smells” introduced by cohesion and coupling problems can be removed from both the non-inheritance and inheritance hierarchies without changing the code behaviors. We rank the refactoring suggestions based on the anticipated benefits that they bring to the system. Based on comparisons with related research and assessing the refactoring results using quality metrics and empirical evaluation, we show that the proposed approach performs well in different systems and is beneficial from the perspective of the original developers. Finally, an open source tool is implemented to support the proposed approach.","1939-3520","","10.1109/TSE.2017.2679752","National Natural Science Foundation of China; MOE research center for online education, China; Ph.D. Start-up Foundation of Liaoning Province, China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7874207","Clustering analysis;cohesion;coupling;complex network;software refactoring","Couplings;Clustering algorithms;Software algorithms;Measurement;Software systems;Partitioning algorithms","network theory (graphs);pattern clustering;software maintenance;software quality","high cohesion;low coupling;merging classes;splitting related classes;optimal functionality distribution;weighted clustering algorithm;merged method-level networks;preprocessing steps;coupling problems;inheritance hierarchies;refactoring suggestions;refactoring results;automatic software refactoring;system-level multiple refactoring algorithm;class refactoring opportunities;open source tool","","3","","52","","8 Mar 2017","","","IEEE","IEEE Journals"
"Changeset-Based Topic Modeling of Software Repositories","C. S. Corley; K. Damevski; N. A. Kraft","Department of Computer Science, University of Alabama, Tuscaloosa, AL, USA; Department of Computer Science, Virginia Commonwealth University, Richmond, VA, USA; ABB Corporate Research, Raleigh, NC, USA","IEEE Transactions on Software Engineering","14 Oct 2020","2020","46","10","1068","1080","The standard approach to applying text retrieval models to code repositories is to train models on documents representing program elements. However, code changes lead to model obsolescence and to the need to retrain the model from the latest snapshot. To address this, we previously introduced an approach that trains a model on documents representing changesets from a repository and demonstrated its feasibility for feature location. In this paper, we expand our work by investigating: a second task (developer identification), the effects of including different changeset parts in the model, the repository characteristics that affect the accuracy of our approach, and the effects of the time invariance assumption on evaluation results. Our results demonstrate that our approach is as accurate as the standard approach for projects with most changes localized to a subset of the code, but less accurate when changes are highly distributed throughout the code. Moreover, our results demonstrate that context and messages are key to the accuracy of changeset-based models and that the time invariance assumption has a statistically significant effect on evaluation results, providing overly-optimistic results. Our findings indicate that our approach is a suitable alternative to the standard approach, providing comparable accuracy while eliminating retraining costs.","1939-3520","","10.1109/TSE.2018.2874960","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8486696","Changesets;feature location;developer identification;program comprehension;mining software repositories;online topic modeling","Task analysis;Standards;Feature extraction;Resource management;Software maintenance;Maintenance engineering","information retrieval;software packages;source code (software);text analysis","changeset-based topic modeling;software repositories;text retrieval models;code repositories;program elements;code changes;time invariance assumption;changeset-based models","","","","56","IEEE","9 Oct 2018","","","IEEE","IEEE Journals"
"Towards Model Checking Android Applications","G. Bai; Q. Ye; Y. Wu; H. Botha; J. Sun; Y. Liu; J. S. Dong; W. Visser","Singapore Institute of Technology, Singapore; National University of Singapore, Singapore; Huawei; Stellenbosch University, Stellenbosch, South Africa; Singapore University of Technology and Design, Singapore; Nanyang Technological University, Singapore; National University of Singapore, Singapore; Stellenbosch University, Stellenbosch, South Africa","IEEE Transactions on Software Engineering","12 Jun 2018","2018","44","6","595","612","As feature-rich Android applications (apps for short) are increasingly popularized in security-sensitive scenarios, methods to verify their security properties are highly desirable. Existing approaches on verifying Android apps often have limited effectiveness. For instance, static analysis often suffers from a high false-positive rate, whereas approaches based on dynamic testing are limited in coverage. In this work, we propose an alternative approach, which is to apply the software model checking technique to verify Android apps. We have built a general framework named DroidPF upon Java PathFinder (JPF), towards model checking Android apps. In the framework, we craft an executable mock-up Android OS which enables JPF to dynamically explore the concrete state spaces of the tested apps; we construct programs to generate user interaction and environmental input so as to drive the dynamic execution of the apps; and we introduce Android specific reduction techniques to help alleviate the state space explosion. DroidPF focuses on common security vulnerabilities in Android apps including sensitive data leakage involving a non-trivial flow- and context-sensitive taint-style analysis. DroidPF has been evaluated with 131 apps, which include real-world apps, third-party libraries, malware samples and benchmarks for evaluating app analysis techniques like ours. DroidPF precisely identifies nearly all of the previously known security issues and nine previously unreported vulnerabilities/bugs.","1939-3520","","10.1109/TSE.2017.2697848","Singapore NRF; NRF; National Research Foundation, Prime Ministers Office, Singapore; National Cybersecurity R&D Program; National Cybersecurity R&D Directorate; National University of Singapore and Singapore University of Technology and Design; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7911333","Software model checking;security verification;android application","Androids;Humanoid robots;Model checking;Java;Security;Software;Libraries","Android (operating system);invasive software;Java;mobile computing;program diagnostics;program verification;public domain software","security properties;DroidPF;Android OS;tested apps;Android specific reduction techniques;context-sensitive taint-style analysis;real-world apps;app analysis techniques;feature-rich Android applications;security-sensitive scenarios;model checking;Android apps verification;Java PathFinder;concrete state spaces;user interaction;environmental input;dynamic execution;state space explosion;sensitive data leakage;nontrivial flow-style analysis;third-party libraries;malware samples","","5","","75","","25 Apr 2017","","","IEEE","IEEE Journals"
"An Empirical Study on API Usages","H. Zhong; H. Mei","Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China; Department of Computer Science and Engineering, Shanghai Jiao Tong University, Shanghai, China","IEEE Transactions on Software Engineering","16 Apr 2019","2019","45","4","319","334","API libraries provide thousands of APIs, and are essential in daily programming tasks. To understand their usages, it has long been a hot research topic to mine specifications that formally define legal usages for APIs. Furthermore, researchers are working on many other research topics on APIs. Although the research on APIs is intensively studied, many fundamental questions on APIs are still open. For example, the answers to open questions, such as which format can naturally define API usages and in which case, are still largely unknown. We notice that many such open questions are not concerned with concrete usages of specific APIs, but usages that describe how to use different types of APIs. To explore these questions, in this paper, we conduct an empirical study on API usages, with an emphasis on how different types of APIs are used. Our empirical results lead to nine findings on API usages. For example, we find that single-type usages are mostly strict orders, but multi-type usages are more complicated since they include both strict orders and partial orders. Based on these findings, for the research on APIs, we provide our suggestions on the four key aspects such as the challenges, the importance of different API elements, usage patterns, and pitfalls in designing evaluations. Furthermore, we interpret our findings, and present our insights on data sources, extraction techniques, mining techniques, and formats of specifications for the research of mining specifications.","1939-3520","","10.1109/TSE.2017.2782280","National Key Basic Research Program of China; National Natural Science Foundation of China; Science and Technology Commission of Shanghai Municipality; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8186224","API usage;mining specification;empirical study","Libraries;Data mining;Programming;Law;Tools;Concrete","application program interfaces;data mining","API usages;API libraries;open questions;single-type usages;multitype usages;API elements;specific API;mining specifications","","4","","94","","11 Dec 2017","","","IEEE","IEEE Journals"
"How Do Static and Dynamic Test Case Prioritization Techniques Perform on Modern Software Systems? An Extensive Study on GitHub Projects","Q. Luo; K. Moran; L. Zhang; D. Poshyvanyk","Department of Computer Science, College of William and Mary, Williamsburg, VA; Department of Computer Science, College of William and Mary, Williamsburg, VA; Department of Computer Science, University of Texas at Dallas, Dallas, TX; Department of Computer Science, College of William and Mary, Williamsburg, VA","IEEE Transactions on Software Engineering","12 Nov 2019","2019","45","11","1054","1080","Test Case Prioritization (TCP) is an increasingly important regression testing technique for reordering test cases according to a pre-defined goal, particularly as agile practices gain adoption. To better understand these techniques, we perform the first extensive study aimed at empirically evaluating four static TCP techniques, comparing them with state-of-research dynamic TCP techniques across several quality metrics. This study was performed on 58 real-word Java programs encompassing 714 KLoC and results in several notable observations. First, our results across two effectiveness metrics (the Average Percentage of Faults Detected APFD and the cost cognizant APFDc) illustrate that at test-class granularity, these metrics tend to correlate, but this correlation does not hold at test-method granularity. Second, our analysis shows that static techniques can be surprisingly effective, particularly when measured by APFDc. Third, we found that TCP techniques tend to perform better on larger programs, but that program size does not affect comparative performance measures between techniques. Fourth, software evolution does not significantly impact comparative performance results between TCP techniques. Fifth, neither the number nor type of mutants utilized dramatically impact measures of TCP effectiveness under typical experimental settings. Finally, our similarity analysis illustrates that highly prioritized test cases tend to uncover dissimilar faults.","1939-3520","","10.1109/TSE.2018.2822270","NSF; NSF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8329518","Regression testing;test case prioritization;static;dynamic;mutation analysis","Testing;Measurement;Computer bugs;Software systems;Java;Fault detection","fault diagnosis;Java;program testing;regression analysis","regression testing technique;static TCP techniques;dynamic TCP techniques;quality metrics;real-word Java programs;test-class granularity;test-method granularity;static techniques;TCP effectiveness;static test case prioritization techniques;dynamic test case prioritization techniques;software systems;GitHub projects","","2","","76","","2 Apr 2018","","","IEEE","IEEE Journals"
"Specifying Callback Control Flow of Mobile Apps Using Finite Automata","D. D. Perez; W. Le","Department of Computer Science, Iowa State University, Ames, IA, USA; Department of Computer Science, Iowa State University, Ames, IA, USA","IEEE Transactions on Software Engineering","11 Feb 2021","2021","47","2","379","392","Given the event-driven and framework-based architecture of Android apps, finding the ordering of callbacks executed by the framework remains a problem that affects every tool that requires inter-callback reasoning. Previous work has focused on the ordering of callbacks related to the Android components and GUI events. But the execution of callbacks can also come from direct calls of the framework (API calls). This paper defines a novel program representation, called Callback Control Flow Automata (CCFA), that specifies the control flow of callbacks invoked via a variety of sources. We present an analysis to automatically construct CCFAs by combining two callback control flow representations developed from the previous research, namely, Window Transition Graphs (WTGs) and Predicate Callback Summaries (PCSs). To demonstrate the usefulness of our representation, we integrated CCFAs into two client analyses: a taint analysis using FLOWDROID, and a value-flow analysis that computes source and sink pairs of a program. Our evaluation shows that we can compute CCFAs efficiently and that CCFAs improved the callback coverages over WTGs. As a result of using CCFAs, we obtained 33 more true positive security leaks than FLOWDROID over a total of 55 apps we have run. With a low false positive rate, we found that 22.76 percent of source-sink pairs we computed are located in different callbacks and that 31 out of 55 apps contain source-sink pairs spreading across components. Thus, callback control flow graphs and inter-callback analysis are indeed important. Although this paper mainly uses Android, we believe that CCFAs can be useful for modeling control flow of callbacks for other event-driven, framework-based systems.","1939-3520","","10.1109/TSE.2019.2893207","Government of Panama; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8613913","Event-driven;framework-based;callbacks;control flow;extended finite automata;android;mobile;program analysis;information flow","Tools;Automata;Microsoft Windows;Graphical user interfaces;Computer architecture;Static analysis;Cameras","Android (operating system);application program interfaces;data flow analysis;finite automata;graph theory;graphical user interfaces;mobile computing;program testing;program verification;security of data","true positive security;FLOWDROID;PCSs;WTGs;window transition graphs;predicate callback summaries;callback control flow automata;event-driven framework-based architecture;value-flow analysis;taint analysis;callback control flow representations;program representation;API calls;direct calls;GUI events;Android components;inter-callback reasoning;Android apps;finite automata;mobile apps;callback control flow graphs;source-sink pairs;CCFAs","","","","41","IEEE","16 Jan 2019","","","IEEE","IEEE Journals"
"checsdm: A Method for Ensuring Consistency in Heterogeneous Safety-Critical System Design","A. Paz; G. El Boussaidi; M. Hafedh","Département de génie logiciel et des TI, école de technologie supérieure, 14849 Montreal, Quebec Canada (e-mail: andres.paz-loboguerrero.1@ens.etsmtl.ca); Software and IT engineering, école de technologie supérieure, 14849 Montreal, Quebec Canada H3C 1K3 (e-mail: ghizlane.elboussaidi@etsmtl.ca); Département d'informatique, Université du Québec - Montréal, Montreal, Quebec Canada (e-mail: mili.hafedh@uqam.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Safety-critical systems are highly heterogeneous, combining different characteristics. Effectively designing such systems requires a complex modelling approach that deals with diverse components (e.g., mechanical, electronic, software)-each having its own underlying domain theories and vocabularies-as well as with various aspects of the same component (e.g., function, structure, behaviour). Furthermore, the regulated nature of such systems prescribes the objectives for their design verification and validation. This paper proposes checsdm, a systematic approach, based on Model-Driven Engineering (MDE), for assisting engineering teams in ensuring consistency of heterogeneous design of safety-critical systems. The approach is developed as a generic methodology and a tool framework, that can be applied to various design scenarios involving different modelling languages and different design guidelines. The methodology comprises an iterative three-phased process. The first phase, elicitation, aims at specifying requirements of the heterogeneous design scenario. Using the proposed tool framework, the second phase, codification, consists in building a particular tool set that supports the heterogeneous design scenario and helps engineers in flagging consistency errors for review and eventual correction. The third phase, operation, applies the tool set to actual system designs. Empirical evaluation of the work is presented through two executions of the checsdm approach for the specific cases of a design scenario involving a mix of UML, Simulink and Stateflow, and a design scenario involving a mix of AADL, Simulink and Stateflow. The operation phase of the first case was performed over three avionics systems and the identified inconsistencies in the design models of these systems were compared to the results of a fully manual verification carried out by professional engineers. The evaluation also includes an assessment workshop with industrial practitioners to examine their perceptions about the approach. The empirical validation indicates the feasibility and ""cost-effectiveness"" of the approach. Inconsistencies were identified in the three avionics systems with a greater recall rate over the manual verification. The assessment workshop shows the practitioners found the approach easy to understand and gave an overall likelihood of adoption within the context of their work.","1939-3520","","10.1109/TSE.2020.2966994","Natural Sciences and Engineering Research Council of Canada; Consortium for Research and Innovation in Aerospace in Quebec; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8960313","Model-Driven Engineering;safety-critical systems;heterogeneous design;consistency;design guidelines;DO-178C","Unified modeling language;Software packages;Tools;Object oriented modeling;Design methodology;Aerospace electronics;Gears","","","","","","","","15 Jan 2020","","","IEEE","IEEE Early Access Articles"
"Effectively Incorporating Expert Knowledge in Automated Software Remodularisation","M. Hall; N. Walkinshaw; P. McMinn","Department of Computer Science, University of Sheffield, Sheffield, United Kingdom; Department of Informatics, University of Leicester, Leicester, United Kingdom; Department of Computer Science, University of Sheffield, Sheffield, United Kingdom","IEEE Transactions on Software Engineering","16 Jul 2018","2018","44","7","613","630","Remodularising the components of a software system is challenging: sound design principles (e.g., coupling and cohesion) need to be balanced against developer intuition of which entities conceptually belong together. Despite this, automated approaches to remodularisation tend to ignore domain knowledge, leading to results that can be nonsensical to developers. Nevertheless, suppling such knowledge is a potentially burdensome task to perform manually. A lot information may need to be specified, particularly for large systems. Addressing these concerns, we propose the SUpervised reMOdularisation (SUMO) approach. SUMO is a technique that aims to leverage a small subset of domain knowledge about a system to produce a remodularisation that will be acceptable to a developer. With SUMO, developers refine a modularisation by iteratively supplying corrections. These corrections constrain the type of remodularisation eventually required, enabling SUMO to dramatically reduce the solution space. This in turn reduces the amount of feedback the developer needs to supply. We perform a comprehensive systematic evaluation using 100 real world subject systems. Our results show that SUMO guarantees convergence on a target remodularisation with a tractable amount of user interaction.","1939-3520","","10.1109/TSE.2017.2786222","Engineering and Physical Sciences Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8259332","Software remodularisation;domain knowledge;set partitioning","Clustering algorithms;Tools;Software algorithms;Software systems;Algorithm design and analysis","knowledge based systems;learning (artificial intelligence);reverse engineering;software maintenance","automated software remodularisation;domain knowledge;SUMO;target remodularisation;expert knowledge;supervised remodularisation approach","","1","","49","CCBY","15 Jan 2018","","","IEEE","IEEE Journals"
"On the Semantics of Distributed Reactive Programming: The Cost of Consistency","A. Margara; G. Salvaneschi","Dipartimento di Elettronica, Informazione e Bioingegneria (DEIB), Politecnico di Milano, Milan, Italy; Department of Computer Science, Technische Universität Darmstadt, Darmstadt, Germany","IEEE Transactions on Software Engineering","16 Jul 2018","2018","44","7","689","711","The reactive programming paradigm aims to simplify the development of reactive systems. It provides abstractions to define time-changing values that are automatically updated by the runtime according to their dependencies. The benefits of reactive programming in distributed settings have been recognized for long. Yet, existing solutions for distributed reactive programming enforce the same semantics as in single processes, introducing communication and synchronization costs that hamper scalability. Establishing suitable abstractions for distributed reactive programming demands for a deeper investigation of the semantics of change propagation. This paper takes a foundational approach and defines precise propagation semantics in terms of consistency guarantees that constrain the order and isolation of value updates. We study the benefits and costs of these consistency guarantees both theoretically and empirically, using case studies and synthetic benchmarks. We show that different applications require different levels of consistency and that manually implementing the required level on a middleware that provides a lower one annuls the abstraction improvements of reactive programming. This motivates a framework that enables the developers to select the best trade-off between consistency and overhead for the problem at hand. To this end, we present DREAM, a distributed reactive programming middleware with flexible consistency guarantees.","1939-3520","","10.1109/TSE.2018.2833109","H2020 European Research Council; German Research Foundation (DFG); DFG; AWS Cloud Credits; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354906","Distributed reactive programming;consistency guarantees;reactive programming middleware;DREAM","Programming;Semantics;Artificial intelligence;Runtime;Middleware;Games;Computational modeling","middleware","synchronization costs;distributed reactive programming demands;foundational approach;value updates;distributed reactive programming middleware;flexible consistency guarantees;reactive programming paradigm;reactive systems;time-changing values;distributed settings","","4","","97","","4 May 2018","","","IEEE","IEEE Journals"
"Comparative Analysis of Constraint Handling Techniques for Constrained Combinatorial Testing","H. Wu; N. Changhai; J. Petke; Y. Jia; M. Harman","Computer Science and Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: hywu@nju.edu.cn); Computer Science and Technology, Nanjing University, 12581 Nanjing, Jiangsu China (e-mail: changhainie@nju.edu.cn); CS, University College London, 4919 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: j.petke@ucl.ac.uk); CS, Facebook London, 507852 London, UK United Kingdom of Great Britain and Northern Ireland (e-mail: yue.jia@ucl.ac.uk); CS, Facebook London, 507852 London, London United Kingdom of Great Britain and Northern Ireland (e-mail: mark.harman@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Constraints depict the dependency relationships between parameters in a software system under test. Because almost all systems are constrained in some way, techniques that adequately cater for constraints have become a crucial factor for adoption, deployment and exploitation of Combinatorial Testing (CT). Currently, despite a variety of different constraint handling techniques available, the relationship between these techniques and the generation algorithms that use them remains unknown, yielding an important gap and pressing concern in the literature of constrained combination testing. In this paper, we present a comparative empirical study to investigate the impact of four common constraint handling techniques on the performance of six representative (greedy and search-based) test suite generation algorithms. The results reveal that the Verify technique implemented with the Minimal Forbidden Tuple (MFT) approach is the fastest, while the Replace technique is promising for producing the smallest constrained covering arrays, especially for algorithms that construct test cases one-at-a-time. The results also show that there is an interplay between effectiveness of the constraint handler and the test suite generation algorithm into which it is developed.","1939-3520","","10.1109/TSE.2019.2955687","National Key Research and Development Plan; National Natural Science Foundation of China; EPSRC Fellowship; DAASE EPSRC Grant; Natural Science Foundation of Jiangsu Province; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8913600","combinatorial testing;constraint;survey;comparative study","Combinatorial testing;Software systems;Computational efficiency","","","","2","","","CCBY","26 Nov 2019","","","IEEE","IEEE Early Access Articles"
"A Formal Specification and Verification Framework for Timed Security Protocols","L. Li; J. Sun; Y. Liu; M. Sun; J. Dong","ISTD, Singapore University of Technology and Design, Singapore; ISTD, Singapore University of Technology and Design, Singapore; School of Computer Engineering, Nanyang Technological University, Singapore; School of Mathematical Sciences, Peking University, Beijing, China; School of Computing, National University of Singapore, Singapore","IEEE Transactions on Software Engineering","13 Aug 2018","2018","44","8","725","746","Nowadays, protocols often use time to provide better security. For instance, critical credentials are often associated with expiry dates in system designs. However, using time correctly in protocol design is challenging, due to the lack of time related formal specification and verification techniques. Thus, we propose a comprehensive analysis framework to formally specify as well as automatically verify timed security protocols. A parameterized method is introduced in our framework to handle timing parameters whose values cannot be decided in the protocol design stage. In this work, we first propose timed applied p-calculus as a formal language for specifying timed security protocols. It supports modeling of continuous time as well as application of cryptographic functions. Then, we define its formal semantics based on timed logic rules, which facilitates efficient verification against various authentication and secrecy properties. Given a parameterized security protocol, our method either produces a constraint on the timing parameters which guarantees the security property satisfied by the protocol, or reports an attack that works for any parameter value. The correctness of our verification algorithm has been formally proved. We evaluate our framework with multiple timed and untimed security protocols and successfully find a previously unknown timing attack in Kerberos V.","1939-3520","","10.1109/TSE.2017.2712621","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7939995","Timed security protocol;timed applied   $\pi$     -calculus;parameterized verification;secrecy and authentication","Cryptographic protocols;Formal specifications;Authentication;Formal verification","cryptographic protocols;formal specification;formal verification;protocols","comprehensive analysis framework;timing parameters;protocol design stage;formal language;formal semantics;parameterized security protocol;security property;formal verification techniques;formal specification framework;timed security protocols","","","","50","","6 Jun 2017","","","IEEE","IEEE Journals"
"ConTesa: Directed Test Suite Augmentation for Concurrent Software","T. Yu; Z. Huang; C. Wang","Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Computer Science, University of Kentucky, Lexington, KY, USA; Department of Computer Science, University of Southern California, Los Angeles, CA, USA","IEEE Transactions on Software Engineering","16 Apr 2020","2020","46","4","405","419","As software evolves, test suite augmentation techniques may be used to identify which part of the program needs to be tested due to code changes and how to generate these new test cases for regression testing. However, existing techniques focus exclusively on sequential software, without considering concurrent software in which multiple threads may interleave with each other during the execution and thus lead to a combinatorial explosion. To fill the gap, we propose ConTesa, the first test suite augmentation tool for concurrent software. The goal is to generate new test cases capable of exercising both code changes and the thread interleavings affected by these code changes. At the center of ConTesa is a two-pronged approach. First, it judiciously reuses the current test inputs while amplifying their interleaving coverage using random thread schedules. Then, it leverages an incremental symbolic execution technique to generate more test inputs and interleavings, to cover the new concurrency-related program behaviors. We have implemented ConTesa and evaluated it on a set of real-world multithreaded Linux applications. Our results show that it can achieve a significantly high interleaving coverage and reveal more bugs than state-of-the-art testing techniques.","1939-3520","","10.1109/TSE.2018.2861392","National Science Foundation; Office of Naval Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8423082","Regression testing;concurrent programming;symbolic execution;dynamic analysis","Testing;Schedules;Instruction sets;Concurrent computing;Tools;Context","Linux;multi-threading;program debugging;program diagnostics;program testing","concurrent software;code changes;thread interleavings;ConTesa;test inputs;random thread schedules;incremental symbolic execution technique;concurrency-related program behaviors;high interleaving coverage;directed test suite augmentation;test suite augmentation techniques;regression testing;sequential software;multiple threads;test suite augmentation tool","","","","68","IEEE","30 Jul 2018","","","IEEE","IEEE Journals"
"Using Docker to Assist Q&A Forum Users","L. Melo; I. S. Wiese; M. D'Amorim","Computer Science, Universidade Federal de Pernambuco, 28116 Recife, Pernambuco Brazil (e-mail: luish.melo@gmail.com); Department of Computing, Federal University of Technology-Paraná, Paraná, Curitiba Brazil (e-mail: igor@utfpr.edu.br); Computer Science, Universidade Federal de Pernambuco, Recife, Pernambuco Brazil (e-mail: damorim@cin.ufpe.br)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Q&A forums are today a valuable tool to assist developers in programming tasks. Unfortunately, contributions to these forums are often unclear and incomplete. Docker is a container solution that enables software developers to encapsulate an operating environment and could help address reproducibility issues. This paper reports on a feasibility study to evaluate if Docker can help improve reproducibility in Stack Overflow. We started surveying Stack Overflow users to understand their perceptions on the proposal of using Docker to reproduce Stack Overflow posts. Participants were critical and mentioned two important aspects: cost and need. To validate their criticism, we conducted an exploratory study focused on understanding how costly the task of creating containers for posts is for developers. Overall, results indicate that the cost of creating containers is not high, especially due to the fact that Dockerfiles are highly similar and small. Based on these findings we developed a tool, dubbed FRISK, to assist developers in creating containers for those posts. We then conducted a user study to evaluate interest of Stack Overflow developers on the tool. We found that, on average, users spent nearly ten minutes interacting with FRISK and that 45.3% of the 563 FRISK sessions we created for existing posts resulted in a successful access to the corresponding web service by the owners of the post. Overall, this paper provides early evidence that the use of Docker in Q&A forums should be encouraged for configuration-related posts.","1939-3520","","10.1109/TSE.2019.2956919","Coordenacao de Aperfeicoamento de Pessoal de Nivel Superior; Fundacao de Amparo a Ciencia e Tecnologia do Estado de Pernambuco; Conselho Nacional de Desenvolvimento Cientifico e Tecnologico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8918334","","Containers;Servers;Tools;Web services;Proposals;Electronic mail","","","","","","","","2 Dec 2019","","","IEEE","IEEE Early Access Articles"
"Finding Faster Configurations Using FLASH","V. Nair; Z. Yu; T. Menzies; N. Siegmund; S. Apel","Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science and Engineering, Bauhaus-University Weimar, Weimar, Germany; Department of Informatics and Mathematics, University of Passau, Passau, Germany","IEEE Transactions on Software Engineering","15 Jul 2020","2020","46","7","794","811","Finding good configurations of a software system is often challenging since the number of configuration options can be large. Software engineers often make poor choices about configuration or, even worse, they usually use a sub-optimal configuration in production, which leads to inadequate performance. To assist engineers in finding the better configuration, this article introduces Flash, a sequential model-based method that sequentially explores the configuration space by reflecting on the configurations evaluated so far to determine the next best configuration to explore. Flash scales up to software systems that defeat the prior state-of-the-art model-based methods in this area. Flash runs much faster than existing methods and can solve both single-objective and multi-objective optimization problems. The central insight of this article is to use the prior knowledge of the configuration space (gained from prior runs) to choose the next promising configuration. This strategy reduces the effort (i.e., number of measurements) required to find the better configuration. We evaluate Flash using 30 scenarios based on 7 software systems to demonstrate that Flash saves effort in 100 and 80 percent of cases in single-objective and multi-objective problems respectively by up to several orders of magnitude compared to state-of-the-art techniques.","1939-3520","","10.1109/TSE.2018.2870895","Deutsche Forschungsgemeinschaft; DFG; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8469102","Performance prediction;search-based SE;configuration;multi-objective optimization;sequential model-based methods","Software systems;Optimization;Throughput;Storms;Task analysis;Cloud computing","evolutionary computation;optimisation;search problems;software fault tolerance","software systems;multiobjective problems;configuration options;software engineers;sub-optimal configuration;sequential model-based method;configuration space;Flash scales;multiobjective optimization problems","","6","","65","IEEE","20 Sep 2018","","","IEEE","IEEE Journals"
"A Systematic Literature Review and Meta-Analysis on Cross Project Defect Prediction","S. Hosseini; B. Turhan; D. Gunarathna","University of Oulu, Oulu, Finland; Department of Computer Science, Brunel University London, London, United Kingdom; Vaimo Finland (Oy), Oulu, Finland","IEEE Transactions on Software Engineering","12 Feb 2019","2019","45","2","111","147","Background: Cross project defect prediction (CPDP) recently gained considerable attention, yet there are no systematic efforts to analyse existing empirical evidence. Objective: To synthesise literature to understand the state-of-the-art in CPDP with respect to metrics, models, data approaches, datasets and associated performances. Further, we aim to assess the performance of CPDP versus within project DP models. Method: We conducted a systematic literature review. Results from primary studies are synthesised (thematic, meta-analysis) to answer research questions. Results: We identified 30 primary studies passing quality assessment. Performance measures, except precision, vary with the choice of metrics. Recall, precision, f-measure, and AUC are the most common measures. Models based on Nearest-Neighbour and Decision Tree tend to perform well in CPDP, whereas the popular naïve Bayes yields average performance. Performance of ensembles varies greatly across f-measure and AUC. Data approaches address CPDP challenges using row/column processing, which improve CPDP in terms of recall at the cost of precision. This is observed in multiple occasions including the meta-analysis of CPDP versus WPDP. NASA and Jureczko datasets seem to favour CPDP over WPDP more frequently. Conclusion: CPDP is still a challenge and requires more research before trustworthy applications can take place. We provide guidelines for further research.","1939-3520","","10.1109/TSE.2017.2770124","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8097045","Defect prediction;fault prediction;cross project;systematic literature review;meta-analysis;within project","Object oriented modeling;Systematics;Measurement;Bibliographies;Predictive models;Context modeling;Data models","Bayes methods;decision trees;learning (artificial intelligence);pattern classification;software maintenance;software metrics;software quality;statistical analysis","systematic literature review;meta-analysis;cross project defect prediction;systematic efforts;associated performances;project DP models;CPDP;AUC;f-measure;nearest-neighbour;decision tree;NASA;Jureczko datasets;WPDP;row-column processing","","54","","150","","7 Nov 2017","","","IEEE","IEEE Journals"
"Mining Semantic Loop Idioms","M. Allamanis; E. T. Barr; C. Bird; P. Devanbu; M. Marron; C. Sutton","University of Edinburgh, Edinburgh, United Kingdom; University College London, London, United Kingdom; Microsoft Research, Redmond, WA; University of California, Davis, CA; Microsoft Research, Redmond, WA; University of Edinburgh, Edinburgh, United Kingdom","IEEE Transactions on Software Engineering","16 Jul 2018","2018","44","7","651","668","To write code, developers stitch together patterns, like API protocols or data structure traversals. Discovering these patterns can identify inconsistencies in code or opportunities to replace these patterns with an API or a language construct. We present coiling, a technique for automatically mining code for semantic idioms: surprisingly probable, semantic patterns. We specialize coiling for loop idioms, semantic idioms of loops. First, we show that automatically identifiable patterns exist, in great numbers, with a largescale empirical study of loops over 25MLOC. We find that most loops in this corpus are simple and predictable: 90 percent have fewer than 15LOC and 90 percent have no nesting and very simple control. Encouraged by this result, we then mine loop idioms over a second, buildable corpus. Over this corpus, we show that only 50 loop idioms cover 50 percent of the concrete loops. Our framework opens the door to data-driven tool and language design, discovering opportunities to introduce new API calls and language constructs. Loop idioms show that LINQ would benefit from an Enumerate operator. This can be confirmed by the exitence of a StackOverflow question with 542k views that requests precisely this feature.","1939-3520","","10.1109/TSE.2018.2832048","Microsoft Research; Engineering and Physical Sciences Research Council; US National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8355713","Data-driven tool design;idiom mining;code patterns","Semantics;Tools;Syntactics;Data mining;C# languages;Machine learning;Testing","application program interfaces;data mining;data structures","data structure traversals;automatically mining code;semantic idioms;semantic patterns;automatically identifiable patterns;concrete loops;semantic loop idiom mining","","2","","68","","7 May 2018","","","IEEE","IEEE Journals"
"A Study of Bug Management Using the Stack Exchange Question and Answering Platform","A. Bhatia; S. Wang; M. Asaduzzaman; A. E. Hassan","School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: aaditya.bhatia@cs.queensu.ca); Department of Computer Science, University of Manitoba, Canada (e-mail: shaowei@cs.umanitoba.ca); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: muhammad.asaduzzaman@cs.queensu.ca); School of Computing, Queen's University, Kingston, Ontario Canada K7L 3N6 (e-mail: ahmed@cs.queensu.ca)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","Traditional bug management systems, like Bugzilla, are widely used in open source and commercial projects. Stack Exchange uses its online question and answer (Q&A) platform to collect and manage bugs, which brings several new unique features that are not offered in traditional bug management systems. Users can edit bug reports, use different communication channels, and vote on bug reports, answers, and their associated comments. Understanding how these features manage bug reports can provide insights to the designers of traditional bug management systems, like whether a feature should be introduced? and how would users leverage such a feature? We performed a large-scale analysis of 19,151 bug reports of the bug management system of Stack Exchange and studied the in-place editing, the answering and commenting, and the voting features. We find that: 1) The three features are used actively. 2) 57% of the edits improved the quality of bug reports. 3) Commenting provides a channel for discussing bug-related information, while answering offers a channel for explaining the causes of a bug and bug-fix information. 4) Downvotes are made due to the disagreement of the reported “bug” being a real bug and the low quality of bug reports. Based on our findings, we provide suggestions for traditional bug management systems.","1939-3520","","10.1109/TSE.2020.2994006","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9091233","Bug management systems;Stack Exchange;Question & answer platform","Computer bugs;Tagging;History;Communication channels;Software;Message systems;Indexes","","","","","","","","11 May 2020","","","IEEE","IEEE Early Access Articles"
"Automated Refactoring of OCL Constraints with Search","H. Lu; S. Wang; T. Yue; s. Ali; J. F. Nygård","Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Simula Research Laboratory, Fornebu, Norway; Cancer Registry of Norway, Oslo, Norway","IEEE Transactions on Software Engineering","12 Feb 2019","2019","45","2","148","170","Object Constraint Language (OCL) constraints are typically used to provide precise semantics to models developed with the Unified Modeling Language (UML). When OCL constraints evolve regularly, it is essential that they are easy to understand and maintain. For instance, in cancer registries, to ensure the quality of cancer data, more than one thousand medical rules are defined and evolve regularly. Such rules can be specified with OCL. It is, therefore, important to ensure the understandability and maintainability of medical rules specified with OCL. To tackle such a challenge, we propose an automated search-based OCL constraint refactoring approach (SBORA) by defining and applying four semantics-preserving refactoring operators (i.e., Context Change, Swap, Split and Merge) and three OCL quality metrics (Complexity, Coupling, and Cohesion) to measure the understandability and maintainability of OCL constraints. We evaluate SBORA along with six commonly used multi-objective search algorithms (e.g., Indicator-Based Evolutionary Algorithm (IBEA)) by employing four case studies from different domains: healthcare (i.e., cancer registry system from Cancer Registry of Norway (CRN)), Oil&Gas (i.e., subsea production systems), warehouse (i.e., handling systems), and an open source case study named SEPA. Results show: 1) IBEA achieves the best performance among all the search algorithms and 2) the refactoring approach along with IBEA can manage to reduce on average 29.25 percent Complexity and 39 percent Coupling and improve 47.75 percent Cohesion, as compared to the original OCL constraint set from CRN. To further test the performance of SBORA, we also applied it to refactor an OCL constraint set specified on the UML 2.3 metamodel and we obtained positive results. Furthermore, we conducted a controlled experiment with 96 subjects and results show that the understandability and maintainability of the original constraint set can be improved significantly from the perspectives of the 96 participants of the controlled experiment.","1939-3520","","10.1109/TSE.2017.2774829","RFF Hovedstaden; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8114267","Constraints;metrics/measurement;methodologies;CASE","Cancer;Unified modeling language;Measurement;Couplings;Complexity theory;Semantics;Computational modeling","cancer;evolutionary computation;health care;object-oriented programming;search problems;Unified Modeling Language","multiobjective search algorithms;semantics-preserving refactoring operators;OCL quality metrics;cancer registry;object constraint language;UML;Unified Modeling Language;medical rules;SBORA;search-based OCL constraint refactoring approach;indicator-based evolutionary algorithm;IBEA;healthcare;CRN;Norway","","1","","59","","17 Nov 2017","","","IEEE","IEEE Journals"
"Bridging Semantic Gaps between Natural Languages and APIs with Word Embedding","X. Li; H. Jiang; Y. Kamei; X. Chen","Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, Dalian, China; Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology, Dalian, China; Principles of Software Languages Group (POSL), Kyushu University, Fukuoka, Japan; School of Computer Science and Technology, Hangzhou Dianzi University, Hangzhou, China","IEEE Transactions on Software Engineering","14 Oct 2020","2020","46","10","1081","1097","Developers increasingly rely on text matching tools to analyze the relation between natural language words and APIs. However, semantic gaps, namely textual mismatches between words and APIs, negatively affect these tools. Previous studies have transformed words or APIs into low-dimensional vectors for matching; however, inaccurate results were obtained due to the failure of modeling words and APIs simultaneously. To resolve this problem, two main challenges are to be addressed: the acquisition of massive words and APIs for mining and the alignment of words and APIs for modeling. Therefore, this study proposes Word2API to effectively estimate relatedness of words and APIs. Word2API collects millions of commonly used words and APIs from code repositories to address the acquisition challenge. Then, a shuffling strategy is used to transform related words and APIs into tuples to address the alignment challenge. Using these tuples, Word2API models words and APIs simultaneously. Word2API outperforms baselines by 10-49.6 percent of relatedness estimation in terms of precision and NDCG. Word2API is also effective on solving typical software tasks, e.g., query expansion and API documents linking. A simple system with Word2API-expanded queries recommends up to 21.4 percent more related APIs for developers. Meanwhile, Word2API improves comparison algorithms by 7.9-17.4 percent in linking questions in Question&Answer communities to API documents.","1939-3520","","10.1109/TSE.2018.2876006","National Key Research and Development Program of China; National Natural Science Foundation of China; JSPS KAKENHI; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8493293","Relatedness estimation;word embedding;word2Vec;query expansion;API documents linking","Tools;Natural languages;Training;Software;Task analysis;Semantics;Estimation","application program interfaces;computational linguistics;data mining;natural language processing;pattern matching;query processing;text analysis","shuffling strategy;word alignment;mining;textual mismatches;text matching tools;word embedding;semantic gaps;natural language words;Word2API-expanded queries;API documents","","3","","57","IEEE","16 Oct 2018","","","IEEE","IEEE Journals"
"A Study of Social Interactions in Open Source Component Use","M. Palyart; G. C. Murphy; V. Masrani","Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada","IEEE Transactions on Software Engineering","9 Dec 2018","2018","44","12","1132","1145","All kinds of software projects, whether open or closed source, rely on open source components. Repositories that serve open source components to organizations, such as the Central Repository and npmjs.org, report billions of requests per year. Despite the widespread reliance of projects on open source components, little is known about the social interactions that occur between developers of a project using a component and developers of the component itself. In this paper, we investigate the social interactions that occur for 5,133 pairs of projects, from two different communities (Java and Ruby) representing user projects that depend on a component project. We consider such questions as how often are there social interactions when a component is used? When do the social interactions occur? And, why do social interactions occur? From our investigation, we observed that social interactions typically occur after a component has been chosen for use and relied upon. When social interactions occur, they most frequently begin with creating issues or feature requests. We also found that the more use a component receives, the less likely it is that developers of project using the component will interact with the component project, and when those interactions occur, they will be shorter in duration. Our results provide insight into how socio-technical interactions occur beyond the level of an individual or small group of projects previously studied by others and identify the need for a new model of socio-technical congruence for dependencies between, instead of within, projects.","1939-3520","","10.1109/TSE.2017.2756043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8049385","Software reuse;collaboration;social interactions;OSS components","Social factors;Computer bugs;Java;Collaboration;Software reusability;Open source software;Project management","human computer interaction;Java;object-oriented programming;project management;public domain software;software development management","open source components;social interactions;component project;Ruby;Java;sociotechnical congruence;sociotechnical interactions;software projects","","","","27","","25 Sep 2017","","","IEEE","IEEE Journals"
"Software Deployment on Heterogeneous Platforms: A Systematic Mapping Study","H. Andrade; J. Schroeder; I. Crnkovic","Computer Science and Engineering, Chalmers University of Technology, 11248 Gothenburg, Vastra Gotaland Sweden (e-mail: sica@chalmers.se); Computer Science and Engineering, University of Gothenburg, 3570 Gothenburg, Vastra Gotaland Sweden (e-mail: jan.schroder@gu.se); Computer Science and Engineering, Chalmers University of Technology, 11248 Gothenburg, Vastra Gotaland Sweden (e-mail: crnkovic@chalmers.se)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Context: Multiple types of processing units (e.g., CPUs, GPUs and FPGAs) can be used jointly to achieve better performance in computational systems. However, these units are built with fundamentally different characteristics and demand attention especially towards software deployment. Objective: The goal of this work is to summarize the state-of-the-art of software deployment on heterogeneous platforms. We provide an overview of the research area by searching for and categorizing relevant studies, as well as discussing gaps and trends of the field. We are interested in the main concerns (RQ1) and the approaches used (RQ2) when deploying software on heterogeneous platforms. Method: In order to achieve our goal, we performed a systematic mapping study, which refers to a method for reviewing literature with basis on predefined search strategies and a multi-step selection process. Results: We selected and analyzed 146 primary studies from multiple sources and found that the area of research is dominated by solution proposals. The majority of the studies discuss concerns about scheduling, the quality of the software, and its architecture. A large number of studies focuses on the problem of scheduling tasks and processes. We found approaches that are applied at different binding times (i.e., design time, runtime, orthogonal). Conclusion: The evaluation of the proposed solutions in an industrial context is missing. Also, the proposed methods have not been evaluated in development processes. Most of the methods address a particular concern, or a few concerns, while there is a lack of a holistic approach.","1939-3520","","10.1109/TSE.2019.2932665","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8786134","Software Deployment;Heterogeneous Computing;Heterogeneous Platforms;Systematic Mapping Study","Task analysis;Program processors;Systematics;Heterogeneous networks;Central Processing Unit;Field programmable gate arrays","","","","3","","","","5 Aug 2019","","","IEEE","IEEE Early Access Articles"
"Hybrid Program Dependence Approximation for Effective Dynamic Impact Prediction","H. Cai","School of Electrical Engineering and Computer Science, Washington State University, Pullman, WA","IEEE Transactions on Software Engineering","16 Apr 2018","2018","44","4","334","364","Impact analysis determines the effects that program entities of interest, or changes to them, may have on the rest of the program for software measurement, maintenance, and evolution tasks. Dynamic impact analysis could be one major approach to impact analysis that computes smaller impact setsthan static alternatives for concrete sets of executions. However, existing dynamic approaches often produce impact sets that are too large to be useful, hindering their adoption in practice. To address this problem, we propose to exploit static program dependencies to drastically prune false-positive impacts that are not exercised by the set of executions utilized by the analysis, via hybrid dependence approximation. Further, we present a novel dynamic impact analysis called Diver which leverages both the information provided by the dependence graph and method-execution events to identify runtimemethod-level dependencies, hence dynamic impact sets, much more precisely without reducing safety and at acceptable costs. We evaluate Diver on ten Java subjects of various sizes and application domains against both arbitrary queries covering entire programs and practical queries based on changes actually committed by developers to actively evolving software repositories. Our extensive empirical studies show that Diver can significantly improve the precision of impact prediction, with 100-186 percent increase, with respect to a representative existing alternative thus provide a far more effective option for dynamic impact prediction. Following a similar rationale to Diver, we further developed and evaluated an online dynamic impact analysis called DiverOnline which produces impact sets immediately upon the termination of program execution. Our results show that compared to the offline approach, for the same precision, the online approach can reduce the time by 50 percent on average for answering all possible queries in the given program at once albeit at the price of possibly significant increase in runtime overhead. For users interested in one specific query only, the online approach may compute the impact set for that query during runtime without much slowing down normal program operation. Further, the online analysis, which does not incur any space cost beyond the static-analysis phase, may be favored against the offline approach when trace storage and/or related file-system resource consumption becomes a serious challenge or even stopper for adopting dynamic impact prediction. Therefore, the online and offline analysis together offer complementary options to practitioners accommodating varied application/task scenarios and diverse budget constraints.","1939-3520","","10.1109/TSE.2017.2692783","ONR; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7895205","Static program dependence;dynamic analysis;impact prediction;online impact analysis;precision;efficiency","Performance analysis;Runtime;Software;Java;Concrete;Software measurement;Maintenance engineering","graph theory;Java;program diagnostics;software maintenance;system monitoring","dynamic impact prediction;software measurement;software maintenance;software evolution;Java;software repositories;DiverOnline;runtime method-level dependencies;dependence graph;false-positive impacts;static program dependencies;hybrid program dependence approximation;offline analysis;static-analysis phase;program execution;online dynamic impact analysis;Diver","","3","","92","","12 Apr 2017","","","IEEE","IEEE Journals"
"PatchNet: Hierarchical Deep Learning-Based Stable Patch Identification for the Linux Kernel","T. Hoang; J. Lawall; Y. Tian; R. J. Oentaryo; D. Lo","School of Information System, Singapore Management University, 54756 Singapore, Singapore Singapore 188065 (e-mail: vdthoang.2016@smu.edu.sg); Computer Science, Inria/LIP6/UPMC/Sorbonne University-Regal, Paris, France France 75005 (e-mail: julia.lawall@lip6.fr); School of Computing, Queen's University, 4257 Kingston, Ontario Canada (e-mail: yuan.tian@cs.queensu.ca); McLaren Applied Technologies, McLaren, Singapore, Singapore Singapore (e-mail: richard.oentaryo@mclaren.com); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","Linux kernel stable versions serve the needs of users who value stability of the kernel over new features. The quality of such stable versions depends on the initiative of kernel developers and maintainers to propagate bug fixing patches to the stable versions. Thus, it is desirable to consider to what extent this process can be automated. A previous approach relies on words from commit messages and a small set of manually constructed code features. This approach, however, shows only moderate accuracy. In this paper, we investigate whether deep learning can provide a more accurate solution. We propose PatchNet, a hierarchical deep learning-based approach capable of automatically extracting features from commit messages and commit code and using them to identify stable patches. PatchNet contains a deep hierarchical structure that mirrors the hierarchical and sequential structure of commit code, making it distinctive from the existing deep learning models on source code. Experiments on 82,403 recent Linux patches confirm the superiority of PatchNet against various state-of-the-art baselines, including the one recently-adopted by Linux kernel maintainers.","1939-3520","","10.1109/TSE.2019.2952614","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8896061","","Kernel;Linux;Computer bugs;Feature extraction;Deep learning;Indexes;Manuals","","","","2","","","","11 Nov 2019","","","IEEE","IEEE Early Access Articles"
"oo7: Low-overhead Defense against Spectre attacks via Program Analysis","G. Wang; S. Chattopadhyay; I. Gotovchits; T. Mitra; A. Roychoudhury","Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: wangghge@gmail.com); ISTD, Singapore University of Technology and Design, 233793 Singapore, Singapore Singapore (e-mail: sudipta_chattopadhyay@sutd.edu.sg); CyLab Security and Privacy Institute, Carnegie Mellon University, 6612 Pittsburgh, Pennsylvania United States (e-mail: ivg@ieee.org); Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: tulika@comp.nus.edu.sg); Computer Science, National University of Singapore, Singapore, Singapore Singapore (e-mail: abhik@comp.nus.edu.sg)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The Spectre vulnerability in modern processors has been widely reported. The key insight in this vulnerability is that speculative execution in processors can be misused to access secrets speculatively. Subsequently even though the speculatively executed instructions are squashed, the secret may linger in micro-architectural states such as cache, and can potentially be accessed by an attacker via side channels. In this paper, we take the analysis approach, and try to see how Spectre attacks can be mitigated using static analysis. We propose oo7, a static analysis approach that can mitigate Spectre attacks by detecting potentially vulnerable code snippets in program binaries and protecting them against the attack. Our key contribution is to balance the concerns of effectiveness, analysis time and run-time overheads. We employ control flow extraction, taint analysis and address analysis to detect tainted conditional branches and speculative memory accesses. oo7 can detect all fifteen purpose-built Spectre-vulnerable code patterns, whereas Microsoft compiler with Spectre mitigation option can only detect two of them. We also report the results of a large-scale study on applying oo7 to over 500 program binaries (average binary size 261 KB) from different real-world projects. We protect programs against Spectre attack by selectively inserting fences only at vulnerable conditional branches to prevent speculative execution. Our approach is experimentally observed to incur low performance overheads on SPECint benchmarks.","1939-3520","","10.1109/TSE.2019.2953709","National Research Foundation Singapore; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8902081","","Program processors;Malware;Arrays;Transient analysis;Benchmark testing;Analytical models;Maintenance engineering","","","","1","","","","15 Nov 2019","","","IEEE","IEEE Early Access Articles"
"EnergyPatch: Repairing Resource Leaks to Improve Energy-Efficiency of Android Apps","A. Banerjee; L. K. Chong; C. Ballabriga; A. Roychoudhury","School of Computing, National University of Singapore, Singapore; School of Computing, National University of Singapore, Singapore; University of Lille, Villeneuve, France; School of Computing, National University of Singapore, Singapore","IEEE Transactions on Software Engineering","14 May 2018","2018","44","5","470","490","Increased usage of mobile devices, such as smartphones and tablets, has led to widespread popularity and usage of mobile apps. If not carefully developed, such apps may demonstrate energy-inefficient behaviour, where one or more energy-intensive hardware components (such as Wifi, GPS, etc) are left in a high-power state, even when no apps are using these components. We refer to such kind of energy-inefficiencies as energy bugs. Executing an app with an energy bug causes the mobile device to exhibit poor energy consumption behaviour and a drastically shortened battery life. Since mobiles apps can have huge input domains, therefore exhaustive exploration is often impractical. We believe that there is a need for a framework that can systematically detect and fix energy bugs in mobile apps in a scalable fashion. To address this need, we have developed EnergyPatch, a framework that uses a combination of static and dynamic analysis techniques to detect, validate and repair energy bugs in Android apps. The use of a light-weight, static analysis technique enables EnergyPatch to quickly narrow down to the potential program paths along which energy bugs may occur. Subsequent exploration of these potentially buggy program paths using a dynamic analysis technique helps in validations of the reported bugs and to generate test cases. Finally, EnergyPatch generates repair expressions to fix the validated energy bugs. Evaluation with real-life apps from repositories such as F-droid and Github, shows that EnergyPatch is scalable and can produce results in reasonable amount of time. Additionally, we observed that the repair expressions generated by EnergyPatch could bring down the energy consumption on tested apps up to 60 percent.","1939-3520","","10.1109/TSE.2017.2689012","Singapore MoE Tier 2; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7889026","Mobile apps;energy bugs;non-functional testing;energy-aware test generation","Computer bugs;Androids;Humanoid robots;Maintenance engineering;Mobile handsets;Energy consumption;Batteries","Android (operating system);energy consumption;mobile computing;power aware computing;program debugging;program diagnostics;program testing;smart phones","EnergyPatch;energy-efficiency;Android apps;mobile device;mobile apps;energy-inefficient behaviour;energy-intensive hardware components;energy-inefficiencies;energy bug;poor energy consumption behaviour;mobiles apps;validated energy bugs;real-life apps;tested apps;smartphones;tablets;static analysis techniques;dynamic analysis techniques;buggy program paths;F-droid;Github","","7","","58","","29 Mar 2017","","","IEEE","IEEE Journals"
"Emerging App Issue Identification via Online Joint Sentiment-Topic Tracing","C. Gao; J. Zeng; Z. Wen; D. Lo; X. Xia; I. King; M. R. Lyu","Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong, Hong Kong, (e-mail: gcyydxf@gmail.com); Department of Computer Science and Engineering, Chinese University of Hong Kong, 26451 New Territories, Hong Kong, Hong Kong, (e-mail: jczeng@cse.cuhk.edu.hk); Department of Computing, Hong Kong Polytechnic University, 26680 Kowloon, Hong Kong, Hong Kong, (e-mail: cszwen@comp.polyu.edu.hk); School of Information Systems, Singapore Management University, Singapore, Singapore, Singapore, 17890 (e-mail: davidlo@smu.edu.sg); Faculty of Information Technology, Monash University, 2541 MELBOURNE, Victoria, Australia, 3800 (e-mail: xin.xia@monash.edu); Computer Science & Engineering, The Chinese University of Hong Kong, Shatin, NT, Hong Kong, SAR (e-mail: king@cse.cuhk.edu.hk); Computer Science & Engineering, The Chinese University of Hong Kong, Shatin, Hong Kong, Hong Kong, 00000 (e-mail: lyu@cse.cuhk.edu.hk)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Millions of mobile apps are available in app stores, such as Apple's App Store and Google Play. For a mobile app, it would be increasingly challenging to stand out from the enormous competitors and become prevalent among users. Good user experience and well-designed functionalities are the keys to a successful app. To achieve this, popular apps usually schedule their updates frequently. If we can capture the critical app issues faced by users in a timely and accurate manner, developers can make timely updates, and good user experience can be ensured. There exist prior studies on analyzing reviews for detecting emerging app issues. These studies are usually based on topic modeling or clustering techniques. However, the short-length characteristics and sentiment of user reviews have not been considered. In this paper, we propose a novel emerging issue detection approach named MERIT to take into consideration the two aforementioned characteristics. Specifically, we propose an Adaptive Online Biterm Sentiment-Topic (AOBST) model for jointly modeling topics and corresponding sentiments that takes into consideration app versions. Based on the AOBST model, we infer the topics negatively reflected in user reviews for one app version, and automatically interpret the meaning of the topics with most relevant phrases and sentences. Experiments on popular apps from Google Play and Apple's App Store demonstrate the effectiveness of MERIT in identifying emerging app issues, improving the state-of-the-art method by 22.3% in terms of F1-score. In terms of efficiency, MERIT can return results within acceptable time.","1939-3520","","10.1109/TSE.2021.3076179","National Research Foundation Singapore under its Industry Alignment Fund Pre-positioning IAF-PP Funding Initiative; Research Grants Council of the Hong Kong Special Administrative Region; National Natural Science Foundation of China; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9417702","User reviews;online topic modeling;emerging issues;review sentiment;word embedding","Magneto electrical resistivity imaging technique;Social networking (online);User experience;Labeling;Mobile applications;Internet;Adaptation models","","","","","","","IEEE","28 Apr 2021","","","IEEE","IEEE Early Access Articles"
"A Combinatorial Testing-Based Approach to Fault Localization","L. Sh. Ghandehari; Y. Lei; R. Kacker; R. Kuhn; T. Xie; D. Kung","Department of Computer Science and Engineering, University of Texas, Arlington, TX, USA; Department of Computer Science and Engineering, University of Texas, Arlington, TX, USA; Information Technology Lab, National Institute of Standards and Technology, Gaithersburg, MD, USA; Information Technology Lab, National Institute of Standards and Technology, Gaithersburg, MD, USA; Department of Computer Science, North Carolina State University, Raleigh, NC, USA; Department of Computer Science and Engineering, University of Texas, Arlington, TX, USA","IEEE Transactions on Software Engineering","15 Jun 2020","2020","46","6","616","645","Combinatorial testing has been shown to be a very effective strategy for software testing. After a failure is detected, the next task is to identify one or more faulty statements in the source code that have caused the failure. In this paper, we present a fault localization approach, called BEN, which produces a ranking of statements in terms of their likelihood of being faulty by leveraging the result of combinatorial testing. BEN consists of two major phases. In the first phase, BEN identifies a combination that is very likely to be failure-inducing. A combination is failure-inducing if it causes any test in which it appears to fail. In the second phase, BEN takes as input a failure-inducing combination identified in the first phase and produces a ranking of statements in terms of their likelihood to be faulty. We conducted an experiment in which our approach was applied to the Siemens suite and four real-world programs, flex, grep, gzip and sed, from Software Infrastructure Repository (SIR). The experimental results show that our approach can effectively and efficiently localize the faulty statements in these programs.","1939-3520","","10.1109/TSE.2018.2865935","National Institute of Standards and Technology; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8438933","Combinatorial testing;fault localization;debugging","Testing;Fault diagnosis;Flexible printed circuits;Software;Task analysis;Debugging;Computer science","program debugging;program testing;software fault tolerance","combinatorial testing-based approach;software testing;faulty statements;fault localization approach;failure-inducing combination;software infrastructure repository;BEN approach","","9","","59","IEEE","17 Aug 2018","","","IEEE","IEEE Journals"
"On the Use of Hidden Markov Model to Predict the Time to Fix Bugs","M. Habayeb; S. S. Murtaza; A. Miranskyy; A. B. Bener","Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada; Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada; Department of Computer Science, Ryerson University, Toronto, Ontario, Canada; Department of Mechanical and Industrial Engineering, Ryerson University, Toronto, Ontario, Canada","IEEE Transactions on Software Engineering","9 Dec 2018","2018","44","12","1224","1244","A significant amount of time is spent by software developers in investigating bug reports. It is useful to indicate when a bug report will be closed, since it would help software teams to prioritise their work. Several studies have been conducted to address this problem in the past decade. Most of these studies have used the frequency of occurrence of certain developer activities as input attributes in building their prediction models. However, these approaches tend to ignore the temporal nature of the occurrence of these activities. In this paper, a novel approach using Hidden Markov Models and temporal sequences of developer activities is proposed. The approach is empirically demonstrated in a case study using eight years of bug reports collected from the Firefox project. Our proposed model correctly identifies bug reports with expected bug fix times. We also compared our proposed approach with the state of the art technique in the literature in the context of our case study. Our approach results in approximately 33 percent higher F-measure than the contemporary technique based on the Firefox project data.","1939-3520","","10.1109/TSE.2017.2757480","NSERC; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8052546","Bug repositories;temporal activities;time to fix a bug;hidden markov model","Computer bugs;Hidden Markov models;Predictive models;Software quality;Data science;Stochastic processes","hidden Markov models;program debugging;public domain software;software maintenance;software quality","bug report;fix bugs;hidden Markov model;time prediction;temporal sequences;Firefox project","","5","","42","","28 Sep 2017","","","IEEE","IEEE Journals"
"A Survey of Performance Optimization for Mobile Applications","M. Hort; M. Kechagia; F. Sarro; M. Harman","Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: max.hort.19@ucl.ac.uk); Computer Science, University College London, 4919 London, Greater London, United Kingdom of Great Britain and Northern Ireland, (e-mail: m.kechagia@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: f.sarro@ucl.ac.uk); Computer Science, University College London, 4919 London, London, United Kingdom of Great Britain and Northern Ireland, (e-mail: mark.harman@ucl.ac.uk)","IEEE Transactions on Software Engineering","","2021","PP","99","1","1","Nowadays there is a mobile application for almost everything a user may think of, ranging from paying bills and gathering information to playing games and watching movies. In order to ensure user satisfaction and success of applications, it is important to provide high performant applications. This is particularly important for resource constraint systems such as mobile devices. Thereby, non-functional performance characteristics, such as energy and memory consumption, play an important role for user satisfaction. This paper provides a comprehensive survey of non-functional performance optimization for Android applications. We collected 155 unique publications, published between 2008 and 2020, that focus on the optimization of non-functional performance of mobile applications. We target our search at four performance characteristics, in particular: responsiveness, launch time, memory and energy consumption. For each performance characteristic, we categorize optimization approaches based on the method used in the corresponding publications. Furthermore, we identify research gaps in the literature for future work.","1939-3520","","10.1109/TSE.2021.3071193","H2020 European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9397392","mobile applications;android;non-functional performance optimization;software optimization;literature survey","Mobile applications;Optimization;Smart phones;Performance evaluation;Energy consumption;Software;Hardware","","","","","","","IEEE","6 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Automatic and Accurate Expansion of Abbreviations in Parameters","Y. Jiang; H. Liu; J. Zhu; L. Zhang","School of Computer Science and Technology, Beijinag Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijinag Institute of Technology, Beijing, P.R. China; School of Computer Science and Technology, Beijinag Institute of Technology, Beijing, P.R. China; Key Laboratory of High Confidence Software Technologies, Ministry of Education, Institute of Software, School of Electronics Engineering and Computer Science, Peking University, Beijing, P.R. China","IEEE Transactions on Software Engineering","15 Jul 2020","2020","46","7","732","747","Abbreviations are widely used in identifiers. However, they have severe negative impact on program comprehension and IR-based software maintenance activities, e.g., concept location, software clustering, and recovery of traceability links. Consequently, a number of efficient approaches have been proposed successfully to expand abbreviations in identifiers. Most of such approaches rely heavily on dictionaries, and rarely exploit the specific and fine-grained context of identifiers. As a result, such approaches are less accurate in expanding abbreviations (especially short ones) that may match multiple dictionary words. To this end, in this paper we propose an automatic approach to improve the accuracy of abbreviation expansion by exploiting the specific and fine-grained context. It focuses on a special but common category of abbreviations (abbreviations in parameter names), and thus it can exploit the specific and fine-grained context, i.e., the type of the enclosing parameter as well the corresponding formal (or actual) parameter name. The recent empirical study on parameters suggest that actual parameters are often lexically similar to their corresponding formal parameters. Consequently, it is likely that an abbreviation in a formal parameter can find its full terms in the corresponding actual parameter, and vice versa. Based on this assumption, a series of heuristics are proposed to look for full terms from the corresponding actual (or formal) parameter names. To the best of our knowledge, we are the first to expand abbreviations by exploiting the lexical similarity between actual and formal parameters. We also search for full terms in the data type of the enclosing parameter. Only if all such heuristics fail, the approach turns to the traditional abbreviation dictionaries. We evaluate the proposed approach on seven well known open-source projects. Evaluation results suggest that when only parameter abbreviations are involved, the proposed approach can improve the precision from 26 to 95 percent and recall from 26 to 65 percent compared against the state-of-the-art general purpose approach. Consequently, the proposed approach could be employed as a useful supplement to existing approaches to expand parameter abbreviations.","1939-3520","","10.1109/TSE.2018.2868762","National Natural Science Foundation of China; National Basic Research Program of China (973 Program); ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8454758","Abbreviation;expansion;comprehension;lexical similarity;quality;information retrieval","Dictionaries;Open source software;Syntactics;Approximation algorithms;Software maintenance;Indexes","information retrieval;software maintenance","formal parameter;parameter abbreviations;IR-based software maintenance activities;abbreviation expansion;parameter names;program comprehension","","1","","44","IEEE","5 Sep 2018","","","IEEE","IEEE Journals"
"On Company Contributions to Community Open Source Software Projects","S. Butler; J. Gamalielsson; B. Lundell; C. Brax; J. Sjoberg; A. Mattsson; T. Gustavsson; J. Feist; E. Lonroth","School of Informatics, University of Skovde, Skovde, Vastra Gotaland Sweden (e-mail: simon.butler@his.se); School of Informatics, University of Skovde, Skovde, Vastra Gotaland Sweden (e-mail: jonas.gamalielsson@his.se); School of Humanities and Informatics, University of Skovde, Skovde, Skovde Sweden 541 28 (e-mail: bjorn.lundell@his.se); not applicable, Combitech AB, Linkaping, not applicable Sweden (e-mail: christoffer.brax@combitech.se); not applicable, Findwise AB, Goteborg, not applicable Sweden (e-mail: johan.sjoberg@findwise.com); not applicable, Husqvarna AB, 355215 Huskvarna, not applicable Sweden (e-mail: anders.mattsson@husqvarnagroup.com); not applicable, PrimeKey Solutions AB, Stockholm, not applicable Sweden (e-mail: tomas.gustavsson@primekey.com); not applicable, RedBridge AB, Stockholm, not applicable Sweden (e-mail: jonas.feist@redbridge.se); not applicable, Scania IT AB, Sadertolje, not applicable Sweden (e-mail: erik.lonroth@scania.com)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The majority of contributions to community open source software (OSS) projects are made by practitioners acting on behalf of companies and other organisations. Previous research has addressed the motivations of both individuals and companies to engage with OSS projects. However, limited research has been undertaken that examines and explains the practical mechanisms or work practices used by companies and their developers to pursue their commercial and technical objectives when engaging with OSS projects. This research investigates the variety of work practices used in public communication channels by company contributors to engage with and contribute to eight community OSS projects. Through interviews with contributors to the eight projects we draw on their experiences and insights to explore the motivations to use particular methods of contribution. We find that companies utilise work practices for contributing to community projects which are congruent with the circumstances and their capabilities that support their short- and long-term needs. We also find that companies contribute to community OSS projects in ways that may not always be apparent from public sources, such as employing core project developers, making donations, and joining project steering committees in order to advance strategic interests. The factors influencing contributor work practices can be complex and are often dynamic arising from considerations such as company and project structure, as well as technical concerns and commercial strategies. The business context in which software created by the OSS project is deployed is also found to influence contributor work practices.","1939-3520","","10.1109/TSE.2019.2919305","The Swedish Knowledge Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737777","Open source software;company contribution;work practices","Companies;Software;Technological innovation;Collaboration;Interviews;Licenses","","","","2","","","CCBY","17 Jun 2019","","","IEEE","IEEE Early Access Articles"
"A Large Scale Study of Long-Time Contributor Prediction for GitHub Projects","L. Bao; X. Xia; D. Lo; G. C. Murphy","Computer Science, Zhejiang University City College, 34705 Hangzhou, Zhejiang, Zhejiang China (e-mail: baolf@zucc.edu.cn); Faculty of Information Technology, Monash University Faculty of Information Technology, 224480 Clayton, Victoria Australia 3800 (e-mail: xxkidd@zju.edu.cn); School of Information Systems, Singapore Management University, Singapore, Singapore Singapore 17890 (e-mail: davidlo@smu.edu.sg); Computer Science, University of British Columbia, Vancouver, British Columbia Canada V6T 1Z4 (e-mail: murphy@cs.ubc.ca)","IEEE Transactions on Software Engineering","","2019","PP","99","1","1","The continuous contributions made by long time contributors LTCsare a key factor enabling open source software (OSS) projects to be successful and survival. We study Github as it has a large number of OSS projects and millions of contributors, which enables the study of the transition from newcomers to LTCs. In this paper, we investigate whether we can effectively predict newcomers in OSS projects to be LTCs based on their activity data that is collected from Github. We collect Github data from GHTorrent, a mirror of Github data. We select the most popular 917 projects, which contain 75,046 contributors. We determine a developer as a LTC of a project if the time interval between his/her first and last commit in the project is larger than a certain time T. In our experiment, we use three different settings on the time interval: 1, 2, and 3 years. There are 9,238, 3,968, and 1,577 contributors who become LTCs of a project in three settings of time interval, respectively. To build a prediction model, we extract many features from the activities of developers on Github, which group into five dimensions: developer profile, repository profile, developer monthly activity, repository monthly activity, and collaboration network. We apply several classifiers including naive Bayes, SVM, decision tree, kNN and random forest. We find that random forest classifier achieves the best performance with AUCs of more than 0.75 in all three settings of time interval for LTCs. We also investigate the most important features that differentiate newcomers who become LTCs from newcomers who stay in the projects for a short time. We find that the number of followers is the most important feature in all three settings of the time interval studied. We also find that the programming language and the average number of commits contributed by other developers when a newcomer joins a project also belong to the top 10 most important features in all three settings of time interval for LTCs. Finally, we provide several implications for action based on our analysis results to help OSS projects retain newcomers.","1939-3520","","10.1109/TSE.2019.2918536","National Basic Research Program of China (973 Program); Fundamental Research Funds for the Central Universities; Project of Science and Technology Research and Development Program of China Railway Corporation; NSFC Program; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8721092","Long Time Contributor;GitHub;Prediction Model","Predictive models;Feature extraction;Computer languages;Task analysis;Computer bugs;Mirrors","","","","1","","","","23 May 2019","","","IEEE","IEEE Early Access Articles"
"On How Bit-Vector Logic Can Help Verify LTL-based Specifications","M. M. Pourhashem Kallehbasti; M. G. Rossi; L. Baresi","Department of Computer Engineering, University of Science and Technology of Mazandaran, 531623 Behshahr, Mazandaran Iran (the Islamic Republic of) (e-mail: pourhashem@mazust.ac.ir); Dipartimento di Meccanica, Politecnico di Milano, Milan, Lombardia Italy (e-mail: matteo.rossi@polimi.it); Dipartimento di Elettronica, Informazione e Bioingegneria, Politecnico di Milano, 18981 Milano, Lombardia Italy (e-mail: luciano.baresi@polimi.it)","IEEE Transactions on Software Engineering","","2020","PP","99","1","1","This paper studies how bit-vector logic (bv logic) can help improve the efficiency of verifying specifications expressed in Linear Temporal Logic (LTL). First, it exploits the notion of Bounded Satisfiability Checking to propose an improved encoding of LTL formulae into formulae of bv logic, which can be formally verified by means of Satisfiability Modulo Theories (SMT) solvers. To assess the gain in efficiency, we compare the proposed encoding, implemented in our tool Zot, against three well-known encodings available in the literature: the classic bounded encoding and the optimized, incremental one, as implemented in both NuSMV and nuXmv, and the encoding optimized for metric temporal logic, which was the “standard” implementation provided by Zot. We also compared the newly proposed solution against five additional efficient algorithms proposed by nuXmv, which is the state-of-the-art tool for verifying LTL specifications. The experiments show that the new encoding provides significant benefits with respect to existing tools. Since the first set of experiments only used Z3 as SMT solver, we also wanted to assess whether the benefits were induced by the specific solver or were more general. This is why we also embedded different SMT solvers in Zot. Besides Z3, we also carried out experiments with CVC4, Mathsat, Yices2, and Boolector, and compared the results against the first and second best solutions provided by either NuSMV or nuXmv. Obtained results witness that the benefits of the bv logic encoding are independent of the specific solver. Bv logic-based solutions are better than traditional ones with only a few exceptions. It is also true that there is no particular SMT solver that outperformed the others. Boolector is often the best as for memory usage, while Yices2 and Z3 are often the fastest ones.","1939-3520","","10.1109/TSE.2020.3014394","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159928","Formal Methods;Linear Temporal Logic;Bounded Satisfiability Checking;Bit-Vector Logic","Encoding;Tools;Standards;Unified modeling language;Optimization;Semantics;Measurement","","","","","","","","5 Aug 2020","","","IEEE","IEEE Early Access Articles"
"Listening to the Crowd for the Release Planning of Mobile Apps","S. Scalabrino; G. Bavota; B. Russo; M. D. Penta; R. Oliveto","University of Molise, Campobasso, Italy; Università della Svizzera Italiana (USI), Lugano, Switzerland; Free University of Bozen-Bolzano, Bolzano, South Tyrol, Italy; University of Sannio, Benevento, Italy; University of Molise, Campobasso, Italy","IEEE Transactions on Software Engineering","8 Jan 2019","2019","45","1","68","86","The market for mobile apps is getting bigger and bigger, and it is expected to be worth over 100 Billion dollars in 2020. To have a chance to succeed in such a competitive environment, developers need to build and maintain high-quality apps, continuously astonishing their users with the coolest new features. Mobile app marketplaces allow users to release reviews. Despite reviews are aimed at recommending apps among users, they also contain precious information for developers, reporting bugs and suggesting new features. To exploit such a source of information, developers are supposed to manually read user reviews, something not doable when hundreds of them are collected per day. To help developers dealing with such a task, we developed CLAP (Crowd Listener for releAse Planning), a web application able to (i) categorize user reviews based on the information they carry out, (ii) cluster together related reviews, and (iii) prioritize the clusters of reviews to be implemented when planning the subsequent app release. We evaluated all the steps behind CLAP, showing its high accuracy in categorizing and clustering reviews and the meaningfulness of the recommended prioritizations. Also, given the availability of CLAP as a working tool, we assessed its applicability in industrial environments.","1939-3520","","10.1109/TSE.2017.2759112","SNF; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057860","Release planning;mobile apps;mining software repositories","Data mining;Internet;Mobile applications;Google;Mobile communication;Pattern clustering","data mining;Internet;mobile computing;pattern clustering","mobile app marketplaces;user reviews;CLAP;clustering reviews;crowd listener for release planning;Web application;categorizing reviews","","6","","42","","4 Oct 2017","","","IEEE","IEEE Journals"
"The AI Effect: Working at the Intersection of AI and SE","A. D. Carleton; E. Harper; T. Menzies; T. Xie; S. Eldh; M. R. Lyu","Software Engineering, Carnegie Mellon University; Carnegie Mellon University; North Carolina State University; Computer Science and Technology, Peking University, China; Ericsson AB, Stockholm, Sweden; Computer Science and Engineering, The Chinese University of Hong Kong","IEEE Software","19 Jun 2020","2020","37","4","26","35","This special issue explores the intersection of artificial intelligence (AI) and software engineering (SE), that is, what can AI do for SE, and how can we as software engineers design and build better AI systems?","1937-4194","","10.1109/MS.2020.2987666","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121618","","","","","","","","25","","19 Jun 2020","","","IEEE","IEEE Magazines"
"The Sound of Software Development: Music Listening Among Software Engineers","L. Barton; G. Candan; T. Fritz; T. Zimmermann; G. C. Murphy","Computer Science, University of British Columbia, Vancouver, British Columbia, Canada; Avigilon, Vancouver, British Columbia, Canada; University of Zurich, Zurich, Switzerland; Research, Microsoft, Redmond, Washington United States; Computer Science, University of British Columbia, Vancouver, British Columbia, Canada","IEEE Software","11 Feb 2020","2020","37","2","78","85","Listening to music is a common phenomenon among software developers in today's work environments. Music can reduce stress, improve happiness, and even increase performance. We conducted two surveys with 2,242 professional software developers and found that between 63 and 88.2% of participants listen to music at work at least some of the time often when writing code or doing repetitive tasks, and that these listeners tend to be more extroverted.","1937-4194","","10.1109/MS.2019.2906312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8669868","","Music;Software development management;Task analysis;Mood;Writing;Noise measurement;Productivity","hearing;music;software development management;software engineering","software development;music listening;software engineers;work environments;professional software developers;repetitive tasks;stress","","","","15","","19 Mar 2019","","","IEEE","IEEE Magazines"
"Insights Into Nonmerged Pull Requests in GitHub: Is There Evidence of Bias Based on Perceptible Race?","R. Nadri; G. Rodriguez-Perez; M. Nagappan","University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada; Computer Science, University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada; Computer Science, University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada","IEEE Software","15 Feb 2021","2021","38","2","51","57","This article is a qualitative study that analyzes whether there is evidence of bias based on perceptible race in the written comments of nonmerged pull requests in GitHub.","1937-4194","","10.1109/MS.2020.3036758","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9250363","","Software development management;Cultural differences;Psychology;Corporate acquisitions;Computer science;Cognition","distributed processing;public domain software;software engineering","GitHub;perceptible race;qualitative study;nonmerged pull requests","","","","14","IEEE","6 Nov 2020","","","IEEE","IEEE Magazines"
"Performance Issues? Hey DevOps, Mind the Uncertainty","C. Trubiani; P. Jamshidi; J. Cito; W. Shang; Z. M. Jiang; M. Borg","Gran Sasso Science Institute, L'Aquila, Italy; University of South Carolina; Massachusetts Institute Technology, Cambridge, Massachuestts United States; Concordia University, Montreal, Canada; York University, Toronto, Canada; RISE Research Institutes of Sweden AB, Lund, Sweden","IEEE Software","21 Feb 2019","2019","36","2","110","117","DevOps is a novel trend that aims to bridge the gap between software development and operation teams. This article presents an experience report that better identifies performance uncertainties through a case study and provides a step-by-step guide to practitioners for controlling system uncertainties.","1937-4194","","10.1109/MS.2018.2875989","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501933","Uncertainty;Performance Analysis;DevOps;Software Development","Software development;Runtime;Predictive models;Analytical models;Hardware;Performance analysis","cloud computing;software engineering","step-by-step guide;system uncertainties;performance issues;software development;operation teams;experience report;performance uncertainties;Hey DevOps","","3","","15","","21 Oct 2018","","","IEEE","IEEE Magazines"
"Gendered Experiences of Software Engineers During the COVID-19 Crisis","L. S. Machado; C. Caldeira; M. Gattermann Perin; C. R. B. de Souza","Computer Science, Federal University of Para, Belem, 66075-110 Para, Brazil; Computer Science, Federal University of Para, Belem, 66075-110 Para, Brazil; Business Administration, Fundação Getulio Vargas’s Sao Paulo, Sao Paulo, 01313-902, Brazil; Computer Science, Federal University of Para, Belem, 66075-110 Para, Brazil","IEEE Software","17 Feb 2021","2021","38","2","38","44","Although gender divides are largely due to cultural and environmental conditions, changes in the nature of professional and domestic work due to the COVID-19 pandemic have had unprecedented implications on gender inequality.","1937-4194","","10.1109/MS.2020.3040135","Conselho Nacional de Desenvolvimento Científico e Tecnológico; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9268454","","Collaboration;Organizations;Software;Pandemics;COVID-19;Task analysis;Couplings","diseases;gender issues;software engineering","gender inequality;gendered experiences;software engineers;COVID-19 crisis;gender divides;cultural conditions;environmental conditions;professional work;domestic work;COVID-19 pandemic","","","","13","IEEE","24 Nov 2020","","","IEEE","IEEE Magazines"
"Enabling the Study of Software Development Behavior With Cross-Tool Logs","C. Jaspan; M. Jorde; C. Egelman; C. Green; B. Holtz; E. Smith; M. Hodges; A. Knight; L. Kammer; J. Dicker; C. Sadowski; J. Lin; L. Cheng; M. Canning; E. Murphy-Hill","Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Google, Mountain View, California United States; Software Engineer, Bloomberg, New York, New York United States; Developer Infrastructure, Artech, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States; User Experience, Google, Mountain View, California United States","IEEE Software","23 Oct 2020","2020","37","6","44","51","Capturing developers' behavior at scale can be challenging. In this article, we describe our experience creating a system that integrates log data from dozens of development tools at Google.","1937-4194","","10.1109/MS.2020.3014573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9159122","","Tools;Task analysis;Google;Licenses;Measurement;Software;Electronic mail","data loggers;data mining;software engineering","software development behavior;cross-tool logs;developers behavior;log data;development tools;Google","","","","8","CCBY","5 Aug 2020","","","IEEE","IEEE Magazines"
"Innovative Practices for Knowledge Sharing in Large-Scale DevOps","A. Hemon; B. Fitzgerald; B. Lyonnet; F. Rowe","ESSCA School of Management, Angers, France; Lero Software Research, University of Limerick, Limerick, Ireland; Management Sciences, University of Nantes, France; University of Nantes, France","IEEE Software","15 Apr 2020","2020","37","3","30","37","Agile development methods and DevOps require adaptation during implementation to meet the needs of a constantly changing softwaredevelopment environment. The emergence of knowledge-sharing practices for large-scale DevOps has not been the subject of much research. Our in-depth case study, consisting of 106 interviews at a multinational company operating in a DevOps-at-scale environment, identified a number of innovative practices.","1937-4194","","10.1109/MS.2019.2958900","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8930607","Agile method;DevOps;Large-Scale;Innovative Practices;Knowledge Sharing","Companies;Software development management;Collaboration;Automation;Large-scale systems;Software tools","formal specification;innovation management;knowledge management;organisational aspects;software engineering","innovative practices;knowledge sharing practices;large-scale DevOps;agile development methods;knowledge-sharing practices;in-depth case study;DevOps-at-scale environment;constantly changing software development environment","","","","20","","10 Dec 2019","","","IEEE","IEEE Magazines"
"A Taxonomy to Assess and Tailor Risk-Based Testing in Recent Testing Standards","J. Grossmann; M. Felderer; J. Viehmann; I. Schieferdecker","Critical Systems Engineering, Fraunhofer Institute for Open Communication Systems, Berlin, Germany; Computer Science, University of Innsbruck, Innsbruck, Tyrol, Austria; Critical Systems Engineering, Fraunhofer Institute for Open Communication Systems, Berlin, Germany; Critical Systems Engineering, Fraunhofer Institute for Open Communication Systems, Berlin, Germany","IEEE Software","20 Dec 2019","2020","37","1","40","49","This article provides a taxonomy for risk-based testing that serves as a tool to define, tailor, or assess such approaches. In this setting, the taxonomy is used to systematically identify deviations between the requirements from public standards and the individual testing approaches.","1937-4194","","10.1109/MS.2019.2915297","Bundesministerium für Bildung und Forschung; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8708236","Risk management;Testing strategies;Test management;Security and Privacy Protection","Software testing;Risk management;Taxonomy;ISO Standards;Computer security;IEC Standards","program testing;risk management;software engineering","taxonomy;testing standards;risk-based testing;software product risks;software development","","","","15","","7 May 2019","","","IEEE","IEEE Magazines"
"What We Know about Software Test Maturity and Test Process Improvement","V. Garousi; M. Felderer; T. Hacaloğlu",Hacettepe University; University of Innsbruck; Atilim University,"IEEE Software","25 Dec 2017","2018","35","1","84","92","In many companies, software testing practices and processes are far from mature and are usually conducted in an ad hoc fashion. Such immature practices lead to negative outcomes-for example, testing that doesn't detect all the defects or that incurs cost and schedule overruns. To conduct test maturity assessment (TMA) and test process improvement (TPI) systematically, researchers and practitioners have proposed various approaches and frameworks. Motivated by a recent industrial project in TMA and TPI and wanting to identify the state of the art and practice in this area, researchers conducted a review of both the scientific literature and practitioners' gray literature (for example, blog posts). The review identified 58 test maturity models and many sources with varying degrees of empirical evidence. The review's results can serve as an evidence-based overview of and index to the vast body of knowledge in this important, fast-growing area. Using this knowledge, both researchers and practitioners should be able to assess and improve the maturity of test processes.","1937-4194","","10.1109/MS.2017.4541043","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239941","software testing;test maturity;test maturity assessment;TMA;test process improvement;TPI;test process assessment;Test Maturity Model Integration;TMMi;multivocal literature review;systematic literature review;software development;software engineering","Capability maturity model;Software testing;Software development;Unified modeling language","program testing;project management;Web sites","software test maturity;test process improvement;software testing practices;immature practices;schedule overruns;test maturity assessment;TMA;TPI;test processes;test maturity models","","3","","20","","25 Dec 2017","","","IEEE","IEEE Magazines"
"A Tool for Generating Health Applications Using Archetypes","A. Araujo; V. Times; M. Silva","Federal University of Pernambuco, Maceio, Brazil; Informatics, Federal University of Pernambuco, Maceio, Brazil; Computer Science, Federal University of Pernambuco, Maceio, Brazil","IEEE Software","20 Dec 2019","2020","37","1","60","67","Template4EHR is a to ol for the dynamic creation of data schemas for electronic health-record storage and user creation and customization of graphical user interfaces. In experimental tests with IT and health professionals, Template4EHR obtained an 81.22% satisfaction rate.","1937-4194","","10.1109/MS.2018.110162508","Fundação de Amparo à Ciência e Tecnologia do Estado de Pernambuco; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254325","computing milieux;computers and society;public policy issues;computer-related health issues;graphical user interfaces;user interfaces;information interfaces and representation (hci);information;distributed/internet based software engineering tools and techniques;design tools and techniques;software;information technology and systems;database management;systems;relational databases","Graphical user interfaces;Software tools;Terminology;Data mining;XML;Computer architecture","graphical user interfaces;medical information systems","Template4EHR;dynamic creation;data schemas;user creation;graphical user interfaces;health professionals;electronic health-record storage;health application generation;archetypes","","1","","15","","11 Jan 2018","","","IEEE","IEEE Magazines"
"Practitioners’ Agile-Methodology Use and Job Perceptions","W. Sun; C. Schmidt",Washburn University; Washburn University,"IEEE Software","12 Mar 2018","2018","35","2","52","61","To examine software professionals' job perceptions related to different levels of agile-methodology use, researchers conducted a survey. The respondents generally reported high professional efficacy, high job satisfaction, moderate work overload, and low cynicism. The respondents with high agile-methodology use reported higher professional efficacy, higher job satisfaction, lower work ambiguity, lower work exhaustion, and lower individual autonomy than those with low agile-methodology use. No difference existed between the two groups regarding role conflict, work overload, and cynicism.","1937-4194","","10.1109/MS.2018.1661333","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314163","software engineering;software development;agile-methodology use;job perceptions;agile development;Extreme Programming","Agile software development;Programming profession;Encoding;Software testing;Information systems","human resource management;industrial psychology;occupational stress;personnel;professional aspects","job perceptions;software professionals;agile-methodology use;work exhaustion;work ambiguity;job satisfaction;professional efficacy;work overload","","","","21","","12 Mar 2018","","","IEEE","IEEE Magazines"
"A Scalable, Reactive Architecture for Cloud Applications","A. Debski; B. Szczepanik; M. Malawski; S. Spahr; D. Muthig",AGH University of Science and Technology; AGH University of Science and Technology; AGH University of Science and Technology; Lufthansa Systems; Lufthansa Systems,"IEEE Software","12 Mar 2018","2018","35","2","62","71","As cloud infrastructures gain popularity, new concepts and design patterns such as Command Query Responsibility Segregation (CQRS) and Event Sourcing (ES) promise to facilitate the development of scalable applications. Despite recent research and the availability of many blogs and tutorials devoted to these topics, few reports on real-world implementations exist that provide experimental insight into their scalability. To bridge this gap, researchers developed an architecture that exploits both CQRS and ES in accordance with Reactive Manifesto guidelines. Using that architecture, they implemented a prototype interactive flight-scheduling application to investigate this approach's scalability. A performance evaluation in a cloud environment of 15 virtual machines demonstrated the CQRS and ES patterns' horizontal scalability, observed independently for the application's read and write models. This article explains how to assemble this type of architecture, first on a conceptual level and then with specific technologies including Akka, Cassandra, Kafka, and Neo4J. A reference implementation is available as an open-source project. This approach provides many interesting advantages without compromising performance, so its rapid adoption by the industry seems likely.","1937-4194","","10.1109/MS.2017.265095722","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950867","scalability;Command Query Responsibility Segregation;CQRS;Event Sourcing;domain-driven design;reactive;Akka;flight scheduling;Reactive Manifesto;software engineering;software development","Cloud computing;Computer architecture;Scalability;Load modeling;Query processing","cloud computing;query processing;software architecture;virtual machines;Web sites","CQRS;ES;reference implementation;open-source project;cloud applications;design patterns;scalable applications;blogs;tutorials;Reactive Manifesto guidelines;prototype interactive flight-scheduling application;performance evaluation;cloud environment;virtual machines;pattern horizontal scalability;command query responsibility segregation;event sourcing","","1","","8","","16 Jun 2017","","","IEEE","IEEE Magazines"
"Daily Stand-Up Meetings: Start Breaking the Rules","V. Stray; N. B. Moe; D. I. K. Sjoberg","Informatics, University of Oslo, Oslo, Norway; SINTEF, Trondheim, Norway; University of Oslo, Oslo, Norway","IEEE Software","15 Apr 2020","2020","37","3","70","77","Daily stand-up meetings are commonly used for software teams to collaborate and exchange information, but conducting them in a way that benefits the whole team can be challenging. We describe factors that can affect meetings and propose recommendations for improving them.","1937-4194","","10.1109/MS.2018.2875988","The Research Council of Norway Grant 267704; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501962","Agile practices;Daily Scrum;Teamwork;Self-organizing software teams;Team autonomy;Coordination;Communication;Empirical software engineering;Case study;Agile Software Development","Companies;Software;Task analysis;Interviews;Decision making;Problem-solving;Scrum (Software development)","DP industry;software development management;software prototyping;team working","software teams;daily stand-up meetings","","","","12","","21 Oct 2018","","","IEEE","IEEE Magazines"
"Code Reviewing in the Trenches: Challenges and Best Practices","L. MacLeod; M. Greiler; M. Storey; C. Bird; J. Czerwonka",Microsoft; Microsoft; University of Victoria; Microsoft Research; Microsoft,"IEEE Software","6 Jul 2018","2018","35","4","34","42","Code review has been widely adopted by and adapted to open source and industrial projects. Code review practices have undergone extensive research, with most studies relying on trace data from tool reviews, sometimes augmented by surveys and interviews. Several recent industrial research studies, along with blog posts and white papers, have revealed additional insights on code reviewing “from the trenches.” Unfortunately, the lessons learned about code reviewing are widely dispersed and poorly summarized by the existing literature. In particular, practitioners wishing to adopt or reflect on an existing or new code review process might have difficulty determining what challenges to expect and which best practices to adopt for their development context. Building on the existing literature, this article adds insights from a recent large-scale study of Microsoft developers to summarize the challenges that code-change authors and reviewers face, suggest best code-reviewing practices, and discuss tradeoffs that practitioners should consider. This article is part of a theme issue on Process Improvement.","1937-4194","","10.1109/MS.2017.265100500","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7950877","peer review;social technologies;learning technologies;code inspection;code walkthroughs;testing;debugging;software engineering;software development","Encoding;Best practices;Interviews;Context awareness;Object recognition;Stakeholders","software quality;software reviews;source code (software)","tool reviews;code-change authors;code-reviewing practices;Microsoft developers;code-change reviewers","","14","","11","","16 Jun 2017","","","IEEE","IEEE Magazines"
"A Framework for Determining Blockchain Applicability","B. A. Scriber",CableLabs,"IEEE Software","6 Jul 2018","2018","35","4","70","77","Researchers analyzed 23 blockchain implementation projects, each tracked for design decisions and architectural alignment showing benefits, detriments, or no effects from blockchain use. The results provide the basis for a framework that lets engineers, architects, investors, and project leaders evaluate blockchain technology's suitability for a given application. This analysis also led to an understanding of why some domains are inherently problematic for blockchains. Blockchains can be used to solve some trust-based problems but aren't always the best or optimal technology. Some problems that can be solved using them can also be solved using simpler methods that don't necessitate as big an investment.","1937-4194","","10.1109/MS.2018.2801552","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405623","blockchains;software architectures;patterns;trust;immutability;transparency;identity;distributed ledgers;transaction;efficiency;software development;software engineering","Ecosystems;Computer architecture;Cryptography;Blockchain","investment;optimisation;software architecture","trust-based problems;optimal technology;design decisions;architectural alignment;blockchain technology;investment","","8","","9","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Lessons in Persisting Object Data Using Object-Relational Mapping","G. Vial","Information Technology, HEC Montreal, Canada","IEEE Software","22 Oct 2019","2019","36","6","43","52","In this article, object-relational mapping (ORM) engines in object-oriented programming are introduced. The tradeoffs that must be considered when using ORM are discussed and four lessons that will help software developers take advantage of ORM in transaction processing scenarios are provided.","1937-4194","","10.1109/MS.2018.227105428","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356175","Information Technology and Systems;database management;systems;relational databases;object-oriented programming;coding tools and techniques;Software Engineering;Software","Databases;Software development management;Object recognition;Java;Object oriented programming;Information technology","object-oriented programming;transaction processing","object data;object-relational mapping engines;ORM;object-oriented programming;transaction processing scenarios","","2","","15","","8 May 2018","","","IEEE","IEEE Magazines"
"Safe, Secure Executions at the Network Edge: Coordinating Cloud, Edge, and Fog Computing","N. Mäkitalo; A. Ometov; J. Kannisto; S. Andreev; Y. Koucheryavy; T. Mikkonen",University of Helsinki; Tampere University of Technology; Tampere University of Technology; Tampere University of Technology; Tampere University of Technology; University of Helsinki,"IEEE Software","25 Dec 2017","2018","35","1","30","37","System design where cyber-physical applications are securely coordinated from the cloud may simplify the development process. However, all private data are then pushed to these remote “swamps,” and human users lose actual control as compared to when the applications are executed directly on their devices. At the same time, computing at the network edge is still lacking support for such straightforward multidevice development, which is essential for a wide range of dynamic cyber-physical services. This article proposes a novel programming model as well as contributes the associated secure-connectivity framework for leveraging safe coordinated device proximity as an additional degree of freedom between the remote cloud and the safety-critical network edge, especially under uncertain environment constraints. This article is part of a special issue on Software Safety and Security Risk Mitigation in Cyber-physical Systems.","1937-4194","","10.1109/MS.2017.4541037","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239948","fog computing;edge computing;programming models;security and trust;proximate connectivity;systems and software design;programmable world;software development;software engineering","Edge computing;Programming;Computer security;Software development;Cyber-physical systems;Computational modeling","cloud computing;data privacy;mobile computing;security of data","secure executions;fog computing;cyber-physical applications;private data;dynamic cyber-physical services;secure-connectivity framework;safety-critical network edge;security risk mitigation;edge computing;cyber-physical systems;cloud computing","","11","","12","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Games for Requirements Engineers: Analysis and Directions","F. Dalpiaz; K. M. L. Cooper","Software Systems, Utrecht University, The Netherlands; Independent Scholar, Canada","IEEE Software","20 Dec 2019","2020","37","1","50","59","The requirements engineering (RE) discipline keeps evolving to cope with increasingly complex systems and shorter development cycles. Using a lightweight analysis framework, we review the current landscape of games for RE and provide guidance for the practitioner interested in improving their skills using innovative game-based RE.","1937-4194","","10.1109/MS.2018.227105450","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356183","Software;Software Engineering;Requirements;specifications;serious games","Games;Requirements engineering;Knowledge engineering;Object recognition;Training data;Task analysis","computer games;formal specification;formal verification;systems analysis","innovative game-based RE;lightweight analysis;development cycles;requirements engineering","","2","","16","","8 May 2018","","","IEEE","IEEE Magazines"
"What We Know about Testing Embedded Software","V. Garousi; M. Felderer; Ç. M. Karapıçak; U. Yılmaz",Wageningen University; University of Innsbruck; KUASOFT A. Ş.; ASELSAN A. Ş.,"IEEE Software","6 Jul 2018","2018","35","4","62","69","To cost-effectively test embedded software, practitioners and researchers have proposed many test techniques, approaches, tools, and frameworks. However, obtaining an overview of the state of the art and state of the practice in this area is challenging for practitioners or new researchers. In addition, owing to an inadequate overview of what already exists in this area, some companies often reinvent the wheel by designing a test approach that's new to them but already exists. To address these problems, the authors conducted a systematic literature review of this area that covered the testing topics, testing activities, test artifacts, and industries on which the studies focused. The results can benefit both practitioners and researchers by serving as an index to the vast body of knowledge in this important, fast-growing area.","1937-4194","","10.1109/MS.2018.2801541","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405633","software testing;embedded systems;embedded software;systematic literature mapping;systematic literature review;software engineering;software development","Testing;Unified modeling language;Automation;Automotive engineering;Embedded software","embedded systems;program testing","test techniques;test approach;testing topics;test artifacts;embedded software testing;testing activities","","2","","15","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Requirements Quality Is Quality in Use","H. Femmer; A. Vogelsang","Qualicen; Systems Engineering, Technical University of Berlin, Germany","IEEE Software","16 Apr 2019","2019","36","3","83","91","Creating a requirements engineering artifact is rarely an end in itself; it is a means to understand and reach the project's goals. So such an artifact's purpose is to support the stakeholders in whatever activities they're performing in the project.","1937-4194","","10.1109/MS.2018.110161823","German Federal Ministry of Education and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8254303","software;software engineering;requirements;specifications;software quality;sqa;general;standards","Stakeholders;Q-factor;ISO Standards;Requirements engineering;Pragmatics","formal specification;systems analysis","requirements quality;requirements engineering artifact;project goals;stakeholders","","1","","15","","11 Jan 2018","","","IEEE","IEEE Magazines"
"Automated Testing of Simulation Software in the Aviation Industry: An Experience Report","V. Garousi; S. Tasli; O. Sertel; M. Tokgoz; K. Herkiloglu; H. F. E. Arkin; O. Bilir","Software Engineering, Wageningen University; HAVELSAN; HAVELSAN; HAVELSAN; HAVELSAN; HAVELSAN; HAVELSAN","IEEE Software","17 Jun 2019","2019","36","4","63","75","An industry-academia collaboration developed a test automation framework for aviation simulation software. The technology has been successfully deployed in several test teams.","1937-4194","","10.1109/MS.2018.227110307","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8356168","automated testing;test automation;simulation software;aviation industry","Object recognition;Monitoring;Software testing;Aerospace and electronic systems","aerospace computing;aerospace industry;aerospace simulation;program testing","automated testing;aviation industry;experience report;industry-academia collaboration;test automation framework;aviation simulation software;test teams","","3","","22","","8 May 2018","","","IEEE","IEEE Magazines"
"Overcoming Challenges With Continuous Integration and Deployment Pipelines: An Experience Report From a Small Company","V. Debroy; S. Miller","Software Engineering, AT&T, Dallas, Texas United States; Dottid, United States","IEEE Software","15 Apr 2020","2020","37","3","21","29","We moved from a monolithic to a microservice-based architecture for the next generation of our applications at Varidesk. This initiative created challenges such as the inability to scale. In this article, we detail how we tackled the problems.","1937-4194","","10.1109/MS.2019.2947004","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8866741","Microservices;Automation;Cloud computing;DevOps;Continuous Integration;Continuous Deployment;Containerization;Orchestration","Software development management;Computer architecture;Cloud computing;Task analysis;Companies","computer centres;maintenance engineering;power system reliability;service-oriented architecture;solar cell arrays;solar power;solar power stations","microservice-based architecture;deployment pipelines;continuous integration;Varidesk","","","","15","","14 Oct 2019","","","IEEE","IEEE Magazines"
"Automatic Recovery of Missing Issue Type Labels","F. Elzanaty; C. Rezk; S. Lijbrink; W. van Bergen; M. Cote; S. McIntosh","Electrical And Computer Engineering, McGill University, Montreal, H3A 0E9 Quebec, Canada; Software Engineering, McGill University, Montreal, H3A 0E9 Quebec, Canada; Production Engineering, Shopify, Inc., Ottawa, K2P 1L4 Ontario, Canada; Production Engineering, Shopify, Inc., Ottawa, K2P 1L4 Ontario, Canada; Production Engineering, Shopify, Inc., Ottawa, K2P 1L4 Ontario, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, N2L 3G1 Ontario, Canada","IEEE Software","19 Apr 2021","2021","38","3","35","42","Ag ile software organizations empower developers to make appropriate decisions rather than enforce adherence to a process, resulting in incomplete and noisy data in software archives. Since software analytics techniques are trained using this data, automated techniques are required to recover it.","1937-4194","","10.1109/MS.2020.3004060","Natural Sciences and Engineering Research Council of Canada; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121712","","Data models;Computer bugs;Organizations;Feature extraction;Manuals;Training","","","","","","14","IEEE","19 Jun 2020","","","IEEE","IEEE Magazines"
"What We Know About Smells in Software Test Code","V. Garousi; B. Kucuk; M. Felderer","Software Engineering, Wageningen University; Proven Information Technologies Ltd.; University of Innsbruck, Austria","IEEE Software","16 Apr 2019","2019","36","3","61","73","Test smells are poorly designed tests and negatively affect the quality of test suites and production code. We present the largest catalog of test smells, along with a summary of guidelines, techniques, and tools used to deal with test smells.","1937-4194","","10.1109/MS.2018.2875843","Scientific and Technological Research Council of Turkey; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501942","Software testing;test automation;test scripts;test smells;test anti-patterns;multivocal literature review;systematic literature review","Software testing;Automation;Software development management;Bibliographies;Encoding;Guidelines;Software tools","program testing;software maintenance;source code (software)","software test code;test suites;production code;catalog;test smells","","2","","23","","21 Oct 2018","","","IEEE","IEEE Magazines"
"On Integrating Design Thinking for Human-Centered Requirements Engineering","J. Hehn; D. Mendez; F. Uebernickel; W. Brenner; M. Broy","Information Management, University of St. Gallen, St. Gallen, Switzerland; Software Engineering Research Lab, Blekinge Institute of Technology, Karlskrona, Blekinge, Sweden; Hasso Plattner Institute, University of Potsdam, Potsdam, Brandenburg, Germany; Information Management, University of St. Gallen, St. Gallen, Switzerland; Technical University of Munich, Germany","IEEE Software","11 Feb 2020","2020","37","2","25","31","We elaborate on the possibilities and needs to integrate design thinking into requirements engineering, drawing from our research and project experiences. We suggest three approaches for tailoring and integrating design thinking and requirements engineering with complementary synergies and point at open challenges for research and practice.","1937-4194","","10.1109/MS.2019.2957715","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8922700","Design Thinking;Requirements Engineering","Requirements engineering;Prototypes;Software design;Design methodology;Organizations","formal specification;formal verification;systems analysis","human-centered requirements engineering;project experiences;design thinking","","3","","10","","4 Dec 2019","","","IEEE","IEEE Magazines"
"Software Reuse in the Era of Opportunistic Design","T. Mikkonen; A. Taivalsaari","Software Engineering, University of Helsinki; Nokia Bell Labs","IEEE Software","16 Apr 2019","2019","36","3","105","111","Opportunistic design, an approach in which people develop new software systems by routinely reusing and combining components that were not designed to be used together, has become very popular. This emergent pattern places focus on largescale reuse and developer convenience with the developers ""trawling"" for most suitable open source components and modules online. The availability of open source assets for almost all imaginable domains has led to software systems in which the visible application code, as written by the application developers themselves, forms only the ""tip of the iceberg,"" compared to the reused bulk that remains mostly unknown to the developers. The actual reuse takes place in an ad hoc, mix-and-match fashion. In this article, we take a look at this increasingly popular approach in light of our industry experiences. We argue that challenges associated with such a development model are quite different from traditional software development and reuse.","1937-4194","","10.1109/MS.2018.2884883","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693072","","Cloud computing;Software systems;Open source software;Computer architecture;Software reusability","Internet;software reliability;software reusability","software reuse;opportunistic design;software systems;emergent pattern places focus;largescale reuse;developer convenience;suitable open source components;modules online;open source assets;imaginable domains;visible application code;application developers;reused bulk;increasingly popular approach;development model;traditional software development","","2","","22","","16 Apr 2019","","","IEEE","IEEE Magazines"
"IEEE 2430 Non-Functional Sizing Measurements: A Numerical Placebo","A. Abran","Software Engineering & Information Technology, Ecole de technologie superieure, Montreal, Quebec, Canada","IEEE Software","19 Apr 2021","2021","38","3","113","120","The IEEE 2430 measurement design fails primary school mathematics and produces numerical noise rather than a number with metrological properties required in engineering. This article presents an alternative approach to nonfunctional requirement sizing utilizing the COSMIC ISO 19761 method.","1937-4194","","10.1109/MS.2020.3028061","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9210110","IEEE 2430™;non-functional requirements;NFR;SNAP;COSMIC;Function Points;metrology","Measurement units;Size measurement;Complexity theory;Software measurement;ISO Standards;Current measurement","","","","","","15","IEEE","30 Sep 2020","","","IEEE","IEEE Magazines"
"An Exploratory Study of Machine Learning Model Stores","M. Xiu; Z. M. J. Jiang; B. Adams","Electrical Engineering and Computer Science, York University, Toronto, Ontario, Canada; Electrical Engineering and Computer Science, York University, Toronto, Ontario, Canada; Software Engineering, Queen’s University, Kingston, Ontario, Canada","IEEE Software","23 Dec 2020","2021","38","1","114","122","Several organizations have introduced stores that provide public access to pretrained machine learning models and infrastructure. We examine three of them and compare the information they provide against two mobileapp stores and among themselves.","1937-4194","","10.1109/MS.2020.2975159","Natural Sciences and Engineering Research Council of Canada; Institut de Valorisation des Données; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9003231","","Training;Software;Machine learning;Documentation;Data models;Computational modeling","learning (artificial intelligence);mobile computing;software quality;user interfaces","pretrained machine learning models;mobileapp stores;machine learning model stores;organizations;public access","","","","15","IEEE","19 Feb 2020","","","IEEE","IEEE Magazines"
"The Online Controlled Experiment Lifecycle","A. Fabijan; P. Dmitriev; H. Holmstrom Olsson; J. Bosch","Malmo University, Malmo, Sweden; Outreach, Seattle, Washington United States; Computer Science and Media Technology, Malmo University, Malmo, Sweden; Software Engineering, Chalmers University of Technology, Goteborg, Sweden","IEEE Software","11 Feb 2020","2020","37","2","60","67","Unlike other techniques for learning from customers, online controlled experiments (OCEs) establish an accurate and causal relationship between a change and the impact observed. We show that OCEs help optimize infrastructure needs and aid in project planning and measuring team efforts. We conclude that product development should fully integrate the experiment lifecycle to benefit from the OCEs.","1937-4194","","10.1109/MS.2018.2875842","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8501922","Data-driven development;A/B tests;online controlled experiments;experiment lifecycle","Software design;Companies;Software development management;Computer science;Product development;Media;Planning;Market research;Customer satisfaction","consumer behaviour;product development;team working","OCE;accurate relationship;causal relationship;online controlled experiment lifecycle;learning;project planning;team efforts","","1","","16","","21 Oct 2018","","","IEEE","IEEE Magazines"
"Visualizing Change in Agile Safety-Critical Systems","J. Cleland-Huang; A. Agrawal; M. Vierhauser; C. Mayr-Dorn","Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana 46556 United States; Computer Science and Engineering, University of Notre Dame, Notre Dame, Indiana 46556 United States; Software Engineering, Johannes Kepler Universitat Linz, Linz, 4040 Linz, Austria; Software and Systems Engineering, Johannes Kepler Universitat Linz, Linz, 4040 Linz, Austria","IEEE Software","19 Apr 2021","2021","38","3","43","51","High dependability software systems must be developed and maintained using rigorous safety-assurance practices. By leveraging traceability, we can visualize and analyze changes as they occur, mitigate potential hazards, and support greater agility.","1937-4194","","10.1109/MS.2020.3000104","Austrian Science Fund; United States National Science Foundation; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9108244","Agility;Safety-Critical Systems;Visualization;Software Traceability","Hazards;Software;Visualization;Drones;Software safety;Mission critical systems","","","","","","16","IEEE","4 Jun 2020","","","IEEE","IEEE Magazines"
"Agile Scalability Engineering: The ScrumScale Method","G. Brataas; G. K. Hanssen; N. Herbst; A. van Hoorn","Process Innovation, SINTEF Digital, Trondheim, Trondelag, Norway; Process Innovation, SINTEF Digital, Trondheim, Trondelag, Norway; Software Engineering, University of Wurzburg, Germany; Software Technology, University of Stuttgart, Stuttgart, Germany","IEEE Software","21 Aug 2020","2020","37","5","77","84","Scalability is a property that must be carefully designed into a system. A case study in the largest Norwegian public portal, Altinn, illustrates how developers and scalability experts improved scalability and spent less time during scalability testing. With minor adjustments to an agile development process, stakeholders spend more up-front time together.","1937-4194","","10.1109/MS.2019.2923184","Deutsche Forschungsgemeinschaft; Norges Forskningsråd; German Federal Ministry of Education and Research; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736723","","Scalability;Agile software development;Stakeholders;Databases;Collaboration;Finance;Computer crashes","information retrieval;portals;probability;software development management;software prototyping","agile scalability engineering;ScrumScale method;largest Norwegian public portal;scalability testing;agile development process","","","","15","CCBY","14 Jun 2019","","","IEEE","IEEE Magazines"
"Understanding the Working Time of Developers in IT Companies in China and the United States","J. Zhang; Y. Chen; Q. Gong; X. Wang; A. Y. Ding; Y. Xiao; P. Hui","Fudan University, China; Fudan University, China; Fudan University, China; Fudan University, China; Delft University of Technology, The Netherlands; Aalto University, Finland; University of Helsinki, Finland, and Hong Kong University of Science and Technology, China","IEEE Software","15 Feb 2021","2021","38","2","96","106","We identified three temporal patterns shown in commit activities among Chinese and American companies and found that Chinese businesses are more likely to follow long work hours than American ones. We also conducted a survey on the trends of, reasons for, and results of overtime work. Our study could provide references for developers to choose workplaces and for companies to make regulations.","1937-4194","","10.1109/MS.2020.2988022","National Natural Science Foundation of China; CERNET Innovation Project; Research Grants Council of Hong Kong; 5GEAR project; FIT project from the Academy of Finland; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068220","working time of developers;overtime;IT company;China;United States;GitHub","Companies;Rhythm;Software;Time-frequency analysis;Social network services;Software engineering;Information technology","human resource management;organisational aspects","United States;temporal patterns;Chinese companies;American companies;overtime work;IT companies;workplaces;online developers","","2","","20","IEEE","15 Apr 2020","","","IEEE","IEEE Magazines"
"Bumps in the Code: Error Handling During Software Development","T. Lopez; H. Sharp; M. Petre; B. Nuseibeh","School of Computing and Communications, The Open University, Milton Keynes, MK7 6AA Milton Keynes, United Kingdom of Great Britain and Northern Ireland; School of Computing and Communications, The Open University, Milton Keynes, MK7 6AA Buckinghamshire, United Kingdom of Great Britain and Northern Ireland; Dept of Computing, Open University, Milton Keynes, MK7 6AA Buckinghamshire, United Kingdom of Great Britain and Northern Ireland; School of Computing and Communications, Open University, Milton Keynes, Buckinghamshire, United Kingdom of Great Britain and Northern Ireland","IEEE Software","19 Apr 2021","2021","38","3","26","34","Problems come up during software development all the time. When developers hit these bumps, they must figure out what has gone wrong. Findings from three studies suggest that the way developers handle errors contributes to professional growth.","1937-4194","","10.1109/MS.2020.3024981","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9200759","","Task analysis;Software engineering;Computer bugs;Software tools;Software development management;Problem-solving","","","","","","15","IEEE","18 Sep 2020","","","IEEE","IEEE Magazines"
"Digital Transformation - A Primer for Practitioners","G. Doukidis; D. Spinellis; C. Ebert","Management Science and Technology, Athens University of Economics and Business, Greece; Management Science and Technology, Athens University of Economics and Business, Greece; Vector Consulting Services","IEEE Software","21 Aug 2020","2020","37","5","13","21","Digital Transformation (DX) has revolutionized entire industries, propelled IT start-ups to stratospheric stock market valuations, and is sustaining legions of consultants evangelizing its message. Yet, beyond the creative disruption, hype, and lip service, we see that many organizations ignore or misapply its principles, ideas, and methods. This gap between theory and practice raises an important responsibility for software engineers and particularly for requirements engineers and software architects. If as a professional you specify and design software-intensive systems that ignore how modern digital technology radically transforms customer experience, business processes, business models, and whole organizations, you are short-changing your employer or client. Based on our industry consulting, government service, and volunteering experience, we provide a taxonomy, a road map, and examples of DX opportunities that will allow you to spot and exploit them.","1937-4194","","10.1109/MS.2020.2999969","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173638","","Biological system modeling;Software engineering;Companies;Training data;Modeling;Digital systems","","","","1","","8","","21 Aug 2020","","","IEEE","IEEE Magazines"
"Fuzzing: Challenges and Reflections","M. Boehme; C. Cadar; A. ROYCHOUDHURY","Faculty of IT, Monash University, Clayton, Victoria, Australia; Department of Computing, Imperial College London, London, SW7 2AZ London, United Kingdom of Great Britain and Northern Ireland; Computer Science, National University of Singapore, Singapore, 117417 Singapore, Singapore","IEEE Software","19 Apr 2021","2021","38","3","79","86","We summarize the open challenges and opportunities for fuzzing and symbolic execution as they emerged in discussions among researchers and practitioners in a Shonan Meeting and that were validated in a subsequent survey.","1937-4194","","10.1109/MS.2020.3016773","Australian Research Council; National Research Foundation Singapore; Engineering and Physical Sciences Research Council; H2020 European Research Council; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9166552","","Fuzzing;Computer bugs;Software engineering;Security;Industries","","","","","","22","CCBY","13 Aug 2020","","","IEEE","IEEE Magazines"
"Can a Machine Learn Through Customer Sentiment?: A Cost-Aware Approach to Predict Support Ticket Escalations","C. Werner; Z. S. Li; D. Damian","University of Victoria, British Columbia, Canada; University of Victoria, British Columbia, Canada; Computer Science, University of Victoria, British Columbia, Canada","IEEE Software","15 Aug 2019","2019","36","5","38","45","Given the connection between customer happiness and support ticket escalation, we describe an approach that 1) analyzes the emotions in conversations between a customer and a support analyst and 2) provides organizations with a cost-based mechanism to evaluate machine-learning algorithms trained on emotion-related features to predict support ticket escalations.","1937-4194","","10.1109/MS.2019.2923408","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8737665","Sentiment analysis;Natural language;Affective Computing;Machine learning;Modeling and prediction;cost-sensitive learning;data mining;defect escalation;machine learning;software defect escalation prediction","Training data;Software engineering;Sentiment analysis;Machine learning algorithms;Data mining;Emotion recognition","customer services;learning (artificial intelligence)","customer sentiment;cost-aware approach;customer happiness;cost-based mechanism;machine-learning algorithms;support ticket escalations;emotion-related features","","2","","16","","17 Jun 2019","","","IEEE","IEEE Magazines"
"Think Your Artificial Intelligence Software Is Fair? Think Again","R. K. E. Bellamy; K. Dey; M. Hind; S. C. Hoffman; S. Houde; K. Kannan; P. Lohia; S. Mehta; A. Mojsilovic; S. Nagar; K. N. Ramamurthy; J. Richards; D. Saha; P. Sattigeri; M. Singh; K. R. Varshney; Y. Zhang","IBM Research, Yorktown Heights, New York United States; IBM Research, New Delhi, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Bangalore, India; IBM Research, Bangalore, India; IBM Research, Bangalore, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Bangalore, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Bangalore, India; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States; IBM Research, Yorktown Heights, New York United States","IEEE Software","17 Jun 2019","2019","36","4","76","80","Today, machine-learning software is used to help make decisions that affect people's lives. Some people believe that the application of such software results in fairer decisions because, unlike humans, machine-learning software generates models that are not biased. Think again. Machine-learning software is also biased, sometimes in similar ways to humans, often in different ways. While fair model- assisted decision making involves more than the application of unbiased models-consideration of application context, specifics of the decisions being made, resolution of conflicting stakeholder viewpoints, and so forth-mitigating bias from machine-learning software is important and possible but difficult and too often ignored.","1937-4194","","10.1109/MS.2019.2908514","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738152","","Machine learning;Software engineering;Measurement;Software algorithms;Software testing","decision making;learning (artificial intelligence)","artificial intelligence software;machine-learning software;forth-mitigating bias;conflicting stakeholder viewpoints;unbiased models;fair model-assisted decision making","","3","","20","","17 Jun 2019","","","IEEE","IEEE Magazines"
"Shockingly Simple:""KEYS"" for Better AI for SE","T. Menzies","North Carolina State University, Raleigh, North Carolina 27695 United States","IEEE Software","15 Feb 2021","2021","38","2","114","118","As 2020 drew to a close, I was thinking about what lessons we have learned about software engineering (SE) for artificial intelligence (AI)-things that we can believe now but, in the last century, would have seemed somewhat shocking. One very surprising lesson, at least for me, is the success of the very complex and very simple. At the complex end, there is now much evidence for the value of deep learners for high-dimensional software engineering problems. For example, consider signal processing for autonomous cars. When reasoning over (say) 10,000 wavelets collected from a vision system, then deep learning can automate much of the engineering required to cover all those data.","1937-4194","","10.1109/MS.2020.3043014","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354395","","Artificial intelligence","","","","","","25","IEEE","15 Feb 2021","","","IEEE","IEEE Magazines"
"A Novel Approach For Search-Based Program Repair","L. Trujillo; O. M. Villanueva; D. E. Hernández","Tecnlogico Nacional de Mexico/IT de Tijuana, Tijuana, Mexico; Tecnlogico Nacional de Mexico/IT de Tijuana, Tijuana, Mexico; Tecnlogico Nacional de Mexico/IT de Tijuana, Tijuana, Mexico","IEEE Software","","2021","PP","99","0","0","In search-based software engineering, automatic bug repair methods use use an objective function that measures a patch’s quality to guide the search. This work presents results of the first study that focuses on solution novelty instead. Novelty search works under the assumption that most real-world problems are intrinsically difficult. By shifting how program patches are evaluated, away from quality and towards novelty, this technique increases a bug repair system’s ability to explore the solution space, produce more viable patches and repair more bugs.","1937-4194","","10.1109/MS.2021.3070552","Consejo Nacional de Ciencia y Tecnología; Tecnologico Nacional de México; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9393496","","Computer bugs;Search problems;Maintenance engineering;Standards;Linear programming;Statistics;Space exploration","","","","","","","IEEE","1 Apr 2021","","","IEEE","IEEE Early Access Articles"
"Towards an Adaptive Software Architecture for Archetype-Based Healthcare Applications","M. A. Pereira da Silva; V. Cesário Times; A. M. Costa da Araüjo; P. Caetano da Silva","Center for Informatics, Federal University of Pernambuco, Recife, Pernambuco, Brazil; Center for Informatics, Federal University of Pernambuco, Recife, Pernambuco, Brazil; Department of Information Systems, Federal University of Alagoas, Penedo, Alagoas, Brazil; Master's Program in Computing, Salvador University, Salvador, BA, Brazil","IEEE Software","","2021","PP","99","0","0","Self-adaptation gives software systems the ability to adjust their behavior or structure in changing environments such as the health software domain. However, adaptability significantly complicates software implementation and brings great challenges to software engineering. This paper proposes an Adaptive Healthcare Software Architecture (AHSA), which is based on international health standards and offers at-runtime adaptation. Three components (Dynamic Linker, Runtime Locator, and Autonomous Component) have been specified to compose AHSA. A tool called AdaptiveHIS has also been developed to dynamically generate AHSA components, and this generation is exemplified through an algorithm. Within two real-world COVID-19 pandemic healthcare scenarios, an assessment compared the adaptability of AHSA and other software architectures built using state-of-art tools. Results based on the level of system adaptability metric respectively showed that AHSA offered 20% and 72% more adaptability in the two real-world scenarios.","1937-4194","","10.1109/MS.2021.3070418","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9391997","Healthcare Applications;Adaptability;Software Architecture;openEHR Archetype","Software;Tools;Runtime;Medical services;Graphical user interfaces;Software architecture;Standards","","","","","","","IEEE","31 Mar 2021","","","IEEE","IEEE Early Access Articles"
"Mind the Gap: On the Relationship Between Automatically Measured and Self-Reported Productivity","M. Beller; V. Orgovan; S. Buja; T. Zimmermann","Probability, Facebook Inc, Menlo Park, California 94025 United States; Microsoft Corp, Redmond, Washington 98052 United States; Microsoft Corp, Redmond, Washington 98052 United States; Research, Microsoft Corporation, Redmond, Washington 98052 United States","IEEE Software","","2020","PP","99","0","0","To improve software developers’ productivity has been the holy grail of software engineering research. But before we can claim to have improved it, we must first be able to measure productivity. This is far from trivial. In fact, two separate research lines on software engineers’ productivity have co-existed almost in complete isolation for a long time: automated product and process measures on the one hand and self-reported or perceived productivity on the other hand. In this article, we bridge the gap between the two with an empirical study of 81 software developers at Microsoft.","1937-4194","","10.1109/MS.2020.3048200","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9311217","","Productivity;Telemetry;Software;Particle measurements;Encoding;Data models;Atmospheric measurements","","","","","","","IEEE","30 Dec 2020","","","IEEE","IEEE Early Access Articles"
"John Doran on Fixing a Broken Development Process","J. Jung",Security Industry,"IEEE Software","29 Nov 2018","2018","35","6","77","80","In this excerpt from Episode 332 of Software Engineering Radio, host Jeremy Jung talks with guest John Doran about his experiences repairing the engineering process at Phorest, a Dublin-based company that books appointments in the hair and beauty salon industry. In this excerpt, Doran discusses how technical debt threatened to sink the company, how the company diagnosed the problems, and how it fixed them by changing technology, process, and culture. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2018.4321233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552646","John Doran;Phorest;technical debt;continuous integration;CI;software engineering;software development;Software Engineering Radio","Interviews;Software development;Software engineering","software engineering","broken development process;technical debt;Dublin-based company;Phorest;engineering process;Software Engineering Radio","","","","0","","29 Nov 2018","","","IEEE","IEEE Magazines"
"Collaborative Modeling in Software Engineering","H. Muccini; J. Bosch; A. van der Hoek","University of L’Aquila; Chalmers University of Technology; University of California, Irvine","IEEE Software","29 Nov 2018","2018","35","6","20","24","The topic of collaborative modeling has long been relevant in software. Collaborative facilities are part and parcel of modeling tools, and every day hundreds of thousands of developers engage in collaborative modeling of some sort. This theme issue contains four articles spanning a variety of areas in collaborative modeling. The first article offers a somewhat classic approach to handling collaborative-design conflicts. The second one addresses securely sharing only parts of a collaborative model. The third discusses whether distance still matters in collaborative design. The fourth introduces a timely approach to collaborative modeling through chatbots.","1937-4194","","10.1109/MS.2018.4321244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552641","collaborative modeling;collaborative software engineering;collaborative design;chatbots;social networks;software engineering;software development","Special issues and sections;Software engineering;Software development;Collaborative software","","","","","","9","","29 Nov 2018","","","IEEE","IEEE Magazines"
"50 Years of Software Engineering","H. Erdogmus; N. Medvidović; F. Paulisch",Carnegie Mellon University; University of Southern California; Siemens Healthineers,"IEEE Software","27 Sep 2018","2018","35","5","20","24","This theme issue on software engineering’s 50th anniversary presents a range of contributions—from pioneers and well-established software engineers, to younger contributors whose imprint on the field is perhaps yet to come. These contributions come in a variety of formats that provide a balanced look at our field’s past, present, and likely future. The topics include both timeless ideas that appeared to fade for a while, only to pop up again in a new incarnation, and entirely new paradigms that have disrupted the field.","1937-4194","","10.1109/MS.2018.3571240","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474511","software engineering;software development","Special issues and sections;Software engineering;History;IEEE publishing","","","","1","","7","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Ben Sigelman on Distributed Tracing [Software Engineering Radio]","R. Blumen",NA,"IEEE Software","14 Jan 2019","2019","36","1","98","101","We bring you this month one of my own shows, Software Engineering Radio Episode 337, featuring guest Ben Sigelman. Sigelman is the cofounder and chief executive officer of LightStep, where he is building reliability management software, and a coauthor of the OpenTracing project. We discuss tracing in general and distributed tracing, which involves the propagation of tracing across process boundaries in a distributed system. The discussion covers the basics of tracing, how distributed tracing is different, the instrumentation required to collect tracing data, what is collected and how, where the data go, and use cases for the data itself, including monitoring, analytics, and capacity planning. The excerpt presented here contains about one half of the interview, with the remaining half available for download from our website or via RSS.","1937-4194","","10.1109/MS.2018.2880598","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611462","","Interviews;Software engineering;Distributed databases;Reliability engineering","","","","","","0","","14 Jan 2019","","","IEEE","IEEE Magazines"
"Release Engineering 3.0","B. Adams; S. Bellomo; C. Bird; B. Debić; F. Khomh; K. Moir; J. O’Duinn",Polytechnique Montreal; Software Engineering Institute; Microsoft; Google; Polytechnique Montreal; Mozilla; CivicActions.com,"IEEE Software","12 Mar 2018","2018","35","2","22","25","This theme issue aims to stimulate industry practitioners and researchers to reflect on what future release-engineering practices and tools could look like and how they could evolve out of more-advanced forms of current release engineering. Each of the four articles in this issue highlights a different facet of release engineering, with two articles focusing on fundamental technologies and practices and two articles discussing new application domains.","1937-4194","","10.1109/MS.2018.1661327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314150","release engineering;continuous experimentation;build systems;continuous delivery;over-the-air software updates;swarm robots;software engineering;software development","Special issues and sections;Software engineering;Product life cycle management;Software development management","","","","2","","1","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Gender, Sentiment and Emotions, and Safety-Critical Systems","J. Carver; R. Capilla; B. Penzenstadler; A. Serebrenik; A. Valdezate","University of Alabama; Rey Juan Carlos University of Madrid; California State University, Long Beach; Eindhoven University of Technology; Ibermática and Rey Juan Carlos University of Madrid","IEEE Software","29 Nov 2018","2018","35","6","16","19","This issue’s article reports from the 40th International Conference on Software Engineering (ICSE 18) and the 17th International Conference on Software Reuse (ICSR 18). The ICSE papers focus on sociotechnical issues related to gender and sentiment or emotion. The ICSR paper focuses on safety-critical systems.","1937-4194","","10.1109/MS.2018.4321243","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552648","40th International Conference on Software Engineering;17th International Conference on Software Reuse;gender;gender stereotypes;GenderMag;sentiment;sentiment analysis;Stack Overflow;Senti4SD;software product lines;SPL;software product line engineering;SPLE;variability management;safety-critical systems;software engineering education;software reuse;software development;software engineering;Practitioners’ Digest","","","","","1","","","","29 Nov 2018","","","IEEE","IEEE Magazines"
"Nate Taggart on Serverless","K. Bhatia",BCG Digital Ventures,"IEEE Software","6 Jul 2018","2018","35","4","101","104","In this excerpt from Software Engineering Radio, Nate Taggart, cofounder and CEO of Stackery, discusses serverless—the ability to purchase function as a service in which the cloud provider assumes responsibility for providing a server and an execution environment on demand to run a piece of code. To hear the full interview, visit www.se-radio.net or access our archives via RSS at feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2018.2801544","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405632","Nate Taggart;serverless;Software Engineering Radio;software engineering;software development","Software engineering;Computational modeling;FAA","","","","1","","","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Being a Software Developer","D. Spinellis",Athens University of Economics and Business,"IEEE Software","6 Jul 2018","2018","35","4","4","7","If you want to be a professional developer, you'll need to continuously invest substantial time to acquire highly specialized knowledge and develop diverse cognitive and interpersonal skills. A university can kindle your passion and provide incentives to expand your horizons, and your employer may support specialized training. But in the end, becoming a professional software developer is your decision and responsibility.","1937-4194","","10.1109/MS.2018.2801555","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405631","professional development;career development;job skills;From the Editor;software engineering;software development","","cognition;professional aspects;software engineering","interpersonal skills;specialized training;professional software developer;software developer;cognitive skills;knowledge acquisition","","1","","1","","6 Jul 2018","","","IEEE","IEEE Magazines"
"The Challenges and Practices of Release Engineering","D. Spinellis",Athens University of Economics and Business,"IEEE Software","12 Mar 2018","2018","35","2","4","7","Release-engineering teams are responsible for building and delivering software to the customer and for enabling its development on an industrial scale. This has always been a tall order. In modern software development, a number of factors make release engineering even more challenging. Thankfully, following a handful of established practices lets us address these challenges and deliver software reliably, dependably, and efficiently.","1937-4194","","10.1109/MS.2018.1661312","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314162","release engineering;software engineering;software development;From the Editor","","software development management;software engineering;software reliability","release-engineering teams;industrial scale;modern software development","","","","3","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Complexity: Let's Not Make This Complicated","A. Hindle",NA,"IEEE Software","21 Feb 2019","2019","36","2","130","132","This article discusses the simplicity in agile software, the relationship between architectural patterns and complexity, the value of simplicity in software engineering research, and why we should refer to the formerly perceived complexity in software as complicated software. Complex software in software engineering typically refers to complicated code. Most measures of complexity are measures of information content in the code, whether it is McCabe's cyclomatic complexity measuring branching or Halstead's volume measuring the information within a block of code- Halstead's volume is very similar to the entropy of tokens multiplied by the number of tokens in a code block.","1937-4194","","10.1109/MS.2018.2883875","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648275","","Software engineering;Complexity theory;Software design","software architecture;software prototyping;source code (software)","entropy;code block;Halstead's volume;McCabe's cyclomatic complexity;software engineering;complicated software;perceived complexity;software engineering research;architectural patterns;architectural complexity;agile software","","","","5","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Sentiment and Emotion in Software Engineering","N. Novielli; A. Serebrenik",University of Bari; Eindhoven University of Technology,"IEEE Software","15 Aug 2019","2019","36","5","6","23","We are glad to present the ""Sentiment and Emotion in Software Engineering"" special issue of <italic>IEEE Software</italic>. In recent years, this topic has gained attention from both the research community and industry. Indeed, academic researchers have organized a number of highly successful workshops, such as the International Workshop on Emotional Awareness in Software Engineering (SEmotion) in 2016-2019. The topic was also explored in a special issue of <italic>The Journal of Systems and Software</italic>.<sup>1</sup> Both small and large companies have considered emotions in some aspects of their work. For example, Microsoft considers emotions in the context of inclusive hiring and support of neurodiverse developers.<sup>2</sup> Meanwhile, SkyTV aims at enhancing productivity of teams<sup>3</sup> by increasing their emotional awareness. Yet another company, source{d}, designs techniques for detection of sentiment in source-code repositories.<sup>4</sup>","1937-4194","","10.1109/MS.2019.2924013","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802324","","Special issues and sections;Emotion recognition;Sentiment analysis;Computational linguistics;Information analysis;Machine learning;Software development management","","","","6","","11","","15 Aug 2019","","","IEEE","IEEE Magazines"
"Ur-Technical Debt","G. Fairbanks","Software Engineering, Google","IEEE Software","19 Jun 2020","2020","37","4","95","98","These days, everyone uses the term technical debt. It's so prevalent that we shorten it to tech debt tech debt or even just TD. Tech debt is also hacky code, code written by novices, code written without consideration of software architecture (so-called big balls of mud), and code with antipatterns flagged by static analysis tools.","1937-4194","","10.1109/MS.2020.2986613","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121630","","Computer architecture;Software engineering;Codes","program diagnostics;source code (software)","static analysis tools;hacky code;tech debt;technical debt","","2","","2","","19 Jun 2020","","","IEEE","IEEE Magazines"
"Under the Covers of IEEE Software","D. Spinellis",Athens University of Economics and Business,"IEEE Software","25 Dec 2017","2018","35","1","4","7","Ecosystems that thrive are those whose members contribute more than they take away. Judging by the growth of its offerings and volunteers, IEEE Software is clearly such a case: over the past year, more than 1,500 people have contributed to it as authors, reviewers, editors, podcast hosts and guests, advisors, curators, and many other roles. Here, Editor in Chief Diomidis Spinellis discusses what makes Software tick and how can you participate in its community of volunteers.","1937-4194","","10.1109/MS.2017.4541035","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239946","IEEE Software;Software Engineering Radio;SE-Radio;IEEE Software Blog;software engineering;software development;From the Editor","","","","","1","","1","","25 Dec 2017","","","IEEE","IEEE Magazines"
"The Success of a Heavenly Marriage","D. Spinellis",Athens University of Economics and Business,"IEEE Software","27 Sep 2018","2018","35","5","3","6","For a field that sprang out of a so-called software crisis, software engineering has done rather well over the past half-century. By riding on the coattails of Moore’s law, it has progressed phenomenally. The field’s achievements are visible through the large, complex, yet effective software systems that power our everyday lives. By looking at the drivers of the field’s progress and taking stock of its achievements, we can appreciate the challenges in front of us and confidently plan for the future. This article is part of a theme issue on software engineering’s 50th anniversary.","1937-4194","","10.1109/MS.2018.3571251","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474499","software engineering;software development;From the Editor","","","","","","","0","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Editorial from the New Editor in Chief","N. Medvidović",NA,"IEEE Transactions on Software Engineering","8 Jan 2018","2018","44","1","3","4","Presents the introductory editorial for this issue of the publication.","1939-3520","","10.1109/TSE.2017.2778899","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249710","","","","","","1","","","","8 Jan 2018","","","IEEE","IEEE Journals"
"State of the Journal","M. Dwyer",NA,"IEEE Transactions on Software Engineering","8 Jan 2018","2018","44","1","1","2","Presents the state of the journal for this issue of the publication.","1939-3520","","10.1109/TSE.2017.2778898","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249614","","","","","","","","","","8 Jan 2018","","","IEEE","IEEE Journals"
"Editorial: State of the Journal","N. Medvidovic",NA,"IEEE Transactions on Software Engineering","8 Jan 2019","2019","45","1","1","1","Presents the introductory editorial for this issue of the publication.","1939-3520","","10.1109/TSE.2018.2885501","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8605418","","","","","","","","0","","8 Jan 2019","","","IEEE","IEEE Journals"
"The Editor’s Retrospective","D. Spinellis",Athens University of Economics and Business,"IEEE Software","29 Nov 2018","2018","35","6","4","7","Outgoing Editor in Chief Diomidis Spinellis reviews the past four years, looking on what went well for the magazine, what could be improved, and what the magazine’s volunteers can do to make IEEE Software an even better publication over the coming years.","1937-4194","","10.1109/MS.2018.4321238","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552645","software engineering;software development;From the Editor","","","","","","","5","","29 Nov 2018","","","IEEE","IEEE Magazines"
"Self-Evolving Software Architectures","D. Spinellis",Athens University of Economics and Business,"IEEE Software","4 May 2018","2018","35","3","4","7","Nature provides the inspiration for self-evolving software architectures that can deal with the increasing size and complexity of software systems.","1937-4194","","10.1109/MS.2018.2141027","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354428","self-evolving software;self-evolving software architecture;software architecture;software engineering;software development;From the Editor","","","","","","","2","","4 May 2018","","","IEEE","IEEE Magazines"
"Scylladb optimizes database architecture to maximize hardware performance","N. Suneja","Amazon Web Services, Palo Alto, California United States","IEEE Software","17 Jun 2019","2019","36","4","96","100","In Episode 354 of “Software Engineering Radio,” guest Avi Kivity, chief technology officer of ScyllaDB, talks with host Ninchant Suneja about ScyllaDB and what makes it a high-performance version of Cassandra, a distributed key-value data store. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http:// feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2019.2909854","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738153","","Interviews;Computer architecture;Distributed databases","database management systems;storage management","database architecture;hardware performance;Software Engineering Radio;distributed key-value data store;Cassandra","","","","0","","17 Jun 2019","","","IEEE","IEEE Magazines"
"Better Code Reviews With Design by Contract","G. Fairbanks","Software Engineering, Google, United States","IEEE Software","22 Oct 2019","2019","36","6","53","56","Design by contract (DBC) is a technique that improves the quality of your team's code. It yields code with both a logical and a procedural nature, where the contracts state declaratively what will happen, and the implementations procedurally cause the desired effect. The team can reason either logically, by using the contracts, or procedurally, by following the code line by line, but the former allows them to reason about far larger programs. It also creates conditions for deliberate practice so developers using DBC grow their design skills faster.","1937-4194","","10.1109/MS.2019.2934192","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880061","","Encoding;Cognition;Pragmatics;Software quality","contracts;reasoning about programs;software quality;source code (software)","DBC;design skills;code reviews;procedural nature;code line;design by contract;team code quality","","","","3","","22 Oct 2019","","","IEEE","IEEE Magazines"
"The Voice of the Developer","I. Ozkaya",Carnegie Mellon Software Engineering Institute,"IEEE Software","15 Aug 2019","2019","36","5","3","5","Developers are seldom shy about expressing how they feel about the current task at hand, especially when the task triggers stress and impacts productivity negatively:","1937-4194","","10.1109/MS.2019.2926545","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802319","","","","","","1","","8","","15 Aug 2019","","","IEEE","IEEE Magazines"
"Emerging Trends, Challenges, and Experiences in DevOps and Microservice APIs","U. Zdun; E. Wittern; P. Leitner","Software Architecture, University of Vienna, Vienna, Austria; IBM, Hamburg, Germany; Software Engineering, Chalmers University of Technology","IEEE Software","20 Dec 2019","2020","37","1","87","91","In August 2019, we organized the second Vienna Software Seminar (VSS) with the topic ""DevOps and Microservice APIs.""<sup>1</sup> Embracing the positive reception of its first iteration in 2017,<sup>2</sup> VSS is an opportunity for attendees to discuss recent software technologies, practices, and related research. The seminar's 34 participants included a mix of practitioners and academics, who were invited based on their roles and experiences. The explicit intention of the seminar was to provide ample opportunities for exchange and communication: six themed sessions consisted of one invited keynote and two lightning talks, giving different perspectives on the session?s topic and (ideally) sparking ideas for follow-up discussions. After the talks, all participants decided on subtopics for two to three breakout sessions (i.e., informal, self-organized discussions among interested participants). Breakout session topics included microservice security, tooling for application programming interface (API) evolution, serverless programming models, and identification of microservices using domaindriven design. The sessions provided opportunities for detailed discussions and identifying challenges to address in future collaborations. Toward the end of each session, all participants gathered once more to summarize the breakout discussions. Additional opportunities for communication were provided during shared lunch breaks and social events in the evenings.","1937-4194","","10.1109/MS.2019.2947982","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938118","","","","","","","","18","","20 Dec 2019","","","IEEE","IEEE Magazines"
"Interact, Collaborate, Debate","I. Ozkaya","Carnegie Mellon Software Engineering Institute, United States","IEEE Software","22 Oct 2019","2019","36","6","3","6","How information is shared has changed signifi cantly due to technology and will continue to change. The pace of innovation in and dependence on software further creates an environment in which models of knowledge production and consumption are continually challenged. Information gets distributed quicker, almost real time, through myriad available social media channels.","1937-4194","","10.1109/MS.2019.2936955","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880052","","","","","","","","6","","22 Oct 2019","","","IEEE","IEEE Magazines"
"James Smith on Software Bugs and Quality","P. Raghavan",NA,"IEEE Software","19 Apr 2021","2021","38","3","142","144","Presents an interview conducted with James Smith of Bugsnag regarding software bugs and quality. Host Priyanka Raghavan spoke with Smith on topics including causes, types, and history of bugs; user experience and environments causing different bugs; and measuring, benchmarking, and fixing bugs based on data. We provide summary excerpts below; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio ","1937-4194","","10.1109/MS.2021.3058704","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9407307","","Interviews;Computer bugs;Software engineering;Mobile applications","","","","","","0","IEEE","19 Apr 2021","","","IEEE","IEEE Magazines"
"A Manifesto for Energy-Aware Software","A. Fonseca; R. Kazman; P. Lago","Faculdade de Ciencias, Universidade de Lisboa, Portugal; University of Hawaii, Honolulu, United States; Vrije Universiteit Amsterdam, The Netherlands","IEEE Software","22 Oct 2019","2019","36","6","79","82","According to recent estimates, computing and communications could account for 20% of energy usage globally by 2025.1 This trend shows no sign of slowing. The annual growth in power consumption of Internet-connected devices is 20%. Data centers alone are now accounting for more than 3% of global emissions. Even if you are not worried about this trend on the mega scale, you are likely concerned with the power consumption of the devices in your pocket, on your wrist, and in your ears. Software, hardware, and network attributes all contribute to power usage, but little attention has been given to this topic by the information and communications technology (ICT) community.","1937-4194","","10.1109/MS.2019.2924498","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880037","","Software engineering;Energy efficiency;Energy consumption;Market research;Complexity theory;Information and communication technology","computer centres;Internet;power aware computing;power consumption","Internet-connected devices;data centers;energy-aware software;information and communications technology community;ICT community","","3","","7","","22 Oct 2019","","","IEEE","IEEE Magazines"
"Howard Chu on Lightning Memory-Mapped Database","G. Henry",SureVoIP,"IEEE Software","22 Oct 2019","2019","36","6","83","87","Gavin Henry: What's the history of LMDB [Lightning Memory-Mapped Database]?","1937-4194","","10.1109/MS.2019.2936273","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880032","","Databases;Software engineering;Computer crashes;History","","","","1","","0","","22 Oct 2019","","","IEEE","IEEE Magazines"
"Jonathan Boccara on Legacy Code","A. G. Bell",Tenable,"IEEE Software","15 Aug 2019","2019","36","5","80","84","Presents an interview conducted with Jonathan Boccara, author of The Legacy Code Programmer’s Toolbox. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2019.2922802","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8802867","","Interviews;Software engineering;Source coding;Operating systems","","","","","","0","","15 Aug 2019","","","IEEE","IEEE Magazines"
"Microservices: The Journey So Far and Challenges Ahead","P. Jamshidi; C. Pahl; N. C. Mendonça; J. Lewis; S. Tilkov",Carnegie Mellon University; Free University of Bozen-Bolzano; University of Fortaleza; ThoughtWorks; INNOQ,"IEEE Software","4 May 2018","2018","35","3","24","35","Microservices are an architectural approach emerging out of service-oriented architecture, emphasizing self-management and lightweightness as the means to improve software agility, scalability, and autonomy. This article examines microservice evolution from the technological and architectural perspectives and discusses key challenges facing future microservice developments.","1937-4194","","10.1109/MS.2018.2141039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354433","microservices;service-oriented architecture;SOA;domain-driven design;DDD;model-driven development;MDD;architectural antipatterns;legacy systems;software development;software engineering","Special issues and sections;Service computing;Software development","","","","43","","23","","4 May 2018","","","IEEE","IEEE Magazines"
"Matt Lacey on Mobile App Usability","G. Henry","SureVoIP, United Kingdom","IEEE Software","15 Feb 2021","2021","38","2","134","136","Presents an interview conducted with Matt Lacey, author of Usability Matters. Lacey discusses usability for consumers and business or in-house users. Host Gavin Henry spoke with Lacey about the six components of great app experiences, things every app should do, native apps, password managers, accessibility, feedback, telemetry, locations, nonmobile devices, examples of good and bad apps, testing, connectivity, user involvement during development, and usability and software engineering. We provide summary excerpts below; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.—Robert Blumen","1937-4194","","10.1109/MS.2020.3042424","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354393","","Interviews;Computer applications;Mobile communication","","","","","","0","IEEE","15 Feb 2021","","","IEEE","IEEE Magazines"
"Johnathan Nightingale on Scaling Engineering Management","T. Kimmel",GitPrime,"IEEE Software","16 Apr 2019","2019","36","3","120","124","In Episode 352 of “Software Engineering Radio,” guest Johnathan Nightingale talks with host Travis Kimmel about scaling engineering management. Portions not included here go into more depth about the organizational structure of engineering teams, seniority in management, career growth, management titles, predictability in management, and goals. To hear the full interview, visit http://www.se-radio.net.","1937-4194","","10.1109/MS.2019.2899530","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693083","","Interviews;Engineering management","","","","","","0","","16 Apr 2019","","","IEEE","IEEE Magazines"
"Justin Richer on OAuth","G. Henry",SureVoIP,"IEEE Software","20 Dec 2019","2020","37","1","98","100","In Episode 376 of “Software Engineering Radio,” Justin Richer, lead author of OAuth2 in Action and editor of OAuth extensions RFC 7591, 7592, and 7662, discusses the key technical features of the OAuth 2.0 protocol for authorization. Gavin Henry spoke with Richer about browser-based OAuth2, types of tokens, OpenID Connect, PKCE, JavaScript Object Notation Web Token pros and cons, where to store them, client secrets, single-page apps, mobile apps, current best practices, OAuth.XYZ, HEART, MITREid, token validation, dynamic client registration, the decision factors of the various types of authorization grants to use, and what is next for OAuth. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http:// feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2019.2949648","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938121","","Interviews;Authorization;Best practices;Token networks","","","","","","0","","20 Dec 2019","","","IEEE","IEEE Magazines"
"Boris Cherny on TypeScript","N. Black",Sleeperbot,"IEEE Software","11 Feb 2020","2020","37","2","98","100","In Episode 384 of “Software Engineering Radio,” Boris Cherny, author of Programming TypeScript, speaks with Nate Black, explaining how TypeScript can scale JavaScript projects to larger teams, larger code bases, and across devices. TypeScript is a gradually typed language, allowing you to add compile-time verification to a JavaScript project bit by bit. TypeScript aims to be practical by catching common mistakes but without adding too much burden on the programmer. Other topics include: structural typing, type refinement and programmer intuition, when to use escape hatches and how to ban them, interoperability with JavaScript, and using TypeScript with frameworks such as Angular, React, and React Native. We provide summary excerpts below; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2019.2958155","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8994835","","Java;Computer languages","","","","","","0","","11 Feb 2020","","","IEEE","IEEE Magazines"
"Chris McCord on Phoenix's LiveView Functionality","A. Conrad","Engineering, Indigo","IEEE Software","15 Apr 2020","2020","37","3","98","100","In Episode 394 of “Software Engineering Radio,” Chris McCord, creator of the Phoenix framework and author of Programming Phoenix 1.4, discusses Phoenix’s LiveView functionality. Host Adam Conrad spoke with McCord about how LiveView was created, use cases for integrating LiveView with Phoenix applications, the benefits and drawbacks of LiveView in comparison to such frameworks as React, Angular, and Vue, and the internal workings of LiveView. To hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner .com/se-radio.","1937-4194","","10.1109/MS.2020.2968207","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068368","","Interviews","","","","","","0","","15 Apr 2020","","","IEEE","IEEE Magazines"
"Jeremy Miller on Waterfall Versus Agile","J. Doolittle",NA,"IEEE Software","19 Jun 2020","2020","37","4","107","C3","Jeremy Miller is a senior software architect at Calavista Software. He is involved in open source .NET development as the author of StructureMap and Storyteller and as the lead developer of Marten. In Episode 401 of “Software Engineering Radio,” host Jeff Doolittle spoke with Miller about Waterfall versus Agile, Extreme Programming, pair programming, specialization and self-contained teams, the emergence of Scrum, YAGNI, Agile teams, reversibility, nonfunctional requirements, integration testing, and abstraction and encapsulation. We provide summary excerpts in this column; to hear the full interview, visit http://www.se-radio.net or access our archives via RSS at http://feeds.feedburner.com/se-radio.","1937-4194","","10.1109/MS.2020.2987493","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9121615","","Interviews;Software architecture","","","","1","","0","","19 Jun 2020","","","IEEE","IEEE Magazines"
"Blockchain and Smart Contract Engineering","X. Larrucea; C. Pautasso","Basque Research and Technology Alliance, TECNALIA; Software, USI Faculty of Informatics, Lugano, Switzerland","IEEE Software","21 Aug 2020","2020","37","5","23","29","Blockchains help to build trust among a decentralized network of unknown and untrusted peers who need to agree on a common protocol and trust the correctness and compatibility of the corresponding software implementations. The software engineering discipline cannot ignore this trend, as it fundamentally affects the way software is designed, developed, deployed, and delivered.1 As with the emergence of the Internet, software smart contracts for solving new classes of real-world problems, as opposed to introducing blockchains everywhere, where they may be unnecessary, or provide an inefficient and environmentally unsound solution.4","1937-4194","","10.1109/MS.2020.3000354","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9173634","","Special issues and sections;Smart contracts;Software;Bitcoin;Peer-to-peer computing;Computer architecture;Blockchain","","","","","","32","","21 Aug 2020","","","IEEE","IEEE Magazines"
"2017 Index IEEE Transactions on Software Engineering Vol. 43","",,"IEEE Transactions on Software Engineering","8 Jan 2018","2018","44","1","1","9","Presents the 2017 subject/author index for this publication.","1939-3520","","10.1109/TSE.2017.2784782","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249567","","","","","","","","","","8 Jan 2018","","","IEEE","IEEE Journals"
"Intellectual Control [Pragmatic Designer]","G. Fairbanks","Software Engineering, Google","IEEE Software","14 Jan 2019","2019","36","1","91","94","In the early days of software engineering, Edsger Dijkstra warned us not to let the size and complexity of our programs cause us to lose “intellectual control” due to the limited nature of our minds. To my knowledge, he never defined precisely what intellectual control was. Our software today is staggeringly larger than the programs of the 1960s, so does that mean we have it under our intellectual control, or did we find ways to make progress without Dijkstra's high standards? I see signs that we have some software that is under intellectual control and other software that is not. In this column, I'm going to discuss how we can recognize these two categories, what happens when engineers on a project have different attitudes about intellectual control, some advice on when we probably should insist on it, and some ideas about how we achieve it.","1937-4194","","10.1109/MS.2018.2874294","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611447","","Software engineering;Standards;Project management;Intelligent control","software engineering","software engineering;program complexity;intellectual control","","2","","1","","14 Jan 2019","","","IEEE","IEEE Magazines"
"Actionable Analytics for Software Engineering","Y. Yang; D. Falessi; T. Menzies; J. Hihn","Stevens Institute of Technology; California Polytechnic State University, San Luis Obispo; North Carolina State University; Jet Propulsion Laboratory","IEEE Software","25 Dec 2017","2018","35","1","51","53","Although intensive research on software analytics has been going on for nearly a decade, a repeated complaint in software analytics is that industrial practitioners find it hard to apply the results generated from data science. This theme issue aims to reflect on actionable analytics for software engineering and to document a catalog of success stories in which analytics has been proven actionable and useful, in some significant way, in an organization. This issue features five articles covering promising analytical methods for improving change triage, strategic maintenance, and team robustness, as well as the success stories of applying analytical tools during an organizational transformation.","1937-4194","","10.1109/MS.2017.4541039","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239931","actionable analytics;context-driven software engineering;software analytics;change triage;agile development;DevOps;software engineering;software development","","","","","4","","4","","25 Dec 2017","","","IEEE","IEEE Magazines"
"The Behavioral Science of Software Engineering and Human–Machine Teaming","I. Ozkaya","Software Engineering, Carnegie Mellon","IEEE Software","23 Oct 2020","2020","37","6","3","6","Designing and sustaining sociotechnical systems where relationships among humans, machines, and environmental aspects are intertwined is not new to software engineering. Emery and Trist1 coined the term sociotechnical systems in 1960 to draw attention to the need for people, machines, and context to all be considered when developing and sustaining these systems. Interactions and dependencies in sociotechnical systems get complex quickly as the interdisciplinary nature of such systems drive different design priorities and information flow mechanisms: sociologists see social systems, psychologists observe them as cognitive systems, computer scientists approach them as information systems, and engineers see the hardware systems.2 All of these perspectives are not only valid but also are essential elements of sociotechnical systems.","1937-4194","","10.1109/MS.2020.3019190","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238651","","","","","","","","10","","23 Oct 2020","","","IEEE","IEEE Magazines"
"Protecting the Health and Longevity of the Peer-Review Process in the Software Engineering Community","I. Ozkaya","Software Engineering, Carnegie Mellon, Pittsburg, Pennsylvania United States","IEEE Software","23 Dec 2020","2021","38","1","3","6","Peer review is the evaluation of scientific, academic, and professional work by other experts in the same field. The main purpose of the peerreview process is to maintain the integrity of the scientific process and increase the quality of the work product by providing timely, professional, and unbiased feedback. The most substantive scientific activity that relies on the success and integrity of the peer-review process is, by all means, scientific publications. All software engineering conferences and workshops as well as all journals and magazines, including IEEE Software's focus and feature articles, select which articles to publish after a peer-review process.","1937-4194","","10.1109/MS.2020.3028681","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305906","","","","","","","","8","IEEE","23 Dec 2020","","","IEEE","IEEE Magazines"
"The Golden Age of Software Engineering [From the Editor]","I. Ozkaya","Software Engineering, Carnegie Mellon University, Pittsburgh, Pennsylvania United States","IEEE Software","14 Jan 2019","2019","36","1","4","10","Presents the introductory editorial for this issue of the publication.","1937-4194","","10.1109/MS.2018.2877032","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611458","","","","","","","","7","","14 Jan 2019","","","IEEE","IEEE Magazines"
"Requirements Engineering (RE) for Social Good: RE Cares [Requirements]","A. Dekhtyar; J. Huffman Hayes; I. Hadar; E. Combs; A. Ferrari; S. Gregory; J. Horkoff; M. Levy; M. Nayebi; B. Paech; J. Payne; M. Primrose; P. Spoletini; S. Clarke; C. Brophy; D. Amyot; W. Maalej; G. Ruhe; J. Cleland-Huang; D. Zowghi","California Polytechnic University, San Luis Obispo, United States; Computer Science, University of Kentucky, United States; University of Haifa; Lexmark; Istituto di Scienza e Tecnologie dell’Informazione; Intel Corporation; Chalmers; Shenkar College of Engineering and Design; Ecole Polytechnique de Montreal, Canada; Software Engineering, Heidelberg University; University of Kentucky, United States; Intel Corporation; Kennesaw State University; Mutual Aid Alberta, Canada; Celsus Management, Inc.; University of Ottawa, Canada; University of Hamburg; University of Calgary, Canada; University of Notre Dame; Software Engineering, University of Technology Sydney, Australia","IEEE Software","14 Jan 2019","2019","36","1","86","94","As researchers and teachers and practitioners, we “software types” excel at multitasking. This, in part, led us to ask the question: Can one attend a software engineering conference and do something good for society? We found the answer to be a resounding yes. In this article, we present our first experience of running RE Cares, a conference collocated event. This event included a workshop, conference sessions, and a hackathon for developing an application to support emergency field activity for Mutual Aid Alberta, a nonprofit organization coordinating natural disaster responses in the Canadian province.","1937-4194","","10.1109/MS.2018.2874327","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611463","","","disasters;emergency management;formal specification;software engineering","requirements engineering;social good;software types;multitasking;software engineering conference;conference collocated event;emergency field activity;Mutual Aid Alberta;RE Cares;nonprofit organization;natural disaster responses;Canadian province","","3","","1","","14 Jan 2019","","","IEEE","IEEE Magazines"
"40th International Conference on Software Engineering","",,"IEEE Software","12 Mar 2018","2018","35","2","c2","c2","Describes the above-named upcoming conference event. May include topics to be covered or calls for papers.","1937-4194","","10.1109/MS.2018.1661331","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314159","","","","","","","","","","12 Mar 2018","","","IEEE","IEEE Magazines"
"2020 Index IEEE Transactions on Software Engineering Vol. 46","",,"IEEE Transactions on Software Engineering","8 Jan 2021","2021","47","1","1","10","This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.","1939-3520","","10.1109/TSE.2020.3045901","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9318456","","","","","","","","","","8 Jan 2021","","","IEEE","IEEE Journals"
"2018 Index IEEE Transactions on Software Engineering Vol. 44","",,"IEEE Transactions on Software Engineering","8 Jan 2019","2019","45","1","1","9","Presents the 2018 subject/author index for this publication.","1939-3520","","10.1109/TSE.2018.2887195","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8605397","","","","","","","","","","8 Jan 2019","","","IEEE","IEEE Journals"
"2019 Index IEEE Transactions on Software Engineering Vol. 45","",,"IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","1","9","This index covers all technical items - papers, correspondence, reviews, etc. - that appeared in this periodical during the year, and items from previous years that were commented upon or corrected in this year. Departments and other items may also be covered if they have been judged to have archival value. The Author Index contains the primary entry for each item, listed under the first author's name. The primary entry includes the co-authors' names, the title of the paper or other item, and its location, specified by the publication abbreviation, year, month, and inclusive pagination. The Subject Index contains entries describing the item under all appropriate subject headings, plus the first author's name, the publication abbreviation, month, and year, and inclusive pages. Note that the item title is found only under the primary entry in the Author Index.","1939-3520","","10.1109/TSE.2019.2960169","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952733","","","","","","","","","","8 Jan 2020","","","IEEE","IEEE Journals"
"Software Engineering in Society","R. Kazman; L. Pasquale","Information Technology, University of Hawaii, Manoa, Hawaii United States; Computer Science, University College Dublin, Dublin, Ireland","IEEE Software","20 Dec 2019","2020","37","1","7","9","Modern Software Systems pervade our lives. They have become more open and hyperconnected, manage large amounts of our personal data, and are used to support the lives of individuals and communities and the functions of businesses and governments. They are a part of our society and play an important role in shaping it.","1937-4194","","10.1109/MS.2019.2949322","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938101","","","","","","","","0","","20 Dec 2019","","","IEEE","IEEE Magazines"
"Behavioral Science of Software Engineering","M. Petre; J. Buckley; L. Church; M. -A. Storey; T. Zimmermann","Computing and Communications, The Open University; Computer Science and Information Systems, University of Limerick, Ireland; Computer Science and Technology, University of Cambridge, United Kingdom; Applied Data Science, University of Victoria, Canada; Microsoft Research, Redmond, Washington United States","IEEE Software","23 Oct 2020","2020","37","6","21","25","Large-scale software development is a sociotechnical activity only bounded by human imagination, ingenuity, and creativity. It involves teams of developers progressing by coordinating their activities and communicating their bottlenecks, goals, and advancements toward the wider goal of creating large, high-quality software systems. The stakeholders they serve are diverse (for example, clients, infrastructure providers, open source communities, project managers, and regulatory authorities), and often they have many competing, implicit requirements. But, as the political and legal implications of algorithms and data (https://harvardmagazine.com/2000/01/code-is-law-html) increasingly affect society, it is imperative that the systems the developers build are high quality in terms of accurately embodying all of those requirements.","1937-4194","","10.1109/MS.2020.3014413","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9238655","","","","","","1","","6","","23 Oct 2020","","","IEEE","IEEE Magazines"
"41st International Conference on Software Engineering","",,"IEEE Software","27 Sep 2018","2018","35","5","c4","c4","Describes the above-named upcoming conference event. May include topics to be covered or calls for papers.","1937-4194","","10.1109/MS.2018.3571244","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474481","","","","","","","","","","27 Sep 2018","","","IEEE","IEEE Magazines"
"Front Cover","",,"IEEE Software","25 Dec 2017","2018","35","1","c1","c1","The theme articles in this issue address Software Safety and Security Risk Mitigation in Cyberphysical Systems and Actionable Analytics for Software Engineering. Other topics in the issue include modular architectures, DevOps, software standards, software bots, and requirements engineering research.","1937-4194","","10.1109/MS.2017.4541046","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239933","IEEE Software;Jan./Feb.;software safety and security;risk mitigation;cyber-physical systems;actionable analytics;software engineering;modular architectures;DevOps;software standards;software bots;requirements engineering;software development","","","","","","","","","25 Dec 2017","","","IEEE","IEEE Magazines"
"Front Cover","",,"IEEE Software","27 Sep 2018","2018","35","5","c1","c1","The articles in this issue address the 50th anniversary of software engineering. Other topics in the issue include software architecture and chaos engineering.","1937-4194","","10.1109/MS.2018.3571233","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8474515","IEEE Software;September/October 2018;software architecture;chaos engineering;software engineering;software development","","","","","","","","","27 Sep 2018","","","IEEE","IEEE Magazines"
"2019 Reviewers List","",,"IEEE Transactions on Software Engineering","8 Jan 2020","2020","46","1","114","117","The publication offers a note of thanks and lists its reviewers.","1939-3520","","10.1109/TSE.2019.2962566","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8952817","","","","","","","","","","8 Jan 2020","","","IEEE","IEEE Journals"
"2018 Reviewers List","",,"IEEE Transactions on Software Engineering","8 Jan 2019","2019","45","1","107","110","The publication offers a note of thanks and lists its reviewers.","1939-3520","","10.1109/TSE.2018.2884373","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8605391","","IEEE publishing","","","","","","","","8 Jan 2019","","","IEEE","IEEE Journals"
"2017 Reviewers List*","",,"IEEE Transactions on Software Engineering","8 Jan 2018","2018","44","1","100","102","Presents a list of reviewers who contributed to this publication in 2017.","1939-3520","","10.1109/TSE.2017.2775290","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8249563","","IEEE publishing","","","","","","","","8 Jan 2018","","","IEEE","IEEE Journals"
"Front Cover","",,"IEEE Software","12 Mar 2018","2018","35","2","c1","c1","The theme articles in this issue address release engineering. Other topics in the issue include cloud computing, agile development, software security, DevOps, software maintenance, software evolution, software architecture, software analytics, requirements engineering, continuous deployment, database management systems, and product development.","1937-4194","","10.1109/MS.2018.1661310","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8314155","IEEE Software;release engineering;cloud computing;agile development;software security;DevOps;software maintenance;software evolution;software architecture;software analytics;requirements engineering;continuous deployment;database management systems;product development;software engineering;software development","","","","","","","","","12 Mar 2018","","","IEEE","IEEE Magazines"
"Front Cover","",,"IEEE Software","4 May 2018","2018","35","3","c1","c1","The theme articles in this issue address microservices. Other topics in the issue include unit testing, WordPress, the Internet of Things, agile development, requirements engineering, and Java 9.","1937-4194","","10.1109/MS.2018.2141021","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8354416","IEEE Software;May/June 2018;microservices;unit testing;WordPress;Internet of Things;IoT;agile development;requirements engineering;Java 9;software engineering;software development","","","","","","","","","4 May 2018","","","IEEE","IEEE Magazines"
"Front Cover","",,"IEEE Software","6 Jul 2018","2018","35","4","c1","c1","The articles in this issue address process improvement. Other topics in the issue include software architecture, test-driven development, software testing, and blockchains.","1937-4194","","10.1109/MS.2018.2801558","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8405625","IEEE Software;July/August 2018;process improvement;software architecture;test-driven development;software testing;blockchains;software engineering;software development","","","","","","","","","6 Jul 2018","","","IEEE","IEEE Magazines"
"Front Cover","",,"IEEE Software","29 Nov 2018","2018","35","6","c1","c1","Presents the front cover for this issue of the publication.","1937-4194","","10.1109/MS.2018.4321249","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8552625","IEEE Software;November/December 2018;collaborative modeling;agile development;gender;safety-critical systems;and refactoring;software engineering;software development","","","","","","","","","29 Nov 2018","","","IEEE","IEEE Magazines"
"Are DevOps and Automation Our Next Silver Bullet?","I. Ozkaya",NA,"IEEE Software","17 Jun 2019","2019","36","4","3","95","Fred brooks, in his well-known classic The Mythical Man-Month, already told the software engineering industry in 1975 that there are no silver bullets in gaining an order-of-magnitude improvement in software productivity.1 He also observed that ""most of the big past gains in software productivity have come from removing artificial barriers that have made the accidental tasks inordinately hard, such as severe hardware constraints, awkward programming languages, lack of machine time."" The hope and goal of software development processes in orchestrating the essential and accidental software engineering and development tasks is precisely to remove artificial barriers to delivering better, faster, cheaper software to the users. Our next silver bullet seems to have emerged as automating repeatable, manual process tasks. While, on one hand, we debate how to scale agile, on the other, we run to DevOps, continuous integration, and continuous delivery tools to achieve the so-called orders of magnitude of productivity improvement.","1937-4194","","10.1109/MS.2019.2910943","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8738081","","","software development management;software maintenance;software product lines","hardware constraints;awkward programming languages;software productivity;order-of-magnitude improvement;software engineering industry;Mythical Man-Month;fred brooks;productivity improvement;manual process tasks;automating repeatable process tasks;silver bullet;artificial barriers;accidental software engineering;software development processes","","","","10","","17 Jun 2019","","","IEEE","IEEE Magazines"
"(Research) Insights for Serverless Application Engineering","J. C. Carver; B. Penzenstadler; J. Scheuner; M. Staron","Computer Science, University of Alabama, Tuscaloosa, Alabama United States; Chalmers University of Technology, Gothenburg, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden; Software Engineering, Chalmers University of Technology, Gothenburg, Sweden","IEEE Software","23 Dec 2020","2021","38","1","123","125","Presents summaries of articles included in this issue of the publication.","1937-4194","","10.1109/MS.2020.3028659","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9305894","","","","","","","","4","IEEE","23 Dec 2020","","","IEEE","IEEE Magazines"
"The Social Developer: The Future of Software Development [Guest Editors' Introduction]","T. Mens; M. Cataldo; D. Damian","Computer Science, University of Mons, Belgium; Uber Advanced Technologies Group; Computer Science, University of Victoria","IEEE Software","14 Jan 2019","2019","36","1","11","14","Contemporary Software Engineering has inevitably become much more social. Due to the size, complexity, and diversity of today's software systems, there is a need to interact across organizational, geographical, cultural, and socioeconomic boundaries. Large-scale software development now implies active user involvement and requires close cooperation and collaboration between team members and all types of development activities. Members of software projects across all roles must communicate and interact continuously with other project members as well as with a variety of stakeholders, such as users, analysts, suppliers, customers, and business partners. This theme issue aims to inform software engineering practitioners about current trends and recent advances in research and practice of sociotechnical analysis and support for large-scale software development.","1937-4194","","10.1109/MS.2018.2874316","F.R.S. - FNRS Belgique; F.R.S. - FNRS Belgique; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611456","","Special issues and sections;Software development management;Software development;Collaboration;Sociotechnical systems;Software engineering","","","","1","","9","","14 Jan 2019","","","IEEE","IEEE Magazines"
"Ethics Is a Software Design Concern","I. Ozkaya",Carnegie Mellon Software Engineering Institute,"IEEE Software","16 Apr 2019","2019","36","3","4","8","The IEEE and Association for Computing Machinery (ACM) joint report ""Software Engineering Code of Ethics"" summarizes the responsibilities of software engineers as the following: ""Software engineers shall commit themselves to making the analysis, specification, design, development, testing and maintenance of software beneficial and respected profession.""","1937-4194","","10.1109/MS.2019.2902592","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8693077","","","","","","2","","10","","16 Apr 2019","","","IEEE","IEEE Magazines"
"Software Safety and Security Risk Mitigation in Cyber-physical Systems","M. Biro; A. Mashkoor; J. Sametinger; R. Seker",Software Competence Center Hagenberg; Software Competence Center Hagenberg; Johannes Kepler University Linz; Embry-Riddle Aeronautical University,"IEEE Software","25 Dec 2017","2018","35","1","24","29","Cyber-physical systems (CPSs) offer many opportunities but pose many challenges—especially regarding functional safety, cybersecurity, and their interplay, as well as the systems’ impact on society. Consequently, new methods and techniques are needed for CPS development and assurance. The articles in this theme issue aim to help address some of these challenges.","1937-4194","","10.1109/MS.2017.4541050","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8239950","software safety;software security;risk mitigation;cyber-physical systems;action-oriented programming;AcOP;probabilistic threat estimation;industrial control systems;software engineering;software development","","","","","5","","17","","25 Dec 2017","","","IEEE","IEEE Magazines"
"What Should a Software Engineer Know?","I. Ozkaya",Carnegie Mellon Software Engineering Institute,"IEEE Software","20 Dec 2019","2020","37","1","3","6","A Software Engineer applies the principles of engineering to the design, development, maintenance, testing, and evaluation of a softwareenabled system. While this fundamental understanding of what a software engineer does is commonly shared, the journey to understand what a software engineer should know evolves, mostly as a consequence of the rapid pace of technological changes.","1937-4194","","10.1109/MS.2019.2946668","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8938103","","","","","","","","7","","20 Dec 2019","","","IEEE","IEEE Magazines"
"If it does not scale, it does not work!","I. Ozkaya","Carnegie Mellon Software Engineering Institute, United States","IEEE Software","21 Feb 2019","2019","36","2","4","7","The world runs on lots of software. For many businesses and domains, this results in more software elements to develop and maintain. The added software elements often make for greater software complexity, which leads, in turn, to increased need for coordination between multiple software teams that build, integrate, and test the software. This increasing complexity often aggravates the challenges of ""large-scale"" software. Achieving scalability means different things in different contexts. The Editor briefly reviews scale, discussed from three different perspectives: scope, people, and time. Scope is about capabilities in terms of added features, greater size, and increased complexity of the system the software serves. The category of people includes the scale of the development organization and the software users. The category of time relates to the expected life of the system. It is then noted that this issue of IEEE Software presents different perspectives of scale with two themes, thus viewing the topic of scale from the perspective of development as well as software property. Articles under the theme ""Large-Scale Agile Development"" look into scaling development teams in large projects and organizations using agile software development methods. Articles under the theme ""Building Long-Lived Adaptive Systems"" cover state-of-the-art developments related to automated adaptive approaches for engineering systems that stand the test of time.","1937-4194","","10.1109/MS.2018.2885991","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648253","","","","","","1","","8","","21 Feb 2019","","","IEEE","IEEE Magazines"
"The Deployment View","I. Ozkaya","Software Engineering, Carnegie Mellon University","IEEE Software","15 Apr 2020","2020","37","3","3","5","The term DevOps grew out of conversations that Patrick Debois, a system administrator at the time, and Andrew Shafer, a software developer, were having in 2009 along with others sharing their frustrations in how difficult it was to move development to operations. They observed that the agility, automation, and communication barriers between development and operations teams were common across many organizations. The developers put the responsibility on operations and mismatches in the deployment environment. The operations teams assumed that the problems culminated from the implementation. The teams clearly lacked a common deployment and operations view of the system, one of the key aspects of any system's architecture.","1937-4194","","10.1109/MS.2020.2971573","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9068374","","","","","","","","5","","15 Apr 2020","","","IEEE","IEEE Magazines"
"Trends in Agile: From Operational to Strategic Agility [Practitioners' Digest]","R. Prikladnicki; C. Lassenius; J. C. Carver","Technology, Pontifical Catholic University of Rio Grande do Sul; Software Engineering, Aalto University; Computer Science, University of Alabama, United States","IEEE Software","14 Jan 2019","2019","36","1","95","97","Reports on meetings and events that were part of the 2018 Agile Conference hat took place August 6-10 in San Diego, CA. ","1937-4194","","10.1109/MS.2018.2875649","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8611452","","","","","","","","0","","14 Jan 2019","","","IEEE","IEEE Magazines"
"Mom, Where Are the Girls?","I. Ozkaya","Software Engineering Institute, Carnegie Mellon, United States","IEEE Software","15 Feb 2021","2021","38","2","3","6","During the fall semester of 2005, I was working hastily on the finishing touches of my Ph.D. dissertation at Carnegie Mellon University. That semester, I also was the teaching assistant for the Methods of Software Development graduate course taught by Dr. Mary Shaw and Dr. Jim Herbsleb. It was a busy time, with the challenges of finishing graduate school; getting ready for a new job; fulfilling responsibilities such as grading and helping students; and parenting my then three-and-a-half-year-old daughter. Methods of Software Development was a demanding course with a lot of reading and reflection assignments. Students took abundant advantage of the office hours. Those meetings always went better if I remembered the students' names, but with that was all going on, my brain did not always comply, so I had a hack. I had printed all of their photos and hung them right above my desk.","1937-4194","","10.1109/MS.2020.3044410","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9354391","","","","","","","","4","IEEE","15 Feb 2021","","","IEEE","IEEE Magazines"
"Ignore, Refactor, or Rewrite","G. Fairbanks",Google,"IEEE Software","21 Feb 2019","2019","36","2","133","136","Most of the guidance applies to smaller chunks of code and decisions implemented in hours or days, not weeks or months. There were a great book on architecture scale refactoring with distilled wisdom and case studies of successes and failures. This article only touches on that but it covers some topics that augment the good advice you will find in Martin Fovvler's Refactoring book and Michael Feathers' Working Effectively with Legacy Code.","1937-4194","","10.1109/MS.2018.2880662","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648269","","Code refractoring;Encoding;Software engineering","software architecture;software maintenance","architecture scale refactoring;software refactoring","","","","6","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Computational Reproducibility: The Elephant in the Room","L. Hatton; M. van Genuchten","Kingston University, London, United Kingdom; VitalHealth Software","IEEE Software","21 Feb 2019","2019","36","2","137","144","Examines the concept of computational reproducibility. Reports on the development of software programming and addresses the challenges of managing software development and developing reliability software update and maintenance procedures.","1937-4194","","10.1109/MS.2018.2883805","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648256","","Software engineering;Software reliability;Software maintenance","","","","","","16","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Quality, Nontechnical Skills, Blind Programmers, and Deep Learning","J. Carver",NA,"IEEE Software","21 Feb 2019","2019","36","2","127","136","Reports from the 34th International Conference on Software Maintenance and Evolution, the 44th Euromicro Conference on Software Engineering and Advanced Applications, and the 12th International Symposium on Empirical Software Engineering and Measurement (ESEM). ","1937-4194","","10.1109/MS.2018.2883874","","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648271","","","","","","","","6","","21 Feb 2019","","","IEEE","IEEE Magazines"
"Twenty Years of Open Source Software: From Skepticism to Mainstream","G. Robles; I. Steinmacher; P. Adams; C. Treude","Universidad Rey Juan Carlos, Madrid, Spain; Informatics, Computing, and Cyber Systems, Northern Arizona University, Flagstaff, United States; Wayfair; Computer Science, University of Adelaide, Australia","IEEE Software","23 Oct 2019","2019","36","6","12","15","Open source software (OSS) has conquered the software world. You can see it nearly everywhere, from Internet infrastructure to mobile phones to the desktop. In addition to that, although many OSS practices were viewed with skepticism 20 years ago, several have become mainstream in software engineering today: from development tools such as Git to practices such as modern code reviews.","1937-4194","","10.1109/MS.2019.2933672","Regional Government of Madrid; Spanish Government; Australian Research Councils Discovery Early Career Researcher Award; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8880574","","","","","","2","","0","","23 Oct 2019","","","IEEE","IEEE Magazines"
"Agile Development at Scale: The Next Frontier","T. Dingsoeyr; D. Falessi; K. Power","SINTEF Digital, Trondheim, Norway; California Polytechnic State University, San Luis Obispo; NA","IEEE Software","21 Feb 2019","2019","36","2","30","38","Agile methods have transformed the way software is developed, emphasizing active end-user involvement, tolerance to change, and evolutionary delivery of products. The first special issue on agile development described the methods as focusing on feedback and change.<sup>1</sup> These methods have led to major changes in how software is developed. Scrum is now the most common framework for development in most countries, and other methods such as extreme programming (XP), elements of lean software development, and Kanban are widely used. What started as a bottom-up movement among software practitioners and consultants has been taken up by major international consulting companies who prescribe agile development, particularly for contexts where learning and innovation are key. Agile development methods have attracted interest primarily in software engineering<sup>1, 2</sup> but also in a number of other disciplines including information systems<sup>3</sup> and project management.<sup>4</sup>","1937-4194","","10.1109/MS.2018.2884884","Norges Forskningsråd; ","https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8648272","","Special issues and sections;Agile software development;Software development management","","","","1","","28","","21 Feb 2019","","","IEEE","IEEE Magazines"
